{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found: ../NewsEdits/data/newsedits_edits_pairs.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt; p &gt; Lopes was arrested and rushed to a hospi...</td>\n",
       "      <td>&lt; p &gt; Lopes was arrested and taken to a hospit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt; p &gt; According to the letter , a uniformed Bo...</td>\n",
       "      <td>The mayor and his security detail were spotte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt; p &gt; According to the letter , a uniformed Bo...</td>\n",
       "      <td>&lt; p &gt; According to the letter , a uniformed Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt; p &gt; According to the letter , a uniformed Bo...</td>\n",
       "      <td>&lt; p &gt; According to the letter , a uniformed Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt; p &gt; Undated file photo shows Emmett Louis Ti...</td>\n",
       "      <td>&lt; /p &gt; &lt; p &gt; Undated file photo shows Emmett ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15228</th>\n",
       "      <td>( Palm Beach County Sheriff 's Office ) &lt; /p &gt;...</td>\n",
       "      <td>&lt; p &gt; Newly released video shows the moment a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15229</th>\n",
       "      <td>&lt; /p &gt; &lt; p &gt; While the winning team from Brita...</td>\n",
       "      <td>&lt; p &gt; While the winning team from Britain cro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15230</th>\n",
       "      <td>&lt; /p &gt; &lt; p &gt; While holding his baby daughter ,...</td>\n",
       "      <td>&lt; p &gt; While holding his baby daughter , James...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15231</th>\n",
       "      <td>&lt; /p &gt; &lt; p &gt; A team of experts from Israel , t...</td>\n",
       "      <td>&lt; p &gt; A team of experts from Israel , the U.S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15232</th>\n",
       "      <td>&lt; /p &gt; &lt; p &gt; Her body has n't been found , but...</td>\n",
       "      <td>&lt; p &gt; Her body has n't been found , but her f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15233 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  before  \\\n",
       "0      < p > Lopes was arrested and rushed to a hospi...   \n",
       "1      < p > According to the letter , a uniformed Bo...   \n",
       "2      < p > According to the letter , a uniformed Bo...   \n",
       "3      < p > According to the letter , a uniformed Bo...   \n",
       "4      < p > Undated file photo shows Emmett Louis Ti...   \n",
       "...                                                  ...   \n",
       "15228  ( Palm Beach County Sheriff 's Office ) < /p >...   \n",
       "15229  < /p > < p > While the winning team from Brita...   \n",
       "15230  < /p > < p > While holding his baby daughter ,...   \n",
       "15231  < /p > < p > A team of experts from Israel , t...   \n",
       "15232  < /p > < p > Her body has n't been found , but...   \n",
       "\n",
       "                                                   after  \n",
       "0      < p > Lopes was arrested and taken to a hospit...  \n",
       "1       The mayor and his security detail were spotte...  \n",
       "2      < p > According to the letter , a uniformed Bo...  \n",
       "3      < p > According to the letter , a uniformed Bo...  \n",
       "4       < /p > < p > Undated file photo shows Emmett ...  \n",
       "...                                                  ...  \n",
       "15228   < p > Newly released video shows the moment a...  \n",
       "15229   < p > While the winning team from Britain cro...  \n",
       "15230   < p > While holding his baby daughter , James...  \n",
       "15231   < p > A team of experts from Israel , the U.S...  \n",
       "15232   < p > Her body has n't been found , but her f...  \n",
       "\n",
       "[15233 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../NewsEdits/data/newsedits_edits_pairs.csv'\n",
    "# Step 1: Verify the file path\n",
    "if not os.path.exists(file_path):\n",
    "    print(\"File not found:\", file_path)\n",
    "else:\n",
    "    print(\"File found:\", file_path)\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop a column (e.g., 'column2')\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo=\"NewsEdits\"\n",
    "n_sampels_pilot_study=100\n",
    "n_sampels_pilot_study_list=[30, 35, 35]\n",
    "n_samples_comparing_group=1000\n",
    "random_seed=41\n",
    "\n",
    "# repo=\"arXivEdits\"\n",
    "# n_sampels_pilot_study=15\n",
    "# n_sampels_pilot_study_list=[5, 5, 5]\n",
    "# n_samples_comparing_group=165\n",
    "# random_seed=41\n",
    "# group_by=['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>&lt; /p &gt; &lt; p &gt; `` Donald Trump has done a lot of...</td>\n",
       "      <td>`` Donald Trump has done a lot of horrible th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4594</th>\n",
       "      <td>&lt; /p &gt; &lt; p &gt; Flake was unsupportive of Preside...</td>\n",
       "      <td>&lt; /p &gt; &lt; p &gt; Flake was unsupportive of Preside...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13410</th>\n",
       "      <td>( Truman Little White House ) &lt; /p &gt; &lt; p &gt; '' ...</td>\n",
       "      <td>&lt; /p &gt; &lt; p &gt; '' While they are higher-end fur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073</th>\n",
       "      <td>This is on Publish with no configured Image &lt; ...</td>\n",
       "      <td>&lt; p &gt; Chick-fil-A claims to have given away a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13858</th>\n",
       "      <td>&lt; p &gt; &lt; /p &gt; &lt; p &gt; A federal judge dismissed a...</td>\n",
       "      <td>&lt; p &gt; &lt; /p &gt; &lt; p &gt; Taylor Swift testified Thur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>&lt; p &gt; Earlier Saturday , Hawaiian citizens rep...</td>\n",
       "      <td>&lt; p &gt; At about 8:07 a.m. local time , Hawaiian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12492</th>\n",
       "      <td>&lt; /p &gt; &lt; p &gt; According to Stars and Stripes , ...</td>\n",
       "      <td>&lt; p &gt; According to Stars and Stripes , the U....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13407</th>\n",
       "      <td>&lt; /p &gt; &lt; p &gt; Click for more from Fox 7. &lt; /p &gt;...</td>\n",
       "      <td>&lt; /p &gt; &lt; p &gt; Click for more from Fox 7. &lt; /p &gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>Jason Chaffetz , R-Utah , in 2015. &lt; /p &gt; &lt; p ...</td>\n",
       "      <td>&lt; p &gt; Rhee is a former partner at WilmerHale ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7685</th>\n",
       "      <td>&lt; /p &gt; &lt; p &gt; '' FBI personnel are on scene con...</td>\n",
       "      <td>&lt; /p &gt; &lt; /p &gt; &lt; p &gt; THE WEEK IN PICTURES &lt; p &gt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  before  \\\n",
       "3260   < /p > < p > `` Donald Trump has done a lot of...   \n",
       "4594   < /p > < p > Flake was unsupportive of Preside...   \n",
       "13410  ( Truman Little White House ) < /p > < p > '' ...   \n",
       "6073   This is on Publish with no configured Image < ...   \n",
       "13858  < p > < /p > < p > A federal judge dismissed a...   \n",
       "...                                                  ...   \n",
       "3071   < p > Earlier Saturday , Hawaiian citizens rep...   \n",
       "12492  < /p > < p > According to Stars and Stripes , ...   \n",
       "13407  < /p > < p > Click for more from Fox 7. < /p >...   \n",
       "1185   Jason Chaffetz , R-Utah , in 2015. < /p > < p ...   \n",
       "7685   < /p > < p > '' FBI personnel are on scene con...   \n",
       "\n",
       "                                                   after  \n",
       "3260    `` Donald Trump has done a lot of horrible th...  \n",
       "4594   < /p > < p > Flake was unsupportive of Preside...  \n",
       "13410   < /p > < p > '' While they are higher-end fur...  \n",
       "6073    < p > Chick-fil-A claims to have given away a...  \n",
       "13858  < p > < /p > < p > Taylor Swift testified Thur...  \n",
       "...                                                  ...  \n",
       "3071   < p > At about 8:07 a.m. local time , Hawaiian...  \n",
       "12492   < p > According to Stars and Stripes , the U....  \n",
       "13407    < /p > < p > Click for more from Fox 7. < /p >   \n",
       "1185    < p > Rhee is a former partner at WilmerHale ...  \n",
       "7685   < /p > < /p > < p > THE WEEK IN PICTURES < p >...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the sampling function\n",
    "def sample_data(group, n=1, random_state=42):\n",
    "    return group.sample(n=min(len(group), n), random_state=random_state)\n",
    "\n",
    "# Sample n rows per 'domain' and 'label' combination with a random seed\n",
    "# sampled_df = df.groupby(group_by).apply(sample_data, n=n_sampels_pilot_study, random_state=random_seed).reset_index(drop=True)\n",
    "sampled_df = df.sample(n=n_sampels_pilot_study, random_state=random_seed)\n",
    "\n",
    "# Display the sampled DataFrame\n",
    "sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the sampled data\n",
    "sampled_indices = sampled_df.index\n",
    "\n",
    "# Drop the sampled data to get the remaining data\n",
    "remaining_df = df.drop(sampled_indices)\n",
    "\n",
    "remaining_df = remaining_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to JSON Lines format and save to a file\n",
    "sampled_df.to_json(f\"./{repo}/pilot_study_{repo.lower()}.json\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx, n_samples in enumerate(n_sampels_pilot_study_list):\n",
    "    # Sample n rows per 'domain' and 'label' combination with a random seed\n",
    "    # sampled_iter_df = sampled_df.groupby(group_by).apply(sample_data, n=n_samples, random_state=random_seed).reset_index(drop=True)\n",
    "    sampled_iter_df = sampled_df.sample(n=n_samples, random_state=random_seed)\n",
    "\n",
    "    sampled_iter_df.to_json(f\"./{repo}/pilot_study_{repo.lower()}_iter{idx+1}.json\", orient='records', lines=True)\n",
    "\n",
    "    # Get the indices of the sampled data\n",
    "    sampled_iter_indices = sampled_iter_df.index\n",
    "\n",
    "    # Drop the sampled data to get the remaining data\n",
    "    sampled_df = sampled_df.drop(sampled_iter_indices)\n",
    "    # Reset the index\n",
    "    sampled_df = sampled_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset for comparing group\n",
    "\n",
    "# Sample n rows per 'domain' and 'label' combination with a random seed\n",
    "# comparing_df = remaining_df.groupby(group_by).apply(sample_data, n=n_samples_comparing_group, random_state=random_seed).reset_index(drop=True)\n",
    "comparing_df = remaining_df.sample(n=n_samples_comparing_group, random_state=random_seed).reset_index(drop=True)\n",
    "\n",
    "comparing_df.to_json(f\"./{repo}/comparing_group_{repo.lower()}.json\", orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manualcmp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
