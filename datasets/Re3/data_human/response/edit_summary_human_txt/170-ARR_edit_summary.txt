In the section response decoder, the sub-section title multimodal fusion was deleted.
In the section experiments, two facts were deleted about how the author optimized the models and second was an instruction to refer to Appendix B and C for details of data and training. The title for sub-section training details was added. Following that, four claims were added; first one was about the observations implying GPT-based models capturing better video context, where second was about how and when these models may fail. The third claim was about the possibility that GPT-models being inferior to VGNMN where the fourth claim was about the finding that VGNMN applied to object-level features being competitive to the model applied to CNN-based features. Another title for sub-section under this section which was The Robustness. Under this sub-section, four facts were added; the first fact was about what was reported to evaluate the model robustness where second fact was about comparing against performance of output response. The third fact was about how video features were retrieved and final fact was about dialogue history being encoded by a hierarchical LSTM encoder. The final edit in the experiment section was a clarity change where question type distribution was changed to type distribution. At the end of this section, a claim was deleted about what future work may focus on. 
In the section broader impacts, extension of this work was changed to extension of work. Following that seven facts were deleted; the first fact was about what was done to learn compositional programs. The second fact was about adopting a simple template where the third one was about the resulting target sequence for dialogue and video understanding. The fourth fact that was deleted was about the parser decompose questioning into subsequences where the fifth fact was about each parser being an attention-based Transformer decoder. The second mast fact was about the Transformer attention where the final fact that was deleted was about what was used to obtain the weighted sum of the corresponding representations in the v sequence. The final edit in this section was a clarity change where feed-forward network was replaced by network. 
A new section title was added (how to locate entities?). 