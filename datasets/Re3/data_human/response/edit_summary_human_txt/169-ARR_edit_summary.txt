In the abstract, few minor edits were done to improve the clarity of the sentence. 
In the introduction, a clarity change was administered where repeated wordings from question-annotator and answer-annotator was changed to question-and answer-annotator. At the end of this section, the website where the codes from the study was made publicly available was added. 
In learning and interaction scenario, a fact was added about the aim of the learner. Following that, a grammar change was made where users were replaced with user and necessary verbs were changed. A fact change was done where the additional information about the learner regret was deleted and equation 1 was added. How regret is calculated in the study was deleted. There was a clarity change following that, optimal model (i.e., policy) was replaced by optimal policy. And finally, additional information about cumulative regret at time T being computed with respect to the optimal policy was updated. 
In simulation setup, majority of the changes were grammatical where first one was changing 'to all be bad' to 'to be all bad'. The second grammar edit was from plural to singular (from sections to section). Third was an addition of a preposition where fourth was the form of comparative (from more strict to stricter). Two changes were made where the wording of a number was replaced with the number itself i.e. from four to 4 and from three to 3. The final grammar change was an addition of a punctuation mark in 1024. Fact was added about MRQA simplifying datasets. And a sentence was re-written about why dropout was turned off.
In online learning, a clarity change was made where feedback collection was replaced by feedback is observed. A typo was also corrected (from The to this). Two claims were deleted about what might happen when one start with weaker initial models and learning with a higher noises where the second claim was about what happens when online perturbation-free simulation fails. The third deletion was a fact about the learning progression across datasets. Rest two deletion were claims where first claim was about training transformer-based models and the second claim was about non-standard training procedure.
In offline learning, the claim being transformer based model best optimised with a linear learning rate has been changed to transformer based model being better optimised with a linear learning rate. Towards the end of the section, a fact about how regret numbers are averaged was added and a claim about the reasons as to why online learning displays lower regret was added. 
In domain adaptation, the target domains has been further intensified with the addition of the word new. Two facts were deleted, first was about the study reporting experiments with online learning and second, the location where offline adaptation experiments were discussed. Following that, a claim was added about the reason why final performance is better with SQUAD-initialized model. Next, a fact was added about how on SearchQA, learning with SQUAD-initialized model performs worse. At the end of this section, a fact was deleted about NewsQA and how Trischler et al. report human performance. 
In related work, a citation was added in Neural machine translation (NMT). Next, a citation was added in the semantics and dialogue along with the citation was deleted. Following that, fact about implicit human feedback was added. Moreover, a claim was added about the explicit feedback. A clarity change has been made where other form of words were used from it seeks to seeking. In this section, 5 facts were added where the first one was about what Campos et al. (2020) proposed. The second fact was about their approaches which relies on multiple samples. The third fact was about the research studying improving QA systems via feedback. Fourth fact was about author's assumptions in both online and offline setups. The fifth fact was about what the study provided. At the end of this section, a clarity change was made with small change in the words from studied in prior work to widely studied. 
In conclusion section, four facts were added, first being the location of the limitations of the work. Second, being all six datasets that are found publicly. Third was about What section 4 reports and fourth was the location where the codebase is available. A clarity change has been made where the sentence was re-written where using F1 as feedback has been deleted.  
