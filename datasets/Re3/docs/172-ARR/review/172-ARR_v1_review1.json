{
    "nodes": [
        {
            "ix": "172-ARR_v1_review1_0",
            "content": "172-ARR_v1_review1",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "172-ARR_v1_review1_1",
            "content": "paper_summary. XDBERT is a cross-model model for NLU that is distilled from CLIP-T, the vision-grounded text encoder of CLIP. The resulted model outperforms its teachers on GLUE and other tasks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "172-ARR_v1_review1_2",
            "content": "summary_of_strengths. - The idea behind the paper is intuitive and straightforward.\n-The results are a little surprising to me and they look good.\n-Experimental details are provided in the appendix, which is good for reproducibility.\n-The authors only use Wiki103 as the distillation corpus, which is easy to reproduce and desirable for computational budgets.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "172-ARR_v1_review1_3",
            "content": "summary_of_weaknesses. ### Original comments from previous review -The main concern is the technical novelty of this paper. There is little novelty since the distillation technique is not new while the idea of cross-model training is not new, either.\n-I'm surprised that in Table 1 CLIP-T performs so badly even when finetuned. Can you explain why?\n-Is it possible that the improvement of the distilled cross-modal model comes from ensembling instead of visual grounding?\n-I suggest the authors make the weights publically available (can be anonymous during double-blind reviewing) so the results can be easily verified by the community.\nAlthough some details are vague and need further investigation, I think the contribution is enough to be accepted as a short paper.\n### After rebuttal Thanks for resubmitting the paper with a response. I've carefully read the response.\n-**Re. To Reviewer2.1**: First, distilling B task into A task improves A is not so surprising. This idea has been explored in Intermediate-Task Transfer Learning. I agree that distilling cross-modal model to a single-modal model is somewhat novel. However, even self-distillation can improve accuracy so I have no idea to what extent is cross-modal distillation helpful.\n-**Re. To Reviewer2.2**: Good answer.\n-**Re. To Reviewer2.3**: Sorry for the confusion. Yes, when fine-tuning there is only the BERT encoder used. However, I suspect that substituting CLIP with any pretrained LM would also work. But again, as the authors point out, \"the linguistic competence is CLIP-T very low\" so this paper has some insights and presents previously unknown results. That's why I gave this paper a score of 3.5.\n-**Re. To Reviewer2.4**: That should be easy. Just manually reassign the weights in the original `state_dict` to a `state_dict` of a Hugging Face BERT model. That would work.\nThus, I keep my recommendation of weak acceptance for this paper and I suggest other reviewers consider increasing their scores.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "172-ARR_v1_review1_4",
            "content": "comments,_suggestions_and_typos. N/A",
            "ntype": "p",
            "meta": null
        }
    ],
    "span_nodes": [
        {
            "ix": "172-ARR_v1_review1_0@0",
            "content": "172-ARR_v1_review1",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_0",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_1@0",
            "content": "paper_summary.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_1",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_1@1",
            "content": "XDBERT is a cross-model model for NLU that is distilled from CLIP-T, the vision-grounded text encoder of CLIP.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_1",
            "start": 15,
            "end": 124,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_1@2",
            "content": "The resulted model outperforms its teachers on GLUE and other tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_1",
            "start": 126,
            "end": 193,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_2@0",
            "content": "summary_of_strengths.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_2",
            "start": 0,
            "end": 20,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_2@1",
            "content": "- The idea behind the paper is intuitive and straightforward.\n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_2",
            "start": 22,
            "end": 83,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_2@2",
            "content": "-The results are a little surprising to me and they look good.\n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_2",
            "start": 84,
            "end": 146,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_2@3",
            "content": "-Experimental details are provided in the appendix, which is good for reproducibility.\n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_2",
            "start": 147,
            "end": 233,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_2@4",
            "content": "-The authors only use Wiki103 as the distillation corpus, which is easy to reproduce and desirable for computational budgets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_2",
            "start": 234,
            "end": 358,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@0",
            "content": "summary_of_weaknesses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@1",
            "content": "### Original comments from previous review -The main concern is the technical novelty of this paper.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 23,
            "end": 122,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@2",
            "content": "There is little novelty since the distillation technique is not new while the idea of cross-model training is not new, either.\n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 124,
            "end": 250,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@3",
            "content": "-I'm surprised that in Table 1 CLIP-T performs so badly even when finetuned.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 251,
            "end": 326,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@4",
            "content": "Can you explain why?\n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 328,
            "end": 348,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@5",
            "content": "-Is it possible that the improvement of the distilled cross-modal model comes from ensembling instead of visual grounding?\n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 349,
            "end": 471,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@6",
            "content": "-I suggest the authors make the weights publically available (can be anonymous during double-blind reviewing) so the results can be easily verified by the community.\n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 472,
            "end": 637,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@7",
            "content": "Although some details are vague and need further investigation, I think the contribution is enough to be accepted as a short paper.\n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 638,
            "end": 769,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@8",
            "content": "### After rebuttal Thanks for resubmitting the paper with a response.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 770,
            "end": 838,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@9",
            "content": "I've carefully read the response.\n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 840,
            "end": 873,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@10",
            "content": "-**Re.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 874,
            "end": 879,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@11",
            "content": "To Reviewer2.1**: First, distilling B task into A task improves A is not so surprising.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 881,
            "end": 967,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@12",
            "content": "This idea has been explored in Intermediate-Task Transfer Learning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 969,
            "end": 1035,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@13",
            "content": "I agree that distilling cross-modal model to a single-modal model is somewhat novel.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 1037,
            "end": 1120,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@14",
            "content": "However, even self-distillation can improve accuracy so I have no idea to what extent is cross-modal distillation helpful.\n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 1122,
            "end": 1244,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@15",
            "content": "-**Re.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 1245,
            "end": 1250,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@16",
            "content": "To Reviewer2.2**: Good answer.\n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 1252,
            "end": 1282,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@17",
            "content": "-**Re.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 1283,
            "end": 1288,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@18",
            "content": "To Reviewer2.3**: Sorry for the confusion.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 1290,
            "end": 1331,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@19",
            "content": "Yes, when fine-tuning there is only the BERT encoder used.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 1333,
            "end": 1390,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@20",
            "content": "However, I suspect that substituting CLIP with any pretrained LM would also work.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 1392,
            "end": 1472,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@21",
            "content": "But again, as the authors point out, \"the linguistic competence is CLIP-T very low\" so this paper has some insights and presents previously unknown results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 1474,
            "end": 1629,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@22",
            "content": "That's why I gave this paper a score of 3.5.\n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 1631,
            "end": 1675,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@23",
            "content": "-**Re.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 1676,
            "end": 1681,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@24",
            "content": "To Reviewer2.4**: That should be easy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 1683,
            "end": 1720,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@25",
            "content": "Just manually reassign the weights in the original `state_dict` to a `state_dict` of a Hugging Face BERT model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 1722,
            "end": 1832,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@26",
            "content": "That would work.\n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 1834,
            "end": 1850,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_3@27",
            "content": "Thus, I keep my recommendation of weak acceptance for this paper and I suggest other reviewers consider increasing their scores.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_3",
            "start": 1851,
            "end": 1978,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_4@0",
            "content": "comments,_suggestions_and_typos.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_4",
            "start": 0,
            "end": 31,
            "label": {}
        },
        {
            "ix": "172-ARR_v1_review1_4@1",
            "content": "N/A",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "172-ARR_v1_review1_4",
            "start": 33,
            "end": 35,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "172-ARR_v1_review1_0",
            "tgt_ix": "172-ARR_v1_review1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "172-ARR_v1_review1_0",
            "tgt_ix": "172-ARR_v1_review1_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "172-ARR_v1_review1_0",
            "tgt_ix": "172-ARR_v1_review1_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "172-ARR_v1_review1_0",
            "tgt_ix": "172-ARR_v1_review1_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "172-ARR_v1_review1_0",
            "tgt_ix": "172-ARR_v1_review1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "172-ARR_v1_review1_1",
            "tgt_ix": "172-ARR_v1_review1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "172-ARR_v1_review1_2",
            "tgt_ix": "172-ARR_v1_review1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "172-ARR_v1_review1_0",
            "tgt_ix": "172-ARR_v1_review1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_1",
            "tgt_ix": "172-ARR_v1_review1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_1",
            "tgt_ix": "172-ARR_v1_review1_1@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_1",
            "tgt_ix": "172-ARR_v1_review1_1@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_2",
            "tgt_ix": "172-ARR_v1_review1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_2",
            "tgt_ix": "172-ARR_v1_review1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_2",
            "tgt_ix": "172-ARR_v1_review1_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_2",
            "tgt_ix": "172-ARR_v1_review1_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_2",
            "tgt_ix": "172-ARR_v1_review1_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@12",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@13",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@14",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@15",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@16",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@17",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@18",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@19",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@20",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@21",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@22",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@23",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@24",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@25",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@26",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_3",
            "tgt_ix": "172-ARR_v1_review1_3@27",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_4",
            "tgt_ix": "172-ARR_v1_review1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "172-ARR_v1_review1_4",
            "tgt_ix": "172-ARR_v1_review1_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "172-ARR_v1_review1",
    "meta": {
        "ix_counter": 43,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy"
    }
}