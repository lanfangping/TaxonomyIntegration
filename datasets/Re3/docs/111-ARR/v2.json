{
    "nodes": [
        {
            "ix": "111-ARR_v2_0",
            "content": "Few-shot Controllable Style Transfer for Low-Resource Multilingual Settings",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_2",
            "content": "Style transfer is the task of rewriting a sentence into a target style while approximately preserving content. While most prior literature assumes access to a large style-labelled corpus, recent work (Riley et al., 2021) has attempted \"few-shot\" style transfer using just 3-10 sentences at inference for style extraction. In this work, we study a relevant low-resource setting: style transfer for languages where no style-labelled corpora are available. We notice that existing few-shot methods perform this task poorly, often copying inputs verbatim.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_3",
            "content": "We push the state-of-the-art for few-shot style transfer with a new method modeling the stylistic difference between paraphrases. When compared to prior work, our model achieves 2-3x better performance in formality transfer and code-mixing addition across seven languages. Moreover, our method is better at controlling the style transfer magnitude using an input scalar knob. We report promising qualitative results for several attribute transfer tasks (sentiment transfer, simplification, gender neutralization, text anonymization) all without retraining the model. Finally, we find model evaluation to be difficult due to the lack of datasets and metrics for many languages. To facilitate future research we crowdsource formality annotations for 4000 sentence pairs in four Indic languages, and use this data to design our automatic evaluations. 1",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_4",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "111-ARR_v2_5",
            "content": "Style transfer is a natural language generation task in which input sentences need to be re-written into a target style, while preserving semantics. It has many applications such as writing assistance (Heidorn, 2000), controlling generation for attributes 1 Please visit the project page for the paper resources: https://martiansideofthemoon.github.io/ 2022/03/03/acl22.html.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_6",
            "content": "*Work done during a Google Research India internship.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_7",
            "content": "Style Vector Extractor -Target (Formal)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_8",
            "content": "It is certainly amongst my favorites.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_9",
            "content": "Source (Informal)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_10",
            "content": "Style Vector Extractor \u0905\u092a\u0928\u0940 \u0935\u093e\u0932\u0940 \u091c\u0949\u092c \u092e \u0941 \u091d \u0947 \u092e\u0924 \u092c\u0924\u093e\u0913.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_11",
            "content": "(don't tell me about your job)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_12",
            "content": "transfer amount \ud835\udf06 \u0906\u092a\u0915\u0940 2 \u0928\u092f \u0941 \u0924 3 \u0915 \u0947 \u092c\u093e\u0930 \u0947 \u092e \u0947\u0902 \u092e \u0941 \u091d \u0947 \u0928\u093e \u092c\u0924\u093e\u090f\u0902 \u0964 4",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_13",
            "content": "\u0905\u092a\u0928\u0940 \u0935\u093e\u0932\u0940 \u0928\u094c\u0915\u0930\u0940 1 \u092e \u0941 \u091d \u0947 \u092e\u0924 \u092c\u0924\u093e\u0913\u0964 \ud835\udf06 = 0.5 \ud835\udf06 = 1.5 honorifics, 2,4 Sanskrit 3 / Persian 1 words for \"job\" in formal Hindi",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_14",
            "content": "Figure 1: An illustration of our few-shot style transfer system during inference. Our model extracts style vectors from exemplar English sentences as input (in this case formal/informal sentences) and uses their vector difference to guide style transfer in other languages (Hindi). \u03bb is used to control the magnitude of transfer: in this example our model produces more high Sanskrit words & honorifics (more formal) with higher \u03bb.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_15",
            "content": "like simplicity, formality or persuasion (Xu et al., 2015;Smith et al., 2020;Niu and Carpuat, 2020), data augmentation (Xie et al., 2020;Lee et al., 2021), and author obfuscation (Shetty et al., 2018).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_16",
            "content": "Most prior work either assumes access to supervised data with parallel sentences between the two styles (Jhamtani et al., 2017), or access to a large corpus of unpaired sentences with style labels (Prabhumoye et al., 2018;Subramanian et al., 2019). Models built are style-specific and cannot generalize to new styles during inference, which is needed for applications like real-time adaptation to a user's style in a dialog or writing application. Moreover, access to a large unpaired corpus with style labels is a strong assumption. Most standard \"unpaired\" style transfer datasets have been carefully curated (Shen et al., 2017) or were originally parallel (Xu et al., 2012;Rao and Tetreault, 2018). This is especially relevant in settings outside En-glish, where NLP tools and labelled datasets are largely underdeveloped (Joshi et al., 2020). In this work, we take the first steps studying style transfer in seven languages 2 with nearly 1.5 billion speakers in total. Since no training data exists for these languages, we analyzed the current state-of-the-art in few-shot multilingual style transfer, the Universal Rewriter (UR) from Garcia et al. (2021). Unfortunately, we find it often copies the inputs verbatim (Section 3.1), without changing their style.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_17",
            "content": "We propose a simple inference-time trick of style-controlled translation through English, which improves the UR output diversity (Section 4.1). To further boost performance we propose DIFFUR, 3 a novel algorithm using the recent finding that paraphrasing leads to stylistic changes (Krishna et al., 2020). DIFFUR extracts edit vectors from paraphrase pairs, which are used to condition and train the model (Figure 2). On formality transfer and code-mixing addition, our best performing DIF-FUR variant significantly outperforms UR across all languages (by 2-3x) using automatic & human evaluation. Besides better rewriting, our system is better able to control the style transfer magnitude (Figure 1). A scalar knob (\u03bb) can be adjusted to make the output text reflect the target style (provided by exemplars) more or less. We also observe promising qualitative results in several attribute transfer directions (Section 6.2) including sentiment transfer, simplification, gender neutralization and text anonymization, all without retraining the model and using just 3-10 examples at inference.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_18",
            "content": "Finally, we found it hard to precisely evaluate models due to the lack of evaluation datasets and style classifiers (often used as metrics) for many languages. To facilitate further research in Indic formality transfer, we crowdsource formality annotations for 4000 sentence pairs in four Indic languages (Section 5.1), and use this dataset to design the automatic evaluation suite (Section 5). In summary, our contributions provide an end-toend recipe for developing and evaluating style transfer models and evaluation in a low-resource setting.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_19",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "111-ARR_v2_20",
            "content": "Few-shot methods are a recent development in English style transfer, with prior work using variational autoencoders (Xu et al., 2020), or prompting large pretrained language models at inference (Reif 2 Indic (hi,bn,kn,gu,te), Spanish, Swahili. 3 \"Difference Universal Rewriter\", pronounced as differ. et al., 2021). Most related is the state-of-the-art TextSETTR model from Riley et al. (2021), who use a neural style encoder to map exemplar sentences to a vector used to guide generation. To train this encoder, they use the idea that adjacent sentences in a document have a similar style. Recently, the Universal Rewriter (Garcia et al., 2021) extended TextSETTR to 101 languages, developing a joint model for translation, few-shot style transfer and stylized translation. This model is the only prior few-shot system we found outside English, and our main baseline. We discuss its shortcomings in Section 3.1, and propose fixes in Section 4. Multilingual style transfer is mostly unexplored in prior work: a 35 paper survey by Briakou et al. (2021b) found only one work in Chinese, Russian, Latvian, Estonian, French. They further introduced XFORMAL, the first formality transfer evaluation dataset in French, Brazilian Portugese and Italian. 4 To the best of our knowledge, we are the first to study style transfer for the languages we consider. More related work from Hindi linguistics and on style transfer control is provided in Appendix B.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_21",
            "content": "The Universal Rewriter (UR) model",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "111-ARR_v2_22",
            "content": "We will start by discussing the Universal Rewriter (UR) model from Garcia et al. (2021), upon which our proposed DIFFUR model is built. At a high level, the UR model extracts a style vector s from an exemplar sentence e, which reflects the desired target style. This style vector is used to style transfer an input sentence x. Concretely, consider f enc , f dec to be encoder & decoder Transformers initialized with mT5 (Xue et al., 2021b), which are composed to form the model f ur . The UR model extracts the style vector using the encoder representation of a special [CLS] token prepended to e, and adds it to the input x representations for style transfer,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_23",
            "content": "f style (e) = s = f enc ([CLS] \u2295 e)[0] f ur (x, s) = f dec (f enc (x) + s)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_24",
            "content": "where \u2295 is string concatenation, + vector addition. f ur is trained using the following objectives, Learning Style Transfer by Exemplar-driven Denoising: To learn a style extractor, the Universal Rewriter uses the idea that two non-overlapping spans of text in the same document are likely to have the same style. Concretely, let x 1 and x 2 be two non-overlapping spans. Style extracted from one span (x 1 ) is used to denoise the other (x 2 ), x2 = f ur (noise(x 2 ), f style (x 1 ))",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_25",
            "content": "L denoise = L CE (x 2 , x 2 )",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_26",
            "content": "where L CE is the standard next-word prediction cross entropy loss function and noise(\u2022) refers to 20-60% random token dropping and token replacement. This objective is used on the mC4 dataset (Xue et al., 2021b) with 101 languages. To build a general-purpose rewriter which can do translation as well as style transfer, the model is additionally trained on two objectives: (1) supervised machine translation using the OPUS-100 parallel dataset (Zhang et al., 2020), and (2) a self-supervised objective to learn effective stylecontrolled translation; more details in Appendix C.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_27",
            "content": "During inference (Figure 1), consider an input sentence x and a transformation from style A to B (say informal to formal). Let S A , S B to be exemplar sentences in each of the styles (typically 3-10 sentences). The output y is computed as,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_28",
            "content": "s A = 1 |S A | y\u2208S A f style (y) s B = 1 |S B | y\u2208S B f style (y) y = f ur (x, \u03bb(s B \u2212 s A ))",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_29",
            "content": "where \u03bb acts as a control knob to determine the magnitude of style transfer, and the vector subtraction helps remove confounding style information. 5",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_30",
            "content": "Shortcomings of the Universal Rewriter",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "111-ARR_v2_31",
            "content": "We experimented with the UR model on Hindi formality transfer, and noticed poor performance. We noticed that UR has a strong tendency to copy sentences verbatim -45.5% outputs were copied exactly from the input (and hence not style transferred) for the best performing value of \u03bb. The copying increase for smaller \u03bb, making magnitude control harder. We identify the following issues: 1. Random token noise leads to unnatural inputs & transformations: The Universal Rewriter uses 20-60% uniformly random token dropping or replacement to noise inputs, which leads to ungrammatical inputs during training. We hypothesize models tend to learn grammatical error correction, which encourages verbatim copying during inference where fluent inputs are used and no error correction is needed. Moreover, token-level noise does not differentiate between content or function words, and cannot do syntactic changes like content reordering (Goyal and Durrett, 2020). Too much noise could distort semantics and encourage hallucination, whereas too little will encourage copying. 2. Style vectors may not capture the precise style transformation: The Universal Rewriter extracts the style vector from a single sentence during training, which is a mismatch from the inference where a difference between vectors is taken. Without taking vector differences at inference, we observe semantic preservation and overall performance of the UR model is much lower. 6 3. mC4 is noisy: On reading training data samples, we noticed noisy samples with severe language identification errors in the Hindi subset of mC4. This has also been observed recently in Kreutzer et al. (2022), who audit 100 sentences in each language, and report 50% sentences in Marathi and 20% sentences in Hindi have the wrong language. 4. No translation data for several languages: We notice worse performance for languages which did not get parallel translation data (for the translation objective in Section 3). In Table 1 we see UR gets a score 7 of 30.4 for Hindi and Bengali, languages for which it got translation data. However, the scores are lower for Kannada, Telugu & Gujarati (25.5,22.8,23.7), for which no translation data was used. We hypothesize translation data encourages learning language-agnostic semantic representations needed for translation from the given language, which in-turn improves style transfer.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_32",
            "content": "Our Models",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "111-ARR_v2_33",
            "content": "Style-Controlled Backtranslation (+ BT)",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "111-ARR_v2_34",
            "content": "While the Universal Rewriter model has a strong tendency to exactly copy input sentences while rewriting sentences in the same language (Section 3.1), we found it is an effective style-controlled translation system. This motivates a simple inference-time trick to improve model outputs and reduce copying -translate sentences to English (en) in a style-agnostic manner with a zero style The DIFFUR approach (Section 4.2), with fixes to the shortcomings of the Universal Rewriter approach (Section 3.1) shown. Sentences are noised using paraphrasing, the style vector difference between the paraphrase & original sentence (\"edit vector\") is used to control denoising. See Figure 1 for the inference-time process.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_35",
            "content": "vector 0, and translate back into the source language (lx) with stylistic control.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_36",
            "content": "x en = f ur (en \u2295 x, 0)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_37",
            "content": "x = f ur (lx \u2295 x en , \u03bb(s B \u2212 s A ))",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_38",
            "content": "where x is the input sentence, s A , s B are the styles vectors we want to transfer between, en, lx are language codes prepended to indicate the output language (Appendix C). Prior work has shown that backtranslation is effective for paraphrasing (Wieting and Gimpel, 2018;Iyyer et al., 2018) and style transfer (Prabhumoye et al., 2018).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_39",
            "content": "Using Paraphrase Vector Differences for",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "111-ARR_v2_40",
            "content": "Style Transfer (DIFFUR)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_41",
            "content": "While style-controlled backtranslation is an effective strategy, it needs two translation steps. This is 2x slower than UR, and semantic errors increase with successive translations. To learn effective style transfer systems needing only a single generation step we develop DIFFUR, a new few-shot style transfer training objective (overview in Figure 2). DIFFUR tackles the issues discussed in Section 3.1 using paraphrases and style vector differences.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_42",
            "content": "Paraphrases as a \"noise\" function: Instead of using random token-level noise (Issue #1 in Section 3.1), we paraphrase sentences to \"noise\" them during training. Paraphrasing modifies the lexical & syntactic properties of sentences, while preserving fluency and input semantics. Prior work (Krishna et al., 2020) has shown that paraphrasing leads to stylistic changes, and denoising can be considered a style re-insertion process.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_43",
            "content": "To create paraphrases, we backtranslate sentences from the UR model 8 with no style control (zero vectors used as style vectors). To increase diversity, we use random sampling in both translation steps, pooling generations obtained using temperature values [0.4, 0.6, 0.8, 1.0]. Finally, we discard paraphrase pairs from the training data where the semantic similarity score 9 is outside the range [0.7, 0.98]. This removes backtransation errors (score < 0.7), and exact copies (score > 0.98). In Appendix K we confirm that our backtranslated paraphrases are lexically diverse from the input.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_44",
            "content": "Using style vector differences for control: To fix the training / inference mismatch for style extraction (Issue #2 in Section 3.1), we propose using style vector differences between the output and input as the stylistic control. Concretely, let x be an input sentence and x para its paraphrase.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_45",
            "content": "s diff = f style (x) \u2212 f style (x para ) x = f ur (x para , stop-grad(s diff )) L = L CE (x, x)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_46",
            "content": "where stop-grad(\u2022) stops gradient flow through s diff , preventing the model from learning to copy x exactly. To ensure f style extracts meaningful style representations, we fine-tune a trained UR model. Vector differences have many advantages, 1. Subtracting style vectors between a sentence and its paraphrase removes confounding features (like semantics) present in the vectors.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_47",
            "content": "The vector difference focuses on the precise",
            "ntype": "title",
            "meta": {
                "section": "2."
            }
        },
        {
            "ix": "111-ARR_v2_48",
            "content": "transformation that is needed to reconstruct the input from its paraphrase.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_49",
            "content": "3. The length of s diff acts as a proxy for the amount of style transfer, which is controlled using \u03bb during inference (Section 3).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_50",
            "content": "DIFFUR is related to neural editor models (Guu et al., 2018;He et al., 2020), where language models are decomposed into a probabilistic space of edit vectors over prototype sentences. We justify the DIFFUR design with ablations in Appendix G.1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_51",
            "content": "Indic Models (UR-INDIC, DIFFUR-INDIC)",
            "ntype": "title",
            "meta": {
                "section": "4.3"
            }
        },
        {
            "ix": "111-ARR_v2_52",
            "content": "To address the issue of no translation data (Issue #4 in Section 3.1), we train Indic variants of our models. We replace the OPUS translation data used for training the Universal Rewriter (Section 3) with Samanantar (Ramesh et al., 2021), which is the largest publicly available parallel translation corpus for 11 Indic languages. We call these variants UR-INDIC and DIFFUR-INDIC. This process significantly up-samples the parallel data seen between English / Indic languages, and gives us better performance (Table 1) and lower copy rates, especially for languages with no OPUS translation data.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_53",
            "content": "Multitask Learning (DIFFUR-MLT)",
            "ntype": "title",
            "meta": {
                "section": "4.4"
            }
        },
        {
            "ix": "111-ARR_v2_54",
            "content": "One issue with our DIFFUR-INDIC setup is usage of a stop-grad(\u2022) to avoid verbatim copying from the input. This prevents gradient flow into the style extractor f style , and as we see in Appendix H, a degradation of the style vector space. To prevent this we simply multi-task between the exemplardriven denoising UR objective (Section 3) and the DIFFUR objective. We initialize the model with the UR-INDIC checkpoint, and fine-tune it on these two losses together, giving each loss equal weight.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_55",
            "content": "Evaluation",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "111-ARR_v2_56",
            "content": "Automatic evaluation of style transfer is challenging (Pang, 2019;Mir et al., 2019;Tikhonov et al., 2019), and the lack of resources (such as evaluation datasets, style classifiers) make evaluation trickier for Indic languages. To tackle this issue, we first collect a small dataset of formality and semantic similarity annotations in four Indic languages (Section 5.1). We use this dataset to guide the design of an evaluation suite (Section 5.2-5.6).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_57",
            "content": "Since automatic metrics in generation are imperfect (Celikyilmaz et al., 2020), we complement our results with human evaluation (Section 5.7).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_58",
            "content": "Indic Formality Transfer Dataset",
            "ntype": "title",
            "meta": {
                "section": "5.1"
            }
        },
        {
            "ix": "111-ARR_v2_59",
            "content": "Since no public datasets exist for formality transfer in Indic languages, it is hard to measure the extent to which automatic metrics (such as style classifiers) are effective. To tackle this issue, we build a dataset of 1000 sentence pairs in each of four Indic languages (Hindi, Bengali, Kannada, Telugu) with formality and semantic similarity annotations. We first style transfer held-out Samanantar sentences using our UR-INDIC + BT model (Section 4.1, 4.3) to create sentence pairs with different formality. We then asked three crowdworkers to 1) label the more formal sentence in each pair; 2) rate semantic similarity on a 3-point scale.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_60",
            "content": "Our crowdsourcing is conducted on Task Mate, 10 where we hired native speakers from India with at least a high school education and 90% approval rating on the platform. To ensure crowdworkers understood \"formality\", we provided instructions following advice from professional Indian linguists, and asked two qualification questions in their native language. More details (agreement, compensation, instructions) are provided in Appendix E.4.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_61",
            "content": "Transfer Accuracy (r-ACC, a-ACC)",
            "ntype": "title",
            "meta": {
                "section": "5.2"
            }
        },
        {
            "ix": "111-ARR_v2_62",
            "content": "Our first metric checks whether the output sentence reflects the target style. This is measured by an external classifier's predictions on system outputs. We use two variants of transfer accuracy: (1) Relative Accuracy (r-ACC): does the target style classifier score the output sentence higher than the input sentence? (2) Absolute Accuracy (a-ACC): does the classifier score the output higher than 0.5? Building multilingual classifiers: Unfortunately, no large style classification datasets exist for most languages, preventing us from building classifiers from scratch. We resort to zero-shot cross lingual transfer techniques (Conneau and Lample, 2019), where large multilingual pretrained models are first fine-tuned on English classification data, and then applied to other languages at inference. We experiment with three such techniques, and find MAD-X classifiers with language adapters (Pfeiffer et al., 2020b) have the highest accuracy of 81% on our Hindi data from Section 5.1. However, MAD-X classifiers were only available for Hindi, so we use the next best XLM RoBERTa-base (Conneau et al., 2020) for other languages, which has 75%-82% accuracy on annotated data; details in Appendix E.1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_63",
            "content": "Semantic Similarity (SIM)",
            "ntype": "title",
            "meta": {
                "section": "5.3"
            }
        },
        {
            "ix": "111-ARR_v2_64",
            "content": "Our second evaluation criteria is semantic similarity between the input and output. Following recent recommendations (Marie et al., 2021;Krishna et al., 2020), we avoid n-gram overlap metrics like BLEU (Papineni et al., 2002). Instead, we use LaBSE (Feng et al., 2020), a language-agnostic semantic similarity model based on multilingual BERT (Devlin et al., 2019). LaBSE supports 109 languages, and is the only similarity model we found supporting all the Indic languages in this work. We also observed LaBSE had greater correlation with our annotated data (Section 5.1) compared to alternatives; details in Appendix E.2.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_65",
            "content": "Qualitatively, we found that sentence pairs with LaBSE scores lower than 0.6 were almost never paraphrases. To avoid rewarding partial credit for low LaBSE scores, we use a hard threshold 11 (L = 0.75) to determine whether pairs are paraphrases, SIM(x, y ) = 1 if LaBSE(x, y ) > L else 0 5.4 Other Metrics (LANG, COPY, 1-g) Additionally, we measure whether the input and output sentences are in the same language (LANG), the fraction of outputs copied verbatim from the input (COPY), and the 1-gram overlap between input / output (1-g). High LANG and low COPY / 1-g (more diversity) is better; details in Appendix E.6.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_66",
            "content": "Aggregated Score (r-AGG, a-AGG)",
            "ntype": "title",
            "meta": {
                "section": "5.5"
            }
        },
        {
            "ix": "111-ARR_v2_67",
            "content": "To get a sense of overall system performance, we combine individual metrics into one score. Similar to Krishna et al. (2020) we aggregate metrics as,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_68",
            "content": "AGG(x, y ) = ACC(x, y ) \u2022 SIM(x, y ) \u2022 LANG(y ) AGG(D) = 1 |D| x,y \u2208D AGG(x, y )",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_69",
            "content": "Where (x, y ) are input-output pairs, and D is the test corpus. Since each of our individual metrics can only take values 0 or 1 at an instance level, our aggregation acts like a Boolean AND operation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_70",
            "content": "In other words, we are measuring the fraction of outputs which simultaneously transfer style, have a semantic similarity of at least L (our threshold in Section 5.3), and have the same language as the input. Depending on the variant of ACC (relative / absolute), we can derive r-AGG / a-AGG.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_71",
            "content": "Evaluating Control (CALIB)",
            "ntype": "title",
            "meta": {
                "section": "5.6"
            }
        },
        {
            "ix": "111-ARR_v2_72",
            "content": "An ideal system should not only be able to style transfer sentences, but also control the magnitude of style transfer using the scalar input \u03bb. To evaluate this, for every system we first determine a \u03bb max value and let [0, \u03bb max ] be the range of control values. While in our setup \u03bb is an unbounded scalar, we noticed high values of \u03bb significantly perturb semantics (also noted in Garcia et al., 2021), with systems outputting style-specific n-grams unfaithful to the output. We choose \u03bb max to be the largest \u03bb from the list [0.5, 1.0, 1.5, 2.0, 2.5, 3.0] whose outputs have an average semantic similarity score (SIM, Section 5.3) of at least 0.75 12 with the validation set inputs. For each system we take three evenly spaced \u03bb values in its control range, denoted as \u039b = [ 1 3 \u03bb max , 2 3 \u03bb max , \u03bb max ]. We then compute the style calibration to \u03bb (CALIB), or how often does increasing \u03bb lead to a style score increase? We measure this with a statistic similar to Kendall's \u03c4 (Kendall, 1938), counting concordant pairs in \u039b,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_73",
            "content": "CALIB(x) = 1 n \u03bb b >\u03bba {style(y \u03bb b ) > style(y \u03bba )}",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_74",
            "content": "where x is input, CALIB(x) is the average over all possible n (= 3) pairs of \u03bb values (\u03bb a , \u03bb b ) in \u039b.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_75",
            "content": "Human Evaluation",
            "ntype": "title",
            "meta": {
                "section": "5.7"
            }
        },
        {
            "ix": "111-ARR_v2_76",
            "content": "Automatic metrics are usually insufficient for style transfer evaluation -according to Briakou et al. (2021a), 69 / 97 surveyed style transfer papers used human evaluation. We adopt the crowd-sourcing setup from Section 5.1, which was used to build our formality evaluation datasets. We presented 200 generations from each model and the corresponding inputs in a random order, and asked three crowdworkers two questions about each pair of sentences: (1) which sentence is more formal/codemixed? (2) how similar are the two sentences in meaning? This lets us evaluate r-ACC, SIM, r-AGG, CALIB with respect to human annotations instead of classifier predictions. More experiment details (inter-annotator agreement, compensation, instructions) are provided in Appendix E.4.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_77",
            "content": "Bengali Kannada Telugu Gujarati r-AGG a-AGG r-AGG a-AGG r-AGG a-AGG r-AGG a-AGG r-AGG a-AGG UR ( 2021 Table 2: Performance by individual metrics for Hindi formality transfer. DIFFUR-MLT gives best overall performance (r-AGG / a-AGG), with a good trade-off between style accuracy (ACC), semantic similarity (SIM), langID score (LANG), and low input copy rates (COPY); metrics defined in Section 5, other language results in Appendix I.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_78",
            "content": "6 Main Experiments",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_79",
            "content": "Experimental Setup",
            "ntype": "title",
            "meta": {
                "section": "6.1"
            }
        },
        {
            "ix": "111-ARR_v2_80",
            "content": "In our experiments, we compare the following models (training details are provided Appendix A):",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_81",
            "content": "\u2022 UR: the Universal Rewriter (Garcia et al., 2021), which is our main baseline (Section 3); \u2022 DIFFUR: our model with paraphrase vector differences (Section 4.2); Our models are evaluated on (1) formality transfer (Rao and Tetreault, 2018); (2) code-mixing addition, a task where systems attempt to use English words in non-English sentences, while preserving the original script. 13 Since we do not have access to any formality evaluation dataset, 14 we hold out 22K sentences from Samanantar in each Indic language for validation / testing. For Swahili / Spanish, we use mC4 / WMT2018 sentences. These sets have similar number of formal / informal sentences, as marked by our formality classifiers (Section 5.2), and are transferred to the opposite formality. We re-use the hi/bn formality transfer splits for codemixing addition, evaluating unidirectional transfer.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_82",
            "content": "\u2022 UR-INDIC,",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_83",
            "content": "Seven languages with varying scripts and morphological richness are used for evaluation (hi,es,sw,bn,kn,te,gu). The UR model only saw translation data for hi,es,bn, whereas UR-INDIC sees translation data for all Indic languages (Section 4.3). To test the generalization capability of the DIFFUR, no Gujarati paraphrase training data for is used. Note that no paired/unpaired data with style labels is used during training: models determine the target style at inference using 3-10 exemplars sentences. For few-shot formality transfer, we use the English exemplars from Garcia et al. ( 2021). We follow their setup and use English exemplars to guide non-English transfer zero-shot. For code-mixing addition, we use Hindi/English code-mixed exemplars in Devanagari (shown in Appendix D).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_84",
            "content": "Main Results",
            "ntype": "title",
            "meta": {
                "section": "6.2"
            }
        },
        {
            "ix": "111-ARR_v2_85",
            "content": "Each proposed method improves over prior work, DIFFUR-MLT works best. We present our On Gujarati, the DIFFUR-INDIC fails to get good performance (36.0 r-AGG) since it did not see Gujarati paraphrase data, but this performance is recovered using DIFFUR-MLT (75.0). In Table 4 we see human evaluations support our automatic evaluation for formality transfer. In Figure 4: Outputs and qualitative analysis of our best performing model for several attribute transfer tasks (\u03bb is transfer magnitude). We notice lower quality qualitatively for ** marked styles; see Appendix J for more outputs.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_86",
            "content": "ACC scores. COPY reduces in our proposed models (4.4% for DIFFUR-MLT), which boosts overall performance. We find the lowest COPY (and lowest 1-g) for models with +BT (1%), which is due to two translation steps. However, this lowers semantic similarity (also seen in Table 4) lowering the overall score (60.0 vs 78.1) compared to DIFFUR-MLT.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_87",
            "content": "In Appendix G we show ablations studies justifying the DIFFUR design, decoding scheme, etc. In Appendix I we show a breakdown by individual metrics for other languages and plot variations with \u03bb. We also analyze the style encoder f style in Appendix H, finding it is an effective style classifier.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_88",
            "content": "We analyze several qualitative outputs from DIFFUR-MLT in Figure 4. Besides formality transfer and code-mixing addition, we transfer several other attributes: sentiment (Li et al., 2018), simplicity (Xu et al., 2015), anonymity (Anandan et al., 2012) and gender neutrality (Reddy and Knight, 2016). More outputs are provided in Appendix J.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_89",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "7"
            }
        },
        {
            "ix": "111-ARR_v2_90",
            "content": "We present a recipe for building & evaluating controllable few-shot style transfer systems needing only 3-10 style examples at inference, useful in low-resource settings. Our methods outperform prior work in formality transfer & code-mixing for 7 languages, with promising qualitative results for several other attribute transfer tasks. Future work includes further improving systems for some attributes, and studying style transfer for languages where little / no translation data is available.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_91",
            "content": "Recent work has highlighted issues of stylistic bias in text generation systems, specifically machine translation systems (Hovy et al., 2020). We acknowledge these issues, and consider style transfer and style-controlled generation technology as an opportunity to work towards fixing them (for instance, gender neutralization as presented in Section 6.2). Note that it is important to tread down this path carefully -In Chapter 9, Blodgett (2021) argue that style is inseparable from social meaning (as originally noted by Eckert, 2008), and humans may perceive automatically generated text very differently compared to automatic style classifiers.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_92",
            "content": "Our models were trained on 32 Google Cloud TPUs. As discussed in Appendix A, the UR & UR-INDIC model take roughly 18 hours to train. The DIFFUR-* and DIFFUR-MLT models are much cheaper to train (2 hours) since we finetune the pretrained UR-* models. The Google 2020 environment report mentions, 15 \"TPUs are highly efficient chips which have been specifically designed for machine learning applications\". These accelerators run on Google Cloud, which is carbon neutral today, and is aiming to \"run on carbon-free energy, 24/7, at all of Google's data centers by 2030\" (https://cloud.google. com/sustainability). A few prior works build models which can control the degree of style transfer using a scalar input (Wang et al., 2019;Samanta et al., 2021).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_93",
            "content": "However, these models are style-specific and require large unpaired style corpora during training. We adopt the inference-time control method used by Garcia et al. ( 2021) and notice much better controllability after our proposed fixes in Section 4.2.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_94",
            "content": "In this section we describe the details of the supervised translation objective and the style-controlled translation objective used in the Universal Rewriter model. See Section 3 for details on the exemplarbased denoising objective.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_95",
            "content": "This objective is the standard supervised translation setup, using zero vectors for style. The output language code is prepended to the input. Consider a pair of parallel sentences (x, y) in languages with codes lx, ly (prepended to the input string), \u0233 = f ur (ly \u2295 x, 0)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_96",
            "content": "L translate = L CE (\u0233, y)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_97",
            "content": "The Universal Rewriter is trained on Englishcentric translation data from the high-resource languages in OPUS-100 (Zhang et al., 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_98",
            "content": "Learning style-controlled translation: This objective emulates \"style-controlled translation\" in a self-supervised manner, via backtranslation through English. Consider x 1 and x 2 to be two non-overlapping spans in mC4 in language lx, protective buildings and military buildings.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_99",
            "content": "x en 2 = f ur (en \u2295 x 2 , \u2212f style (x 1 )) x2 = f ur (lx \u2295 x en 2 , f style (x 1 )) L BT = L CE (x 2 , x 2 )",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_100",
            "content": "Positive sentiment exemplars 1. The most comfortable bed I've ever slept on, I highly recommend it. 2. I loved it. 3. The movie was fantastic. Negative sentiment exemplars 1. The most uncomfortable bed I've ever slept on, I would never recommend it. 2. I hated it. 3. The movie was awful.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_101",
            "content": "Due to the absence of a style classification dataset in Indic languages, we built our multilingual classifier drawing inspiration from recent research in zero-shot cross-lingual transfer (Conneau et al., 2018;Conneau and Lample, 2019;Pfeiffer et al., 2020b). We experimented with three zero-shot transfer techniques while selecting our classifiers for evaluating multilingual style transfer.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_102",
            "content": "TRANSLATE TRAIN: The first technique uses the hypothesis that style is preserved across translation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_103",
            "content": "We classify the style of English sentences in the Samanantar translation dataset (Ramesh et al., 2021) using a style classifier trained on English formality data from Krishna et al. (2020). We use the human translated Indic languages sentences as training data. This training data is used to fine-tune a large-scale multilingual language model. ZERO-SHOT: The second technique fine-tunes large-scale multilingual language models on a English style transfer dataset, and applies it zero-shot on multilingual data during inference.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_104",
            "content": "MAD-X: Introduced by Pfeiffer et al. (2020b), this technique is similar to ZERO-SHOT but additionally uses language-specific parameters (\"adapters\") during inference. These language-specific adapters have been originally trained using masked language modeling on the desired language data. Dataset for evaluating classifiers: We conduct our experiments on Hindi formality classification, leveraging our evaluation datasets from Section 5.1. We removed pairs which did not have full agreement across the three annotators and those pairs which had the consensus rating of \"Equal\" formality. This filtering process leaves us with 316 pairs in Hindi (out of 1000). In our experiments, we check whether the classifiers give a higher score to the more formal sentence in the pair.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_105",
            "content": "We leverage the multilingual classifiers open-sourced 18 by Krishna et al. (2020). These models have been trained on the English GYAFC formality classification dataset (Rao and Tetreault, 2018), and have been shown to be effective on the XFORMAL dataset (Briakou et al., 2021b) for formality classification in Italian, French and Brazilian Portuguese. 13 These classifiers were trained on preprocessed data which had trailing punctuation stripped and English sentences lower-cased, encouraging the models to focus on lexical and syntactic choices. As base multilingual language models, we use (1) mBERT-base from Devlin et al. ( 2019 2020b), we find MAD-X to be a superior zero-shot cross lingual transfer method compared to baselines. We also find XLM-R has better multilingual representations than mBERT. Unfortunately, AdapterHub (Pfeiffer et al., 2020a) has XLM-R language adapters available only for Hindi & Tamil (among Indic languages). For other languages we use the ZERO-SHOT technique on XLM-R, consistent with the recommendations 13 provided by Krishna et al. (2020) based on their experiments on XFORMAL (Briakou et al., 2021b).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_106",
            "content": "Model Accuracy (\u2191)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_107",
            "content": "TRANSLATE TRAIN mBERT 66% ZERO-SHOT mBERT 72% XLM-R 76% MAD-X",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_108",
            "content": "XLM-R 81%",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_109",
            "content": "We considered three models for evaluating semantic similarity between the input and output:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_110",
            "content": "(1) LaBSE (Feng et al., 2020);",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_111",
            "content": "(2) m-USE (Yang et al., 2020);",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_112",
            "content": "(3) multilingual Sentence-BERT (Reimers and Gurevych, 2020), the knowledge-distilled variant paraphrase-xlm-r-multilingual-v1",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_113",
            "content": "Among these models, only LaBSE has support for all the Indic languages we were interested in.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_114",
            "content": "No Indic language is supported by m-USE, and multilingual Sentence-BERT has been trained on parallel data only for Hindi, Gujarati and Marathi among our Indic languages. However, in terms of Semantic Textual Similarity (STS) benchmarks (Cer et al., 2017) for English, Arabic & Spanish, m-USE and Sentence-BERT outperform LaBSE (Table 1 in Reimers and Gurevych, 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_115",
            "content": "LaBSE correlates better than Sentence-BERT with our human-annotated formality dataset:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_116",
            "content": "We measured the Spearman's rank correlation between the semantic similarity annotations on our human-annotated formality datasets (Section 5.1). We discarded 10% sentence pairs which had no agreement among three annotators and took the majority vote for the other sentence pairs. We assigned \"Different Meaning\" a score of 0, \"Slight Difference in Meaning\" a score of 1 and \"Approximately Same Meaning\" a score of 2 before measuring Spearman's rank correlation. In Table 9 we see a stronger correlation of human annotations with LaBSE compared to Sentence-BERT, especially for languages like Bengali, Kannada for which Sentence-BERT did not see parallel data.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_117",
            "content": "Model hi bn kn te LaBSE 0.34 0.49 0.39 0.25 Sentence-BERT 0.33 0.36 0.29 0.18 Table 9: Spearman's rank correlation between different semantic similarity models and our semantic similarity human annotations collected along with formality labels. Overall, LaBSE correlates more strongly than Sentence-BERT with our annotated data.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_118",
            "content": "In Section 6, we set our LaBSE threshold L to 0.75.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_119",
            "content": "In this section, we present our evaluations with a more and less conservative value of L.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_120",
            "content": "In Table 18, we present results with L = 0.65, and in Table 19 we set L = 0.85. Compared to Table 1, trends are mostly similar, with DIFFUR models and INDIC variants outperforming counterparts. Note that the absolute values of SIM and AGG metrics differ, with absolute values going down with the stricter threshold of L = 0.85, and up with the relaxed threshold of L = 0.65.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_121",
            "content": "To verify these three thresholds are reasonable choices, we measure the LaBSE similarity of the sentence pairs annotated by humans, and compare the LaBSE scores to human semantic similarity annotations. We pool the \"Approximately Same Meaning\" and \"Slight Difference in Meaning\" categories as \"same\", and consider only sentence pairs with a majority rating of \"same\". In As we increase the threshold L, we see this percentage substantially reduces, indicating our chosen thresholds are within the range of variation in LaBSE scores for semantically similar sentences.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_122",
            "content": "In Figure 17, we show screenshots of our crowdsourcing interface along with all the instructions shown to crowdworkers. The instructions were written after consulting professional Indian linguists. Each crowdworker was allowed to annotate a maximum of 50 different sentence pairs per language, paying them $0.05 per pair. For formality classification, we showed crowdworkers two sentences and asked them to choose which one is more formal. Crowdworkers were allowed to mark ties using an \"Equal\" option. For semantic similarity annotation, we showed crowdworkers the sentence pair and provided three options -\"approximately same meaning\", \"slight difference in meaning\", \"different meaning\", to emulate a 3-point Likert scale. While performing our human evaluation (Section 5.7), we use a 0.5 SIM score for \"slight difference in meaning\" and a 1.0 SIM score for \"approximately same meaning\" annotations. For every system considered, we analyzed the same set of 200 input sentences for style transfer performance, and 100 of those sentences for evaluating controllability. We removed sentences which were exact copies of the input (after removing trailing punctuation) or were in the wrong language to save annotator time and cost. When outputs were exact copies of the input, we assigned SIM = 100, ACC = 0, AGG = 0.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_123",
            "content": "In Table 11 and Table 12 we show the interannotator agreement statistics. We measure Fleiss Kappa (Fleiss, 1971), Randolph Kappa (Randolph, 2005Warrens, 2010), the fraction of sentence pairs with total agreement between the three annotators and the fraction of sentence pairs with no agreement. 19 In the table we can see all agreement statistics are well away from a uniform random annotation baseline, indicating good agreement.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_124",
            "content": "Unlike some prior works, we avoid evaluation of output fluency due to the following reasons:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_125",
            "content": "(1) lack of fluency evaluation tools for Indic languages; 20 (2) fluency evaluation often discriminates against styles which are out-of-distribution for the fluency classifier, as discussed in Appendix A.8 of Krishna et al. ( 2020); (3) several prior works (Pang, 2019;Mir et al., 2019;Krishna et al., 2020) have recommended against using perplexity of style language models for fluency evaluation since it is unbounded and favours unnatural sentences with common words; (4) large language 19 The \u03ba scores are measured using the library https: //github.com/statsmodels/statsmodels. 20 A potential tool for fluency evaluation in future work is LAMBRE (Pratapa et al., 2021). However, the original paper does not evaluate performance on Indic languages and the grammars for Indic languages would need to collected / built. models are known to produce fluent text as perceived by humans (Ippolito et al., 2020;Akoury et al., 2020), reducing the need for this evaluation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_126",
            "content": "Language Consistency (LANG): Since our semantic similarity metric LaBSE is languageagnostic, it tends to ignore accidental translations, which are common errors in large multilingual transformers (Xue et al., 2021a,b), especially the Universal Rewriter (Section 3.1). Hence, we check whether the output sentence is in the same language as the input, using langdetect. 21 Output Diversity (COPY, 1-g): As discussed in Section 3.1, the Universal Rewriter has a strong tendency to copy the input verbatim. We build two metrics to measure output diversity compared to the input, which have been previously used for extractive question answering evaluation (Rajpurkar et al., 2016). The first metric COPY measures the fraction of outputs which were copied verbatim from the input. This is done after removing trailing punctuation, to penalize models generations which solely modify punctuation. A second metric 1-g measures the unigram overlap F1 score between the input and output. A diverse style transfer system should minimize both COPY and 1-g.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_127",
            "content": "We follow the setup in Section 5.6 to first compute a \u03bb max per system. We then compute the following, 1. Style Transfer Performance (r-AGG): An ideal system should have good overall performance (Section 5.5) across different values in the range \u039b. 2. Average Style Score Increase (INCR): As our control value increases, we want the classifier's target style score (compared to the input) to increase. Additionally, we want the style score increase of \u03bb max to be as high as possible, indicating the system can span the range of classifier scores. 3. Style Calibration to \u03bb (CALIB, C-IN): As defined in Section 5.6. We additionally also measure calibration by including the input sentence x in the CALIB(x) calculation, treating it as the output for \u03bb = 0 (no style transfer). Here, calibration is averaged over a total of n = 6 (\u03bb 1 , \u03bb 2 ) pairs. We call this metric C-IN.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_128",
            "content": "A detailed breakdown of performance by different metrics for every model is shown in Table 15.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_129",
            "content": "This section describes the ablation experiments conducted for the DIFFUR modeling choices in Section 4.2. We ablate a DIFFUR-INDIC model trained on Hindi paraphrase data only, and present results for Hindi formality transfer in Table 16.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_130",
            "content": "no paraphrase: We replaced the paraphrase noise function with the random token dropping / replacing noise used in the denoising objective of UR model (Section 3), and continued to use vector differences. As seen in Table 16, this significantly increases the copy rate, which lowers the style transfer performance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_131",
            "content": "no paraphrase semantic filtering: We keep a setup identical to Section 4.2, but avoid the LaBSE filtering done (discarding pairs having a LaBSE score outside [0.7, 0.98]) to remove noisy paraphrases or exact copies. As seen in Table 16, this decreases the semantic similarity score of the generations, lowering the overall performance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_132",
            "content": "no vector differences: Instead of using vector differences for DIFFUR-INDIC, we simply set s diff = f style (x), or the style of the target sentence. In Table 16, we see this significantly decreases SIM scores, and LANG scores for \u03bb = 2.0. We hypothesize that this training encourages the model to rely more heavily on the style vectors, ignoring the paraphrase input. This could happen since the style vectors are solely constructed from the output sentence itself, and semantic information / confounding style is not subtracted out. In other words, the model is behaving more like an autoencoder (through the style vector) instead of a denoising autoencoder with stylistic supervision.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_133",
            "content": "-mC4 instead of Samanantar: Instead of creating pseudo-parallel data with Samanantar, we leverage the mC4 dataset itself which was used to train the UR model. We backtranslate spans of text from the Hindi split of mC4 on-the-fly using the UR translation capabilities, and use it as the \"paraphrase noise function\". To ensure translation performance does not deteriorate during training, 50% minibatches are supervised translation between Hindi and English. In Table 16, we see decent overall performance, but the LANG score is 6% lower than DIFFUR-INDIC. Qualitatively we found that the model often translates a few Hindi words to English while making text informal. Due to sparsity of English tokens, it often escapes penalization from LANG.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_134",
            "content": "-mC4 + exemplar instead of target: This setting is similar to the previous one, but in addition to the mC4 dataset we utilize the vector difference between the style vector of the exemplar span (instead of target span), and the \"paraphrase noised\" input. Results in Table 16 show this method is not effective, and it's important for the vector difference to model the precise transformation needed.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_135",
            "content": "We experiment with five decoding schemes on the Hindi formality validation set -beam search with beam size 1, 4 and top-p sampling (Holtzman et al., 2020) with p = 0.6, 0.75, 0.9.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_136",
            "content": "In Table 17, we present results at a constant style transfer magnitude (\u03bb = 3.0). Consistent with Krishna et al. (2020), we find that top-p decoding usually gets higher style accuracy (r-ACC, a-ACC) and output diversity (1-g, COPY) scores, but lower semantic similarity (SIM) scores. Overall beam search triumphs since the loss in semantic similarity leads to a worse performing model. In Figure 10, we see a consistent trend across different magnitudes of style transfer (\u03bb). In all our main experiments, we use beam search with beam size 4 to obtain our generations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_137",
            "content": "In Figure 11, we present the variation in style transfer performance with number of training steps for our best model, the DIFFUR-MLT model. We find that with more training steps performance generally improves, but improvements saturate after 8k steps. We also see the peak of the graphs (best style transfer performance) shift rightwards, indicating a preference for higher \u03bb values. style classifier? To explore this, we measure the cosine distance between the mean style vector of our informal exemplars, 22 and the style vectors derived by passing human-annotated formal/informal pairs (from our dataset of Section 5.1) through f style . We only consider pairs which had complete agreement among annotators. In Table 13 we see good agreement (68.2%-80.7%) between human annotations and the classifier derived from the metric space of the UR-INDIC model. Agreement is lower (67.0%-74.3%) for the DIFFUR-INDIC model, likely due to the stop gradient used in Section 4.2. With DIFFUR-MLT, agreement jumps back up to 75%-81.7% since gradients flow into the style extractor as well.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_138",
            "content": "In Appendix H.1, we saw that the metric vector space derived from the style encoder f style of various models is an effective style classifier, using the informal exemplar vectors. In Table 14 22 See Appendix D for the exemplar sentences. We found the informal exemplars more effective than formal exemplars for style classification; Appendix H.2 has a comparison.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_139",
            "content": "A full breakdown of results by individual metrics, along with plots showing variation with change in \u03bb, is provided for -Hindi (Table 20, Figure 12), Bengali (Table 21, Figure 13), Kannada (Table 22, Figure 14), Telugu (Table 23, Figure 15), Gujarati (Table 24, Figure 16).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_140",
            "content": "Please refer to Figure 8. In the main body, Figure 4 has a few examples as well with detailed analysis.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_141",
            "content": "In Figure 9 we measure the lexical overlap between paraphrases used in our DIFFUR training strategy for six different languages (Hindi, Bengali, Kannada, Telugu, Swahili and Spanish). The lexical overlap is measured using the unigram F1 score, using the implementation from the SQuAD evaluation script (Rajpurkar et al., 2016). The wide spread of the histogram and sufficient percentage of low overlap pairs confirm the lexical diversity of the paraphrases used. As shown in prior work (Krishna et al., 2020), high lexical diversity of paraphrases is helpful for changing the input style. 20 for a individual metric breakdown of the models at the best performing \u03bb). The plots show overall style transfer performance, using the r-AGG (top-left) and a-AGG (top-right) metrics from Section 5.5. We see the DIFFUR models outperform other systems across the \u03bb range, and get best performance with the DIFFUR-MLT variant. We also see that DIFFUR models, especially with DIFFUR-MLT, lead to better style transfer control (bottom plot, closer to x = 1 is better), giving large style variation with \u03bb without loss in semantics (X-axis). 21 for a individual metric breakdown of the models at the best performing \u03bb). The plots show overall style transfer performance, using the r-AGG (top-left) and a-AGG (top-right) metrics from Section 5.5. We see the DIFFUR models outperform other systems across the \u03bb range, and get best performance with the DIFFUR-MLT variant. We also see that DIFFUR models, especially with DIFFUR-MLT, lead to better style transfer control (bottom plot, closer to x = 1 is better), giving large style variation with \u03bb without loss in semantics (X-axis).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_142",
            "content": "Figure 17: Our crowdsourcing interface on Task Mate, used to build our formality evaluation datasets (Section 5.1) and conduct human evaluations (Section 5.7). The first row shows our landing page and instruction set derived from our conversations with professional linguists. The second row shows our qualification questions for formality classification, and the third row shows templates for the two questions asked to crowdworkers per pair.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v2_143",
            "content": "UNKNOWN, None, 2013, Hindi: An essential grammar, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": null,
                "title": null,
                "pub_date": "2013",
                "pub_title": "Hindi: An essential grammar",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_144",
            "content": "Nader Akoury, Shufan Wang, Josh Whiting, Stephen Hood, Nanyun Peng, Mohit Iyyer, STO-RIUM: A Dataset and Evaluation Platform for Machine-in-the-Loop Story Generation, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Nader Akoury",
                    "Shufan Wang",
                    "Josh Whiting",
                    "Stephen Hood",
                    "Nanyun Peng",
                    "Mohit Iyyer"
                ],
                "title": "STO-RIUM: A Dataset and Evaluation Platform for Machine-in-the-Loop Story Generation",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "111-ARR_v2_145",
            "content": "UNKNOWN, None, 2012, Generalizing words to desensitize text. Transactions on Data Privacy, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": null,
                "title": null,
                "pub_date": "2012",
                "pub_title": "Generalizing words to desensitize text. Transactions on Data Privacy",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_146",
            "content": "Kalika Bali, Jatin Sharma, Monojit Choudhury, Yogarshi Vyas, i am borrowing ya mixing?\" an analysis of english-hindi code mixing in facebook, 2014, Proceedings of the First Workshop on Computational Approaches to Code Switching, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Kalika Bali",
                    "Jatin Sharma",
                    "Monojit Choudhury",
                    "Yogarshi Vyas"
                ],
                "title": "i am borrowing ya mixing?\" an analysis of english-hindi code mixing in facebook",
                "pub_date": "2014",
                "pub_title": "Proceedings of the First Workshop on Computational Approaches to Code Switching",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_147",
            "content": "Su Lin,  Blodgett, Sociolinguistically driven approaches for just natural language processing, 2021, UMass Amherst Doctoral Dissertations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    " Su Lin",
                    " Blodgett"
                ],
                "title": "Sociolinguistically driven approaches for just natural language processing",
                "pub_date": "2021",
                "pub_title": "UMass Amherst Doctoral Dissertations",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_148",
            "content": "UNKNOWN, None, 2018, , .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": null,
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_149",
            "content": "Eleftheria Briakou, Sweta Agrawal, Ke Zhang, Joel Tetreault, and Marine Carpuat. 2021a. A review of human evaluation for style transfer, , Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021), .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "Eleftheria Briakou",
                    "Sweta Agrawal",
                    "Ke Zhang"
                ],
                "title": "Joel Tetreault, and Marine Carpuat. 2021a. A review of human evaluation for style transfer",
                "pub_date": null,
                "pub_title": "Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021)",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_150",
            "content": "Sravana Reddy, Kevin Knight, Obfuscating gender in social media writing, 2016, Proceedings of the First Workshop on NLP and Computational Social Science, .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Sravana Reddy",
                    "Kevin Knight"
                ],
                "title": "Obfuscating gender in social media writing",
                "pub_date": "2016",
                "pub_title": "Proceedings of the First Workshop on NLP and Computational Social Science",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_151",
            "content": "UNKNOWN, None, 2021, A recipe for arbitrary text style transfer with large language models, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "A recipe for arbitrary text style transfer with large language models",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_152",
            "content": "Nils Reimers, Iryna Gurevych, Making monolingual sentence embeddings multilingual using knowledge distillation, 2020, Proceedings of Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Nils Reimers",
                    "Iryna Gurevych"
                ],
                "title": "Making monolingual sentence embeddings multilingual using knowledge distillation",
                "pub_date": "2020",
                "pub_title": "Proceedings of Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_153",
            "content": "Parker Riley, Noah Constant, Mandy Guo, Girish Kumar, David Uthus, Zarana Parekh, TextSETTR: Few-shot text style extraction and tunable targeted restyling, 2021, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Parker Riley",
                    "Noah Constant",
                    "Mandy Guo",
                    "Girish Kumar",
                    "David Uthus",
                    "Zarana Parekh"
                ],
                "title": "TextSETTR: Few-shot text style extraction and tunable targeted restyling",
                "pub_date": "2021",
                "pub_title": "Proceedings of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_154",
            "content": "Bidisha Samanta, Mohit Agrawal, Niloy Ganguly, A hierarchical vae for calibrating attributes while generating text using normalizing flow, 2021, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Bidisha Samanta",
                    "Mohit Agrawal",
                    "Niloy Ganguly"
                ],
                "title": "A hierarchical vae for calibrating attributes while generating text using normalizing flow",
                "pub_date": "2021",
                "pub_title": "Proceedings of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_155",
            "content": "UNKNOWN, None, 2019, A deep generative model for code-switched text, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "A deep generative model for code-switched text",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_156",
            "content": "Mingyue Shang, Piji Li, Zhenxin Fu, Lidong Bing, Dongyan Zhao, Shuming Shi, Rui Yan, Semi-supervised text style transfer: Cross projection in latent space, 2019, Proceedings of Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    "Mingyue Shang",
                    "Piji Li",
                    "Zhenxin Fu",
                    "Lidong Bing",
                    "Dongyan Zhao",
                    "Shuming Shi",
                    "Rui Yan"
                ],
                "title": "Semi-supervised text style transfer: Cross projection in latent space",
                "pub_date": "2019",
                "pub_title": "Proceedings of Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_157",
            "content": "Tianxiao Shen, Tao Lei, Regina Barzilay, Tommi Jaakkola, Style transfer from non-parallel text by cross-alignment, 2017, Advances in neural information processing systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Tianxiao Shen",
                    "Tao Lei",
                    "Regina Barzilay",
                    "Tommi Jaakkola"
                ],
                "title": "Style transfer from non-parallel text by cross-alignment",
                "pub_date": "2017",
                "pub_title": "Advances in neural information processing systems",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_158",
            "content": "Rakshith Shetty, Bernt Schiele, Mario Fritz, A4nt: author attribute anonymity by adversarial training of neural machine translation, 2018, 27th {USENIX} Security Symposium ({USENIX} Security 18), .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Rakshith Shetty",
                    "Bernt Schiele",
                    "Mario Fritz"
                ],
                "title": "A4nt: author attribute anonymity by adversarial training of neural machine translation",
                "pub_date": "2018",
                "pub_title": "27th {USENIX} Security Symposium ({USENIX} Security 18)",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_159",
            "content": "UNKNOWN, None, 2020, Controlling style in generated dialogue, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Controlling style in generated dialogue",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_160",
            "content": "Sandeep Subramanian, Guillaume Lample, Eric Smith, Ludovic Denoyer, Marc'aurelio Ranzato, Y-Lan Boureau, Multiple-attribute text style transfer, 2019, Proceedings of the International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Sandeep Subramanian",
                    "Guillaume Lample",
                    "Eric Smith",
                    "Ludovic Denoyer",
                    "Marc'aurelio Ranzato",
                    "Y-Lan Boureau"
                ],
                "title": "Multiple-attribute text style transfer",
                "pub_date": "2019",
                "pub_title": "Proceedings of the International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_161",
            "content": "Aleksey Tikhonov, P Ivan,  Yamshchikov, Sounds wilde. phonetically extended embeddings for author-stylized poetry generation, 2018, Proceedings of the Fifteenth Workshop on Computational Research in Phonetics, Phonology, and Morphology, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Aleksey Tikhonov",
                    "P Ivan",
                    " Yamshchikov"
                ],
                "title": "Sounds wilde. phonetically extended embeddings for author-stylized poetry generation",
                "pub_date": "2018",
                "pub_title": "Proceedings of the Fifteenth Workshop on Computational Research in Phonetics, Phonology, and Morphology",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_162",
            "content": "Alexey Tikhonov, Viacheslav Shibaev, Aleksander Nagaev, Aigul Nugmanova, Ivan Yamshchikov, Style transfer for texts: Retrain, report errors, compare with rewrites, 2019, Proceedings of Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "Alexey Tikhonov",
                    "Viacheslav Shibaev",
                    "Aleksander Nagaev",
                    "Aigul Nugmanova",
                    "Ivan Yamshchikov"
                ],
                "title": "Style transfer for texts: Retrain, report errors, compare with rewrites",
                "pub_date": "2019",
                "pub_title": "Proceedings of Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_163",
            "content": "Ke Wang, Hang Hua, Xiaojun Wan, Controllable unsupervised text attribute transfer via editing entangled latent representation, 2019, Advances in Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Ke Wang",
                    "Hang Hua",
                    "Xiaojun Wan"
                ],
                "title": "Controllable unsupervised text attribute transfer via editing entangled latent representation",
                "pub_date": "2019",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_164",
            "content": "UNKNOWN, None, 2010, Inequalities between multirater kappas. Advances in data analysis and classification, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": null,
                "title": null,
                "pub_date": "2010",
                "pub_title": "Inequalities between multirater kappas. Advances in data analysis and classification",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_165",
            "content": "John Wieting, Kevin Gimpel, ParaNMT-50M: Pushing the limits of paraphrastic sentence embeddings with millions of machine translations, 2018, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "John Wieting",
                    "Kevin Gimpel"
                ],
                "title": "ParaNMT-50M: Pushing the limits of paraphrastic sentence embeddings with millions of machine translations",
                "pub_date": "2018",
                "pub_title": "Proceedings of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_166",
            "content": "Qizhe Xie, Zihang Dai, Eduard Hovy, Thang Luong, Quoc Le, Unsupervised data augmentation for consistency training, 2020, Advances in Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Qizhe Xie",
                    "Zihang Dai",
                    "Eduard Hovy",
                    "Thang Luong",
                    "Quoc Le"
                ],
                "title": "Unsupervised data augmentation for consistency training",
                "pub_date": "2020",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_167",
            "content": "Peng Xu, Jackie Chi Kit Cheung, Yanshuai Cao, On variational learning of controllable representations for text without supervision, 2020, International Conference on Machine Learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Peng Xu",
                    "Jackie Chi Kit Cheung",
                    "Yanshuai Cao"
                ],
                "title": "On variational learning of controllable representations for text without supervision",
                "pub_date": "2020",
                "pub_title": "International Conference on Machine Learning",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_168",
            "content": "Wei Xu, Chris Callison-Burch, Courtney Napoles, Problems in current text simplification research: New data can help, 2015, Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Wei Xu",
                    "Chris Callison-Burch",
                    "Courtney Napoles"
                ],
                "title": "Problems in current text simplification research: New data can help",
                "pub_date": "2015",
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_169",
            "content": "Wei Xu, Alan Ritter, Bill Dolan, Ralph Grishman, Colin Cherry, Paraphrasing for style, 2012, Proceedings of International Conference on Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": [
                    "Wei Xu",
                    "Alan Ritter",
                    "Bill Dolan",
                    "Ralph Grishman",
                    "Colin Cherry"
                ],
                "title": "Paraphrasing for style",
                "pub_date": "2012",
                "pub_title": "Proceedings of International Conference on Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_170",
            "content": "UNKNOWN, None, , and Colin Raffel. 2021a. Byt5: Towards a tokenfree future with pre-trained byte-to-byte models, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "and Colin Raffel. 2021a. Byt5: Towards a tokenfree future with pre-trained byte-to-byte models",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_171",
            "content": "Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, and Colin Raffel. 2021b. mT5: A massively multilingual pre-trained text-to-text transformer, , Conference of the North American Chapter, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Linting Xue",
                    "Noah Constant",
                    "Adam Roberts",
                    "Mihir Kale",
                    "Rami Al-Rfou",
                    "Aditya Siddhant"
                ],
                "title": "Aditya Barua, and Colin Raffel. 2021b. mT5: A massively multilingual pre-trained text-to-text transformer",
                "pub_date": null,
                "pub_title": "Conference of the North American Chapter",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "111-ARR_v2_172",
            "content": "Yinfei Yang, Daniel Cer, Amin Ahmad, Mandy Guo, Jax Law, Noah Constant, Gustavo Hernandez Abrego, Steve Yuan, Chris Tar, Yun-Hsuan Sung, Brian Strope, Ray Kurzweil, Multilingual universal sentence encoder for semantic retrieval, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "Yinfei Yang",
                    "Daniel Cer",
                    "Amin Ahmad",
                    "Mandy Guo",
                    "Jax Law",
                    "Noah Constant",
                    "Gustavo Hernandez Abrego",
                    "Steve Yuan",
                    "Chris Tar",
                    "Yun-Hsuan Sung",
                    "Brian Strope",
                    "Ray Kurzweil"
                ],
                "title": "Multilingual universal sentence encoder for semantic retrieval",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v2_173",
            "content": "Biao Zhang, Philip Williams, Ivan Titov, Rico Sennrich, Improving massively multilingual neural machine translation and zero-shot translation, 2020, Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": [
                    "Biao Zhang",
                    "Philip Williams",
                    "Ivan Titov",
                    "Rico Sennrich"
                ],
                "title": "Improving massively multilingual neural machine translation and zero-shot translation",
                "pub_date": "2020",
                "pub_title": "Association for Computational Linguistics",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "111-ARR_v2_0@0",
            "content": "Few-shot Controllable Style Transfer for Low-Resource Multilingual Settings",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_0",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_2@0",
            "content": "Style transfer is the task of rewriting a sentence into a target style while approximately preserving content.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_2",
            "start": 0,
            "end": 109,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_2@1",
            "content": "While most prior literature assumes access to a large style-labelled corpus, recent work (Riley et al., 2021) has attempted \"few-shot\" style transfer using just 3-10 sentences at inference for style extraction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_2",
            "start": 111,
            "end": 320,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_2@2",
            "content": "In this work, we study a relevant low-resource setting: style transfer for languages where no style-labelled corpora are available.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_2",
            "start": 322,
            "end": 452,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_2@3",
            "content": "We notice that existing few-shot methods perform this task poorly, often copying inputs verbatim.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_2",
            "start": 454,
            "end": 550,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_3@0",
            "content": "We push the state-of-the-art for few-shot style transfer with a new method modeling the stylistic difference between paraphrases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_3",
            "start": 0,
            "end": 128,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_3@1",
            "content": "When compared to prior work, our model achieves 2-3x better performance in formality transfer and code-mixing addition across seven languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_3",
            "start": 130,
            "end": 271,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_3@2",
            "content": "Moreover, our method is better at controlling the style transfer magnitude using an input scalar knob.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_3",
            "start": 273,
            "end": 374,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_3@3",
            "content": "We report promising qualitative results for several attribute transfer tasks (sentiment transfer, simplification, gender neutralization, text anonymization) all without retraining the model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_3",
            "start": 376,
            "end": 565,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_3@4",
            "content": "Finally, we find model evaluation to be difficult due to the lack of datasets and metrics for many languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_3",
            "start": 567,
            "end": 675,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_3@5",
            "content": "To facilitate future research we crowdsource formality annotations for 4000 sentence pairs in four Indic languages, and use this data to design our automatic evaluations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_3",
            "start": 677,
            "end": 846,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_3@6",
            "content": "1",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_3",
            "start": 848,
            "end": 848,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_4@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_4",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_5@0",
            "content": "Style transfer is a natural language generation task in which input sentences need to be re-written into a target style, while preserving semantics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_5",
            "start": 0,
            "end": 147,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_5@1",
            "content": "It has many applications such as writing assistance (Heidorn, 2000), controlling generation for attributes 1 Please visit the project page for the paper resources: https://martiansideofthemoon.github.io/ 2022/03/03/acl22.html.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_5",
            "start": 149,
            "end": 374,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_6@0",
            "content": "*Work done during a Google Research India internship.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_6",
            "start": 0,
            "end": 52,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_7@0",
            "content": "Style Vector Extractor -Target (Formal)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_7",
            "start": 0,
            "end": 38,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_8@0",
            "content": "It is certainly amongst my favorites.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_8",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_9@0",
            "content": "Source (Informal)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_9",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_10@0",
            "content": "Style Vector Extractor \u0905\u092a\u0928\u0940 \u0935\u093e\u0932\u0940 \u091c\u0949\u092c \u092e \u0941 \u091d \u0947 \u092e\u0924 \u092c\u0924\u093e\u0913.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_10",
            "start": 0,
            "end": 52,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_11@0",
            "content": "(don't tell me about your job)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_11",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_12@0",
            "content": "transfer amount \ud835\udf06 \u0906\u092a\u0915\u0940 2 \u0928\u092f \u0941 \u0924 3 \u0915 \u0947 \u092c\u093e\u0930 \u0947 \u092e \u0947\u0902 \u092e \u0941 \u091d \u0947 \u0928\u093e \u092c\u0924\u093e\u090f\u0902 \u0964 4",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_12",
            "start": 0,
            "end": 68,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_13@0",
            "content": "\u0905\u092a\u0928\u0940 \u0935\u093e\u0932\u0940 \u0928\u094c\u0915\u0930\u0940 1 \u092e \u0941 \u091d \u0947 \u092e\u0924 \u092c\u0924\u093e\u0913\u0964 \ud835\udf06 = 0.5 \ud835\udf06 = 1.5 honorifics, 2,4 Sanskrit 3 / Persian 1 words for \"job\" in formal Hindi",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_13",
            "start": 0,
            "end": 120,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_14@0",
            "content": "Figure 1: An illustration of our few-shot style transfer system during inference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_14",
            "start": 0,
            "end": 80,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_14@1",
            "content": "Our model extracts style vectors from exemplar English sentences as input (in this case formal/informal sentences) and uses their vector difference to guide style transfer in other languages (Hindi).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_14",
            "start": 82,
            "end": 280,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_14@2",
            "content": "\u03bb is used to control the magnitude of transfer: in this example our model produces more high Sanskrit words & honorifics (more formal) with higher \u03bb.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_14",
            "start": 282,
            "end": 430,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_15@0",
            "content": "like simplicity, formality or persuasion (Xu et al., 2015;Smith et al., 2020;Niu and Carpuat, 2020), data augmentation (Xie et al., 2020;Lee et al., 2021), and author obfuscation (Shetty et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_15",
            "start": 0,
            "end": 200,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_16@0",
            "content": "Most prior work either assumes access to supervised data with parallel sentences between the two styles (Jhamtani et al., 2017), or access to a large corpus of unpaired sentences with style labels (Prabhumoye et al., 2018;Subramanian et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_16",
            "start": 0,
            "end": 247,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_16@1",
            "content": "Models built are style-specific and cannot generalize to new styles during inference, which is needed for applications like real-time adaptation to a user's style in a dialog or writing application.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_16",
            "start": 249,
            "end": 446,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_16@2",
            "content": "Moreover, access to a large unpaired corpus with style labels is a strong assumption.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_16",
            "start": 448,
            "end": 532,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_16@3",
            "content": "Most standard \"unpaired\" style transfer datasets have been carefully curated (Shen et al., 2017) or were originally parallel (Xu et al., 2012;Rao and Tetreault, 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_16",
            "start": 534,
            "end": 700,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_16@4",
            "content": "This is especially relevant in settings outside En-glish, where NLP tools and labelled datasets are largely underdeveloped (Joshi et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_16",
            "start": 702,
            "end": 845,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_16@5",
            "content": "In this work, we take the first steps studying style transfer in seven languages 2 with nearly 1.5 billion speakers in total.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_16",
            "start": 847,
            "end": 971,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_16@6",
            "content": "Since no training data exists for these languages, we analyzed the current state-of-the-art in few-shot multilingual style transfer, the Universal Rewriter (UR) from Garcia et al. (2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_16",
            "start": 973,
            "end": 1159,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_16@7",
            "content": "Unfortunately, we find it often copies the inputs verbatim (Section 3.1), without changing their style.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_16",
            "start": 1161,
            "end": 1263,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_17@0",
            "content": "We propose a simple inference-time trick of style-controlled translation through English, which improves the UR output diversity (Section 4.1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_17",
            "start": 0,
            "end": 142,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_17@1",
            "content": "To further boost performance we propose DIFFUR, 3 a novel algorithm using the recent finding that paraphrasing leads to stylistic changes (Krishna et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_17",
            "start": 144,
            "end": 304,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_17@2",
            "content": "DIFFUR extracts edit vectors from paraphrase pairs, which are used to condition and train the model (Figure 2).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_17",
            "start": 306,
            "end": 416,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_17@3",
            "content": "On formality transfer and code-mixing addition, our best performing DIF-FUR variant significantly outperforms UR across all languages (by 2-3x) using automatic & human evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_17",
            "start": 418,
            "end": 596,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_17@4",
            "content": "Besides better rewriting, our system is better able to control the style transfer magnitude (Figure 1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_17",
            "start": 598,
            "end": 700,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_17@5",
            "content": "A scalar knob (\u03bb) can be adjusted to make the output text reflect the target style (provided by exemplars) more or less.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_17",
            "start": 702,
            "end": 821,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_17@6",
            "content": "We also observe promising qualitative results in several attribute transfer directions (Section 6.2) including sentiment transfer, simplification, gender neutralization and text anonymization, all without retraining the model and using just 3-10 examples at inference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_17",
            "start": 823,
            "end": 1090,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_18@0",
            "content": "Finally, we found it hard to precisely evaluate models due to the lack of evaluation datasets and style classifiers (often used as metrics) for many languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_18",
            "start": 0,
            "end": 158,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_18@1",
            "content": "To facilitate further research in Indic formality transfer, we crowdsource formality annotations for 4000 sentence pairs in four Indic languages (Section 5.1), and use this dataset to design the automatic evaluation suite (Section 5).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_18",
            "start": 160,
            "end": 393,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_18@2",
            "content": "In summary, our contributions provide an end-toend recipe for developing and evaluating style transfer models and evaluation in a low-resource setting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_18",
            "start": 395,
            "end": 545,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_19@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_19",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_20@0",
            "content": "Few-shot methods are a recent development in English style transfer, with prior work using variational autoencoders (Xu et al., 2020), or prompting large pretrained language models at inference (Reif 2 Indic (hi,bn,kn,gu,te), Spanish, Swahili.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_20",
            "start": 0,
            "end": 242,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_20@1",
            "content": "3 \"Difference Universal Rewriter\", pronounced as differ.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_20",
            "start": 244,
            "end": 299,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_20@2",
            "content": "et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_20",
            "start": 301,
            "end": 314,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_20@3",
            "content": "Most related is the state-of-the-art TextSETTR model from Riley et al. (2021), who use a neural style encoder to map exemplar sentences to a vector used to guide generation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_20",
            "start": 316,
            "end": 488,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_20@4",
            "content": "To train this encoder, they use the idea that adjacent sentences in a document have a similar style.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_20",
            "start": 490,
            "end": 589,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_20@5",
            "content": "Recently, the Universal Rewriter (Garcia et al., 2021) extended TextSETTR to 101 languages, developing a joint model for translation, few-shot style transfer and stylized translation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_20",
            "start": 591,
            "end": 773,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_20@6",
            "content": "This model is the only prior few-shot system we found outside English, and our main baseline.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_20",
            "start": 775,
            "end": 867,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_20@7",
            "content": "We discuss its shortcomings in Section 3.1, and propose fixes in Section 4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_20",
            "start": 869,
            "end": 943,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_20@8",
            "content": "Multilingual style transfer is mostly unexplored in prior work: a 35 paper survey by Briakou et al. (2021b) found only one work in Chinese, Russian, Latvian, Estonian, French.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_20",
            "start": 945,
            "end": 1119,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_20@9",
            "content": "They further introduced XFORMAL, the first formality transfer evaluation dataset in French, Brazilian Portugese and Italian.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_20",
            "start": 1121,
            "end": 1244,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_20@10",
            "content": "4 To the best of our knowledge, we are the first to study style transfer for the languages we consider.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_20",
            "start": 1246,
            "end": 1348,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_20@11",
            "content": "More related work from Hindi linguistics and on style transfer control is provided in Appendix B.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_20",
            "start": 1350,
            "end": 1446,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_21@0",
            "content": "The Universal Rewriter (UR) model",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_21",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_22@0",
            "content": "We will start by discussing the Universal Rewriter (UR) model from Garcia et al. (2021), upon which our proposed DIFFUR model is built.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_22",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_22@1",
            "content": "At a high level, the UR model extracts a style vector s from an exemplar sentence e, which reflects the desired target style.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_22",
            "start": 136,
            "end": 260,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_22@2",
            "content": "This style vector is used to style transfer an input sentence x. Concretely, consider f enc , f dec to be encoder & decoder Transformers initialized with mT5 (Xue et al., 2021b), which are composed to form the model f ur .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_22",
            "start": 262,
            "end": 483,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_22@3",
            "content": "The UR model extracts the style vector using the encoder representation of a special [CLS] token prepended to e, and adds it to the input x representations for style transfer,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_22",
            "start": 485,
            "end": 659,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_23@0",
            "content": "f style (e) = s = f enc ([CLS] \u2295 e)[0] f ur (x, s) = f dec (f enc (x) + s)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_23",
            "start": 0,
            "end": 73,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_24@0",
            "content": "where \u2295 is string concatenation, + vector addition.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_24",
            "start": 0,
            "end": 50,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_24@1",
            "content": "f ur is trained using the following objectives, Learning Style Transfer by Exemplar-driven Denoising: To learn a style extractor, the Universal Rewriter uses the idea that two non-overlapping spans of text in the same document are likely to have the same style.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_24",
            "start": 52,
            "end": 312,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_24@2",
            "content": "Concretely, let x 1 and x 2 be two non-overlapping spans.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_24",
            "start": 314,
            "end": 370,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_24@3",
            "content": "Style extracted from one span (x 1 ) is used to denoise the other (x 2 ), x2 = f ur (noise(x 2 ), f style (x 1 ))",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_24",
            "start": 372,
            "end": 484,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_25@0",
            "content": "L denoise = L CE (x 2 , x 2 )",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_25",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_26@0",
            "content": "where L CE is the standard next-word prediction cross entropy loss function and noise(\u2022) refers to 20-60% random token dropping and token replacement.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_26",
            "start": 0,
            "end": 149,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_26@1",
            "content": "This objective is used on the mC4 dataset (Xue et al., 2021b) with 101 languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_26",
            "start": 151,
            "end": 231,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_26@2",
            "content": "To build a general-purpose rewriter which can do translation as well as style transfer, the model is additionally trained on two objectives: (1) supervised machine translation using the OPUS-100 parallel dataset (Zhang et al., 2020), and (2) a self-supervised objective to learn effective stylecontrolled translation; more details in Appendix C.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_26",
            "start": 233,
            "end": 577,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_27@0",
            "content": "During inference (Figure 1), consider an input sentence x and a transformation from style A to B (say informal to formal).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_27",
            "start": 0,
            "end": 121,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_27@1",
            "content": "Let S A , S B to be exemplar sentences in each of the styles (typically 3-10 sentences).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_27",
            "start": 123,
            "end": 210,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_27@2",
            "content": "The output y is computed as,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_27",
            "start": 212,
            "end": 239,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_28@0",
            "content": "s A = 1 |S A | y\u2208S A f style (y) s B = 1 |S B | y\u2208S B f style (y) y = f ur (x, \u03bb(s B \u2212 s A ))",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_28",
            "start": 0,
            "end": 92,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_29@0",
            "content": "where \u03bb acts as a control knob to determine the magnitude of style transfer, and the vector subtraction helps remove confounding style information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_29",
            "start": 0,
            "end": 146,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_29@1",
            "content": "5",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_29",
            "start": 148,
            "end": 148,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_30@0",
            "content": "Shortcomings of the Universal Rewriter",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_30",
            "start": 0,
            "end": 37,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_31@0",
            "content": "We experimented with the UR model on Hindi formality transfer, and noticed poor performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_31",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_31@1",
            "content": "We noticed that UR has a strong tendency to copy sentences verbatim -45.5% outputs were copied exactly from the input (and hence not style transferred) for the best performing value of \u03bb.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_31",
            "start": 93,
            "end": 279,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_31@2",
            "content": "The copying increase for smaller \u03bb, making magnitude control harder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_31",
            "start": 281,
            "end": 348,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_31@3",
            "content": "We identify the following issues:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_31",
            "start": 350,
            "end": 382,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_31@4",
            "content": "1. Random token noise leads to unnatural inputs & transformations: The Universal Rewriter uses 20-60% uniformly random token dropping or replacement to noise inputs, which leads to ungrammatical inputs during training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_31",
            "start": 384,
            "end": 601,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_31@5",
            "content": "We hypothesize models tend to learn grammatical error correction, which encourages verbatim copying during inference where fluent inputs are used and no error correction is needed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_31",
            "start": 603,
            "end": 782,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_31@6",
            "content": "Moreover, token-level noise does not differentiate between content or function words, and cannot do syntactic changes like content reordering (Goyal and Durrett, 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_31",
            "start": 784,
            "end": 951,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_31@7",
            "content": "Too much noise could distort semantics and encourage hallucination, whereas too little will encourage copying.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_31",
            "start": 953,
            "end": 1062,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_31@8",
            "content": "2. Style vectors may not capture the precise style transformation: The Universal Rewriter extracts the style vector from a single sentence during training, which is a mismatch from the inference where a difference between vectors is taken.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_31",
            "start": 1064,
            "end": 1302,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_31@9",
            "content": "Without taking vector differences at inference, we observe semantic preservation and overall performance of the UR model is much lower.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_31",
            "start": 1304,
            "end": 1438,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_31@10",
            "content": "6 3. mC4 is noisy: On reading training data samples, we noticed noisy samples with severe language identification errors in the Hindi subset of mC4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_31",
            "start": 1440,
            "end": 1587,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_31@11",
            "content": "This has also been observed recently in Kreutzer et al. (2022), who audit 100 sentences in each language, and report 50% sentences in Marathi and 20% sentences in Hindi have the wrong language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_31",
            "start": 1589,
            "end": 1781,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_31@12",
            "content": "4. No translation data for several languages: We notice worse performance for languages which did not get parallel translation data (for the translation objective in Section 3).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_31",
            "start": 1783,
            "end": 1959,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_31@13",
            "content": "In Table 1 we see UR gets a score 7 of 30.4 for Hindi and Bengali, languages for which it got translation data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_31",
            "start": 1961,
            "end": 2071,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_31@14",
            "content": "However, the scores are lower for Kannada, Telugu & Gujarati (25.5,22.8,23.7), for which no translation data was used.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_31",
            "start": 2073,
            "end": 2190,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_31@15",
            "content": "We hypothesize translation data encourages learning language-agnostic semantic representations needed for translation from the given language, which in-turn improves style transfer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_31",
            "start": 2192,
            "end": 2372,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_32@0",
            "content": "Our Models",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_32",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_33@0",
            "content": "Style-Controlled Backtranslation (+ BT)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_33",
            "start": 0,
            "end": 38,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_34@0",
            "content": "While the Universal Rewriter model has a strong tendency to exactly copy input sentences while rewriting sentences in the same language (Section 3.1), we found it is an effective style-controlled translation system.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_34",
            "start": 0,
            "end": 214,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_34@1",
            "content": "This motivates a simple inference-time trick to improve model outputs and reduce copying -translate sentences to English (en) in a style-agnostic manner with a zero style The DIFFUR approach (Section 4.2), with fixes to the shortcomings of the Universal Rewriter approach (Section 3.1) shown.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_34",
            "start": 216,
            "end": 507,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_34@2",
            "content": "Sentences are noised using paraphrasing, the style vector difference between the paraphrase & original sentence (\"edit vector\") is used to control denoising.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_34",
            "start": 509,
            "end": 665,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_34@3",
            "content": "See Figure 1 for the inference-time process.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_34",
            "start": 667,
            "end": 710,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_35@0",
            "content": "vector 0, and translate back into the source language (lx) with stylistic control.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_35",
            "start": 0,
            "end": 81,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_36@0",
            "content": "x en = f ur (en \u2295 x, 0)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_36",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_37@0",
            "content": "x = f ur (lx \u2295 x en , \u03bb(s B \u2212 s A ))",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_37",
            "start": 0,
            "end": 35,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_38@0",
            "content": "where x is the input sentence, s A , s B are the styles vectors we want to transfer between, en, lx are language codes prepended to indicate the output language (Appendix C).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_38",
            "start": 0,
            "end": 173,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_38@1",
            "content": "Prior work has shown that backtranslation is effective for paraphrasing (Wieting and Gimpel, 2018;Iyyer et al., 2018) and style transfer (Prabhumoye et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_38",
            "start": 175,
            "end": 337,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_39@0",
            "content": "Using Paraphrase Vector Differences for",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_39",
            "start": 0,
            "end": 38,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_40@0",
            "content": "Style Transfer (DIFFUR)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_40",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_41@0",
            "content": "While style-controlled backtranslation is an effective strategy, it needs two translation steps.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_41",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_41@1",
            "content": "This is 2x slower than UR, and semantic errors increase with successive translations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_41",
            "start": 97,
            "end": 181,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_41@2",
            "content": "To learn effective style transfer systems needing only a single generation step we develop DIFFUR, a new few-shot style transfer training objective (overview in Figure 2).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_41",
            "start": 183,
            "end": 353,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_41@3",
            "content": "DIFFUR tackles the issues discussed in Section 3.1 using paraphrases and style vector differences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_41",
            "start": 355,
            "end": 452,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_42@0",
            "content": "Paraphrases as a \"noise\" function: Instead of using random token-level noise (Issue #1 in Section 3.1), we paraphrase sentences to \"noise\" them during training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_42",
            "start": 0,
            "end": 159,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_42@1",
            "content": "Paraphrasing modifies the lexical & syntactic properties of sentences, while preserving fluency and input semantics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_42",
            "start": 161,
            "end": 276,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_42@2",
            "content": "Prior work (Krishna et al., 2020) has shown that paraphrasing leads to stylistic changes, and denoising can be considered a style re-insertion process.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_42",
            "start": 278,
            "end": 428,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_43@0",
            "content": "To create paraphrases, we backtranslate sentences from the UR model 8 with no style control (zero vectors used as style vectors).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_43",
            "start": 0,
            "end": 128,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_43@1",
            "content": "To increase diversity, we use random sampling in both translation steps, pooling generations obtained using temperature values [0.4, 0.6, 0.8, 1.0].",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_43",
            "start": 130,
            "end": 277,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_43@2",
            "content": "Finally, we discard paraphrase pairs from the training data where the semantic similarity score 9 is outside the range [0.7, 0.98].",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_43",
            "start": 279,
            "end": 409,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_43@3",
            "content": "This removes backtransation errors (score < 0.7), and exact copies (score > 0.98).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_43",
            "start": 411,
            "end": 492,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_43@4",
            "content": "In Appendix K we confirm that our backtranslated paraphrases are lexically diverse from the input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_43",
            "start": 494,
            "end": 591,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_44@0",
            "content": "Using style vector differences for control: To fix the training / inference mismatch for style extraction (Issue #2 in Section 3.1), we propose using style vector differences between the output and input as the stylistic control.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_44",
            "start": 0,
            "end": 228,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_44@1",
            "content": "Concretely, let x be an input sentence and x para its paraphrase.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_44",
            "start": 230,
            "end": 294,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_45@0",
            "content": "s diff = f style (x) \u2212 f style (x para ) x = f ur (x para , stop-grad(s diff )) L = L CE (x, x)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_45",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_46@0",
            "content": "where stop-grad(\u2022) stops gradient flow through s diff , preventing the model from learning to copy x exactly.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_46",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_46@1",
            "content": "To ensure f style extracts meaningful style representations, we fine-tune a trained UR model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_46",
            "start": 110,
            "end": 202,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_46@2",
            "content": "Vector differences have many advantages, 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_46",
            "start": 204,
            "end": 246,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_46@3",
            "content": "Subtracting style vectors between a sentence and its paraphrase removes confounding features (like semantics) present in the vectors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_46",
            "start": 248,
            "end": 380,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_47@0",
            "content": "The vector difference focuses on the precise",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_47",
            "start": 0,
            "end": 43,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_48@0",
            "content": "transformation that is needed to reconstruct the input from its paraphrase.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_48",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_49@0",
            "content": "3. The length of s diff acts as a proxy for the amount of style transfer, which is controlled using \u03bb during inference (Section 3).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_49",
            "start": 0,
            "end": 130,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_50@0",
            "content": "DIFFUR is related to neural editor models (Guu et al., 2018;He et al., 2020), where language models are decomposed into a probabilistic space of edit vectors over prototype sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_50",
            "start": 0,
            "end": 182,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_50@1",
            "content": "We justify the DIFFUR design with ablations in Appendix G.1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_50",
            "start": 184,
            "end": 243,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_51@0",
            "content": "Indic Models (UR-INDIC, DIFFUR-INDIC)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_51",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_52@0",
            "content": "To address the issue of no translation data (Issue #4 in Section 3.1), we train Indic variants of our models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_52",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_52@1",
            "content": "We replace the OPUS translation data used for training the Universal Rewriter (Section 3) with Samanantar (Ramesh et al., 2021), which is the largest publicly available parallel translation corpus for 11 Indic languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_52",
            "start": 110,
            "end": 329,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_52@2",
            "content": "We call these variants UR-INDIC and DIFFUR-INDIC.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_52",
            "start": 331,
            "end": 379,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_52@3",
            "content": "This process significantly up-samples the parallel data seen between English / Indic languages, and gives us better performance (Table 1) and lower copy rates, especially for languages with no OPUS translation data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_52",
            "start": 381,
            "end": 595,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_53@0",
            "content": "Multitask Learning (DIFFUR-MLT)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_53",
            "start": 0,
            "end": 30,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_54@0",
            "content": "One issue with our DIFFUR-INDIC setup is usage of a stop-grad(\u2022) to avoid verbatim copying from the input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_54",
            "start": 0,
            "end": 105,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_54@1",
            "content": "This prevents gradient flow into the style extractor f style , and as we see in Appendix H, a degradation of the style vector space.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_54",
            "start": 107,
            "end": 238,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_54@2",
            "content": "To prevent this we simply multi-task between the exemplardriven denoising UR objective (Section 3) and the DIFFUR objective.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_54",
            "start": 240,
            "end": 363,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_54@3",
            "content": "We initialize the model with the UR-INDIC checkpoint, and fine-tune it on these two losses together, giving each loss equal weight.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_54",
            "start": 365,
            "end": 495,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_55@0",
            "content": "Evaluation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_55",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_56@0",
            "content": "Automatic evaluation of style transfer is challenging (Pang, 2019;Mir et al., 2019;Tikhonov et al., 2019), and the lack of resources (such as evaluation datasets, style classifiers) make evaluation trickier for Indic languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_56",
            "start": 0,
            "end": 226,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_56@1",
            "content": "To tackle this issue, we first collect a small dataset of formality and semantic similarity annotations in four Indic languages (Section 5.1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_56",
            "start": 228,
            "end": 369,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_56@2",
            "content": "We use this dataset to guide the design of an evaluation suite (Section 5.2-5.6).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_56",
            "start": 371,
            "end": 451,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_57@0",
            "content": "Since automatic metrics in generation are imperfect (Celikyilmaz et al., 2020), we complement our results with human evaluation (Section 5.7).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_57",
            "start": 0,
            "end": 141,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_58@0",
            "content": "Indic Formality Transfer Dataset",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_58",
            "start": 0,
            "end": 31,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_59@0",
            "content": "Since no public datasets exist for formality transfer in Indic languages, it is hard to measure the extent to which automatic metrics (such as style classifiers) are effective.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_59",
            "start": 0,
            "end": 175,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_59@1",
            "content": "To tackle this issue, we build a dataset of 1000 sentence pairs in each of four Indic languages (Hindi, Bengali, Kannada, Telugu) with formality and semantic similarity annotations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_59",
            "start": 177,
            "end": 357,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_59@2",
            "content": "We first style transfer held-out Samanantar sentences using our UR-INDIC + BT model (Section 4.1, 4.3) to create sentence pairs with different formality.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_59",
            "start": 359,
            "end": 511,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_59@3",
            "content": "We then asked three crowdworkers to 1) label the more formal sentence in each pair; 2) rate semantic similarity on a 3-point scale.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_59",
            "start": 513,
            "end": 643,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_60@0",
            "content": "Our crowdsourcing is conducted on Task Mate, 10 where we hired native speakers from India with at least a high school education and 90% approval rating on the platform.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_60",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_60@1",
            "content": "To ensure crowdworkers understood \"formality\", we provided instructions following advice from professional Indian linguists, and asked two qualification questions in their native language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_60",
            "start": 169,
            "end": 356,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_60@2",
            "content": "More details (agreement, compensation, instructions) are provided in Appendix E.4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_60",
            "start": 358,
            "end": 439,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_61@0",
            "content": "Transfer Accuracy (r-ACC, a-ACC)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_61",
            "start": 0,
            "end": 31,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_62@0",
            "content": "Our first metric checks whether the output sentence reflects the target style.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_62",
            "start": 0,
            "end": 77,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_62@1",
            "content": "This is measured by an external classifier's predictions on system outputs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_62",
            "start": 79,
            "end": 153,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_62@2",
            "content": "We use two variants of transfer accuracy: (1) Relative Accuracy (r-ACC): does the target style classifier score the output sentence higher than the input sentence? (2) Absolute Accuracy (a-ACC): does the classifier score the output higher than 0.5?",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_62",
            "start": 155,
            "end": 402,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_62@3",
            "content": "Building multilingual classifiers: Unfortunately, no large style classification datasets exist for most languages, preventing us from building classifiers from scratch.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_62",
            "start": 404,
            "end": 571,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_62@4",
            "content": "We resort to zero-shot cross lingual transfer techniques (Conneau and Lample, 2019), where large multilingual pretrained models are first fine-tuned on English classification data, and then applied to other languages at inference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_62",
            "start": 573,
            "end": 802,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_62@5",
            "content": "We experiment with three such techniques, and find MAD-X classifiers with language adapters (Pfeiffer et al., 2020b) have the highest accuracy of 81% on our Hindi data from Section 5.1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_62",
            "start": 804,
            "end": 988,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_62@6",
            "content": "However, MAD-X classifiers were only available for Hindi, so we use the next best XLM RoBERTa-base (Conneau et al., 2020) for other languages, which has 75%-82% accuracy on annotated data; details in Appendix E.1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_62",
            "start": 990,
            "end": 1202,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_63@0",
            "content": "Semantic Similarity (SIM)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_63",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_64@0",
            "content": "Our second evaluation criteria is semantic similarity between the input and output.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_64",
            "start": 0,
            "end": 82,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_64@1",
            "content": "Following recent recommendations (Marie et al., 2021;Krishna et al., 2020), we avoid n-gram overlap metrics like BLEU (Papineni et al., 2002).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_64",
            "start": 84,
            "end": 225,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_64@2",
            "content": "Instead, we use LaBSE (Feng et al., 2020), a language-agnostic semantic similarity model based on multilingual BERT (Devlin et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_64",
            "start": 227,
            "end": 364,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_64@3",
            "content": "LaBSE supports 109 languages, and is the only similarity model we found supporting all the Indic languages in this work.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_64",
            "start": 366,
            "end": 485,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_64@4",
            "content": "We also observed LaBSE had greater correlation with our annotated data (Section 5.1) compared to alternatives; details in Appendix E.2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_64",
            "start": 487,
            "end": 621,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_65@0",
            "content": "Qualitatively, we found that sentence pairs with LaBSE scores lower than 0.6 were almost never paraphrases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_65",
            "start": 0,
            "end": 106,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_65@1",
            "content": "To avoid rewarding partial credit for low LaBSE scores, we use a hard threshold 11 (L = 0.75) to determine whether pairs are paraphrases, SIM(x, y ) = 1 if LaBSE(x, y ) > L else 0 5.4 Other Metrics (LANG, COPY, 1-g) Additionally, we measure whether the input and output sentences are in the same language (LANG), the fraction of outputs copied verbatim from the input (COPY), and the 1-gram overlap between input / output (1-g).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_65",
            "start": 108,
            "end": 535,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_65@2",
            "content": "High LANG and low COPY / 1-g (more diversity) is better; details in Appendix E.6.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_65",
            "start": 537,
            "end": 617,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_66@0",
            "content": "Aggregated Score (r-AGG, a-AGG)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_66",
            "start": 0,
            "end": 30,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_67@0",
            "content": "To get a sense of overall system performance, we combine individual metrics into one score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_67",
            "start": 0,
            "end": 90,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_67@1",
            "content": "Similar to Krishna et al. (2020) we aggregate metrics as,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_67",
            "start": 92,
            "end": 148,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_68@0",
            "content": "AGG(x, y ) = ACC(x, y ) \u2022 SIM(x, y ) \u2022 LANG(y ) AGG(D) = 1 |D| x,y \u2208D AGG(x, y )",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_68",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_69@0",
            "content": "Where (x, y ) are input-output pairs, and D is the test corpus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_69",
            "start": 0,
            "end": 62,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_69@1",
            "content": "Since each of our individual metrics can only take values 0 or 1 at an instance level, our aggregation acts like a Boolean AND operation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_69",
            "start": 64,
            "end": 200,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_70@0",
            "content": "In other words, we are measuring the fraction of outputs which simultaneously transfer style, have a semantic similarity of at least L (our threshold in Section 5.3), and have the same language as the input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_70",
            "start": 0,
            "end": 206,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_70@1",
            "content": "Depending on the variant of ACC (relative / absolute), we can derive r-AGG / a-AGG.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_70",
            "start": 208,
            "end": 290,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_71@0",
            "content": "Evaluating Control (CALIB)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_71",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_72@0",
            "content": "An ideal system should not only be able to style transfer sentences, but also control the magnitude of style transfer using the scalar input \u03bb.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_72",
            "start": 0,
            "end": 142,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_72@1",
            "content": "To evaluate this, for every system we first determine a \u03bb max value and let [0, \u03bb max ] be the range of control values.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_72",
            "start": 144,
            "end": 262,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_72@2",
            "content": "While in our setup \u03bb is an unbounded scalar, we noticed high values of \u03bb significantly perturb semantics (also noted in Garcia et al., 2021), with systems outputting style-specific n-grams unfaithful to the output.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_72",
            "start": 264,
            "end": 477,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_72@3",
            "content": "We choose \u03bb max to be the largest \u03bb from the list [0.5, 1.0, 1.5, 2.0, 2.5, 3.0] whose outputs have an average semantic similarity score (SIM, Section 5.3) of at least 0.75 12 with the validation set inputs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_72",
            "start": 479,
            "end": 685,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_72@4",
            "content": "For each system we take three evenly spaced \u03bb values in its control range, denoted as \u039b = [ 1 3 \u03bb max , 2 3 \u03bb max , \u03bb max ].",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_72",
            "start": 687,
            "end": 810,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_72@5",
            "content": "We then compute the style calibration to \u03bb (CALIB), or how often does increasing \u03bb lead to a style score increase?",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_72",
            "start": 812,
            "end": 925,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_72@6",
            "content": "We measure this with a statistic similar to Kendall's \u03c4 (Kendall, 1938), counting concordant pairs in \u039b,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_72",
            "start": 927,
            "end": 1030,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_73@0",
            "content": "CALIB(x) = 1 n \u03bb b >\u03bba {style(y \u03bb b ) > style(y \u03bba )}",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_73",
            "start": 0,
            "end": 52,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_74@0",
            "content": "where x is input, CALIB(x) is the average over all possible n (= 3) pairs of \u03bb values (\u03bb a , \u03bb b ) in \u039b.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_74",
            "start": 0,
            "end": 103,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_75@0",
            "content": "Human Evaluation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_75",
            "start": 0,
            "end": 15,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_76@0",
            "content": "Automatic metrics are usually insufficient for style transfer evaluation -according to Briakou et al. (2021a), 69 / 97 surveyed style transfer papers used human evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_76",
            "start": 0,
            "end": 171,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_76@1",
            "content": "We adopt the crowd-sourcing setup from Section 5.1, which was used to build our formality evaluation datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_76",
            "start": 173,
            "end": 282,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_76@2",
            "content": "We presented 200 generations from each model and the corresponding inputs in a random order, and asked three crowdworkers two questions about each pair of sentences: (1) which sentence is more formal/codemixed? (2) how similar are the two sentences in meaning?",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_76",
            "start": 284,
            "end": 543,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_76@3",
            "content": "This lets us evaluate r-ACC, SIM, r-AGG, CALIB with respect to human annotations instead of classifier predictions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_76",
            "start": 545,
            "end": 659,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_76@4",
            "content": "More experiment details (inter-annotator agreement, compensation, instructions) are provided in Appendix E.4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_76",
            "start": 661,
            "end": 769,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_77@0",
            "content": "Bengali Kannada Telugu Gujarati r-AGG a-AGG r-AGG a-AGG r-AGG a-AGG r-AGG a-AGG r-AGG a-AGG UR ( 2021 Table 2: Performance by individual metrics for Hindi formality transfer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_77",
            "start": 0,
            "end": 173,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_77@1",
            "content": "DIFFUR-MLT gives best overall performance (r-AGG / a-AGG), with a good trade-off between style accuracy (ACC), semantic similarity (SIM), langID score (LANG), and low input copy rates (COPY); metrics defined in Section 5, other language results in Appendix I.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_77",
            "start": 175,
            "end": 433,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_78@0",
            "content": "6 Main Experiments",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_78",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_79@0",
            "content": "Experimental Setup",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_79",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_80@0",
            "content": "In our experiments, we compare the following models (training details are provided Appendix A):",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_80",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_81@0",
            "content": "\u2022 UR: the Universal Rewriter (Garcia et al., 2021), which is our main baseline (Section 3); \u2022 DIFFUR: our model with paraphrase vector differences (Section 4.2); Our models are evaluated on (1) formality transfer (Rao and Tetreault, 2018); (2) code-mixing addition, a task where systems attempt to use English words in non-English sentences, while preserving the original script. 13 Since we do not have access to any formality evaluation dataset, 14 we hold out 22K sentences from Samanantar in each Indic language for validation / testing. For Swahili / Spanish, we use mC4 / WMT2018 sentences. These sets have similar number of formal / informal sentences, as marked by our formality classifiers (Section 5.2), and are transferred to the opposite formality. We re-use the hi/bn formality transfer splits for codemixing addition, evaluating unidirectional transfer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_81",
            "start": 0,
            "end": 866,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_82@0",
            "content": "\u2022 UR-INDIC,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_82",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_83@0",
            "content": "Seven languages with varying scripts and morphological richness are used for evaluation (hi,es,sw,bn,kn,te,gu).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_83",
            "start": 0,
            "end": 110,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_83@1",
            "content": "The UR model only saw translation data for hi,es,bn, whereas UR-INDIC sees translation data for all Indic languages (Section 4.3).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_83",
            "start": 112,
            "end": 241,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_83@2",
            "content": "To test the generalization capability of the DIFFUR, no Gujarati paraphrase training data for is used.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_83",
            "start": 243,
            "end": 344,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_83@3",
            "content": "Note that no paired/unpaired data with style labels is used during training: models determine the target style at inference using 3-10 exemplars sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_83",
            "start": 346,
            "end": 500,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_83@4",
            "content": "For few-shot formality transfer, we use the English exemplars from Garcia et al. ( 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_83",
            "start": 502,
            "end": 590,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_83@5",
            "content": "We follow their setup and use English exemplars to guide non-English transfer zero-shot.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_83",
            "start": 592,
            "end": 679,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_83@6",
            "content": "For code-mixing addition, we use Hindi/English code-mixed exemplars in Devanagari (shown in Appendix D).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_83",
            "start": 681,
            "end": 784,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_84@0",
            "content": "Main Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_84",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_85@0",
            "content": "Each proposed method improves over prior work, DIFFUR-MLT works best.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_85",
            "start": 0,
            "end": 68,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_85@1",
            "content": "We present our On Gujarati, the DIFFUR-INDIC fails to get good performance (36.0 r-AGG) since it did not see Gujarati paraphrase data, but this performance is recovered using DIFFUR-MLT (75.0).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_85",
            "start": 70,
            "end": 262,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_85@2",
            "content": "In Table 4 we see human evaluations support our automatic evaluation for formality transfer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_85",
            "start": 264,
            "end": 355,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_85@3",
            "content": "In Figure 4: Outputs and qualitative analysis of our best performing model for several attribute transfer tasks (\u03bb is transfer magnitude).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_85",
            "start": 357,
            "end": 494,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_85@4",
            "content": "We notice lower quality qualitatively for ** marked styles; see Appendix J for more outputs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_85",
            "start": 496,
            "end": 587,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_86@0",
            "content": "ACC scores.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_86",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_86@1",
            "content": "COPY reduces in our proposed models (4.4% for DIFFUR-MLT), which boosts overall performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_86",
            "start": 12,
            "end": 103,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_86@2",
            "content": "We find the lowest COPY (and lowest 1-g) for models with +BT (1%), which is due to two translation steps.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_86",
            "start": 105,
            "end": 209,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_86@3",
            "content": "However, this lowers semantic similarity (also seen in Table 4) lowering the overall score (60.0 vs 78.1) compared to DIFFUR-MLT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_86",
            "start": 211,
            "end": 339,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_87@0",
            "content": "In Appendix G we show ablations studies justifying the DIFFUR design, decoding scheme, etc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_87",
            "start": 0,
            "end": 90,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_87@1",
            "content": "In Appendix I we show a breakdown by individual metrics for other languages and plot variations with \u03bb.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_87",
            "start": 92,
            "end": 194,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_87@2",
            "content": "We also analyze the style encoder f style in Appendix H, finding it is an effective style classifier.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_87",
            "start": 196,
            "end": 296,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_88@0",
            "content": "We analyze several qualitative outputs from DIFFUR-MLT in Figure 4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_88",
            "start": 0,
            "end": 66,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_88@1",
            "content": "Besides formality transfer and code-mixing addition, we transfer several other attributes: sentiment (Li et al., 2018), simplicity (Xu et al., 2015), anonymity (Anandan et al., 2012) and gender neutrality (Reddy and Knight, 2016).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_88",
            "start": 68,
            "end": 297,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_88@2",
            "content": "More outputs are provided in Appendix J.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_88",
            "start": 299,
            "end": 338,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_89@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_89",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_90@0",
            "content": "We present a recipe for building & evaluating controllable few-shot style transfer systems needing only 3-10 style examples at inference, useful in low-resource settings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_90",
            "start": 0,
            "end": 169,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_90@1",
            "content": "Our methods outperform prior work in formality transfer & code-mixing for 7 languages, with promising qualitative results for several other attribute transfer tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_90",
            "start": 171,
            "end": 335,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_90@2",
            "content": "Future work includes further improving systems for some attributes, and studying style transfer for languages where little / no translation data is available.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_90",
            "start": 337,
            "end": 494,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_91@0",
            "content": "Recent work has highlighted issues of stylistic bias in text generation systems, specifically machine translation systems (Hovy et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_91",
            "start": 0,
            "end": 141,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_91@1",
            "content": "We acknowledge these issues, and consider style transfer and style-controlled generation technology as an opportunity to work towards fixing them (for instance, gender neutralization as presented in Section 6.2).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_91",
            "start": 143,
            "end": 354,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_91@2",
            "content": "Note that it is important to tread down this path carefully -In Chapter 9, Blodgett (2021) argue that style is inseparable from social meaning (as originally noted by Eckert, 2008), and humans may perceive automatically generated text very differently compared to automatic style classifiers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_91",
            "start": 356,
            "end": 647,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_92@0",
            "content": "Our models were trained on 32 Google Cloud TPUs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_92",
            "start": 0,
            "end": 47,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_92@1",
            "content": "As discussed in Appendix A, the UR & UR-INDIC model take roughly 18 hours to train.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_92",
            "start": 49,
            "end": 131,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_92@2",
            "content": "The DIFFUR-* and DIFFUR-MLT models are much cheaper to train (2 hours) since we finetune the pretrained UR-* models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_92",
            "start": 133,
            "end": 248,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_92@3",
            "content": "The Google 2020 environment report mentions, 15 \"TPUs are highly efficient chips which have been specifically designed for machine learning applications\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_92",
            "start": 250,
            "end": 403,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_92@4",
            "content": "These accelerators run on Google Cloud, which is carbon neutral today, and is aiming to \"run on carbon-free energy, 24/7, at all of Google's data centers by 2030\" (https://cloud.google. com/sustainability).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_92",
            "start": 405,
            "end": 610,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_92@5",
            "content": "A few prior works build models which can control the degree of style transfer using a scalar input (Wang et al., 2019;Samanta et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_92",
            "start": 612,
            "end": 751,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_93@0",
            "content": "However, these models are style-specific and require large unpaired style corpora during training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_93",
            "start": 0,
            "end": 97,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_93@1",
            "content": "We adopt the inference-time control method used by Garcia et al. ( 2021) and notice much better controllability after our proposed fixes in Section 4.2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_93",
            "start": 99,
            "end": 250,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_94@0",
            "content": "In this section we describe the details of the supervised translation objective and the style-controlled translation objective used in the Universal Rewriter model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_94",
            "start": 0,
            "end": 163,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_94@1",
            "content": "See Section 3 for details on the exemplarbased denoising objective.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_94",
            "start": 165,
            "end": 231,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_95@0",
            "content": "This objective is the standard supervised translation setup, using zero vectors for style.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_95",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_95@1",
            "content": "The output language code is prepended to the input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_95",
            "start": 91,
            "end": 141,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_95@2",
            "content": "Consider a pair of parallel sentences (x, y) in languages with codes lx, ly (prepended to the input string), \u0233 = f ur (ly \u2295 x, 0)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_95",
            "start": 143,
            "end": 271,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_96@0",
            "content": "L translate = L CE (\u0233, y)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_96",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_97@0",
            "content": "The Universal Rewriter is trained on Englishcentric translation data from the high-resource languages in OPUS-100 (Zhang et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_97",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_98@0",
            "content": "Learning style-controlled translation: This objective emulates \"style-controlled translation\" in a self-supervised manner, via backtranslation through English.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_98",
            "start": 0,
            "end": 158,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_98@1",
            "content": "Consider x 1 and x 2 to be two non-overlapping spans in mC4 in language lx, protective buildings and military buildings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_98",
            "start": 160,
            "end": 279,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_99@0",
            "content": "x en 2 = f ur (en \u2295 x 2 , \u2212f style (x 1 )) x2 = f ur (lx \u2295 x en 2 , f style (x 1 )) L BT = L CE (x 2 , x 2 )",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_99",
            "start": 0,
            "end": 107,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_100@0",
            "content": "Positive sentiment exemplars",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_100",
            "start": 0,
            "end": 27,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_100@1",
            "content": "1. The most comfortable bed I've ever slept on, I highly recommend it.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_100",
            "start": 29,
            "end": 98,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_100@2",
            "content": "2. I loved it.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_100",
            "start": 100,
            "end": 113,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_100@3",
            "content": "3. The movie was fantastic.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_100",
            "start": 115,
            "end": 141,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_100@4",
            "content": "Negative sentiment exemplars",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_100",
            "start": 143,
            "end": 170,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_100@5",
            "content": "1. The most uncomfortable bed I've ever slept on, I would never recommend it.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_100",
            "start": 172,
            "end": 248,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_100@6",
            "content": "2. I hated it.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_100",
            "start": 250,
            "end": 263,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_100@7",
            "content": "3. The movie was awful.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_100",
            "start": 265,
            "end": 287,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_101@0",
            "content": "Due to the absence of a style classification dataset in Indic languages, we built our multilingual classifier drawing inspiration from recent research in zero-shot cross-lingual transfer (Conneau et al., 2018;Conneau and Lample, 2019;Pfeiffer et al., 2020b).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_101",
            "start": 0,
            "end": 257,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_101@1",
            "content": "We experimented with three zero-shot transfer techniques while selecting our classifiers for evaluating multilingual style transfer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_101",
            "start": 259,
            "end": 390,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_102@0",
            "content": "TRANSLATE TRAIN: The first technique uses the hypothesis that style is preserved across translation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_102",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_103@0",
            "content": "We classify the style of English sentences in the Samanantar translation dataset (Ramesh et al., 2021) using a style classifier trained on English formality data from Krishna et al. (2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_103",
            "start": 0,
            "end": 188,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_103@1",
            "content": "We use the human translated Indic languages sentences as training data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_103",
            "start": 190,
            "end": 260,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_103@2",
            "content": "This training data is used to fine-tune a large-scale multilingual language model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_103",
            "start": 262,
            "end": 343,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_103@3",
            "content": "ZERO-SHOT: The second technique fine-tunes large-scale multilingual language models on a English style transfer dataset, and applies it zero-shot on multilingual data during inference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_103",
            "start": 345,
            "end": 528,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_104@0",
            "content": "MAD-X: Introduced by Pfeiffer et al. (2020b), this technique is similar to ZERO-SHOT but additionally uses language-specific parameters (\"adapters\") during inference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_104",
            "start": 0,
            "end": 165,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_104@1",
            "content": "These language-specific adapters have been originally trained using masked language modeling on the desired language data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_104",
            "start": 167,
            "end": 288,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_104@2",
            "content": "Dataset for evaluating classifiers: We conduct our experiments on Hindi formality classification, leveraging our evaluation datasets from Section 5.1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_104",
            "start": 290,
            "end": 439,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_104@3",
            "content": "We removed pairs which did not have full agreement across the three annotators and those pairs which had the consensus rating of \"Equal\" formality.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_104",
            "start": 441,
            "end": 587,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_104@4",
            "content": "This filtering process leaves us with 316 pairs in Hindi (out of 1000).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_104",
            "start": 589,
            "end": 659,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_104@5",
            "content": "In our experiments, we check whether the classifiers give a higher score to the more formal sentence in the pair.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_104",
            "start": 661,
            "end": 773,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_105@0",
            "content": "We leverage the multilingual classifiers open-sourced 18 by Krishna et al. (2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_105",
            "start": 0,
            "end": 81,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_105@1",
            "content": "These models have been trained on the English GYAFC formality classification dataset (Rao and Tetreault, 2018), and have been shown to be effective on the XFORMAL dataset (Briakou et al., 2021b) for formality classification in Italian, French and Brazilian Portuguese.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_105",
            "start": 83,
            "end": 350,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_105@2",
            "content": "13 These classifiers were trained on preprocessed data which had trailing punctuation stripped and English sentences lower-cased, encouraging the models to focus on lexical and syntactic choices.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_105",
            "start": 352,
            "end": 546,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_105@3",
            "content": "As base multilingual language models, we use (1) mBERT-base from Devlin et al. ( 2019 2020b), we find MAD-X to be a superior zero-shot cross lingual transfer method compared to baselines.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_105",
            "start": 548,
            "end": 734,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_105@4",
            "content": "We also find XLM-R has better multilingual representations than mBERT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_105",
            "start": 736,
            "end": 805,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_105@5",
            "content": "Unfortunately, AdapterHub (Pfeiffer et al., 2020a) has XLM-R language adapters available only for Hindi & Tamil (among Indic languages).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_105",
            "start": 807,
            "end": 942,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_105@6",
            "content": "For other languages we use the ZERO-SHOT technique on XLM-R, consistent with the recommendations 13 provided by Krishna et al. (2020) based on their experiments on XFORMAL (Briakou et al., 2021b).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_105",
            "start": 944,
            "end": 1139,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_106@0",
            "content": "Model Accuracy (\u2191)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_106",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_107@0",
            "content": "TRANSLATE TRAIN mBERT 66% ZERO-SHOT mBERT 72% XLM-R 76% MAD-X",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_107",
            "start": 0,
            "end": 60,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_108@0",
            "content": "XLM-R 81%",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_108",
            "start": 0,
            "end": 8,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_109@0",
            "content": "We considered three models for evaluating semantic similarity between the input and output:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_109",
            "start": 0,
            "end": 90,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_110@0",
            "content": "(1) LaBSE (Feng et al., 2020);",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_110",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_111@0",
            "content": "(2) m-USE (Yang et al., 2020);",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_111",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_112@0",
            "content": "(3) multilingual Sentence-BERT (Reimers and Gurevych, 2020), the knowledge-distilled variant paraphrase-xlm-r-multilingual-v1",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_112",
            "start": 0,
            "end": 124,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_113@0",
            "content": "Among these models, only LaBSE has support for all the Indic languages we were interested in.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_113",
            "start": 0,
            "end": 92,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_114@0",
            "content": "No Indic language is supported by m-USE, and multilingual Sentence-BERT has been trained on parallel data only for Hindi, Gujarati and Marathi among our Indic languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_114",
            "start": 0,
            "end": 168,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_114@1",
            "content": "However, in terms of Semantic Textual Similarity (STS) benchmarks (Cer et al., 2017) for English, Arabic & Spanish, m-USE and Sentence-BERT outperform LaBSE (Table 1 in Reimers and Gurevych, 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_114",
            "start": 170,
            "end": 366,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_115@0",
            "content": "LaBSE correlates better than Sentence-BERT with our human-annotated formality dataset:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_115",
            "start": 0,
            "end": 85,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_116@0",
            "content": "We measured the Spearman's rank correlation between the semantic similarity annotations on our human-annotated formality datasets (Section 5.1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_116",
            "start": 0,
            "end": 143,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_116@1",
            "content": "We discarded 10% sentence pairs which had no agreement among three annotators and took the majority vote for the other sentence pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_116",
            "start": 145,
            "end": 278,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_116@2",
            "content": "We assigned \"Different Meaning\" a score of 0, \"Slight Difference in Meaning\" a score of 1 and \"Approximately Same Meaning\" a score of 2 before measuring Spearman's rank correlation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_116",
            "start": 280,
            "end": 460,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_116@3",
            "content": "In Table 9 we see a stronger correlation of human annotations with LaBSE compared to Sentence-BERT, especially for languages like Bengali, Kannada for which Sentence-BERT did not see parallel data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_116",
            "start": 462,
            "end": 658,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_117@0",
            "content": "Model hi bn kn te LaBSE 0.34 0.49 0.39 0.25 Sentence-BERT 0.33 0.36 0.29 0.18 Table 9: Spearman's rank correlation between different semantic similarity models and our semantic similarity human annotations collected along with formality labels.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_117",
            "start": 0,
            "end": 243,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_117@1",
            "content": "Overall, LaBSE correlates more strongly than Sentence-BERT with our annotated data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_117",
            "start": 245,
            "end": 327,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_118@0",
            "content": "In Section 6, we set our LaBSE threshold L to 0.75.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_118",
            "start": 0,
            "end": 50,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_119@0",
            "content": "In this section, we present our evaluations with a more and less conservative value of L.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_119",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_120@0",
            "content": "In Table 18, we present results with L = 0.65, and in Table 19 we set L = 0.85.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_120",
            "start": 0,
            "end": 78,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_120@1",
            "content": "Compared to Table 1, trends are mostly similar, with DIFFUR models and INDIC variants outperforming counterparts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_120",
            "start": 80,
            "end": 192,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_120@2",
            "content": "Note that the absolute values of SIM and AGG metrics differ, with absolute values going down with the stricter threshold of L = 0.85, and up with the relaxed threshold of L = 0.65.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_120",
            "start": 194,
            "end": 373,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_121@0",
            "content": "To verify these three thresholds are reasonable choices, we measure the LaBSE similarity of the sentence pairs annotated by humans, and compare the LaBSE scores to human semantic similarity annotations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_121",
            "start": 0,
            "end": 201,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_121@1",
            "content": "We pool the \"Approximately Same Meaning\" and \"Slight Difference in Meaning\" categories as \"same\", and consider only sentence pairs with a majority rating of \"same\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_121",
            "start": 203,
            "end": 366,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_121@2",
            "content": "In As we increase the threshold L, we see this percentage substantially reduces, indicating our chosen thresholds are within the range of variation in LaBSE scores for semantically similar sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_121",
            "start": 368,
            "end": 566,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_122@0",
            "content": "In Figure 17, we show screenshots of our crowdsourcing interface along with all the instructions shown to crowdworkers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_122",
            "start": 0,
            "end": 118,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_122@1",
            "content": "The instructions were written after consulting professional Indian linguists.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_122",
            "start": 120,
            "end": 196,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_122@2",
            "content": "Each crowdworker was allowed to annotate a maximum of 50 different sentence pairs per language, paying them $0.05 per pair.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_122",
            "start": 198,
            "end": 320,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_122@3",
            "content": "For formality classification, we showed crowdworkers two sentences and asked them to choose which one is more formal.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_122",
            "start": 322,
            "end": 438,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_122@4",
            "content": "Crowdworkers were allowed to mark ties using an \"Equal\" option.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_122",
            "start": 440,
            "end": 502,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_122@5",
            "content": "For semantic similarity annotation, we showed crowdworkers the sentence pair and provided three options -\"approximately same meaning\", \"slight difference in meaning\", \"different meaning\", to emulate a 3-point Likert scale.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_122",
            "start": 504,
            "end": 725,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_122@6",
            "content": "While performing our human evaluation (Section 5.7), we use a 0.5 SIM score for \"slight difference in meaning\" and a 1.0 SIM score for \"approximately same meaning\" annotations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_122",
            "start": 727,
            "end": 902,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_122@7",
            "content": "For every system considered, we analyzed the same set of 200 input sentences for style transfer performance, and 100 of those sentences for evaluating controllability.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_122",
            "start": 904,
            "end": 1070,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_122@8",
            "content": "We removed sentences which were exact copies of the input (after removing trailing punctuation) or were in the wrong language to save annotator time and cost.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_122",
            "start": 1072,
            "end": 1229,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_122@9",
            "content": "When outputs were exact copies of the input, we assigned SIM = 100, ACC = 0, AGG = 0.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_122",
            "start": 1231,
            "end": 1315,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_123@0",
            "content": "In Table 11 and Table 12 we show the interannotator agreement statistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_123",
            "start": 0,
            "end": 72,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_123@1",
            "content": "We measure Fleiss Kappa (Fleiss, 1971), Randolph Kappa (Randolph, 2005Warrens, 2010), the fraction of sentence pairs with total agreement between the three annotators and the fraction of sentence pairs with no agreement.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_123",
            "start": 74,
            "end": 293,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_123@2",
            "content": "19 In the table we can see all agreement statistics are well away from a uniform random annotation baseline, indicating good agreement.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_123",
            "start": 295,
            "end": 429,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_124@0",
            "content": "Unlike some prior works, we avoid evaluation of output fluency due to the following reasons:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_124",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_125@0",
            "content": "(1) lack of fluency evaluation tools for Indic languages; 20 (2) fluency evaluation often discriminates against styles which are out-of-distribution for the fluency classifier, as discussed in Appendix A.8 of Krishna et al. ( 2020); (3) several prior works (Pang, 2019;Mir et al., 2019;Krishna et al., 2020) have recommended against using perplexity of style language models for fluency evaluation since it is unbounded and favours unnatural sentences with common words; (4) large language 19 The \u03ba scores are measured using the library https: //github.com/statsmodels/statsmodels.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_125",
            "start": 0,
            "end": 580,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_125@1",
            "content": "20 A potential tool for fluency evaluation in future work is LAMBRE (Pratapa et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_125",
            "start": 582,
            "end": 672,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_125@2",
            "content": "However, the original paper does not evaluate performance on Indic languages and the grammars for Indic languages would need to collected / built.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_125",
            "start": 674,
            "end": 819,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_125@3",
            "content": "models are known to produce fluent text as perceived by humans (Ippolito et al., 2020;Akoury et al., 2020), reducing the need for this evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_125",
            "start": 821,
            "end": 966,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_126@0",
            "content": "Language Consistency (LANG): Since our semantic similarity metric LaBSE is languageagnostic, it tends to ignore accidental translations, which are common errors in large multilingual transformers (Xue et al., 2021a,b), especially the Universal Rewriter (Section 3.1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_126",
            "start": 0,
            "end": 266,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_126@1",
            "content": "Hence, we check whether the output sentence is in the same language as the input, using langdetect.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_126",
            "start": 268,
            "end": 366,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_126@2",
            "content": "21 Output Diversity (COPY, 1-g): As discussed in Section 3.1, the Universal Rewriter has a strong tendency to copy the input verbatim.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_126",
            "start": 368,
            "end": 501,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_126@3",
            "content": "We build two metrics to measure output diversity compared to the input, which have been previously used for extractive question answering evaluation (Rajpurkar et al., 2016).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_126",
            "start": 503,
            "end": 676,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_126@4",
            "content": "The first metric COPY measures the fraction of outputs which were copied verbatim from the input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_126",
            "start": 678,
            "end": 774,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_126@5",
            "content": "This is done after removing trailing punctuation, to penalize models generations which solely modify punctuation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_126",
            "start": 776,
            "end": 888,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_126@6",
            "content": "A second metric 1-g measures the unigram overlap F1 score between the input and output.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_126",
            "start": 890,
            "end": 976,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_126@7",
            "content": "A diverse style transfer system should minimize both COPY and 1-g.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_126",
            "start": 978,
            "end": 1043,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_127@0",
            "content": "We follow the setup in Section 5.6 to first compute a \u03bb max per system.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_127",
            "start": 0,
            "end": 70,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_127@1",
            "content": "We then compute the following,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_127",
            "start": 72,
            "end": 101,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_127@2",
            "content": "1. Style Transfer Performance (r-AGG): An ideal system should have good overall performance (Section 5.5) across different values in the range \u039b.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_127",
            "start": 103,
            "end": 247,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_127@3",
            "content": "2. Average Style Score Increase (INCR): As our control value increases, we want the classifier's target style score (compared to the input) to increase.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_127",
            "start": 249,
            "end": 400,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_127@4",
            "content": "Additionally, we want the style score increase of \u03bb max to be as high as possible, indicating the system can span the range of classifier scores.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_127",
            "start": 402,
            "end": 546,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_127@5",
            "content": "3. Style Calibration to \u03bb (CALIB, C-IN): As defined in Section 5.6.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_127",
            "start": 548,
            "end": 614,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_127@6",
            "content": "We additionally also measure calibration by including the input sentence x in the CALIB(x) calculation, treating it as the output for \u03bb = 0 (no style transfer).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_127",
            "start": 616,
            "end": 775,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_127@7",
            "content": "Here, calibration is averaged over a total of n = 6 (\u03bb 1 , \u03bb 2 ) pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_127",
            "start": 777,
            "end": 847,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_127@8",
            "content": "We call this metric C-IN.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_127",
            "start": 849,
            "end": 873,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_128@0",
            "content": "A detailed breakdown of performance by different metrics for every model is shown in Table 15.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_128",
            "start": 0,
            "end": 93,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_129@0",
            "content": "This section describes the ablation experiments conducted for the DIFFUR modeling choices in Section 4.2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_129",
            "start": 0,
            "end": 104,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_129@1",
            "content": "We ablate a DIFFUR-INDIC model trained on Hindi paraphrase data only, and present results for Hindi formality transfer in Table 16.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_129",
            "start": 106,
            "end": 236,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_130@0",
            "content": "no paraphrase: We replaced the paraphrase noise function with the random token dropping / replacing noise used in the denoising objective of UR model (Section 3), and continued to use vector differences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_130",
            "start": 0,
            "end": 202,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_130@1",
            "content": "As seen in Table 16, this significantly increases the copy rate, which lowers the style transfer performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_130",
            "start": 204,
            "end": 312,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_131@0",
            "content": "no paraphrase semantic filtering: We keep a setup identical to Section 4.2, but avoid the LaBSE filtering done (discarding pairs having a LaBSE score outside [0.7, 0.98]) to remove noisy paraphrases or exact copies.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_131",
            "start": 0,
            "end": 214,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_131@1",
            "content": "As seen in Table 16, this decreases the semantic similarity score of the generations, lowering the overall performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_131",
            "start": 216,
            "end": 334,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_132@0",
            "content": "no vector differences: Instead of using vector differences for DIFFUR-INDIC, we simply set s diff = f style (x), or the style of the target sentence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_132",
            "start": 0,
            "end": 148,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_132@1",
            "content": "In Table 16, we see this significantly decreases SIM scores, and LANG scores for \u03bb = 2.0.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_132",
            "start": 150,
            "end": 238,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_132@2",
            "content": "We hypothesize that this training encourages the model to rely more heavily on the style vectors, ignoring the paraphrase input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_132",
            "start": 240,
            "end": 367,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_132@3",
            "content": "This could happen since the style vectors are solely constructed from the output sentence itself, and semantic information / confounding style is not subtracted out.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_132",
            "start": 369,
            "end": 533,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_132@4",
            "content": "In other words, the model is behaving more like an autoencoder (through the style vector) instead of a denoising autoencoder with stylistic supervision.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_132",
            "start": 535,
            "end": 686,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_133@0",
            "content": "-mC4 instead of Samanantar: Instead of creating pseudo-parallel data with Samanantar, we leverage the mC4 dataset itself which was used to train the UR model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_133",
            "start": 0,
            "end": 157,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_133@1",
            "content": "We backtranslate spans of text from the Hindi split of mC4 on-the-fly using the UR translation capabilities, and use it as the \"paraphrase noise function\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_133",
            "start": 159,
            "end": 313,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_133@2",
            "content": "To ensure translation performance does not deteriorate during training, 50% minibatches are supervised translation between Hindi and English.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_133",
            "start": 315,
            "end": 455,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_133@3",
            "content": "In Table 16, we see decent overall performance, but the LANG score is 6% lower than DIFFUR-INDIC.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_133",
            "start": 457,
            "end": 553,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_133@4",
            "content": "Qualitatively we found that the model often translates a few Hindi words to English while making text informal.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_133",
            "start": 555,
            "end": 665,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_133@5",
            "content": "Due to sparsity of English tokens, it often escapes penalization from LANG.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_133",
            "start": 667,
            "end": 741,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_134@0",
            "content": "-mC4 + exemplar instead of target: This setting is similar to the previous one, but in addition to the mC4 dataset we utilize the vector difference between the style vector of the exemplar span (instead of target span), and the \"paraphrase noised\" input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_134",
            "start": 0,
            "end": 253,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_134@1",
            "content": "Results in Table 16 show this method is not effective, and it's important for the vector difference to model the precise transformation needed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_134",
            "start": 255,
            "end": 397,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_135@0",
            "content": "We experiment with five decoding schemes on the Hindi formality validation set -beam search with beam size 1, 4 and top-p sampling (Holtzman et al., 2020) with p = 0.6, 0.75, 0.9.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_135",
            "start": 0,
            "end": 178,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_136@0",
            "content": "In Table 17, we present results at a constant style transfer magnitude (\u03bb = 3.0).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_136",
            "start": 0,
            "end": 80,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_136@1",
            "content": "Consistent with Krishna et al. (2020), we find that top-p decoding usually gets higher style accuracy (r-ACC, a-ACC) and output diversity (1-g, COPY) scores, but lower semantic similarity (SIM) scores.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_136",
            "start": 82,
            "end": 282,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_136@2",
            "content": "Overall beam search triumphs since the loss in semantic similarity leads to a worse performing model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_136",
            "start": 284,
            "end": 384,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_136@3",
            "content": "In Figure 10, we see a consistent trend across different magnitudes of style transfer (\u03bb).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_136",
            "start": 386,
            "end": 475,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_136@4",
            "content": "In all our main experiments, we use beam search with beam size 4 to obtain our generations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_136",
            "start": 477,
            "end": 567,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_137@0",
            "content": "In Figure 11, we present the variation in style transfer performance with number of training steps for our best model, the DIFFUR-MLT model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_137",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_137@1",
            "content": "We find that with more training steps performance generally improves, but improvements saturate after 8k steps.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_137",
            "start": 141,
            "end": 251,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_137@2",
            "content": "We also see the peak of the graphs (best style transfer performance) shift rightwards, indicating a preference for higher \u03bb values.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_137",
            "start": 253,
            "end": 383,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_137@3",
            "content": "style classifier? To explore this, we measure the cosine distance between the mean style vector of our informal exemplars, 22 and the style vectors derived by passing human-annotated formal/informal pairs (from our dataset of Section 5.1) through f style .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_137",
            "start": 385,
            "end": 640,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_137@4",
            "content": "We only consider pairs which had complete agreement among annotators.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_137",
            "start": 642,
            "end": 710,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_137@5",
            "content": "In Table 13 we see good agreement (68.2%-80.7%) between human annotations and the classifier derived from the metric space of the UR-INDIC model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_137",
            "start": 712,
            "end": 856,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_137@6",
            "content": "Agreement is lower (67.0%-74.3%) for the DIFFUR-INDIC model, likely due to the stop gradient used in Section 4.2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_137",
            "start": 858,
            "end": 970,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_137@7",
            "content": "With DIFFUR-MLT, agreement jumps back up to 75%-81.7% since gradients flow into the style extractor as well.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_137",
            "start": 972,
            "end": 1079,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_138@0",
            "content": "In Appendix H.1, we saw that the metric vector space derived from the style encoder f style of various models is an effective style classifier, using the informal exemplar vectors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_138",
            "start": 0,
            "end": 179,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_138@1",
            "content": "In Table 14 22 See Appendix D for the exemplar sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_138",
            "start": 181,
            "end": 237,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_138@2",
            "content": "We found the informal exemplars more effective than formal exemplars for style classification; Appendix H.2 has a comparison.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_138",
            "start": 239,
            "end": 363,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_139@0",
            "content": "A full breakdown of results by individual metrics, along with plots showing variation with change in \u03bb, is provided for -Hindi (Table 20, Figure 12), Bengali (Table 21, Figure 13), Kannada (Table 22, Figure 14), Telugu (Table 23, Figure 15), Gujarati (Table 24, Figure 16).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_139",
            "start": 0,
            "end": 272,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_140@0",
            "content": "Please refer to Figure 8.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_140",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_140@1",
            "content": "In the main body, Figure 4 has a few examples as well with detailed analysis.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_140",
            "start": 26,
            "end": 102,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_141@0",
            "content": "In Figure 9 we measure the lexical overlap between paraphrases used in our DIFFUR training strategy for six different languages (Hindi, Bengali, Kannada, Telugu, Swahili and Spanish).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_141",
            "start": 0,
            "end": 182,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_141@1",
            "content": "The lexical overlap is measured using the unigram F1 score, using the implementation from the SQuAD evaluation script (Rajpurkar et al., 2016).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_141",
            "start": 184,
            "end": 326,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_141@2",
            "content": "The wide spread of the histogram and sufficient percentage of low overlap pairs confirm the lexical diversity of the paraphrases used.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_141",
            "start": 328,
            "end": 461,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_141@3",
            "content": "As shown in prior work (Krishna et al., 2020), high lexical diversity of paraphrases is helpful for changing the input style.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_141",
            "start": 463,
            "end": 587,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_141@4",
            "content": "20 for a individual metric breakdown of the models at the best performing \u03bb).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_141",
            "start": 589,
            "end": 665,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_141@5",
            "content": "The plots show overall style transfer performance, using the r-AGG (top-left) and a-AGG (top-right) metrics from Section 5.5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_141",
            "start": 667,
            "end": 791,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_141@6",
            "content": "We see the DIFFUR models outperform other systems across the \u03bb range, and get best performance with the DIFFUR-MLT variant.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_141",
            "start": 793,
            "end": 915,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_141@7",
            "content": "We also see that DIFFUR models, especially with DIFFUR-MLT, lead to better style transfer control (bottom plot, closer to x = 1 is better), giving large style variation with \u03bb without loss in semantics (X-axis).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_141",
            "start": 917,
            "end": 1127,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_141@8",
            "content": "21 for a individual metric breakdown of the models at the best performing \u03bb).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_141",
            "start": 1129,
            "end": 1205,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_141@9",
            "content": "The plots show overall style transfer performance, using the r-AGG (top-left) and a-AGG (top-right) metrics from Section 5.5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_141",
            "start": 1207,
            "end": 1331,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_141@10",
            "content": "We see the DIFFUR models outperform other systems across the \u03bb range, and get best performance with the DIFFUR-MLT variant.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_141",
            "start": 1333,
            "end": 1455,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_141@11",
            "content": "We also see that DIFFUR models, especially with DIFFUR-MLT, lead to better style transfer control (bottom plot, closer to x = 1 is better), giving large style variation with \u03bb without loss in semantics (X-axis).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_141",
            "start": 1457,
            "end": 1667,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_142@0",
            "content": "Figure 17: Our crowdsourcing interface on Task Mate, used to build our formality evaluation datasets (Section 5.1) and conduct human evaluations (Section 5.7).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_142",
            "start": 0,
            "end": 158,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_142@1",
            "content": "The first row shows our landing page and instruction set derived from our conversations with professional linguists.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_142",
            "start": 160,
            "end": 275,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_142@2",
            "content": "The second row shows our qualification questions for formality classification, and the third row shows templates for the two questions asked to crowdworkers per pair.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_142",
            "start": 277,
            "end": 442,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_143@0",
            "content": "UNKNOWN, None, 2013, Hindi: An essential grammar, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_143",
            "start": 0,
            "end": 50,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_144@0",
            "content": "Nader Akoury, Shufan Wang, Josh Whiting, Stephen Hood, Nanyun Peng, Mohit Iyyer, STO-RIUM: A Dataset and Evaluation Platform for Machine-in-the-Loop Story Generation, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_144",
            "start": 0,
            "end": 318,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_145@0",
            "content": "UNKNOWN, None, 2012, Generalizing words to desensitize text. Transactions on Data Privacy, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_145",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_146@0",
            "content": "Kalika Bali, Jatin Sharma, Monojit Choudhury, Yogarshi Vyas, i am borrowing ya mixing?\" an analysis of english-hindi code mixing in facebook, 2014, Proceedings of the First Workshop on Computational Approaches to Code Switching, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_146",
            "start": 0,
            "end": 229,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_147@0",
            "content": "Su Lin,  Blodgett, Sociolinguistically driven approaches for just natural language processing, 2021, UMass Amherst Doctoral Dissertations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_147",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_148@0",
            "content": "UNKNOWN, None, 2018, , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_148",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_149@0",
            "content": "Eleftheria Briakou, Sweta Agrawal, Ke Zhang, Joel Tetreault, and Marine Carpuat. 2021a. A review of human evaluation for style transfer, , Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_149",
            "start": 0,
            "end": 239,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_150@0",
            "content": "Sravana Reddy, Kevin Knight, Obfuscating gender in social media writing, 2016, Proceedings of the First Workshop on NLP and Computational Social Science, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_150",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_151@0",
            "content": "UNKNOWN, None, 2021, A recipe for arbitrary text style transfer with large language models, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_151",
            "start": 0,
            "end": 92,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_152@0",
            "content": "Nils Reimers, Iryna Gurevych, Making monolingual sentence embeddings multilingual using knowledge distillation, 2020, Proceedings of Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_152",
            "start": 0,
            "end": 183,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_153@0",
            "content": "Parker Riley, Noah Constant, Mandy Guo, Girish Kumar, David Uthus, Zarana Parekh, TextSETTR: Few-shot text style extraction and tunable targeted restyling, 2021, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_153",
            "start": 0,
            "end": 224,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_154@0",
            "content": "Bidisha Samanta, Mohit Agrawal, Niloy Ganguly, A hierarchical vae for calibrating attributes while generating text using normalizing flow, 2021, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_154",
            "start": 0,
            "end": 207,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_155@0",
            "content": "UNKNOWN, None, 2019, A deep generative model for code-switched text, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_155",
            "start": 0,
            "end": 69,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_156@0",
            "content": "Mingyue Shang, Piji Li, Zhenxin Fu, Lidong Bing, Dongyan Zhao, Shuming Shi, Rui Yan, Semi-supervised text style transfer: Cross projection in latent space, 2019, Proceedings of Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_156",
            "start": 0,
            "end": 227,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_157@0",
            "content": "Tianxiao Shen, Tao Lei, Regina Barzilay, Tommi Jaakkola, Style transfer from non-parallel text by cross-alignment, 2017, Advances in neural information processing systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_157",
            "start": 0,
            "end": 172,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_158@0",
            "content": "Rakshith Shetty, Bernt Schiele, Mario Fritz, A4nt: author attribute anonymity by adversarial training of neural machine translation, 2018, 27th {USENIX} Security Symposium ({USENIX} Security 18), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_158",
            "start": 0,
            "end": 196,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_159@0",
            "content": "UNKNOWN, None, 2020, Controlling style in generated dialogue, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_159",
            "start": 0,
            "end": 62,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_160@0",
            "content": "Sandeep Subramanian, Guillaume Lample, Eric Smith, Ludovic Denoyer, Marc'aurelio Ranzato, Y-Lan Boureau, Multiple-attribute text style transfer, 2019, Proceedings of the International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_160",
            "start": 0,
            "end": 224,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_161@0",
            "content": "Aleksey Tikhonov, P Ivan,  Yamshchikov, Sounds wilde. phonetically extended embeddings for author-stylized poetry generation, 2018, Proceedings of the Fifteenth Workshop on Computational Research in Phonetics, Phonology, and Morphology, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_161",
            "start": 0,
            "end": 237,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_162@0",
            "content": "Alexey Tikhonov, Viacheslav Shibaev, Aleksander Nagaev, Aigul Nugmanova, Ivan Yamshchikov, Style transfer for texts: Retrain, report errors, compare with rewrites, 2019, Proceedings of Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_162",
            "start": 0,
            "end": 235,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_163@0",
            "content": "Ke Wang, Hang Hua, Xiaojun Wan, Controllable unsupervised text attribute transfer via editing entangled latent representation, 2019, Advances in Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_163",
            "start": 0,
            "end": 184,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_164@0",
            "content": "UNKNOWN, None, 2010, Inequalities between multirater kappas. Advances in data analysis and classification, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_164",
            "start": 0,
            "end": 107,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_165@0",
            "content": "John Wieting, Kevin Gimpel, ParaNMT-50M: Pushing the limits of paraphrastic sentence embeddings with millions of machine translations, 2018, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_165",
            "start": 0,
            "end": 203,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_166@0",
            "content": "Qizhe Xie, Zihang Dai, Eduard Hovy, Thang Luong, Quoc Le, Unsupervised data augmentation for consistency training, 2020, Advances in Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_166",
            "start": 0,
            "end": 172,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_167@0",
            "content": "Peng Xu, Jackie Chi Kit Cheung, Yanshuai Cao, On variational learning of controllable representations for text without supervision, 2020, International Conference on Machine Learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_167",
            "start": 0,
            "end": 184,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_168@0",
            "content": "Wei Xu, Chris Callison-Burch, Courtney Napoles, Problems in current text simplification research: New data can help, 2015, Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_168",
            "start": 0,
            "end": 186,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_169@0",
            "content": "Wei Xu, Alan Ritter, Bill Dolan, Ralph Grishman, Colin Cherry, Paraphrasing for style, 2012, Proceedings of International Conference on Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_169",
            "start": 0,
            "end": 163,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_170@0",
            "content": "UNKNOWN, None, , and Colin Raffel. 2021a. Byt5: Towards a tokenfree future with pre-trained byte-to-byte models, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_170",
            "start": 0,
            "end": 113,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_171@0",
            "content": "Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, and Colin Raffel. 2021b. mT5: A massively multilingual pre-trained text-to-text transformer, , Conference of the North American Chapter, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_171",
            "start": 0,
            "end": 277,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_172@0",
            "content": "Yinfei Yang, Daniel Cer, Amin Ahmad, Mandy Guo, Jax Law, Noah Constant, Gustavo Hernandez Abrego, Steve Yuan, Chris Tar, Yun-Hsuan Sung, Brian Strope, Ray Kurzweil, Multilingual universal sentence encoder for semantic retrieval, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_172",
            "start": 0,
            "end": 347,
            "label": {}
        },
        {
            "ix": "111-ARR_v2_173@0",
            "content": "Biao Zhang, Philip Williams, Ivan Titov, Rico Sennrich, Improving massively multilingual neural machine translation and zero-shot translation, 2020, Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v2_173",
            "start": 0,
            "end": 192,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "111-ARR_v2_0",
            "tgt_ix": "111-ARR_v2_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_0",
            "tgt_ix": "111-ARR_v2_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_1",
            "tgt_ix": "111-ARR_v2_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_1",
            "tgt_ix": "111-ARR_v2_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_1",
            "tgt_ix": "111-ARR_v2_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_2",
            "tgt_ix": "111-ARR_v2_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_0",
            "tgt_ix": "111-ARR_v2_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_3",
            "tgt_ix": "111-ARR_v2_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_5",
            "tgt_ix": "111-ARR_v2_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_4",
            "tgt_ix": "111-ARR_v2_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_4",
            "tgt_ix": "111-ARR_v2_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_4",
            "tgt_ix": "111-ARR_v2_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_7",
            "tgt_ix": "111-ARR_v2_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_8",
            "tgt_ix": "111-ARR_v2_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_4",
            "tgt_ix": "111-ARR_v2_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_4",
            "tgt_ix": "111-ARR_v2_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_4",
            "tgt_ix": "111-ARR_v2_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_6",
            "tgt_ix": "111-ARR_v2_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_10",
            "tgt_ix": "111-ARR_v2_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_11",
            "tgt_ix": "111-ARR_v2_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_12",
            "tgt_ix": "111-ARR_v2_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_13",
            "tgt_ix": "111-ARR_v2_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_14",
            "tgt_ix": "111-ARR_v2_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_15",
            "tgt_ix": "111-ARR_v2_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_16",
            "tgt_ix": "111-ARR_v2_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_17",
            "tgt_ix": "111-ARR_v2_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_4",
            "tgt_ix": "111-ARR_v2_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_4",
            "tgt_ix": "111-ARR_v2_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_4",
            "tgt_ix": "111-ARR_v2_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_4",
            "tgt_ix": "111-ARR_v2_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_4",
            "tgt_ix": "111-ARR_v2_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_4",
            "tgt_ix": "111-ARR_v2_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_4",
            "tgt_ix": "111-ARR_v2_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_4",
            "tgt_ix": "111-ARR_v2_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_4",
            "tgt_ix": "111-ARR_v2_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_9",
            "tgt_ix": "111-ARR_v2_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_0",
            "tgt_ix": "111-ARR_v2_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_18",
            "tgt_ix": "111-ARR_v2_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_19",
            "tgt_ix": "111-ARR_v2_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_19",
            "tgt_ix": "111-ARR_v2_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_0",
            "tgt_ix": "111-ARR_v2_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_20",
            "tgt_ix": "111-ARR_v2_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_22",
            "tgt_ix": "111-ARR_v2_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_23",
            "tgt_ix": "111-ARR_v2_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_24",
            "tgt_ix": "111-ARR_v2_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_25",
            "tgt_ix": "111-ARR_v2_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_26",
            "tgt_ix": "111-ARR_v2_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_27",
            "tgt_ix": "111-ARR_v2_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_28",
            "tgt_ix": "111-ARR_v2_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_21",
            "tgt_ix": "111-ARR_v2_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_21",
            "tgt_ix": "111-ARR_v2_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_21",
            "tgt_ix": "111-ARR_v2_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_21",
            "tgt_ix": "111-ARR_v2_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_21",
            "tgt_ix": "111-ARR_v2_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_21",
            "tgt_ix": "111-ARR_v2_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_21",
            "tgt_ix": "111-ARR_v2_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_21",
            "tgt_ix": "111-ARR_v2_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_21",
            "tgt_ix": "111-ARR_v2_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_21",
            "tgt_ix": "111-ARR_v2_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_29",
            "tgt_ix": "111-ARR_v2_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_30",
            "tgt_ix": "111-ARR_v2_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_30",
            "tgt_ix": "111-ARR_v2_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_0",
            "tgt_ix": "111-ARR_v2_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_31",
            "tgt_ix": "111-ARR_v2_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_32",
            "tgt_ix": "111-ARR_v2_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_32",
            "tgt_ix": "111-ARR_v2_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_34",
            "tgt_ix": "111-ARR_v2_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_35",
            "tgt_ix": "111-ARR_v2_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_36",
            "tgt_ix": "111-ARR_v2_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_37",
            "tgt_ix": "111-ARR_v2_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_33",
            "tgt_ix": "111-ARR_v2_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_33",
            "tgt_ix": "111-ARR_v2_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_33",
            "tgt_ix": "111-ARR_v2_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_33",
            "tgt_ix": "111-ARR_v2_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_33",
            "tgt_ix": "111-ARR_v2_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_33",
            "tgt_ix": "111-ARR_v2_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_32",
            "tgt_ix": "111-ARR_v2_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_38",
            "tgt_ix": "111-ARR_v2_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_40",
            "tgt_ix": "111-ARR_v2_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_41",
            "tgt_ix": "111-ARR_v2_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_42",
            "tgt_ix": "111-ARR_v2_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_43",
            "tgt_ix": "111-ARR_v2_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_44",
            "tgt_ix": "111-ARR_v2_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_45",
            "tgt_ix": "111-ARR_v2_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_39",
            "tgt_ix": "111-ARR_v2_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_39",
            "tgt_ix": "111-ARR_v2_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_39",
            "tgt_ix": "111-ARR_v2_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_39",
            "tgt_ix": "111-ARR_v2_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_39",
            "tgt_ix": "111-ARR_v2_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_39",
            "tgt_ix": "111-ARR_v2_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_39",
            "tgt_ix": "111-ARR_v2_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_39",
            "tgt_ix": "111-ARR_v2_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_19",
            "tgt_ix": "111-ARR_v2_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_46",
            "tgt_ix": "111-ARR_v2_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_48",
            "tgt_ix": "111-ARR_v2_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_49",
            "tgt_ix": "111-ARR_v2_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_47",
            "tgt_ix": "111-ARR_v2_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_47",
            "tgt_ix": "111-ARR_v2_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_47",
            "tgt_ix": "111-ARR_v2_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_47",
            "tgt_ix": "111-ARR_v2_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_32",
            "tgt_ix": "111-ARR_v2_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_50",
            "tgt_ix": "111-ARR_v2_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_51",
            "tgt_ix": "111-ARR_v2_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_51",
            "tgt_ix": "111-ARR_v2_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_32",
            "tgt_ix": "111-ARR_v2_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_52",
            "tgt_ix": "111-ARR_v2_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_53",
            "tgt_ix": "111-ARR_v2_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_53",
            "tgt_ix": "111-ARR_v2_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_0",
            "tgt_ix": "111-ARR_v2_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_54",
            "tgt_ix": "111-ARR_v2_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_56",
            "tgt_ix": "111-ARR_v2_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_55",
            "tgt_ix": "111-ARR_v2_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_55",
            "tgt_ix": "111-ARR_v2_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_55",
            "tgt_ix": "111-ARR_v2_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_55",
            "tgt_ix": "111-ARR_v2_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_57",
            "tgt_ix": "111-ARR_v2_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_59",
            "tgt_ix": "111-ARR_v2_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_58",
            "tgt_ix": "111-ARR_v2_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_58",
            "tgt_ix": "111-ARR_v2_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_58",
            "tgt_ix": "111-ARR_v2_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_55",
            "tgt_ix": "111-ARR_v2_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_60",
            "tgt_ix": "111-ARR_v2_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_61",
            "tgt_ix": "111-ARR_v2_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_61",
            "tgt_ix": "111-ARR_v2_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_55",
            "tgt_ix": "111-ARR_v2_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_62",
            "tgt_ix": "111-ARR_v2_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_64",
            "tgt_ix": "111-ARR_v2_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_63",
            "tgt_ix": "111-ARR_v2_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_63",
            "tgt_ix": "111-ARR_v2_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_63",
            "tgt_ix": "111-ARR_v2_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_55",
            "tgt_ix": "111-ARR_v2_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_65",
            "tgt_ix": "111-ARR_v2_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_67",
            "tgt_ix": "111-ARR_v2_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_68",
            "tgt_ix": "111-ARR_v2_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_69",
            "tgt_ix": "111-ARR_v2_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_66",
            "tgt_ix": "111-ARR_v2_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_66",
            "tgt_ix": "111-ARR_v2_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_66",
            "tgt_ix": "111-ARR_v2_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_66",
            "tgt_ix": "111-ARR_v2_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_66",
            "tgt_ix": "111-ARR_v2_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_55",
            "tgt_ix": "111-ARR_v2_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_70",
            "tgt_ix": "111-ARR_v2_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_72",
            "tgt_ix": "111-ARR_v2_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_73",
            "tgt_ix": "111-ARR_v2_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_71",
            "tgt_ix": "111-ARR_v2_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_71",
            "tgt_ix": "111-ARR_v2_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_71",
            "tgt_ix": "111-ARR_v2_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_71",
            "tgt_ix": "111-ARR_v2_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_55",
            "tgt_ix": "111-ARR_v2_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_74",
            "tgt_ix": "111-ARR_v2_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_75",
            "tgt_ix": "111-ARR_v2_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_75",
            "tgt_ix": "111-ARR_v2_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_77",
            "tgt_ix": "111-ARR_v2_78",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_75",
            "tgt_ix": "111-ARR_v2_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_75",
            "tgt_ix": "111-ARR_v2_78",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_76",
            "tgt_ix": "111-ARR_v2_77",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_0",
            "tgt_ix": "111-ARR_v2_79",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_78",
            "tgt_ix": "111-ARR_v2_79",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_80",
            "tgt_ix": "111-ARR_v2_81",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_82",
            "tgt_ix": "111-ARR_v2_83",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_79",
            "tgt_ix": "111-ARR_v2_80",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_79",
            "tgt_ix": "111-ARR_v2_81",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_79",
            "tgt_ix": "111-ARR_v2_82",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_79",
            "tgt_ix": "111-ARR_v2_83",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_79",
            "tgt_ix": "111-ARR_v2_80",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_0",
            "tgt_ix": "111-ARR_v2_84",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_83",
            "tgt_ix": "111-ARR_v2_84",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_85",
            "tgt_ix": "111-ARR_v2_86",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_86",
            "tgt_ix": "111-ARR_v2_87",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_87",
            "tgt_ix": "111-ARR_v2_88",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_84",
            "tgt_ix": "111-ARR_v2_85",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_84",
            "tgt_ix": "111-ARR_v2_86",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_84",
            "tgt_ix": "111-ARR_v2_87",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_84",
            "tgt_ix": "111-ARR_v2_88",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_84",
            "tgt_ix": "111-ARR_v2_85",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_0",
            "tgt_ix": "111-ARR_v2_89",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_88",
            "tgt_ix": "111-ARR_v2_89",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_90",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_90",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_91",
            "tgt_ix": "111-ARR_v2_92",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_91",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_92",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_93",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_90",
            "tgt_ix": "111-ARR_v2_91",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_94",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_93",
            "tgt_ix": "111-ARR_v2_94",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_95",
            "tgt_ix": "111-ARR_v2_96",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_96",
            "tgt_ix": "111-ARR_v2_97",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_97",
            "tgt_ix": "111-ARR_v2_98",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_98",
            "tgt_ix": "111-ARR_v2_99",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_95",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_96",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_97",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_98",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_99",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_94",
            "tgt_ix": "111-ARR_v2_95",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_100",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_99",
            "tgt_ix": "111-ARR_v2_100",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_101",
            "tgt_ix": "111-ARR_v2_102",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_102",
            "tgt_ix": "111-ARR_v2_103",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_103",
            "tgt_ix": "111-ARR_v2_104",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_101",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_102",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_103",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_104",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_100",
            "tgt_ix": "111-ARR_v2_101",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_105",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_104",
            "tgt_ix": "111-ARR_v2_105",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_106",
            "tgt_ix": "111-ARR_v2_107",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_107",
            "tgt_ix": "111-ARR_v2_108",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_106",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_107",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_108",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_105",
            "tgt_ix": "111-ARR_v2_106",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_109",
            "tgt_ix": "111-ARR_v2_110",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_110",
            "tgt_ix": "111-ARR_v2_111",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_111",
            "tgt_ix": "111-ARR_v2_112",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_112",
            "tgt_ix": "111-ARR_v2_113",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_113",
            "tgt_ix": "111-ARR_v2_114",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_114",
            "tgt_ix": "111-ARR_v2_115",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_115",
            "tgt_ix": "111-ARR_v2_116",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_116",
            "tgt_ix": "111-ARR_v2_117",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_109",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_110",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_111",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_112",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_113",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_114",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_115",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_116",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_117",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_108",
            "tgt_ix": "111-ARR_v2_109",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_118",
            "tgt_ix": "111-ARR_v2_119",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_119",
            "tgt_ix": "111-ARR_v2_120",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_118",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_119",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_120",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_117",
            "tgt_ix": "111-ARR_v2_118",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_121",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_120",
            "tgt_ix": "111-ARR_v2_121",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_122",
            "tgt_ix": "111-ARR_v2_123",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_122",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_123",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_121",
            "tgt_ix": "111-ARR_v2_122",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_124",
            "tgt_ix": "111-ARR_v2_125",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_124",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_125",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_123",
            "tgt_ix": "111-ARR_v2_124",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_126",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_125",
            "tgt_ix": "111-ARR_v2_126",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_127",
            "tgt_ix": "111-ARR_v2_128",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_127",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_128",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_126",
            "tgt_ix": "111-ARR_v2_127",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_129",
            "tgt_ix": "111-ARR_v2_130",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_130",
            "tgt_ix": "111-ARR_v2_131",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_131",
            "tgt_ix": "111-ARR_v2_132",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_132",
            "tgt_ix": "111-ARR_v2_133",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_133",
            "tgt_ix": "111-ARR_v2_134",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_129",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_130",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_131",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_132",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_133",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_134",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_128",
            "tgt_ix": "111-ARR_v2_129",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_135",
            "tgt_ix": "111-ARR_v2_136",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_135",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_136",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_134",
            "tgt_ix": "111-ARR_v2_135",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_137",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_136",
            "tgt_ix": "111-ARR_v2_137",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_138",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_137",
            "tgt_ix": "111-ARR_v2_138",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_139",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_138",
            "tgt_ix": "111-ARR_v2_139",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_140",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_139",
            "tgt_ix": "111-ARR_v2_140",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_141",
            "tgt_ix": "111-ARR_v2_142",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_141",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_142",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_140",
            "tgt_ix": "111-ARR_v2_141",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v2_0",
            "tgt_ix": "111-ARR_v2_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_1",
            "tgt_ix": "111-ARR_v2_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_2",
            "tgt_ix": "111-ARR_v2_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_2",
            "tgt_ix": "111-ARR_v2_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_2",
            "tgt_ix": "111-ARR_v2_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_2",
            "tgt_ix": "111-ARR_v2_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_3",
            "tgt_ix": "111-ARR_v2_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_3",
            "tgt_ix": "111-ARR_v2_3@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_3",
            "tgt_ix": "111-ARR_v2_3@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_3",
            "tgt_ix": "111-ARR_v2_3@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_3",
            "tgt_ix": "111-ARR_v2_3@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_3",
            "tgt_ix": "111-ARR_v2_3@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_3",
            "tgt_ix": "111-ARR_v2_3@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_4",
            "tgt_ix": "111-ARR_v2_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_5",
            "tgt_ix": "111-ARR_v2_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_5",
            "tgt_ix": "111-ARR_v2_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_6",
            "tgt_ix": "111-ARR_v2_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_7",
            "tgt_ix": "111-ARR_v2_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_8",
            "tgt_ix": "111-ARR_v2_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_9",
            "tgt_ix": "111-ARR_v2_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_10",
            "tgt_ix": "111-ARR_v2_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_11",
            "tgt_ix": "111-ARR_v2_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_12",
            "tgt_ix": "111-ARR_v2_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_13",
            "tgt_ix": "111-ARR_v2_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_14",
            "tgt_ix": "111-ARR_v2_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_14",
            "tgt_ix": "111-ARR_v2_14@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_14",
            "tgt_ix": "111-ARR_v2_14@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_15",
            "tgt_ix": "111-ARR_v2_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_16",
            "tgt_ix": "111-ARR_v2_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_16",
            "tgt_ix": "111-ARR_v2_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_16",
            "tgt_ix": "111-ARR_v2_16@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_16",
            "tgt_ix": "111-ARR_v2_16@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_16",
            "tgt_ix": "111-ARR_v2_16@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_16",
            "tgt_ix": "111-ARR_v2_16@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_16",
            "tgt_ix": "111-ARR_v2_16@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_16",
            "tgt_ix": "111-ARR_v2_16@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_17",
            "tgt_ix": "111-ARR_v2_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_17",
            "tgt_ix": "111-ARR_v2_17@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_17",
            "tgt_ix": "111-ARR_v2_17@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_17",
            "tgt_ix": "111-ARR_v2_17@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_17",
            "tgt_ix": "111-ARR_v2_17@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_17",
            "tgt_ix": "111-ARR_v2_17@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_17",
            "tgt_ix": "111-ARR_v2_17@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_18",
            "tgt_ix": "111-ARR_v2_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_18",
            "tgt_ix": "111-ARR_v2_18@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_18",
            "tgt_ix": "111-ARR_v2_18@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_19",
            "tgt_ix": "111-ARR_v2_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_20",
            "tgt_ix": "111-ARR_v2_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_20",
            "tgt_ix": "111-ARR_v2_20@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_20",
            "tgt_ix": "111-ARR_v2_20@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_20",
            "tgt_ix": "111-ARR_v2_20@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_20",
            "tgt_ix": "111-ARR_v2_20@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_20",
            "tgt_ix": "111-ARR_v2_20@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_20",
            "tgt_ix": "111-ARR_v2_20@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_20",
            "tgt_ix": "111-ARR_v2_20@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_20",
            "tgt_ix": "111-ARR_v2_20@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_20",
            "tgt_ix": "111-ARR_v2_20@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_20",
            "tgt_ix": "111-ARR_v2_20@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_20",
            "tgt_ix": "111-ARR_v2_20@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_21",
            "tgt_ix": "111-ARR_v2_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_22",
            "tgt_ix": "111-ARR_v2_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_22",
            "tgt_ix": "111-ARR_v2_22@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_22",
            "tgt_ix": "111-ARR_v2_22@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_22",
            "tgt_ix": "111-ARR_v2_22@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_23",
            "tgt_ix": "111-ARR_v2_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_24",
            "tgt_ix": "111-ARR_v2_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_24",
            "tgt_ix": "111-ARR_v2_24@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_24",
            "tgt_ix": "111-ARR_v2_24@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_24",
            "tgt_ix": "111-ARR_v2_24@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_25",
            "tgt_ix": "111-ARR_v2_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_26",
            "tgt_ix": "111-ARR_v2_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_26",
            "tgt_ix": "111-ARR_v2_26@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_26",
            "tgt_ix": "111-ARR_v2_26@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_27",
            "tgt_ix": "111-ARR_v2_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_27",
            "tgt_ix": "111-ARR_v2_27@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_27",
            "tgt_ix": "111-ARR_v2_27@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_28",
            "tgt_ix": "111-ARR_v2_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_29",
            "tgt_ix": "111-ARR_v2_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_29",
            "tgt_ix": "111-ARR_v2_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_30",
            "tgt_ix": "111-ARR_v2_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_31",
            "tgt_ix": "111-ARR_v2_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_31",
            "tgt_ix": "111-ARR_v2_31@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_31",
            "tgt_ix": "111-ARR_v2_31@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_31",
            "tgt_ix": "111-ARR_v2_31@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_31",
            "tgt_ix": "111-ARR_v2_31@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_31",
            "tgt_ix": "111-ARR_v2_31@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_31",
            "tgt_ix": "111-ARR_v2_31@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_31",
            "tgt_ix": "111-ARR_v2_31@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_31",
            "tgt_ix": "111-ARR_v2_31@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_31",
            "tgt_ix": "111-ARR_v2_31@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_31",
            "tgt_ix": "111-ARR_v2_31@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_31",
            "tgt_ix": "111-ARR_v2_31@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_31",
            "tgt_ix": "111-ARR_v2_31@12",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_31",
            "tgt_ix": "111-ARR_v2_31@13",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_31",
            "tgt_ix": "111-ARR_v2_31@14",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_31",
            "tgt_ix": "111-ARR_v2_31@15",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_32",
            "tgt_ix": "111-ARR_v2_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_33",
            "tgt_ix": "111-ARR_v2_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_34",
            "tgt_ix": "111-ARR_v2_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_34",
            "tgt_ix": "111-ARR_v2_34@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_34",
            "tgt_ix": "111-ARR_v2_34@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_34",
            "tgt_ix": "111-ARR_v2_34@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_35",
            "tgt_ix": "111-ARR_v2_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_36",
            "tgt_ix": "111-ARR_v2_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_37",
            "tgt_ix": "111-ARR_v2_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_38",
            "tgt_ix": "111-ARR_v2_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_38",
            "tgt_ix": "111-ARR_v2_38@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_39",
            "tgt_ix": "111-ARR_v2_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_40",
            "tgt_ix": "111-ARR_v2_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_41",
            "tgt_ix": "111-ARR_v2_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_41",
            "tgt_ix": "111-ARR_v2_41@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_41",
            "tgt_ix": "111-ARR_v2_41@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_41",
            "tgt_ix": "111-ARR_v2_41@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_42",
            "tgt_ix": "111-ARR_v2_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_42",
            "tgt_ix": "111-ARR_v2_42@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_42",
            "tgt_ix": "111-ARR_v2_42@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_43",
            "tgt_ix": "111-ARR_v2_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_43",
            "tgt_ix": "111-ARR_v2_43@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_43",
            "tgt_ix": "111-ARR_v2_43@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_43",
            "tgt_ix": "111-ARR_v2_43@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_43",
            "tgt_ix": "111-ARR_v2_43@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_44",
            "tgt_ix": "111-ARR_v2_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_44",
            "tgt_ix": "111-ARR_v2_44@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_45",
            "tgt_ix": "111-ARR_v2_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_46",
            "tgt_ix": "111-ARR_v2_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_46",
            "tgt_ix": "111-ARR_v2_46@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_46",
            "tgt_ix": "111-ARR_v2_46@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_46",
            "tgt_ix": "111-ARR_v2_46@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_47",
            "tgt_ix": "111-ARR_v2_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_48",
            "tgt_ix": "111-ARR_v2_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_49",
            "tgt_ix": "111-ARR_v2_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_50",
            "tgt_ix": "111-ARR_v2_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_50",
            "tgt_ix": "111-ARR_v2_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_51",
            "tgt_ix": "111-ARR_v2_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_52",
            "tgt_ix": "111-ARR_v2_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_52",
            "tgt_ix": "111-ARR_v2_52@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_52",
            "tgt_ix": "111-ARR_v2_52@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_52",
            "tgt_ix": "111-ARR_v2_52@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_53",
            "tgt_ix": "111-ARR_v2_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_54",
            "tgt_ix": "111-ARR_v2_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_54",
            "tgt_ix": "111-ARR_v2_54@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_54",
            "tgt_ix": "111-ARR_v2_54@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_54",
            "tgt_ix": "111-ARR_v2_54@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_55",
            "tgt_ix": "111-ARR_v2_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_56",
            "tgt_ix": "111-ARR_v2_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_56",
            "tgt_ix": "111-ARR_v2_56@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_56",
            "tgt_ix": "111-ARR_v2_56@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_57",
            "tgt_ix": "111-ARR_v2_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_58",
            "tgt_ix": "111-ARR_v2_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_59",
            "tgt_ix": "111-ARR_v2_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_59",
            "tgt_ix": "111-ARR_v2_59@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_59",
            "tgt_ix": "111-ARR_v2_59@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_59",
            "tgt_ix": "111-ARR_v2_59@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_60",
            "tgt_ix": "111-ARR_v2_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_60",
            "tgt_ix": "111-ARR_v2_60@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_60",
            "tgt_ix": "111-ARR_v2_60@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_61",
            "tgt_ix": "111-ARR_v2_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_62",
            "tgt_ix": "111-ARR_v2_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_62",
            "tgt_ix": "111-ARR_v2_62@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_62",
            "tgt_ix": "111-ARR_v2_62@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_62",
            "tgt_ix": "111-ARR_v2_62@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_62",
            "tgt_ix": "111-ARR_v2_62@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_62",
            "tgt_ix": "111-ARR_v2_62@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_62",
            "tgt_ix": "111-ARR_v2_62@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_63",
            "tgt_ix": "111-ARR_v2_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_64",
            "tgt_ix": "111-ARR_v2_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_64",
            "tgt_ix": "111-ARR_v2_64@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_64",
            "tgt_ix": "111-ARR_v2_64@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_64",
            "tgt_ix": "111-ARR_v2_64@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_64",
            "tgt_ix": "111-ARR_v2_64@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_65",
            "tgt_ix": "111-ARR_v2_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_65",
            "tgt_ix": "111-ARR_v2_65@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_65",
            "tgt_ix": "111-ARR_v2_65@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_66",
            "tgt_ix": "111-ARR_v2_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_67",
            "tgt_ix": "111-ARR_v2_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_67",
            "tgt_ix": "111-ARR_v2_67@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_68",
            "tgt_ix": "111-ARR_v2_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_69",
            "tgt_ix": "111-ARR_v2_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_69",
            "tgt_ix": "111-ARR_v2_69@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_70",
            "tgt_ix": "111-ARR_v2_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_70",
            "tgt_ix": "111-ARR_v2_70@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_71",
            "tgt_ix": "111-ARR_v2_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_72",
            "tgt_ix": "111-ARR_v2_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_72",
            "tgt_ix": "111-ARR_v2_72@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_72",
            "tgt_ix": "111-ARR_v2_72@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_72",
            "tgt_ix": "111-ARR_v2_72@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_72",
            "tgt_ix": "111-ARR_v2_72@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_72",
            "tgt_ix": "111-ARR_v2_72@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_72",
            "tgt_ix": "111-ARR_v2_72@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_73",
            "tgt_ix": "111-ARR_v2_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_74",
            "tgt_ix": "111-ARR_v2_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_75",
            "tgt_ix": "111-ARR_v2_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_76",
            "tgt_ix": "111-ARR_v2_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_76",
            "tgt_ix": "111-ARR_v2_76@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_76",
            "tgt_ix": "111-ARR_v2_76@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_76",
            "tgt_ix": "111-ARR_v2_76@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_76",
            "tgt_ix": "111-ARR_v2_76@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_77",
            "tgt_ix": "111-ARR_v2_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_77",
            "tgt_ix": "111-ARR_v2_77@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_78",
            "tgt_ix": "111-ARR_v2_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_79",
            "tgt_ix": "111-ARR_v2_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_80",
            "tgt_ix": "111-ARR_v2_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_81",
            "tgt_ix": "111-ARR_v2_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_82",
            "tgt_ix": "111-ARR_v2_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_83",
            "tgt_ix": "111-ARR_v2_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_83",
            "tgt_ix": "111-ARR_v2_83@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_83",
            "tgt_ix": "111-ARR_v2_83@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_83",
            "tgt_ix": "111-ARR_v2_83@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_83",
            "tgt_ix": "111-ARR_v2_83@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_83",
            "tgt_ix": "111-ARR_v2_83@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_83",
            "tgt_ix": "111-ARR_v2_83@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_84",
            "tgt_ix": "111-ARR_v2_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_85",
            "tgt_ix": "111-ARR_v2_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_85",
            "tgt_ix": "111-ARR_v2_85@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_85",
            "tgt_ix": "111-ARR_v2_85@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_85",
            "tgt_ix": "111-ARR_v2_85@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_85",
            "tgt_ix": "111-ARR_v2_85@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_86",
            "tgt_ix": "111-ARR_v2_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_86",
            "tgt_ix": "111-ARR_v2_86@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_86",
            "tgt_ix": "111-ARR_v2_86@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_86",
            "tgt_ix": "111-ARR_v2_86@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_87",
            "tgt_ix": "111-ARR_v2_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_87",
            "tgt_ix": "111-ARR_v2_87@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_87",
            "tgt_ix": "111-ARR_v2_87@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_88",
            "tgt_ix": "111-ARR_v2_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_88",
            "tgt_ix": "111-ARR_v2_88@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_88",
            "tgt_ix": "111-ARR_v2_88@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_89",
            "tgt_ix": "111-ARR_v2_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_90",
            "tgt_ix": "111-ARR_v2_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_90",
            "tgt_ix": "111-ARR_v2_90@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_90",
            "tgt_ix": "111-ARR_v2_90@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_91",
            "tgt_ix": "111-ARR_v2_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_91",
            "tgt_ix": "111-ARR_v2_91@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_91",
            "tgt_ix": "111-ARR_v2_91@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_92",
            "tgt_ix": "111-ARR_v2_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_92",
            "tgt_ix": "111-ARR_v2_92@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_92",
            "tgt_ix": "111-ARR_v2_92@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_92",
            "tgt_ix": "111-ARR_v2_92@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_92",
            "tgt_ix": "111-ARR_v2_92@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_92",
            "tgt_ix": "111-ARR_v2_92@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_93",
            "tgt_ix": "111-ARR_v2_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_93",
            "tgt_ix": "111-ARR_v2_93@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_94",
            "tgt_ix": "111-ARR_v2_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_94",
            "tgt_ix": "111-ARR_v2_94@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_95",
            "tgt_ix": "111-ARR_v2_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_95",
            "tgt_ix": "111-ARR_v2_95@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_95",
            "tgt_ix": "111-ARR_v2_95@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_96",
            "tgt_ix": "111-ARR_v2_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_97",
            "tgt_ix": "111-ARR_v2_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_98",
            "tgt_ix": "111-ARR_v2_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_98",
            "tgt_ix": "111-ARR_v2_98@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_99",
            "tgt_ix": "111-ARR_v2_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_100",
            "tgt_ix": "111-ARR_v2_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_100",
            "tgt_ix": "111-ARR_v2_100@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_100",
            "tgt_ix": "111-ARR_v2_100@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_100",
            "tgt_ix": "111-ARR_v2_100@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_100",
            "tgt_ix": "111-ARR_v2_100@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_100",
            "tgt_ix": "111-ARR_v2_100@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_100",
            "tgt_ix": "111-ARR_v2_100@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_100",
            "tgt_ix": "111-ARR_v2_100@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_101",
            "tgt_ix": "111-ARR_v2_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_101",
            "tgt_ix": "111-ARR_v2_101@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_102",
            "tgt_ix": "111-ARR_v2_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_103",
            "tgt_ix": "111-ARR_v2_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_103",
            "tgt_ix": "111-ARR_v2_103@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_103",
            "tgt_ix": "111-ARR_v2_103@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_103",
            "tgt_ix": "111-ARR_v2_103@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_104",
            "tgt_ix": "111-ARR_v2_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_104",
            "tgt_ix": "111-ARR_v2_104@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_104",
            "tgt_ix": "111-ARR_v2_104@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_104",
            "tgt_ix": "111-ARR_v2_104@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_104",
            "tgt_ix": "111-ARR_v2_104@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_104",
            "tgt_ix": "111-ARR_v2_104@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_105",
            "tgt_ix": "111-ARR_v2_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_105",
            "tgt_ix": "111-ARR_v2_105@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_105",
            "tgt_ix": "111-ARR_v2_105@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_105",
            "tgt_ix": "111-ARR_v2_105@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_105",
            "tgt_ix": "111-ARR_v2_105@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_105",
            "tgt_ix": "111-ARR_v2_105@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_105",
            "tgt_ix": "111-ARR_v2_105@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_106",
            "tgt_ix": "111-ARR_v2_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_107",
            "tgt_ix": "111-ARR_v2_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_108",
            "tgt_ix": "111-ARR_v2_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_109",
            "tgt_ix": "111-ARR_v2_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_110",
            "tgt_ix": "111-ARR_v2_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_111",
            "tgt_ix": "111-ARR_v2_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_112",
            "tgt_ix": "111-ARR_v2_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_113",
            "tgt_ix": "111-ARR_v2_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_114",
            "tgt_ix": "111-ARR_v2_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_114",
            "tgt_ix": "111-ARR_v2_114@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_115",
            "tgt_ix": "111-ARR_v2_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_116",
            "tgt_ix": "111-ARR_v2_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_116",
            "tgt_ix": "111-ARR_v2_116@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_116",
            "tgt_ix": "111-ARR_v2_116@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_116",
            "tgt_ix": "111-ARR_v2_116@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_117",
            "tgt_ix": "111-ARR_v2_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_117",
            "tgt_ix": "111-ARR_v2_117@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_118",
            "tgt_ix": "111-ARR_v2_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_119",
            "tgt_ix": "111-ARR_v2_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_120",
            "tgt_ix": "111-ARR_v2_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_120",
            "tgt_ix": "111-ARR_v2_120@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_120",
            "tgt_ix": "111-ARR_v2_120@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_121",
            "tgt_ix": "111-ARR_v2_121@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_121",
            "tgt_ix": "111-ARR_v2_121@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_121",
            "tgt_ix": "111-ARR_v2_121@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_122",
            "tgt_ix": "111-ARR_v2_122@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_122",
            "tgt_ix": "111-ARR_v2_122@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_122",
            "tgt_ix": "111-ARR_v2_122@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_122",
            "tgt_ix": "111-ARR_v2_122@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_122",
            "tgt_ix": "111-ARR_v2_122@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_122",
            "tgt_ix": "111-ARR_v2_122@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_122",
            "tgt_ix": "111-ARR_v2_122@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_122",
            "tgt_ix": "111-ARR_v2_122@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_122",
            "tgt_ix": "111-ARR_v2_122@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_122",
            "tgt_ix": "111-ARR_v2_122@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_123",
            "tgt_ix": "111-ARR_v2_123@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_123",
            "tgt_ix": "111-ARR_v2_123@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_123",
            "tgt_ix": "111-ARR_v2_123@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_124",
            "tgt_ix": "111-ARR_v2_124@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_125",
            "tgt_ix": "111-ARR_v2_125@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_125",
            "tgt_ix": "111-ARR_v2_125@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_125",
            "tgt_ix": "111-ARR_v2_125@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_125",
            "tgt_ix": "111-ARR_v2_125@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_126",
            "tgt_ix": "111-ARR_v2_126@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_126",
            "tgt_ix": "111-ARR_v2_126@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_126",
            "tgt_ix": "111-ARR_v2_126@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_126",
            "tgt_ix": "111-ARR_v2_126@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_126",
            "tgt_ix": "111-ARR_v2_126@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_126",
            "tgt_ix": "111-ARR_v2_126@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_126",
            "tgt_ix": "111-ARR_v2_126@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_126",
            "tgt_ix": "111-ARR_v2_126@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_127",
            "tgt_ix": "111-ARR_v2_127@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_127",
            "tgt_ix": "111-ARR_v2_127@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_127",
            "tgt_ix": "111-ARR_v2_127@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_127",
            "tgt_ix": "111-ARR_v2_127@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_127",
            "tgt_ix": "111-ARR_v2_127@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_127",
            "tgt_ix": "111-ARR_v2_127@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_127",
            "tgt_ix": "111-ARR_v2_127@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_127",
            "tgt_ix": "111-ARR_v2_127@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_127",
            "tgt_ix": "111-ARR_v2_127@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_128",
            "tgt_ix": "111-ARR_v2_128@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_129",
            "tgt_ix": "111-ARR_v2_129@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_129",
            "tgt_ix": "111-ARR_v2_129@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_130",
            "tgt_ix": "111-ARR_v2_130@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_130",
            "tgt_ix": "111-ARR_v2_130@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_131",
            "tgt_ix": "111-ARR_v2_131@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_131",
            "tgt_ix": "111-ARR_v2_131@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_132",
            "tgt_ix": "111-ARR_v2_132@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_132",
            "tgt_ix": "111-ARR_v2_132@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_132",
            "tgt_ix": "111-ARR_v2_132@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_132",
            "tgt_ix": "111-ARR_v2_132@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_132",
            "tgt_ix": "111-ARR_v2_132@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_133",
            "tgt_ix": "111-ARR_v2_133@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_133",
            "tgt_ix": "111-ARR_v2_133@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_133",
            "tgt_ix": "111-ARR_v2_133@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_133",
            "tgt_ix": "111-ARR_v2_133@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_133",
            "tgt_ix": "111-ARR_v2_133@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_133",
            "tgt_ix": "111-ARR_v2_133@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_134",
            "tgt_ix": "111-ARR_v2_134@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_134",
            "tgt_ix": "111-ARR_v2_134@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_135",
            "tgt_ix": "111-ARR_v2_135@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_136",
            "tgt_ix": "111-ARR_v2_136@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_136",
            "tgt_ix": "111-ARR_v2_136@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_136",
            "tgt_ix": "111-ARR_v2_136@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_136",
            "tgt_ix": "111-ARR_v2_136@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_136",
            "tgt_ix": "111-ARR_v2_136@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_137",
            "tgt_ix": "111-ARR_v2_137@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_137",
            "tgt_ix": "111-ARR_v2_137@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_137",
            "tgt_ix": "111-ARR_v2_137@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_137",
            "tgt_ix": "111-ARR_v2_137@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_137",
            "tgt_ix": "111-ARR_v2_137@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_137",
            "tgt_ix": "111-ARR_v2_137@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_137",
            "tgt_ix": "111-ARR_v2_137@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_137",
            "tgt_ix": "111-ARR_v2_137@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_138",
            "tgt_ix": "111-ARR_v2_138@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_138",
            "tgt_ix": "111-ARR_v2_138@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_138",
            "tgt_ix": "111-ARR_v2_138@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_139",
            "tgt_ix": "111-ARR_v2_139@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_140",
            "tgt_ix": "111-ARR_v2_140@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_140",
            "tgt_ix": "111-ARR_v2_140@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_141",
            "tgt_ix": "111-ARR_v2_141@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_141",
            "tgt_ix": "111-ARR_v2_141@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_141",
            "tgt_ix": "111-ARR_v2_141@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_141",
            "tgt_ix": "111-ARR_v2_141@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_141",
            "tgt_ix": "111-ARR_v2_141@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_141",
            "tgt_ix": "111-ARR_v2_141@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_141",
            "tgt_ix": "111-ARR_v2_141@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_141",
            "tgt_ix": "111-ARR_v2_141@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_141",
            "tgt_ix": "111-ARR_v2_141@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_141",
            "tgt_ix": "111-ARR_v2_141@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_141",
            "tgt_ix": "111-ARR_v2_141@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_141",
            "tgt_ix": "111-ARR_v2_141@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_142",
            "tgt_ix": "111-ARR_v2_142@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_142",
            "tgt_ix": "111-ARR_v2_142@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_142",
            "tgt_ix": "111-ARR_v2_142@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_143",
            "tgt_ix": "111-ARR_v2_143@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_144",
            "tgt_ix": "111-ARR_v2_144@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_145",
            "tgt_ix": "111-ARR_v2_145@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_146",
            "tgt_ix": "111-ARR_v2_146@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_147",
            "tgt_ix": "111-ARR_v2_147@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_148",
            "tgt_ix": "111-ARR_v2_148@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_149",
            "tgt_ix": "111-ARR_v2_149@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_150",
            "tgt_ix": "111-ARR_v2_150@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_151",
            "tgt_ix": "111-ARR_v2_151@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_152",
            "tgt_ix": "111-ARR_v2_152@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_153",
            "tgt_ix": "111-ARR_v2_153@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_154",
            "tgt_ix": "111-ARR_v2_154@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_155",
            "tgt_ix": "111-ARR_v2_155@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_156",
            "tgt_ix": "111-ARR_v2_156@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_157",
            "tgt_ix": "111-ARR_v2_157@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_158",
            "tgt_ix": "111-ARR_v2_158@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_159",
            "tgt_ix": "111-ARR_v2_159@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_160",
            "tgt_ix": "111-ARR_v2_160@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_161",
            "tgt_ix": "111-ARR_v2_161@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_162",
            "tgt_ix": "111-ARR_v2_162@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_163",
            "tgt_ix": "111-ARR_v2_163@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_164",
            "tgt_ix": "111-ARR_v2_164@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_165",
            "tgt_ix": "111-ARR_v2_165@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_166",
            "tgt_ix": "111-ARR_v2_166@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_167",
            "tgt_ix": "111-ARR_v2_167@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_168",
            "tgt_ix": "111-ARR_v2_168@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_169",
            "tgt_ix": "111-ARR_v2_169@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_170",
            "tgt_ix": "111-ARR_v2_170@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_171",
            "tgt_ix": "111-ARR_v2_171@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_172",
            "tgt_ix": "111-ARR_v2_172@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v2_173",
            "tgt_ix": "111-ARR_v2_173@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 1344,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "doc_id": "111-ARR",
        "version": 2
    }
}