{
    "nodes": [
        {
            "ix": "111-ARR_v1_0",
            "content": "Few-shot Controllable Style Transfer for Low-Resource Multilinugal Settings",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_2",
            "content": "Style transfer is the task of rewriting an input sentence into a target style while approximately preserving its content. While most prior literature assumes access to large stylelabelled corpora, recent work (Riley et al., 2021) has attempted \"few-shot\" style transfer using only 3-10 sentences at inference for extracting the target style. In this work we study a relevant low-resource setting: style transfer for languages where no style-labelled corpora are available. We find that existing fewshot methods perform this task poorly, with a strong tendency to copy inputs verbatim.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_3",
            "content": "We push the state-of-the-art for few-shot style transfer with a new method modeling the stylistic difference between paraphrases. When compared to prior work using automatic and human evaluations, our model achieves 2-3x better performance and output diversity in formality transfer and code-mixing addition across seven languages. Moreover, our method is better able to control the amount of style transfer using an input scalar knob. We report promising qualitative results for several attribute transfer directions, including sentiment transfer, text simplification, gender neutralization and text anonymization, all without retraining the model. Finally we found model evaluation to be difficult due to the lack of evaluation datasets and metrics for many languages. To facilitate further research in formality transfer for Indic languages, we crowdsource annotations for 4000 sentence pairs in four languages, and use this dataset 1 to design our automatic evaluation suite.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_4",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "111-ARR_v1_5",
            "content": "Style transfer is a natural language generation task in which input sentences need to be re-written into a target style, while preserving semantics. It has many applications such as writing assistance (Heidorn, 2000), controlling generation for attributes 1 Dataset will be open-sourced on paper acceptance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_6",
            "content": "Extractor -Target (Formal)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_7",
            "content": "It is certainly amongst my favorites.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_8",
            "content": "Source (Informal)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_9",
            "content": "Style Vector Extractor Figure 1: An illustration of our few-shot style transfer system during inference. Our model extracts style vectors from exemplar English sentences as input (in this case formal/informal sentences) and uses their vector difference to guide style transfer in other languages (Hindi). \u03bb is used to control the magnitude of transfer: in this example our model produces more high Sanskrit words & honorifics (more formal) with higher \u03bb.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_10",
            "content": "like simplicity, formality or persuasion (Xu et al., 2015;Smith et al., 2020;Niu and Carpuat, 2020), data augmentation (Xie et al., 2019;Lee et al., 2021), and author obfuscation (Shetty et al., 2018). Most prior work either assumes access to supervised data with parallel sentences between the two styles (Jhamtani et al., 2017), or access to large corpus of unpaired sentences with style labels (Prabhumoye et al., 2018;Subramanian et al., 2019). Models built are style-specific and cannot generalize to new styles during inference, which is needed for applications like real-time adaptation to a user's style in a dialog or writing application. Moreover, access to a large unpaired corpus with style labels is a strong assumption. Most standard \"unpaired\" style transfer datasets have been carefully curated (Shen et al., 2017) or were originally parallel (Xu et al., 2012;Rao and Tetreault, 2018). This is especially relevant in settings outside English, where NLP tools and labelled datasets are largely underdeveloped (Joshi et al., 2020). In this work, we take the first steps studying style transfer in seven languages 2 with nearly 1.5 billion speakers. Since no training data exists for these languages, we analyzed the current state-of-the-art in few-shot multilingual style transfer, the Universal Rewriter (UR) from Garcia et al. (2021). Unfortunately, we found it often copied input sentences verbatim (Section 3.1) without transferring their style.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_11",
            "content": "We propose a simple inference-time trick of style-controlled translation through English, which improves the UR output diversity (Section 4.1). To further boost performance we propose DIFFUR, 3 an algorithm using the recent finding that paraphrasing leads to stylistic changes (Krishna et al., 2020). DIFFUR extracts edit vectors from paraphrase pairs, which are used to condition and train the model (Figure 2). On formality transfer and code-mixing addition, our best performing DIFFUR variant significantly outperforms UR across all languages (by 2-3x) using automatic & human evaluation. Besides better rewriting, our system is better able to control the style transfer magnitude (Figure 1). A scalar knob (\u03bb) can be adjusted to make the output text reflect the target style (provided by exemplars) more or less. We also observe promising qualitative results in several attribute transfer directions (Section 6) including sentiment transfer, simplification, gender neutralization and text anonymization, all without retraining the model and using just 3-10 examples at inference.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_12",
            "content": "Finally, we found it hard to precisely evaluate models due to the lack of evaluation datasets and style classifiers (often used as metrics) for many languages. To facilitate further research in Indic formality transfer, we crowdsource formality annotations for 4000 sentence pairs in four Indic languages (Section 5.1), and use this dataset to design the automatic evaluation suite (Section 5). In summary, our contributions provide an end-toend recipe for developing and evaluating style transfer models and evaluation in a low-resource setting.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_13",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "111-ARR_v1_14",
            "content": "Few-shot methods are a recent development in English style transfer, with prior work using variational autoencoders (Xu et al., 2020), or prompting large pretrained language models at inference (Reif et al., 2021). Most related is the state-of-the-art TextSETTR model from Riley et al. (2021), who use a neural style encoder to map exemplar sentences to a vector used to guide generation. To train this encoder, they use the idea that adjacent sentences in a document have a similar style. Recently, the Universal Rewriter (Garcia et al., 2021) extended TextSETTR to 101 languages, developing a joint model for translation, few-shot style transfer and stylized translation. This model is the only prior few-shot system we found outside English, and our main baseline. We discuss its shortcomings in Section 3.1, and propose fixes in Section 4. Multilingual style transfer is mostly unexplored in prior work: a 35 paper survey by Briakou et al. (2021b) found only one work in Chinese, Russian, Latvian, Estonian, French. They further introduced XFORMAL, the first formality transfer evaluation dataset in French, Brazilian Portugese and Italian. 4 To the best of our knowledge, we are the first to study style transfer for the languages we consider. More related work from Hindi linguistics and on style transfer control is provided in Appendix B.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_15",
            "content": "The Universal Rewriter (UR) model",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "111-ARR_v1_16",
            "content": "We will start by discussing the Universal Rewriter (UR) model from Garcia et al. (2021), upon which our proposed DIFFUR model is built. The UR model extracts a style vector s from an exemplar sentence e, which reflects the desired target style. This style vector is used to style transfer an input sentence x. Consider f enc , f dec to be encoder & decoder Transformers initialized with mT5 (Xue et al., 2021b), which are composed to form the model f ur .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_17",
            "content": "f style (e) = s = f enc ([CLS] \u2295 e)[0] f ur (x, s) = f dec (f enc (x) + s)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_18",
            "content": "where \u2295 is string concatenation, + vector addition. f ur is trained using the following objectives,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_19",
            "content": "Denoising: To learn a style extractor, the Universal Rewriter uses the idea that two non-overlapping spans of text in the same document are likely to have the same style. Concretely, let x 1 and x 2 be two non-overlapping spans in mC4. Style extracted from one span is used to denoise the other,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_20",
            "content": "x2 = f ur (noise(x 2 ), f style (x 1 )) L denoise = L CE (x 2 , x 2 )",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_21",
            "content": "where L CE is the standard next-word prediction cross entropy loss function and noise(\u2022) refers to 20-60% random token dropping and token replacement. This objective is used on the mC4 dataset (Xue et al., 2021b) with 101 languages. To build a general-purpose rewriter which can do translation as well as style transfer, the model is additionally trained on two objectives: (1) supervised machine translation using the OPUS-100 parallel dataset (Zhang et al., 2020), and (2) a self-supervised objective to learn effective stylecontrolled translation; more details in Appendix C.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_22",
            "content": "During inference (Figure 1), consider an input sentence x and a transformation from style A to B (say informal to formal). Let S A , S B to be exemplar sentences in each of the styles (typically 3-10 sentences). The output y is computed as,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_23",
            "content": "s A , s B = 1 N y\u2208S A , S B f style (y) y = f ur (x, \u03bb(s B \u2212 s A ))",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_24",
            "content": "where \u03bb acts as a control knob to determine the magnitude of style transfer, and the vector subtraction helps remove confounding style information. 5",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_25",
            "content": "Shortcomings of the Universal Rewriter",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "111-ARR_v1_26",
            "content": "We experimented with the UR model on Hindi formality transfer, and noticed poor performance. We noticed that UR has a strong tendency to copy sentences verbatim -45.5% outputs were copied exactly from the input (and hence not style transferred) for the best performing value of \u03bb. The copying increase for smaller \u03bb, making magnitude control harder. We identify the following issues: 1. Random token noise leads to unnatural inputs & transformations: The Universal Rewriter uses 20-60% uniformly random token dropping / replacement to noise inputs, which leads to ungrammatical inputs during training. We hypothesize models tend to learn grammatical error correction, which encourages verbatim copying during inference where fluent inputs are used and no error correction is needed. Moreover, token-level noise does not differentiate between content / function words, and cannot do syntactic changes like content reordering (Goyal and Durrett, 2020). Too much noise could distort semantics and encourage hallucination, whereas too little will encourage copying.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_27",
            "content": "2. Style vectors may not capture the precise style transformation: The Universal Rewriter extracts the style vector from a single sentence during training, which is a mismatch from the inference where a difference between vectors is taken. Without taking vector differences at inference, we observe semantic preservation and overall performance of the UR model is much lower. 6 3. mC4 is noisy: On reading training data samples, we noticed noisy samples with severe language identification errors in the Hindi subset of mC4. This has also been observed recently in Caswell et al. (2021), who audit 100 sentences in each language, and report 50% sentences in Marathi and 20% sentences in Hindi have the wrong language. 4. No translation data for several languages: We notice worse performance for languages which did not get parallel translation data (for the translation objective in Section 3). In Table 1 we see UR gets a score 7 of 30.4 for Hindi and Bengali, languages for which it got translation data. However, the scores are lower for Kannada, Telugu & Gujarati (25.5,22.8,23.7), for which no translation data was used. We hypothesize translation data encourages learning language-agnostic semantic representations needed for translation from the given language, which in-turn improves style transfer.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_28",
            "content": "Our Models",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "111-ARR_v1_29",
            "content": "Style-Controlled Backtranslation (+ BT)",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "111-ARR_v1_30",
            "content": "While the Universal Rewriter model has a strong tendency to exactly copy input sentences while rewriting sentences in the same language (Section 3.1), we found it is an effective style-controlled translation system. This motivates a simple inference-time trick to improve model outputs and reduce copying -translate sentences to English (en) in a style-agnostic manner with a zero style vector 0, and translate back into the source language (lx) with stylistic control.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_31",
            "content": "s A , s B = 1 N y\u2208S A , S B",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_32",
            "content": "f style (y) The DIFFUR approach (Section 4.2), with fixes to the shortcomings of the Universal Rewriter approach (Section 3.1) shown. Sentences are noised using paraphrasing, the style vector difference between the paraphrase & original sentence (\"edit vector\") is used to control denoising. See Figure 1 for the inference-time process.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_33",
            "content": "x en = f ur (en \u2295 x, 0) x = f ur (lx \u2295 x en , \u03bb(s B \u2212 s A ))",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_34",
            "content": "where x is the input sentence, S A , S B are exemplars of the styles we want to transfer between, en, lx are language codes prepended to indicate the output language (Appendix C). Prior work has shown that backtranslation is effective for paraphrasing (Wieting and Gimpel, 2018;Iyyer et al., 2018) and style transfer (Prabhumoye et al., 2018).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_35",
            "content": "Using Paraphrase Vector Differences for",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "111-ARR_v1_36",
            "content": "Style Transfer (DIFFUR)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_37",
            "content": "While style-controlled backtranslation is an effective strategy, it needs two translation steps. This is 2x slower than UR, and semantic errors increase with successive translations. To learn effective style transfer systems needing only a single generation step we develop DIFFUR, a new few-shot style transfer training objective (overview in Figure 2). DIFFUR tackles the issues discussed in Section 3.1 using paraphrases and style vector differences.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_38",
            "content": "Paraphrases as a \"noise\" function: Instead of using random token-level noise (issue #1 in Section 3.1), we paraphrase sentences to \"noise\" them during training. Paraphrasing modifies the lexical & syntactic properties of sentences, while preserving fluency and input semantics. Prior work (Krishna et al., 2020) has shown that paraphrasing leads to stylistic changes, and denoising can be considered a style re-insertion process.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_39",
            "content": "To create paraphrases, we backtranslate sentences from the UR model 8 with no style control (zero vectors used as style vectors). To increase diversity, we use random sampling in both translation steps, pooling generations obtained using temperature values [0.4, 0.6, 0.8, 1.0]. Finally, we discard paraphrase pairs from the training data where the semantic similarity score 9 is outside the range [0.7, 0.98]. This removes backtransation errors (score < 0.7), and exact copies (score > 0.98).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_40",
            "content": "Using style vector differences for control: To fix the training / inference mismatch for style extraction (issue #2 in Section 3.1), we propose using style vector differences between the output and input as the stylistic control. Concretely, let x be an input sentence and x para its paraphrase.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_41",
            "content": "s diff = f style (x) \u2212 f style (x para ) x = f ur (x para , stop-grad(s diff )) L = L CE (x, x)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_42",
            "content": "where stop-grad(\u2022) stops gradient flow through s diff , preventing the model from learning to copy x exactly. To ensure f style extracts meaningful style representations, we fine-tune a trained UR model. Vector differences have many advantages, 1. Subtracting style vectors between a sentence and its paraphrase removes confounding features (like semantics) present in the vectors.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_43",
            "content": "2. The vector difference focuses on the precise transformation that is needed to reconstruct the input from its paraphrase.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_44",
            "content": "DIFFUR is related to neural editor models (Guu et al., 2018;He et al., 2020), where language models are decomposed into a probabilistic space of edit vectors over prototype sentences. We justify the DIFFUR design with ablations in Appendix G.1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_45",
            "content": "Indic Models (UR-INDIC, DIFFUR-INDIC)",
            "ntype": "title",
            "meta": {
                "section": "4.3"
            }
        },
        {
            "ix": "111-ARR_v1_46",
            "content": "To address the issue of no translation data (issue #4 in Section 3.1), we train Indic variants of our models. We replace the OPUS translation data used for training the Universal Rewriter (Section 3) with Samanantar (Ramesh et al., 2021), which is the largest publicly available parallel translation corpus for 11 Indic languages. We call these variants UR-INDIC and DIFFUR-INDIC. This process significantly up-samples the parallel data seen between English / Indic languages, and gives us better performance (Table 1) and lower copy rates, especially for languages with no OPUS translation data.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_47",
            "content": "Multitask Learning (DIFFUR-MLT)",
            "ntype": "title",
            "meta": {
                "section": "4.4"
            }
        },
        {
            "ix": "111-ARR_v1_48",
            "content": "One issue with our DIFFUR-INDIC setup is usage of a stop-grad(\u2022), to avoid verbatim copying from the input. This prevents gradient flow into the style extractor f style , and as we see in Appendix H, a degradation of the style vector space. To prevent this from happening, we simply do multi-task learning between the original Universal Rewriter objective (Section 3) and our DIFFUR-INDIC objective, using an equal number of minibatches for each objective.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_49",
            "content": "Evaluation",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "111-ARR_v1_50",
            "content": "Automatic evaluation of style transfer is challenging (Pang, 2019;Mir et al., 2019;Tikhonov et al., 2019), and the lack of resources (such as evaluation datasets, style classifiers) make evaluation trickier for Indic languages. To tackle this issue, we first collect a small dataset of formality and semantic similarity annotations in four Indic languages (Section 5.1). We use this dataset to guide the design of an evaluation suite (Section 5.2-5.6). Since automatic metrics in generation are imperfect (Celikyilmaz et al., 2020), we complement our results with human evaluation (Section 5.7).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_51",
            "content": "Indic Formality Transfer Dataset",
            "ntype": "title",
            "meta": {
                "section": "5.1"
            }
        },
        {
            "ix": "111-ARR_v1_52",
            "content": "Since no public datasets exist for formality transfer in Indic languages, it is hard to measure the extent to which automatic metrics (such as style classifiers) are effective. To tackle this issue, we build a dataset of 1000 sentence pairs in each of four Indic languages (Hindi, Bengali, Kannada, Telugu) with formality and semantic similarity annotations. We first style transfer held-out Samanantar sentences using our UR-INDIC + BT model (Section 4.1, 4.3) to create sentence pairs with different formality. We then asked three crowdworkers to 1) label the more formal sentence in each pair; 2) rate semantic similarity on a 3-point scale.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_53",
            "content": "Our crowdsourcing is conducted on Task Mate, 10 where we hired native speakers from India with at least a high school education and 90% approval rating on the platform. To ensure crowdworkers understood \"formality\", we provided instructions following advice from professional Indian linguists, and asked two qualification questions in their native language. More details (agreement, compensation, instructions) are provided in Appendix E.4.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_54",
            "content": "Transfer Accuracy (r-ACC, a-ACC)",
            "ntype": "title",
            "meta": {
                "section": "5.2"
            }
        },
        {
            "ix": "111-ARR_v1_55",
            "content": "Our first metric checks whether the output sentence reflects the target style. This is measured by an external classifier's predictions on system outputs. We use two variants of transfer accuracy: (1) Relative Accuracy (r-ACC): does the target style classifier score the output sentence higher than the input sentence? (2) Absolute Accuracy (a-ACC): does the classifier score the output higher than 0.5? Building multilingual classifiers: Unfortunately, no large style classification datasets exist for most languages, preventing us from building classifiers from scratch. We resort to zero-shot cross lingual transfer techniques (Conneau and Lample, 2019), where large multilingual pretrained models are first fine-tuned on English classification data, and then applied to other languages at inference. We experiment with three such techniques, and find MAD-X classifiers with language adapters (Pfeiffer et al., 2020b) have the highest accuracy of 81% on our Hindi data from Section 5.1. However, MAD-X classifiers were only available for Hindi, so we use the next best XLM RoBERTa-base (Conneau et al., 2020) for other languages, which has 75%-82% accuracy on annotated data; details in Appendix E.1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_56",
            "content": "Semantic Similarity (SIM)",
            "ntype": "title",
            "meta": {
                "section": "5.3"
            }
        },
        {
            "ix": "111-ARR_v1_57",
            "content": "Our second evaluation criteria is semantic similarity between the input and output. Following recent recommendations (Marie et al., 2021;Krishna et al., 2020), we avoid n-gram overlap metrics like BLEU (Papineni et al., 2002). Instead, we use LaBSE (Feng et al., 2020), a language-agnostic semantic similarity model based on multilingual BERT (Devlin et al., 2019). LaBSE supports 109 languages, and is the only similarity model we found supporting all the Indic languages in this work. We also observed LaBSE had greater correlation with our annotated data (Section 5.1) compared to alternatives; details in Appendix E.2.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_58",
            "content": "Qualitatively, we found that sentence pairs with LaBSE scores lower than 0.6 were almost never paraphrases. To avoid rewarding partial credit for low LaBSE scores, we use a hard threshold 11 (L = 0.75) to determine whether pairs are paraphrases, SIM(x, y ) = 1 if LaBSE(x, y ) > L else 0 5.4 Other Metrics (LANG, COPY, 1-g) Additionally, we measure whether the input and output sentences are in the same language (LANG), the fraction of outputs copied verbatim from the input (COPY), and the 1-gram overlap between input / output (1-g). High LANG and low COPY / 1-g (more diversity) is better; details in Appendix E.6.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_59",
            "content": "Aggregated Score (r-AGG, a-AGG)",
            "ntype": "title",
            "meta": {
                "section": "5.5"
            }
        },
        {
            "ix": "111-ARR_v1_60",
            "content": "To get a sense of overall system performance, we combine individual metrics into one score. Similar to Krishna et al. (2020) we aggregate metrics as, AGG(x, y ) = ACC(x, y )",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_61",
            "content": "\u2022 SIM(x, y ) \u2022 LANG(y ) AGG(D) = 1 |D| x,y \u2208D AGG(x, y )",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_62",
            "content": "Where (x, y ) are input-output pairs, and D is the test corpus. In other words, we measure the fraction of outputs which simultaneously transfer style, have a semantic similarity of at least L (our threshold in Section 5.3), and have the same language as the input. Depending on the variant of ACC (relative / absolute), we can derive r-AGG / a-AGG.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_63",
            "content": "Evaluating Control (CALIB)",
            "ntype": "title",
            "meta": {
                "section": "5.6"
            }
        },
        {
            "ix": "111-ARR_v1_64",
            "content": "An ideal system should not only be able to style transfer sentences, but also control the magnitude of style transfer using the scalar input \u03bb. To evaluate this, for every system we first determine a \u03bb max value and let [0, \u03bb max ] be the range of control values. While in our setup \u03bb is an unbounded scalar, we noticed high values of \u03bb significantly perturb semantics (also noted in Garcia et al., 2021), with systems outputting style-specific n-grams unfaithful to the output. We choose \u03bb max to be the largest \u03bb from the list [0.5, 1.0, 1.5, 2.0, 2.5, 3.0] whose outputs have an average semantic similarity score (SIM, Section 5.3) of at least 0.75 12 with the validation set inputs. For each system we take three evenly spaced \u03bb values in its control range, denoted as \u039b = [ 1 3 \u03bb max , 2 3 \u03bb max , \u03bb max ]. We then compute the style calibration to \u03bb (CALIB), or how often does increasing \u03bb lead to a style score increase? We measure this with a statistic similar to Kendall's \u03c4 (Kendall, 1938), counting concordant pairs in \u039b,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_65",
            "content": "CALIB(x) = 1 n \u03bb b >\u03bba {style(y \u03bb b ) > style(y \u03bba )}",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_66",
            "content": "where x is input, CALIB(x) is the average over all possible n (= 3) pairs of \u03bb values (\u03bb a , \u03bb b ) in \u039b.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_67",
            "content": "Human Evaluation",
            "ntype": "title",
            "meta": {
                "section": "5.7"
            }
        },
        {
            "ix": "111-ARR_v1_68",
            "content": "Automatic metrics are usually insufficient for style transfer evaluation -according to Briakou et al. (2021a), 69 / 97 surveyed style transfer papers used human evaluation. We adopt the crowd-sourcing setup from Section 5.1, which was used to build our formality evaluation datasets. We presented 200 generations from each model and the corresponding inputs in a random order, and asked three crowdworkers two questions about each pair of sentences: (1) which sentence is more formal/codemixed? (2) how similar are the two sentences in meaning? This lets us evaluate r-ACC, SIM, r-AGG, CALIB with respect to human annotations instead of classifier predictions; details in Appendix E.4.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_69",
            "content": "Main Experiments",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "111-ARR_v1_70",
            "content": "We evaluate models on (1) formality transfer;",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_71",
            "content": "(2) increasing the amount of code-mixing with English. Seven languages with varying scripts and morphological richness are used for evaluation (hi,es,sw,bn,kn,te,gu). Note that no paired/unpaired data with style labels is used during training: models determine the target style at inference using 3-10 exemplars sentences. For few-shot formality transfer, we use the English exemplars from Garcia et al. (2021). We follow their setup and use English exemplars to guide non-English transfer zero-shot. For code-mixing addition, we use Hindi/English code-mixed exemplars In Appendix G we show ablations studies justifying the DIFFUR design, decoding scheme, etc. We also analyze the style encoder f style in Appendix H, finding it is an effective style classifier.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_72",
            "content": "We analyze several qualitative outputs from DIFFUR-MLT in Figure 4. Besides formality transfer and code-mixing addition, we transfer several other attributes: sentiment (Li et al., 2018), simplicity (Xu et al., 2015), anonymity (Anandan et al., 2012) and gender neutrality (Reddy and Knight, 2016); more outputs in Appendix J.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_73",
            "content": "We present a recipe for building & evaluating controllable few-shot style transfer systems needing only 3-10 style examples at inference, useful in low-resource settings. Our methods outperform prior work in formality transfer & codemixing for 7 languages, with promising qualitative results. Future work includes further improving systems for some attributes, and considering languages where little / no translation data is available.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_74",
            "content": "Recent work has highlighted issues of stylistic bias in text generation systems, specifically machine translation systems (Hovy et al., 2020). We acknowledge these issues, and consider style transfer and style-controlled generation technology as an opportunity to work towards fixing them (for instance, gender neutralization as presented in Section 6). Note that it is important to tread down this path carefully -In Chapter 9, Blodgett (2021) argue that style is inseparable from social meaning (as originally noted by Eckert, 2008), and humans may perceive automatically generated text very differently compared to automatic style classifiers.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_75",
            "content": "Our models were trained on 32 Google Cloud TPUs. As discussed in Appendix A, the UR & UR-INDIC model take roughly 18 hours to train. The DIFFUR-* and DIFFUR-MLT models are much cheaper to train (2 hours) since we finetune the pretrained UR-* models. The Google 2020 environment report mentions, 13 \"TPUs are highly efficient chips which have been specifically designed for machine learning applications\". These accelerators run on Google Cloud, which is carbon neutral today, and is aiming to \"run on carbon-free energy, 24/7, at all of Google's data centers by 2030\" (https://cloud.google. com/sustainability). We compare the following models:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_76",
            "content": "\u2022 UR: the Universal Rewriter (Garcia et al., 2021), which is our main baseline (Section 3); \u2022 DIFFUR: our model with paraphrase vector differences (Section 4.2); \u2022 To train the UR-INDIC model, we use mC4 (Xue et al., 2021b) for the self-supervised objectives and Samanantar (Ramesh et al., 2021) for the supervised translation. For creating paraphrase data for training our DIFFUR models (Section 4.2), we again leverage Indic language side of Samanantar sentence pairs. Our models are implemented in JAX (Bradbury et al., 2018) using the T5X library. 14 We re-use the UR checkpoint from Garcia et al. (2021). To train the UR-INDIC model, we follow the setup in Garcia et al. ( 2021) and initialize the model with mT5-XL (Xue et al., 2021b), which has 3.7B parameters. We fine-tune the model for 25K steps with a batch size of 512 inputs and a learning rate of 1e-3, using the objectives in Section 3. Training was done on 32 Google Cloud TPUs which took a total of 17.5 hours. To train the DIFFUR and DIFFUR-INDIC models, we further finetune UR and UR-INDIC for a total of 4K steps using the objective from Section 4.2, taking 2 hours. Evaluation Datasets: Our models are evaluated on (1) formality transfer; (2) the task of adding code-mixing in text. Since we do not have access to any formality evaluation dataset, 15 we hold out 22K sentences from Samanantar in each Indic language for validation / testing. For Swahili / Spanish, we use mC4 / WMT2018 sentences. These sets",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_77",
            "content": "have similar number of formal / informal sentences, as marked by our formality classifiers (Section 5.2), and are transferred to the opposite formality. We re-use the hi/bn formality transfer splits for codemixing addition, where a system must increase the amount of code-mixing (with English) in a sentence, as shown in our exemplars in Appendix D. Seven languages with varying scripts and morphological richness are used for evaluation (hi,es,sw,bn,kn,te,gu). The UR model only saw translation data for hi,es,bn, whereas UR-INDIC sees translation data for all Indic languages (Section 4.3). To test the generalization capability of the DIFFUR, no Gujarati paraphrase training data for is used.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_78",
            "content": "Multilingual style transfer is mostly unexplored in prior work: a 35 paper survey by Briakou et al. (2021b) found only one work in Chinese, Russian, Latvian, Estonian, French (Shang et al., 2019;Tikhonov and Yamshchikov, 2018;Korotkova et al., 2019;Niu et al., 2018). Briakou et al. (2021b) further introduced XFORMAL, the first formality transfer evaluation dataset in French, Brazilian Portugese and Italian. 16 Hindi formality has been studied in linguistics, focusing on politeness (Kachru, 2006;Agnihotri, 2013;Kumar, 2014) and codemixing (Bali et al., 2014). Due to its prevalence in India, English-Hindi code-mixing has seen work in language modeling (Pratapa et al., 2018;Samanta et al., 2019) and core NLP tasks (Khanuja et al., 2020). To the best of our knowledge, we are the first to study style transfer for Indic languages. A few prior works build models which can control the degree of style transfer using a scalar input (Wang et al., 2019;Samanta et al., 2021). However, these models are style-specific and require large unpaired style corpora during training. We adopt the inference-time control method used by Garcia et al. ( 2021) and notice much better controllability after our proposed fixes in Section 4.2.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_79",
            "content": "In this section we describe the details of the supervised translation objective and the style-controlled translation objective used in the Universal Rewriter model. See Section 3 for details on the exemplarbased denoising objective.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_80",
            "content": "This objective is the standard supervised translation setup, using zero vectors for style. The output language code is prepended to the input. Consider a pair of parallel sentences (x, y) in languages with codes lx, ly (prepended to the input string), \u0233 = f ur (ly \u2295 x, 0)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_81",
            "content": "L translate = L CE (\u0233, y)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_82",
            "content": "The Universal Rewriter is trained on Englishcentric translation data from the high-resource languages in OPUS-100 (Zhang et al., 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_83",
            "content": "Learning style-controlled translation: This objective emulates \"style-controlled translation\" in a self-supervised manner, via backtranslation through English. Consider x 1 and x 2 to be two non-overlapping spans in mC4 in language lx, Complex exemplars 1. The static charges remain on an object until they either bleed off to ground or are quickly neutralized by a discharge. 2. It is particularly famous for the cultivation of kiwifruit. 3. Notably absent from the city are fortifications and military structures. Simple exemplars 1. Static charges last until they are grounded or discharged. 2. This area is known for growing kiwifruit. 3. Some things important missing from the city are protective buildings and military buildings.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_84",
            "content": "x en 2 = f ur (en \u2295 x 2 , \u2212f style (x 1 )) x2 = f ur (lx \u2295 x en 2 , f style (x 1 )) L BT = L CE (x 2 , x 2 )",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_85",
            "content": "Positive sentiment exemplars 1. The most comfortable bed I've ever slept on, I highly recommend it. 2. I loved it. 3. The movie was fantastic.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_86",
            "content": "Negative sentiment exemplars 1. The most uncomfortable bed I've ever slept on, I would never recommend it. 2. I hated it. 3. The movie was awful.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_87",
            "content": "Due to the absence of a style classification dataset in Indic languages, we built our multilingual classifier drawing inspiration from recent research in zero-shot cross-lingual transfer (Conneau et al., 2018;Conneau and Lample, 2019;Pfeiffer et al., 2020b). We experimented with three zero-shot transfer techniques while selecting our classifiers for evaluating multilingual style transfer.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_88",
            "content": "TRANSLATE TRAIN: The first technique uses the hypothesis that style is preserved across translation. We classify the style of English sentences in the Samanantar translation dataset (Ramesh et al., 2021) using a style classifier trained on English formality data from Krishna et al. (2020). We use the human translated Indic languages sentences as training data. This training data is used to fine-tune a large-scale multilingual language model. ZERO-SHOT: The second technique fine-tunes large-scale multilingual language models on a English style transfer dataset, and applies it zero-shot on multilingual data during inference.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_89",
            "content": "MAD-X: Introduced by Pfeiffer et al. (2020b), this technique is similar to ZERO-SHOT but additionally uses language-specific parameters (\"adapters\") during inference. These language-specific adapters have been originally trained using masked language modeling on the desired language data. Dataset for evaluating classifiers: We conduct our experiments on Hindi formality classification, leveraging our evaluation datasets from Section 5.1. We removed pairs which did not have full agreement across the three annotators and those pairs which had the consensus rating of \"Equal\" formality. This filtering process leaves us with 316 pairs in Hindi (out of 1000). In our experiments, we check whether the classifiers give a higher score to the more formal sentence in the pair.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_90",
            "content": "We leverage the multilingual classifiers open-sourced 17 by Krishna et al. ( 2020). These models have been trained on the English GYAFC formality classification dataset (Rao and Tetreault, 2018), and have been shown to be effective on the XFORMAL dataset (Briakou et al., 2021b) for formality classification in Italian, French and Brazilian Portuguese. 13 These classifiers were trained on preprocessed data which had trailing punctuation stripped and English sentences lower-cased, encouraging the models to focus on lexical and syntactic choices. As base multilingual language models, we use (1) mBERT-base from Devlin et al. ( 2019); (2) XLM-RoBERTabase from Conneau et al. (2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_91",
            "content": "Results: Our results on Hindi are presented in Table 6 and other languages in Table 7. Consistent with Pfeiffer et al. (2020b), we find MAD-X to be a superior zero-shot cross lingual transfer method compared to baselines. We also find XLM-R has better multilingual representations than mBERT. Unfortunately, AdapterHub (Pfeiffer et al., 2020a) has XLM-R language adapters available only for Hindi & Tamil (among Indic languages). For other languages we use the ZERO-SHOT technique on XLM-R, consistent with the recommendations 13 provided by Krishna et al. (2020) based on their experiments on XFORMAL (Briakou et al., 2021b).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_92",
            "content": "Model Accuracy (\u2191)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_93",
            "content": "We considered three models for evaluating semantic similarity between the input and output:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_94",
            "content": "(1) LaBSE (Feng et al., 2020);",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_95",
            "content": "(2) m-USE (Yang et al., 2020);",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_96",
            "content": "(3) multilingual Sentence-BERT (Reimers and Gurevych, 2020), the knowledge-distilled variant paraphrase-xlm-r-multilingual-v1",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_97",
            "content": "Among these models, only LaBSE has support for all the Indic languages we were interested in.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_98",
            "content": "No Indic language is supported by m-USE, and multilingual Sentence-BERT has been trained on parallel data only for Hindi, Gujarati and Marathi among our Indic languages. However, in terms of Semantic Textual Similarity (STS) benchmarks (Cer et al., 2017) for English, Arabic & Spanish, m-USE and Sentence-BERT outperform LaBSE (Table 1 in Reimers and Gurevych, 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_99",
            "content": "LaBSE correlates better than Sentence-BERT with our human-annotated formality dataset:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_100",
            "content": "We measured the Spearman's rank correlation between the semantic similarity annotations on our human-annotated formality datasets (Section 5.1). We discarded 10% sentence pairs which had no agreement among three annotators and took the majority vote for the other sentence pairs. We assigned \"Different Meaning\" a score of 0, \"Slight Difference in Meaning\" a score of 1 and \"Approximately Same Meaning\" a score of 2 before measuring Spearman's rank correlation. In",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_101",
            "content": "In Section 6, we set our LaBSE threshold L to 0.75.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_102",
            "content": "In this section, we present our evaluations with a more and less conservative value of L.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_103",
            "content": "In Table 17, we present results with L = 0.65, and in Table 18 we set L = 0.85. Compared to Table 1, trends are mostly similar, with DIFFUR models and INDIC variants outperforming counterparts. Note that the absolute values of SIM and AGG metrics differ, with absolute values going down with the stricter threshold of L = 0.85, and up with the relaxed threshold of L = 0.65.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_104",
            "content": "To verify these three thresholds are reasonable choices, we measure the LaBSE similarity of the sentence pairs annotated by humans, and compare the LaBSE scores to human semantic similarity annotations. We pool the \"Approximately Same Meaning\" and \"Slight Difference in Meaning\" categories as \"same\", and consider only sentence pairs with a majority rating of \"same\". In",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_105",
            "content": "In Figure 16, we show screenshots of our crowdsourcing interface along with all the instructions shown to crowdworkers. The instructions were written after consulting professional Indian linguists. Each crowdworker was allowed to annotate a maximum of 50 different sentence pairs per language, paying them $0.05 per pair. For formality classification, we showed crowdworkers two sentences and asked them to choose which one is more formal. Crowdworkers were allowed to mark ties using an \"Equal\" option. For semantic similarity annotation, we showed crowdworkers the sentence pair and provided three options -\"approximately same meaning\", \"slight difference in meaning\", \"different meaning\", to emulate a 3-point Likert scale. While performing our human evaluation (Section 5.7), we use a 0.5 SIM score for \"slight difference in meaning\" and a 1.0 SIM score for \"approximately same meaning\" annotations. For every system considered, we analyzed the same set of 200 input sentences for style transfer performance, and 100 of those sentences for evaluating controllability. We removed sentences which were exact copies of the input (after removing trailing punctuation) or were in the wrong language to save annotator time and cost. When outputs were exact copies of the input, we assigned SIM = 100, ACC = 0, AGG = 0.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_106",
            "content": "In Table 10 and Table 11 we show the interannotator agreement statistics. We measure Fleiss Kappa (Fleiss, 1971), Randolph Kappa (Randolph, 2005Warrens, 2010), the fraction of sentence pairs with total agreement between the three annotators and the fraction of sentence pairs with no agreement. 18 In the table we can see all agreement statis- 18 The \u03ba scores are measured using the library https: //github.com/statsmodels/statsmodels.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_107",
            "content": "Unlike some prior works, we avoid evaluation of output fluency due to the following reasons:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_108",
            "content": "(1) lack of fluency evaluation tools for Indic languages; 19 (2) fluency evaluation often discriminates against styles which are out-of-distribution for the fluency classifier, as discussed in Appendix A.8 of Krishna et al. ( 2020); (3) several prior works (Pang, 2019;Mir et al., 2019;Krishna et al., 2020) have recommended against using perplexity of style language models for fluency evaluation since it is unbounded and favours unnatural sentences with common words; (4) large language models are known to produce fluent text as perceived by humans (Ippolito et al., 2020;Akoury et al., 2020), reducing the need for this evaluation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_109",
            "content": "Language Consistency (LANG): Since our semantic similarity metric LaBSE is languageagnostic, it tends to ignore accidental translations, which are common errors in large multilingual transformers (Xue et al., 2021a,b), especially the Universal Rewriter (Section 3.1). Hence, we check whether the output sentence is in the same language as the input, using langdetect. 20",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_110",
            "content": "Output Diversity (COPY, 1-g): As discussed in Section 3.1, the Universal Rewriter has a strong tendency to copy the input verbatim. We build two metrics to measure output diversity compared to the input, which have been previously used for extractive question answering evaluation (Rajpurkar et al., 2016). The first metric COPY measures the fraction of outputs which were copied verbatim from the input. This is done after removing trailing punctuation, to penalize models generations which solely modify punctuation. A second metric 1-g measures the unigram overlap F1 score between the input and output. A diverse style transfer system should minimize both COPY and 1-g.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_111",
            "content": "We follow the setup in Section 5.6 to first compute a \u03bb max per system. We then compute the following, 1. Style Transfer Performance (r-AGG): An ideal system should have good overall performance (Section 5.5) across different values in the range \u039b.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_112",
            "content": "2. Average Style Score Increase (INCR): As our control value increases, we want the classifier's target style score (compared to the input) to increase. Additionally, we want the style score increase of \u03bb max to be as high as possible, indicating the system can span the range of classifier scores.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_113",
            "content": "Style Calibration to \u03bb (CALIB, C-IN):",
            "ntype": "title",
            "meta": {
                "section": "3."
            }
        },
        {
            "ix": "111-ARR_v1_114",
            "content": "As defined in Section 5.6. We additionally also measure calibration by including the input sentence x in the CALIB(x) calculation, treating it as the output for \u03bb = 0 (no style transfer). Here, calibration is averaged over a total of n = 6 (\u03bb 1 , \u03bb 2 ) pairs. We call this metric C-IN.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_115",
            "content": "A detailed breakdown of performance by different metrics for every model is shown in Table 14.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_116",
            "content": "This section describes the ablation experiments conducted for the DIFFUR modeling choices in Section 4.2. We ablate a DIFFUR-INDIC model trained on Hindi paraphrase data only, and present results for Hindi formality transfer in Table 15.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_117",
            "content": "no paraphrase: We replaced the paraphrase noise function with the random token dropping / replacing noise used in the denoising objective of UR model (Section 3), and continued to use vector differences. As seen in Table 15, this significantly increases the copy rate, which lowers the style transfer performance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_118",
            "content": "no paraphrase semantic filtering: We keep a setup identical to Section 4.2, but avoid the LaBSE filtering done (discarding pairs having a LaBSE score outside [0.7, 0.98]) to remove noisy paraphrases or exact copies. As seen in Table 15, this decreases the semantic similarity score of the generations, lowering the overall performance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_119",
            "content": "no vector differences: Instead of using vector differences for DIFFUR-INDIC, we simply set s diff = f style (x), or the style of the target sentence.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_120",
            "content": "In Table 15, we see this significantly decreases SIM scores, and LANG scores for \u03bb = 2.0. We hypothesize that this training encourages the model to rely more heavily on the style vectors, ignoring the paraphrase input. This could happen since the style vectors are solely constructed from the output sentence itself, and semantic information / confounding style is not subtracted out. In other words, the model is behaving more like an autoencoder (through the style vector) instead of a denoising autoencoder with stylistic supervision.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_121",
            "content": "-mC4 instead of Samanantar: Instead of creating pseudo-parallel data with Samanantar, we leverage the mC4 dataset itself which was used to train the UR model. We backtranslate spans of text from the Hindi split of mC4 on-the-fly using the UR translation capabilities, and use it as the \"paraphrase noise function\". To ensure translation performance does not deteriorate during training, 50% minibatches are supervised translation between Hindi and English. In Table 15, we see decent overall performance, but the LANG score is 6% lower than DIFFUR-INDIC. Qualitatively we found that the model often translates a few Hindi words to English while making text informal. Due to sparsity of English tokens, it often escapes penalization from LANG.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_122",
            "content": "-mC4 + exemplar instead of target: This setting is similar to the previous one, but in addition to the mC4 dataset we utilize the vector difference between the style vector of the exemplar span (instead of target span), and the \"paraphrase noised\" input.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_123",
            "content": "Results in Table 15 show this method is not effective, and it's important for the vector difference to model the precise transformation needed.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_124",
            "content": "We experiment with five decoding schemes on the Hindi formality validation set -beam search with beam size 1, 4 and top-p sampling (Holtzman et al., 2020) with p = 0.6, 0.75, 0.9.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_125",
            "content": "In Table 16, we present results at a constant style transfer magnitude (\u03bb = 3.0). Consistent with Krishna et al. (2020), we find that top-p decoding usually gets higher style accuracy (r-ACC, a-ACC) and output diversity (1-g, COPY) scores, but lower similarity (SIM) scores. Overall beam search triumphs since the loss in semantic similarity leads to a worse performing model. In Figure 9, we see a consistent trend across different magnitudes of style transfer (\u03bb). In all our main experiments, we use beam search with beam size 4 to obtain our generations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_126",
            "content": "In Figure 10, we present the variation in style transfer performance with number of training steps for our best model, the DIFFUR-MLT model. We find that with more training steps performance generally improves, but improvements saturate after 8k steps. We also see the peak of the graphs (best style transfer performance) shift rightwards, indicating a preference for higher \u03bb values.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_127",
            "content": "The Universal Rewriter models succeed in learning an effective style space, useful for few-shot style transfer. But can this metric space also act as a style classifier? To explore this, we measure the cosine distance between the mean style vector of our informal exemplars, 21 and the style vectors derived by passing human-annotated formal/informal pairs (from our dataset of Section 5.1) through f style . We only consider pairs which had complete agreement among annotators. In Table 12 we see good agreement (68.2%-80.7%) between human annotations and the classifier derived from the metric space of the UR-INDIC model. Agreement is lower (67.0%-74.3%) for the DIFFUR-INDIC model, likely due to the stop gradient used in Section 4.2. With DIFFUR-MLT, agreement jumps back up to 75%-81.7% since gradients flow into the style extractor as well.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_128",
            "content": "In Appendix H.1, we saw that the metric vector space derived from the style encoder f style of various models is an effective style classifier, using the informal exemplar vectors. In",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_129",
            "content": "A full breakdown of results by individual metrics, along with plots showing variation with change in 21 See Appendix D for the exemplar sentences. We found the informal exemplars more effective than formal exemplars for style classification; Appendix H.2 has a comparison. \u03bb, is provided for -Hindi (Table 19, Figure 11), Bengali (Table 20, Figure 12), Kannada (Table 21, Figure 13), Telugu (Table 22, Figure 14), Gujarati (Table 23, Figure 15).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_130",
            "content": "In the baseline Hindi UR model, we notice high COPY rates (45.4%), resulting in lower ACC scores. COPY reduces in our proposed models (4.4% for DIFFUR-MLT), which boosts overall performance. We find the lowest COPY (and lowest 1-g) for models with +BT (1%), which is due to two steps of translation. However, this lowers semantic similarity (also seen in Table 3) lowering the overall score compared to DIFFUR-MLT (60.0 vs 78.1 r-AGG).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_131",
            "content": "Please refer to Figure 8. In the main body, Figure 4 has a few examples as well with detailed analysis. and style accuracy (r-ACC, a-ACC) improves as we move down the table, but compromise semantic preservation (SIM), bringing the overall performance (r-AGG, a-AGG) down. Also see Figure 9 for a comparison across \u03bb values, and Section 5 for detailed metric descriptions. 19 for a individual metric breakdown of the models at the best performing \u03bb). The plots show overall style transfer performance, using the r-AGG (top-left) and a-AGG (top-right) metrics from Section 5.5. We see the DIFFUR models outperform other systems across the \u03bb range, and get best performance with the DIFFUR-MLT variant. We also see that DIFFUR models, especially with DIFFUR-MLT, lead to better style transfer control (bottom plot, closer to x = 1 is better), giving large style variation with \u03bb without loss in semantics (X-axis). 20 for a individual metric breakdown of the models at the best performing \u03bb). The plots show overall style transfer performance, using the r-AGG (top-left) and a-AGG (top-right) metrics from Section 5.5. We see the DIFFUR models outperform other systems across the \u03bb range, and get best performance with the DIFFUR-MLT variant. We also see that DIFFUR models, especially with DIFFUR-MLT, lead to better style transfer control (bottom plot, closer to x = 1 is better), giving large style variation with \u03bb without loss in semantics (X-axis). 21 for a individual metric breakdown of the models at the best performing \u03bb). The plots show overall style transfer performance, using the r-AGG (top-left) and a-AGG (top-right) metrics from Section 5.5. We see the DIFFUR models outperform other systems across the \u03bb range, and get best performance with the DIFFUR-MLT variant. We also see that DIFFUR models, especially with DIFFUR-MLT, lead to better style transfer control (bottom plot, closer to x = 1 is better), giving large style variation with \u03bb without loss in semantics (X-axis). 23 for a individual metric breakdown of the models at the best performing \u03bb). The plots show overall style transfer performance, using the r-AGG (top-left) and a-AGG (top-right) metrics from Section 5.5. Note that Gujarati is a zero-shot language for DIFFUR models -no Gujarati paraphrase data was seen during training. We see that while the vanilla DIFFUR model performs poorly, the DIFFUR-INDIC is competitive with baselines and the DIFFUR-MLT variant significantly outperforms other systems. We also see that the DIFFUR-MLT variant lead to better style transfer control (bottom plot, closer to x = 1 is better), giving style variation with \u03bb without loss in semantics (X-axis).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_132",
            "content": "Figure 16: Our crowdsourcing interface on Task Mate, used to build our formality evaluation datasets (Section 5.1) and conduct human evaluations (Section 5.7). The first row shows our landing page and instruction set derived from our conversations with professional linguists. The second row shows our qualification questions for formality classification, and the third row shows templates for the two questions asked to crowdworkers per pair.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "111-ARR_v1_133",
            "content": "UNKNOWN, None, 2013, Hindi: An essential grammar, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": null,
                "title": null,
                "pub_date": "2013",
                "pub_title": "Hindi: An essential grammar",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_134",
            "content": "Nader Akoury, Shufan Wang, Josh Whiting, Stephen Hood, Nanyun Peng, Mohit Iyyer, STO-RIUM: A Dataset and Evaluation Platform for Machine-in-the-Loop Story Generation, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Nader Akoury",
                    "Shufan Wang",
                    "Josh Whiting",
                    "Stephen Hood",
                    "Nanyun Peng",
                    "Mohit Iyyer"
                ],
                "title": "STO-RIUM: A Dataset and Evaluation Platform for Machine-in-the-Loop Story Generation",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "111-ARR_v1_135",
            "content": "UNKNOWN, None, 2012, Generalizing words to desensitize text. Transactions on Data Privacy, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": null,
                "title": null,
                "pub_date": "2012",
                "pub_title": "Generalizing words to desensitize text. Transactions on Data Privacy",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_136",
            "content": "Kalika Bali, Jatin Sharma, Monojit Choudhury, Yogarshi Vyas, i am borrowing ya mixing?\" an analysis of english-hindi code mixing in facebook, 2014, Proceedings of the First Workshop on Computational Approaches to Code Switching, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Kalika Bali",
                    "Jatin Sharma",
                    "Monojit Choudhury",
                    "Yogarshi Vyas"
                ],
                "title": "i am borrowing ya mixing?\" an analysis of english-hindi code mixing in facebook",
                "pub_date": "2014",
                "pub_title": "Proceedings of the First Workshop on Computational Approaches to Code Switching",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_137",
            "content": "Su Lin,  Blodgett, Sociolinguistically driven approaches for just natural language processing, 2021, UMass Amherst Doctoral Dissertations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    " Su Lin",
                    " Blodgett"
                ],
                "title": "Sociolinguistically driven approaches for just natural language processing",
                "pub_date": "2021",
                "pub_title": "UMass Amherst Doctoral Dissertations",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_138",
            "content": "UNKNOWN, None, 2018, , .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": null,
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_139",
            "content": "UNKNOWN, None, , Joel Tetreault, and Marine Carpuat. 2021a. A review of human evaluation for style transfer, .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Joel Tetreault, and Marine Carpuat. 2021a. A review of human evaluation for style transfer",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_140",
            "content": "Eleftheria Briakou, Di Lu, Ke Zhang, Joel Tetreault, Ol\u00e1, bonjour, salve! XFORMAL: A benchmark for multilingual formality style transfer, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Eleftheria Briakou",
                    "Di Lu",
                    "Ke Zhang",
                    "Joel Tetreault"
                ],
                "title": "Ol\u00e1, bonjour, salve! XFORMAL: A benchmark for multilingual formality style transfer",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "111-ARR_v1_141",
            "content": "UNKNOWN, None, 2021, Quality at a glance: An audit of web-crawled multilingual datasets, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Quality at a glance: An audit of web-crawled multilingual datasets",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_142",
            "content": "UNKNOWN, None, 2020, Evaluation of text generation: A survey, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Evaluation of text generation: A survey",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_143",
            "content": "Daniel Cer, Mona Diab, Eneko Agirre, I\u00f1igo Lopez-Gazpio, Lucia Specia, SemEval-2017 task 1: Semantic textual similarity multilingual and crosslingual focused evaluation, 2017, Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017), Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Daniel Cer",
                    "Mona Diab",
                    "Eneko Agirre",
                    "I\u00f1igo Lopez-Gazpio",
                    "Lucia Specia"
                ],
                "title": "SemEval-2017 task 1: Semantic textual similarity multilingual and crosslingual focused evaluation",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "111-ARR_v1_144",
            "content": "Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettlemoyer, Veselin Stoyanov, Unsupervised cross-lingual representation learning at scale, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Alexis Conneau",
                    "Kartikay Khandelwal",
                    "Naman Goyal",
                    "Vishrav Chaudhary",
                    "Guillaume Wenzek",
                    "Francisco Guzm\u00e1n",
                    "Edouard Grave",
                    "Myle Ott",
                    "Luke Zettlemoyer",
                    "Veselin Stoyanov"
                ],
                "title": "Unsupervised cross-lingual representation learning at scale",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_145",
            "content": "Alexis Conneau, Guillaume Lample, Crosslingual language model pretraining, 2019, Proceedings of Advances in Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Alexis Conneau",
                    "Guillaume Lample"
                ],
                "title": "Crosslingual language model pretraining",
                "pub_date": "2019",
                "pub_title": "Proceedings of Advances in Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_146",
            "content": "UNKNOWN, None, 2018, XNLI: Evaluating Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "XNLI: Evaluating Association for Computational Linguistics: Human Language Technologies",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "111-ARR_v1_147",
            "content": "Benjamin Marie, Atsushi Fujita, Raphael Rubino, Scientific credibility of machine translation research: A meta-evaluation of 769 papers, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Benjamin Marie",
                    "Atsushi Fujita",
                    "Raphael Rubino"
                ],
                "title": "Scientific credibility of machine translation research: A meta-evaluation of 769 papers",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "111-ARR_v1_148",
            "content": "Remi Mir, Bjarke Felbo, Nick Obradovich, Iyad Rahwan, Evaluating style transfer for text, 2019, Conference of the North American Chapter, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Remi Mir",
                    "Bjarke Felbo",
                    "Nick Obradovich",
                    "Iyad Rahwan"
                ],
                "title": "Evaluating style transfer for text",
                "pub_date": "2019",
                "pub_title": "Conference of the North American Chapter",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "111-ARR_v1_149",
            "content": "UNKNOWN, None, 2010, Language detection library for java, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": null,
                "title": null,
                "pub_date": "2010",
                "pub_title": "Language detection library for java",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_150",
            "content": "Xing Niu, Marine Carpuat, Controlling neural machine translation formality with synthetic supervision, 2020, Association for the Advancement of Artificial Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Xing Niu",
                    "Marine Carpuat"
                ],
                "title": "Controlling neural machine translation formality with synthetic supervision",
                "pub_date": "2020",
                "pub_title": "Association for the Advancement of Artificial Intelligence",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_151",
            "content": "Xing Niu, Sudha Rao, Marine Carpuat, Multi-task neural models for translating between styles within and across languages, 2018, Proceedings of the 27th International Conference on Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Xing Niu",
                    "Sudha Rao",
                    "Marine Carpuat"
                ],
                "title": "Multi-task neural models for translating between styles within and across languages",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 27th International Conference on Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_152",
            "content": "Pang Richard Yuanzhe, Towards actual (not operational) textual style transfer auto-evaluation, 2019, Proceedings of the 5th Workshop on Noisy Usergenerated Text, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "Pang Richard Yuanzhe"
                ],
                "title": "Towards actual (not operational) textual style transfer auto-evaluation",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 5th Workshop on Noisy Usergenerated Text",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_153",
            "content": "Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, Bleu: a method for automatic evaluation of machine translation, 2002, Proceedings of the Association for Computational Linguistics. Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Kishore Papineni",
                    "Salim Roukos",
                    "Todd Ward",
                    "Wei-Jing Zhu"
                ],
                "title": "Bleu: a method for automatic evaluation of machine translation",
                "pub_date": "2002",
                "pub_title": "Proceedings of the Association for Computational Linguistics. Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_154",
            "content": "Jonas Pfeiffer, Andreas R\u00fcckl\u00e9, Clifton Poth, Aishwarya Kamath, Ivan Vuli\u0107, Sebastian Ruder, Kyunghyun Cho, Iryna Gurevych, Adapterhub: A framework for adapting transformers, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "Jonas Pfeiffer",
                    "Andreas R\u00fcckl\u00e9",
                    "Clifton Poth",
                    "Aishwarya Kamath",
                    "Ivan Vuli\u0107",
                    "Sebastian Ruder",
                    "Kyunghyun Cho",
                    "Iryna Gurevych"
                ],
                "title": "Adapterhub: A framework for adapting transformers",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_155",
            "content": "Jonas Pfeiffer, Ivan Vuli\u0107, Iryna Gurevych, Sebastian Ruder, MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer, 2020, Proceedings of Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Jonas Pfeiffer",
                    "Ivan Vuli\u0107",
                    "Iryna Gurevych",
                    "Sebastian Ruder"
                ],
                "title": "MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer",
                "pub_date": "2020",
                "pub_title": "Proceedings of Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_156",
            "content": "Yulia Shrimai Prabhumoye, Ruslan Tsvetkov, Alan Salakhutdinov,  Black, Style transfer through back-translation, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Yulia Shrimai Prabhumoye",
                    "Ruslan Tsvetkov",
                    "Alan Salakhutdinov",
                    " Black"
                ],
                "title": "Style transfer through back-translation",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "111-ARR_v1_157",
            "content": "UNKNOWN, None, , Graham Neubig, and Yulia Tsvetkov. 2021. Evaluating the morphosyntactic well-formedness of generated texts, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Graham Neubig, and Yulia Tsvetkov. 2021. Evaluating the morphosyntactic well-formedness of generated texts",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_158",
            "content": "Adithya Pratapa, Gayatri Bhat, Monojit Choudhury, Sunayana Sitaram, Sandipan Dandapat, Kalika Bali, Language modeling for code-mixing: The role of linguistic theory based synthetic data, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Adithya Pratapa",
                    "Gayatri Bhat",
                    "Monojit Choudhury",
                    "Sunayana Sitaram",
                    "Sandipan Dandapat",
                    "Kalika Bali"
                ],
                "title": "Language modeling for code-mixing: The role of linguistic theory based synthetic data",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "111-ARR_v1_159",
            "content": "Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang, SQuAD: 100,000+ questions for machine comprehension of text, 2016, Proceedings of Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": [
                    "Pranav Rajpurkar",
                    "Jian Zhang",
                    "Konstantin Lopyrev",
                    "Percy Liang"
                ],
                "title": "SQuAD: 100,000+ questions for machine comprehension of text",
                "pub_date": "2016",
                "pub_title": "Proceedings of Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_160",
            "content": "UNKNOWN, None, , Anoop Kunchukuttan, Pratyush Kumar, and Mitesh Shantadevi Khapra. 2021. Samanantar: The largest publicly available parallel corpora collection for 11 indic languages, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Anoop Kunchukuttan, Pratyush Kumar, and Mitesh Shantadevi Khapra. 2021. Samanantar: The largest publicly available parallel corpora collection for 11 indic languages",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_161",
            "content": "UNKNOWN, None, 2005, Free-marginal multirater kappa (multirater k [free]): An alternative to fleiss' fixed-marginal multirater kappa, .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": null,
                "title": null,
                "pub_date": "2005",
                "pub_title": "Free-marginal multirater kappa (multirater k [free]): An alternative to fleiss' fixed-marginal multirater kappa",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_162",
            "content": "Sudha Rao, Joel Tetreault, Dear sir or madam, may I introduce the GYAFC dataset: Corpus, benchmarks and metrics for formality style transfer, 2018, Conference of the North American Chapter of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "Sudha Rao",
                    "Joel Tetreault"
                ],
                "title": "Dear sir or madam, may I introduce the GYAFC dataset: Corpus, benchmarks and metrics for formality style transfer",
                "pub_date": "2018",
                "pub_title": "Conference of the North American Chapter of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_163",
            "content": "Sravana Reddy, Kevin Knight, Obfuscating gender in social media writing, 2016, Proceedings of the First Workshop on NLP and Computational Social Science, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": [
                    "Sravana Reddy",
                    "Kevin Knight"
                ],
                "title": "Obfuscating gender in social media writing",
                "pub_date": "2016",
                "pub_title": "Proceedings of the First Workshop on NLP and Computational Social Science",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_164",
            "content": "UNKNOWN, None, 2021, A recipe for arbitrary text style transfer with large language models, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "A recipe for arbitrary text style transfer with large language models",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_165",
            "content": "Nils Reimers, Iryna Gurevych, Making monolingual sentence embeddings multilingual using knowledge distillation, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": [
                    "Nils Reimers",
                    "Iryna Gurevych"
                ],
                "title": "Making monolingual sentence embeddings multilingual using knowledge distillation",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "111-ARR_v1_166",
            "content": "Parker Riley, Noah Constant, Mandy Guo, Girish Kumar, David Uthus, Zarana Parekh, TextSETTR: Few-shot text style extraction and tunable targeted restyling, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": [
                    "Parker Riley",
                    "Noah Constant",
                    "Mandy Guo",
                    "Girish Kumar",
                    "David Uthus",
                    "Zarana Parekh"
                ],
                "title": "TextSETTR: Few-shot text style extraction and tunable targeted restyling",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_167",
            "content": "UNKNOWN, None, , Mohit Agrawal, and Niloy Ganguly. 2021. A hierarchical vae for calibrating attributes while generating text using normalizing flow. ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Mohit Agrawal, and Niloy Ganguly. 2021. A hierarchical vae for calibrating attributes while generating text using normalizing flow. ACL",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_168",
            "content": "UNKNOWN, None, 2019, A deep generative model for code-switched text, .",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "A deep generative model for code-switched text",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_169",
            "content": "Mingyue Shang, Piji Li, Zhenxin Fu, Lidong Bing, Dongyan Zhao, Shuming Shi, Rui Yan, Semi-supervised text style transfer: Cross projection in latent space, 2019, Proceedings of Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "Mingyue Shang",
                    "Piji Li",
                    "Zhenxin Fu",
                    "Lidong Bing",
                    "Dongyan Zhao",
                    "Shuming Shi",
                    "Rui Yan"
                ],
                "title": "Semi-supervised text style transfer: Cross projection in latent space",
                "pub_date": "2019",
                "pub_title": "Proceedings of Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_170",
            "content": "Tianxiao Shen, Tao Lei, Regina Barzilay, Tommi Jaakkola, Style transfer from non-parallel text by cross-alignment, 2017, Advances in neural information processing systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": [
                    "Tianxiao Shen",
                    "Tao Lei",
                    "Regina Barzilay",
                    "Tommi Jaakkola"
                ],
                "title": "Style transfer from non-parallel text by cross-alignment",
                "pub_date": "2017",
                "pub_title": "Advances in neural information processing systems",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_171",
            "content": "Rakshith Shetty, Bernt Schiele, Mario Fritz, A4nt: author attribute anonymity by adversarial training of neural machine translation, 2018, 27th {USENIX} Security Symposium ({USENIX} Security 18), .",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": [
                    "Rakshith Shetty",
                    "Bernt Schiele",
                    "Mario Fritz"
                ],
                "title": "A4nt: author attribute anonymity by adversarial training of neural machine translation",
                "pub_date": "2018",
                "pub_title": "27th {USENIX} Security Symposium ({USENIX} Security 18)",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_172",
            "content": "UNKNOWN, None, 2020, Controlling style in generated dialogue, .",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Controlling style in generated dialogue",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_173",
            "content": "Sandeep Subramanian, Guillaume Lample, Eric Smith, Ludovic Denoyer, Marc'aurelio Ranzato, Y-Lan Boureau, Multiple-attribute text style transfer, 2019, Proceedings of the International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b40",
                "authors": [
                    "Sandeep Subramanian",
                    "Guillaume Lample",
                    "Eric Smith",
                    "Ludovic Denoyer",
                    "Marc'aurelio Ranzato",
                    "Y-Lan Boureau"
                ],
                "title": "Multiple-attribute text style transfer",
                "pub_date": "2019",
                "pub_title": "Proceedings of the International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_174",
            "content": "Aleksey Tikhonov, P Ivan,  Yamshchikov, Sounds wilde. phonetically extended embeddings for author-stylized poetry generation, 2018, Proceedings of the Fifteenth Workshop on Computational Research in Phonetics, Phonology, and Morphology, .",
            "ntype": "ref",
            "meta": {
                "xid": "b41",
                "authors": [
                    "Aleksey Tikhonov",
                    "P Ivan",
                    " Yamshchikov"
                ],
                "title": "Sounds wilde. phonetically extended embeddings for author-stylized poetry generation",
                "pub_date": "2018",
                "pub_title": "Proceedings of the Fifteenth Workshop on Computational Research in Phonetics, Phonology, and Morphology",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_175",
            "content": "Alexey Tikhonov, Viacheslav Shibaev, Aleksander Nagaev, Aigul Nugmanova, Ivan Yamshchikov, Style transfer for texts: Retrain, report errors, compare with rewrites, 2019, Proceedings of Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b42",
                "authors": [
                    "Alexey Tikhonov",
                    "Viacheslav Shibaev",
                    "Aleksander Nagaev",
                    "Aigul Nugmanova",
                    "Ivan Yamshchikov"
                ],
                "title": "Style transfer for texts: Retrain, report errors, compare with rewrites",
                "pub_date": "2019",
                "pub_title": "Proceedings of Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_176",
            "content": "Ke Wang, Hang Hua, Xiaojun Wan, Controllable unsupervised text attribute transfer via editing entangled latent representation, 2019, Advances in Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b43",
                "authors": [
                    "Ke Wang",
                    "Hang Hua",
                    "Xiaojun Wan"
                ],
                "title": "Controllable unsupervised text attribute transfer via editing entangled latent representation",
                "pub_date": "2019",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_177",
            "content": "UNKNOWN, None, 2010, Inequalities between multirater kappas. Advances in data analysis and classification, .",
            "ntype": "ref",
            "meta": {
                "xid": "b44",
                "authors": null,
                "title": null,
                "pub_date": "2010",
                "pub_title": "Inequalities between multirater kappas. Advances in data analysis and classification",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_178",
            "content": "John Wieting, Kevin Gimpel, ParaNMT-50M: Pushing the limits of paraphrastic sentence embeddings with millions of machine translations, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b45",
                "authors": [
                    "John Wieting",
                    "Kevin Gimpel"
                ],
                "title": "ParaNMT-50M: Pushing the limits of paraphrastic sentence embeddings with millions of machine translations",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "111-ARR_v1_179",
            "content": "UNKNOWN, None, 2019, Unsupervised data augmentation for consistency training, .",
            "ntype": "ref",
            "meta": {
                "xid": "b46",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Unsupervised data augmentation for consistency training",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_180",
            "content": "Peng Xu, Jackie Chi Kit Cheung, Yanshuai Cao, On variational learning of controllable representations for text without supervision, 2020, Proceedings of the 37th International Conference on Machine Learning, PMLR.",
            "ntype": "ref",
            "meta": {
                "xid": "b47",
                "authors": [
                    "Peng Xu",
                    "Jackie Chi Kit Cheung",
                    "Yanshuai Cao"
                ],
                "title": "On variational learning of controllable representations for text without supervision",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 37th International Conference on Machine Learning",
                "pub": "PMLR"
            }
        },
        {
            "ix": "111-ARR_v1_181",
            "content": "Wei Xu, Chris Callison-Burch, Courtney Napoles, Problems in current text simplification research: New data can help, 2015, Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b48",
                "authors": [
                    "Wei Xu",
                    "Chris Callison-Burch",
                    "Courtney Napoles"
                ],
                "title": "Problems in current text simplification research: New data can help",
                "pub_date": "2015",
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_182",
            "content": "Wei Xu, Alan Ritter, Bill Dolan, Ralph Grishman, Colin Cherry, Paraphrasing for style, 2012, Proceedings of International Conference on Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b49",
                "authors": [
                    "Wei Xu",
                    "Alan Ritter",
                    "Bill Dolan",
                    "Ralph Grishman",
                    "Colin Cherry"
                ],
                "title": "Paraphrasing for style",
                "pub_date": "2012",
                "pub_title": "Proceedings of International Conference on Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_183",
            "content": "UNKNOWN, None, , and Colin Raffel. 2021a. Byt5: Towards a tokenfree future with pre-trained byte-to-byte models, .",
            "ntype": "ref",
            "meta": {
                "xid": "b50",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "and Colin Raffel. 2021a. Byt5: Towards a tokenfree future with pre-trained byte-to-byte models",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_184",
            "content": "Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, and Colin Raffel. 2021b. mT5: A massively multilingual pre-trained text-to-text transformer, , Conference of the North American Chapter, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b51",
                "authors": [
                    "Linting Xue",
                    "Noah Constant",
                    "Adam Roberts",
                    "Mihir Kale",
                    "Rami Al-Rfou",
                    "Aditya Siddhant"
                ],
                "title": "Aditya Barua, and Colin Raffel. 2021b. mT5: A massively multilingual pre-trained text-to-text transformer",
                "pub_date": null,
                "pub_title": "Conference of the North American Chapter",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "111-ARR_v1_185",
            "content": "Yinfei Yang, Daniel Cer, Amin Ahmad, Mandy Guo, Jax Law, Noah Constant, Gustavo Hernandez Abrego, Steve Yuan, Chris Tar, Yun-Hsuan Sung, Brian Strope, Ray Kurzweil, Multilingual universal sentence encoder for semantic retrieval, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, Online. Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b52",
                "authors": [
                    "Yinfei Yang",
                    "Daniel Cer",
                    "Amin Ahmad",
                    "Mandy Guo",
                    "Jax Law",
                    "Noah Constant",
                    "Gustavo Hernandez Abrego",
                    "Steve Yuan",
                    "Chris Tar",
                    "Yun-Hsuan Sung",
                    "Brian Strope",
                    "Ray Kurzweil"
                ],
                "title": "Multilingual universal sentence encoder for semantic retrieval",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, Online. Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "111-ARR_v1_186",
            "content": "Biao Zhang, Philip Williams, Ivan Titov, Rico Sennrich, Improving massively multilingual neural machine translation and zero-shot translation, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b53",
                "authors": [
                    "Biao Zhang",
                    "Philip Williams",
                    "Ivan Titov",
                    "Rico Sennrich"
                ],
                "title": "Improving massively multilingual neural machine translation and zero-shot translation",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "111-ARR_v1_0@0",
            "content": "Few-shot Controllable Style Transfer for Low-Resource Multilinugal Settings",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_0",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_2@0",
            "content": "Style transfer is the task of rewriting an input sentence into a target style while approximately preserving its content.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_2",
            "start": 0,
            "end": 120,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_2@1",
            "content": "While most prior literature assumes access to large stylelabelled corpora, recent work (Riley et al., 2021) has attempted \"few-shot\" style transfer using only 3-10 sentences at inference for extracting the target style.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_2",
            "start": 122,
            "end": 340,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_2@2",
            "content": "In this work we study a relevant low-resource setting: style transfer for languages where no style-labelled corpora are available.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_2",
            "start": 342,
            "end": 471,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_2@3",
            "content": "We find that existing fewshot methods perform this task poorly, with a strong tendency to copy inputs verbatim.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_2",
            "start": 473,
            "end": 583,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_3@0",
            "content": "We push the state-of-the-art for few-shot style transfer with a new method modeling the stylistic difference between paraphrases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_3",
            "start": 0,
            "end": 128,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_3@1",
            "content": "When compared to prior work using automatic and human evaluations, our model achieves 2-3x better performance and output diversity in formality transfer and code-mixing addition across seven languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_3",
            "start": 130,
            "end": 330,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_3@2",
            "content": "Moreover, our method is better able to control the amount of style transfer using an input scalar knob.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_3",
            "start": 332,
            "end": 434,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_3@3",
            "content": "We report promising qualitative results for several attribute transfer directions, including sentiment transfer, text simplification, gender neutralization and text anonymization, all without retraining the model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_3",
            "start": 436,
            "end": 648,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_3@4",
            "content": "Finally we found model evaluation to be difficult due to the lack of evaluation datasets and metrics for many languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_3",
            "start": 650,
            "end": 769,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_3@5",
            "content": "To facilitate further research in formality transfer for Indic languages, we crowdsource annotations for 4000 sentence pairs in four languages, and use this dataset 1 to design our automatic evaluation suite.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_3",
            "start": 771,
            "end": 978,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_4@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_4",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_5@0",
            "content": "Style transfer is a natural language generation task in which input sentences need to be re-written into a target style, while preserving semantics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_5",
            "start": 0,
            "end": 147,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_5@1",
            "content": "It has many applications such as writing assistance (Heidorn, 2000), controlling generation for attributes 1 Dataset will be open-sourced on paper acceptance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_5",
            "start": 149,
            "end": 306,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_6@0",
            "content": "Extractor -Target (Formal)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_6",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_7@0",
            "content": "It is certainly amongst my favorites.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_7",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_8@0",
            "content": "Source (Informal)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_8",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_9@0",
            "content": "Style Vector Extractor Figure 1: An illustration of our few-shot style transfer system during inference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_9",
            "start": 0,
            "end": 103,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_9@1",
            "content": "Our model extracts style vectors from exemplar English sentences as input (in this case formal/informal sentences) and uses their vector difference to guide style transfer in other languages (Hindi).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_9",
            "start": 105,
            "end": 303,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_9@2",
            "content": "\u03bb is used to control the magnitude of transfer: in this example our model produces more high Sanskrit words & honorifics (more formal) with higher \u03bb.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_9",
            "start": 305,
            "end": 453,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_10@0",
            "content": "like simplicity, formality or persuasion (Xu et al., 2015;Smith et al., 2020;Niu and Carpuat, 2020), data augmentation (Xie et al., 2019;Lee et al., 2021), and author obfuscation (Shetty et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_10",
            "start": 0,
            "end": 200,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_10@1",
            "content": "Most prior work either assumes access to supervised data with parallel sentences between the two styles (Jhamtani et al., 2017), or access to large corpus of unpaired sentences with style labels (Prabhumoye et al., 2018;Subramanian et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_10",
            "start": 202,
            "end": 447,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_10@2",
            "content": "Models built are style-specific and cannot generalize to new styles during inference, which is needed for applications like real-time adaptation to a user's style in a dialog or writing application.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_10",
            "start": 449,
            "end": 646,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_10@3",
            "content": "Moreover, access to a large unpaired corpus with style labels is a strong assumption.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_10",
            "start": 648,
            "end": 732,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_10@4",
            "content": "Most standard \"unpaired\" style transfer datasets have been carefully curated (Shen et al., 2017) or were originally parallel (Xu et al., 2012;Rao and Tetreault, 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_10",
            "start": 734,
            "end": 900,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_10@5",
            "content": "This is especially relevant in settings outside English, where NLP tools and labelled datasets are largely underdeveloped (Joshi et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_10",
            "start": 902,
            "end": 1044,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_10@6",
            "content": "In this work, we take the first steps studying style transfer in seven languages 2 with nearly 1.5 billion speakers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_10",
            "start": 1046,
            "end": 1161,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_10@7",
            "content": "Since no training data exists for these languages, we analyzed the current state-of-the-art in few-shot multilingual style transfer, the Universal Rewriter (UR) from Garcia et al. (2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_10",
            "start": 1163,
            "end": 1349,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_10@8",
            "content": "Unfortunately, we found it often copied input sentences verbatim (Section 3.1) without transferring their style.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_10",
            "start": 1351,
            "end": 1462,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_11@0",
            "content": "We propose a simple inference-time trick of style-controlled translation through English, which improves the UR output diversity (Section 4.1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_11",
            "start": 0,
            "end": 142,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_11@1",
            "content": "To further boost performance we propose DIFFUR, 3 an algorithm using the recent finding that paraphrasing leads to stylistic changes (Krishna et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_11",
            "start": 144,
            "end": 299,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_11@2",
            "content": "DIFFUR extracts edit vectors from paraphrase pairs, which are used to condition and train the model (Figure 2).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_11",
            "start": 301,
            "end": 411,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_11@3",
            "content": "On formality transfer and code-mixing addition, our best performing DIFFUR variant significantly outperforms UR across all languages (by 2-3x) using automatic & human evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_11",
            "start": 413,
            "end": 590,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_11@4",
            "content": "Besides better rewriting, our system is better able to control the style transfer magnitude (Figure 1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_11",
            "start": 592,
            "end": 694,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_11@5",
            "content": "A scalar knob (\u03bb) can be adjusted to make the output text reflect the target style (provided by exemplars) more or less.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_11",
            "start": 696,
            "end": 815,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_11@6",
            "content": "We also observe promising qualitative results in several attribute transfer directions (Section 6) including sentiment transfer, simplification, gender neutralization and text anonymization, all without retraining the model and using just 3-10 examples at inference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_11",
            "start": 817,
            "end": 1082,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_12@0",
            "content": "Finally, we found it hard to precisely evaluate models due to the lack of evaluation datasets and style classifiers (often used as metrics) for many languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_12",
            "start": 0,
            "end": 158,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_12@1",
            "content": "To facilitate further research in Indic formality transfer, we crowdsource formality annotations for 4000 sentence pairs in four Indic languages (Section 5.1), and use this dataset to design the automatic evaluation suite (Section 5).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_12",
            "start": 160,
            "end": 393,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_12@2",
            "content": "In summary, our contributions provide an end-toend recipe for developing and evaluating style transfer models and evaluation in a low-resource setting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_12",
            "start": 395,
            "end": 545,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_13@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_13",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_14@0",
            "content": "Few-shot methods are a recent development in English style transfer, with prior work using variational autoencoders (Xu et al., 2020), or prompting large pretrained language models at inference (Reif et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_14",
            "start": 0,
            "end": 213,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_14@1",
            "content": "Most related is the state-of-the-art TextSETTR model from Riley et al. (2021), who use a neural style encoder to map exemplar sentences to a vector used to guide generation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_14",
            "start": 215,
            "end": 387,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_14@2",
            "content": "To train this encoder, they use the idea that adjacent sentences in a document have a similar style.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_14",
            "start": 389,
            "end": 488,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_14@3",
            "content": "Recently, the Universal Rewriter (Garcia et al., 2021) extended TextSETTR to 101 languages, developing a joint model for translation, few-shot style transfer and stylized translation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_14",
            "start": 490,
            "end": 672,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_14@4",
            "content": "This model is the only prior few-shot system we found outside English, and our main baseline.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_14",
            "start": 674,
            "end": 766,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_14@5",
            "content": "We discuss its shortcomings in Section 3.1, and propose fixes in Section 4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_14",
            "start": 768,
            "end": 842,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_14@6",
            "content": "Multilingual style transfer is mostly unexplored in prior work: a 35 paper survey by Briakou et al. (2021b) found only one work in Chinese, Russian, Latvian, Estonian, French.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_14",
            "start": 844,
            "end": 1018,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_14@7",
            "content": "They further introduced XFORMAL, the first formality transfer evaluation dataset in French, Brazilian Portugese and Italian.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_14",
            "start": 1020,
            "end": 1143,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_14@8",
            "content": "4 To the best of our knowledge, we are the first to study style transfer for the languages we consider.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_14",
            "start": 1145,
            "end": 1247,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_14@9",
            "content": "More related work from Hindi linguistics and on style transfer control is provided in Appendix B.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_14",
            "start": 1249,
            "end": 1345,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_15@0",
            "content": "The Universal Rewriter (UR) model",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_15",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_16@0",
            "content": "We will start by discussing the Universal Rewriter (UR) model from Garcia et al. (2021), upon which our proposed DIFFUR model is built.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_16",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_16@1",
            "content": "The UR model extracts a style vector s from an exemplar sentence e, which reflects the desired target style.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_16",
            "start": 136,
            "end": 243,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_16@2",
            "content": "This style vector is used to style transfer an input sentence x. Consider f enc , f dec to be encoder & decoder Transformers initialized with mT5 (Xue et al., 2021b), which are composed to form the model f ur .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_16",
            "start": 245,
            "end": 454,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_17@0",
            "content": "f style (e) = s = f enc ([CLS] \u2295 e)[0] f ur (x, s) = f dec (f enc (x) + s)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_17",
            "start": 0,
            "end": 73,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_18@0",
            "content": "where \u2295 is string concatenation, + vector addition.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_18",
            "start": 0,
            "end": 50,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_18@1",
            "content": "f ur is trained using the following objectives,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_18",
            "start": 52,
            "end": 98,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_19@0",
            "content": "Denoising: To learn a style extractor, the Universal Rewriter uses the idea that two non-overlapping spans of text in the same document are likely to have the same style.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_19",
            "start": 0,
            "end": 169,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_19@1",
            "content": "Concretely, let x 1 and x 2 be two non-overlapping spans in mC4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_19",
            "start": 171,
            "end": 234,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_19@2",
            "content": "Style extracted from one span is used to denoise the other,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_19",
            "start": 236,
            "end": 294,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_20@0",
            "content": "x2 = f ur (noise(x 2 ), f style (x 1 )) L denoise = L CE (x 2 , x 2 )",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_20",
            "start": 0,
            "end": 68,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_21@0",
            "content": "where L CE is the standard next-word prediction cross entropy loss function and noise(\u2022) refers to 20-60% random token dropping and token replacement.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_21",
            "start": 0,
            "end": 149,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_21@1",
            "content": "This objective is used on the mC4 dataset (Xue et al., 2021b) with 101 languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_21",
            "start": 151,
            "end": 231,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_21@2",
            "content": "To build a general-purpose rewriter which can do translation as well as style transfer, the model is additionally trained on two objectives: (1) supervised machine translation using the OPUS-100 parallel dataset (Zhang et al., 2020), and (2) a self-supervised objective to learn effective stylecontrolled translation; more details in Appendix C.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_21",
            "start": 233,
            "end": 577,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_22@0",
            "content": "During inference (Figure 1), consider an input sentence x and a transformation from style A to B (say informal to formal).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_22",
            "start": 0,
            "end": 121,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_22@1",
            "content": "Let S A , S B to be exemplar sentences in each of the styles (typically 3-10 sentences).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_22",
            "start": 123,
            "end": 210,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_22@2",
            "content": "The output y is computed as,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_22",
            "start": 212,
            "end": 239,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_23@0",
            "content": "s A , s B = 1 N y\u2208S A , S B f style (y) y = f ur (x, \u03bb(s B \u2212 s A ))",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_23",
            "start": 0,
            "end": 66,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_24@0",
            "content": "where \u03bb acts as a control knob to determine the magnitude of style transfer, and the vector subtraction helps remove confounding style information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_24",
            "start": 0,
            "end": 146,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_24@1",
            "content": "5",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_24",
            "start": 148,
            "end": 148,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_25@0",
            "content": "Shortcomings of the Universal Rewriter",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_25",
            "start": 0,
            "end": 37,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_26@0",
            "content": "We experimented with the UR model on Hindi formality transfer, and noticed poor performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_26",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_26@1",
            "content": "We noticed that UR has a strong tendency to copy sentences verbatim -45.5% outputs were copied exactly from the input (and hence not style transferred) for the best performing value of \u03bb.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_26",
            "start": 93,
            "end": 279,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_26@2",
            "content": "The copying increase for smaller \u03bb, making magnitude control harder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_26",
            "start": 281,
            "end": 348,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_26@3",
            "content": "We identify the following issues: 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_26",
            "start": 350,
            "end": 385,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_26@4",
            "content": "Random token noise leads to unnatural inputs & transformations: The Universal Rewriter uses 20-60% uniformly random token dropping / replacement to noise inputs, which leads to ungrammatical inputs during training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_26",
            "start": 387,
            "end": 600,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_26@5",
            "content": "We hypothesize models tend to learn grammatical error correction, which encourages verbatim copying during inference where fluent inputs are used and no error correction is needed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_26",
            "start": 602,
            "end": 781,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_26@6",
            "content": "Moreover, token-level noise does not differentiate between content / function words, and cannot do syntactic changes like content reordering (Goyal and Durrett, 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_26",
            "start": 783,
            "end": 949,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_26@7",
            "content": "Too much noise could distort semantics and encourage hallucination, whereas too little will encourage copying.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_26",
            "start": 951,
            "end": 1060,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_27@0",
            "content": "2. Style vectors may not capture the precise style transformation: The Universal Rewriter extracts the style vector from a single sentence during training, which is a mismatch from the inference where a difference between vectors is taken.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_27",
            "start": 0,
            "end": 238,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_27@1",
            "content": "Without taking vector differences at inference, we observe semantic preservation and overall performance of the UR model is much lower.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_27",
            "start": 240,
            "end": 374,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_27@2",
            "content": "6 3. mC4 is noisy: On reading training data samples, we noticed noisy samples with severe language identification errors in the Hindi subset of mC4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_27",
            "start": 376,
            "end": 523,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_27@3",
            "content": "This has also been observed recently in Caswell et al. (2021), who audit 100 sentences in each language, and report 50% sentences in Marathi and 20% sentences in Hindi have the wrong language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_27",
            "start": 525,
            "end": 716,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_27@4",
            "content": "4. No translation data for several languages: We notice worse performance for languages which did not get parallel translation data (for the translation objective in Section 3).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_27",
            "start": 718,
            "end": 894,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_27@5",
            "content": "In Table 1 we see UR gets a score 7 of 30.4 for Hindi and Bengali, languages for which it got translation data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_27",
            "start": 896,
            "end": 1006,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_27@6",
            "content": "However, the scores are lower for Kannada, Telugu & Gujarati (25.5,22.8,23.7), for which no translation data was used.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_27",
            "start": 1008,
            "end": 1125,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_27@7",
            "content": "We hypothesize translation data encourages learning language-agnostic semantic representations needed for translation from the given language, which in-turn improves style transfer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_27",
            "start": 1127,
            "end": 1307,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_28@0",
            "content": "Our Models",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_28",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_29@0",
            "content": "Style-Controlled Backtranslation (+ BT)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_29",
            "start": 0,
            "end": 38,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_30@0",
            "content": "While the Universal Rewriter model has a strong tendency to exactly copy input sentences while rewriting sentences in the same language (Section 3.1), we found it is an effective style-controlled translation system.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_30",
            "start": 0,
            "end": 214,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_30@1",
            "content": "This motivates a simple inference-time trick to improve model outputs and reduce copying -translate sentences to English (en) in a style-agnostic manner with a zero style vector 0, and translate back into the source language (lx) with stylistic control.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_30",
            "start": 216,
            "end": 468,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_31@0",
            "content": "s A , s B = 1 N y\u2208S A , S B",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_31",
            "start": 0,
            "end": 26,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_32@0",
            "content": "f style (y) The DIFFUR approach (Section 4.2), with fixes to the shortcomings of the Universal Rewriter approach (Section 3.1) shown.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_32",
            "start": 0,
            "end": 132,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_32@1",
            "content": "Sentences are noised using paraphrasing, the style vector difference between the paraphrase & original sentence (\"edit vector\") is used to control denoising.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_32",
            "start": 134,
            "end": 290,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_32@2",
            "content": "See Figure 1 for the inference-time process.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_32",
            "start": 292,
            "end": 335,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_33@0",
            "content": "x en = f ur (en \u2295 x, 0) x = f ur (lx \u2295 x en , \u03bb(s B \u2212 s A ))",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_33",
            "start": 0,
            "end": 59,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_34@0",
            "content": "where x is the input sentence, S A , S B are exemplars of the styles we want to transfer between, en, lx are language codes prepended to indicate the output language (Appendix C).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_34",
            "start": 0,
            "end": 178,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_34@1",
            "content": "Prior work has shown that backtranslation is effective for paraphrasing (Wieting and Gimpel, 2018;Iyyer et al., 2018) and style transfer (Prabhumoye et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_34",
            "start": 180,
            "end": 342,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_35@0",
            "content": "Using Paraphrase Vector Differences for",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_35",
            "start": 0,
            "end": 38,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_36@0",
            "content": "Style Transfer (DIFFUR)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_36",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_37@0",
            "content": "While style-controlled backtranslation is an effective strategy, it needs two translation steps.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_37",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_37@1",
            "content": "This is 2x slower than UR, and semantic errors increase with successive translations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_37",
            "start": 97,
            "end": 181,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_37@2",
            "content": "To learn effective style transfer systems needing only a single generation step we develop DIFFUR, a new few-shot style transfer training objective (overview in Figure 2).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_37",
            "start": 183,
            "end": 353,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_37@3",
            "content": "DIFFUR tackles the issues discussed in Section 3.1 using paraphrases and style vector differences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_37",
            "start": 355,
            "end": 452,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_38@0",
            "content": "Paraphrases as a \"noise\" function: Instead of using random token-level noise (issue #1 in Section 3.1), we paraphrase sentences to \"noise\" them during training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_38",
            "start": 0,
            "end": 159,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_38@1",
            "content": "Paraphrasing modifies the lexical & syntactic properties of sentences, while preserving fluency and input semantics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_38",
            "start": 161,
            "end": 276,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_38@2",
            "content": "Prior work (Krishna et al., 2020) has shown that paraphrasing leads to stylistic changes, and denoising can be considered a style re-insertion process.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_38",
            "start": 278,
            "end": 428,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_39@0",
            "content": "To create paraphrases, we backtranslate sentences from the UR model 8 with no style control (zero vectors used as style vectors).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_39",
            "start": 0,
            "end": 128,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_39@1",
            "content": "To increase diversity, we use random sampling in both translation steps, pooling generations obtained using temperature values [0.4, 0.6, 0.8, 1.0].",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_39",
            "start": 130,
            "end": 277,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_39@2",
            "content": "Finally, we discard paraphrase pairs from the training data where the semantic similarity score 9 is outside the range [0.7, 0.98].",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_39",
            "start": 279,
            "end": 409,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_39@3",
            "content": "This removes backtransation errors (score < 0.7), and exact copies (score > 0.98).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_39",
            "start": 411,
            "end": 492,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_40@0",
            "content": "Using style vector differences for control: To fix the training / inference mismatch for style extraction (issue #2 in Section 3.1), we propose using style vector differences between the output and input as the stylistic control.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_40",
            "start": 0,
            "end": 228,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_40@1",
            "content": "Concretely, let x be an input sentence and x para its paraphrase.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_40",
            "start": 230,
            "end": 294,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_41@0",
            "content": "s diff = f style (x) \u2212 f style (x para ) x = f ur (x para , stop-grad(s diff )) L = L CE (x, x)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_41",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_42@0",
            "content": "where stop-grad(\u2022) stops gradient flow through s diff , preventing the model from learning to copy x exactly.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_42",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_42@1",
            "content": "To ensure f style extracts meaningful style representations, we fine-tune a trained UR model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_42",
            "start": 110,
            "end": 202,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_42@2",
            "content": "Vector differences have many advantages, 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_42",
            "start": 204,
            "end": 246,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_42@3",
            "content": "Subtracting style vectors between a sentence and its paraphrase removes confounding features (like semantics) present in the vectors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_42",
            "start": 248,
            "end": 380,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_43@0",
            "content": "2. The vector difference focuses on the precise transformation that is needed to reconstruct the input from its paraphrase.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_43",
            "start": 0,
            "end": 122,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_44@0",
            "content": "DIFFUR is related to neural editor models (Guu et al., 2018;He et al., 2020), where language models are decomposed into a probabilistic space of edit vectors over prototype sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_44",
            "start": 0,
            "end": 182,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_44@1",
            "content": "We justify the DIFFUR design with ablations in Appendix G.1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_44",
            "start": 184,
            "end": 243,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_45@0",
            "content": "Indic Models (UR-INDIC, DIFFUR-INDIC)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_45",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_46@0",
            "content": "To address the issue of no translation data (issue #4 in Section 3.1), we train Indic variants of our models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_46",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_46@1",
            "content": "We replace the OPUS translation data used for training the Universal Rewriter (Section 3) with Samanantar (Ramesh et al., 2021), which is the largest publicly available parallel translation corpus for 11 Indic languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_46",
            "start": 110,
            "end": 329,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_46@2",
            "content": "We call these variants UR-INDIC and DIFFUR-INDIC.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_46",
            "start": 331,
            "end": 379,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_46@3",
            "content": "This process significantly up-samples the parallel data seen between English / Indic languages, and gives us better performance (Table 1) and lower copy rates, especially for languages with no OPUS translation data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_46",
            "start": 381,
            "end": 595,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_47@0",
            "content": "Multitask Learning (DIFFUR-MLT)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_47",
            "start": 0,
            "end": 30,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_48@0",
            "content": "One issue with our DIFFUR-INDIC setup is usage of a stop-grad(\u2022), to avoid verbatim copying from the input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_48",
            "start": 0,
            "end": 106,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_48@1",
            "content": "This prevents gradient flow into the style extractor f style , and as we see in Appendix H, a degradation of the style vector space.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_48",
            "start": 108,
            "end": 239,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_48@2",
            "content": "To prevent this from happening, we simply do multi-task learning between the original Universal Rewriter objective (Section 3) and our DIFFUR-INDIC objective, using an equal number of minibatches for each objective.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_48",
            "start": 241,
            "end": 455,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_49@0",
            "content": "Evaluation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_49",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_50@0",
            "content": "Automatic evaluation of style transfer is challenging (Pang, 2019;Mir et al., 2019;Tikhonov et al., 2019), and the lack of resources (such as evaluation datasets, style classifiers) make evaluation trickier for Indic languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_50",
            "start": 0,
            "end": 226,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_50@1",
            "content": "To tackle this issue, we first collect a small dataset of formality and semantic similarity annotations in four Indic languages (Section 5.1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_50",
            "start": 228,
            "end": 369,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_50@2",
            "content": "We use this dataset to guide the design of an evaluation suite (Section 5.2-5.6).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_50",
            "start": 371,
            "end": 451,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_50@3",
            "content": "Since automatic metrics in generation are imperfect (Celikyilmaz et al., 2020), we complement our results with human evaluation (Section 5.7).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_50",
            "start": 453,
            "end": 594,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_51@0",
            "content": "Indic Formality Transfer Dataset",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_51",
            "start": 0,
            "end": 31,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_52@0",
            "content": "Since no public datasets exist for formality transfer in Indic languages, it is hard to measure the extent to which automatic metrics (such as style classifiers) are effective.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_52",
            "start": 0,
            "end": 175,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_52@1",
            "content": "To tackle this issue, we build a dataset of 1000 sentence pairs in each of four Indic languages (Hindi, Bengali, Kannada, Telugu) with formality and semantic similarity annotations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_52",
            "start": 177,
            "end": 357,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_52@2",
            "content": "We first style transfer held-out Samanantar sentences using our UR-INDIC + BT model (Section 4.1, 4.3) to create sentence pairs with different formality.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_52",
            "start": 359,
            "end": 511,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_52@3",
            "content": "We then asked three crowdworkers to 1) label the more formal sentence in each pair; 2) rate semantic similarity on a 3-point scale.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_52",
            "start": 513,
            "end": 643,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_53@0",
            "content": "Our crowdsourcing is conducted on Task Mate, 10 where we hired native speakers from India with at least a high school education and 90% approval rating on the platform.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_53",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_53@1",
            "content": "To ensure crowdworkers understood \"formality\", we provided instructions following advice from professional Indian linguists, and asked two qualification questions in their native language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_53",
            "start": 169,
            "end": 356,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_53@2",
            "content": "More details (agreement, compensation, instructions) are provided in Appendix E.4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_53",
            "start": 358,
            "end": 439,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_54@0",
            "content": "Transfer Accuracy (r-ACC, a-ACC)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_54",
            "start": 0,
            "end": 31,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_55@0",
            "content": "Our first metric checks whether the output sentence reflects the target style.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_55",
            "start": 0,
            "end": 77,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_55@1",
            "content": "This is measured by an external classifier's predictions on system outputs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_55",
            "start": 79,
            "end": 153,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_55@2",
            "content": "We use two variants of transfer accuracy: (1) Relative Accuracy (r-ACC): does the target style classifier score the output sentence higher than the input sentence? (2) Absolute Accuracy (a-ACC): does the classifier score the output higher than 0.5?",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_55",
            "start": 155,
            "end": 402,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_55@3",
            "content": "Building multilingual classifiers: Unfortunately, no large style classification datasets exist for most languages, preventing us from building classifiers from scratch.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_55",
            "start": 404,
            "end": 571,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_55@4",
            "content": "We resort to zero-shot cross lingual transfer techniques (Conneau and Lample, 2019), where large multilingual pretrained models are first fine-tuned on English classification data, and then applied to other languages at inference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_55",
            "start": 573,
            "end": 802,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_55@5",
            "content": "We experiment with three such techniques, and find MAD-X classifiers with language adapters (Pfeiffer et al., 2020b) have the highest accuracy of 81% on our Hindi data from Section 5.1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_55",
            "start": 804,
            "end": 988,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_55@6",
            "content": "However, MAD-X classifiers were only available for Hindi, so we use the next best XLM RoBERTa-base (Conneau et al., 2020) for other languages, which has 75%-82% accuracy on annotated data; details in Appendix E.1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_55",
            "start": 990,
            "end": 1202,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_56@0",
            "content": "Semantic Similarity (SIM)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_56",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_57@0",
            "content": "Our second evaluation criteria is semantic similarity between the input and output.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_57",
            "start": 0,
            "end": 82,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_57@1",
            "content": "Following recent recommendations (Marie et al., 2021;Krishna et al., 2020), we avoid n-gram overlap metrics like BLEU (Papineni et al., 2002).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_57",
            "start": 84,
            "end": 225,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_57@2",
            "content": "Instead, we use LaBSE (Feng et al., 2020), a language-agnostic semantic similarity model based on multilingual BERT (Devlin et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_57",
            "start": 227,
            "end": 364,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_57@3",
            "content": "LaBSE supports 109 languages, and is the only similarity model we found supporting all the Indic languages in this work.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_57",
            "start": 366,
            "end": 485,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_57@4",
            "content": "We also observed LaBSE had greater correlation with our annotated data (Section 5.1) compared to alternatives; details in Appendix E.2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_57",
            "start": 487,
            "end": 621,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_58@0",
            "content": "Qualitatively, we found that sentence pairs with LaBSE scores lower than 0.6 were almost never paraphrases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_58",
            "start": 0,
            "end": 106,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_58@1",
            "content": "To avoid rewarding partial credit for low LaBSE scores, we use a hard threshold 11 (L = 0.75) to determine whether pairs are paraphrases, SIM(x, y ) = 1 if LaBSE(x, y ) > L else 0 5.4 Other Metrics (LANG, COPY, 1-g) Additionally, we measure whether the input and output sentences are in the same language (LANG), the fraction of outputs copied verbatim from the input (COPY), and the 1-gram overlap between input / output (1-g).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_58",
            "start": 108,
            "end": 535,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_58@2",
            "content": "High LANG and low COPY / 1-g (more diversity) is better; details in Appendix E.6.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_58",
            "start": 537,
            "end": 617,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_59@0",
            "content": "Aggregated Score (r-AGG, a-AGG)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_59",
            "start": 0,
            "end": 30,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_60@0",
            "content": "To get a sense of overall system performance, we combine individual metrics into one score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_60",
            "start": 0,
            "end": 90,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_60@1",
            "content": "Similar to Krishna et al. (2020) we aggregate metrics as, AGG(x, y ) = ACC(x, y )",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_60",
            "start": 92,
            "end": 172,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_61@0",
            "content": "\u2022 SIM(x, y ) \u2022 LANG(y ) AGG(D) = 1 |D| x,y \u2208D AGG(x, y )",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_61",
            "start": 0,
            "end": 55,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_62@0",
            "content": "Where (x, y ) are input-output pairs, and D is the test corpus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_62",
            "start": 0,
            "end": 62,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_62@1",
            "content": "In other words, we measure the fraction of outputs which simultaneously transfer style, have a semantic similarity of at least L (our threshold in Section 5.3), and have the same language as the input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_62",
            "start": 64,
            "end": 264,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_62@2",
            "content": "Depending on the variant of ACC (relative / absolute), we can derive r-AGG / a-AGG.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_62",
            "start": 266,
            "end": 348,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_63@0",
            "content": "Evaluating Control (CALIB)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_63",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_64@0",
            "content": "An ideal system should not only be able to style transfer sentences, but also control the magnitude of style transfer using the scalar input \u03bb.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_64",
            "start": 0,
            "end": 142,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_64@1",
            "content": "To evaluate this, for every system we first determine a \u03bb max value and let [0, \u03bb max ] be the range of control values.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_64",
            "start": 144,
            "end": 262,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_64@2",
            "content": "While in our setup \u03bb is an unbounded scalar, we noticed high values of \u03bb significantly perturb semantics (also noted in Garcia et al., 2021), with systems outputting style-specific n-grams unfaithful to the output.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_64",
            "start": 264,
            "end": 477,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_64@3",
            "content": "We choose \u03bb max to be the largest \u03bb from the list [0.5, 1.0, 1.5, 2.0, 2.5, 3.0] whose outputs have an average semantic similarity score (SIM, Section 5.3) of at least 0.75 12 with the validation set inputs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_64",
            "start": 479,
            "end": 685,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_64@4",
            "content": "For each system we take three evenly spaced \u03bb values in its control range, denoted as \u039b = [ 1 3 \u03bb max , 2 3 \u03bb max , \u03bb max ].",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_64",
            "start": 687,
            "end": 810,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_64@5",
            "content": "We then compute the style calibration to \u03bb (CALIB), or how often does increasing \u03bb lead to a style score increase?",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_64",
            "start": 812,
            "end": 925,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_64@6",
            "content": "We measure this with a statistic similar to Kendall's \u03c4 (Kendall, 1938), counting concordant pairs in \u039b,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_64",
            "start": 927,
            "end": 1030,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_65@0",
            "content": "CALIB(x) = 1 n \u03bb b >\u03bba {style(y \u03bb b ) > style(y \u03bba )}",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_65",
            "start": 0,
            "end": 52,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_66@0",
            "content": "where x is input, CALIB(x) is the average over all possible n (= 3) pairs of \u03bb values (\u03bb a , \u03bb b ) in \u039b.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_66",
            "start": 0,
            "end": 103,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_67@0",
            "content": "Human Evaluation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_67",
            "start": 0,
            "end": 15,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_68@0",
            "content": "Automatic metrics are usually insufficient for style transfer evaluation -according to Briakou et al. (2021a), 69 / 97 surveyed style transfer papers used human evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_68",
            "start": 0,
            "end": 171,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_68@1",
            "content": "We adopt the crowd-sourcing setup from Section 5.1, which was used to build our formality evaluation datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_68",
            "start": 173,
            "end": 282,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_68@2",
            "content": "We presented 200 generations from each model and the corresponding inputs in a random order, and asked three crowdworkers two questions about each pair of sentences: (1) which sentence is more formal/codemixed? (2) how similar are the two sentences in meaning?",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_68",
            "start": 284,
            "end": 543,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_68@3",
            "content": "This lets us evaluate r-ACC, SIM, r-AGG, CALIB with respect to human annotations instead of classifier predictions; details in Appendix E.4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_68",
            "start": 545,
            "end": 684,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_69@0",
            "content": "Main Experiments",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_69",
            "start": 0,
            "end": 15,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_70@0",
            "content": "We evaluate models on (1) formality transfer;",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_70",
            "start": 0,
            "end": 44,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_71@0",
            "content": "(2) increasing the amount of code-mixing with English.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_71",
            "start": 0,
            "end": 53,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_71@1",
            "content": "Seven languages with varying scripts and morphological richness are used for evaluation (hi,es,sw,bn,kn,te,gu).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_71",
            "start": 55,
            "end": 165,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_71@2",
            "content": "Note that no paired/unpaired data with style labels is used during training: models determine the target style at inference using 3-10 exemplars sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_71",
            "start": 167,
            "end": 321,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_71@3",
            "content": "For few-shot formality transfer, we use the English exemplars from Garcia et al. (2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_71",
            "start": 323,
            "end": 410,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_71@4",
            "content": "We follow their setup and use English exemplars to guide non-English transfer zero-shot.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_71",
            "start": 412,
            "end": 499,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_71@5",
            "content": "For code-mixing addition, we use Hindi/English code-mixed exemplars In Appendix G we show ablations studies justifying the DIFFUR design, decoding scheme, etc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_71",
            "start": 501,
            "end": 659,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_71@6",
            "content": "We also analyze the style encoder f style in Appendix H, finding it is an effective style classifier.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_71",
            "start": 661,
            "end": 761,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_72@0",
            "content": "We analyze several qualitative outputs from DIFFUR-MLT in Figure 4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_72",
            "start": 0,
            "end": 66,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_72@1",
            "content": "Besides formality transfer and code-mixing addition, we transfer several other attributes: sentiment (Li et al., 2018), simplicity (Xu et al., 2015), anonymity (Anandan et al., 2012) and gender neutrality (Reddy and Knight, 2016); more outputs in Appendix J.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_72",
            "start": 68,
            "end": 325,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_73@0",
            "content": "We present a recipe for building & evaluating controllable few-shot style transfer systems needing only 3-10 style examples at inference, useful in low-resource settings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_73",
            "start": 0,
            "end": 169,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_73@1",
            "content": "Our methods outperform prior work in formality transfer & codemixing for 7 languages, with promising qualitative results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_73",
            "start": 171,
            "end": 291,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_73@2",
            "content": "Future work includes further improving systems for some attributes, and considering languages where little / no translation data is available.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_73",
            "start": 293,
            "end": 434,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_74@0",
            "content": "Recent work has highlighted issues of stylistic bias in text generation systems, specifically machine translation systems (Hovy et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_74",
            "start": 0,
            "end": 141,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_74@1",
            "content": "We acknowledge these issues, and consider style transfer and style-controlled generation technology as an opportunity to work towards fixing them (for instance, gender neutralization as presented in Section 6).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_74",
            "start": 143,
            "end": 352,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_74@2",
            "content": "Note that it is important to tread down this path carefully -In Chapter 9, Blodgett (2021) argue that style is inseparable from social meaning (as originally noted by Eckert, 2008), and humans may perceive automatically generated text very differently compared to automatic style classifiers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_74",
            "start": 354,
            "end": 645,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_75@0",
            "content": "Our models were trained on 32 Google Cloud TPUs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_75",
            "start": 0,
            "end": 47,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_75@1",
            "content": "As discussed in Appendix A, the UR & UR-INDIC model take roughly 18 hours to train.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_75",
            "start": 49,
            "end": 131,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_75@2",
            "content": "The DIFFUR-* and DIFFUR-MLT models are much cheaper to train (2 hours) since we finetune the pretrained UR-* models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_75",
            "start": 133,
            "end": 248,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_75@3",
            "content": "The Google 2020 environment report mentions, 13 \"TPUs are highly efficient chips which have been specifically designed for machine learning applications\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_75",
            "start": 250,
            "end": 403,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_75@4",
            "content": "These accelerators run on Google Cloud, which is carbon neutral today, and is aiming to \"run on carbon-free energy, 24/7, at all of Google's data centers by 2030\" (https://cloud.google. com/sustainability).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_75",
            "start": 405,
            "end": 610,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_75@5",
            "content": "We compare the following models:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_75",
            "start": 612,
            "end": 643,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_76@0",
            "content": "\u2022 UR: the Universal Rewriter (Garcia et al., 2021), which is our main baseline (Section 3); \u2022 DIFFUR: our model with paraphrase vector differences (Section 4.2); \u2022 To train the UR-INDIC model, we use mC4 (Xue et al., 2021b) for the self-supervised objectives and Samanantar (Ramesh et al., 2021) for the supervised translation. For creating paraphrase data for training our DIFFUR models (Section 4.2), we again leverage Indic language side of Samanantar sentence pairs. Our models are implemented in JAX (Bradbury et al., 2018) using the T5X library. 14 We re-use the UR checkpoint from Garcia et al. (2021). To train the UR-INDIC model, we follow the setup in Garcia et al. ( 2021) and initialize the model with mT5-XL (Xue et al., 2021b), which has 3.7B parameters. We fine-tune the model for 25K steps with a batch size of 512 inputs and a learning rate of 1e-3, using the objectives in Section 3. Training was done on 32 Google Cloud TPUs which took a total of 17.5 hours. To train the DIFFUR and DIFFUR-INDIC models, we further finetune UR and UR-INDIC for a total of 4K steps using the objective from Section 4.2, taking 2 hours. Evaluation Datasets: Our models are evaluated on (1) formality transfer; (2) the task of adding code-mixing in text. Since we do not have access to any formality evaluation dataset, 15 we hold out 22K sentences from Samanantar in each Indic language for validation / testing. For Swahili / Spanish, we use mC4 / WMT2018 sentences. These sets",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_76",
            "start": 0,
            "end": 1477,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_77@0",
            "content": "have similar number of formal / informal sentences, as marked by our formality classifiers (Section 5.2), and are transferred to the opposite formality.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_77",
            "start": 0,
            "end": 151,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_77@1",
            "content": "We re-use the hi/bn formality transfer splits for codemixing addition, where a system must increase the amount of code-mixing (with English) in a sentence, as shown in our exemplars in Appendix D. Seven languages with varying scripts and morphological richness are used for evaluation (hi,es,sw,bn,kn,te,gu).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_77",
            "start": 153,
            "end": 460,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_77@2",
            "content": "The UR model only saw translation data for hi,es,bn, whereas UR-INDIC sees translation data for all Indic languages (Section 4.3).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_77",
            "start": 462,
            "end": 591,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_77@3",
            "content": "To test the generalization capability of the DIFFUR, no Gujarati paraphrase training data for is used.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_77",
            "start": 593,
            "end": 694,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_78@0",
            "content": "Multilingual style transfer is mostly unexplored in prior work: a 35 paper survey by Briakou et al. (2021b) found only one work in Chinese, Russian, Latvian, Estonian, French (Shang et al., 2019;Tikhonov and Yamshchikov, 2018;Korotkova et al., 2019;Niu et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_78",
            "start": 0,
            "end": 266,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_78@1",
            "content": "Briakou et al. (2021b) further introduced XFORMAL, the first formality transfer evaluation dataset in French, Brazilian Portugese and Italian.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_78",
            "start": 268,
            "end": 409,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_78@2",
            "content": "16 Hindi formality has been studied in linguistics, focusing on politeness (Kachru, 2006;Agnihotri, 2013;Kumar, 2014) and codemixing (Bali et al., 2014).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_78",
            "start": 411,
            "end": 563,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_78@3",
            "content": "Due to its prevalence in India, English-Hindi code-mixing has seen work in language modeling (Pratapa et al., 2018;Samanta et al., 2019) and core NLP tasks (Khanuja et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_78",
            "start": 565,
            "end": 743,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_78@4",
            "content": "To the best of our knowledge, we are the first to study style transfer for Indic languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_78",
            "start": 745,
            "end": 835,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_78@5",
            "content": "A few prior works build models which can control the degree of style transfer using a scalar input (Wang et al., 2019;Samanta et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_78",
            "start": 837,
            "end": 976,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_78@6",
            "content": "However, these models are style-specific and require large unpaired style corpora during training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_78",
            "start": 978,
            "end": 1075,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_78@7",
            "content": "We adopt the inference-time control method used by Garcia et al. ( 2021) and notice much better controllability after our proposed fixes in Section 4.2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_78",
            "start": 1077,
            "end": 1228,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_79@0",
            "content": "In this section we describe the details of the supervised translation objective and the style-controlled translation objective used in the Universal Rewriter model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_79",
            "start": 0,
            "end": 163,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_79@1",
            "content": "See Section 3 for details on the exemplarbased denoising objective.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_79",
            "start": 165,
            "end": 231,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_80@0",
            "content": "This objective is the standard supervised translation setup, using zero vectors for style.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_80",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_80@1",
            "content": "The output language code is prepended to the input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_80",
            "start": 91,
            "end": 141,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_80@2",
            "content": "Consider a pair of parallel sentences (x, y) in languages with codes lx, ly (prepended to the input string), \u0233 = f ur (ly \u2295 x, 0)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_80",
            "start": 143,
            "end": 271,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_81@0",
            "content": "L translate = L CE (\u0233, y)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_81",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_82@0",
            "content": "The Universal Rewriter is trained on Englishcentric translation data from the high-resource languages in OPUS-100 (Zhang et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_82",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_83@0",
            "content": "Learning style-controlled translation: This objective emulates \"style-controlled translation\" in a self-supervised manner, via backtranslation through English.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_83",
            "start": 0,
            "end": 158,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_83@1",
            "content": "Consider x 1 and x 2 to be two non-overlapping spans in mC4 in language lx, Complex exemplars",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_83",
            "start": 160,
            "end": 252,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_83@2",
            "content": "1. The static charges remain on an object until they either bleed off to ground or are quickly neutralized by a discharge.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_83",
            "start": 254,
            "end": 375,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_83@3",
            "content": "2. It is particularly famous for the cultivation of kiwifruit.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_83",
            "start": 377,
            "end": 438,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_83@4",
            "content": "3. Notably absent from the city are fortifications and military structures.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_83",
            "start": 440,
            "end": 514,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_83@5",
            "content": "Simple exemplars",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_83",
            "start": 516,
            "end": 531,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_83@6",
            "content": "1. Static charges last until they are grounded or discharged.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_83",
            "start": 533,
            "end": 593,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_83@7",
            "content": "2. This area is known for growing kiwifruit.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_83",
            "start": 595,
            "end": 638,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_83@8",
            "content": "3. Some things important missing from the city are protective buildings and military buildings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_83",
            "start": 640,
            "end": 734,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_84@0",
            "content": "x en 2 = f ur (en \u2295 x 2 , \u2212f style (x 1 )) x2 = f ur (lx \u2295 x en 2 , f style (x 1 )) L BT = L CE (x 2 , x 2 )",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_84",
            "start": 0,
            "end": 107,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_85@0",
            "content": "Positive sentiment exemplars",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_85",
            "start": 0,
            "end": 27,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_85@1",
            "content": "1. The most comfortable bed I've ever slept on, I highly recommend it.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_85",
            "start": 29,
            "end": 98,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_85@2",
            "content": "2. I loved it.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_85",
            "start": 100,
            "end": 113,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_85@3",
            "content": "3. The movie was fantastic.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_85",
            "start": 115,
            "end": 141,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_86@0",
            "content": "Negative sentiment exemplars",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_86",
            "start": 0,
            "end": 27,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_86@1",
            "content": "1. The most uncomfortable bed I've ever slept on, I would never recommend it.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_86",
            "start": 29,
            "end": 105,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_86@2",
            "content": "2. I hated it.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_86",
            "start": 107,
            "end": 120,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_86@3",
            "content": "3. The movie was awful.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_86",
            "start": 122,
            "end": 144,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_87@0",
            "content": "Due to the absence of a style classification dataset in Indic languages, we built our multilingual classifier drawing inspiration from recent research in zero-shot cross-lingual transfer (Conneau et al., 2018;Conneau and Lample, 2019;Pfeiffer et al., 2020b).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_87",
            "start": 0,
            "end": 257,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_87@1",
            "content": "We experimented with three zero-shot transfer techniques while selecting our classifiers for evaluating multilingual style transfer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_87",
            "start": 259,
            "end": 390,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_88@0",
            "content": "TRANSLATE TRAIN: The first technique uses the hypothesis that style is preserved across translation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_88",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_88@1",
            "content": "We classify the style of English sentences in the Samanantar translation dataset (Ramesh et al., 2021) using a style classifier trained on English formality data from Krishna et al. (2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_88",
            "start": 101,
            "end": 289,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_88@2",
            "content": "We use the human translated Indic languages sentences as training data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_88",
            "start": 291,
            "end": 361,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_88@3",
            "content": "This training data is used to fine-tune a large-scale multilingual language model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_88",
            "start": 363,
            "end": 444,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_88@4",
            "content": "ZERO-SHOT: The second technique fine-tunes large-scale multilingual language models on a English style transfer dataset, and applies it zero-shot on multilingual data during inference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_88",
            "start": 446,
            "end": 629,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_89@0",
            "content": "MAD-X: Introduced by Pfeiffer et al. (2020b), this technique is similar to ZERO-SHOT but additionally uses language-specific parameters (\"adapters\") during inference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_89",
            "start": 0,
            "end": 165,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_89@1",
            "content": "These language-specific adapters have been originally trained using masked language modeling on the desired language data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_89",
            "start": 167,
            "end": 288,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_89@2",
            "content": "Dataset for evaluating classifiers: We conduct our experiments on Hindi formality classification, leveraging our evaluation datasets from Section 5.1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_89",
            "start": 290,
            "end": 439,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_89@3",
            "content": "We removed pairs which did not have full agreement across the three annotators and those pairs which had the consensus rating of \"Equal\" formality.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_89",
            "start": 441,
            "end": 587,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_89@4",
            "content": "This filtering process leaves us with 316 pairs in Hindi (out of 1000).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_89",
            "start": 589,
            "end": 659,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_89@5",
            "content": "In our experiments, we check whether the classifiers give a higher score to the more formal sentence in the pair.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_89",
            "start": 661,
            "end": 773,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_90@0",
            "content": "We leverage the multilingual classifiers open-sourced 17 by Krishna et al. ( 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_90",
            "start": 0,
            "end": 82,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_90@1",
            "content": "These models have been trained on the English GYAFC formality classification dataset (Rao and Tetreault, 2018), and have been shown to be effective on the XFORMAL dataset (Briakou et al., 2021b) for formality classification in Italian, French and Brazilian Portuguese.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_90",
            "start": 84,
            "end": 351,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_90@2",
            "content": "13 These classifiers were trained on preprocessed data which had trailing punctuation stripped and English sentences lower-cased, encouraging the models to focus on lexical and syntactic choices.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_90",
            "start": 353,
            "end": 547,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_90@3",
            "content": "As base multilingual language models, we use (1) mBERT-base from Devlin et al. ( 2019); (2) XLM-RoBERTabase from Conneau et al. (2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_90",
            "start": 549,
            "end": 683,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_91@0",
            "content": "Results: Our results on Hindi are presented in Table 6 and other languages in Table 7.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_91",
            "start": 0,
            "end": 85,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_91@1",
            "content": "Consistent with Pfeiffer et al. (2020b), we find MAD-X to be a superior zero-shot cross lingual transfer method compared to baselines.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_91",
            "start": 87,
            "end": 220,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_91@2",
            "content": "We also find XLM-R has better multilingual representations than mBERT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_91",
            "start": 222,
            "end": 291,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_91@3",
            "content": "Unfortunately, AdapterHub (Pfeiffer et al., 2020a) has XLM-R language adapters available only for Hindi & Tamil (among Indic languages).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_91",
            "start": 293,
            "end": 428,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_91@4",
            "content": "For other languages we use the ZERO-SHOT technique on XLM-R, consistent with the recommendations 13 provided by Krishna et al. (2020) based on their experiments on XFORMAL (Briakou et al., 2021b).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_91",
            "start": 430,
            "end": 625,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_92@0",
            "content": "Model Accuracy (\u2191)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_92",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_93@0",
            "content": "We considered three models for evaluating semantic similarity between the input and output:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_93",
            "start": 0,
            "end": 90,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_94@0",
            "content": "(1) LaBSE (Feng et al., 2020);",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_94",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_95@0",
            "content": "(2) m-USE (Yang et al., 2020);",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_95",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_96@0",
            "content": "(3) multilingual Sentence-BERT (Reimers and Gurevych, 2020), the knowledge-distilled variant paraphrase-xlm-r-multilingual-v1",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_96",
            "start": 0,
            "end": 124,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_97@0",
            "content": "Among these models, only LaBSE has support for all the Indic languages we were interested in.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_97",
            "start": 0,
            "end": 92,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_98@0",
            "content": "No Indic language is supported by m-USE, and multilingual Sentence-BERT has been trained on parallel data only for Hindi, Gujarati and Marathi among our Indic languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_98",
            "start": 0,
            "end": 168,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_98@1",
            "content": "However, in terms of Semantic Textual Similarity (STS) benchmarks (Cer et al., 2017) for English, Arabic & Spanish, m-USE and Sentence-BERT outperform LaBSE (Table 1 in Reimers and Gurevych, 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_98",
            "start": 170,
            "end": 366,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_99@0",
            "content": "LaBSE correlates better than Sentence-BERT with our human-annotated formality dataset:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_99",
            "start": 0,
            "end": 85,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_100@0",
            "content": "We measured the Spearman's rank correlation between the semantic similarity annotations on our human-annotated formality datasets (Section 5.1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_100",
            "start": 0,
            "end": 143,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_100@1",
            "content": "We discarded 10% sentence pairs which had no agreement among three annotators and took the majority vote for the other sentence pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_100",
            "start": 145,
            "end": 278,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_100@2",
            "content": "We assigned \"Different Meaning\" a score of 0, \"Slight Difference in Meaning\" a score of 1 and \"Approximately Same Meaning\" a score of 2 before measuring Spearman's rank correlation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_100",
            "start": 280,
            "end": 460,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_100@3",
            "content": "In",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_100",
            "start": 462,
            "end": 463,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_101@0",
            "content": "In Section 6, we set our LaBSE threshold L to 0.75.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_101",
            "start": 0,
            "end": 50,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_102@0",
            "content": "In this section, we present our evaluations with a more and less conservative value of L.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_102",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_103@0",
            "content": "In Table 17, we present results with L = 0.65, and in Table 18 we set L = 0.85.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_103",
            "start": 0,
            "end": 78,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_103@1",
            "content": "Compared to Table 1, trends are mostly similar, with DIFFUR models and INDIC variants outperforming counterparts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_103",
            "start": 80,
            "end": 192,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_103@2",
            "content": "Note that the absolute values of SIM and AGG metrics differ, with absolute values going down with the stricter threshold of L = 0.85, and up with the relaxed threshold of L = 0.65.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_103",
            "start": 194,
            "end": 373,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_104@0",
            "content": "To verify these three thresholds are reasonable choices, we measure the LaBSE similarity of the sentence pairs annotated by humans, and compare the LaBSE scores to human semantic similarity annotations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_104",
            "start": 0,
            "end": 201,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_104@1",
            "content": "We pool the \"Approximately Same Meaning\" and \"Slight Difference in Meaning\" categories as \"same\", and consider only sentence pairs with a majority rating of \"same\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_104",
            "start": 203,
            "end": 366,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_104@2",
            "content": "In",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_104",
            "start": 368,
            "end": 369,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_105@0",
            "content": "In Figure 16, we show screenshots of our crowdsourcing interface along with all the instructions shown to crowdworkers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_105",
            "start": 0,
            "end": 118,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_105@1",
            "content": "The instructions were written after consulting professional Indian linguists.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_105",
            "start": 120,
            "end": 196,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_105@2",
            "content": "Each crowdworker was allowed to annotate a maximum of 50 different sentence pairs per language, paying them $0.05 per pair.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_105",
            "start": 198,
            "end": 320,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_105@3",
            "content": "For formality classification, we showed crowdworkers two sentences and asked them to choose which one is more formal.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_105",
            "start": 322,
            "end": 438,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_105@4",
            "content": "Crowdworkers were allowed to mark ties using an \"Equal\" option.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_105",
            "start": 440,
            "end": 502,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_105@5",
            "content": "For semantic similarity annotation, we showed crowdworkers the sentence pair and provided three options -\"approximately same meaning\", \"slight difference in meaning\", \"different meaning\", to emulate a 3-point Likert scale.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_105",
            "start": 504,
            "end": 725,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_105@6",
            "content": "While performing our human evaluation (Section 5.7), we use a 0.5 SIM score for \"slight difference in meaning\" and a 1.0 SIM score for \"approximately same meaning\" annotations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_105",
            "start": 727,
            "end": 902,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_105@7",
            "content": "For every system considered, we analyzed the same set of 200 input sentences for style transfer performance, and 100 of those sentences for evaluating controllability.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_105",
            "start": 904,
            "end": 1070,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_105@8",
            "content": "We removed sentences which were exact copies of the input (after removing trailing punctuation) or were in the wrong language to save annotator time and cost.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_105",
            "start": 1072,
            "end": 1229,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_105@9",
            "content": "When outputs were exact copies of the input, we assigned SIM = 100, ACC = 0, AGG = 0.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_105",
            "start": 1231,
            "end": 1315,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_106@0",
            "content": "In Table 10 and Table 11 we show the interannotator agreement statistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_106",
            "start": 0,
            "end": 72,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_106@1",
            "content": "We measure Fleiss Kappa (Fleiss, 1971), Randolph Kappa (Randolph, 2005Warrens, 2010), the fraction of sentence pairs with total agreement between the three annotators and the fraction of sentence pairs with no agreement.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_106",
            "start": 74,
            "end": 293,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_106@2",
            "content": "18 In the table we can see all agreement statis- 18 The \u03ba scores are measured using the library https: //github.com/statsmodels/statsmodels.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_106",
            "start": 295,
            "end": 434,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_107@0",
            "content": "Unlike some prior works, we avoid evaluation of output fluency due to the following reasons:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_107",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_108@0",
            "content": "(1) lack of fluency evaluation tools for Indic languages; 19 (2) fluency evaluation often discriminates against styles which are out-of-distribution for the fluency classifier, as discussed in Appendix A.8 of Krishna et al. ( 2020); (3) several prior works (Pang, 2019;Mir et al., 2019;Krishna et al., 2020) have recommended against using perplexity of style language models for fluency evaluation since it is unbounded and favours unnatural sentences with common words; (4) large language models are known to produce fluent text as perceived by humans (Ippolito et al., 2020;Akoury et al., 2020), reducing the need for this evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_108",
            "start": 0,
            "end": 635,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_109@0",
            "content": "Language Consistency (LANG): Since our semantic similarity metric LaBSE is languageagnostic, it tends to ignore accidental translations, which are common errors in large multilingual transformers (Xue et al., 2021a,b), especially the Universal Rewriter (Section 3.1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_109",
            "start": 0,
            "end": 266,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_109@1",
            "content": "Hence, we check whether the output sentence is in the same language as the input, using langdetect.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_109",
            "start": 268,
            "end": 366,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_109@2",
            "content": "20",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_109",
            "start": 368,
            "end": 369,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_110@0",
            "content": "Output Diversity (COPY, 1-g): As discussed in Section 3.1, the Universal Rewriter has a strong tendency to copy the input verbatim.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_110",
            "start": 0,
            "end": 130,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_110@1",
            "content": "We build two metrics to measure output diversity compared to the input, which have been previously used for extractive question answering evaluation (Rajpurkar et al., 2016).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_110",
            "start": 132,
            "end": 305,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_110@2",
            "content": "The first metric COPY measures the fraction of outputs which were copied verbatim from the input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_110",
            "start": 307,
            "end": 403,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_110@3",
            "content": "This is done after removing trailing punctuation, to penalize models generations which solely modify punctuation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_110",
            "start": 405,
            "end": 517,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_110@4",
            "content": "A second metric 1-g measures the unigram overlap F1 score between the input and output.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_110",
            "start": 519,
            "end": 605,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_110@5",
            "content": "A diverse style transfer system should minimize both COPY and 1-g.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_110",
            "start": 607,
            "end": 672,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_111@0",
            "content": "We follow the setup in Section 5.6 to first compute a \u03bb max per system.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_111",
            "start": 0,
            "end": 70,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_111@1",
            "content": "We then compute the following, 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_111",
            "start": 72,
            "end": 104,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_111@2",
            "content": "Style Transfer Performance (r-AGG): An ideal system should have good overall performance (Section 5.5) across different values in the range \u039b.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_111",
            "start": 106,
            "end": 247,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_112@0",
            "content": "2. Average Style Score Increase (INCR): As our control value increases, we want the classifier's target style score (compared to the input) to increase.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_112",
            "start": 0,
            "end": 151,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_112@1",
            "content": "Additionally, we want the style score increase of \u03bb max to be as high as possible, indicating the system can span the range of classifier scores.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_112",
            "start": 153,
            "end": 297,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_113@0",
            "content": "Style Calibration to \u03bb (CALIB, C-IN):",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_113",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_114@0",
            "content": "As defined in Section 5.6.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_114",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_114@1",
            "content": "We additionally also measure calibration by including the input sentence x in the CALIB(x) calculation, treating it as the output for \u03bb = 0 (no style transfer).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_114",
            "start": 27,
            "end": 186,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_114@2",
            "content": "Here, calibration is averaged over a total of n = 6 (\u03bb 1 , \u03bb 2 ) pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_114",
            "start": 188,
            "end": 258,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_114@3",
            "content": "We call this metric C-IN.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_114",
            "start": 260,
            "end": 284,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_115@0",
            "content": "A detailed breakdown of performance by different metrics for every model is shown in Table 14.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_115",
            "start": 0,
            "end": 93,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_116@0",
            "content": "This section describes the ablation experiments conducted for the DIFFUR modeling choices in Section 4.2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_116",
            "start": 0,
            "end": 104,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_116@1",
            "content": "We ablate a DIFFUR-INDIC model trained on Hindi paraphrase data only, and present results for Hindi formality transfer in Table 15.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_116",
            "start": 106,
            "end": 236,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_117@0",
            "content": "no paraphrase: We replaced the paraphrase noise function with the random token dropping / replacing noise used in the denoising objective of UR model (Section 3), and continued to use vector differences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_117",
            "start": 0,
            "end": 202,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_117@1",
            "content": "As seen in Table 15, this significantly increases the copy rate, which lowers the style transfer performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_117",
            "start": 204,
            "end": 312,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_118@0",
            "content": "no paraphrase semantic filtering: We keep a setup identical to Section 4.2, but avoid the LaBSE filtering done (discarding pairs having a LaBSE score outside [0.7, 0.98]) to remove noisy paraphrases or exact copies.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_118",
            "start": 0,
            "end": 214,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_118@1",
            "content": "As seen in Table 15, this decreases the semantic similarity score of the generations, lowering the overall performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_118",
            "start": 216,
            "end": 334,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_119@0",
            "content": "no vector differences: Instead of using vector differences for DIFFUR-INDIC, we simply set s diff = f style (x), or the style of the target sentence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_119",
            "start": 0,
            "end": 148,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_120@0",
            "content": "In Table 15, we see this significantly decreases SIM scores, and LANG scores for \u03bb = 2.0.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_120",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_120@1",
            "content": "We hypothesize that this training encourages the model to rely more heavily on the style vectors, ignoring the paraphrase input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_120",
            "start": 90,
            "end": 217,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_120@2",
            "content": "This could happen since the style vectors are solely constructed from the output sentence itself, and semantic information / confounding style is not subtracted out.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_120",
            "start": 219,
            "end": 383,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_120@3",
            "content": "In other words, the model is behaving more like an autoencoder (through the style vector) instead of a denoising autoencoder with stylistic supervision.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_120",
            "start": 385,
            "end": 536,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_121@0",
            "content": "-mC4 instead of Samanantar: Instead of creating pseudo-parallel data with Samanantar, we leverage the mC4 dataset itself which was used to train the UR model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_121",
            "start": 0,
            "end": 157,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_121@1",
            "content": "We backtranslate spans of text from the Hindi split of mC4 on-the-fly using the UR translation capabilities, and use it as the \"paraphrase noise function\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_121",
            "start": 159,
            "end": 313,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_121@2",
            "content": "To ensure translation performance does not deteriorate during training, 50% minibatches are supervised translation between Hindi and English.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_121",
            "start": 315,
            "end": 455,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_121@3",
            "content": "In Table 15, we see decent overall performance, but the LANG score is 6% lower than DIFFUR-INDIC.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_121",
            "start": 457,
            "end": 553,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_121@4",
            "content": "Qualitatively we found that the model often translates a few Hindi words to English while making text informal.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_121",
            "start": 555,
            "end": 665,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_121@5",
            "content": "Due to sparsity of English tokens, it often escapes penalization from LANG.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_121",
            "start": 667,
            "end": 741,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_122@0",
            "content": "-mC4 + exemplar instead of target: This setting is similar to the previous one, but in addition to the mC4 dataset we utilize the vector difference between the style vector of the exemplar span (instead of target span), and the \"paraphrase noised\" input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_122",
            "start": 0,
            "end": 253,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_123@0",
            "content": "Results in Table 15 show this method is not effective, and it's important for the vector difference to model the precise transformation needed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_123",
            "start": 0,
            "end": 142,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_124@0",
            "content": "We experiment with five decoding schemes on the Hindi formality validation set -beam search with beam size 1, 4 and top-p sampling (Holtzman et al., 2020) with p = 0.6, 0.75, 0.9.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_124",
            "start": 0,
            "end": 178,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_125@0",
            "content": "In Table 16, we present results at a constant style transfer magnitude (\u03bb = 3.0).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_125",
            "start": 0,
            "end": 80,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_125@1",
            "content": "Consistent with Krishna et al. (2020), we find that top-p decoding usually gets higher style accuracy (r-ACC, a-ACC) and output diversity (1-g, COPY) scores, but lower similarity (SIM) scores.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_125",
            "start": 82,
            "end": 273,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_125@2",
            "content": "Overall beam search triumphs since the loss in semantic similarity leads to a worse performing model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_125",
            "start": 275,
            "end": 375,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_125@3",
            "content": "In Figure 9, we see a consistent trend across different magnitudes of style transfer (\u03bb).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_125",
            "start": 377,
            "end": 465,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_125@4",
            "content": "In all our main experiments, we use beam search with beam size 4 to obtain our generations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_125",
            "start": 467,
            "end": 557,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_126@0",
            "content": "In Figure 10, we present the variation in style transfer performance with number of training steps for our best model, the DIFFUR-MLT model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_126",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_126@1",
            "content": "We find that with more training steps performance generally improves, but improvements saturate after 8k steps.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_126",
            "start": 141,
            "end": 251,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_126@2",
            "content": "We also see the peak of the graphs (best style transfer performance) shift rightwards, indicating a preference for higher \u03bb values.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_126",
            "start": 253,
            "end": 383,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_127@0",
            "content": "The Universal Rewriter models succeed in learning an effective style space, useful for few-shot style transfer. But can this metric space also act as a style classifier? To explore this, we measure the cosine distance between the mean style vector of our informal exemplars, 21 and the style vectors derived by passing human-annotated formal/informal pairs (from our dataset of Section 5.1) through f style .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_127",
            "start": 0,
            "end": 407,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_127@1",
            "content": "We only consider pairs which had complete agreement among annotators.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_127",
            "start": 409,
            "end": 477,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_127@2",
            "content": "In Table 12 we see good agreement (68.2%-80.7%) between human annotations and the classifier derived from the metric space of the UR-INDIC model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_127",
            "start": 479,
            "end": 623,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_127@3",
            "content": "Agreement is lower (67.0%-74.3%) for the DIFFUR-INDIC model, likely due to the stop gradient used in Section 4.2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_127",
            "start": 625,
            "end": 737,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_127@4",
            "content": "With DIFFUR-MLT, agreement jumps back up to 75%-81.7% since gradients flow into the style extractor as well.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_127",
            "start": 739,
            "end": 846,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_128@0",
            "content": "In Appendix H.1, we saw that the metric vector space derived from the style encoder f style of various models is an effective style classifier, using the informal exemplar vectors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_128",
            "start": 0,
            "end": 179,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_128@1",
            "content": "In",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_128",
            "start": 181,
            "end": 182,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_129@0",
            "content": "A full breakdown of results by individual metrics, along with plots showing variation with change in 21 See Appendix D for the exemplar sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_129",
            "start": 0,
            "end": 145,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_129@1",
            "content": "We found the informal exemplars more effective than formal exemplars for style classification; Appendix H.2 has a comparison.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_129",
            "start": 147,
            "end": 271,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_129@2",
            "content": "\u03bb, is provided for -Hindi (Table 19, Figure 11), Bengali (Table 20, Figure 12), Kannada (Table 21, Figure 13), Telugu (Table 22, Figure 14), Gujarati (Table 23, Figure 15).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_129",
            "start": 273,
            "end": 444,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_130@0",
            "content": "In the baseline Hindi UR model, we notice high COPY rates (45.4%), resulting in lower ACC scores.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_130",
            "start": 0,
            "end": 96,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_130@1",
            "content": "COPY reduces in our proposed models (4.4% for DIFFUR-MLT), which boosts overall performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_130",
            "start": 98,
            "end": 189,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_130@2",
            "content": "We find the lowest COPY (and lowest 1-g) for models with +BT (1%), which is due to two steps of translation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_130",
            "start": 191,
            "end": 298,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_130@3",
            "content": "However, this lowers semantic similarity (also seen in Table 3) lowering the overall score compared to DIFFUR-MLT (60.0 vs 78.1 r-AGG).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_130",
            "start": 300,
            "end": 434,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_131@0",
            "content": "Please refer to Figure 8.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_131",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_131@1",
            "content": "In the main body, Figure 4 has a few examples as well with detailed analysis.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_131",
            "start": 26,
            "end": 102,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_131@2",
            "content": "and style accuracy (r-ACC, a-ACC) improves as we move down the table, but compromise semantic preservation (SIM), bringing the overall performance (r-AGG, a-AGG) down.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_131",
            "start": 104,
            "end": 270,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_131@3",
            "content": "Also see Figure 9 for a comparison across \u03bb values, and Section 5 for detailed metric descriptions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_131",
            "start": 272,
            "end": 370,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_131@4",
            "content": "19 for a individual metric breakdown of the models at the best performing \u03bb).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_131",
            "start": 372,
            "end": 448,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_131@5",
            "content": "The plots show overall style transfer performance, using the r-AGG (top-left) and a-AGG (top-right) metrics from Section 5.5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_131",
            "start": 450,
            "end": 574,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_131@6",
            "content": "We see the DIFFUR models outperform other systems across the \u03bb range, and get best performance with the DIFFUR-MLT variant.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_131",
            "start": 576,
            "end": 698,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_131@7",
            "content": "We also see that DIFFUR models, especially with DIFFUR-MLT, lead to better style transfer control (bottom plot, closer to x = 1 is better), giving large style variation with \u03bb without loss in semantics (X-axis).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_131",
            "start": 700,
            "end": 910,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_131@8",
            "content": "20 for a individual metric breakdown of the models at the best performing \u03bb).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_131",
            "start": 912,
            "end": 988,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_131@9",
            "content": "The plots show overall style transfer performance, using the r-AGG (top-left) and a-AGG (top-right) metrics from Section 5.5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_131",
            "start": 990,
            "end": 1114,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_131@10",
            "content": "We see the DIFFUR models outperform other systems across the \u03bb range, and get best performance with the DIFFUR-MLT variant.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_131",
            "start": 1116,
            "end": 1238,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_131@11",
            "content": "We also see that DIFFUR models, especially with DIFFUR-MLT, lead to better style transfer control (bottom plot, closer to x = 1 is better), giving large style variation with \u03bb without loss in semantics (X-axis).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_131",
            "start": 1240,
            "end": 1450,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_131@12",
            "content": "21 for a individual metric breakdown of the models at the best performing \u03bb).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_131",
            "start": 1452,
            "end": 1528,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_131@13",
            "content": "The plots show overall style transfer performance, using the r-AGG (top-left) and a-AGG (top-right) metrics from Section 5.5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_131",
            "start": 1530,
            "end": 1654,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_131@14",
            "content": "We see the DIFFUR models outperform other systems across the \u03bb range, and get best performance with the DIFFUR-MLT variant.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_131",
            "start": 1656,
            "end": 1778,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_131@15",
            "content": "We also see that DIFFUR models, especially with DIFFUR-MLT, lead to better style transfer control (bottom plot, closer to x = 1 is better), giving large style variation with \u03bb without loss in semantics (X-axis).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_131",
            "start": 1780,
            "end": 1990,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_131@16",
            "content": "23 for a individual metric breakdown of the models at the best performing \u03bb).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_131",
            "start": 1992,
            "end": 2068,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_131@17",
            "content": "The plots show overall style transfer performance, using the r-AGG (top-left) and a-AGG (top-right) metrics from Section 5.5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_131",
            "start": 2070,
            "end": 2194,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_131@18",
            "content": "Note that Gujarati is a zero-shot language for DIFFUR models -no Gujarati paraphrase data was seen during training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_131",
            "start": 2196,
            "end": 2310,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_131@19",
            "content": "We see that while the vanilla DIFFUR model performs poorly, the DIFFUR-INDIC is competitive with baselines and the DIFFUR-MLT variant significantly outperforms other systems.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_131",
            "start": 2312,
            "end": 2485,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_131@20",
            "content": "We also see that the DIFFUR-MLT variant lead to better style transfer control (bottom plot, closer to x = 1 is better), giving style variation with \u03bb without loss in semantics (X-axis).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_131",
            "start": 2487,
            "end": 2671,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_132@0",
            "content": "Figure 16: Our crowdsourcing interface on Task Mate, used to build our formality evaluation datasets (Section 5.1) and conduct human evaluations (Section 5.7).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_132",
            "start": 0,
            "end": 158,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_132@1",
            "content": "The first row shows our landing page and instruction set derived from our conversations with professional linguists.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_132",
            "start": 160,
            "end": 275,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_132@2",
            "content": "The second row shows our qualification questions for formality classification, and the third row shows templates for the two questions asked to crowdworkers per pair.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_132",
            "start": 277,
            "end": 442,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_133@0",
            "content": "UNKNOWN, None, 2013, Hindi: An essential grammar, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_133",
            "start": 0,
            "end": 50,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_134@0",
            "content": "Nader Akoury, Shufan Wang, Josh Whiting, Stephen Hood, Nanyun Peng, Mohit Iyyer, STO-RIUM: A Dataset and Evaluation Platform for Machine-in-the-Loop Story Generation, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_134",
            "start": 0,
            "end": 318,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_135@0",
            "content": "UNKNOWN, None, 2012, Generalizing words to desensitize text. Transactions on Data Privacy, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_135",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_136@0",
            "content": "Kalika Bali, Jatin Sharma, Monojit Choudhury, Yogarshi Vyas, i am borrowing ya mixing?\" an analysis of english-hindi code mixing in facebook, 2014, Proceedings of the First Workshop on Computational Approaches to Code Switching, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_136",
            "start": 0,
            "end": 229,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_137@0",
            "content": "Su Lin,  Blodgett, Sociolinguistically driven approaches for just natural language processing, 2021, UMass Amherst Doctoral Dissertations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_137",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_138@0",
            "content": "UNKNOWN, None, 2018, , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_138",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_139@0",
            "content": "UNKNOWN, None, , Joel Tetreault, and Marine Carpuat. 2021a. A review of human evaluation for style transfer, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_139",
            "start": 0,
            "end": 109,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_140@0",
            "content": "Eleftheria Briakou, Di Lu, Ke Zhang, Joel Tetreault, Ol\u00e1, bonjour, salve! XFORMAL: A benchmark for multilingual formality style transfer, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_140",
            "start": 0,
            "end": 337,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_141@0",
            "content": "UNKNOWN, None, 2021, Quality at a glance: An audit of web-crawled multilingual datasets, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_141",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_142@0",
            "content": "UNKNOWN, None, 2020, Evaluation of text generation: A survey, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_142",
            "start": 0,
            "end": 62,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_143@0",
            "content": "Daniel Cer, Mona Diab, Eneko Agirre, I\u00f1igo Lopez-Gazpio, Lucia Specia, SemEval-2017 task 1: Semantic textual similarity multilingual and crosslingual focused evaluation, 2017, Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017), Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_143",
            "start": 0,
            "end": 303,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_144@0",
            "content": "Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettlemoyer, Veselin Stoyanov, Unsupervised cross-lingual representation learning at scale, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_144",
            "start": 0,
            "end": 322,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_145@0",
            "content": "Alexis Conneau, Guillaume Lample, Crosslingual language model pretraining, 2019, Proceedings of Advances in Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_145",
            "start": 0,
            "end": 147,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_146@0",
            "content": "UNKNOWN, None, 2018, XNLI: Evaluating Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_146",
            "start": 0,
            "end": 151,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_147@0",
            "content": "Benjamin Marie, Atsushi Fujita, Raphael Rubino, Scientific credibility of machine translation research: A meta-evaluation of 769 papers, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_147",
            "start": 0,
            "end": 318,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_148@0",
            "content": "Remi Mir, Bjarke Felbo, Nick Obradovich, Iyad Rahwan, Evaluating style transfer for text, 2019, Conference of the North American Chapter, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_148",
            "start": 0,
            "end": 179,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_149@0",
            "content": "UNKNOWN, None, 2010, Language detection library for java, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_149",
            "start": 0,
            "end": 58,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_150@0",
            "content": "Xing Niu, Marine Carpuat, Controlling neural machine translation formality with synthetic supervision, 2020, Association for the Advancement of Artificial Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_150",
            "start": 0,
            "end": 169,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_151@0",
            "content": "Xing Niu, Sudha Rao, Marine Carpuat, Multi-task neural models for translating between styles within and across languages, 2018, Proceedings of the 27th International Conference on Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_151",
            "start": 0,
            "end": 207,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_152@0",
            "content": "Pang Richard Yuanzhe, Towards actual (not operational) textual style transfer auto-evaluation, 2019, Proceedings of the 5th Workshop on Noisy Usergenerated Text, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_152",
            "start": 0,
            "end": 162,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_153@0",
            "content": "Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, Bleu: a method for automatic evaluation of machine translation, 2002, Proceedings of the Association for Computational Linguistics. Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_153",
            "start": 0,
            "end": 232,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_154@0",
            "content": "Jonas Pfeiffer, Andreas R\u00fcckl\u00e9, Clifton Poth, Aishwarya Kamath, Ivan Vuli\u0107, Sebastian Ruder, Kyunghyun Cho, Iryna Gurevych, Adapterhub: A framework for adapting transformers, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_154",
            "start": 0,
            "end": 269,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_155@0",
            "content": "Jonas Pfeiffer, Ivan Vuli\u0107, Iryna Gurevych, Sebastian Ruder, MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer, 2020, Proceedings of Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_155",
            "start": 0,
            "end": 205,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_156@0",
            "content": "Yulia Shrimai Prabhumoye, Ruslan Tsvetkov, Alan Salakhutdinov,  Black, Style transfer through back-translation, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_156",
            "start": 0,
            "end": 248,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_157@0",
            "content": "UNKNOWN, None, , Graham Neubig, and Yulia Tsvetkov. 2021. Evaluating the morphosyntactic well-formedness of generated texts, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_157",
            "start": 0,
            "end": 125,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_158@0",
            "content": "Adithya Pratapa, Gayatri Bhat, Monojit Choudhury, Sunayana Sitaram, Sandipan Dandapat, Kalika Bali, Language modeling for code-mixing: The role of linguistic theory based synthetic data, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_158",
            "start": 0,
            "end": 293,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_159@0",
            "content": "Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang, SQuAD: 100,000+ questions for machine comprehension of text, 2016, Proceedings of Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_159",
            "start": 0,
            "end": 195,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_160@0",
            "content": "UNKNOWN, None, , Anoop Kunchukuttan, Pratyush Kumar, and Mitesh Shantadevi Khapra. 2021. Samanantar: The largest publicly available parallel corpora collection for 11 indic languages, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_160",
            "start": 0,
            "end": 184,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_161@0",
            "content": "UNKNOWN, None, 2005, Free-marginal multirater kappa (multirater k [free]): An alternative to fleiss' fixed-marginal multirater kappa, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_161",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_162@0",
            "content": "Sudha Rao, Joel Tetreault, Dear sir or madam, may I introduce the GYAFC dataset: Corpus, benchmarks and metrics for formality style transfer, 2018, Conference of the North American Chapter of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_162",
            "start": 0,
            "end": 239,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_163@0",
            "content": "Sravana Reddy, Kevin Knight, Obfuscating gender in social media writing, 2016, Proceedings of the First Workshop on NLP and Computational Social Science, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_163",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_164@0",
            "content": "UNKNOWN, None, 2021, A recipe for arbitrary text style transfer with large language models, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_164",
            "start": 0,
            "end": 92,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_165@0",
            "content": "Nils Reimers, Iryna Gurevych, Making monolingual sentence embeddings multilingual using knowledge distillation, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_165",
            "start": 0,
            "end": 263,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_166@0",
            "content": "Parker Riley, Noah Constant, Mandy Guo, Girish Kumar, David Uthus, Zarana Parekh, TextSETTR: Few-shot text style extraction and tunable targeted restyling, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_166",
            "start": 0,
            "end": 326,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_167@0",
            "content": "UNKNOWN, None, , Mohit Agrawal, and Niloy Ganguly. 2021. A hierarchical vae for calibrating attributes while generating text using normalizing flow. ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_167",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_168@0",
            "content": "UNKNOWN, None, 2019, A deep generative model for code-switched text, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_168",
            "start": 0,
            "end": 69,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_169@0",
            "content": "Mingyue Shang, Piji Li, Zhenxin Fu, Lidong Bing, Dongyan Zhao, Shuming Shi, Rui Yan, Semi-supervised text style transfer: Cross projection in latent space, 2019, Proceedings of Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_169",
            "start": 0,
            "end": 227,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_170@0",
            "content": "Tianxiao Shen, Tao Lei, Regina Barzilay, Tommi Jaakkola, Style transfer from non-parallel text by cross-alignment, 2017, Advances in neural information processing systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_170",
            "start": 0,
            "end": 172,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_171@0",
            "content": "Rakshith Shetty, Bernt Schiele, Mario Fritz, A4nt: author attribute anonymity by adversarial training of neural machine translation, 2018, 27th {USENIX} Security Symposium ({USENIX} Security 18), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_171",
            "start": 0,
            "end": 196,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_172@0",
            "content": "UNKNOWN, None, 2020, Controlling style in generated dialogue, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_172",
            "start": 0,
            "end": 62,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_173@0",
            "content": "Sandeep Subramanian, Guillaume Lample, Eric Smith, Ludovic Denoyer, Marc'aurelio Ranzato, Y-Lan Boureau, Multiple-attribute text style transfer, 2019, Proceedings of the International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_173",
            "start": 0,
            "end": 224,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_174@0",
            "content": "Aleksey Tikhonov, P Ivan,  Yamshchikov, Sounds wilde. phonetically extended embeddings for author-stylized poetry generation, 2018, Proceedings of the Fifteenth Workshop on Computational Research in Phonetics, Phonology, and Morphology, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_174",
            "start": 0,
            "end": 237,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_175@0",
            "content": "Alexey Tikhonov, Viacheslav Shibaev, Aleksander Nagaev, Aigul Nugmanova, Ivan Yamshchikov, Style transfer for texts: Retrain, report errors, compare with rewrites, 2019, Proceedings of Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_175",
            "start": 0,
            "end": 235,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_176@0",
            "content": "Ke Wang, Hang Hua, Xiaojun Wan, Controllable unsupervised text attribute transfer via editing entangled latent representation, 2019, Advances in Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_176",
            "start": 0,
            "end": 184,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_177@0",
            "content": "UNKNOWN, None, 2010, Inequalities between multirater kappas. Advances in data analysis and classification, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_177",
            "start": 0,
            "end": 107,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_178@0",
            "content": "John Wieting, Kevin Gimpel, ParaNMT-50M: Pushing the limits of paraphrastic sentence embeddings with millions of machine translations, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_178",
            "start": 0,
            "end": 271,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_179@0",
            "content": "UNKNOWN, None, 2019, Unsupervised data augmentation for consistency training, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_179",
            "start": 0,
            "end": 78,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_180@0",
            "content": "Peng Xu, Jackie Chi Kit Cheung, Yanshuai Cao, On variational learning of controllable representations for text without supervision, 2020, Proceedings of the 37th International Conference on Machine Learning, PMLR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_180",
            "start": 0,
            "end": 212,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_181@0",
            "content": "Wei Xu, Chris Callison-Burch, Courtney Napoles, Problems in current text simplification research: New data can help, 2015, Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_181",
            "start": 0,
            "end": 186,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_182@0",
            "content": "Wei Xu, Alan Ritter, Bill Dolan, Ralph Grishman, Colin Cherry, Paraphrasing for style, 2012, Proceedings of International Conference on Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_182",
            "start": 0,
            "end": 163,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_183@0",
            "content": "UNKNOWN, None, , and Colin Raffel. 2021a. Byt5: Towards a tokenfree future with pre-trained byte-to-byte models, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_183",
            "start": 0,
            "end": 113,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_184@0",
            "content": "Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, and Colin Raffel. 2021b. mT5: A massively multilingual pre-trained text-to-text transformer, , Conference of the North American Chapter, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_184",
            "start": 0,
            "end": 277,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_185@0",
            "content": "Yinfei Yang, Daniel Cer, Amin Ahmad, Mandy Guo, Jax Law, Noah Constant, Gustavo Hernandez Abrego, Steve Yuan, Chris Tar, Yun-Hsuan Sung, Brian Strope, Ray Kurzweil, Multilingual universal sentence encoder for semantic retrieval, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, Online. Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_185",
            "start": 0,
            "end": 398,
            "label": {}
        },
        {
            "ix": "111-ARR_v1_186@0",
            "content": "Biao Zhang, Philip Williams, Ivan Titov, Rico Sennrich, Improving massively multilingual neural machine translation and zero-shot translation, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "111-ARR_v1_186",
            "start": 0,
            "end": 238,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "111-ARR_v1_0",
            "tgt_ix": "111-ARR_v1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_0",
            "tgt_ix": "111-ARR_v1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_1",
            "tgt_ix": "111-ARR_v1_2",
            "etype": "parent",
            "meta": null
        },

        {
            "src_ix": "111-ARR_v1_1",
            "tgt_ix": "111-ARR_v1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_1",
            "tgt_ix": "111-ARR_v1_3",
            "etype": "parent",
            "meta": null
        },
         {
            "src_ix": "111-ARR_v1_2",
            "tgt_ix": "111-ARR_v1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_3",
            "tgt_ix": "111-ARR_v1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_4",
            "tgt_ix": "111-ARR_v1_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_4",
            "tgt_ix": "111-ARR_v1_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_6",
            "tgt_ix": "111-ARR_v1_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_7",
            "tgt_ix": "111-ARR_v1_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_4",
            "tgt_ix": "111-ARR_v1_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_4",
            "tgt_ix": "111-ARR_v1_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_4",
            "tgt_ix": "111-ARR_v1_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_5",
            "tgt_ix": "111-ARR_v1_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_9",
            "tgt_ix": "111-ARR_v1_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_10",
            "tgt_ix": "111-ARR_v1_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_11",
            "tgt_ix": "111-ARR_v1_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_4",
            "tgt_ix": "111-ARR_v1_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_4",
            "tgt_ix": "111-ARR_v1_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_4",
            "tgt_ix": "111-ARR_v1_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_4",
            "tgt_ix": "111-ARR_v1_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_8",
            "tgt_ix": "111-ARR_v1_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_0",
            "tgt_ix": "111-ARR_v1_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_12",
            "tgt_ix": "111-ARR_v1_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_13",
            "tgt_ix": "111-ARR_v1_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_13",
            "tgt_ix": "111-ARR_v1_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_0",
            "tgt_ix": "111-ARR_v1_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_14",
            "tgt_ix": "111-ARR_v1_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_16",
            "tgt_ix": "111-ARR_v1_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_17",
            "tgt_ix": "111-ARR_v1_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_15",
            "tgt_ix": "111-ARR_v1_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_15",
            "tgt_ix": "111-ARR_v1_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_15",
            "tgt_ix": "111-ARR_v1_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_15",
            "tgt_ix": "111-ARR_v1_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_19",
            "tgt_ix": "111-ARR_v1_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_20",
            "tgt_ix": "111-ARR_v1_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_21",
            "tgt_ix": "111-ARR_v1_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_22",
            "tgt_ix": "111-ARR_v1_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_23",
            "tgt_ix": "111-ARR_v1_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_15",
            "tgt_ix": "111-ARR_v1_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_15",
            "tgt_ix": "111-ARR_v1_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_15",
            "tgt_ix": "111-ARR_v1_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_15",
            "tgt_ix": "111-ARR_v1_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_15",
            "tgt_ix": "111-ARR_v1_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_15",
            "tgt_ix": "111-ARR_v1_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_18",
            "tgt_ix": "111-ARR_v1_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_15",
            "tgt_ix": "111-ARR_v1_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_24",
            "tgt_ix": "111-ARR_v1_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_26",
            "tgt_ix": "111-ARR_v1_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_25",
            "tgt_ix": "111-ARR_v1_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_25",
            "tgt_ix": "111-ARR_v1_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_25",
            "tgt_ix": "111-ARR_v1_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_0",
            "tgt_ix": "111-ARR_v1_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_27",
            "tgt_ix": "111-ARR_v1_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_28",
            "tgt_ix": "111-ARR_v1_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_28",
            "tgt_ix": "111-ARR_v1_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_30",
            "tgt_ix": "111-ARR_v1_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_31",
            "tgt_ix": "111-ARR_v1_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_32",
            "tgt_ix": "111-ARR_v1_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_33",
            "tgt_ix": "111-ARR_v1_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_29",
            "tgt_ix": "111-ARR_v1_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_29",
            "tgt_ix": "111-ARR_v1_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_29",
            "tgt_ix": "111-ARR_v1_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_29",
            "tgt_ix": "111-ARR_v1_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_29",
            "tgt_ix": "111-ARR_v1_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_29",
            "tgt_ix": "111-ARR_v1_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_28",
            "tgt_ix": "111-ARR_v1_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_34",
            "tgt_ix": "111-ARR_v1_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_36",
            "tgt_ix": "111-ARR_v1_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_37",
            "tgt_ix": "111-ARR_v1_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_38",
            "tgt_ix": "111-ARR_v1_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_39",
            "tgt_ix": "111-ARR_v1_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_40",
            "tgt_ix": "111-ARR_v1_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_41",
            "tgt_ix": "111-ARR_v1_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_42",
            "tgt_ix": "111-ARR_v1_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_43",
            "tgt_ix": "111-ARR_v1_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_35",
            "tgt_ix": "111-ARR_v1_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_35",
            "tgt_ix": "111-ARR_v1_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_35",
            "tgt_ix": "111-ARR_v1_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_35",
            "tgt_ix": "111-ARR_v1_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_35",
            "tgt_ix": "111-ARR_v1_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_35",
            "tgt_ix": "111-ARR_v1_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_35",
            "tgt_ix": "111-ARR_v1_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_35",
            "tgt_ix": "111-ARR_v1_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_35",
            "tgt_ix": "111-ARR_v1_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_35",
            "tgt_ix": "111-ARR_v1_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_28",
            "tgt_ix": "111-ARR_v1_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_44",
            "tgt_ix": "111-ARR_v1_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_45",
            "tgt_ix": "111-ARR_v1_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_45",
            "tgt_ix": "111-ARR_v1_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_28",
            "tgt_ix": "111-ARR_v1_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_46",
            "tgt_ix": "111-ARR_v1_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_47",
            "tgt_ix": "111-ARR_v1_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_47",
            "tgt_ix": "111-ARR_v1_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_0",
            "tgt_ix": "111-ARR_v1_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_48",
            "tgt_ix": "111-ARR_v1_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_49",
            "tgt_ix": "111-ARR_v1_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_49",
            "tgt_ix": "111-ARR_v1_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_49",
            "tgt_ix": "111-ARR_v1_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_50",
            "tgt_ix": "111-ARR_v1_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_52",
            "tgt_ix": "111-ARR_v1_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_51",
            "tgt_ix": "111-ARR_v1_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_51",
            "tgt_ix": "111-ARR_v1_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_51",
            "tgt_ix": "111-ARR_v1_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_49",
            "tgt_ix": "111-ARR_v1_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_53",
            "tgt_ix": "111-ARR_v1_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_54",
            "tgt_ix": "111-ARR_v1_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_54",
            "tgt_ix": "111-ARR_v1_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_49",
            "tgt_ix": "111-ARR_v1_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_55",
            "tgt_ix": "111-ARR_v1_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_57",
            "tgt_ix": "111-ARR_v1_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_56",
            "tgt_ix": "111-ARR_v1_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_56",
            "tgt_ix": "111-ARR_v1_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_56",
            "tgt_ix": "111-ARR_v1_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_49",
            "tgt_ix": "111-ARR_v1_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_58",
            "tgt_ix": "111-ARR_v1_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_60",
            "tgt_ix": "111-ARR_v1_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_61",
            "tgt_ix": "111-ARR_v1_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_59",
            "tgt_ix": "111-ARR_v1_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_59",
            "tgt_ix": "111-ARR_v1_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_59",
            "tgt_ix": "111-ARR_v1_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_59",
            "tgt_ix": "111-ARR_v1_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_49",
            "tgt_ix": "111-ARR_v1_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_62",
            "tgt_ix": "111-ARR_v1_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_64",
            "tgt_ix": "111-ARR_v1_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_65",
            "tgt_ix": "111-ARR_v1_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_63",
            "tgt_ix": "111-ARR_v1_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_63",
            "tgt_ix": "111-ARR_v1_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_63",
            "tgt_ix": "111-ARR_v1_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_63",
            "tgt_ix": "111-ARR_v1_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_49",
            "tgt_ix": "111-ARR_v1_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_66",
            "tgt_ix": "111-ARR_v1_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_67",
            "tgt_ix": "111-ARR_v1_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_67",
            "tgt_ix": "111-ARR_v1_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_0",
            "tgt_ix": "111-ARR_v1_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_68",
            "tgt_ix": "111-ARR_v1_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_70",
            "tgt_ix": "111-ARR_v1_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_71",
            "tgt_ix": "111-ARR_v1_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_72",
            "tgt_ix": "111-ARR_v1_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_74",
            "tgt_ix": "111-ARR_v1_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_75",
            "tgt_ix": "111-ARR_v1_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_73",
            "tgt_ix": "111-ARR_v1_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_78",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_77",
            "tgt_ix": "111-ARR_v1_78",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_79",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_78",
            "tgt_ix": "111-ARR_v1_79",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_80",
            "tgt_ix": "111-ARR_v1_81",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_81",
            "tgt_ix": "111-ARR_v1_82",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_82",
            "tgt_ix": "111-ARR_v1_83",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_83",
            "tgt_ix": "111-ARR_v1_84",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_80",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_81",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_82",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_83",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_84",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_79",
            "tgt_ix": "111-ARR_v1_80",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_85",
            "tgt_ix": "111-ARR_v1_86",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_85",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_86",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_84",
            "tgt_ix": "111-ARR_v1_85",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_87",
            "tgt_ix": "111-ARR_v1_88",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_88",
            "tgt_ix": "111-ARR_v1_89",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_87",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_88",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_89",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_86",
            "tgt_ix": "111-ARR_v1_87",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_90",
            "tgt_ix": "111-ARR_v1_91",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_90",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_91",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_89",
            "tgt_ix": "111-ARR_v1_90",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_92",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_91",
            "tgt_ix": "111-ARR_v1_92",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_93",
            "tgt_ix": "111-ARR_v1_94",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_94",
            "tgt_ix": "111-ARR_v1_95",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_95",
            "tgt_ix": "111-ARR_v1_96",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_96",
            "tgt_ix": "111-ARR_v1_97",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_97",
            "tgt_ix": "111-ARR_v1_98",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_98",
            "tgt_ix": "111-ARR_v1_99",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_99",
            "tgt_ix": "111-ARR_v1_100",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_93",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_94",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_95",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_96",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_97",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_98",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_99",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_100",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_92",
            "tgt_ix": "111-ARR_v1_93",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_101",
            "tgt_ix": "111-ARR_v1_102",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_102",
            "tgt_ix": "111-ARR_v1_103",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_101",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_102",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_103",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_100",
            "tgt_ix": "111-ARR_v1_101",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_104",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_103",
            "tgt_ix": "111-ARR_v1_104",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_105",
            "tgt_ix": "111-ARR_v1_106",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_105",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_106",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_104",
            "tgt_ix": "111-ARR_v1_105",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_107",
            "tgt_ix": "111-ARR_v1_108",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_107",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_108",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_106",
            "tgt_ix": "111-ARR_v1_107",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_109",
            "tgt_ix": "111-ARR_v1_110",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_109",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_110",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_108",
            "tgt_ix": "111-ARR_v1_109",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_111",
            "tgt_ix": "111-ARR_v1_112",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_111",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_112",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_110",
            "tgt_ix": "111-ARR_v1_111",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_15",
            "tgt_ix": "111-ARR_v1_113",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_112",
            "tgt_ix": "111-ARR_v1_113",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_114",
            "tgt_ix": "111-ARR_v1_115",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_113",
            "tgt_ix": "111-ARR_v1_114",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_113",
            "tgt_ix": "111-ARR_v1_115",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_113",
            "tgt_ix": "111-ARR_v1_114",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_116",
            "tgt_ix": "111-ARR_v1_117",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_117",
            "tgt_ix": "111-ARR_v1_118",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_118",
            "tgt_ix": "111-ARR_v1_119",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_119",
            "tgt_ix": "111-ARR_v1_120",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_120",
            "tgt_ix": "111-ARR_v1_121",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_121",
            "tgt_ix": "111-ARR_v1_122",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_122",
            "tgt_ix": "111-ARR_v1_123",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_113",
            "tgt_ix": "111-ARR_v1_116",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_113",
            "tgt_ix": "111-ARR_v1_117",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_113",
            "tgt_ix": "111-ARR_v1_118",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_113",
            "tgt_ix": "111-ARR_v1_119",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_113",
            "tgt_ix": "111-ARR_v1_120",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_113",
            "tgt_ix": "111-ARR_v1_121",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_113",
            "tgt_ix": "111-ARR_v1_122",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_113",
            "tgt_ix": "111-ARR_v1_123",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_115",
            "tgt_ix": "111-ARR_v1_116",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_124",
            "tgt_ix": "111-ARR_v1_125",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_113",
            "tgt_ix": "111-ARR_v1_124",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_113",
            "tgt_ix": "111-ARR_v1_125",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_123",
            "tgt_ix": "111-ARR_v1_124",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_113",
            "tgt_ix": "111-ARR_v1_126",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_125",
            "tgt_ix": "111-ARR_v1_126",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_113",
            "tgt_ix": "111-ARR_v1_127",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_126",
            "tgt_ix": "111-ARR_v1_127",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_113",
            "tgt_ix": "111-ARR_v1_128",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_127",
            "tgt_ix": "111-ARR_v1_128",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_129",
            "tgt_ix": "111-ARR_v1_130",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_113",
            "tgt_ix": "111-ARR_v1_129",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_113",
            "tgt_ix": "111-ARR_v1_130",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_128",
            "tgt_ix": "111-ARR_v1_129",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_131",
            "tgt_ix": "111-ARR_v1_132",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_113",
            "tgt_ix": "111-ARR_v1_131",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_113",
            "tgt_ix": "111-ARR_v1_132",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_130",
            "tgt_ix": "111-ARR_v1_131",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "111-ARR_v1_0",
            "tgt_ix": "111-ARR_v1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_1",
            "tgt_ix": "111-ARR_v1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_2",
            "tgt_ix": "111-ARR_v1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_2",
            "tgt_ix": "111-ARR_v1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_2",
            "tgt_ix": "111-ARR_v1_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_2",
            "tgt_ix": "111-ARR_v1_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_3",
            "tgt_ix": "111-ARR_v1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_3",
            "tgt_ix": "111-ARR_v1_3@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_3",
            "tgt_ix": "111-ARR_v1_3@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_3",
            "tgt_ix": "111-ARR_v1_3@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_3",
            "tgt_ix": "111-ARR_v1_3@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_3",
            "tgt_ix": "111-ARR_v1_3@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_4",
            "tgt_ix": "111-ARR_v1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_5",
            "tgt_ix": "111-ARR_v1_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_5",
            "tgt_ix": "111-ARR_v1_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_6",
            "tgt_ix": "111-ARR_v1_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_7",
            "tgt_ix": "111-ARR_v1_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_8",
            "tgt_ix": "111-ARR_v1_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_9",
            "tgt_ix": "111-ARR_v1_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_9",
            "tgt_ix": "111-ARR_v1_9@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_9",
            "tgt_ix": "111-ARR_v1_9@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_10",
            "tgt_ix": "111-ARR_v1_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_10",
            "tgt_ix": "111-ARR_v1_10@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_10",
            "tgt_ix": "111-ARR_v1_10@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_10",
            "tgt_ix": "111-ARR_v1_10@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_10",
            "tgt_ix": "111-ARR_v1_10@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_10",
            "tgt_ix": "111-ARR_v1_10@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_10",
            "tgt_ix": "111-ARR_v1_10@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_10",
            "tgt_ix": "111-ARR_v1_10@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_10",
            "tgt_ix": "111-ARR_v1_10@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_11",
            "tgt_ix": "111-ARR_v1_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_11",
            "tgt_ix": "111-ARR_v1_11@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_11",
            "tgt_ix": "111-ARR_v1_11@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_11",
            "tgt_ix": "111-ARR_v1_11@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_11",
            "tgt_ix": "111-ARR_v1_11@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_11",
            "tgt_ix": "111-ARR_v1_11@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_11",
            "tgt_ix": "111-ARR_v1_11@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_12",
            "tgt_ix": "111-ARR_v1_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_12",
            "tgt_ix": "111-ARR_v1_12@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_12",
            "tgt_ix": "111-ARR_v1_12@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_13",
            "tgt_ix": "111-ARR_v1_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_14",
            "tgt_ix": "111-ARR_v1_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_14",
            "tgt_ix": "111-ARR_v1_14@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_14",
            "tgt_ix": "111-ARR_v1_14@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_14",
            "tgt_ix": "111-ARR_v1_14@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_14",
            "tgt_ix": "111-ARR_v1_14@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_14",
            "tgt_ix": "111-ARR_v1_14@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_14",
            "tgt_ix": "111-ARR_v1_14@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_14",
            "tgt_ix": "111-ARR_v1_14@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_14",
            "tgt_ix": "111-ARR_v1_14@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_14",
            "tgt_ix": "111-ARR_v1_14@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_15",
            "tgt_ix": "111-ARR_v1_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_16",
            "tgt_ix": "111-ARR_v1_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_16",
            "tgt_ix": "111-ARR_v1_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_16",
            "tgt_ix": "111-ARR_v1_16@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_17",
            "tgt_ix": "111-ARR_v1_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_18",
            "tgt_ix": "111-ARR_v1_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_18",
            "tgt_ix": "111-ARR_v1_18@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_19",
            "tgt_ix": "111-ARR_v1_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_19",
            "tgt_ix": "111-ARR_v1_19@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_19",
            "tgt_ix": "111-ARR_v1_19@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_20",
            "tgt_ix": "111-ARR_v1_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_21",
            "tgt_ix": "111-ARR_v1_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_21",
            "tgt_ix": "111-ARR_v1_21@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_21",
            "tgt_ix": "111-ARR_v1_21@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_22",
            "tgt_ix": "111-ARR_v1_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_22",
            "tgt_ix": "111-ARR_v1_22@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_22",
            "tgt_ix": "111-ARR_v1_22@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_23",
            "tgt_ix": "111-ARR_v1_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_24",
            "tgt_ix": "111-ARR_v1_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_24",
            "tgt_ix": "111-ARR_v1_24@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_25",
            "tgt_ix": "111-ARR_v1_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_26",
            "tgt_ix": "111-ARR_v1_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_26",
            "tgt_ix": "111-ARR_v1_26@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_26",
            "tgt_ix": "111-ARR_v1_26@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_26",
            "tgt_ix": "111-ARR_v1_26@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_26",
            "tgt_ix": "111-ARR_v1_26@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_26",
            "tgt_ix": "111-ARR_v1_26@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_26",
            "tgt_ix": "111-ARR_v1_26@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_26",
            "tgt_ix": "111-ARR_v1_26@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_27",
            "tgt_ix": "111-ARR_v1_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_27",
            "tgt_ix": "111-ARR_v1_27@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_27",
            "tgt_ix": "111-ARR_v1_27@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_27",
            "tgt_ix": "111-ARR_v1_27@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_27",
            "tgt_ix": "111-ARR_v1_27@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_27",
            "tgt_ix": "111-ARR_v1_27@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_27",
            "tgt_ix": "111-ARR_v1_27@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_27",
            "tgt_ix": "111-ARR_v1_27@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_28",
            "tgt_ix": "111-ARR_v1_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_29",
            "tgt_ix": "111-ARR_v1_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_30",
            "tgt_ix": "111-ARR_v1_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_30",
            "tgt_ix": "111-ARR_v1_30@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_31",
            "tgt_ix": "111-ARR_v1_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_32",
            "tgt_ix": "111-ARR_v1_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_32",
            "tgt_ix": "111-ARR_v1_32@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_32",
            "tgt_ix": "111-ARR_v1_32@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_33",
            "tgt_ix": "111-ARR_v1_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_34",
            "tgt_ix": "111-ARR_v1_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_34",
            "tgt_ix": "111-ARR_v1_34@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_35",
            "tgt_ix": "111-ARR_v1_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_36",
            "tgt_ix": "111-ARR_v1_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_37",
            "tgt_ix": "111-ARR_v1_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_37",
            "tgt_ix": "111-ARR_v1_37@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_37",
            "tgt_ix": "111-ARR_v1_37@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_37",
            "tgt_ix": "111-ARR_v1_37@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_38",
            "tgt_ix": "111-ARR_v1_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_38",
            "tgt_ix": "111-ARR_v1_38@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_38",
            "tgt_ix": "111-ARR_v1_38@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_39",
            "tgt_ix": "111-ARR_v1_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_39",
            "tgt_ix": "111-ARR_v1_39@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_39",
            "tgt_ix": "111-ARR_v1_39@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_39",
            "tgt_ix": "111-ARR_v1_39@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_40",
            "tgt_ix": "111-ARR_v1_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_40",
            "tgt_ix": "111-ARR_v1_40@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_41",
            "tgt_ix": "111-ARR_v1_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_42",
            "tgt_ix": "111-ARR_v1_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_42",
            "tgt_ix": "111-ARR_v1_42@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_42",
            "tgt_ix": "111-ARR_v1_42@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_42",
            "tgt_ix": "111-ARR_v1_42@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_43",
            "tgt_ix": "111-ARR_v1_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_44",
            "tgt_ix": "111-ARR_v1_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_44",
            "tgt_ix": "111-ARR_v1_44@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_45",
            "tgt_ix": "111-ARR_v1_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_46",
            "tgt_ix": "111-ARR_v1_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_46",
            "tgt_ix": "111-ARR_v1_46@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_46",
            "tgt_ix": "111-ARR_v1_46@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_46",
            "tgt_ix": "111-ARR_v1_46@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_47",
            "tgt_ix": "111-ARR_v1_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_48",
            "tgt_ix": "111-ARR_v1_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_48",
            "tgt_ix": "111-ARR_v1_48@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_48",
            "tgt_ix": "111-ARR_v1_48@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_49",
            "tgt_ix": "111-ARR_v1_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_50",
            "tgt_ix": "111-ARR_v1_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_50",
            "tgt_ix": "111-ARR_v1_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_50",
            "tgt_ix": "111-ARR_v1_50@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_50",
            "tgt_ix": "111-ARR_v1_50@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_51",
            "tgt_ix": "111-ARR_v1_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_52",
            "tgt_ix": "111-ARR_v1_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_52",
            "tgt_ix": "111-ARR_v1_52@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_52",
            "tgt_ix": "111-ARR_v1_52@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_52",
            "tgt_ix": "111-ARR_v1_52@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_53",
            "tgt_ix": "111-ARR_v1_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_53",
            "tgt_ix": "111-ARR_v1_53@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_53",
            "tgt_ix": "111-ARR_v1_53@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_54",
            "tgt_ix": "111-ARR_v1_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_55",
            "tgt_ix": "111-ARR_v1_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_55",
            "tgt_ix": "111-ARR_v1_55@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_55",
            "tgt_ix": "111-ARR_v1_55@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_55",
            "tgt_ix": "111-ARR_v1_55@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_55",
            "tgt_ix": "111-ARR_v1_55@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_55",
            "tgt_ix": "111-ARR_v1_55@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_55",
            "tgt_ix": "111-ARR_v1_55@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_56",
            "tgt_ix": "111-ARR_v1_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_57",
            "tgt_ix": "111-ARR_v1_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_57",
            "tgt_ix": "111-ARR_v1_57@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_57",
            "tgt_ix": "111-ARR_v1_57@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_57",
            "tgt_ix": "111-ARR_v1_57@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_57",
            "tgt_ix": "111-ARR_v1_57@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_58",
            "tgt_ix": "111-ARR_v1_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_58",
            "tgt_ix": "111-ARR_v1_58@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_58",
            "tgt_ix": "111-ARR_v1_58@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_59",
            "tgt_ix": "111-ARR_v1_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_60",
            "tgt_ix": "111-ARR_v1_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_60",
            "tgt_ix": "111-ARR_v1_60@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_61",
            "tgt_ix": "111-ARR_v1_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_62",
            "tgt_ix": "111-ARR_v1_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_62",
            "tgt_ix": "111-ARR_v1_62@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_62",
            "tgt_ix": "111-ARR_v1_62@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_63",
            "tgt_ix": "111-ARR_v1_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_64",
            "tgt_ix": "111-ARR_v1_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_64",
            "tgt_ix": "111-ARR_v1_64@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_64",
            "tgt_ix": "111-ARR_v1_64@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_64",
            "tgt_ix": "111-ARR_v1_64@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_64",
            "tgt_ix": "111-ARR_v1_64@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_64",
            "tgt_ix": "111-ARR_v1_64@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_64",
            "tgt_ix": "111-ARR_v1_64@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_65",
            "tgt_ix": "111-ARR_v1_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_66",
            "tgt_ix": "111-ARR_v1_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_67",
            "tgt_ix": "111-ARR_v1_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_68",
            "tgt_ix": "111-ARR_v1_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_68",
            "tgt_ix": "111-ARR_v1_68@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_68",
            "tgt_ix": "111-ARR_v1_68@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_68",
            "tgt_ix": "111-ARR_v1_68@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_69",
            "tgt_ix": "111-ARR_v1_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_70",
            "tgt_ix": "111-ARR_v1_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_71",
            "tgt_ix": "111-ARR_v1_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_71",
            "tgt_ix": "111-ARR_v1_71@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_71",
            "tgt_ix": "111-ARR_v1_71@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_71",
            "tgt_ix": "111-ARR_v1_71@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_71",
            "tgt_ix": "111-ARR_v1_71@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_71",
            "tgt_ix": "111-ARR_v1_71@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_71",
            "tgt_ix": "111-ARR_v1_71@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_72",
            "tgt_ix": "111-ARR_v1_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_72",
            "tgt_ix": "111-ARR_v1_72@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_73",
            "tgt_ix": "111-ARR_v1_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_73",
            "tgt_ix": "111-ARR_v1_73@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_73",
            "tgt_ix": "111-ARR_v1_73@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_74",
            "tgt_ix": "111-ARR_v1_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_74",
            "tgt_ix": "111-ARR_v1_74@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_74",
            "tgt_ix": "111-ARR_v1_74@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_75",
            "tgt_ix": "111-ARR_v1_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_75",
            "tgt_ix": "111-ARR_v1_75@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_75",
            "tgt_ix": "111-ARR_v1_75@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_75",
            "tgt_ix": "111-ARR_v1_75@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_75",
            "tgt_ix": "111-ARR_v1_75@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_75",
            "tgt_ix": "111-ARR_v1_75@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_76",
            "tgt_ix": "111-ARR_v1_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_77",
            "tgt_ix": "111-ARR_v1_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_77",
            "tgt_ix": "111-ARR_v1_77@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_77",
            "tgt_ix": "111-ARR_v1_77@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_77",
            "tgt_ix": "111-ARR_v1_77@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_78",
            "tgt_ix": "111-ARR_v1_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_78",
            "tgt_ix": "111-ARR_v1_78@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_78",
            "tgt_ix": "111-ARR_v1_78@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_78",
            "tgt_ix": "111-ARR_v1_78@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_78",
            "tgt_ix": "111-ARR_v1_78@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_78",
            "tgt_ix": "111-ARR_v1_78@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_78",
            "tgt_ix": "111-ARR_v1_78@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_78",
            "tgt_ix": "111-ARR_v1_78@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_79",
            "tgt_ix": "111-ARR_v1_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_79",
            "tgt_ix": "111-ARR_v1_79@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_80",
            "tgt_ix": "111-ARR_v1_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_80",
            "tgt_ix": "111-ARR_v1_80@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_80",
            "tgt_ix": "111-ARR_v1_80@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_81",
            "tgt_ix": "111-ARR_v1_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_82",
            "tgt_ix": "111-ARR_v1_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_83",
            "tgt_ix": "111-ARR_v1_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_83",
            "tgt_ix": "111-ARR_v1_83@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_83",
            "tgt_ix": "111-ARR_v1_83@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_83",
            "tgt_ix": "111-ARR_v1_83@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_83",
            "tgt_ix": "111-ARR_v1_83@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_83",
            "tgt_ix": "111-ARR_v1_83@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_83",
            "tgt_ix": "111-ARR_v1_83@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_83",
            "tgt_ix": "111-ARR_v1_83@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_83",
            "tgt_ix": "111-ARR_v1_83@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_84",
            "tgt_ix": "111-ARR_v1_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_85",
            "tgt_ix": "111-ARR_v1_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_85",
            "tgt_ix": "111-ARR_v1_85@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_85",
            "tgt_ix": "111-ARR_v1_85@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_85",
            "tgt_ix": "111-ARR_v1_85@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_86",
            "tgt_ix": "111-ARR_v1_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_86",
            "tgt_ix": "111-ARR_v1_86@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_86",
            "tgt_ix": "111-ARR_v1_86@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_86",
            "tgt_ix": "111-ARR_v1_86@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_87",
            "tgt_ix": "111-ARR_v1_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_87",
            "tgt_ix": "111-ARR_v1_87@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_88",
            "tgt_ix": "111-ARR_v1_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_88",
            "tgt_ix": "111-ARR_v1_88@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_88",
            "tgt_ix": "111-ARR_v1_88@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_88",
            "tgt_ix": "111-ARR_v1_88@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_88",
            "tgt_ix": "111-ARR_v1_88@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_89",
            "tgt_ix": "111-ARR_v1_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_89",
            "tgt_ix": "111-ARR_v1_89@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_89",
            "tgt_ix": "111-ARR_v1_89@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_89",
            "tgt_ix": "111-ARR_v1_89@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_89",
            "tgt_ix": "111-ARR_v1_89@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_89",
            "tgt_ix": "111-ARR_v1_89@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_90",
            "tgt_ix": "111-ARR_v1_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_90",
            "tgt_ix": "111-ARR_v1_90@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_90",
            "tgt_ix": "111-ARR_v1_90@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_90",
            "tgt_ix": "111-ARR_v1_90@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_91",
            "tgt_ix": "111-ARR_v1_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_91",
            "tgt_ix": "111-ARR_v1_91@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_91",
            "tgt_ix": "111-ARR_v1_91@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_91",
            "tgt_ix": "111-ARR_v1_91@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_91",
            "tgt_ix": "111-ARR_v1_91@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_92",
            "tgt_ix": "111-ARR_v1_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_93",
            "tgt_ix": "111-ARR_v1_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_94",
            "tgt_ix": "111-ARR_v1_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_95",
            "tgt_ix": "111-ARR_v1_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_96",
            "tgt_ix": "111-ARR_v1_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_97",
            "tgt_ix": "111-ARR_v1_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_98",
            "tgt_ix": "111-ARR_v1_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_98",
            "tgt_ix": "111-ARR_v1_98@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_99",
            "tgt_ix": "111-ARR_v1_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_100",
            "tgt_ix": "111-ARR_v1_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_100",
            "tgt_ix": "111-ARR_v1_100@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_100",
            "tgt_ix": "111-ARR_v1_100@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_100",
            "tgt_ix": "111-ARR_v1_100@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_101",
            "tgt_ix": "111-ARR_v1_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_102",
            "tgt_ix": "111-ARR_v1_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_103",
            "tgt_ix": "111-ARR_v1_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_103",
            "tgt_ix": "111-ARR_v1_103@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_103",
            "tgt_ix": "111-ARR_v1_103@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_104",
            "tgt_ix": "111-ARR_v1_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_104",
            "tgt_ix": "111-ARR_v1_104@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_104",
            "tgt_ix": "111-ARR_v1_104@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_105",
            "tgt_ix": "111-ARR_v1_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_105",
            "tgt_ix": "111-ARR_v1_105@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_105",
            "tgt_ix": "111-ARR_v1_105@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_105",
            "tgt_ix": "111-ARR_v1_105@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_105",
            "tgt_ix": "111-ARR_v1_105@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_105",
            "tgt_ix": "111-ARR_v1_105@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_105",
            "tgt_ix": "111-ARR_v1_105@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_105",
            "tgt_ix": "111-ARR_v1_105@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_105",
            "tgt_ix": "111-ARR_v1_105@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_105",
            "tgt_ix": "111-ARR_v1_105@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_106",
            "tgt_ix": "111-ARR_v1_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_106",
            "tgt_ix": "111-ARR_v1_106@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_106",
            "tgt_ix": "111-ARR_v1_106@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_107",
            "tgt_ix": "111-ARR_v1_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_108",
            "tgt_ix": "111-ARR_v1_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_109",
            "tgt_ix": "111-ARR_v1_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_109",
            "tgt_ix": "111-ARR_v1_109@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_109",
            "tgt_ix": "111-ARR_v1_109@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_110",
            "tgt_ix": "111-ARR_v1_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_110",
            "tgt_ix": "111-ARR_v1_110@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_110",
            "tgt_ix": "111-ARR_v1_110@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_110",
            "tgt_ix": "111-ARR_v1_110@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_110",
            "tgt_ix": "111-ARR_v1_110@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_110",
            "tgt_ix": "111-ARR_v1_110@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_111",
            "tgt_ix": "111-ARR_v1_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_111",
            "tgt_ix": "111-ARR_v1_111@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_111",
            "tgt_ix": "111-ARR_v1_111@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_112",
            "tgt_ix": "111-ARR_v1_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_112",
            "tgt_ix": "111-ARR_v1_112@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_113",
            "tgt_ix": "111-ARR_v1_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_114",
            "tgt_ix": "111-ARR_v1_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_114",
            "tgt_ix": "111-ARR_v1_114@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_114",
            "tgt_ix": "111-ARR_v1_114@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_114",
            "tgt_ix": "111-ARR_v1_114@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_115",
            "tgt_ix": "111-ARR_v1_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_116",
            "tgt_ix": "111-ARR_v1_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_116",
            "tgt_ix": "111-ARR_v1_116@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_117",
            "tgt_ix": "111-ARR_v1_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_117",
            "tgt_ix": "111-ARR_v1_117@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_118",
            "tgt_ix": "111-ARR_v1_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_118",
            "tgt_ix": "111-ARR_v1_118@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_119",
            "tgt_ix": "111-ARR_v1_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_120",
            "tgt_ix": "111-ARR_v1_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_120",
            "tgt_ix": "111-ARR_v1_120@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_120",
            "tgt_ix": "111-ARR_v1_120@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_120",
            "tgt_ix": "111-ARR_v1_120@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_121",
            "tgt_ix": "111-ARR_v1_121@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_121",
            "tgt_ix": "111-ARR_v1_121@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_121",
            "tgt_ix": "111-ARR_v1_121@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_121",
            "tgt_ix": "111-ARR_v1_121@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_121",
            "tgt_ix": "111-ARR_v1_121@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_121",
            "tgt_ix": "111-ARR_v1_121@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_122",
            "tgt_ix": "111-ARR_v1_122@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_123",
            "tgt_ix": "111-ARR_v1_123@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_124",
            "tgt_ix": "111-ARR_v1_124@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_125",
            "tgt_ix": "111-ARR_v1_125@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_125",
            "tgt_ix": "111-ARR_v1_125@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_125",
            "tgt_ix": "111-ARR_v1_125@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_125",
            "tgt_ix": "111-ARR_v1_125@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_125",
            "tgt_ix": "111-ARR_v1_125@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_126",
            "tgt_ix": "111-ARR_v1_126@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_126",
            "tgt_ix": "111-ARR_v1_126@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_126",
            "tgt_ix": "111-ARR_v1_126@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_127",
            "tgt_ix": "111-ARR_v1_127@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_127",
            "tgt_ix": "111-ARR_v1_127@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_127",
            "tgt_ix": "111-ARR_v1_127@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_127",
            "tgt_ix": "111-ARR_v1_127@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_127",
            "tgt_ix": "111-ARR_v1_127@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_128",
            "tgt_ix": "111-ARR_v1_128@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_128",
            "tgt_ix": "111-ARR_v1_128@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_129",
            "tgt_ix": "111-ARR_v1_129@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_129",
            "tgt_ix": "111-ARR_v1_129@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_129",
            "tgt_ix": "111-ARR_v1_129@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_130",
            "tgt_ix": "111-ARR_v1_130@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_130",
            "tgt_ix": "111-ARR_v1_130@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_130",
            "tgt_ix": "111-ARR_v1_130@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_130",
            "tgt_ix": "111-ARR_v1_130@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_131",
            "tgt_ix": "111-ARR_v1_131@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_131",
            "tgt_ix": "111-ARR_v1_131@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_131",
            "tgt_ix": "111-ARR_v1_131@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_131",
            "tgt_ix": "111-ARR_v1_131@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_131",
            "tgt_ix": "111-ARR_v1_131@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_131",
            "tgt_ix": "111-ARR_v1_131@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_131",
            "tgt_ix": "111-ARR_v1_131@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_131",
            "tgt_ix": "111-ARR_v1_131@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_131",
            "tgt_ix": "111-ARR_v1_131@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_131",
            "tgt_ix": "111-ARR_v1_131@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_131",
            "tgt_ix": "111-ARR_v1_131@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_131",
            "tgt_ix": "111-ARR_v1_131@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_131",
            "tgt_ix": "111-ARR_v1_131@12",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_131",
            "tgt_ix": "111-ARR_v1_131@13",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_131",
            "tgt_ix": "111-ARR_v1_131@14",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_131",
            "tgt_ix": "111-ARR_v1_131@15",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_131",
            "tgt_ix": "111-ARR_v1_131@16",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_131",
            "tgt_ix": "111-ARR_v1_131@17",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_131",
            "tgt_ix": "111-ARR_v1_131@18",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_131",
            "tgt_ix": "111-ARR_v1_131@19",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_131",
            "tgt_ix": "111-ARR_v1_131@20",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_132",
            "tgt_ix": "111-ARR_v1_132@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_132",
            "tgt_ix": "111-ARR_v1_132@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_132",
            "tgt_ix": "111-ARR_v1_132@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_133",
            "tgt_ix": "111-ARR_v1_133@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_134",
            "tgt_ix": "111-ARR_v1_134@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_135",
            "tgt_ix": "111-ARR_v1_135@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_136",
            "tgt_ix": "111-ARR_v1_136@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_137",
            "tgt_ix": "111-ARR_v1_137@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_138",
            "tgt_ix": "111-ARR_v1_138@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_139",
            "tgt_ix": "111-ARR_v1_139@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_140",
            "tgt_ix": "111-ARR_v1_140@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_141",
            "tgt_ix": "111-ARR_v1_141@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_142",
            "tgt_ix": "111-ARR_v1_142@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_143",
            "tgt_ix": "111-ARR_v1_143@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_144",
            "tgt_ix": "111-ARR_v1_144@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_145",
            "tgt_ix": "111-ARR_v1_145@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_146",
            "tgt_ix": "111-ARR_v1_146@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_147",
            "tgt_ix": "111-ARR_v1_147@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_148",
            "tgt_ix": "111-ARR_v1_148@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_149",
            "tgt_ix": "111-ARR_v1_149@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_150",
            "tgt_ix": "111-ARR_v1_150@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_151",
            "tgt_ix": "111-ARR_v1_151@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_152",
            "tgt_ix": "111-ARR_v1_152@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_153",
            "tgt_ix": "111-ARR_v1_153@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_154",
            "tgt_ix": "111-ARR_v1_154@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_155",
            "tgt_ix": "111-ARR_v1_155@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_156",
            "tgt_ix": "111-ARR_v1_156@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_157",
            "tgt_ix": "111-ARR_v1_157@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_158",
            "tgt_ix": "111-ARR_v1_158@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_159",
            "tgt_ix": "111-ARR_v1_159@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_160",
            "tgt_ix": "111-ARR_v1_160@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_161",
            "tgt_ix": "111-ARR_v1_161@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_162",
            "tgt_ix": "111-ARR_v1_162@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_163",
            "tgt_ix": "111-ARR_v1_163@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_164",
            "tgt_ix": "111-ARR_v1_164@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_165",
            "tgt_ix": "111-ARR_v1_165@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_166",
            "tgt_ix": "111-ARR_v1_166@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_167",
            "tgt_ix": "111-ARR_v1_167@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_168",
            "tgt_ix": "111-ARR_v1_168@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_169",
            "tgt_ix": "111-ARR_v1_169@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_170",
            "tgt_ix": "111-ARR_v1_170@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_171",
            "tgt_ix": "111-ARR_v1_171@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_172",
            "tgt_ix": "111-ARR_v1_172@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_173",
            "tgt_ix": "111-ARR_v1_173@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_174",
            "tgt_ix": "111-ARR_v1_174@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_175",
            "tgt_ix": "111-ARR_v1_175@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_176",
            "tgt_ix": "111-ARR_v1_176@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_177",
            "tgt_ix": "111-ARR_v1_177@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_178",
            "tgt_ix": "111-ARR_v1_178@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_179",
            "tgt_ix": "111-ARR_v1_179@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_180",
            "tgt_ix": "111-ARR_v1_180@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_181",
            "tgt_ix": "111-ARR_v1_181@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_182",
            "tgt_ix": "111-ARR_v1_182@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_183",
            "tgt_ix": "111-ARR_v1_183@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_184",
            "tgt_ix": "111-ARR_v1_184@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_185",
            "tgt_ix": "111-ARR_v1_185@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "111-ARR_v1_186",
            "tgt_ix": "111-ARR_v1_186@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 1468,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "position_tag_type": "from_draft",
        "doc_id": "111-ARR",
        "version": 1
    }
}