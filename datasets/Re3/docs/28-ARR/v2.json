{
    "nodes": [
        {
            "ix": "28-ARR_v2_0",
            "content": "TEAM: A multitask learning based Taxonomy Expansion approach for Attach and Merge",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_2",
            "content": "Taxonomy expansion is a crucial task. Most of the taxonomy expansion approaches are of two types, attach and merge. In a taxonomy like WordNet, both merge and attach are integral parts of the expansion operations, but the majority of studies consider them separately. This paper proposes a novel multi-task learning-based deep learning method known as Taxonomy Expansion with Attach and Merge (TEAM) that performs both the merge and attach operations. This is the first study that integrates both the merge and attach operations in a single model to the best of our knowledge. The proposed models have been evaluated on three separate WordNet taxonomies, viz., Assamese, Bangla, and Hindi. From the various experimental setups, it is shown that TEAM outperforms its state-of-the-art counterparts for attach operation and also provides highly encouraging performance for the merge operation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "28-ARR_v2_4",
            "content": "Taxonomy, such as the WordNet, is a crucial resource for developing NLP related technologies, as it plays a vital role in various text processing tasks such as information retrieval, information extraction, text classification, summarization, etc. (Pang et al., 2008;Allan et al., 1998;Singhal et al., 2001) (Miller, 1998. As most of the WordNets are manually curated, it often suffers from the problem of limited coverage. Therefore, an automatic taxonomy expansion is a crucial problem to handle the above issue. For taxonomy expansion, WordNet in particular, may need two types of operations; (i) merge, where a new concept 1 is merged to an existing node, and (ii) attach, where a new concept is inserted as a new node. Figure 1 illustrates these two operations where the word Mango is inserted as a new concept with the attach operation, and the \"Mango\" is a specific concept of Fruit not present in the existing WordNet. Hence, a new concept node is created in the taxonomy by attaching it to its generic concept Fruit . As \"Nutrient\" refers to the same concept as \"Food\", no new concept is created. \"Nutrient\" is merged with the existing concept \"Food\".",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_5",
            "content": "word Nutrient is inserted as a new synonymy in an existing concept with the merge operation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_6",
            "content": "Though both of these operations are integral parts of a WordNet taxonomy expansion, all of the existing studies on taxonomy expansion have considered expansion with either attach operation (Schlichtkrull and Alonso, 2016;Vedula et al., 2018;Shen et al., 2020;Yu et al., 2020b;Zhang et al., 2021;Takeoka et al., 2021; or merge operation (Nakashole et al., 2012;Nguyen et al., 2017;Nakashole et al., 2012;Qu et al., 2017;Boteanu et al., 2018;Wang et al., 2019;Fei et al., 2019), but not together. Realizing the need to apply both the operation, SemEval-2016:task 14 (Semantic taxonomy enrichment) Jurgens and Pilehvar (2016) includes a call for expansion with both attach and merge operations. However, none of the submissions incorporate both operations in a single model. Motivated by the above observations, in this study, we propose an integrated deep learningbased method, namely, Taxonomy Expansion with Attach and Merge (TEAM), which performs both the attach and merge operations in a multitasklearning framework. Though most of the existing studies consider the expansion a regression problem (Shen et al., 2020;Yu et al., 2020b;Zhang et al., 2021), considering that our method performs both the attach and merge operation in a single model, it can also be considered a classification task. As a result, we propose two versions of TEAM, namely, TEAM-RG: Regression, and TEAM-CL: Classification to perform with explicit and implicit rankings. The proposed models have been evaluated on three different WordNet taxonomies, viz., Assamese, Bangla, and Hindi. From the various experimental setups, it is observed that the proposed TEAM-RG and TEAM-CL outperform their baselines counterparts for attach operation, and also obtained encouraging performance for merge operation as well. The major contributions of the paper are summarized as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_7",
            "content": "\u2022 A multi-task learning based taxonomy expansion framework TEAM is jointly trained to perform both the Attach and Merge operations.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_8",
            "content": "To the best of our knowledge, it is the first integrated model to perform both the Attach and Merge operations in a single model.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_9",
            "content": "\u2022 Two variants of TEAM, namely TEAM-Regression (RG) and TEAM-Classification (CL) are proposed.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_10",
            "content": "Taxonomy Expansion -Attach and Merge",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "28-ARR_v2_11",
            "content": "In this study, we have considered WordNets as our target taxonomies. A WordNet may be defined by a collection of concepts connected by various semantic relationships such as hypernymy, hyponymy, troponymy, etc., where each concept is further defined by a set of attributes such as definition, synonyms, examples, etc (Bhattacharyya, 2010). In this study, we have considered only the hypernymy relation and the definition and synonymy attributes.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_12",
            "content": "In order to be able to apply the proposed model, we first transform the original WordNet taxonomy into an experimental intermediate taxonomy ( directed unweighted acyclic graph) T = (V, E) where V represents the set of concepts and E represents the set of hypernymy relations between the concepts. A concept v \u2208 V is further defined by a tuple v = (d v , s v ) where d v represents the definition of the concept, and s v represents the set of associated synonyms. An edge e \u2208 E represents a hypernymy relation from a parent concept v p to its child concept v ch and is denoted as",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_13",
            "content": "e : (v p hyper \u2212 \u2212\u2212 \u2192 v ch )",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_14",
            "content": ". The taxonomy T is arranged in a hierarchical manner with directed edges in E, as shown in Figure 1. Given the taxonomy T and a query concept q = (d q , s q ), the attach and the merge expansion operations are defined below.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_15",
            "content": "Attach (A) -An attach operation is performed when the concept q is not present in T. The objective of the attach operation is to identify the best matching parent node in taxonomy network known as anchor concept a = (d a , s a ), and insert a new concept q with an edge e : (a hyper \u2212 \u2212\u2212 \u2192 q). In a taxonomy network, a parent node represents a more generic concept of its children. After an attach operation i.e., insertion of q in T under the anchor a, the expanded taxonomy is updated as follows.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_16",
            "content": "T = (V \u222a {q}, E \u222a {e})(1)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_17",
            "content": "Merge (M) -A merge operation is performed when an equivalent concept a = (d a , s a ) of the query q (i.e., d a \u2261 d q ) is already present in T, but the synset s q is not present in a (i.e., s q \u2229 s a = \u2205). The objective of the merge operation is to identify the best matching concept a = (d a , s a ), known as the anchor concept, in the taxonomy network T and add the synset s q to s a . It neither creates a new node nor adds a new edge. It only updates the synset of the anchor concept. After the merge operation, the updated anchor concept in the expanded taxonomy can be expressed as follows.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_18",
            "content": "a = (d a , s a \u222a s q ) : a \u2208 V (2)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_19",
            "content": "3 Proposed Methods",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_20",
            "content": "Our objective is to develop an integrated model that performs both attach and merge operations for taxonomy expansion. Since we have two tasks to unify in a single model, we resort to a multi-task learning framework known as Taxonomy Expansion Framework with Attach and Merge (TEAM). This joint learning objective facilitates information flow so that the two tasks can aid each other. Also, we are interested in deciding which expansion operation is to perform given a triplet (expansion task classification) and retrieving the ranked list of candidates (ranking) as prospective anchors to associate the query with. For this first-of-its-kind novel taxonomy expansion task, we propose two versions of TEAM, namely TEAM-Regression (TEAM-RG) and TEAM-Classification (TEAM-CL) -where we show that using either regression or classification learning objectives, this task can be accomplished.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_21",
            "content": "Training dataset generation",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "28-ARR_v2_22",
            "content": "Given a transformed taxonomy T (as described in Section 2), we generate a training dataset for building the model as follows. The training samples are defined by a 3-tuple < q, a, label >, where q is the query, a is the potential anchor, and label is associated class, i.e., true/false (1/0). We randomly select a set of nodes in T as a set of queries 2 , and generate the training samples for the attach and the merge operations separately as follows.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_23",
            "content": "Attach (A) -We first remove the query nodes from the T. For each query q = (d q , s q ), we consider its parent as anchor node a = (d a , s a ) and generate positive sample < q, a, T RU E >. We then randomly pick up N number other nodes a \u2032 = (d a \u2032 , s a \u2032 ), and generate N negative samples < q, a \u2032 , F ALSE >. Thus, for a given query node q, we extract one positive and N negative samples.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_24",
            "content": "Merge (M) -For each of the randomly selected query node x = (d x , s x >) in T, we generate the following positive training sample < q, x, T rue > where q = (d x , s q ), s q \u2282 s x is the query and x = (d x , s x \u2212s q ) is the anchor.The s q is a randomly selected synonym in s x . Unlike attach, for generating the training sample for the query q, we only remove the query synset s q from the anchor synset s x i.e., s x = s x \u2212s q , and, not the node. Like attach, we randomly pick up N number other nodes a \u2032 , and generate N negative samples < q, a \u2032 , F ALSE >.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_25",
            "content": "2 As we consider the same query set for both attach and merge experiments, nodes with at least two synonyms are considered.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_26",
            "content": "TEAM-Regression (TEAM-RG)",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "28-ARR_v2_27",
            "content": "The proposed TEAM-RG works in two tiers process. Given a training input sample < q, a, c >, it first generates encoding of the query q and the anchor a.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_28",
            "content": "It then merges to a shared layer to produce two different multi-tasking dense networks; one for merge and another for attach, as shown in figure 4.D.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_29",
            "content": "For learning embedding of the anchor concept from the taxonomy network and the query concept from the associated attributes, we consider the publicly available Fasttext pre-trained embedding available at https://fasttext.cc/docs/ en/crawl-vectors.html.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_30",
            "content": "Processing of the query concept: As mentioned in Section 2, a query concept consists of its definition and the associated synset i.e., q = (d q , s q ). The definition is a piece of text describing the concept, and the synset is a synonym associated with the query concept. . The two embeddings are then concatenated to represent the query.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_31",
            "content": "Processing of the anchor concept: For generating the encoding of the anchor concept, we exploit the proximity structure of the nodes in the taxonomy T. For a given anchor node a \u2208 T, we first extract its ego-tree from the taxonomy. An ego tree T a : (V a , E a ) of a node a in the taxonomy T is a sub-tree that comprises the node a and its k-hop neighborhood nodes. In this study, we considered k = 1, i.e., the anchor node, its parent node, and all its children nodes. Figure 3 illustrates an example of an ego tree. A similar approach has also been used in (Wang et al., 2021;Yu et al., 2020b;Zhang et al., 2021;Shen et al., 2020) studies. To obtain the embedding of the anchor concept, we further apply graph embedding as described below.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_32",
            "content": "Embedding Ego-tree",
            "ntype": "title",
            "meta": {
                "section": "3.2.1"
            }
        },
        {
            "ix": "28-ARR_v2_33",
            "content": "Ideally, we should be able to use any graph embedding method to obtain the embedding of the anchor node. As the objective is to incorporate the positional information of the parent and children node in the ego tree, we use the Graph Attention Network (GAT) proposed in Taxo-Expan (Shen et al., 2020). This GAT is a special type of graph neural network (GNN) (Kipf and Welling, 2016) with a neighborhood-based attention mechanism. The details of GAT and its difference from GNN are given in Section B of Appendix. Thus we used position enhanced GAT to obtain the node embeddings of an anchor's ego tree.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_34",
            "content": "We summarize the tree by applying an activation function over the average of the embedding vectors of all nodes in the ego-tree as given in equation 3 to define the encoding of the anchor node.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_35",
            "content": "Ta = \u03c3 1 |V a | x\u2208Va x(3)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_36",
            "content": "where \u03c3(.) is an activation function. We have considered Sigmoid function in this study.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_37",
            "content": "Multi-task Learning",
            "ntype": "title",
            "meta": {
                "section": "3.2.2"
            }
        },
        {
            "ix": "28-ARR_v2_38",
            "content": "Once we obtain the embeddings of the anchor and query concepts, the concatenated vector is subjected to a shared dense layer and then build two multi-task layers to perform the merge and attach operations as shown in Figure 4.D. Given a query concept and its true anchor concept with N false anchor concepts, the task is to design a regressionbased ranking model such that the true concept is ranked higher than the N false concepts. This objective should be realized for all the queries in the training dataset.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_39",
            "content": "Given the embedding vectors of anchor \u0101 and query q as learned above, we first estimate similarity between the two using a bi-linear model proposed in (Gutmann and Hyv\u00e4rinen, 2010). It learns the discrimination between q and a through a learnable bi-linear scoring matrix B \u2208 R |q|\u00d7|\u0101| via a function D : R |q|\u00d7|\u0101| \u2192 R as follows.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_40",
            "content": "D(q, a) = \u03c3(q T B\u0101) (4)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_41",
            "content": "Here \u03c3 is sigmoid non-linearity. The output of this matching module is a probability estimate indicating the strength of association between the query and anchor. Now, considering the query concept q and its associated N + 1 anchor concepts, we estimate the probability of being the correct anchor using InfoNCE loss proposed in (Oord et al., 2018). Let X be a set of query concepts and their respective N + 1 anchor nodes (one positive and N negative). An element of x q \u2208 X for a given query q consists of {(q, a, 1), (q, a \u2032 1 , a \u2032 2 , ..., a \u2032 N , 0)}, where a is the positive anchor, and a \u2032 are the negative anchors of q. InfoNCE estimates loss function using an average probability of being true anchor node across the dataset X as follows.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_42",
            "content": "L A/M = \u2212 1 |X| xq\u2208X log D(q, \u0101) v\u2208M(q) D(q, v)(5)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_43",
            "content": "where M(q) denotes the set of both positive and negative anchors of q. As mentioned earlier, the loss defined in Equation 5 is estimated separately for attach and merge operations. Therefore, we generate two different training datasets for attach and merge, and estimate L A and L M separately using respective datasets, The final model loss is defined as L = L A + L M -considering both the operations attach and merge.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_44",
            "content": "TEAM-Classification (TEAM-CL)",
            "ntype": "title",
            "meta": {
                "section": "3.3"
            }
        },
        {
            "ix": "28-ARR_v2_45",
            "content": "Figure 4E shows the schematic diagram of the TEAM-CL. We use the identical representations for query q and candidate anchors a A , a M as described for TEAM-RG. We also adopt the same position-enhanced graph propagation and read-out modules as described in Section 3.2.1 for learning anchor a = (d a , s a ) concept representation. Once we obtain the query and anchor representations, we model the strength of association of an input query and the candidate anchors based on their features to predict the expansion task i.e., merge M or attach A. The matching module, a multilayer perceptron (MLP) based classifier, takes the features of query q \u2208 R |q| and anchor \u0101 \u2208 R |\u0101| , and generates a contextualized pair representation k = [q \u2295(q \u2212\u0101)\u2295(q \u00d7\u0101)\u2295\u0101] (assuming |q| = |\u0101|).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_46",
            "content": "Here, \u2295 denotes concatenation. The anchor a can be any of the attach or merge candidates (a A /a M ).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_47",
            "content": "A three-way classifier is learned to produce the categorical probability distribution over the training samples for Merge (M), Attach (A) and Nooperation (N) -three classes (|Z| = 3) of operations. If \u03b8 \u2208 R | k|\u00d7| Z| be a learnable projection matrix that projects the contextualized pair embedding k to the label space Z \u2208 R 3 . The predictions are obtained as below,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_48",
            "content": "\u0176 = softmax(MLP( k; \u03b8))(6)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_49",
            "content": "Query Q",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_50",
            "content": "[ q, q -a A , q x a A , a A ] [ q, q -a M , q x a M , a M ] For two versions of TEAM, we chose two different kinds of matching models based on empirical performances to capture different kinds of embedding interaction in the latent space.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_51",
            "content": "Multi-task Learning",
            "ntype": "title",
            "meta": {
                "section": "3.3.1"
            }
        },
        {
            "ix": "28-ARR_v2_52",
            "content": "Classification. Unlike in TEAM-RG, where we posit taxonomy expansion as a regression task with implicit ranking viz. discriminating true and false examples via InfoNCE loss, in TEAM-CL, we simultaneously optimize for classification and explicit ranking objectives. We obtain classification predictions from the matching module as described before. Given a training set X, and a set of classes Z (M: Merge, A: Attach, N: No-operation), we optimize for the self-supervised cross-entropy loss over the task predictions \u0176 given the ground-truth task-classes Y for an input query-anchor pair.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_53",
            "content": "L C = \u2212 1 |X| i\u2208X z\u2208Z Y iz ln \u0176iz (7)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_54",
            "content": "Ranking. The classification objective can only learn and infer the confidence score of an operation (M/ A/ N) for a training sample. It fails to give us a reliable ranked list of prospective anchors-(A/ M) given a query -since it does not learn the relative ranks of positive and negative anchors for a query. As illustrated in Figure 4, for a query q, (i) the ego-tree of anchor-A comprises of that query's parent's hierarchical neighborhood, and (ii) the ego-tree of anchor-M comprises of that query's replica's (same/similar definition with a missing portion of synset) hierarchical neighborhood. Since a query q is very similar to both of its anchor-A and anchor-M's ego-trees -these operations are hardly distinguishable. Thus, a model must accommodate a provision for directly comparing the prediction scores of M and A operations and learning a margin of separation between the scores. Here, we introduce two ranking objectives in the framework -(i) a contrastive objective to compare and contrast among a positive anchor and N negative anchors, (ii) a pair-wise hinge loss to learn a maximum margin between the M and A prediction scores. Let, dist(.) be a function to measure the distance between a query q and its true/ false anchor-(A/ M) representations ( \u0101A , \u0101A \u2032 ), ( \u0101 M , \u0101 M \u2032 ). We use \"slash\" (/) to denote either. We intend to rank a positive query-anchor pair (q, a A /a M ) higher than N no of negative pairs (q, a \u2032 A /a \u2032 M ) by enforcing a group-wise contrastive loss using a margin \u03bb as,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_55",
            "content": "L R1 A = 1 X i\u2208X 1 |N(q i )| \u0101A \u2032 i \u2208N(q i ) max(0, \u03bb \u2212 m + m \u2032 ) m = \u2212 dist(q i \u2212 \u0101Ai ), m \u2032 = \u2212 dist(q i \u2212 \u0101A \u2032 i ) (8)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_56",
            "content": "We can similarly compute the margin-based groupwise contrastive loss L R1 M for the Merge (M). Now, to distinguish between M and A operations, let, f ( k) be a function that projects the contextualized (q, a) embedding k in Equation 6, to a hidden space R h . Here we introduce a marginbased hinge-loss on sample anchor pairs attachmerge \u27e8a A , a M \u27e9 for a given query q via their contextualized vectors \u27e8 kA , k M \u27e9. If class labels of merge and attach are M = 2, A = 1, we ensure the prediction scores \u0176A/M = f ( kA/M ) for M and A are separated by a margin of \u03bb.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_57",
            "content": "L R2 = Y ( kA )>Y ( k M ) max(0, \u03bb \u2212 f ( k M ) + f ( kA ))",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_58",
            "content": "Therefore, the final loss is, L = L C + L R1 A + L R1 M + L R2 -considering both margin-based group-wise contrastive loss and pairwise hinge loss comprising the overall ranking loss.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_59",
            "content": "Model Inference",
            "ntype": "title",
            "meta": {
                "section": "3.4"
            }
        },
        {
            "ix": "28-ARR_v2_60",
            "content": "We follow Taxo-Expan's (Shen et al., 2020) evaluation strategy for inferring the best candidate anchor a given a query q. We use our classification objective to decide which operation among merge, attach, or no-operation (M, A, N) to perform when q is given. i) For TEAM-RG, we augment a classification layer on top of the task-specific regression layers. Given a query q and a set of candidate anchors a, we obtain the merge and attach regression scores and choose the best value along with the corresponding operation as the apt operation to perform. ii) For TEAM-CL choosing which operation to perform is obtained based on the three-way prediction scores, given < q, a, (0/1) > as input. Since both of our proposed frameworks optimize for ranking loss, i.e., discriminates true candidate pairs from the negative ones -we get a ranked list of candidate anchors a while matching each of them with q via respective matching modules.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_61",
            "content": "Experiments and Results",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "28-ARR_v2_62",
            "content": "Here we give you an overview of our experiment settings and provide the detailed reproducibility information in the Sections C, D, E of the Appendix.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_63",
            "content": "Datasets. Metrics. We use Mean Rank (MR), Hit@k, and Mean Reciprocal Rank (MRR) to evaluate the ranks of the retrieved results obtained from different models, for the test queries. Like Taxo-Expan (Shen et al., 2020) evaluation strategy, we scale the MRR score by a factor of 10 to highlight the discrepancy of the performances among different methods. Further, we use Accuracy, Micro/ Macro F1, Precision, Recall, and F-Scores to evaluate a method's prediction capability to decide which operation among merge (M), attach (A), and no-operation (N) needs to be performed.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_64",
            "content": "Baselines. We choose two most recent benchmark SOTA taxonomy-expansion frameworks Tax-oExpan (Shen et al., 2020) and Triplet Matching Network(TMN) (Zhang et al., 2021) as the competing methods. As Taxo-Expan and TMN outperform SemEval-2016 (Shen et al., 2020;Zhang et al., 2021), we have not included SemEval-2016 as baseline in this study. In terms of learning objective, Taxo-Expan is similar to ours. It uses ego-treebased anchor features for matching query features in a regression-based setting. TMN captures finegrained relationship dynamics of query and anchor concepts using channel-wise gating mechanismbased attention learning.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_65",
            "content": "All datasets and our model implementations are available at: https://github.com/ barnal/TEAM",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_66",
            "content": "Results",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "28-ARR_v2_67",
            "content": "Here we report the classification and ranking results of the competing methods. We also compare and contrast among the variants of our TEAM framework. Apart from the two versions of the TEAM, namely, TEAM-RG and TEAM-CL, we have task-specific model variants specified asattach-A, merge-M and merge+attach-MA. Here, (attach+merge) means simultaneously optimizing for both the tasks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_68",
            "content": "Ranking Results",
            "ntype": "title",
            "meta": {
                "section": "5.1"
            }
        },
        {
            "ix": "28-ARR_v2_69",
            "content": "In Table [2], we show the performance of the competing methods in terms of (best) ranking scores. We see similar trends for all taxonomies in the sub-tables. When considering only attach operation and the test ranking scores, we see TEAM-RG clearly beats Taxo-Expan by a large margin of (196.87, 487.75, 470.87) in MR, by a margin of Assamese WordNet-Noun Bengali WordNet-Noun Hindi WordNet-Noun Methods Micro_MR Hit@1 Hit@3 MRR Micro_MR Hit@1 Hit@3 MRR Micro_MR Hit@1 Hit@3 MRR (0.2, 0.14, 0.24) in Hit@1 and (0.31, 0.32, 0.37) in Hit@3 for Assamese, Bengali and Hindi WordNet respectively. We see TEAM-CL though performing competitively but is outperformed by TEAM-RG by a margin of (44.82, 86.01, 43.04) in MR, by a margin of (0.11, 0.12, 0.28) in Hit@1 and (0.14, 0.18, 0.43) in Hit@3 respectively for Assamese, Bengali and Hindi WordNet. In TEAM-RG(M), we obtain near-perfect MRR scores. This is because the definitions are already present in training set for the query concepts with known definitions (test sample drawn from the base taxonomy). The score of 1 indicates the ability of the proposed method TEAM-RG(M) to correctly identify the appropriate anchor nodes for the merge operation. TMN gives better performance than Taxo-Expan owing to its useful attention mechanism. But, Team-RG(A) outperforms TMN in all the metrics except Hits@1. We only compare Taxo-Expan results for the attach since it is originally proposed for the attach operation. In the (merge-M) and (merge+attach-MA) section of the tables also, we see that TEAM-RG outperforms TEAM-CL on all three WordNet taxonomies. We attribute this huge performance improvement of TEAM-RG to InfoNCE based training -as it simultaneously provides pseudo-supervision from the negative examples while optimizing for the task-specific regression layers.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_70",
            "content": "Classification Results",
            "ntype": "title",
            "meta": {
                "section": "5.2"
            }
        },
        {
            "ix": "28-ARR_v2_71",
            "content": "In Table [3], We observe similar trends on all three WordNet taxonomies. Since Taxo-Expan is a regression-based algorithm proposed for only attach operation in taxonomy expansion taskwe could not obtain its classification performance. Therefore, we only consider variants of our frameworks as competing methods. As described in the sub-section 3.4, using a classification layer on top of the regression layer in TEAM-RG, we obtain classification performances for the attach, merge operations along with both (attach+merge) operations. Whereas obtaining classification performance for TEAM-CL is straightforward since this is already a classification framework.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_72",
            "content": "When comparing TEAM-RG (attach) and (merge) variants -we see, unlike ranking results where ranking results of merge operation were always better than the attach operation, here the classification results of merge operation are inferior to attach operation. It means that the RG variant learns better ranking as compared to CL variants, but they fail to distinguish M and A -the operation to perform. This is expected since we do not provide a scheme here to contrast M and A operations -which is the motivation for our CL variant framework.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_73",
            "content": "When comparing TEAM-RG and TEAM-CL for (merge+attach), we see TEAM-CL gives better classification scores using test queries except for Macro-F1 scores. TEAM-RG gives the best performance for the Macro-F1 score for the test cases. This essentially means that class-wise prediction performances are inferior for TEAM-CL. This is expected behavior since, in each batch of the training sample, we include a substantially large number (N) of negative examples with class-label (N-No operation). We design our training samples like this so that the contrastive loss is better approximated. Nevertheless, it leads to a class-imbalance issue in our three-way classification setup, i.e., a large number of samples with N class labels as compared to the other M/ A class labels. Thus, TEAM-CL biases its prediction towards the N class, leading to poorer Macro-F1 scores than TEAM-RG.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_74",
            "content": "To summarize, we observe that TEAM-RG gives the best ranking performances, whereas TEAM-CL gives the best classification performances. TEAM- CL performs poorly in Macro-F1 since it presumably suffers from class-imbalance issues owing to the style of training sample generation. Frameworks with multi-task learning strategy (TEAM-RG and TEAM-CL) outperform frameworks (Taxo-Expan) designed to perform a single task -which is motivated by the fact that simultaneously optimizing for multiple tasks provides self-supervision to each other, resulting in better performances. To investigate the effectiveness of the proposed models, we employ the models for expanding a WordNet with OOV words. For this, first, we find out-of-vocabulary words, i.e., words that are not present in Assamese WordNet. Second, we manually identify true anchors of respective out-ofvocabulary words with associated operations (Attach/Merge) in Assamese WordNet. We evaluate the predicted results of the proposed model against the manually identified true anchors. Since we can either perform an A or M operation with OOV words and not both, we do not predict expansion tasks for OOV words using any of the MA variants of our proposed frameworks. Table 4 shows the ranking performance of the model in predicting true anchors for attach and merge expansion operations. We see a similar trend of prediction ranking as seen with the test set in our earlier experiments. TEAM-RG gives the best performance in both expansion operations. The detailed analysis of results is in Section F of the Appendix.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_75",
            "content": "Expansion of Assamese WordNet",
            "ntype": "title",
            "meta": {
                "section": "5.3"
            }
        },
        {
            "ix": "28-ARR_v2_76",
            "content": "Related Works",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "28-ARR_v2_77",
            "content": "Existing methods for taxonomy expansion can be divided into two categories: relying on alignment between multiple taxonomies [Ruiz-Casado et al. (2005), Toral et al. (2008), Ponzetto and Navigli (2009), and Yamada et al. (2011] or relying on machine learning-based rating sub-graphs. Further, the latter category can be divided into two sub-categories (1) by expanding synonymy relations/Merge (2) by expanding hypernymy relations/Attach. Synonymy-based taxonomy expansion leverages synonymy relations of the taxonomy. Given a seed taxonomy, the distributional approach discovers synonyms by representing strings with their distributional feature and learning a classifier to predict the relation between strings [ (Nakashole et al., 2012), (Wang et al., 2019), (Fei et al., 2019)]. Most of the recent taxonomy expansion approaches are based on hypernymy expansion. These methods attempt to determine the attachment position by scoring between several nodes. Recently numerous methods have been proposed to solve this problem (Shen et al., 2018), (Shen et al., 2020), (Yu et al., 2020b), (Zhang et al., 2021), . (Shen et al., 2020). Hence, all the existing taxonomy expansion approaches expand a taxonomy either by merge operation(synonymy expansion) or by attach operation(hypernymy expansion). However, particular to WordNet expansion it is an integrated task of Merge and attach operation. We are the first to study the problem of taxonomy expansion using both the Attach and Merge taxonomy expansion operations in a single model. A detailed related study is in Section A of the Appendix.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_78",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "7"
            }
        },
        {
            "ix": "28-ARR_v2_79",
            "content": "In this paper, we proposed an integrated framework called Taxonomy Expansion with Attach and Merge (TEAM) for expanding taxonomy with attach and merge operations together. We built two multi-task learning-based variants of TEAM, namely, TEAM-Regression and TEAM-Classification, which solve the taxonomy expansion problem as regression and classification, respectively. Our proposed methods learned to predict the taxonomy expansion operation (merge, attach, or no-operation) to perform and provided a ranked list of candidates. We evaluated the effectiveness of TEAM on WordNet taxonomies of three distinct languages, viz., Assamese, Bangla, and Hindi. In various experimental setups, the proposed TEAM-RG and TEAM-CL outperformed its state of the art for attach operation and provided a highly encouraging performance on merge operation. We had also investigated the performance of the proposed model with out-ofvocabulary concepts.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_80",
            "content": "In the future, we plan to investigate the response of the proposed model with different types of taxonomies and WordNet of different languages. Another future research possibility can be to explore the response of this model using advanced contextual encoders.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_81",
            "content": "Expansion by resource alignment: In the first category of studies, Poprat et al. (2008) first attempted to automatically expand a WordNet with biomedical terminology; however, they were unable in developing the resource. Ruiz-Casado et al. (2005), Toral et al. (2008), Ponzetto and Navigli (2009), and Yamada et al. (2011 exploit structured information in Wikipedia to expand Word-Net with new synsets. Snow et al. (2006) leverage distributional similarity techniques for WordNet expansion. Jurgens and Pilehvar (2015) enrich the existing WordNet taxonomy using an additional resource, Wiktionary, to extract sense data based on information in the term concepts. Synonymy Expansion: Synonymy expansion in a taxonomy leverages synonymy relations to enrich a taxonomy with new concepts. Approaches for synonymy expansion can be divided in to two categories: (1) Distributional based approach (Wang et al., 2019), (Fei et al., 2019) (2) Pattern-based approach (Nguyen et al., 2017), (Nakashole et al., 2012). Given a seed taxonomy, the distributional approach discovers synonyms by representing strings with their distributional feature and learning a classifier to predict the relation between strings. However, in the pattern-based approach, consider the sentences mentioning a pair of synonymous strings and learn some textual patterns from these sentences, which are further used to discover more synonyms. Qu et al. (2017) proposed an approach that integrates both the categories. Boteanu et al. (2018) focus on the problem of expanding taxonomies with synonyms for applications in which entities are complex concepts arranged into taxonomies designed to facilitate browsing the product catalog on amazon.com. They first generate synonymy candidates for each node in the taxonomy and then filter synonymy candidates using a binary classifier. Yu et al. (2020a) study a task of synonym expansion using transitivity named SYNET, which leverages both the contexts of two synonymy pairs. Hypernymy expansion : Jurgens and Pilehvar (2016) formulated a task of synonymy expansion, where it is proposed to enrich the WordNet taxonomy by performing two operations for each new concept. The first action is Attach, where a new concept is treated as a new synset and is attached as a hyponym of one existing synset in WordNet, and the second action is Merge, where a new concept is merged into an existing synset. The best solution proposed by Schlichtkrull and Alonso (2016) included only the attach operation. Later solutions for attaching, as in Shen et al. (2020), adopted selfsupervision and tried to exploit the information of nodes in the seed taxonomy to perform node pair matching. On the other hand, Yu et al. (2020b) resorted to classification along mini paths in the taxonomy. In contrast, in our current approach, we have incorporated both the attach and merge operations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_82",
            "content": "Graph Neural Network (GNN) allows us to transform and propagate node features as messages to learn structure-aware node representations. The EXTRACT() mechanism extracts the messages from a target node and its neighborhood, which is later on combined based on a chosen ATTEN-TION() mechanism by the AGGREGATE() operation. Next, the aggregated message is propagated to the rest of the graph. Studies apply various aggregation strategies to combine the propagated and extracted messages from the target node's neighborhood based on the importance of each node in the neighborhood towards that target node. GCN (Kipf and Welling, 2016) and GAT (Veli\u010dkovi\u0107 et al., 2017) are popular GNN frameworks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_83",
            "content": "GCN uses N ( * ) neighborhood-based normalization constant to calculate the importance (att v\u2212 \u2192u ) of node v towards the target node u without considering the participating nodes' features as follows.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_84",
            "content": "H l u = \u03c3 \u2200v\u2208 \u00d1 (u) att l\u22121 v\u2212 \u2192u W l\u22121 H l\u22121 v (9) ATTENTION GCN (v \u2212 \u2192 u) : att l\u22121 v\u2212 \u2192u = 1 | \u00d1 (u)|| \u00d1 (v)| EXTRACT GCN (v) : W l\u22121 H l\u22121 v AGGREGATE GCN ( * ) : \u03c3( * )",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_85",
            "content": "where \u03c3 is non-linear activation function, W l is a projection matrix for a GNN layer l and \u00d1 ( * ) is a node's extended neighborhood structure including the node itself (i.e., including self-loop edges). GAT uses the same message extraction and aggregation strategies as above except for the fact that it uses attentive aggregation strategies that consider both the participating nodes' features as well as the neighborhood information, as follows.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_86",
            "content": "ATTENTION GAT (v \u2212 \u2192 u) : att l\u22121 v\u2212 \u2192u = SOFTMAX \u2200v\u2208 \u00d1 (u) c l\u22121 (W l\u22121 H l\u22121 u \u2295 W l\u22121 H l\u22121 v )",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_87",
            "content": "where c l\u22121 is a learnable parameter to approximate the importance of node v towards u (att l\u22121 v\u2212 \u2192u ) based on their interaction in the latent space in l layerwise manner, W is the layer-wise projection matrix, and \u2295 denotes concatenation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_88",
            "content": "We use an array of performance metrics from the domain of classification and ranking to evaluate the competing methods' performances. Among the ranking metrics, we use Mean Rank (MR), Hit@k (k=1, 3), and Mean Reciprocal Rank (MRR) to judge how well a competing method performs in producing a ranked list of candidate anchors given a test query and a taxonomy expansion operation to carry-out -merge or attach.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_89",
            "content": "\u2022 Mean Rank: It calculates the average rank of true anchors among all the candidate anchors with respect to the matching scores, given a query. \u2022 Hit@k: It calculates the number of times a true anchor appears in the top k positions when matched with a test query. \u2022 Mean Reciprocal Rank(MRR): The Mean Reciprocal Rank is used to assess the ranking quality of the true anchor. The reciprocal rank can be computed by finding and inversing the rank of a true anchor in the predicted anchors' list of each query. MRR is averaged over all queries.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_90",
            "content": "Further, we use Accuracy, Micro/ Macro F1, Precision, Recall, and F-Scores as classification metrics for deciding given a test query and an initial taxonomy tree, which operation among merge (M), attach (A), and no-operation (N) is to be performed.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_91",
            "content": "\u2022 Accuracy: It summarizes the performance of the classification model as the fraction of the number of true tasks predicted over the total number of ground-truth tasks for a set of queries. \u2022 Precision: It calculates the fraction of truepositive predicted expansion task classes among the total number of true-positive and false-negative task classes. \u2022 Recall: It calculates the fraction of truepositive predicted expansion task classes among all the relevant ground-truth task classes. \u2022 F-Score: The harmonic mean of precision and recall. It is also known as F1-Score. \u2022 Micro/ Macro F1 : The Macro F1 computes F1-Score for each class (merge M/ attach A) independently but averages the final score by treating each expansion task-class as equally contributing. However, Micro F1 computes the F1-Score for each query sample in the training set and therefore aggregates the contributions of all expansion task classes to compute the final average metric.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_92",
            "content": "We obtain the initial feature vector for train and test concepts using pre-trained subword-aware Fasttext embeddings. For each concept, we generate its definition embedding by averaging the embedding of each word in its textual definition. We employ PyTorch and DGL framework 3 to load and train embeddings. In TEAM, we use a two-layer position-enhanced GAT where the first layer (of size 300) has four attention heads and the second layer (of size 600) has one attention head. We use 50-dimension position embeddings for both layers and apply dropout with the rate of 0.1 on the input feature vectors. We use Adam optimizer with an initial learning rate of 0.001.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_93",
            "content": "In the case of attach expansion, TEAM-RG beats state-of-the-art Taxo-expan by a large margin of (321, 0.31, 0.48, 0.69) in MR, Hit@1, Hit@3, MRR, respectively. However, our proposed frameworks are seen not to perform so well in merge M operation as compared to the attach A operation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_94",
            "content": "Intuitively, this is because, for OOV words, we use a set of manually collected paraphrase definitions of the OOV words to match them with the candidate anchor concepts in the existing taxonomy.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_95",
            "content": "Whereas for actually training our model, we have used the same definitions in the replica nodes. That is, we have used the same definition in the original anchor concept and in the input query-concept with mutually exclusive synset information. Thus, in this case-study, the paraphrase-based definition matching deems challenging for our learning model resulting in poorer results for M operation. We believe we can always eliminate this drawback by using a description generation tool (Wang et al., 2021) to generate different definitions of the same concept nodes and train our learning model in a more powerful way.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "28-ARR_v2_96",
            "content": "James Allan, Ron Papka, Victor Lavrenko, On-line new event detection and tracking, 1998, Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval, ACM.",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "James Allan",
                    "Ron Papka",
                    "Victor Lavrenko"
                ],
                "title": "On-line new event detection and tracking",
                "pub_date": "1998",
                "pub_title": "Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval",
                "pub": "ACM"
            }
        },
        {
            "ix": "28-ARR_v2_97",
            "content": ", Pushpak Bhattacharyya. 2010. Indowordnet, , Proc. of LREC-10, Citeseer.",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [],
                "title": "Pushpak Bhattacharyya. 2010. Indowordnet",
                "pub_date": null,
                "pub_title": "Proc. of LREC-10",
                "pub": "Citeseer"
            }
        },
        {
            "ix": "28-ARR_v2_98",
            "content": "Adrian Boteanu, Adam Kiezun, Shay Artzi, Synonym expansion for large shopping taxonomies, 2018, Automated Knowledge Base Construction (AKBC), .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "Adrian Boteanu",
                    "Adam Kiezun",
                    "Shay Artzi"
                ],
                "title": "Synonym expansion for large shopping taxonomies",
                "pub_date": "2018",
                "pub_title": "Automated Knowledge Base Construction (AKBC)",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_99",
            "content": "Hongliang Fei, Shulong Tan, Ping Li, Hierarchical multi-task word embedding learning for synonym prediction, 2019, Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Hongliang Fei",
                    "Shulong Tan",
                    "Ping Li"
                ],
                "title": "Hierarchical multi-task word embedding learning for synonym prediction",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_100",
            "content": "Michael Gutmann, Aapo Hyv\u00e4rinen, Noisecontrastive estimation: A new estimation principle for unnormalized statistical models, 2010, Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Michael Gutmann",
                    "Aapo Hyv\u00e4rinen"
                ],
                "title": "Noisecontrastive estimation: A new estimation principle for unnormalized statistical models",
                "pub_date": "2010",
                "pub_title": "Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_101",
            "content": "David Jurgens, Mohammad Taher Pilehvar, Reserating the awesometastic: An automatic extension of the wordnet taxonomy for novel terms, 2015, Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "David Jurgens",
                    "Mohammad Taher Pilehvar"
                ],
                "title": "Reserating the awesometastic: An automatic extension of the wordnet taxonomy for novel terms",
                "pub_date": "2015",
                "pub_title": "Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_102",
            "content": "David Jurgens, Mohammad Taher Pilehvar, Semeval-2016 task 14: Semantic taxonomy enrichment, 2016, Proceedings of the 10th international workshop on semantic evaluation (SemEval-2016), .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "David Jurgens",
                    "Mohammad Taher Pilehvar"
                ],
                "title": "Semeval-2016 task 14: Semantic taxonomy enrichment",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 10th international workshop on semantic evaluation (SemEval-2016)",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_103",
            "content": "UNKNOWN, None, 2016, Semisupervised classification with graph convolutional networks, .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": null,
                "title": null,
                "pub_date": "2016",
                "pub_title": "Semisupervised classification with graph convolutional networks",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_104",
            "content": "Zichen Liu, Hongyuan Xu, Yanlong Wen, Ning Jiang, Haiying Wu, Xiaojie Yuan, Temp: Taxonomy expansion with dynamic margin loss through taxonomy-paths, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Zichen Liu",
                    "Hongyuan Xu",
                    "Yanlong Wen",
                    "Ning Jiang",
                    "Haiying Wu",
                    "Xiaojie Yuan"
                ],
                "title": "Temp: Taxonomy expansion with dynamic margin loss through taxonomy-paths",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_105",
            "content": "UNKNOWN, None, 1998, WordNet: An electronic lexical database, MIT press.",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": null,
                "title": null,
                "pub_date": "1998",
                "pub_title": "WordNet: An electronic lexical database",
                "pub": "MIT press"
            }
        },
        {
            "ix": "28-ARR_v2_106",
            "content": "Ndapandula Nakashole, Gerhard Weikum, Fabian Suchanek, Patty: A taxonomy of relational patterns with semantic types, 2012, Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Ndapandula Nakashole",
                    "Gerhard Weikum",
                    "Fabian Suchanek"
                ],
                "title": "Patty: A taxonomy of relational patterns with semantic types",
                "pub_date": "2012",
                "pub_title": "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_107",
            "content": "UNKNOWN, None, 2017, Distinguishing antonyms and synonyms in a pattern-based neural network, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": "Distinguishing antonyms and synonyms in a pattern-based neural network",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_108",
            "content": "UNKNOWN, None, 2018, Representation learning with contrastive predictive coding, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Representation learning with contrastive predictive coding",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_109",
            "content": "UNKNOWN, None, 2008, Opinion mining and sentiment analysis. Foundations and Trends\u00ae in Information Retrieval, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": null,
                "title": null,
                "pub_date": "2008",
                "pub_title": "Opinion mining and sentiment analysis. Foundations and Trends\u00ae in Information Retrieval",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_110",
            "content": "Paolo Simone, Roberto Ponzetto,  Navigli, Large-scale taxonomy mapping for restructuring and integrating wikipedia, 2009, IJCAI, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Paolo Simone",
                    "Roberto Ponzetto",
                    " Navigli"
                ],
                "title": "Large-scale taxonomy mapping for restructuring and integrating wikipedia",
                "pub_date": "2009",
                "pub_title": "IJCAI",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_111",
            "content": "Michael Poprat, Elena Beisswanger, Udo Hahn, Building a biowordnet using wordnet data structures and wordnet's software infrastructure-a failure story, 2008, Software engineering, testing, and quality assurance for natural language processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Michael Poprat",
                    "Elena Beisswanger",
                    "Udo Hahn"
                ],
                "title": "Building a biowordnet using wordnet data structures and wordnet's software infrastructure-a failure story",
                "pub_date": "2008",
                "pub_title": "Software engineering, testing, and quality assurance for natural language processing",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_112",
            "content": "Meng Qu, Xiang Ren, Jiawei Han, Automatic synonym discovery with knowledge bases, 2017, Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "Meng Qu",
                    "Xiang Ren",
                    "Jiawei Han"
                ],
                "title": "Automatic synonym discovery with knowledge bases",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_113",
            "content": "Maria Ruiz-Casado, Enrique Alfonseca, Pablo Castells, Automatic assignment of wikipedia encyclopedic entries to wordnet synsets, 2005, International Atlantic Web Intelligence Conference, Springer.",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Maria Ruiz-Casado",
                    "Enrique Alfonseca",
                    "Pablo Castells"
                ],
                "title": "Automatic assignment of wikipedia encyclopedic entries to wordnet synsets",
                "pub_date": "2005",
                "pub_title": "International Atlantic Web Intelligence Conference",
                "pub": "Springer"
            }
        },
        {
            "ix": "28-ARR_v2_114",
            "content": "Michael Schlichtkrull, Alonso H\u00e9ctor Mart\u00ednez, Msejrku at semeval-2016 task 14: Taxonomy enrichment by evidence ranking, 2016, Proceedings of the 10th international workshop on semantic evaluation (SemEval-2016), .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Michael Schlichtkrull",
                    "Alonso H\u00e9ctor Mart\u00ednez"
                ],
                "title": "Msejrku at semeval-2016 task 14: Taxonomy enrichment by evidence ranking",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 10th international workshop on semantic evaluation (SemEval-2016)",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_115",
            "content": "Jiaming Shen, Zhihong Shen, Chenyan Xiong, Chi Wang, Kuansan Wang, Jiawei Han, Taxoexpan: self-supervised taxonomy expansion with position-enhanced graph neural network, 2020, Proceedings of The Web Conference 2020, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "Jiaming Shen",
                    "Zhihong Shen",
                    "Chenyan Xiong",
                    "Chi Wang",
                    "Kuansan Wang",
                    "Jiawei Han"
                ],
                "title": "Taxoexpan: self-supervised taxonomy expansion with position-enhanced graph neural network",
                "pub_date": "2020",
                "pub_title": "Proceedings of The Web Conference 2020",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_116",
            "content": "Jiaming Shen, Zeqiu Wu, Dongming Lei, Chao Zhang, Xiang Ren, Michelle Vanni, Brian Sadler, Jiawei Han, Hiexpan: Task-guided taxonomy construction by hierarchical tree expansion, 2018, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Jiaming Shen",
                    "Zeqiu Wu",
                    "Dongming Lei",
                    "Chao Zhang",
                    "Xiang Ren",
                    "Michelle Vanni",
                    "Brian Sadler",
                    "Jiawei Han"
                ],
                "title": "Hiexpan: Task-guided taxonomy construction by hierarchical tree expansion",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_117",
            "content": "Amit Singhal, Modern information retrieval: A brief overview, 2001, IEEE Data Eng. Bull, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "Amit Singhal"
                ],
                "title": "Modern information retrieval: A brief overview",
                "pub_date": "2001",
                "pub_title": "IEEE Data Eng. Bull",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_118",
            "content": "Rion Snow, Daniel Jurafsky, Andrew Ng, Semantic taxonomy induction from heterogenous evidence, 2006, Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Rion Snow",
                    "Daniel Jurafsky",
                    "Andrew Ng"
                ],
                "title": "Semantic taxonomy induction from heterogenous evidence",
                "pub_date": "2006",
                "pub_title": "Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "28-ARR_v2_119",
            "content": "Kunihiro Takeoka, Kosuke Akimoto, Masafumi Oyamada, Low-resource taxonomy enrichment with pretrained language models, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Kunihiro Takeoka",
                    "Kosuke Akimoto",
                    "Masafumi Oyamada"
                ],
                "title": "Low-resource taxonomy enrichment with pretrained language models",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_120",
            "content": "Antonio Toral, Rafael Mu\u00f1oz, Monica Monachini, Named entity WordNet, 2008, Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC'08), .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Antonio Toral",
                    "Rafael Mu\u00f1oz",
                    "Monica Monachini"
                ],
                "title": "Named entity WordNet",
                "pub_date": "2008",
                "pub_title": "Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC'08)",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_121",
            "content": "Nikhita Vedula, K Patrick, Deepak Nicholson, Sourav Ajwani, Alessandra Dutta, Srinivasan Sala,  Parthasarathy, Enriching taxonomies with functional domain knowledge, 2018, The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval, .",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Nikhita Vedula",
                    "K Patrick",
                    "Deepak Nicholson",
                    "Sourav Ajwani",
                    "Alessandra Dutta",
                    "Srinivasan Sala",
                    " Parthasarathy"
                ],
                "title": "Enriching taxonomies with functional domain knowledge",
                "pub_date": "2018",
                "pub_title": "The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_122",
            "content": "UNKNOWN, None, 2017, , .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": null,
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_123",
            "content": "Jin Wang, Chunbin Lin, Mingda Li, Carlo Zaniolo, An efficient sliding window approach for approximate entity extraction with synonyms, 2019, EDBT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": [
                    "Jin Wang",
                    "Chunbin Lin",
                    "Mingda Li",
                    "Carlo Zaniolo"
                ],
                "title": "An efficient sliding window approach for approximate entity extraction with synonyms",
                "pub_date": "2019",
                "pub_title": "EDBT",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_124",
            "content": "Suyuchen Wang, Ruihui Zhao, Xi Chen, Yefeng Zheng, Bang Liu, Enquire one's parent and child before decision: Fully exploit hierarchical structure for self-supervised taxonomy expansion, 2021, Proceedings of the Web Conference 2021, .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Suyuchen Wang",
                    "Ruihui Zhao",
                    "Xi Chen",
                    "Yefeng Zheng",
                    "Bang Liu"
                ],
                "title": "Enquire one's parent and child before decision: Fully exploit hierarchical structure for self-supervised taxonomy expansion",
                "pub_date": "2021",
                "pub_title": "Proceedings of the Web Conference 2021",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_125",
            "content": "Ichiro Yamada, Jong-Hoon Oh, Chikara Hashimoto, Kentaro Torisawa, Stijn Jun'ichi Kazama, Takuya De Saeger,  Kawada, Extending WordNet with hypernyms and siblings acquired from Wikipedia, 2011, Proceedings of 5th International Joint Conference on Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "Ichiro Yamada",
                    "Jong-Hoon Oh",
                    "Chikara Hashimoto",
                    "Kentaro Torisawa",
                    "Stijn Jun'ichi Kazama",
                    "Takuya De Saeger",
                    " Kawada"
                ],
                "title": "Extending WordNet with hypernyms and siblings acquired from Wikipedia",
                "pub_date": "2011",
                "pub_title": "Proceedings of 5th International Joint Conference on Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_126",
            "content": "Jiale Yu, Yongliang Shen, Xinyin Ma, Chenghao Jia, Chen Chen, Weiming Lu, Synet: Synonym expansion using transitivity, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": [
                    "Jiale Yu",
                    "Yongliang Shen",
                    "Xinyin Ma",
                    "Chenghao Jia",
                    "Chen Chen",
                    "Weiming Lu"
                ],
                "title": "Synet: Synonym expansion using transitivity",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_127",
            "content": "Yue Yu, Yinghao Li, Jiaming Shen, Hao Feng, Jimeng Sun, Chao Zhang, Steam: Selfsupervised taxonomy expansion with mini-paths, 2020, Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": [
                    "Yue Yu",
                    "Yinghao Li",
                    "Jiaming Shen",
                    "Hao Feng",
                    "Jimeng Sun",
                    "Chao Zhang"
                ],
                "title": "Steam: Selfsupervised taxonomy expansion with mini-paths",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining",
                "pub": null
            }
        },
        {
            "ix": "28-ARR_v2_128",
            "content": "UNKNOWN, None, 2021, Taxonomy completion via triplet matching network, .",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Taxonomy completion via triplet matching network",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "28-ARR_v2_0@0",
            "content": "TEAM: A multitask learning based Taxonomy Expansion approach for Attach and Merge",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_0",
            "start": 0,
            "end": 80,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_2@0",
            "content": "Taxonomy expansion is a crucial task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_2",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_2@1",
            "content": "Most of the taxonomy expansion approaches are of two types, attach and merge.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_2",
            "start": 38,
            "end": 114,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_2@2",
            "content": "In a taxonomy like WordNet, both merge and attach are integral parts of the expansion operations, but the majority of studies consider them separately.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_2",
            "start": 116,
            "end": 266,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_2@3",
            "content": "This paper proposes a novel multi-task learning-based deep learning method known as Taxonomy Expansion with Attach and Merge (TEAM) that performs both the merge and attach operations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_2",
            "start": 268,
            "end": 450,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_2@4",
            "content": "This is the first study that integrates both the merge and attach operations in a single model to the best of our knowledge.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_2",
            "start": 452,
            "end": 575,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_2@5",
            "content": "The proposed models have been evaluated on three separate WordNet taxonomies, viz., Assamese, Bangla, and Hindi.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_2",
            "start": 577,
            "end": 688,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_2@6",
            "content": "From the various experimental setups, it is shown that TEAM outperforms its state-of-the-art counterparts for attach operation and also provides highly encouraging performance for the merge operation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_2",
            "start": 690,
            "end": 889,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_4@0",
            "content": "Taxonomy, such as the WordNet, is a crucial resource for developing NLP related technologies, as it plays a vital role in various text processing tasks such as information retrieval, information extraction, text classification, summarization, etc. (Pang et al., 2008;Allan et al., 1998;Singhal et al., 2001) (Miller, 1998.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_4",
            "start": 0,
            "end": 321,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_4@1",
            "content": "As most of the WordNets are manually curated, it often suffers from the problem of limited coverage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_4",
            "start": 323,
            "end": 422,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_4@2",
            "content": "Therefore, an automatic taxonomy expansion is a crucial problem to handle the above issue.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_4",
            "start": 424,
            "end": 513,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_4@3",
            "content": "For taxonomy expansion, WordNet in particular, may need two types of operations; (i) merge, where a new concept 1 is merged to an existing node, and (ii) attach, where a new concept is inserted as a new node.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_4",
            "start": 515,
            "end": 722,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_4@4",
            "content": "Figure 1 illustrates these two operations where the word Mango is inserted as a new concept with the attach operation, and the \"Mango\" is a specific concept of Fruit not present in the existing WordNet.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_4",
            "start": 724,
            "end": 925,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_4@5",
            "content": "Hence, a new concept node is created in the taxonomy by attaching it to its generic concept Fruit .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_4",
            "start": 927,
            "end": 1025,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_4@6",
            "content": "As \"Nutrient\" refers to the same concept as \"Food\", no new concept is created. \"Nutrient\" is merged with the existing concept \"Food\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_4",
            "start": 1027,
            "end": 1159,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_5@0",
            "content": "word Nutrient is inserted as a new synonymy in an existing concept with the merge operation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_5",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_6@0",
            "content": "Though both of these operations are integral parts of a WordNet taxonomy expansion, all of the existing studies on taxonomy expansion have considered expansion with either attach operation (Schlichtkrull and Alonso, 2016;Vedula et al., 2018;Shen et al., 2020;Yu et al., 2020b;Zhang et al., 2021;Takeoka et al., 2021; or merge operation (Nakashole et al., 2012;Nguyen et al., 2017;Nakashole et al., 2012;Qu et al., 2017;Boteanu et al., 2018;Wang et al., 2019;Fei et al., 2019), but not together.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_6",
            "start": 0,
            "end": 493,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_6@1",
            "content": "Realizing the need to apply both the operation, SemEval-2016:task 14 (Semantic taxonomy enrichment) Jurgens and Pilehvar (2016) includes a call for expansion with both attach and merge operations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_6",
            "start": 495,
            "end": 690,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_6@2",
            "content": "However, none of the submissions incorporate both operations in a single model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_6",
            "start": 692,
            "end": 770,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_6@3",
            "content": "Motivated by the above observations, in this study, we propose an integrated deep learningbased method, namely, Taxonomy Expansion with Attach and Merge (TEAM), which performs both the attach and merge operations in a multitasklearning framework.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_6",
            "start": 772,
            "end": 1017,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_6@4",
            "content": "Though most of the existing studies consider the expansion a regression problem (Shen et al., 2020;Yu et al., 2020b;Zhang et al., 2021), considering that our method performs both the attach and merge operation in a single model, it can also be considered a classification task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_6",
            "start": 1019,
            "end": 1295,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_6@5",
            "content": "As a result, we propose two versions of TEAM, namely, TEAM-RG: Regression, and TEAM-CL: Classification to perform with explicit and implicit rankings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_6",
            "start": 1297,
            "end": 1446,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_6@6",
            "content": "The proposed models have been evaluated on three different WordNet taxonomies, viz., Assamese, Bangla, and Hindi.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_6",
            "start": 1448,
            "end": 1560,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_6@7",
            "content": "From the various experimental setups, it is observed that the proposed TEAM-RG and TEAM-CL outperform their baselines counterparts for attach operation, and also obtained encouraging performance for merge operation as well.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_6",
            "start": 1562,
            "end": 1784,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_6@8",
            "content": "The major contributions of the paper are summarized as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_6",
            "start": 1786,
            "end": 1848,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_7@0",
            "content": "\u2022 A multi-task learning based taxonomy expansion framework TEAM is jointly trained to perform both the Attach and Merge operations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_7",
            "start": 0,
            "end": 130,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_8@0",
            "content": "To the best of our knowledge, it is the first integrated model to perform both the Attach and Merge operations in a single model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_8",
            "start": 0,
            "end": 128,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_9@0",
            "content": "\u2022 Two variants of TEAM, namely TEAM-Regression (RG) and TEAM-Classification (CL) are proposed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_9",
            "start": 0,
            "end": 93,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_10@0",
            "content": "Taxonomy Expansion -Attach and Merge",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_10",
            "start": 0,
            "end": 35,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_11@0",
            "content": "In this study, we have considered WordNets as our target taxonomies.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_11",
            "start": 0,
            "end": 67,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_11@1",
            "content": "A WordNet may be defined by a collection of concepts connected by various semantic relationships such as hypernymy, hyponymy, troponymy, etc., where each concept is further defined by a set of attributes such as definition, synonyms, examples, etc (Bhattacharyya, 2010).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_11",
            "start": 69,
            "end": 338,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_11@2",
            "content": "In this study, we have considered only the hypernymy relation and the definition and synonymy attributes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_11",
            "start": 340,
            "end": 444,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_12@0",
            "content": "In order to be able to apply the proposed model, we first transform the original WordNet taxonomy into an experimental intermediate taxonomy ( directed unweighted acyclic graph) T = (V, E) where V represents the set of concepts and E represents the set of hypernymy relations between the concepts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_12",
            "start": 0,
            "end": 296,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_12@1",
            "content": "A concept v \u2208 V is further defined by a tuple v = (d v , s v ) where d v represents the definition of the concept, and s v represents the set of associated synonyms.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_12",
            "start": 298,
            "end": 462,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_12@2",
            "content": "An edge e \u2208 E represents a hypernymy relation from a parent concept v p to its child concept v ch and is denoted as",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_12",
            "start": 464,
            "end": 578,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_13@0",
            "content": "e : (v p hyper \u2212 \u2212\u2212 \u2192 v ch )",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_13",
            "start": 0,
            "end": 27,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_14@0",
            "content": ".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_14",
            "start": 0,
            "end": 0,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_14@1",
            "content": "The taxonomy T is arranged in a hierarchical manner with directed edges in E, as shown in Figure 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_14",
            "start": 2,
            "end": 100,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_14@2",
            "content": "Given the taxonomy T and a query concept q = (d q , s q ), the attach and the merge expansion operations are defined below.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_14",
            "start": 102,
            "end": 224,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_15@0",
            "content": "Attach (A) -An attach operation is performed when the concept q is not present in T. The objective of the attach operation is to identify the best matching parent node in taxonomy network known as anchor concept a = (d a , s a ), and insert a new concept q with an edge e : (a hyper \u2212 \u2212\u2212 \u2192 q).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_15",
            "start": 0,
            "end": 292,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_15@1",
            "content": "In a taxonomy network, a parent node represents a more generic concept of its children.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_15",
            "start": 294,
            "end": 380,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_15@2",
            "content": "After an attach operation i.e., insertion of q in T under the anchor a, the expanded taxonomy is updated as follows.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_15",
            "start": 382,
            "end": 497,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_16@0",
            "content": "T = (V \u222a {q}, E \u222a {e})(1)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_16",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_17@0",
            "content": "Merge (M) -A merge operation is performed when an equivalent concept a = (d a , s a ) of the query q (i.e., d a \u2261 d q ) is already present in T, but the synset s q is not present in a (i.e., s q \u2229 s a = \u2205).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_17",
            "start": 0,
            "end": 205,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_17@1",
            "content": "The objective of the merge operation is to identify the best matching concept a = (d a , s a ), known as the anchor concept, in the taxonomy network T and add the synset s q to s a .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_17",
            "start": 207,
            "end": 388,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_17@2",
            "content": "It neither creates a new node nor adds a new edge.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_17",
            "start": 390,
            "end": 439,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_17@3",
            "content": "It only updates the synset of the anchor concept.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_17",
            "start": 441,
            "end": 489,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_17@4",
            "content": "After the merge operation, the updated anchor concept in the expanded taxonomy can be expressed as follows.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_17",
            "start": 491,
            "end": 597,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_18@0",
            "content": "a = (d a , s a \u222a s q ) : a \u2208 V (2)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_18",
            "start": 0,
            "end": 33,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_19@0",
            "content": "3 Proposed Methods",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_19",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_20@0",
            "content": "Our objective is to develop an integrated model that performs both attach and merge operations for taxonomy expansion.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_20",
            "start": 0,
            "end": 117,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_20@1",
            "content": "Since we have two tasks to unify in a single model, we resort to a multi-task learning framework known as Taxonomy Expansion Framework with Attach and Merge (TEAM).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_20",
            "start": 119,
            "end": 282,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_20@2",
            "content": "This joint learning objective facilitates information flow so that the two tasks can aid each other.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_20",
            "start": 284,
            "end": 383,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_20@3",
            "content": "Also, we are interested in deciding which expansion operation is to perform given a triplet (expansion task classification) and retrieving the ranked list of candidates (ranking) as prospective anchors to associate the query with.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_20",
            "start": 385,
            "end": 614,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_20@4",
            "content": "For this first-of-its-kind novel taxonomy expansion task, we propose two versions of TEAM, namely TEAM-Regression (TEAM-RG) and TEAM-Classification (TEAM-CL) -where we show that using either regression or classification learning objectives, this task can be accomplished.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_20",
            "start": 616,
            "end": 886,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_21@0",
            "content": "Training dataset generation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_21",
            "start": 0,
            "end": 26,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_22@0",
            "content": "Given a transformed taxonomy T (as described in Section 2), we generate a training dataset for building the model as follows.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_22",
            "start": 0,
            "end": 124,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_22@1",
            "content": "The training samples are defined by a 3-tuple < q, a, label >, where q is the query, a is the potential anchor, and label is associated class, i.e., true/false (1/0).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_22",
            "start": 126,
            "end": 291,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_22@2",
            "content": "We randomly select a set of nodes in T as a set of queries 2 , and generate the training samples for the attach and the merge operations separately as follows.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_22",
            "start": 293,
            "end": 451,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_23@0",
            "content": "Attach (A) -We first remove the query nodes from the T. For each query q = (d q , s q ), we consider its parent as anchor node a = (d a , s a ) and generate positive sample < q, a, T RU E >.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_23",
            "start": 0,
            "end": 189,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_23@1",
            "content": "We then randomly pick up N number other nodes a \u2032 = (d a \u2032 , s a \u2032 ), and generate N negative samples < q, a \u2032 , F ALSE >.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_23",
            "start": 191,
            "end": 312,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_23@2",
            "content": "Thus, for a given query node q, we extract one positive and N negative samples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_23",
            "start": 314,
            "end": 392,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_24@0",
            "content": "Merge (M) -For each of the randomly selected query node x = (d x , s x >) in T, we generate the following positive training sample < q, x, T rue > where q = (d x , s q ), s q \u2282 s x is the query and x = (d x , s x \u2212s q ) is the anchor.The s q is a randomly selected synonym in s x .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_24",
            "start": 0,
            "end": 280,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_24@1",
            "content": "Unlike attach, for generating the training sample for the query q, we only remove the query synset s q from the anchor synset s x i.e., s x = s x \u2212s q , and, not the node.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_24",
            "start": 282,
            "end": 452,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_24@2",
            "content": "Like attach, we randomly pick up N number other nodes a \u2032 , and generate N negative samples < q, a \u2032 , F ALSE >.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_24",
            "start": 454,
            "end": 565,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_25@0",
            "content": "2 As we consider the same query set for both attach and merge experiments, nodes with at least two synonyms are considered.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_25",
            "start": 0,
            "end": 122,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_26@0",
            "content": "TEAM-Regression (TEAM-RG)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_26",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_27@0",
            "content": "The proposed TEAM-RG works in two tiers process.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_27",
            "start": 0,
            "end": 47,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_27@1",
            "content": "Given a training input sample < q, a, c >, it first generates encoding of the query q and the anchor a.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_27",
            "start": 49,
            "end": 151,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_28@0",
            "content": "It then merges to a shared layer to produce two different multi-tasking dense networks; one for merge and another for attach, as shown in figure 4.D.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_28",
            "start": 0,
            "end": 148,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_29@0",
            "content": "For learning embedding of the anchor concept from the taxonomy network and the query concept from the associated attributes, we consider the publicly available Fasttext pre-trained embedding available at https://fasttext.cc/docs/ en/crawl-vectors.html.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_29",
            "start": 0,
            "end": 251,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_30@0",
            "content": "Processing of the query concept: As mentioned in Section 2, a query concept consists of its definition and the associated synset i.e., q = (d q , s q ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_30",
            "start": 0,
            "end": 151,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_30@1",
            "content": "The definition is a piece of text describing the concept, and the synset is a synonym associated with the query concept. .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_30",
            "start": 153,
            "end": 274,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_30@2",
            "content": "The two embeddings are then concatenated to represent the query.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_30",
            "start": 276,
            "end": 339,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_31@0",
            "content": "Processing of the anchor concept: For generating the encoding of the anchor concept, we exploit the proximity structure of the nodes in the taxonomy T. For a given anchor node a \u2208 T, we first extract its ego-tree from the taxonomy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_31",
            "start": 0,
            "end": 230,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_31@1",
            "content": "An ego tree T a : (V a , E a ) of a node a in the taxonomy T is a sub-tree that comprises the node a and its k-hop neighborhood nodes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_31",
            "start": 232,
            "end": 365,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_31@2",
            "content": "In this study, we considered k = 1, i.e., the anchor node, its parent node, and all its children nodes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_31",
            "start": 367,
            "end": 469,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_31@3",
            "content": "Figure 3 illustrates an example of an ego tree.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_31",
            "start": 471,
            "end": 517,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_31@4",
            "content": "A similar approach has also been used in (Wang et al., 2021;Yu et al., 2020b;Zhang et al., 2021;Shen et al., 2020) studies.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_31",
            "start": 519,
            "end": 641,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_31@5",
            "content": "To obtain the embedding of the anchor concept, we further apply graph embedding as described below.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_31",
            "start": 643,
            "end": 741,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_32@0",
            "content": "Embedding Ego-tree",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_32",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_33@0",
            "content": "Ideally, we should be able to use any graph embedding method to obtain the embedding of the anchor node.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_33",
            "start": 0,
            "end": 103,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_33@1",
            "content": "As the objective is to incorporate the positional information of the parent and children node in the ego tree, we use the Graph Attention Network (GAT) proposed in Taxo-Expan (Shen et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_33",
            "start": 105,
            "end": 299,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_33@2",
            "content": "This GAT is a special type of graph neural network (GNN) (Kipf and Welling, 2016) with a neighborhood-based attention mechanism.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_33",
            "start": 301,
            "end": 428,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_33@3",
            "content": "The details of GAT and its difference from GNN are given in Section B of Appendix.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_33",
            "start": 430,
            "end": 511,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_33@4",
            "content": "Thus we used position enhanced GAT to obtain the node embeddings of an anchor's ego tree.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_33",
            "start": 513,
            "end": 601,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_34@0",
            "content": "We summarize the tree by applying an activation function over the average of the embedding vectors of all nodes in the ego-tree as given in equation 3 to define the encoding of the anchor node.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_34",
            "start": 0,
            "end": 192,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_35@0",
            "content": "Ta = \u03c3 1 |V a | x\u2208Va x(3)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_35",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_36@0",
            "content": "where \u03c3(.) is an activation function.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_36",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_36@1",
            "content": "We have considered Sigmoid function in this study.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_36",
            "start": 38,
            "end": 87,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_37@0",
            "content": "Multi-task Learning",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_37",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_38@0",
            "content": "Once we obtain the embeddings of the anchor and query concepts, the concatenated vector is subjected to a shared dense layer and then build two multi-task layers to perform the merge and attach operations as shown in Figure 4.D. Given a query concept and its true anchor concept with N false anchor concepts, the task is to design a regressionbased ranking model such that the true concept is ranked higher than the N false concepts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_38",
            "start": 0,
            "end": 432,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_38@1",
            "content": "This objective should be realized for all the queries in the training dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_38",
            "start": 434,
            "end": 511,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_39@0",
            "content": "Given the embedding vectors of anchor \u0101 and query q as learned above, we first estimate similarity between the two using a bi-linear model proposed in (Gutmann and Hyv\u00e4rinen, 2010).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_39",
            "start": 0,
            "end": 180,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_39@1",
            "content": "It learns the discrimination between q and a through a learnable bi-linear scoring matrix B \u2208 R |q|\u00d7|\u0101| via a function D : R |q|\u00d7|\u0101| \u2192 R as follows.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_39",
            "start": 182,
            "end": 329,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_40@0",
            "content": "D(q, a) = \u03c3(q T B\u0101) (4)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_40",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_41@0",
            "content": "Here \u03c3 is sigmoid non-linearity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_41",
            "start": 0,
            "end": 31,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_41@1",
            "content": "The output of this matching module is a probability estimate indicating the strength of association between the query and anchor.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_41",
            "start": 33,
            "end": 161,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_41@2",
            "content": "Now, considering the query concept q and its associated N + 1 anchor concepts, we estimate the probability of being the correct anchor using InfoNCE loss proposed in (Oord et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_41",
            "start": 163,
            "end": 348,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_41@3",
            "content": "Let X be a set of query concepts and their respective N + 1 anchor nodes (one positive and N negative).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_41",
            "start": 350,
            "end": 452,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_41@4",
            "content": "An element of x q \u2208 X for a given query q consists of {(q, a, 1), (q, a \u2032 1 , a \u2032 2 , ..., a \u2032 N , 0)}, where a is the positive anchor, and a \u2032 are the negative anchors of q. InfoNCE estimates loss function using an average probability of being true anchor node across the dataset X as follows.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_41",
            "start": 454,
            "end": 747,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_42@0",
            "content": "L A/M = \u2212 1 |X| xq\u2208X log D(q, \u0101) v\u2208M(q) D(q, v)(5)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_42",
            "start": 0,
            "end": 49,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_43@0",
            "content": "where M(q) denotes the set of both positive and negative anchors of q. As mentioned earlier, the loss defined in Equation 5 is estimated separately for attach and merge operations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_43",
            "start": 0,
            "end": 179,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_43@1",
            "content": "Therefore, we generate two different training datasets for attach and merge, and estimate L A and L M separately using respective datasets, The final model loss is defined as L = L A + L M -considering both the operations attach and merge.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_43",
            "start": 181,
            "end": 419,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_44@0",
            "content": "TEAM-Classification (TEAM-CL)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_44",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_45@0",
            "content": "Figure 4E shows the schematic diagram of the TEAM-CL.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_45",
            "start": 0,
            "end": 52,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_45@1",
            "content": "We use the identical representations for query q and candidate anchors a A , a M as described for TEAM-RG.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_45",
            "start": 54,
            "end": 159,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_45@2",
            "content": "We also adopt the same position-enhanced graph propagation and read-out modules as described in Section 3.2.1 for learning anchor a = (d a , s a ) concept representation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_45",
            "start": 161,
            "end": 330,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_45@3",
            "content": "Once we obtain the query and anchor representations, we model the strength of association of an input query and the candidate anchors based on their features to predict the expansion task i.e., merge M or attach A. The matching module, a multilayer perceptron (MLP) based classifier, takes the features of query q \u2208 R |q| and anchor \u0101 \u2208 R |\u0101| , and generates a contextualized pair representation k = [q \u2295(q \u2212\u0101)\u2295(q \u00d7\u0101)\u2295\u0101] (assuming |q| = |\u0101|).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_45",
            "start": 332,
            "end": 773,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_46@0",
            "content": "Here, \u2295 denotes concatenation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_46",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_46@1",
            "content": "The anchor a can be any of the attach or merge candidates (a A /a M ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_46",
            "start": 31,
            "end": 100,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_47@0",
            "content": "A three-way classifier is learned to produce the categorical probability distribution over the training samples for Merge (M), Attach (A) and Nooperation (N) -three classes (|Z| = 3) of operations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_47",
            "start": 0,
            "end": 196,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_47@1",
            "content": "If \u03b8 \u2208 R | k|\u00d7| Z| be a learnable projection matrix that projects the contextualized pair embedding k to the label space Z \u2208 R 3 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_47",
            "start": 198,
            "end": 327,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_47@2",
            "content": "The predictions are obtained as below,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_47",
            "start": 329,
            "end": 366,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_48@0",
            "content": "\u0176 = softmax(MLP( k; \u03b8))(6)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_48",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_49@0",
            "content": "Query Q",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_49",
            "start": 0,
            "end": 6,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_50@0",
            "content": "[ q, q -a A , q x a A , a A ] [ q, q -a M , q x a M , a M ] For two versions of TEAM, we chose two different kinds of matching models based on empirical performances to capture different kinds of embedding interaction in the latent space.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_50",
            "start": 0,
            "end": 237,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_51@0",
            "content": "Multi-task Learning",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_51",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_52@0",
            "content": "Classification.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_52",
            "start": 0,
            "end": 14,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_52@1",
            "content": "Unlike in TEAM-RG, where we posit taxonomy expansion as a regression task with implicit ranking viz. discriminating true and false examples via InfoNCE loss, in TEAM-CL, we simultaneously optimize for classification and explicit ranking objectives.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_52",
            "start": 16,
            "end": 263,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_52@2",
            "content": "We obtain classification predictions from the matching module as described before.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_52",
            "start": 265,
            "end": 346,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_52@3",
            "content": "Given a training set X, and a set of classes Z (M: Merge, A: Attach, N: No-operation), we optimize for the self-supervised cross-entropy loss over the task predictions \u0176 given the ground-truth task-classes Y for an input query-anchor pair.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_52",
            "start": 348,
            "end": 586,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_53@0",
            "content": "L C = \u2212 1 |X| i\u2208X z\u2208Z Y iz ln \u0176iz (7)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_53",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_54@0",
            "content": "Ranking.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_54",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_54@1",
            "content": "The classification objective can only learn and infer the confidence score of an operation (M/ A/ N) for a training sample.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_54",
            "start": 9,
            "end": 131,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_54@2",
            "content": "It fails to give us a reliable ranked list of prospective anchors-(A/ M) given a query -since it does not learn the relative ranks of positive and negative anchors for a query.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_54",
            "start": 133,
            "end": 308,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_54@3",
            "content": "As illustrated in Figure 4, for a query q, (i) the ego-tree of anchor-A comprises of that query's parent's hierarchical neighborhood, and (ii) the ego-tree of anchor-M comprises of that query's replica's (same/similar definition with a missing portion of synset) hierarchical neighborhood.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_54",
            "start": 310,
            "end": 598,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_54@4",
            "content": "Since a query q is very similar to both of its anchor-A and anchor-M's ego-trees -these operations are hardly distinguishable.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_54",
            "start": 600,
            "end": 725,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_54@5",
            "content": "Thus, a model must accommodate a provision for directly comparing the prediction scores of M and A operations and learning a margin of separation between the scores.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_54",
            "start": 727,
            "end": 891,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_54@6",
            "content": "Here, we introduce two ranking objectives in the framework -(i) a contrastive objective to compare and contrast among a positive anchor and N negative anchors, (ii) a pair-wise hinge loss to learn a maximum margin between the M and A prediction scores.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_54",
            "start": 893,
            "end": 1144,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_54@7",
            "content": "Let, dist(.) be a function to measure the distance between a query q and its true/ false anchor-(A/ M) representations ( \u0101A , \u0101A \u2032 ), ( \u0101 M , \u0101 M \u2032 ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_54",
            "start": 1146,
            "end": 1295,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_54@8",
            "content": "We use \"slash\" (/) to denote either.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_54",
            "start": 1297,
            "end": 1332,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_54@9",
            "content": "We intend to rank a positive query-anchor pair (q, a A /a M ) higher than N no of negative pairs (q, a \u2032 A /a \u2032 M ) by enforcing a group-wise contrastive loss using a margin \u03bb as,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_54",
            "start": 1334,
            "end": 1512,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_55@0",
            "content": "L R1 A = 1 X i\u2208X 1 |N(q i )| \u0101A \u2032 i \u2208N(q i ) max(0, \u03bb \u2212 m + m \u2032 ) m = \u2212 dist(q i \u2212 \u0101Ai ), m \u2032 = \u2212 dist(q i \u2212 \u0101A \u2032 i ) (8)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_55",
            "start": 0,
            "end": 120,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_56@0",
            "content": "We can similarly compute the margin-based groupwise contrastive loss L R1 M for the Merge (M).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_56",
            "start": 0,
            "end": 93,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_56@1",
            "content": "Now, to distinguish between M and A operations, let, f ( k) be a function that projects the contextualized (q, a) embedding k in Equation 6, to a hidden space R h .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_56",
            "start": 95,
            "end": 258,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_56@2",
            "content": "Here we introduce a marginbased hinge-loss on sample anchor pairs attachmerge \u27e8a A , a M \u27e9 for a given query q via their contextualized vectors \u27e8 kA , k M \u27e9. If class labels of merge and attach are M = 2, A = 1, we ensure the prediction scores \u0176A/M = f ( kA/M ) for M and A are separated by a margin of \u03bb.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_56",
            "start": 260,
            "end": 564,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_57@0",
            "content": "L R2 = Y ( kA )>Y ( k M ) max(0, \u03bb \u2212 f ( k M ) + f ( kA ))",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_57",
            "start": 0,
            "end": 57,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_58@0",
            "content": "Therefore, the final loss is, L = L C + L R1 A + L R1 M + L R2 -considering both margin-based group-wise contrastive loss and pairwise hinge loss comprising the overall ranking loss.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_58",
            "start": 0,
            "end": 181,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_59@0",
            "content": "Model Inference",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_59",
            "start": 0,
            "end": 14,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_60@0",
            "content": "We follow Taxo-Expan's (Shen et al., 2020) evaluation strategy for inferring the best candidate anchor a given a query q. We use our classification objective to decide which operation among merge, attach, or no-operation (M, A, N) to perform when q is given.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_60",
            "start": 0,
            "end": 257,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_60@1",
            "content": "i) For TEAM-RG, we augment a classification layer on top of the task-specific regression layers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_60",
            "start": 259,
            "end": 354,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_60@2",
            "content": "Given a query q and a set of candidate anchors a, we obtain the merge and attach regression scores and choose the best value along with the corresponding operation as the apt operation to perform.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_60",
            "start": 356,
            "end": 551,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_60@3",
            "content": "ii) For TEAM-CL choosing which operation to perform is obtained based on the three-way prediction scores, given < q, a, (0/1) > as input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_60",
            "start": 553,
            "end": 689,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_60@4",
            "content": "Since both of our proposed frameworks optimize for ranking loss, i.e., discriminates true candidate pairs from the negative ones -we get a ranked list of candidate anchors a while matching each of them with q via respective matching modules.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_60",
            "start": 691,
            "end": 931,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_61@0",
            "content": "Experiments and Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_61",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_62@0",
            "content": "Here we give you an overview of our experiment settings and provide the detailed reproducibility information in the Sections C, D, E of the Appendix.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_62",
            "start": 0,
            "end": 148,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_63@0",
            "content": "Datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_63",
            "start": 0,
            "end": 8,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_63@1",
            "content": "Metrics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_63",
            "start": 10,
            "end": 17,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_63@2",
            "content": "We use Mean Rank (MR), Hit@k, and Mean Reciprocal Rank (MRR) to evaluate the ranks of the retrieved results obtained from different models, for the test queries.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_63",
            "start": 19,
            "end": 179,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_63@3",
            "content": "Like Taxo-Expan (Shen et al., 2020) evaluation strategy, we scale the MRR score by a factor of 10 to highlight the discrepancy of the performances among different methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_63",
            "start": 181,
            "end": 351,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_63@4",
            "content": "Further, we use Accuracy, Micro/ Macro F1, Precision, Recall, and F-Scores to evaluate a method's prediction capability to decide which operation among merge (M), attach (A), and no-operation (N) needs to be performed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_63",
            "start": 353,
            "end": 570,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_64@0",
            "content": "Baselines.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_64",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_64@1",
            "content": "We choose two most recent benchmark SOTA taxonomy-expansion frameworks Tax-oExpan (Shen et al., 2020) and Triplet Matching Network(TMN) (Zhang et al., 2021) as the competing methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_64",
            "start": 11,
            "end": 192,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_64@2",
            "content": "As Taxo-Expan and TMN outperform SemEval-2016 (Shen et al., 2020;Zhang et al., 2021), we have not included SemEval-2016 as baseline in this study.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_64",
            "start": 194,
            "end": 339,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_64@3",
            "content": "In terms of learning objective, Taxo-Expan is similar to ours.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_64",
            "start": 341,
            "end": 402,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_64@4",
            "content": "It uses ego-treebased anchor features for matching query features in a regression-based setting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_64",
            "start": 404,
            "end": 499,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_64@5",
            "content": "TMN captures finegrained relationship dynamics of query and anchor concepts using channel-wise gating mechanismbased attention learning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_64",
            "start": 501,
            "end": 636,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_65@0",
            "content": "All datasets and our model implementations are available at: https://github.com/ barnal/TEAM",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_65",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_66@0",
            "content": "Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_66",
            "start": 0,
            "end": 6,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_67@0",
            "content": "Here we report the classification and ranking results of the competing methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_67",
            "start": 0,
            "end": 78,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_67@1",
            "content": "We also compare and contrast among the variants of our TEAM framework.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_67",
            "start": 80,
            "end": 149,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_67@2",
            "content": "Apart from the two versions of the TEAM, namely, TEAM-RG and TEAM-CL, we have task-specific model variants specified asattach-A, merge-M and merge+attach-MA.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_67",
            "start": 151,
            "end": 307,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_67@3",
            "content": "Here, (attach+merge) means simultaneously optimizing for both the tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_67",
            "start": 309,
            "end": 380,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_68@0",
            "content": "Ranking Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_68",
            "start": 0,
            "end": 14,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_69@0",
            "content": "In Table [2], we show the performance of the competing methods in terms of (best) ranking scores.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_69",
            "start": 0,
            "end": 96,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_69@1",
            "content": "We see similar trends for all taxonomies in the sub-tables.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_69",
            "start": 98,
            "end": 156,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_69@2",
            "content": "When considering only attach operation and the test ranking scores, we see TEAM-RG clearly beats Taxo-Expan by a large margin of (196.87, 487.75, 470.87) in MR, by a margin of Assamese WordNet-Noun Bengali WordNet-Noun Hindi WordNet-Noun Methods Micro_MR Hit@1 Hit@3 MRR Micro_MR Hit@1 Hit@3 MRR Micro_MR Hit@1 Hit@3 MRR (0.2, 0.14, 0.24) in Hit@1 and (0.31, 0.32, 0.37) in Hit@3 for Assamese, Bengali and Hindi WordNet respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_69",
            "start": 158,
            "end": 590,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_69@3",
            "content": "We see TEAM-CL though performing competitively but is outperformed by TEAM-RG by a margin of (44.82, 86.01, 43.04) in MR, by a margin of (0.11, 0.12, 0.28) in Hit@1 and (0.14, 0.18, 0.43) in Hit@3 respectively for Assamese, Bengali and Hindi WordNet.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_69",
            "start": 592,
            "end": 841,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_69@4",
            "content": "In TEAM-RG(M), we obtain near-perfect MRR scores.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_69",
            "start": 843,
            "end": 891,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_69@5",
            "content": "This is because the definitions are already present in training set for the query concepts with known definitions (test sample drawn from the base taxonomy).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_69",
            "start": 893,
            "end": 1049,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_69@6",
            "content": "The score of 1 indicates the ability of the proposed method TEAM-RG(M) to correctly identify the appropriate anchor nodes for the merge operation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_69",
            "start": 1051,
            "end": 1196,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_69@7",
            "content": "TMN gives better performance than Taxo-Expan owing to its useful attention mechanism.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_69",
            "start": 1198,
            "end": 1282,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_69@8",
            "content": "But, Team-RG(A) outperforms TMN in all the metrics except Hits@1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_69",
            "start": 1284,
            "end": 1348,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_69@9",
            "content": "We only compare Taxo-Expan results for the attach since it is originally proposed for the attach operation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_69",
            "start": 1350,
            "end": 1456,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_69@10",
            "content": "In the (merge-M) and (merge+attach-MA) section of the tables also, we see that TEAM-RG outperforms TEAM-CL on all three WordNet taxonomies.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_69",
            "start": 1458,
            "end": 1596,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_69@11",
            "content": "We attribute this huge performance improvement of TEAM-RG to InfoNCE based training -as it simultaneously provides pseudo-supervision from the negative examples while optimizing for the task-specific regression layers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_69",
            "start": 1598,
            "end": 1815,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_70@0",
            "content": "Classification Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_70",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_71@0",
            "content": "In Table [3], We observe similar trends on all three WordNet taxonomies.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_71",
            "start": 0,
            "end": 71,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_71@1",
            "content": "Since Taxo-Expan is a regression-based algorithm proposed for only attach operation in taxonomy expansion taskwe could not obtain its classification performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_71",
            "start": 73,
            "end": 233,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_71@2",
            "content": "Therefore, we only consider variants of our frameworks as competing methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_71",
            "start": 235,
            "end": 310,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_71@3",
            "content": "As described in the sub-section 3.4, using a classification layer on top of the regression layer in TEAM-RG, we obtain classification performances for the attach, merge operations along with both (attach+merge) operations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_71",
            "start": 312,
            "end": 533,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_71@4",
            "content": "Whereas obtaining classification performance for TEAM-CL is straightforward since this is already a classification framework.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_71",
            "start": 535,
            "end": 659,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_72@0",
            "content": "When comparing TEAM-RG (attach) and (merge) variants -we see, unlike ranking results where ranking results of merge operation were always better than the attach operation, here the classification results of merge operation are inferior to attach operation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_72",
            "start": 0,
            "end": 255,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_72@1",
            "content": "It means that the RG variant learns better ranking as compared to CL variants, but they fail to distinguish M and A -the operation to perform.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_72",
            "start": 257,
            "end": 398,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_72@2",
            "content": "This is expected since we do not provide a scheme here to contrast M and A operations -which is the motivation for our CL variant framework.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_72",
            "start": 400,
            "end": 539,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_73@0",
            "content": "When comparing TEAM-RG and TEAM-CL for (merge+attach), we see TEAM-CL gives better classification scores using test queries except for Macro-F1 scores.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_73",
            "start": 0,
            "end": 150,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_73@1",
            "content": "TEAM-RG gives the best performance for the Macro-F1 score for the test cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_73",
            "start": 152,
            "end": 228,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_73@2",
            "content": "This essentially means that class-wise prediction performances are inferior for TEAM-CL.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_73",
            "start": 230,
            "end": 317,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_73@3",
            "content": "This is expected behavior since, in each batch of the training sample, we include a substantially large number (N) of negative examples with class-label (N-No operation).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_73",
            "start": 319,
            "end": 488,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_73@4",
            "content": "We design our training samples like this so that the contrastive loss is better approximated.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_73",
            "start": 490,
            "end": 582,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_73@5",
            "content": "Nevertheless, it leads to a class-imbalance issue in our three-way classification setup, i.e., a large number of samples with N class labels as compared to the other M/ A class labels.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_73",
            "start": 584,
            "end": 767,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_73@6",
            "content": "Thus, TEAM-CL biases its prediction towards the N class, leading to poorer Macro-F1 scores than TEAM-RG.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_73",
            "start": 769,
            "end": 872,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_74@0",
            "content": "To summarize, we observe that TEAM-RG gives the best ranking performances, whereas TEAM-CL gives the best classification performances.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_74",
            "start": 0,
            "end": 133,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_74@1",
            "content": "TEAM- CL performs poorly in Macro-F1 since it presumably suffers from class-imbalance issues owing to the style of training sample generation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_74",
            "start": 135,
            "end": 276,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_74@2",
            "content": "Frameworks with multi-task learning strategy (TEAM-RG and TEAM-CL) outperform frameworks (Taxo-Expan) designed to perform a single task -which is motivated by the fact that simultaneously optimizing for multiple tasks provides self-supervision to each other, resulting in better performances.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_74",
            "start": 278,
            "end": 569,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_74@3",
            "content": "To investigate the effectiveness of the proposed models, we employ the models for expanding a WordNet with OOV words.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_74",
            "start": 571,
            "end": 687,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_74@4",
            "content": "For this, first, we find out-of-vocabulary words, i.e., words that are not present in Assamese WordNet.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_74",
            "start": 689,
            "end": 791,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_74@5",
            "content": "Second, we manually identify true anchors of respective out-ofvocabulary words with associated operations (Attach/Merge) in Assamese WordNet.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_74",
            "start": 793,
            "end": 933,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_74@6",
            "content": "We evaluate the predicted results of the proposed model against the manually identified true anchors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_74",
            "start": 935,
            "end": 1035,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_74@7",
            "content": "Since we can either perform an A or M operation with OOV words and not both, we do not predict expansion tasks for OOV words using any of the MA variants of our proposed frameworks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_74",
            "start": 1037,
            "end": 1217,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_74@8",
            "content": "Table 4 shows the ranking performance of the model in predicting true anchors for attach and merge expansion operations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_74",
            "start": 1219,
            "end": 1338,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_74@9",
            "content": "We see a similar trend of prediction ranking as seen with the test set in our earlier experiments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_74",
            "start": 1340,
            "end": 1437,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_74@10",
            "content": "TEAM-RG gives the best performance in both expansion operations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_74",
            "start": 1439,
            "end": 1502,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_74@11",
            "content": "The detailed analysis of results is in Section F of the Appendix.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_74",
            "start": 1504,
            "end": 1568,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_75@0",
            "content": "Expansion of Assamese WordNet",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_75",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_76@0",
            "content": "Related Works",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_76",
            "start": 0,
            "end": 12,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_77@0",
            "content": "Existing methods for taxonomy expansion can be divided into two categories: relying on alignment between multiple taxonomies [Ruiz-Casado et al. (2005), Toral et al. (2008), Ponzetto and Navigli (2009), and Yamada et al. (2011] or relying on machine learning-based rating sub-graphs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_77",
            "start": 0,
            "end": 282,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_77@1",
            "content": "Further, the latter category can be divided into two sub-categories (1) by expanding synonymy relations/Merge (2) by expanding hypernymy relations/Attach.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_77",
            "start": 284,
            "end": 437,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_77@2",
            "content": "Synonymy-based taxonomy expansion leverages synonymy relations of the taxonomy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_77",
            "start": 439,
            "end": 517,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_77@3",
            "content": "Given a seed taxonomy, the distributional approach discovers synonyms by representing strings with their distributional feature and learning a classifier to predict the relation between strings [ (Nakashole et al., 2012), (Wang et al., 2019), (Fei et al., 2019)].",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_77",
            "start": 519,
            "end": 781,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_77@4",
            "content": "Most of the recent taxonomy expansion approaches are based on hypernymy expansion.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_77",
            "start": 783,
            "end": 864,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_77@5",
            "content": "These methods attempt to determine the attachment position by scoring between several nodes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_77",
            "start": 866,
            "end": 957,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_77@6",
            "content": "Recently numerous methods have been proposed to solve this problem (Shen et al., 2018), (Shen et al., 2020), (Yu et al., 2020b), (Zhang et al., 2021), . (Shen et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_77",
            "start": 959,
            "end": 1131,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_77@7",
            "content": "Hence, all the existing taxonomy expansion approaches expand a taxonomy either by merge operation(synonymy expansion) or by attach operation(hypernymy expansion).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_77",
            "start": 1133,
            "end": 1294,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_77@8",
            "content": "However, particular to WordNet expansion it is an integrated task of Merge and attach operation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_77",
            "start": 1296,
            "end": 1391,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_77@9",
            "content": "We are the first to study the problem of taxonomy expansion using both the Attach and Merge taxonomy expansion operations in a single model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_77",
            "start": 1393,
            "end": 1532,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_77@10",
            "content": "A detailed related study is in Section A of the Appendix.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_77",
            "start": 1534,
            "end": 1590,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_78@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_78",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_79@0",
            "content": "In this paper, we proposed an integrated framework called Taxonomy Expansion with Attach and Merge (TEAM) for expanding taxonomy with attach and merge operations together.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_79",
            "start": 0,
            "end": 170,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_79@1",
            "content": "We built two multi-task learning-based variants of TEAM, namely, TEAM-Regression and TEAM-Classification, which solve the taxonomy expansion problem as regression and classification, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_79",
            "start": 172,
            "end": 367,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_79@2",
            "content": "Our proposed methods learned to predict the taxonomy expansion operation (merge, attach, or no-operation) to perform and provided a ranked list of candidates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_79",
            "start": 369,
            "end": 526,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_79@3",
            "content": "We evaluated the effectiveness of TEAM on WordNet taxonomies of three distinct languages, viz., Assamese, Bangla, and Hindi.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_79",
            "start": 528,
            "end": 651,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_79@4",
            "content": "In various experimental setups, the proposed TEAM-RG and TEAM-CL outperformed its state of the art for attach operation and provided a highly encouraging performance on merge operation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_79",
            "start": 653,
            "end": 837,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_79@5",
            "content": "We had also investigated the performance of the proposed model with out-ofvocabulary concepts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_79",
            "start": 839,
            "end": 932,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_80@0",
            "content": "In the future, we plan to investigate the response of the proposed model with different types of taxonomies and WordNet of different languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_80",
            "start": 0,
            "end": 142,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_80@1",
            "content": "Another future research possibility can be to explore the response of this model using advanced contextual encoders.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_80",
            "start": 144,
            "end": 259,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_81@0",
            "content": "Expansion by resource alignment: In the first category of studies, Poprat et al. (2008) first attempted to automatically expand a WordNet with biomedical terminology; however, they were unable in developing the resource.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_81",
            "start": 0,
            "end": 219,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_81@1",
            "content": "Ruiz-Casado et al. (2005), Toral et al. (2008), Ponzetto and Navigli (2009), and Yamada et al. (2011 exploit structured information in Wikipedia to expand Word-Net with new synsets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_81",
            "start": 221,
            "end": 401,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_81@2",
            "content": "Snow et al. (2006) leverage distributional similarity techniques for WordNet expansion.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_81",
            "start": 403,
            "end": 489,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_81@3",
            "content": "Jurgens and Pilehvar (2015) enrich the existing WordNet taxonomy using an additional resource, Wiktionary, to extract sense data based on information in the term concepts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_81",
            "start": 491,
            "end": 661,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_81@4",
            "content": "Synonymy Expansion: Synonymy expansion in a taxonomy leverages synonymy relations to enrich a taxonomy with new concepts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_81",
            "start": 663,
            "end": 783,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_81@5",
            "content": "Approaches for synonymy expansion can be divided in to two categories: (1) Distributional based approach (Wang et al., 2019), (Fei et al., 2019) (2) Pattern-based approach (Nguyen et al., 2017), (Nakashole et al., 2012).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_81",
            "start": 785,
            "end": 1004,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_81@6",
            "content": "Given a seed taxonomy, the distributional approach discovers synonyms by representing strings with their distributional feature and learning a classifier to predict the relation between strings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_81",
            "start": 1006,
            "end": 1199,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_81@7",
            "content": "However, in the pattern-based approach, consider the sentences mentioning a pair of synonymous strings and learn some textual patterns from these sentences, which are further used to discover more synonyms.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_81",
            "start": 1201,
            "end": 1406,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_81@8",
            "content": "Qu et al. (2017) proposed an approach that integrates both the categories.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_81",
            "start": 1408,
            "end": 1481,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_81@9",
            "content": "Boteanu et al. (2018) focus on the problem of expanding taxonomies with synonyms for applications in which entities are complex concepts arranged into taxonomies designed to facilitate browsing the product catalog on amazon.com.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_81",
            "start": 1483,
            "end": 1710,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_81@10",
            "content": "They first generate synonymy candidates for each node in the taxonomy and then filter synonymy candidates using a binary classifier.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_81",
            "start": 1712,
            "end": 1843,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_81@11",
            "content": "Yu et al. (2020a) study a task of synonym expansion using transitivity named SYNET, which leverages both the contexts of two synonymy pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_81",
            "start": 1845,
            "end": 1984,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_81@12",
            "content": "Hypernymy expansion : Jurgens and Pilehvar (2016) formulated a task of synonymy expansion, where it is proposed to enrich the WordNet taxonomy by performing two operations for each new concept.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_81",
            "start": 1986,
            "end": 2178,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_81@13",
            "content": "The first action is Attach, where a new concept is treated as a new synset and is attached as a hyponym of one existing synset in WordNet, and the second action is Merge, where a new concept is merged into an existing synset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_81",
            "start": 2180,
            "end": 2404,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_81@14",
            "content": "The best solution proposed by Schlichtkrull and Alonso (2016) included only the attach operation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_81",
            "start": 2406,
            "end": 2502,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_81@15",
            "content": "Later solutions for attaching, as in Shen et al. (2020), adopted selfsupervision and tried to exploit the information of nodes in the seed taxonomy to perform node pair matching.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_81",
            "start": 2504,
            "end": 2681,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_81@16",
            "content": "On the other hand, Yu et al. (2020b) resorted to classification along mini paths in the taxonomy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_81",
            "start": 2683,
            "end": 2779,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_81@17",
            "content": "In contrast, in our current approach, we have incorporated both the attach and merge operations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_81",
            "start": 2781,
            "end": 2876,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_82@0",
            "content": "Graph Neural Network (GNN) allows us to transform and propagate node features as messages to learn structure-aware node representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_82",
            "start": 0,
            "end": 135,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_82@1",
            "content": "The EXTRACT() mechanism extracts the messages from a target node and its neighborhood, which is later on combined based on a chosen ATTEN-TION() mechanism by the AGGREGATE() operation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_82",
            "start": 137,
            "end": 320,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_82@2",
            "content": "Next, the aggregated message is propagated to the rest of the graph.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_82",
            "start": 322,
            "end": 389,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_82@3",
            "content": "Studies apply various aggregation strategies to combine the propagated and extracted messages from the target node's neighborhood based on the importance of each node in the neighborhood towards that target node.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_82",
            "start": 391,
            "end": 602,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_82@4",
            "content": "GCN (Kipf and Welling, 2016) and GAT (Veli\u010dkovi\u0107 et al., 2017) are popular GNN frameworks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_82",
            "start": 604,
            "end": 693,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_83@0",
            "content": "GCN uses N ( * ) neighborhood-based normalization constant to calculate the importance (att v\u2212 \u2192u ) of node v towards the target node u without considering the participating nodes' features as follows.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_83",
            "start": 0,
            "end": 200,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_84@0",
            "content": "H l u = \u03c3 \u2200v\u2208 \u00d1 (u) att l\u22121 v\u2212 \u2192u W l\u22121 H l\u22121 v (9) ATTENTION GCN (v \u2212 \u2192 u) : att l\u22121 v\u2212 \u2192u = 1 | \u00d1 (u)|| \u00d1 (v)| EXTRACT GCN (v) : W l\u22121 H l\u22121 v AGGREGATE GCN ( * ) : \u03c3( * )",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_84",
            "start": 0,
            "end": 172,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_85@0",
            "content": "where \u03c3 is non-linear activation function, W l is a projection matrix for a GNN layer l and \u00d1 ( * ) is a node's extended neighborhood structure including the node itself (i.e., including self-loop edges).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_85",
            "start": 0,
            "end": 203,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_85@1",
            "content": "GAT uses the same message extraction and aggregation strategies as above except for the fact that it uses attentive aggregation strategies that consider both the participating nodes' features as well as the neighborhood information, as follows.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_85",
            "start": 205,
            "end": 448,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_86@0",
            "content": "ATTENTION GAT (v \u2212 \u2192 u) : att l\u22121 v\u2212 \u2192u = SOFTMAX \u2200v\u2208 \u00d1 (u) c l\u22121 (W l\u22121 H l\u22121 u \u2295 W l\u22121 H l\u22121 v )",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_86",
            "start": 0,
            "end": 97,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_87@0",
            "content": "where c l\u22121 is a learnable parameter to approximate the importance of node v towards u (att l\u22121 v\u2212 \u2192u ) based on their interaction in the latent space in l layerwise manner, W is the layer-wise projection matrix, and \u2295 denotes concatenation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_87",
            "start": 0,
            "end": 240,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_88@0",
            "content": "We use an array of performance metrics from the domain of classification and ranking to evaluate the competing methods' performances.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_88",
            "start": 0,
            "end": 132,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_88@1",
            "content": "Among the ranking metrics, we use Mean Rank (MR), Hit@k (k=1, 3), and Mean Reciprocal Rank (MRR) to judge how well a competing method performs in producing a ranked list of candidate anchors given a test query and a taxonomy expansion operation to carry-out -merge or attach.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_88",
            "start": 134,
            "end": 408,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_89@0",
            "content": "\u2022 Mean Rank: It calculates the average rank of true anchors among all the candidate anchors with respect to the matching scores, given a query. \u2022 Hit@k: It calculates the number of times a true anchor appears in the top k positions when matched with a test query. \u2022 Mean Reciprocal Rank(MRR): The Mean Reciprocal Rank is used to assess the ranking quality of the true anchor. The reciprocal rank can be computed by finding and inversing the rank of a true anchor in the predicted anchors' list of each query. MRR is averaged over all queries.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_89",
            "start": 0,
            "end": 541,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_90@0",
            "content": "Further, we use Accuracy, Micro/ Macro F1, Precision, Recall, and F-Scores as classification metrics for deciding given a test query and an initial taxonomy tree, which operation among merge (M), attach (A), and no-operation (N) is to be performed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_90",
            "start": 0,
            "end": 247,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_91@0",
            "content": "\u2022 Accuracy: It summarizes the performance of the classification model as the fraction of the number of true tasks predicted over the total number of ground-truth tasks for a set of queries. \u2022 Precision: It calculates the fraction of truepositive predicted expansion task classes among the total number of true-positive and false-negative task classes. \u2022 Recall: It calculates the fraction of truepositive predicted expansion task classes among all the relevant ground-truth task classes. \u2022 F-Score: The harmonic mean of precision and recall. It is also known as F1-Score. \u2022 Micro/ Macro F1 : The Macro F1 computes F1-Score for each class (merge M/ attach A) independently but averages the final score by treating each expansion task-class as equally contributing. However, Micro F1 computes the F1-Score for each query sample in the training set and therefore aggregates the contributions of all expansion task classes to compute the final average metric.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_91",
            "start": 0,
            "end": 954,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_92@0",
            "content": "We obtain the initial feature vector for train and test concepts using pre-trained subword-aware Fasttext embeddings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_92",
            "start": 0,
            "end": 116,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_92@1",
            "content": "For each concept, we generate its definition embedding by averaging the embedding of each word in its textual definition.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_92",
            "start": 118,
            "end": 238,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_92@2",
            "content": "We employ PyTorch and DGL framework 3 to load and train embeddings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_92",
            "start": 240,
            "end": 306,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_92@3",
            "content": "In TEAM, we use a two-layer position-enhanced GAT where the first layer (of size 300) has four attention heads and the second layer (of size 600) has one attention head.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_92",
            "start": 308,
            "end": 476,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_92@4",
            "content": "We use 50-dimension position embeddings for both layers and apply dropout with the rate of 0.1 on the input feature vectors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_92",
            "start": 478,
            "end": 601,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_92@5",
            "content": "We use Adam optimizer with an initial learning rate of 0.001.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_92",
            "start": 603,
            "end": 663,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_93@0",
            "content": "In the case of attach expansion, TEAM-RG beats state-of-the-art Taxo-expan by a large margin of (321, 0.31, 0.48, 0.69) in MR, Hit@1, Hit@3, MRR, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_93",
            "start": 0,
            "end": 158,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_93@1",
            "content": "However, our proposed frameworks are seen not to perform so well in merge M operation as compared to the attach A operation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_93",
            "start": 160,
            "end": 283,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_94@0",
            "content": "Intuitively, this is because, for OOV words, we use a set of manually collected paraphrase definitions of the OOV words to match them with the candidate anchor concepts in the existing taxonomy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_94",
            "start": 0,
            "end": 193,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_95@0",
            "content": "Whereas for actually training our model, we have used the same definitions in the replica nodes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_95",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_95@1",
            "content": "That is, we have used the same definition in the original anchor concept and in the input query-concept with mutually exclusive synset information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_95",
            "start": 97,
            "end": 243,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_95@2",
            "content": "Thus, in this case-study, the paraphrase-based definition matching deems challenging for our learning model resulting in poorer results for M operation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_95",
            "start": 245,
            "end": 396,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_95@3",
            "content": "We believe we can always eliminate this drawback by using a description generation tool (Wang et al., 2021) to generate different definitions of the same concept nodes and train our learning model in a more powerful way.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_95",
            "start": 398,
            "end": 617,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_96@0",
            "content": "James Allan, Ron Papka, Victor Lavrenko, On-line new event detection and tracking, 1998, Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval, ACM.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_96",
            "start": 0,
            "end": 212,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_97@0",
            "content": ", Pushpak Bhattacharyya. 2010. Indowordnet, , Proc. of LREC-10, Citeseer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_97",
            "start": 0,
            "end": 72,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_98@0",
            "content": "Adrian Boteanu, Adam Kiezun, Shay Artzi, Synonym expansion for large shopping taxonomies, 2018, Automated Knowledge Base Construction (AKBC), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_98",
            "start": 0,
            "end": 142,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_99@0",
            "content": "Hongliang Fei, Shulong Tan, Ping Li, Hierarchical multi-task word embedding learning for synonym prediction, 2019, Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_99",
            "start": 0,
            "end": 213,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_100@0",
            "content": "Michael Gutmann, Aapo Hyv\u00e4rinen, Noisecontrastive estimation: A new estimation principle for unnormalized statistical models, 2010, Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_100",
            "start": 0,
            "end": 230,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_101@0",
            "content": "David Jurgens, Mohammad Taher Pilehvar, Reserating the awesometastic: An automatic extension of the wordnet taxonomy for novel terms, 2015, Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_101",
            "start": 0,
            "end": 284,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_102@0",
            "content": "David Jurgens, Mohammad Taher Pilehvar, Semeval-2016 task 14: Semantic taxonomy enrichment, 2016, Proceedings of the 10th international workshop on semantic evaluation (SemEval-2016), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_102",
            "start": 0,
            "end": 184,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_103@0",
            "content": "UNKNOWN, None, 2016, Semisupervised classification with graph convolutional networks, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_103",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_104@0",
            "content": "Zichen Liu, Hongyuan Xu, Yanlong Wen, Ning Jiang, Haiying Wu, Xiaojie Yuan, Temp: Taxonomy expansion with dynamic margin loss through taxonomy-paths, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_104",
            "start": 0,
            "end": 244,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_105@0",
            "content": "UNKNOWN, None, 1998, WordNet: An electronic lexical database, MIT press.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_105",
            "start": 0,
            "end": 71,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_106@0",
            "content": "Ndapandula Nakashole, Gerhard Weikum, Fabian Suchanek, Patty: A taxonomy of relational patterns with semantic types, 2012, Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_106",
            "start": 0,
            "end": 261,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_107@0",
            "content": "UNKNOWN, None, 2017, Distinguishing antonyms and synonyms in a pattern-based neural network, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_107",
            "start": 0,
            "end": 93,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_108@0",
            "content": "UNKNOWN, None, 2018, Representation learning with contrastive predictive coding, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_108",
            "start": 0,
            "end": 81,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_109@0",
            "content": "UNKNOWN, None, 2008, Opinion mining and sentiment analysis. Foundations and Trends\u00ae in Information Retrieval, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_109",
            "start": 0,
            "end": 110,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_110@0",
            "content": "Paolo Simone, Roberto Ponzetto,  Navigli, Large-scale taxonomy mapping for restructuring and integrating wikipedia, 2009, IJCAI, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_110",
            "start": 0,
            "end": 129,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_111@0",
            "content": "Michael Poprat, Elena Beisswanger, Udo Hahn, Building a biowordnet using wordnet data structures and wordnet's software infrastructure-a failure story, 2008, Software engineering, testing, and quality assurance for natural language processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_111",
            "start": 0,
            "end": 244,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_112@0",
            "content": "Meng Qu, Xiang Ren, Jiawei Han, Automatic synonym discovery with knowledge bases, 2017, Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_112",
            "start": 0,
            "end": 188,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_113@0",
            "content": "Maria Ruiz-Casado, Enrique Alfonseca, Pablo Castells, Automatic assignment of wikipedia encyclopedic entries to wordnet synsets, 2005, International Atlantic Web Intelligence Conference, Springer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_113",
            "start": 0,
            "end": 195,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_114@0",
            "content": "Michael Schlichtkrull, Alonso H\u00e9ctor Mart\u00ednez, Msejrku at semeval-2016 task 14: Taxonomy enrichment by evidence ranking, 2016, Proceedings of the 10th international workshop on semantic evaluation (SemEval-2016), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_114",
            "start": 0,
            "end": 213,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_115@0",
            "content": "Jiaming Shen, Zhihong Shen, Chenyan Xiong, Chi Wang, Kuansan Wang, Jiawei Han, Taxoexpan: self-supervised taxonomy expansion with position-enhanced graph neural network, 2020, Proceedings of The Web Conference 2020, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_115",
            "start": 0,
            "end": 216,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_116@0",
            "content": "Jiaming Shen, Zeqiu Wu, Dongming Lei, Chao Zhang, Xiang Ren, Michelle Vanni, Brian Sadler, Jiawei Han, Hiexpan: Task-guided taxonomy construction by hierarchical tree expansion, 2018, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_116",
            "start": 0,
            "end": 282,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_117@0",
            "content": "Amit Singhal, Modern information retrieval: A brief overview, 2001, IEEE Data Eng. Bull, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_117",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_118@0",
            "content": "Rion Snow, Daniel Jurafsky, Andrew Ng, Semantic taxonomy induction from heterogenous evidence, 2006, Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_118",
            "start": 0,
            "end": 294,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_119@0",
            "content": "Kunihiro Takeoka, Kosuke Akimoto, Masafumi Oyamada, Low-resource taxonomy enrichment with pretrained language models, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_119",
            "start": 0,
            "end": 212,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_120@0",
            "content": "Antonio Toral, Rafael Mu\u00f1oz, Monica Monachini, Named entity WordNet, 2008, Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC'08), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_120",
            "start": 0,
            "end": 173,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_121@0",
            "content": "Nikhita Vedula, K Patrick, Deepak Nicholson, Sourav Ajwani, Alessandra Dutta, Srinivasan Sala,  Parthasarathy, Enriching taxonomies with functional domain knowledge, 2018, The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_121",
            "start": 0,
            "end": 268,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_122@0",
            "content": "UNKNOWN, None, 2017, , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_122",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_123@0",
            "content": "Jin Wang, Chunbin Lin, Mingda Li, Carlo Zaniolo, An efficient sliding window approach for approximate entity extraction with synonyms, 2019, EDBT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_123",
            "start": 0,
            "end": 147,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_124@0",
            "content": "Suyuchen Wang, Ruihui Zhao, Xi Chen, Yefeng Zheng, Bang Liu, Enquire one's parent and child before decision: Fully exploit hierarchical structure for self-supervised taxonomy expansion, 2021, Proceedings of the Web Conference 2021, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_124",
            "start": 0,
            "end": 232,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_125@0",
            "content": "Ichiro Yamada, Jong-Hoon Oh, Chikara Hashimoto, Kentaro Torisawa, Stijn Jun'ichi Kazama, Takuya De Saeger,  Kawada, Extending WordNet with hypernyms and siblings acquired from Wikipedia, 2011, Proceedings of 5th International Joint Conference on Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_125",
            "start": 0,
            "end": 275,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_126@0",
            "content": "Jiale Yu, Yongliang Shen, Xinyin Ma, Chenghao Jia, Chen Chen, Weiming Lu, Synet: Synonym expansion using transitivity, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_126",
            "start": 0,
            "end": 223,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_127@0",
            "content": "Yue Yu, Yinghao Li, Jiaming Shen, Hao Feng, Jimeng Sun, Chao Zhang, Steam: Selfsupervised taxonomy expansion with mini-paths, 2020, Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_127",
            "start": 0,
            "end": 230,
            "label": {}
        },
        {
            "ix": "28-ARR_v2_128@0",
            "content": "UNKNOWN, None, 2021, Taxonomy completion via triplet matching network, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "28-ARR_v2_128",
            "start": 0,
            "end": 71,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "28-ARR_v2_0",
            "tgt_ix": "28-ARR_v2_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_0",
            "tgt_ix": "28-ARR_v2_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_1",
            "tgt_ix": "28-ARR_v2_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_1",
            "tgt_ix": "28-ARR_v2_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_0",
            "tgt_ix": "28-ARR_v2_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_2",
            "tgt_ix": "28-ARR_v2_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_4",
            "tgt_ix": "28-ARR_v2_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_5",
            "tgt_ix": "28-ARR_v2_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_6",
            "tgt_ix": "28-ARR_v2_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_8",
            "tgt_ix": "28-ARR_v2_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_3",
            "tgt_ix": "28-ARR_v2_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_3",
            "tgt_ix": "28-ARR_v2_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_3",
            "tgt_ix": "28-ARR_v2_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_3",
            "tgt_ix": "28-ARR_v2_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_3",
            "tgt_ix": "28-ARR_v2_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_3",
            "tgt_ix": "28-ARR_v2_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_3",
            "tgt_ix": "28-ARR_v2_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_0",
            "tgt_ix": "28-ARR_v2_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_11",
            "tgt_ix": "28-ARR_v2_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_12",
            "tgt_ix": "28-ARR_v2_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_13",
            "tgt_ix": "28-ARR_v2_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_14",
            "tgt_ix": "28-ARR_v2_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_15",
            "tgt_ix": "28-ARR_v2_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_16",
            "tgt_ix": "28-ARR_v2_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_17",
            "tgt_ix": "28-ARR_v2_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_18",
            "tgt_ix": "28-ARR_v2_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_19",
            "tgt_ix": "28-ARR_v2_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_10",
            "tgt_ix": "28-ARR_v2_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_10",
            "tgt_ix": "28-ARR_v2_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_10",
            "tgt_ix": "28-ARR_v2_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_10",
            "tgt_ix": "28-ARR_v2_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_10",
            "tgt_ix": "28-ARR_v2_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_10",
            "tgt_ix": "28-ARR_v2_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_10",
            "tgt_ix": "28-ARR_v2_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_10",
            "tgt_ix": "28-ARR_v2_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_10",
            "tgt_ix": "28-ARR_v2_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_10",
            "tgt_ix": "28-ARR_v2_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_10",
            "tgt_ix": "28-ARR_v2_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_0",
            "tgt_ix": "28-ARR_v2_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_20",
            "tgt_ix": "28-ARR_v2_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_22",
            "tgt_ix": "28-ARR_v2_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_23",
            "tgt_ix": "28-ARR_v2_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_24",
            "tgt_ix": "28-ARR_v2_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_21",
            "tgt_ix": "28-ARR_v2_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_21",
            "tgt_ix": "28-ARR_v2_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_21",
            "tgt_ix": "28-ARR_v2_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_21",
            "tgt_ix": "28-ARR_v2_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_21",
            "tgt_ix": "28-ARR_v2_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_0",
            "tgt_ix": "28-ARR_v2_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_25",
            "tgt_ix": "28-ARR_v2_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_27",
            "tgt_ix": "28-ARR_v2_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_28",
            "tgt_ix": "28-ARR_v2_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_29",
            "tgt_ix": "28-ARR_v2_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_30",
            "tgt_ix": "28-ARR_v2_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_26",
            "tgt_ix": "28-ARR_v2_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_26",
            "tgt_ix": "28-ARR_v2_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_26",
            "tgt_ix": "28-ARR_v2_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_26",
            "tgt_ix": "28-ARR_v2_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_26",
            "tgt_ix": "28-ARR_v2_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_26",
            "tgt_ix": "28-ARR_v2_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_26",
            "tgt_ix": "28-ARR_v2_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_31",
            "tgt_ix": "28-ARR_v2_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_33",
            "tgt_ix": "28-ARR_v2_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_34",
            "tgt_ix": "28-ARR_v2_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_35",
            "tgt_ix": "28-ARR_v2_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_32",
            "tgt_ix": "28-ARR_v2_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_32",
            "tgt_ix": "28-ARR_v2_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_32",
            "tgt_ix": "28-ARR_v2_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_32",
            "tgt_ix": "28-ARR_v2_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_32",
            "tgt_ix": "28-ARR_v2_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_26",
            "tgt_ix": "28-ARR_v2_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_36",
            "tgt_ix": "28-ARR_v2_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_38",
            "tgt_ix": "28-ARR_v2_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_39",
            "tgt_ix": "28-ARR_v2_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_40",
            "tgt_ix": "28-ARR_v2_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_41",
            "tgt_ix": "28-ARR_v2_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_42",
            "tgt_ix": "28-ARR_v2_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_37",
            "tgt_ix": "28-ARR_v2_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_37",
            "tgt_ix": "28-ARR_v2_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_37",
            "tgt_ix": "28-ARR_v2_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_37",
            "tgt_ix": "28-ARR_v2_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_37",
            "tgt_ix": "28-ARR_v2_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_37",
            "tgt_ix": "28-ARR_v2_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_37",
            "tgt_ix": "28-ARR_v2_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_0",
            "tgt_ix": "28-ARR_v2_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_43",
            "tgt_ix": "28-ARR_v2_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_45",
            "tgt_ix": "28-ARR_v2_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_46",
            "tgt_ix": "28-ARR_v2_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_47",
            "tgt_ix": "28-ARR_v2_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_44",
            "tgt_ix": "28-ARR_v2_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_44",
            "tgt_ix": "28-ARR_v2_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_44",
            "tgt_ix": "28-ARR_v2_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_44",
            "tgt_ix": "28-ARR_v2_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_44",
            "tgt_ix": "28-ARR_v2_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_49",
            "tgt_ix": "28-ARR_v2_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_44",
            "tgt_ix": "28-ARR_v2_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_44",
            "tgt_ix": "28-ARR_v2_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_48",
            "tgt_ix": "28-ARR_v2_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_44",
            "tgt_ix": "28-ARR_v2_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_50",
            "tgt_ix": "28-ARR_v2_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_52",
            "tgt_ix": "28-ARR_v2_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_53",
            "tgt_ix": "28-ARR_v2_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_54",
            "tgt_ix": "28-ARR_v2_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_55",
            "tgt_ix": "28-ARR_v2_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_56",
            "tgt_ix": "28-ARR_v2_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_57",
            "tgt_ix": "28-ARR_v2_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_51",
            "tgt_ix": "28-ARR_v2_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_51",
            "tgt_ix": "28-ARR_v2_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_51",
            "tgt_ix": "28-ARR_v2_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_51",
            "tgt_ix": "28-ARR_v2_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_51",
            "tgt_ix": "28-ARR_v2_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_51",
            "tgt_ix": "28-ARR_v2_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_51",
            "tgt_ix": "28-ARR_v2_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_51",
            "tgt_ix": "28-ARR_v2_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_0",
            "tgt_ix": "28-ARR_v2_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_58",
            "tgt_ix": "28-ARR_v2_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_59",
            "tgt_ix": "28-ARR_v2_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_59",
            "tgt_ix": "28-ARR_v2_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_0",
            "tgt_ix": "28-ARR_v2_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_60",
            "tgt_ix": "28-ARR_v2_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_62",
            "tgt_ix": "28-ARR_v2_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_63",
            "tgt_ix": "28-ARR_v2_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_64",
            "tgt_ix": "28-ARR_v2_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_61",
            "tgt_ix": "28-ARR_v2_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_61",
            "tgt_ix": "28-ARR_v2_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_61",
            "tgt_ix": "28-ARR_v2_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_61",
            "tgt_ix": "28-ARR_v2_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_61",
            "tgt_ix": "28-ARR_v2_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_0",
            "tgt_ix": "28-ARR_v2_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_65",
            "tgt_ix": "28-ARR_v2_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_66",
            "tgt_ix": "28-ARR_v2_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_66",
            "tgt_ix": "28-ARR_v2_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_66",
            "tgt_ix": "28-ARR_v2_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_67",
            "tgt_ix": "28-ARR_v2_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_68",
            "tgt_ix": "28-ARR_v2_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_68",
            "tgt_ix": "28-ARR_v2_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_66",
            "tgt_ix": "28-ARR_v2_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_69",
            "tgt_ix": "28-ARR_v2_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_71",
            "tgt_ix": "28-ARR_v2_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_72",
            "tgt_ix": "28-ARR_v2_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_73",
            "tgt_ix": "28-ARR_v2_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_70",
            "tgt_ix": "28-ARR_v2_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_70",
            "tgt_ix": "28-ARR_v2_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_70",
            "tgt_ix": "28-ARR_v2_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_70",
            "tgt_ix": "28-ARR_v2_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_70",
            "tgt_ix": "28-ARR_v2_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_66",
            "tgt_ix": "28-ARR_v2_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_74",
            "tgt_ix": "28-ARR_v2_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_0",
            "tgt_ix": "28-ARR_v2_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_75",
            "tgt_ix": "28-ARR_v2_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_76",
            "tgt_ix": "28-ARR_v2_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_76",
            "tgt_ix": "28-ARR_v2_77",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_0",
            "tgt_ix": "28-ARR_v2_78",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_77",
            "tgt_ix": "28-ARR_v2_78",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_79",
            "tgt_ix": "28-ARR_v2_80",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_78",
            "tgt_ix": "28-ARR_v2_79",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_78",
            "tgt_ix": "28-ARR_v2_80",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_78",
            "tgt_ix": "28-ARR_v2_79",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_78",
            "tgt_ix": "28-ARR_v2_81",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_80",
            "tgt_ix": "28-ARR_v2_81",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_82",
            "tgt_ix": "28-ARR_v2_83",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_83",
            "tgt_ix": "28-ARR_v2_84",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_84",
            "tgt_ix": "28-ARR_v2_85",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_85",
            "tgt_ix": "28-ARR_v2_86",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_86",
            "tgt_ix": "28-ARR_v2_87",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_78",
            "tgt_ix": "28-ARR_v2_82",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_78",
            "tgt_ix": "28-ARR_v2_83",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_78",
            "tgt_ix": "28-ARR_v2_84",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_78",
            "tgt_ix": "28-ARR_v2_85",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_78",
            "tgt_ix": "28-ARR_v2_86",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_78",
            "tgt_ix": "28-ARR_v2_87",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_81",
            "tgt_ix": "28-ARR_v2_82",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_88",
            "tgt_ix": "28-ARR_v2_89",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_90",
            "tgt_ix": "28-ARR_v2_91",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_78",
            "tgt_ix": "28-ARR_v2_88",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_78",
            "tgt_ix": "28-ARR_v2_89",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_78",
            "tgt_ix": "28-ARR_v2_90",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_78",
            "tgt_ix": "28-ARR_v2_91",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_87",
            "tgt_ix": "28-ARR_v2_88",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_78",
            "tgt_ix": "28-ARR_v2_92",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_93",
            "tgt_ix": "28-ARR_v2_94",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_94",
            "tgt_ix": "28-ARR_v2_95",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_78",
            "tgt_ix": "28-ARR_v2_93",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_78",
            "tgt_ix": "28-ARR_v2_94",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_78",
            "tgt_ix": "28-ARR_v2_95",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_92",
            "tgt_ix": "28-ARR_v2_93",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "28-ARR_v2_0",
            "tgt_ix": "28-ARR_v2_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_1",
            "tgt_ix": "28-ARR_v2_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_2",
            "tgt_ix": "28-ARR_v2_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_2",
            "tgt_ix": "28-ARR_v2_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_2",
            "tgt_ix": "28-ARR_v2_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_2",
            "tgt_ix": "28-ARR_v2_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_2",
            "tgt_ix": "28-ARR_v2_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_2",
            "tgt_ix": "28-ARR_v2_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_2",
            "tgt_ix": "28-ARR_v2_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_3",
            "tgt_ix": "28-ARR_v2_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_4",
            "tgt_ix": "28-ARR_v2_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_4",
            "tgt_ix": "28-ARR_v2_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_4",
            "tgt_ix": "28-ARR_v2_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_4",
            "tgt_ix": "28-ARR_v2_4@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_4",
            "tgt_ix": "28-ARR_v2_4@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_4",
            "tgt_ix": "28-ARR_v2_4@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_4",
            "tgt_ix": "28-ARR_v2_4@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_5",
            "tgt_ix": "28-ARR_v2_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_6",
            "tgt_ix": "28-ARR_v2_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_6",
            "tgt_ix": "28-ARR_v2_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_6",
            "tgt_ix": "28-ARR_v2_6@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_6",
            "tgt_ix": "28-ARR_v2_6@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_6",
            "tgt_ix": "28-ARR_v2_6@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_6",
            "tgt_ix": "28-ARR_v2_6@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_6",
            "tgt_ix": "28-ARR_v2_6@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_6",
            "tgt_ix": "28-ARR_v2_6@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_6",
            "tgt_ix": "28-ARR_v2_6@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_7",
            "tgt_ix": "28-ARR_v2_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_8",
            "tgt_ix": "28-ARR_v2_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_9",
            "tgt_ix": "28-ARR_v2_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_10",
            "tgt_ix": "28-ARR_v2_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_11",
            "tgt_ix": "28-ARR_v2_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_11",
            "tgt_ix": "28-ARR_v2_11@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_11",
            "tgt_ix": "28-ARR_v2_11@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_12",
            "tgt_ix": "28-ARR_v2_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_12",
            "tgt_ix": "28-ARR_v2_12@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_12",
            "tgt_ix": "28-ARR_v2_12@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_13",
            "tgt_ix": "28-ARR_v2_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_14",
            "tgt_ix": "28-ARR_v2_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_14",
            "tgt_ix": "28-ARR_v2_14@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_14",
            "tgt_ix": "28-ARR_v2_14@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_15",
            "tgt_ix": "28-ARR_v2_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_15",
            "tgt_ix": "28-ARR_v2_15@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_15",
            "tgt_ix": "28-ARR_v2_15@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_16",
            "tgt_ix": "28-ARR_v2_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_17",
            "tgt_ix": "28-ARR_v2_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_17",
            "tgt_ix": "28-ARR_v2_17@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_17",
            "tgt_ix": "28-ARR_v2_17@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_17",
            "tgt_ix": "28-ARR_v2_17@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_17",
            "tgt_ix": "28-ARR_v2_17@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_18",
            "tgt_ix": "28-ARR_v2_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_19",
            "tgt_ix": "28-ARR_v2_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_20",
            "tgt_ix": "28-ARR_v2_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_20",
            "tgt_ix": "28-ARR_v2_20@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_20",
            "tgt_ix": "28-ARR_v2_20@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_20",
            "tgt_ix": "28-ARR_v2_20@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_20",
            "tgt_ix": "28-ARR_v2_20@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_21",
            "tgt_ix": "28-ARR_v2_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_22",
            "tgt_ix": "28-ARR_v2_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_22",
            "tgt_ix": "28-ARR_v2_22@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_22",
            "tgt_ix": "28-ARR_v2_22@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_23",
            "tgt_ix": "28-ARR_v2_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_23",
            "tgt_ix": "28-ARR_v2_23@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_23",
            "tgt_ix": "28-ARR_v2_23@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_24",
            "tgt_ix": "28-ARR_v2_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_24",
            "tgt_ix": "28-ARR_v2_24@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_24",
            "tgt_ix": "28-ARR_v2_24@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_25",
            "tgt_ix": "28-ARR_v2_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_26",
            "tgt_ix": "28-ARR_v2_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_27",
            "tgt_ix": "28-ARR_v2_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_27",
            "tgt_ix": "28-ARR_v2_27@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_28",
            "tgt_ix": "28-ARR_v2_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_29",
            "tgt_ix": "28-ARR_v2_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_30",
            "tgt_ix": "28-ARR_v2_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_30",
            "tgt_ix": "28-ARR_v2_30@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_30",
            "tgt_ix": "28-ARR_v2_30@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_31",
            "tgt_ix": "28-ARR_v2_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_31",
            "tgt_ix": "28-ARR_v2_31@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_31",
            "tgt_ix": "28-ARR_v2_31@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_31",
            "tgt_ix": "28-ARR_v2_31@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_31",
            "tgt_ix": "28-ARR_v2_31@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_31",
            "tgt_ix": "28-ARR_v2_31@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_32",
            "tgt_ix": "28-ARR_v2_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_33",
            "tgt_ix": "28-ARR_v2_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_33",
            "tgt_ix": "28-ARR_v2_33@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_33",
            "tgt_ix": "28-ARR_v2_33@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_33",
            "tgt_ix": "28-ARR_v2_33@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_33",
            "tgt_ix": "28-ARR_v2_33@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_34",
            "tgt_ix": "28-ARR_v2_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_35",
            "tgt_ix": "28-ARR_v2_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_36",
            "tgt_ix": "28-ARR_v2_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_36",
            "tgt_ix": "28-ARR_v2_36@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_37",
            "tgt_ix": "28-ARR_v2_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_38",
            "tgt_ix": "28-ARR_v2_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_38",
            "tgt_ix": "28-ARR_v2_38@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_39",
            "tgt_ix": "28-ARR_v2_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_39",
            "tgt_ix": "28-ARR_v2_39@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_40",
            "tgt_ix": "28-ARR_v2_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_41",
            "tgt_ix": "28-ARR_v2_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_41",
            "tgt_ix": "28-ARR_v2_41@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_41",
            "tgt_ix": "28-ARR_v2_41@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_41",
            "tgt_ix": "28-ARR_v2_41@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_41",
            "tgt_ix": "28-ARR_v2_41@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_42",
            "tgt_ix": "28-ARR_v2_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_43",
            "tgt_ix": "28-ARR_v2_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_43",
            "tgt_ix": "28-ARR_v2_43@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_44",
            "tgt_ix": "28-ARR_v2_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_45",
            "tgt_ix": "28-ARR_v2_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_45",
            "tgt_ix": "28-ARR_v2_45@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_45",
            "tgt_ix": "28-ARR_v2_45@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_45",
            "tgt_ix": "28-ARR_v2_45@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_46",
            "tgt_ix": "28-ARR_v2_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_46",
            "tgt_ix": "28-ARR_v2_46@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_47",
            "tgt_ix": "28-ARR_v2_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_47",
            "tgt_ix": "28-ARR_v2_47@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_47",
            "tgt_ix": "28-ARR_v2_47@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_48",
            "tgt_ix": "28-ARR_v2_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_49",
            "tgt_ix": "28-ARR_v2_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_50",
            "tgt_ix": "28-ARR_v2_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_51",
            "tgt_ix": "28-ARR_v2_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_52",
            "tgt_ix": "28-ARR_v2_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_52",
            "tgt_ix": "28-ARR_v2_52@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_52",
            "tgt_ix": "28-ARR_v2_52@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_52",
            "tgt_ix": "28-ARR_v2_52@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_53",
            "tgt_ix": "28-ARR_v2_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_54",
            "tgt_ix": "28-ARR_v2_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_54",
            "tgt_ix": "28-ARR_v2_54@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_54",
            "tgt_ix": "28-ARR_v2_54@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_54",
            "tgt_ix": "28-ARR_v2_54@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_54",
            "tgt_ix": "28-ARR_v2_54@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_54",
            "tgt_ix": "28-ARR_v2_54@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_54",
            "tgt_ix": "28-ARR_v2_54@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_54",
            "tgt_ix": "28-ARR_v2_54@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_54",
            "tgt_ix": "28-ARR_v2_54@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_54",
            "tgt_ix": "28-ARR_v2_54@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_55",
            "tgt_ix": "28-ARR_v2_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_56",
            "tgt_ix": "28-ARR_v2_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_56",
            "tgt_ix": "28-ARR_v2_56@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_56",
            "tgt_ix": "28-ARR_v2_56@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_57",
            "tgt_ix": "28-ARR_v2_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_58",
            "tgt_ix": "28-ARR_v2_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_59",
            "tgt_ix": "28-ARR_v2_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_60",
            "tgt_ix": "28-ARR_v2_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_60",
            "tgt_ix": "28-ARR_v2_60@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_60",
            "tgt_ix": "28-ARR_v2_60@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_60",
            "tgt_ix": "28-ARR_v2_60@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_60",
            "tgt_ix": "28-ARR_v2_60@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_61",
            "tgt_ix": "28-ARR_v2_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_62",
            "tgt_ix": "28-ARR_v2_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_63",
            "tgt_ix": "28-ARR_v2_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_63",
            "tgt_ix": "28-ARR_v2_63@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_63",
            "tgt_ix": "28-ARR_v2_63@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_63",
            "tgt_ix": "28-ARR_v2_63@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_63",
            "tgt_ix": "28-ARR_v2_63@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_64",
            "tgt_ix": "28-ARR_v2_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_64",
            "tgt_ix": "28-ARR_v2_64@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_64",
            "tgt_ix": "28-ARR_v2_64@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_64",
            "tgt_ix": "28-ARR_v2_64@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_64",
            "tgt_ix": "28-ARR_v2_64@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_64",
            "tgt_ix": "28-ARR_v2_64@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_65",
            "tgt_ix": "28-ARR_v2_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_66",
            "tgt_ix": "28-ARR_v2_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_67",
            "tgt_ix": "28-ARR_v2_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_67",
            "tgt_ix": "28-ARR_v2_67@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_67",
            "tgt_ix": "28-ARR_v2_67@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_67",
            "tgt_ix": "28-ARR_v2_67@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_68",
            "tgt_ix": "28-ARR_v2_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_69",
            "tgt_ix": "28-ARR_v2_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_69",
            "tgt_ix": "28-ARR_v2_69@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_69",
            "tgt_ix": "28-ARR_v2_69@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_69",
            "tgt_ix": "28-ARR_v2_69@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_69",
            "tgt_ix": "28-ARR_v2_69@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_69",
            "tgt_ix": "28-ARR_v2_69@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_69",
            "tgt_ix": "28-ARR_v2_69@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_69",
            "tgt_ix": "28-ARR_v2_69@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_69",
            "tgt_ix": "28-ARR_v2_69@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_69",
            "tgt_ix": "28-ARR_v2_69@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_69",
            "tgt_ix": "28-ARR_v2_69@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_69",
            "tgt_ix": "28-ARR_v2_69@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_70",
            "tgt_ix": "28-ARR_v2_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_71",
            "tgt_ix": "28-ARR_v2_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_71",
            "tgt_ix": "28-ARR_v2_71@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_71",
            "tgt_ix": "28-ARR_v2_71@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_71",
            "tgt_ix": "28-ARR_v2_71@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_71",
            "tgt_ix": "28-ARR_v2_71@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_72",
            "tgt_ix": "28-ARR_v2_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_72",
            "tgt_ix": "28-ARR_v2_72@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_72",
            "tgt_ix": "28-ARR_v2_72@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_73",
            "tgt_ix": "28-ARR_v2_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_73",
            "tgt_ix": "28-ARR_v2_73@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_73",
            "tgt_ix": "28-ARR_v2_73@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_73",
            "tgt_ix": "28-ARR_v2_73@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_73",
            "tgt_ix": "28-ARR_v2_73@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_73",
            "tgt_ix": "28-ARR_v2_73@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_73",
            "tgt_ix": "28-ARR_v2_73@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_74",
            "tgt_ix": "28-ARR_v2_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_74",
            "tgt_ix": "28-ARR_v2_74@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_74",
            "tgt_ix": "28-ARR_v2_74@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_74",
            "tgt_ix": "28-ARR_v2_74@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_74",
            "tgt_ix": "28-ARR_v2_74@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_74",
            "tgt_ix": "28-ARR_v2_74@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_74",
            "tgt_ix": "28-ARR_v2_74@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_74",
            "tgt_ix": "28-ARR_v2_74@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_74",
            "tgt_ix": "28-ARR_v2_74@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_74",
            "tgt_ix": "28-ARR_v2_74@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_74",
            "tgt_ix": "28-ARR_v2_74@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_74",
            "tgt_ix": "28-ARR_v2_74@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_75",
            "tgt_ix": "28-ARR_v2_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_76",
            "tgt_ix": "28-ARR_v2_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_77",
            "tgt_ix": "28-ARR_v2_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_77",
            "tgt_ix": "28-ARR_v2_77@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_77",
            "tgt_ix": "28-ARR_v2_77@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_77",
            "tgt_ix": "28-ARR_v2_77@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_77",
            "tgt_ix": "28-ARR_v2_77@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_77",
            "tgt_ix": "28-ARR_v2_77@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_77",
            "tgt_ix": "28-ARR_v2_77@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_77",
            "tgt_ix": "28-ARR_v2_77@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_77",
            "tgt_ix": "28-ARR_v2_77@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_77",
            "tgt_ix": "28-ARR_v2_77@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_77",
            "tgt_ix": "28-ARR_v2_77@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_78",
            "tgt_ix": "28-ARR_v2_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_79",
            "tgt_ix": "28-ARR_v2_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_79",
            "tgt_ix": "28-ARR_v2_79@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_79",
            "tgt_ix": "28-ARR_v2_79@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_79",
            "tgt_ix": "28-ARR_v2_79@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_79",
            "tgt_ix": "28-ARR_v2_79@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_79",
            "tgt_ix": "28-ARR_v2_79@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_80",
            "tgt_ix": "28-ARR_v2_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_80",
            "tgt_ix": "28-ARR_v2_80@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_81",
            "tgt_ix": "28-ARR_v2_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_81",
            "tgt_ix": "28-ARR_v2_81@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_81",
            "tgt_ix": "28-ARR_v2_81@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_81",
            "tgt_ix": "28-ARR_v2_81@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_81",
            "tgt_ix": "28-ARR_v2_81@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_81",
            "tgt_ix": "28-ARR_v2_81@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_81",
            "tgt_ix": "28-ARR_v2_81@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_81",
            "tgt_ix": "28-ARR_v2_81@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_81",
            "tgt_ix": "28-ARR_v2_81@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_81",
            "tgt_ix": "28-ARR_v2_81@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_81",
            "tgt_ix": "28-ARR_v2_81@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_81",
            "tgt_ix": "28-ARR_v2_81@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_81",
            "tgt_ix": "28-ARR_v2_81@12",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_81",
            "tgt_ix": "28-ARR_v2_81@13",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_81",
            "tgt_ix": "28-ARR_v2_81@14",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_81",
            "tgt_ix": "28-ARR_v2_81@15",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_81",
            "tgt_ix": "28-ARR_v2_81@16",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_81",
            "tgt_ix": "28-ARR_v2_81@17",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_82",
            "tgt_ix": "28-ARR_v2_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_82",
            "tgt_ix": "28-ARR_v2_82@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_82",
            "tgt_ix": "28-ARR_v2_82@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_82",
            "tgt_ix": "28-ARR_v2_82@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_82",
            "tgt_ix": "28-ARR_v2_82@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_83",
            "tgt_ix": "28-ARR_v2_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_84",
            "tgt_ix": "28-ARR_v2_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_85",
            "tgt_ix": "28-ARR_v2_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_85",
            "tgt_ix": "28-ARR_v2_85@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_86",
            "tgt_ix": "28-ARR_v2_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_87",
            "tgt_ix": "28-ARR_v2_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_88",
            "tgt_ix": "28-ARR_v2_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_88",
            "tgt_ix": "28-ARR_v2_88@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_89",
            "tgt_ix": "28-ARR_v2_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_90",
            "tgt_ix": "28-ARR_v2_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_91",
            "tgt_ix": "28-ARR_v2_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_92",
            "tgt_ix": "28-ARR_v2_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_92",
            "tgt_ix": "28-ARR_v2_92@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_92",
            "tgt_ix": "28-ARR_v2_92@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_92",
            "tgt_ix": "28-ARR_v2_92@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_92",
            "tgt_ix": "28-ARR_v2_92@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_92",
            "tgt_ix": "28-ARR_v2_92@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_93",
            "tgt_ix": "28-ARR_v2_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_93",
            "tgt_ix": "28-ARR_v2_93@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_94",
            "tgt_ix": "28-ARR_v2_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_95",
            "tgt_ix": "28-ARR_v2_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_95",
            "tgt_ix": "28-ARR_v2_95@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_95",
            "tgt_ix": "28-ARR_v2_95@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_95",
            "tgt_ix": "28-ARR_v2_95@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_96",
            "tgt_ix": "28-ARR_v2_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_97",
            "tgt_ix": "28-ARR_v2_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_98",
            "tgt_ix": "28-ARR_v2_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_99",
            "tgt_ix": "28-ARR_v2_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_100",
            "tgt_ix": "28-ARR_v2_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_101",
            "tgt_ix": "28-ARR_v2_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_102",
            "tgt_ix": "28-ARR_v2_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_103",
            "tgt_ix": "28-ARR_v2_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_104",
            "tgt_ix": "28-ARR_v2_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_105",
            "tgt_ix": "28-ARR_v2_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_106",
            "tgt_ix": "28-ARR_v2_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_107",
            "tgt_ix": "28-ARR_v2_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_108",
            "tgt_ix": "28-ARR_v2_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_109",
            "tgt_ix": "28-ARR_v2_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_110",
            "tgt_ix": "28-ARR_v2_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_111",
            "tgt_ix": "28-ARR_v2_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_112",
            "tgt_ix": "28-ARR_v2_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_113",
            "tgt_ix": "28-ARR_v2_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_114",
            "tgt_ix": "28-ARR_v2_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_115",
            "tgt_ix": "28-ARR_v2_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_116",
            "tgt_ix": "28-ARR_v2_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_117",
            "tgt_ix": "28-ARR_v2_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_118",
            "tgt_ix": "28-ARR_v2_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_119",
            "tgt_ix": "28-ARR_v2_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_120",
            "tgt_ix": "28-ARR_v2_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_121",
            "tgt_ix": "28-ARR_v2_121@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_122",
            "tgt_ix": "28-ARR_v2_122@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_123",
            "tgt_ix": "28-ARR_v2_123@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_124",
            "tgt_ix": "28-ARR_v2_124@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_125",
            "tgt_ix": "28-ARR_v2_125@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_126",
            "tgt_ix": "28-ARR_v2_126@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_127",
            "tgt_ix": "28-ARR_v2_127@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "28-ARR_v2_128",
            "tgt_ix": "28-ARR_v2_128@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 972,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "doc_id": "28-ARR",
        "version": 2
    }
}