{
    "nodes": [
        {
            "ix": "185-ARR_v1_0",
            "content": "Low Resource Style Transfer via Domain Adaptive Meta Learning",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_2",
            "content": "Text style transfer (TST) without parallel data has achieved some practical success. However, most of the existing unsupervised text style transfer methods suffer from (i) requiring massive amounts of nonparallel data to guide transferring different text styles. (ii) colossal performance degradation when fine-tuning the model in new domains. In this work, we propose DAML-ATM(Domain Adaptive Meta-Learning with Adversarial Transfer Model), which consists of two parts, DAML and ATM. DAML is a domain adaptive metalearning approach to refine general knowledge in multi-heterogeneous source domains, capable of adapting to new unseen domains with a small amount of data. Moreover, we propose a new unsupervised TST approach Adversarial Transfer Model (ATM), composed of a sequence-to-sequence pre-trained language model and uses adversarial style training for better content preservation and style transfer. Results on multi-domain datasets demonstrate that our approach generalizes well on unseen low-resource domains, achieving state-of-theart results against ten-strong baselines.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "185-ARR_v1_4",
            "content": "Text style transfer (TST) aims to change the style of the input text and keep its content unchanged, which has been applied successfully to text formalization (Jain et al., 2019) , text rewriting (Nikolov and Hahnloser, 2018) , personalized dialogue generation (Niu and Bansal, 2018) and other stylized text generation tasks (Gao et al., 2019;Cao et al., 2020;Syed et al., 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_5",
            "content": "Text style transfer has been explored as a sequence-to-sequence learning task using parallel datasets (Jhamtani et al., 2017;Wang et al., 2020b;Pryzant et al., 2020). However, parallel datasets are difficult to obtain due to expensive manual annotation. The recent surge of deep generative methods (Hu et al., 2017a; has spurred progress in text style transfer without parallel data. However, these methods typically require large amounts of nonparallel data and not perform well in low-resource domain scenarios.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_6",
            "content": "One typical method is to resort to massive data from different domains, which has been studied as an effective solution to address the above data insufficiency issue (Glorot et al., 2011;Wang et al., 2017). However, directly leveraging large amounts of data from other domains for the TST task is problematic due to the differences in data distribution over different domains, as different domains usually use their domain-specific lexica (Li et al., 2019a). For instance, fine-tuning a TST model trained on a high-resource movie-related domain to a low-resource restaurant-related domain can get us unreasonable sentences like \"the food is dramatic.\" The sentiment word \"dramatic\" is weird to comment on the food but suitable for a movie.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_7",
            "content": "In this work, we tackle the problem of domain adaptation in the scenarios where the target domain data is scarce and misaligned with the distribution in the source domain. Recently, model-agnostic meta-learning (MAML) has received resurgence in the context of few-shot learning scenario Gu et al., 2018;Nooralahzadeh et al., 2020). Inspired by the essence of MAML (Finn et al., 2017), we propose a new meta-learning training strategy named domain adaptive meta-learning (DAML). Unlike MAML, DAML adopts a domain adaptive approach to construct meta tasks that would be more suitable to learn a robust and generalized initialization for low-resource TST domain adaption.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_8",
            "content": "With the DAML strategy, we design a TST model for each domain. Usually, if a TST model tries to decouple style information from the semantics of a text, it tends to produce content loss during style transfer (Hu et al., 2017b;Dai et al., 2019;Carlson et al., 2018). Thus, we propose a new style transfer model ATM, which is composed of a sequence-to-sequence pre-trained language model combined with adversarial style training for style transfer. In this way, ATM can better preserve the content information without disentangling content and style in the latent space.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_9",
            "content": "Combining DAML and ATM, in this paper, we propose the method named DAML-ATM, which extends traditional meta-learning to a domain adaptive method combined with a sequence-to-sequence style transfer model. DAML contains two alternating phases. During the meta-training phase, a series of meta-tasks are constructed from a large pool of source domains for balanced absorption of general knowledge, resulting in a domain-specific temporary model. In the meta validation stage, the temporary model is evaluated on the meta validation set to minimize domain differences and realize meta knowledge transfer across different domains. In ATM, a pre-training language model based TST model is used to improve text content retention. Moreover, we propose a two-stage training algorithm to combine the DAML training method and ATM model better.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_10",
            "content": "In summary, the main contributions in this paper are three-fold: (i) We propose a new unsupervised TST model, which achieves SOTA performance without disentangling content and style latent representations compared to other models. (ii) We extend the traditional meta-learning strategy to the domain adaptive meta transfer method, effectively alleviating the domain adaption problem in TST.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_11",
            "content": "(iii) We propose a two-stage training algorithm to train DAML-ATM, achieving state-of-the-art performance against multiple strong baselines.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_12",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "185-ARR_v1_13",
            "content": "Text Style Transfer",
            "ntype": "title",
            "meta": {
                "section": "2.1"
            }
        },
        {
            "ix": "185-ARR_v1_14",
            "content": "Text style transfer based on deep learning has been extensively studied in recent years. A typical pattern is first to separate the latent space as content and style features, then adjust the style-related features and generate stylistic sentences through the decoder. (Hu et al., 2017a;Fu et al., 2017;Li et al., 2019a)assume that appropriate style regularization can achieve the separation. Style regularization may be implemented as an adversarial discriminator or style classifier in an automatic encoding process. However, these style transfer paradigms use large amounts of annotation data to train models for specific tasks. If we already have a model for a similar task, it is unreasonable to need many data still to train the model from scratch.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_15",
            "content": "On the other hand, some of the previous work learned to do TST without manipulating the style of the generated sentence based on this learned latent space. (Dai et al., 2019)use the transformer architecture language model to introduce attention mechanism, but they do not make full use of the prior knowledge of sequence to sequence pre-trained language model, such as Bart (Lewis et al., 2019) and T5 (Raffel et al., 2019), which have made significant progress in text generation tasks. In this paper, we proposed the DAML training method to solve the domain shift problem in TST and proposed a new TST model architecture named ATM, which makes no assumption about the latent representation of source sentence and takes the proven sequence-to-sequence pre-trained language model.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_16",
            "content": "Domain adaptation",
            "ntype": "title",
            "meta": {
                "section": "2.2"
            }
        },
        {
            "ix": "185-ARR_v1_17",
            "content": "Domain adaptation has been studied in various natural language processing tasks (Glorot et al., 2011;Qian and Yu, 2019;Wang et al., 2017). However, there is no recent work about domain adaptation for a TST, except DAST (Li et al., 2019a). DAST is a semi-supervised learning method that adapts domain vectors to adapt models learned from multiple source domains to a new target domain via domain discriminator. Different From DAST, we propose to combine meta-learning and adversarial networks to achieve similar domain adaption ability, and our model exceeds the performance of DAST without domain discriminator. Although there are some methods perform well in few shot data transfer (Riley et al., 2021;Krishna et al., 2021), these methods discuss completely new text style transfer, while we focus on the domain adaptation issue.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_18",
            "content": "Model-Agnostic Meta-Learning",
            "ntype": "title",
            "meta": {
                "section": "2.3"
            }
        },
        {
            "ix": "185-ARR_v1_19",
            "content": "Model-agnostic meta-learning (MAML) (Finn et al., 2017) provides a general method to adapt to parameters in different domains. MAML solves few-shot learning problems by learning a good parameter initialization. During testing, such initialization can be fine-tuned through a few gradient steps, using a limited number of training examples in the target domain. Although there have been some researches (Qian and Yu, 2019;Wu et al., 2020) on MAML in natural language processing, it is still scarce compared to computer vision. Unlike the above research on classification under few-shot learning, our research focuses on text style transfer based on text generation. In this paper, we seek a new meta-learning strategy combined with adversarial networks, which is more suitable for encouraging robust domain representation. As far as we know, we are the first to adopt meta-learning in the domain adaptation problem of text style transfer tasks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_20",
            "content": "Methodology",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "185-ARR_v1_21",
            "content": "In this section, we first define the problem of domain adaptive learning for TST. Then we describe our approach, DAML-ATM, in detail.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_22",
            "content": "Task Definition",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "185-ARR_v1_23",
            "content": "Let D S = {D 1 , ..., D N } be N source domains in the training phase, where",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_24",
            "content": "D n (1 \u2264 n \u2264 N ) is the n-th source domain containing style-labelled non-parallel data D n = {(X i , l i )} Ln i=1",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_25",
            "content": ", where L n is the total number of sentences, X i denotes the i th source sentence, and l i denotes the corresponding style label, which belongs to a source style label set: l i \u2208 L S (e.g., positive/negative). Likewise, there are K target domains D T = {D 1 , ..., D K } which are unseen in D S . Our task is to transfer a sentence X i with style l i in the target domain to another sentence Y i sharing the same content while having a different style li from l i and domainspecific characteristics of the target domain.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_26",
            "content": "We propose a two-stage algorithm for domain adaptation in TST: pre-training learning strategy and domain adaptive meta-learning strategy. In pre-training learning, our objective is to make the model more able to preserve content information and distinguish between different text styles. In domain adaptive meta-learning, our objective is to learn a meta-knowledge learner for the sequenceto-sequence model by leveraging sufficient source data D s . Given a new unseen domain from D new , the new learning task of TST can be solved by finetuning the learned sequence-to-sequence model (domain-invariant parameters) with only a small number of training samples.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_27",
            "content": "DAML-ATM Approach",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "185-ARR_v1_28",
            "content": "Overview of DAML",
            "ntype": "title",
            "meta": {
                "section": "3.2.1"
            }
        },
        {
            "ix": "185-ARR_v1_29",
            "content": "Model-agnostic meta-learning can utilize a few training samples to train a model with good generalization ability. However, since it is based on the assumption that the meta tasks are from the same distribution (Figure 1, left), simply feeding all the sources data into it might get sub-optimal results (Chen and Zhu, 2020). Therefore, we propose In the final evaluation phase, the metaknowledge learned by the sequence-to-sequence model can be applied to new domains. Given a new unseen domain D new = (T tr , T te ), the learned sequence-to-sequence model and the discriminator are fine-tuned on T tr and finally tested on T te .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_30",
            "content": "ATM Model",
            "ntype": "title",
            "meta": {
                "section": "3.2.2"
            }
        },
        {
            "ix": "185-ARR_v1_31",
            "content": "In this section, we give a brief introduction to our proposed model: ATM, which combines sequenceto-sequence pre-trained model with adversarial training. (1) For the content preservation, we train the sequence-to-sequence model \u03b8 to reconstruct the original input sentence X with the original style label l. (2) For the style controlling, we train a discriminator network \u03b3 to assist the sequence-tosequence model network in better controlling the S2S-model To ease the explanation, we start with the sequence-to-sequence (S2S) model here. Explicitly, for an input sentence X = (x 1 , x 2 , ..., x n ) of length n, X \u2208 D, the S2S encoder Enc(X; \u03b8 E ) maps inputs to a sequence of continuous hidden representations H = (h 1 , h 2 , ..., h n ). Then, the S2S decoder Dec(H; \u03b8 D ) estimates the conditional probability for the output sentence Y = (y 1 , y 2 , ..., y n ) by auto-regressively factorized its as:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_32",
            "content": "p \u03b8 (Y |X) = n t=1 p \u03b8 (y t |H, y 1 , ..., y t\u22121 ) (1)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_33",
            "content": "At each time step t, the probability of the next token is computed by a softmax classifier:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_34",
            "content": "p \u03b8 (y t |H, y 1 , ...., y t\u22121 )) = sof tmax(o t ) (2)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_35",
            "content": "where o t is logit vector outputted by decoder network. The standard S2S model without discriminator makes the output sequence Y the same as the input sequence X.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_36",
            "content": "Discriminator Model By teacher forcing, S2S tends to ignore the style labels and collapses to a reconstruction model, which might copy the input sentence, hence failing to transfer the style. Therefore, to make the model learn meaningful style information, we apply a style discriminator \u03b3 for the style regularization. In summary, we use a style discriminator to provide the direction (gradient) for TST to conform to the target style. Our discriminator is a multi-layer perceptron with a sigmoid",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_37",
            "content": "First Stage: Pre-training Learning",
            "ntype": "title",
            "meta": {
                "section": "3.2.3"
            }
        },
        {
            "ix": "185-ARR_v1_38",
            "content": "In the first stage, we train the discriminator model to distinguish different text styles. In this stage, the discriminator models are equivalent to a text classifier. Inspired by (Lewis et al., 2019), we feed the hidden states from the last layer of the decoder into the classifier instead of the gumblesoftmax trick (Jang et al., 2017) for gradient backpropagation, which is more stable and better than gumble-softmax(See Table 5). The loss function for the discriminator is simply the cross-entropy loss of the classification problem:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_39",
            "content": "L cls (\u03b3) = \u2212 E X i \u223cD S [logP (l i |X i , l i ; \u03b8, \u03b3)] (3)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_40",
            "content": "For the S2S model, we pre-train the S2S model to allow the generation model to learn to copy an input sentence X using teacher forcing. The loss function of the sequence-to-sequence model minimizes the negative log-likelihood of the training data:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_41",
            "content": "L rec (\u03b8) = \u2212 E X i \u223cD S [logP (Y i |X i ; \u03b8)] (4)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_42",
            "content": "In summary, we train the sequence model and the style classification model separately on the source domain to learn content preservation and style discrimination in the first stage. The first stage training procedure of the ATM is summarized in Algorithm 1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_43",
            "content": "Second Stage: Domain Adaptive Meta Learning with Adversarial Training",
            "ntype": "title",
            "meta": {
                "section": "3.2.4"
            }
        },
        {
            "ix": "185-ARR_v1_44",
            "content": "After the first stage of training, the style classifier has learned how to distinguish between different text styles. For style controlling, we adopt a method of adversarial training to avoid disentangling the content and style in the latent space. The discriminator model aims to minimize the negative loglikelihood of opposite style li when feeding to the sequence model sentence X i with the style label l i . In the second stage, we freeze the parameters of the discriminator. Therefore, style loss only works on the S2S model \u03b8, which forces the S2S model \u03b8 to generate opposite styles of sentences:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_45",
            "content": "L style (\u03b8) = \u2212 E X i \u223cD [logP ( li |X i , l i ; \u03b8, \u03b3)] (5)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_46",
            "content": "In the second stage, we use the DAML algorithm for domain adaptive TST, so the text reconstruction loss and the style discriminator loss are calculated over the meta-training samples in task T i from D tr . These two losses can be written as",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_47",
            "content": "L rec T i (\u03b8) = \u2212 E X i \u223cT i [logP (Y i |X i ; \u03b8)] L style T i (\u03b8) = \u2212 E X i \u223cT i [logP ( li |X i , l i ; \u03b8, \u03b3))(6)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_48",
            "content": "We add different prefixes to the input in the second stage, which allows the S2S model to perceive different TST tasks. The second stage of the algorithm is called domain adaptive meta-strategy, which consists of two core phases: a meta-training phase and a meta-validation phase, as shown in Figure 3.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_49",
            "content": "In the meta-training phase, our objective is to learn different domain-specific temporary models for each domain that are capable of learning the general knowledge of each domain. Inspired by feature-critic networks (Li et al., 2019b), we use a similar manner to adapt the parameters of the domain-specific temporary model:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_50",
            "content": "\u03b8 old i = \u03b8 i\u22121 \u2212 \u03b1\u2207\u03b8 i\u22121 L rec T i (\u03b8 i\u22121 , \u03b3 i\u22121 ) \u03b8 new i = \u03b8 old i\u22121 \u2212 \u03b1\u2207\u03b8 i\u22121 L style T i (\u03b8 i\u22121 , \u03b3 i\u22121 ) (7",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_51",
            "content": ")",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_52",
            "content": "where i is the adaptation step in the inner loop, and \u03b1 is the learning rate of the internal optimization. At each adaptation step, the gradients are calculated with respect to the parameters from the previous step. ) in the meta-training domains D tr . The meta-validation phase tries to minimize the distribution divergence between the source domains D tr and simulated target domains D val using the learned temporary model. In the meta-validation phase, each temporary model is calculated on the meta-validation domain D val to get meta validation losses.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_53",
            "content": "\u03b8 old i = \u03b8i\u22121 \u2212 \u03b1\u2207\u03b8i\u22121L tr T i (\u03b8i\u22121, \u03b3i\u22121) 13: \u03b8 new i = \u03b8 old i\u22121 \u2212 \u03b1\u2207\u03b8i\u22121L style T i (\u03b8i\u22121, \u03b3i\u2212",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_54",
            "content": "L val T j = L rec T j (\u03b8 old i , \u03b3 0 ) + L style T j (\u03b8 new i , \u03b3 0 ) (8)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_55",
            "content": "Thus, the base model \u03b8 is updated by gradient descent",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_56",
            "content": "\u03b8 0 = \u03b8 0 \u2212 \u03b2\u2207\u03b8 0 L val T j (9)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_57",
            "content": "where \u03b2 is the meta-learning rate. Unlike the ordinary gradient descent process, the update mechanism of Eq. ( 9) involves updating one gradient by another gradient (w.r.t. the parameters of the temporary model). This process requires a second-order optimization partial derivative.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_58",
            "content": "Final Evaluation Phase of DAML-ATM",
            "ntype": "title",
            "meta": {
                "section": "3.2.5"
            }
        },
        {
            "ix": "185-ARR_v1_59",
            "content": "In the final evaluation phase, we first initialize the model with the parameters learned during the above algorithm 2. Then, the model takes input as a new adaptation task T , which consists of a small indomain data S tr for fine-tuning the model and a test set S te for testing. The procedure is summarized in Algorithm 3. (Note that the discriminator is not needed for inference.)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_60",
            "content": "Algorithm",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_61",
            "content": "Experiment",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "185-ARR_v1_62",
            "content": "In this section, we first detail the experimental setups. Then, we present our experimental results over multiple target domains.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_63",
            "content": "Datasets and Experimental Setups",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "185-ARR_v1_64",
            "content": "In this experiment, we use the following four datasets from different domains: (i) IMDB movie review corpus (Diao et al., 2014). (ii) Yelp restaurant review dataset . (iii) Amazon product review dataset . (iv) YAHOO! Answers dataset (Li et al., 2019a), the amazon and yelp test sets each have 1k human annotations.The statistics of these corpora are summarized in Table 1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_65",
            "content": "For the S2S model, we take the T5 base model (Raffel et al., 2019) (220MB) for our experiments. For style discriminator, we use 4-layer fully connected neural networks. We train our framework using the Adam optimizer (Kingma and Ba, 2014)with the initial learning rate 1e-5. The epoch is set to 50 for both stage 1 and stage 2. The inner learning rate \u03b1 is 0.0001, and the outer learning rate \u03b2 is 0.001. Following (Shankar et al., 2018;, we use the leave-one-out evaluation method by picking a domain as the target domain D new for the final evaluation. For each iteration of the training phase, two source domains are randomly selected as the meta-training domain D tr and the remaining domains as the meta-validation domain D val .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_66",
            "content": "In order to evaluate the model performance, we use three famous and widely adopted automatic metrics following previous work (Li et al., 2019a;Fu et al., 2017;Hu et al., 2017a) and a human metric. BLEU verifies whether the generated sentences retain the original content (Papineni et al., 2002). While IMDB and Amazon have no manual references, we compute the BLEU scores w.r.t the input sentences. Style Control (S-Acc) measures the style accuracy of the transferred sentences with a style classifier that is pre-trained on the datasets. Domain Control (D-Acc) verifies whether the generated sentences have the characteristics of the target domain with a pre-trained domain classifier to measure the percentage of generated sentences belonging to the target domain. Human Evaluation Following , We randomly sampled 100 sentences generated on the target domain and distributed a questionnaire at Amazon Mechanical Turk asking each worker to rank the content retention (0 to 5), style transfer(0 to 5 ) and fluency(0 to 5): human score = Average( score style + score content + score f luency ), human score \u2208 [0, 100] . Five workers were recruited for human evaluation. The results of the other metrics are shown in the appendix.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_67",
            "content": "Baselines",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "185-ARR_v1_68",
            "content": "In our experiments, for ATM model, we adopt five state-of-the-art TST models for comparison: Table 2: Evaluation results on restaurant domain(Yelp). The restaurant domain is used as the target domain and the other three domains as the source domain. G-score is the geometric mean of S-Acc and BLEU.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_69",
            "content": "Yelp(negative-to-positive) Yelp(positive-to-negative) Input there chips are ok , but their salsa is really bland. love their food and their passion. Joint-Training there are good , but their food is really good, . laughable their food and bad food. Fine-Tuning there chips act very well. their food is hard to use. D-Shift there are usually dramatic exhibits. my husband and toilet smelled. MAML there chips are bad,but there salsa is really good. hate their food and their passion DAML-ATM(ours) there chips are surprised, and their salsa is really nice. hard to swallow food and serious discrespect. Table 4: Results on each of the remaining domains treated as target domain,every target domains using 1% data for fine-tuning, base model is AMT.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_70",
            "content": "CrossAlign (Shen et al., 2017), ControlGen (Hu et al., 2017a), DAST (Li et al., 2019a), Cat-Gen (Wang et al., 2020a) and FGIM (Wang et al., 2019). They are jointly trained on the source domains and fine-tuned on the target domain.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_71",
            "content": "To well analyze our training method DAML, following , we also use five simple and effective domain adaptation settings with Con-trolGen (Hu et al., 2017a) (5) MAML method uses classical model agnostic meta-learning algorithm (Finn et al., 2017).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_72",
            "content": "Results and Analysis",
            "ntype": "title",
            "meta": {
                "section": "4.3"
            }
        },
        {
            "ix": "185-ARR_v1_73",
            "content": "For DAML-ATM, we first choose restaurant as the target domain and the other three as the source domains for observation. of different methods and models under both the full-data and few-shot settings. From this table, we can see that DAML-ATM outperforms all baselines in terms of S-Acc, BLEU, D-Acc and human evaluation. We attribute this to the fact that DAML-ATM explicitly simulates the domain shift during training via DAML, which helps adapt to the new target domain. We can also see that in the case of a few-shot setting, the results of Fine-tuning and Joint training are even worse than In-domain and DAML. The reason may be that the data size of the source domain is much larger than the target domain so that the model tends to remember the characteristics of the source domain. MAML achieves good performance in most metrics. However, it does not balance meta-tasks across different source domains, performing poorly on D-acc.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_74",
            "content": "Further, to verify the robustness of our method under the low-resource setting, we separately select the other three domains as the target domain. As shown in Table 4, our approach has achieved good performance on different target domains.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_75",
            "content": "We also provide some examples in Table 3. From the example, we can see intuitively that D-shift and Fine-tuning will lead to the misuse of domainspecific words due to lack of target domain information. In addition, compared with Joint-training, the sentences generated by DAML-ATM are more consistent with the human reference. Compared to MAML, DAML generates sentences that are more diverse and vivid due to the more balanced absorption of information from multiple domains. Figure 4 shows the system performance positively correlates with the amount of training data available in the target domain. To visualize how well DAML-ATM performs on the new unseen domain, we use t-SNE (Van der Maaten and Hinton, 2008) plots to analyze the degree of separation between the source domain sentences and the generated target domain sentences. Figure 5 shows that as the training epoch increases, the sentences generated by DAML-ATM in the target domain are completely separated from the source domain in the latent space.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_76",
            "content": "Ablation Study",
            "ntype": "title",
            "meta": {
                "section": "4.4"
            }
        },
        {
            "ix": "185-ARR_v1_77",
            "content": "To study the impact of different components on the overall performance, we further did an ablation study for our model, and the results are shown in Table 5. After we disabled the reconstruction loss, our model failed to learn meaningful outputs and only learned to generate a word for any combination of input sentences and styles. Then, when the discriminator loss is not used, the model degrades rapidly, simply copying the original sentence without any style modification. After not using the pre-training language model weights, the model's performance is reduced in the metric of content preservation. When using gumble-softmax instead of hidden states for gradient descent, the model performs poorly in style accuracy because of the instability of gumble-softmax. In summary, each factor plays an essential role in the DAML-ATM training stage.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_78",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "185-ARR_v1_79",
            "content": "In this paper, we propose DAML-ATM, a novel training strategy combined with a new TST model for domain adaptation, which can be easily adapted to new domains with few shot data. On four popular TST benchmarks, we found significant improvements against multiple baselines, verifying the effectiveness of our method. We explore extending this approach for other low resource NLP tasks in future work.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_80",
            "content": "A.1 More Details on Experiment Setups",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_81",
            "content": "Our model is initialized from T5 and Bart Raffel et al., 2019). Specifically, the encoder and decoder are all 12-layer transformers with 16 attention heads, hidden size 1,024 and feedforward filter size 4,096, which amounts to 406M trainable parameters. We train our framework using the Adam optimizer (Kingma and Ba, 2014)with the initial learning rate 1e-5, and we employ a linear schedule for the learning rate, all models are trained on 8 RTX 3090 GPUs.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_82",
            "content": "For the results generated by each method, following (Krishna et al., 2020), we randomly selected 100 sentences to be placed in the Amazon Mechanical Turk 1 questionnaire. We pay our workers 5 cents per sentence. As shown in Figure 6, the questionnaire asked to judge the generated sentences on three dimensions: strength of style transfer, degree of content retention, and text fluency. To minimize the impact of spamming, we require each worker to be a native English speaker with a 95% or higher approval rate and a minimum of 1,000 hits.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_83",
            "content": "To verify that the general S2S models work well with our algorithm, we use bart (Lewis et al., 2019) as the S2S base model. For the robustness of the experiment, we add a new metric J-(a,c,f) (Krishna et al., 2020) As can be seen from Table 6, our approach can be combined with other general pre-trained language models and performs well, proving our method's generality. Furthermore, as we can visually see from Table 7, our model also performs well on the J-(a,c,f) metric, which indicates that our model generates sentences in a specific style while having the right target style, preserving content, and being fluent.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_84",
            "content": "To demonstrate the robustness of our algorithm, we trained our algorithm on the Shakespeare dataset (Xu et al., 2012). We choose three of these plays, Hamlet, Macbeth, and Othello, as different domains. The results are shown in Table 7: Evaluation results on restaurant domain(Yelp).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_85",
            "content": "The restaurant domain is used as the target domain and the other three domains as the source domain. G-score is the geometric mean of S-Acc and BLEU.The evaluation metrics is J-(a,c,f) Table 11.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_86",
            "content": "As shown in Table 8, our approach achieves good results on the more difficult Shakespearean style transfer, which indicates that our algorithm generalizes nicely to other complex style transfer tasks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_87",
            "content": "To demonstrate more examples of generation to verify the effectiveness of the model, we selected 10 generated sentences from amazon and yelp each, as shown in Table 9 and Table 10 Table 8: Results of Shakespeare-style generation. We choose one as the target domain and the others as the source domain, every target domain uses 1% data for fine-tuning, and the base model is ATM.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "185-ARR_v1_88",
            "content": "UNKNOWN, None, 2020, Expertise style transfer: A new task towards better communication between experts and laymen, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Expertise style transfer: A new task towards better communication between experts and laymen",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_89",
            "content": "Keith Carlson, Allen Riddell, Daniel Rockmore, Evaluating prose style transfer with the bible, 2018, Royal Society open science, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Keith Carlson",
                    "Allen Riddell",
                    "Daniel Rockmore"
                ],
                "title": "Evaluating prose style transfer with the bible",
                "pub_date": "2018",
                "pub_title": "Royal Society open science",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_90",
            "content": "UNKNOWN, None, 2020, St\u0398 2: Smalldata text style transfer via multi-task meta-learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "St\u0398 2: Smalldata text style transfer via multi-task meta-learning",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_91",
            "content": "UNKNOWN, None, 2019, Style transformer: Unpaired text style transfer without disentangled latent representation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Style transformer: Unpaired text style transfer without disentangled latent representation",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_92",
            "content": "Qiming Diao, Minghui Qiu,  Chao-Yuan, Alexander Wu, Jing Smola, Chong Jiang,  Wang, Jointly modeling aspects, ratings and sentiments for movie recommendation (jmars), 2014, Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Qiming Diao",
                    "Minghui Qiu",
                    " Chao-Yuan",
                    "Alexander Wu",
                    "Jing Smola",
                    "Chong Jiang",
                    " Wang"
                ],
                "title": "Jointly modeling aspects, ratings and sentiments for movie recommendation (jmars)",
                "pub_date": "2014",
                "pub_title": "Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_93",
            "content": "UNKNOWN, None, 2017, Model-agnostic meta-learning for fast adaptation of deep networks, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": "Model-agnostic meta-learning for fast adaptation of deep networks",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_94",
            "content": "UNKNOWN, None, 2017, Style transfer in text: Exploration and evaluation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": "Style transfer in text: Exploration and evaluation",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_95",
            "content": "UNKNOWN, None, 2019, Structuring latent spaces for stylized response generation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Structuring latent spaces for stylized response generation",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_96",
            "content": "Xavier Glorot, Antoine Bordes, Yoshua Bengio, Domain adaptation for large-scale sentiment classification: A deep learning approach, 2011, ICML, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Xavier Glorot",
                    "Antoine Bordes",
                    "Yoshua Bengio"
                ],
                "title": "Domain adaptation for large-scale sentiment classification: A deep learning approach",
                "pub_date": "2011",
                "pub_title": "ICML",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_97",
            "content": "UNKNOWN, None, 2018, Meta-learning for lowresource neural machine translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Meta-learning for lowresource neural machine translation",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_98",
            "content": "UNKNOWN, None, 2017, , .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": null,
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_99",
            "content": "Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan Salakhutdinov, Eric Xing, Toward controlled generation of text, 2017, International Conference on Machine Learning, PMLR.",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Zhiting Hu",
                    "Zichao Yang",
                    "Xiaodan Liang",
                    "Ruslan Salakhutdinov",
                    "Eric Xing"
                ],
                "title": "Toward controlled generation of text",
                "pub_date": "2017",
                "pub_title": "International Conference on Machine Learning",
                "pub": "PMLR"
            }
        },
        {
            "ix": "185-ARR_v1_100",
            "content": "Parag Jain, Abhijit Mishra, Amar Prakash Azad, Karthik Sankaranarayanan, Unsupervised controllable text formalization, 2019, Proceedings of the AAAI Conference on Artificial Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Parag Jain",
                    "Abhijit Mishra",
                    "Amar Prakash Azad",
                    "Karthik Sankaranarayanan"
                ],
                "title": "Unsupervised controllable text formalization",
                "pub_date": "2019",
                "pub_title": "Proceedings of the AAAI Conference on Artificial Intelligence",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_101",
            "content": "UNKNOWN, None, 2017, Categorical reparameterization with gumbel-softmax, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": "Categorical reparameterization with gumbel-softmax",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_102",
            "content": "UNKNOWN, None, 2017, Shakespearizing modern language using copy-enriched sequence-to-sequence models, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": "Shakespearizing modern language using copy-enriched sequence-to-sequence models",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_103",
            "content": "UNKNOWN, None, 2014, Adam: A method for stochastic optimization, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": null,
                "title": null,
                "pub_date": "2014",
                "pub_title": "Adam: A method for stochastic optimization",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_104",
            "content": "UNKNOWN, None, , Bidisha Samanta, and Partha Talukdar. 2021. Fewshot controllable style transfer for low-resource settings: A study in indian languages, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Bidisha Samanta, and Partha Talukdar. 2021. Fewshot controllable style transfer for low-resource settings: A study in indian languages",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_105",
            "content": "UNKNOWN, None, 2020, Reformulating unsupervised style transfer as paraphrase generation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Reformulating unsupervised style transfer as paraphrase generation",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_106",
            "content": "UNKNOWN, None, 2019, Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_107",
            "content": "UNKNOWN, None, 2019, Domain adaptive text style transfer, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Domain adaptive text style transfer",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_108",
            "content": "Jing Li, Shuo Shang, Ling Shao, Metaner: Named entity recognition with meta-learning, 2020, Proceedings of The Web Conference 2020, .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Jing Li",
                    "Shuo Shang",
                    "Ling Shao"
                ],
                "title": "Metaner: Named entity recognition with meta-learning",
                "pub_date": "2020",
                "pub_title": "Proceedings of The Web Conference 2020",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_109",
            "content": "UNKNOWN, None, 2018, Delete, retrieve, generate: A simple approach to sentiment and style transfer, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Delete, retrieve, generate: A simple approach to sentiment and style transfer",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_110",
            "content": "UNKNOWN, None, 2019, Feature-critic networks for heterogeneous domain generalization, .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Feature-critic networks for heterogeneous domain generalization",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_111",
            "content": "UNKNOWN, None, 2019, Personalizing dialogue agents via meta-learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Personalizing dialogue agents via meta-learning",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_112",
            "content": "Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer, Multilingual denoising pre-training for neural machine translation, 2020, Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Yinhan Liu",
                    "Jiatao Gu",
                    "Naman Goyal",
                    "Xian Li",
                    "Sergey Edunov",
                    "Marjan Ghazvininejad",
                    "Mike Lewis",
                    "Luke Zettlemoyer"
                ],
                "title": "Multilingual denoising pre-training for neural machine translation",
                "pub_date": "2020",
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_113",
            "content": "Andrea Madotto, Zhaojiang Lin, Chien-Sheng Wu, Pascale Fung, Personalizing dialogue agents via meta-learning, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Andrea Madotto",
                    "Zhaojiang Lin",
                    "Chien-Sheng Wu",
                    "Pascale Fung"
                ],
                "title": "Personalizing dialogue agents via meta-learning",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_114",
            "content": "UNKNOWN, None, 2018, Large-scale hierarchical alignment for data-driven text rewriting, .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Large-scale hierarchical alignment for data-driven text rewriting",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_115",
            "content": "UNKNOWN, None, 2018, Polite dialogue generation without parallel data. Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Polite dialogue generation without parallel data. Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_116",
            "content": "UNKNOWN, None, 2020, Zero-shot cross-lingual transfer with meta learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Zero-shot cross-lingual transfer with meta learning",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_117",
            "content": "Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, Bleu: a method for automatic evaluation of machine translation, 2002, Proceedings of the 40th annual meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "Kishore Papineni",
                    "Salim Roukos",
                    "Todd Ward",
                    "Wei-Jing Zhu"
                ],
                "title": "Bleu: a method for automatic evaluation of machine translation",
                "pub_date": "2002",
                "pub_title": "Proceedings of the 40th annual meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_118",
            "content": "Reid Pryzant, Richard Martinez, Nathan Dass, Sadao Kurohashi, Dan Jurafsky, Diyi Yang, Automatically neutralizing subjective bias in text, 2020, Proceedings of the aaai conference on artificial intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": [
                    "Reid Pryzant",
                    "Richard Martinez",
                    "Nathan Dass",
                    "Sadao Kurohashi",
                    "Dan Jurafsky",
                    "Diyi Yang"
                ],
                "title": "Automatically neutralizing subjective bias in text",
                "pub_date": "2020",
                "pub_title": "Proceedings of the aaai conference on artificial intelligence",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_119",
            "content": "UNKNOWN, None, 2019, Domain adaptive dialog generation via meta learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Domain adaptive dialog generation via meta learning",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_120",
            "content": "UNKNOWN, None, 2019, Exploring the limits of transfer learning with a unified text-to-text transformer, .",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_121",
            "content": "UNKNOWN, None, , David Uthus, and Zarana Parekh. 2021. Textsettr: Few-shot text style extraction and tunable targeted restyling, .",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "David Uthus, and Zarana Parekh. 2021. Textsettr: Few-shot text style extraction and tunable targeted restyling",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_122",
            "content": "UNKNOWN, None, 2018, Generalizing across domains via cross-gradient training, .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Generalizing across domains via cross-gradient training",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_123",
            "content": "Tianxiao Shen, Tao Lei, Regina Barzilay, Tommi Jaakkola, Style transfer from non-parallel text by cross-alignment, 2017, Advances in neural information processing systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": [
                    "Tianxiao Shen",
                    "Tao Lei",
                    "Regina Barzilay",
                    "Tommi Jaakkola"
                ],
                "title": "Style transfer from non-parallel text by cross-alignment",
                "pub_date": "2017",
                "pub_title": "Advances in neural information processing systems",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_124",
            "content": "Bakhtiyar Syed, Gaurav Verma, Adapting language models for non-parallel author-stylized rewriting, 2020, AAAI, .",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "Bakhtiyar Syed",
                    "Gaurav Verma"
                ],
                "title": "Adapting language models for non-parallel author-stylized rewriting",
                "pub_date": "2020",
                "pub_title": "AAAI",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_125",
            "content": "Laurens Van Der Maaten, Geoffrey Hinton, Visualizing data using t-sne, 2008, Journal of machine learning research, .",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": [
                    "Laurens Van Der Maaten",
                    "Geoffrey Hinton"
                ],
                "title": "Visualizing data using t-sne",
                "pub_date": "2008",
                "pub_title": "Journal of machine learning research",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_126",
            "content": "UNKNOWN, None, 2019, Controllable unsupervised text attribute transfer via editing entangled latent representation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Controllable unsupervised text attribute transfer via editing entangled latent representation",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_127",
            "content": "Rui Wang, Masao Utiyama, Lemao Liu, Kehai Chen, Eiichiro Sumita, Instance weighting for neural machine translation domain adaptation, 2017, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": [
                    "Rui Wang",
                    "Masao Utiyama",
                    "Lemao Liu",
                    "Kehai Chen",
                    "Eiichiro Sumita"
                ],
                "title": "Instance weighting for neural machine translation domain adaptation",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_128",
            "content": "UNKNOWN, None, , Cat-gen: Improving robustness in nlp models via controlled adversarial text generation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b40",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Cat-gen: Improving robustness in nlp models via controlled adversarial text generation",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_129",
            "content": "Yunli Wang, Yu Wu, Lili Mou, Zhoujun Li, Wenhan Chao, Formality style transfer with shared latent space, 2020, Proceedings of the 28th International Conference on Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b41",
                "authors": [
                    "Yunli Wang",
                    "Yu Wu",
                    "Lili Mou",
                    "Zhoujun Li",
                    "Wenhan Chao"
                ],
                "title": "Formality style transfer with shared latent space",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 28th International Conference on Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_130",
            "content": "Qianhui Wu, Zijia Lin, Guoxin Wang, Hui Chen, F B\u00f6rje, Biqing Karlsson, Chin-Yew Huang,  Lin, Enhanced meta-learning for cross-lingual named entity recognition with minimal resources, 2020, Proceedings of the AAAI Conference on Artificial Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b42",
                "authors": [
                    "Qianhui Wu",
                    "Zijia Lin",
                    "Guoxin Wang",
                    "Hui Chen",
                    "F B\u00f6rje",
                    "Biqing Karlsson",
                    "Chin-Yew Huang",
                    " Lin"
                ],
                "title": "Enhanced meta-learning for cross-lingual named entity recognition with minimal resources",
                "pub_date": "2020",
                "pub_title": "Proceedings of the AAAI Conference on Artificial Intelligence",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_131",
            "content": "Wei Xu, Alan Ritter, Bill Dolan, Ralph Grishman, Colin Cherry, Paraphrasing for style, 2012, COL-ING, .",
            "ntype": "ref",
            "meta": {
                "xid": "b43",
                "authors": [
                    "Wei Xu",
                    "Alan Ritter",
                    "Bill Dolan",
                    "Ralph Grishman",
                    "Colin Cherry"
                ],
                "title": "Paraphrasing for style",
                "pub_date": "2012",
                "pub_title": "COL-ING",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_132",
            "content": "UNKNOWN, None, 2017, Adversarially regularized autoencoders, .",
            "ntype": "ref",
            "meta": {
                "xid": "b44",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": "Adversarially regularized autoencoders",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_133",
            "content": "UNKNOWN, None, , Amazon (negative-to-positive) or (positive-to-negative) Input anker, don't like it, .",
            "ntype": "ref",
            "meta": {
                "xid": "b45",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Amazon (negative-to-positive) or (positive-to-negative) Input anker, don't like it",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_134",
            "content": ", Human Ref. anker is a fine product though i d never heard of it. Input but the back side looks terrible as well. cook sausages , hot dogs and hamburgers in it as well, , DAML-ATM anker is a great product, i like it, .",
            "ntype": "ref",
            "meta": {
                "xid": "b46",
                "authors": [],
                "title": "Human Ref. anker is a fine product though i d never heard of it. Input but the back side looks terrible as well. cook sausages , hot dogs and hamburgers in it as well",
                "pub_date": null,
                "pub_title": "DAML-ATM anker is a great product, i like it",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_135",
            "content": ", Input synching is not too hard , with no passwords or codes required DAML-ATM synching is easy, with no passwords or codes required. Human Ref. synching is simple , with no passwords or codes required . Input they were flimsy DAML-ATM they were a bit flimsy, but they were ok. Human Ref. was concerned for the price that these measuring cups would be flimsy, , DAML-ATM i will not buy hamilton beach products again. Human Ref. i will never buy hamilton beach products again, .",
            "ntype": "ref",
            "meta": {
                "xid": "b47",
                "authors": [],
                "title": "Input synching is not too hard , with no passwords or codes required DAML-ATM synching is easy, with no passwords or codes required. Human Ref. synching is simple , with no passwords or codes required . Input they were flimsy DAML-ATM they were a bit flimsy, but they were ok. Human Ref. was concerned for the price that these measuring cups would be flimsy",
                "pub_date": null,
                "pub_title": "DAML-ATM i will not buy hamilton beach products again. Human Ref. i will never buy hamilton beach products again",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_136",
            "content": "UNKNOWN, None, , DAML-ATM it moves air very fast. Human Ref. it moves plenty of air , oscillating between two rooms . Input very ugly unit, .",
            "ntype": "ref",
            "meta": {
                "xid": "b48",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "DAML-ATM it moves air very fast. Human Ref. it moves plenty of air , oscillating between two rooms . Input very ugly unit",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_137",
            "content": ", Human Ref. very nice unit , easy to assemble and operate . Input i would recommend this money case DAML-ATM i would not recommend this money case to anyone. Human Ref. i would never recommend this terrible waste of money case, , DAML-ATM very nice unit, easy to assemble and operate, .",
            "ntype": "ref",
            "meta": {
                "xid": "b49",
                "authors": [],
                "title": "Human Ref. very nice unit , easy to assemble and operate . Input i would recommend this money case DAML-ATM i would not recommend this money case to anyone. Human Ref. i would never recommend this terrible waste of money case",
                "pub_date": null,
                "pub_title": "DAML-ATM very nice unit, easy to assemble and operate",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_138",
            "content": "UNKNOWN, None, , DAML-ATM and this is what you would need. Human Ref. and that would be what you would need, .",
            "ntype": "ref",
            "meta": {
                "xid": "b50",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "DAML-ATM and this is what you would need. Human Ref. and that would be what you would need",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_139",
            "content": "UNKNOWN, None, , More Transferred sentences on Amazon(few shot setting), .",
            "ntype": "ref",
            "meta": {
                "xid": "b51",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "More Transferred sentences on Amazon(few shot setting)",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_140",
            "content": "UNKNOWN, None, , Yelp (negative-to-positive) or (positive-to-negative) Input Ever since joes has changed hands it's gotten better and better, .",
            "ntype": "ref",
            "meta": {
                "xid": "b52",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Yelp (negative-to-positive) or (positive-to-negative) Input Ever since joes has changed hands it's gotten better and better",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_141",
            "content": "UNKNOWN, None, , DAML-ATM ever since joes has changed hands it's gotten worse and worse. Human Ref. ever since joes has changed hands it 's just gotten worse and worse . Input There is so much room in that part of the venue DAML-ATM there is not enough room in that part of the venue. Human Ref. there is definitely not enough room in that part of the venue, .",
            "ntype": "ref",
            "meta": {
                "xid": "b53",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "DAML-ATM ever since joes has changed hands it's gotten worse and worse. Human Ref. ever since joes has changed hands it 's just gotten worse and worse . Input There is so much room in that part of the venue DAML-ATM there is not enough room in that part of the venue. Human Ref. there is definitely not enough room in that part of the venue",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_142",
            "content": "UNKNOWN, None, , DAML-ATM it tasted watered down. Human Ref. so basically tasted watered down, .",
            "ntype": "ref",
            "meta": {
                "xid": "b54",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "DAML-ATM it tasted watered down. Human Ref. so basically tasted watered down",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_143",
            "content": ", Input definitely not disappointed that i could use my birthday gift ! DAML-ATM definitely disappointed that i could not use my birthday gift! Human Ref. definitely disappointed that i could not use my birthday gift ! Input but it probably doesn't suck too ! DAML-ATM but it probably does suck too! Human Ref. but it probably sucks too ! Input the service was quick and responsive DAML-ATM the service was slow and not responsive. Human Ref. we sit down and we got some really slow and lazy service, , DAML-ATM this pharmacy is really a shithole. Human Ref. i ca n't believe how inconsiderate this pharmacy is, .",
            "ntype": "ref",
            "meta": {
                "xid": "b55",
                "authors": [],
                "title": "Input definitely not disappointed that i could use my birthday gift ! DAML-ATM definitely disappointed that i could not use my birthday gift! Human Ref. definitely disappointed that i could not use my birthday gift ! Input but it probably doesn't suck too ! DAML-ATM but it probably does suck too! Human Ref. but it probably sucks too ! Input the service was quick and responsive DAML-ATM the service was slow and not responsive. Human Ref. we sit down and we got some really slow and lazy service",
                "pub_date": null,
                "pub_title": "DAML-ATM this pharmacy is really a shithole. Human Ref. i ca n't believe how inconsiderate this pharmacy is",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_144",
            "content": "UNKNOWN, None, , Modern-to-Shakespeare) Input How are you , my golden girl ? DAML-ATM How now, my golden girl? Human Ref. How now , my metal of India ? Input Goodbye . DAML-ATM Farewell. Human Ref. Farewell . Input Sir Toby , I've, .",
            "ntype": "ref",
            "meta": {
                "xid": "b56",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Modern-to-Shakespeare) Input How are you , my golden girl ? DAML-ATM How now, my golden girl? Human Ref. How now , my metal of India ? Input Goodbye . DAML-ATM Farewell. Human Ref. Farewell . Input Sir Toby , I've",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_145",
            "content": "Daml-Atm Sir Toby, Sir Toby , I must be round with you . Input Well , I can not tell how my difficult life has weathered my face , but I will never let those difficulties subdue my courage, , I must be frank with you. Human Ref, .",
            "ntype": "ref",
            "meta": {
                "xid": "b57",
                "authors": [
                    "Daml-Atm Sir Toby"
                ],
                "title": "Sir Toby , I must be round with you . Input Well , I can not tell how my difficult life has weathered my face , but I will never let those difficulties subdue my courage",
                "pub_date": null,
                "pub_title": "I must be frank with you. Human Ref",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_146",
            "content": "UNKNOWN, None, , I can not tell how my fortune hath weathered my face, but I will never let those fortunes subdue my valor, .",
            "ntype": "ref",
            "meta": {
                "xid": "b58",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "I can not tell how my fortune hath weathered my face, but I will never let those fortunes subdue my valor",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_147",
            "content": "UNKNOWN, None, , Well, I know not What counts harsh Fortune casts upon my face, But in my bosom shall she never come to make my heart her vassal. Input No , Pompey , I haven't had anything to drink, .",
            "ntype": "ref",
            "meta": {
                "xid": "b59",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Well, I know not What counts harsh Fortune casts upon my face, But in my bosom shall she never come to make my heart her vassal. Input No , Pompey , I haven't had anything to drink",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_148",
            "content": "Pompey Daml-Atm No, Input Tell me , good grandmother , is our father dead ? DAML-ATM Tell us, good grandam, is our father dead? Human Ref. Good grandam , tell us , is our father dead ? Input Tell us when you wish to get married , and may God give you joy . DAML-ATM Tell us when you shall marry, and God give thee joy. Human Ref. Name the day of marriage , and God give thee joy . Input Oh , yes , I'm sorry , uncle. , If you'll excuse me , your grace . DAML-ATM I cry you mercy , uncle. By your Grace's pardon . Human Ref. I cry you mercy , uncle. , By your Grace's pardon, , I have nothing to drink. Human Ref. No , Pompey , I have kept me from the cup, .",
            "ntype": "ref",
            "meta": {
                "xid": "b60",
                "authors": [
                    "Pompey Daml-Atm No"
                ],
                "title": "Input Tell me , good grandmother , is our father dead ? DAML-ATM Tell us, good grandam, is our father dead? Human Ref. Good grandam , tell us , is our father dead ? Input Tell us when you wish to get married , and may God give you joy . DAML-ATM Tell us when you shall marry, and God give thee joy. Human Ref. Name the day of marriage , and God give thee joy . Input Oh , yes , I'm sorry , uncle. , If you'll excuse me , your grace . DAML-ATM I cry you mercy , uncle. By your Grace's pardon . Human Ref. I cry you mercy , uncle. , By your Grace's pardon",
                "pub_date": null,
                "pub_title": "I have nothing to drink. Human Ref. No , Pompey , I have kept me from the cup",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_149",
            "content": "UNKNOWN, None, , Come in with me, and I will tell you my course. Human Ref. Go in with me , and I will tell you my drift . Input He'll bring a lot of money to the person who owns him , that's for sure . DAML-ATM He shall bring a great sum to the man that owns him, and that's certain. Human Ref. He shall pay for him that hath him, .",
            "ntype": "ref",
            "meta": {
                "xid": "b61",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Come in with me, and I will tell you my course. Human Ref. Go in with me , and I will tell you my drift . Input He'll bring a lot of money to the person who owns him , that's for sure . DAML-ATM He shall bring a great sum to the man that owns him, and that's certain. Human Ref. He shall pay for him that hath him",
                "pub": null
            }
        },
        {
            "ix": "185-ARR_v1_150",
            "content": "UNKNOWN, None, , More Transferred sentences on Shakespeare(few shot setting, .",
            "ntype": "ref",
            "meta": {
                "xid": "b62",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "More Transferred sentences on Shakespeare(few shot setting",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "185-ARR_v1_0@0",
            "content": "Low Resource Style Transfer via Domain Adaptive Meta Learning",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_0",
            "start": 0,
            "end": 60,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_2@0",
            "content": "Text style transfer (TST) without parallel data has achieved some practical success.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_2",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_2@1",
            "content": "However, most of the existing unsupervised text style transfer methods suffer from (i) requiring massive amounts of nonparallel data to guide transferring different text styles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_2",
            "start": 85,
            "end": 261,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_2@2",
            "content": "(ii) colossal performance degradation when fine-tuning the model in new domains.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_2",
            "start": 263,
            "end": 342,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_2@3",
            "content": "In this work, we propose DAML-ATM(Domain Adaptive Meta-Learning with Adversarial Transfer Model), which consists of two parts, DAML and ATM.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_2",
            "start": 344,
            "end": 483,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_2@4",
            "content": "DAML is a domain adaptive metalearning approach to refine general knowledge in multi-heterogeneous source domains, capable of adapting to new unseen domains with a small amount of data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_2",
            "start": 485,
            "end": 669,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_2@5",
            "content": "Moreover, we propose a new unsupervised TST approach Adversarial Transfer Model (ATM), composed of a sequence-to-sequence pre-trained language model and uses adversarial style training for better content preservation and style transfer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_2",
            "start": 671,
            "end": 906,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_2@6",
            "content": "Results on multi-domain datasets demonstrate that our approach generalizes well on unseen low-resource domains, achieving state-of-theart results against ten-strong baselines.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_2",
            "start": 908,
            "end": 1082,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_4@0",
            "content": "Text style transfer (TST) aims to change the style of the input text and keep its content unchanged, which has been applied successfully to text formalization (Jain et al., 2019) , text rewriting (Nikolov and Hahnloser, 2018) , personalized dialogue generation (Niu and Bansal, 2018) and other stylized text generation tasks (Gao et al., 2019;Cao et al., 2020;Syed et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_4",
            "start": 0,
            "end": 378,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_5@0",
            "content": "Text style transfer has been explored as a sequence-to-sequence learning task using parallel datasets (Jhamtani et al., 2017;Wang et al., 2020b;Pryzant et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_5",
            "start": 0,
            "end": 165,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_5@1",
            "content": "However, parallel datasets are difficult to obtain due to expensive manual annotation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_5",
            "start": 167,
            "end": 252,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_5@2",
            "content": "The recent surge of deep generative methods (Hu et al., 2017a; has spurred progress in text style transfer without parallel data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_5",
            "start": 254,
            "end": 382,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_5@3",
            "content": "However, these methods typically require large amounts of nonparallel data and not perform well in low-resource domain scenarios.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_5",
            "start": 384,
            "end": 512,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_6@0",
            "content": "One typical method is to resort to massive data from different domains, which has been studied as an effective solution to address the above data insufficiency issue (Glorot et al., 2011;Wang et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_6",
            "start": 0,
            "end": 205,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_6@1",
            "content": "However, directly leveraging large amounts of data from other domains for the TST task is problematic due to the differences in data distribution over different domains, as different domains usually use their domain-specific lexica (Li et al., 2019a).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_6",
            "start": 207,
            "end": 457,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_6@2",
            "content": "For instance, fine-tuning a TST model trained on a high-resource movie-related domain to a low-resource restaurant-related domain can get us unreasonable sentences like \"the food is dramatic.\" The sentiment word \"dramatic\" is weird to comment on the food but suitable for a movie.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_6",
            "start": 459,
            "end": 738,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_7@0",
            "content": "In this work, we tackle the problem of domain adaptation in the scenarios where the target domain data is scarce and misaligned with the distribution in the source domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_7",
            "start": 0,
            "end": 170,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_7@1",
            "content": "Recently, model-agnostic meta-learning (MAML) has received resurgence in the context of few-shot learning scenario Gu et al., 2018;Nooralahzadeh et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_7",
            "start": 172,
            "end": 330,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_7@2",
            "content": "Inspired by the essence of MAML (Finn et al., 2017), we propose a new meta-learning training strategy named domain adaptive meta-learning (DAML).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_7",
            "start": 332,
            "end": 476,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_7@3",
            "content": "Unlike MAML, DAML adopts a domain adaptive approach to construct meta tasks that would be more suitable to learn a robust and generalized initialization for low-resource TST domain adaption.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_7",
            "start": 478,
            "end": 667,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_8@0",
            "content": "With the DAML strategy, we design a TST model for each domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_8",
            "start": 0,
            "end": 61,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_8@1",
            "content": "Usually, if a TST model tries to decouple style information from the semantics of a text, it tends to produce content loss during style transfer (Hu et al., 2017b;Dai et al., 2019;Carlson et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_8",
            "start": 63,
            "end": 264,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_8@2",
            "content": "Thus, we propose a new style transfer model ATM, which is composed of a sequence-to-sequence pre-trained language model combined with adversarial style training for style transfer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_8",
            "start": 266,
            "end": 445,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_8@3",
            "content": "In this way, ATM can better preserve the content information without disentangling content and style in the latent space.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_8",
            "start": 447,
            "end": 567,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_9@0",
            "content": "Combining DAML and ATM, in this paper, we propose the method named DAML-ATM, which extends traditional meta-learning to a domain adaptive method combined with a sequence-to-sequence style transfer model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_9",
            "start": 0,
            "end": 202,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_9@1",
            "content": "DAML contains two alternating phases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_9",
            "start": 204,
            "end": 240,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_9@2",
            "content": "During the meta-training phase, a series of meta-tasks are constructed from a large pool of source domains for balanced absorption of general knowledge, resulting in a domain-specific temporary model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_9",
            "start": 242,
            "end": 441,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_9@3",
            "content": "In the meta validation stage, the temporary model is evaluated on the meta validation set to minimize domain differences and realize meta knowledge transfer across different domains.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_9",
            "start": 443,
            "end": 624,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_9@4",
            "content": "In ATM, a pre-training language model based TST model is used to improve text content retention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_9",
            "start": 626,
            "end": 721,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_9@5",
            "content": "Moreover, we propose a two-stage training algorithm to combine the DAML training method and ATM model better.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_9",
            "start": 723,
            "end": 831,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_10@0",
            "content": "In summary, the main contributions in this paper are three-fold: (i) We propose a new unsupervised TST model, which achieves SOTA performance without disentangling content and style latent representations compared to other models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_10",
            "start": 0,
            "end": 229,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_10@1",
            "content": "(ii) We extend the traditional meta-learning strategy to the domain adaptive meta transfer method, effectively alleviating the domain adaption problem in TST.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_10",
            "start": 231,
            "end": 388,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_11@0",
            "content": "(iii) We propose a two-stage training algorithm to train DAML-ATM, achieving state-of-the-art performance against multiple strong baselines.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_11",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_12@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_12",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_13@0",
            "content": "Text Style Transfer",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_13",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_14@0",
            "content": "Text style transfer based on deep learning has been extensively studied in recent years.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_14",
            "start": 0,
            "end": 87,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_14@1",
            "content": "A typical pattern is first to separate the latent space as content and style features, then adjust the style-related features and generate stylistic sentences through the decoder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_14",
            "start": 89,
            "end": 267,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_14@2",
            "content": "(Hu et al., 2017a;Fu et al., 2017;Li et al., 2019a)assume that appropriate style regularization can achieve the separation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_14",
            "start": 269,
            "end": 391,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_14@3",
            "content": "Style regularization may be implemented as an adversarial discriminator or style classifier in an automatic encoding process.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_14",
            "start": 393,
            "end": 517,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_14@4",
            "content": "However, these style transfer paradigms use large amounts of annotation data to train models for specific tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_14",
            "start": 519,
            "end": 630,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_14@5",
            "content": "If we already have a model for a similar task, it is unreasonable to need many data still to train the model from scratch.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_14",
            "start": 632,
            "end": 753,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_15@0",
            "content": "On the other hand, some of the previous work learned to do TST without manipulating the style of the generated sentence based on this learned latent space.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_15",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_15@1",
            "content": "(Dai et al., 2019)use the transformer architecture language model to introduce attention mechanism, but they do not make full use of the prior knowledge of sequence to sequence pre-trained language model, such as Bart (Lewis et al., 2019) and T5 (Raffel et al., 2019), which have made significant progress in text generation tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_15",
            "start": 156,
            "end": 486,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_15@2",
            "content": "In this paper, we proposed the DAML training method to solve the domain shift problem in TST and proposed a new TST model architecture named ATM, which makes no assumption about the latent representation of source sentence and takes the proven sequence-to-sequence pre-trained language model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_15",
            "start": 488,
            "end": 779,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_16@0",
            "content": "Domain adaptation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_16",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_17@0",
            "content": "Domain adaptation has been studied in various natural language processing tasks (Glorot et al., 2011;Qian and Yu, 2019;Wang et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_17",
            "start": 0,
            "end": 137,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_17@1",
            "content": "However, there is no recent work about domain adaptation for a TST, except DAST (Li et al., 2019a).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_17",
            "start": 139,
            "end": 237,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_17@2",
            "content": "DAST is a semi-supervised learning method that adapts domain vectors to adapt models learned from multiple source domains to a new target domain via domain discriminator.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_17",
            "start": 239,
            "end": 408,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_17@3",
            "content": "Different From DAST, we propose to combine meta-learning and adversarial networks to achieve similar domain adaption ability, and our model exceeds the performance of DAST without domain discriminator.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_17",
            "start": 410,
            "end": 610,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_17@4",
            "content": "Although there are some methods perform well in few shot data transfer (Riley et al., 2021;Krishna et al., 2021), these methods discuss completely new text style transfer, while we focus on the domain adaptation issue.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_17",
            "start": 612,
            "end": 829,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_18@0",
            "content": "Model-Agnostic Meta-Learning",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_18",
            "start": 0,
            "end": 27,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_19@0",
            "content": "Model-agnostic meta-learning (MAML) (Finn et al., 2017) provides a general method to adapt to parameters in different domains.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_19",
            "start": 0,
            "end": 125,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_19@1",
            "content": "MAML solves few-shot learning problems by learning a good parameter initialization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_19",
            "start": 127,
            "end": 209,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_19@2",
            "content": "During testing, such initialization can be fine-tuned through a few gradient steps, using a limited number of training examples in the target domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_19",
            "start": 211,
            "end": 359,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_19@3",
            "content": "Although there have been some researches (Qian and Yu, 2019;Wu et al., 2020) on MAML in natural language processing, it is still scarce compared to computer vision.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_19",
            "start": 361,
            "end": 524,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_19@4",
            "content": "Unlike the above research on classification under few-shot learning, our research focuses on text style transfer based on text generation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_19",
            "start": 526,
            "end": 663,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_19@5",
            "content": "In this paper, we seek a new meta-learning strategy combined with adversarial networks, which is more suitable for encouraging robust domain representation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_19",
            "start": 665,
            "end": 820,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_19@6",
            "content": "As far as we know, we are the first to adopt meta-learning in the domain adaptation problem of text style transfer tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_19",
            "start": 822,
            "end": 942,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_20@0",
            "content": "Methodology",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_20",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_21@0",
            "content": "In this section, we first define the problem of domain adaptive learning for TST.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_21",
            "start": 0,
            "end": 80,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_21@1",
            "content": "Then we describe our approach, DAML-ATM, in detail.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_21",
            "start": 82,
            "end": 132,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_22@0",
            "content": "Task Definition",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_22",
            "start": 0,
            "end": 14,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_23@0",
            "content": "Let D S = {D 1 , ..., D N } be N source domains in the training phase, where",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_23",
            "start": 0,
            "end": 75,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_24@0",
            "content": "D n (1 \u2264 n \u2264 N ) is the n-th source domain containing style-labelled non-parallel data D n = {(X i , l i )} Ln i=1",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_24",
            "start": 0,
            "end": 113,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_25@0",
            "content": ", where L n is the total number of sentences, X i denotes the i th source sentence, and l i denotes the corresponding style label, which belongs to a source style label set: l i \u2208 L S (e.g., positive/negative).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_25",
            "start": 0,
            "end": 209,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_25@1",
            "content": "Likewise, there are K target domains D T = {D 1 , ..., D K } which are unseen in D S .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_25",
            "start": 211,
            "end": 296,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_25@2",
            "content": "Our task is to transfer a sentence X i with style l i in the target domain to another sentence Y i sharing the same content while having a different style li from l i and domainspecific characteristics of the target domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_25",
            "start": 298,
            "end": 520,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_26@0",
            "content": "We propose a two-stage algorithm for domain adaptation in TST: pre-training learning strategy and domain adaptive meta-learning strategy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_26",
            "start": 0,
            "end": 136,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_26@1",
            "content": "In pre-training learning, our objective is to make the model more able to preserve content information and distinguish between different text styles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_26",
            "start": 138,
            "end": 286,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_26@2",
            "content": "In domain adaptive meta-learning, our objective is to learn a meta-knowledge learner for the sequenceto-sequence model by leveraging sufficient source data D s .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_26",
            "start": 288,
            "end": 448,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_26@3",
            "content": "Given a new unseen domain from D new , the new learning task of TST can be solved by finetuning the learned sequence-to-sequence model (domain-invariant parameters) with only a small number of training samples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_26",
            "start": 450,
            "end": 659,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_27@0",
            "content": "DAML-ATM Approach",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_27",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_28@0",
            "content": "Overview of DAML",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_28",
            "start": 0,
            "end": 15,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_29@0",
            "content": "Model-agnostic meta-learning can utilize a few training samples to train a model with good generalization ability.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_29",
            "start": 0,
            "end": 113,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_29@1",
            "content": "However, since it is based on the assumption that the meta tasks are from the same distribution (Figure 1, left), simply feeding all the sources data into it might get sub-optimal results (Chen and Zhu, 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_29",
            "start": 115,
            "end": 323,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_29@2",
            "content": "Therefore, we propose In the final evaluation phase, the metaknowledge learned by the sequence-to-sequence model can be applied to new domains.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_29",
            "start": 325,
            "end": 467,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_29@3",
            "content": "Given a new unseen domain D new = (T tr , T te ), the learned sequence-to-sequence model and the discriminator are fine-tuned on T tr and finally tested on T te .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_29",
            "start": 469,
            "end": 630,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_30@0",
            "content": "ATM Model",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_30",
            "start": 0,
            "end": 8,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_31@0",
            "content": "In this section, we give a brief introduction to our proposed model: ATM, which combines sequenceto-sequence pre-trained model with adversarial training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_31",
            "start": 0,
            "end": 152,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_31@1",
            "content": "(1) For the content preservation, we train the sequence-to-sequence model \u03b8 to reconstruct the original input sentence X with the original style label l. (2) For the style controlling, we train a discriminator network \u03b3 to assist the sequence-tosequence model network in better controlling the S2S-model To ease the explanation, we start with the sequence-to-sequence (S2S) model here.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_31",
            "start": 154,
            "end": 538,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_31@2",
            "content": "Explicitly, for an input sentence X = (x 1 , x 2 , ..., x n ) of length n, X \u2208 D, the S2S encoder Enc(X; \u03b8 E ) maps inputs to a sequence of continuous hidden representations H = (h 1 , h 2 , ..., h n ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_31",
            "start": 540,
            "end": 741,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_31@3",
            "content": "Then, the S2S decoder Dec(H; \u03b8 D ) estimates the conditional probability for the output sentence Y = (y 1 , y 2 , ..., y n ) by auto-regressively factorized its as:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_31",
            "start": 743,
            "end": 906,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_32@0",
            "content": "p \u03b8 (Y |X) = n t=1 p \u03b8 (y t |H, y 1 , ..., y t\u22121 ) (1)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_32",
            "start": 0,
            "end": 53,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_33@0",
            "content": "At each time step t, the probability of the next token is computed by a softmax classifier:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_33",
            "start": 0,
            "end": 90,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_34@0",
            "content": "p \u03b8 (y t |H, y 1 , ...., y t\u22121 )) = sof tmax(o t ) (2)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_34",
            "start": 0,
            "end": 53,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_35@0",
            "content": "where o t is logit vector outputted by decoder network.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_35",
            "start": 0,
            "end": 54,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_35@1",
            "content": "The standard S2S model without discriminator makes the output sequence Y the same as the input sequence X.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_35",
            "start": 56,
            "end": 161,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_36@0",
            "content": "Discriminator Model By teacher forcing, S2S tends to ignore the style labels and collapses to a reconstruction model, which might copy the input sentence, hence failing to transfer the style.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_36",
            "start": 0,
            "end": 190,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_36@1",
            "content": "Therefore, to make the model learn meaningful style information, we apply a style discriminator \u03b3 for the style regularization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_36",
            "start": 192,
            "end": 318,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_36@2",
            "content": "In summary, we use a style discriminator to provide the direction (gradient) for TST to conform to the target style.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_36",
            "start": 320,
            "end": 435,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_36@3",
            "content": "Our discriminator is a multi-layer perceptron with a sigmoid",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_36",
            "start": 437,
            "end": 496,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_37@0",
            "content": "First Stage: Pre-training Learning",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_37",
            "start": 0,
            "end": 33,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_38@0",
            "content": "In the first stage, we train the discriminator model to distinguish different text styles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_38",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_38@1",
            "content": "In this stage, the discriminator models are equivalent to a text classifier.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_38",
            "start": 91,
            "end": 166,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_38@2",
            "content": "Inspired by (Lewis et al., 2019), we feed the hidden states from the last layer of the decoder into the classifier instead of the gumblesoftmax trick (Jang et al., 2017) for gradient backpropagation, which is more stable and better than gumble-softmax(See Table 5).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_38",
            "start": 168,
            "end": 432,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_38@3",
            "content": "The loss function for the discriminator is simply the cross-entropy loss of the classification problem:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_38",
            "start": 434,
            "end": 536,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_39@0",
            "content": "L cls (\u03b3) = \u2212 E X i \u223cD S [logP (l i |X i , l i ; \u03b8, \u03b3)] (3)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_39",
            "start": 0,
            "end": 58,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_40@0",
            "content": "For the S2S model, we pre-train the S2S model to allow the generation model to learn to copy an input sentence X using teacher forcing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_40",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_40@1",
            "content": "The loss function of the sequence-to-sequence model minimizes the negative log-likelihood of the training data:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_40",
            "start": 136,
            "end": 246,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_41@0",
            "content": "L rec (\u03b8) = \u2212 E X i \u223cD S [logP (Y i |X i ; \u03b8)] (4)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_41",
            "start": 0,
            "end": 49,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_42@0",
            "content": "In summary, we train the sequence model and the style classification model separately on the source domain to learn content preservation and style discrimination in the first stage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_42",
            "start": 0,
            "end": 180,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_42@1",
            "content": "The first stage training procedure of the ATM is summarized in Algorithm 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_42",
            "start": 182,
            "end": 256,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_43@0",
            "content": "Second Stage: Domain Adaptive Meta Learning with Adversarial Training",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_43",
            "start": 0,
            "end": 68,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_44@0",
            "content": "After the first stage of training, the style classifier has learned how to distinguish between different text styles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_44",
            "start": 0,
            "end": 116,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_44@1",
            "content": "For style controlling, we adopt a method of adversarial training to avoid disentangling the content and style in the latent space.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_44",
            "start": 118,
            "end": 247,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_44@2",
            "content": "The discriminator model aims to minimize the negative loglikelihood of opposite style li when feeding to the sequence model sentence X i with the style label l i .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_44",
            "start": 249,
            "end": 411,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_44@3",
            "content": "In the second stage, we freeze the parameters of the discriminator.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_44",
            "start": 413,
            "end": 479,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_44@4",
            "content": "Therefore, style loss only works on the S2S model \u03b8, which forces the S2S model \u03b8 to generate opposite styles of sentences:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_44",
            "start": 481,
            "end": 603,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_45@0",
            "content": "L style (\u03b8) = \u2212 E X i \u223cD [logP ( li |X i , l i ; \u03b8, \u03b3)] (5)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_45",
            "start": 0,
            "end": 58,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_46@0",
            "content": "In the second stage, we use the DAML algorithm for domain adaptive TST, so the text reconstruction loss and the style discriminator loss are calculated over the meta-training samples in task T i from D tr .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_46",
            "start": 0,
            "end": 205,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_46@1",
            "content": "These two losses can be written as",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_46",
            "start": 207,
            "end": 240,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_47@0",
            "content": "L rec T i (\u03b8) = \u2212 E X i \u223cT i [logP (Y i |X i ; \u03b8)] L style T i (\u03b8) = \u2212 E X i \u223cT i [logP ( li |X i , l i ; \u03b8, \u03b3))(6)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_47",
            "start": 0,
            "end": 114,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_48@0",
            "content": "We add different prefixes to the input in the second stage, which allows the S2S model to perceive different TST tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_48",
            "start": 0,
            "end": 118,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_48@1",
            "content": "The second stage of the algorithm is called domain adaptive meta-strategy, which consists of two core phases: a meta-training phase and a meta-validation phase, as shown in Figure 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_48",
            "start": 120,
            "end": 301,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_49@0",
            "content": "In the meta-training phase, our objective is to learn different domain-specific temporary models for each domain that are capable of learning the general knowledge of each domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_49",
            "start": 0,
            "end": 178,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_49@1",
            "content": "Inspired by feature-critic networks (Li et al., 2019b), we use a similar manner to adapt the parameters of the domain-specific temporary model:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_49",
            "start": 180,
            "end": 322,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_50@0",
            "content": "\u03b8 old i = \u03b8 i\u22121 \u2212 \u03b1\u2207\u03b8 i\u22121 L rec T i (\u03b8 i\u22121 , \u03b3 i\u22121 ) \u03b8 new i = \u03b8 old i\u22121 \u2212 \u03b1\u2207\u03b8 i\u22121 L style T i (\u03b8 i\u22121 , \u03b3 i\u22121 ) (7",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_50",
            "start": 0,
            "end": 113,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_51@0",
            "content": ")",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_51",
            "start": 0,
            "end": 0,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_52@0",
            "content": "where i is the adaptation step in the inner loop, and \u03b1 is the learning rate of the internal optimization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_52",
            "start": 0,
            "end": 105,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_52@1",
            "content": "At each adaptation step, the gradients are calculated with respect to the parameters from the previous step. ) in the meta-training domains D tr .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_52",
            "start": 107,
            "end": 252,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_52@2",
            "content": "The meta-validation phase tries to minimize the distribution divergence between the source domains D tr and simulated target domains D val using the learned temporary model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_52",
            "start": 254,
            "end": 426,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_52@3",
            "content": "In the meta-validation phase, each temporary model is calculated on the meta-validation domain D val to get meta validation losses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_52",
            "start": 428,
            "end": 558,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_53@0",
            "content": "\u03b8 old i = \u03b8i\u22121 \u2212 \u03b1\u2207\u03b8i\u22121L tr T i (\u03b8i\u22121, \u03b3i\u22121) 13: \u03b8 new i = \u03b8 old i\u22121 \u2212 \u03b1\u2207\u03b8i\u22121L style T i (\u03b8i\u22121, \u03b3i\u2212",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_53",
            "start": 0,
            "end": 98,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_54@0",
            "content": "L val T j = L rec T j (\u03b8 old i , \u03b3 0 ) + L style T j (\u03b8 new i , \u03b3 0 ) (8)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_54",
            "start": 0,
            "end": 72,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_55@0",
            "content": "Thus, the base model \u03b8 is updated by gradient descent",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_55",
            "start": 0,
            "end": 52,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_56@0",
            "content": "\u03b8 0 = \u03b8 0 \u2212 \u03b2\u2207\u03b8 0 L val T j (9)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_56",
            "start": 0,
            "end": 30,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_57@0",
            "content": "where \u03b2 is the meta-learning rate.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_57",
            "start": 0,
            "end": 33,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_57@1",
            "content": "Unlike the ordinary gradient descent process, the update mechanism of Eq. ( 9) involves updating one gradient by another gradient (w.r.t. the parameters of the temporary model).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_57",
            "start": 35,
            "end": 211,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_57@2",
            "content": "This process requires a second-order optimization partial derivative.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_57",
            "start": 213,
            "end": 281,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_58@0",
            "content": "Final Evaluation Phase of DAML-ATM",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_58",
            "start": 0,
            "end": 33,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_59@0",
            "content": "In the final evaluation phase, we first initialize the model with the parameters learned during the above algorithm 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_59",
            "start": 0,
            "end": 117,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_59@1",
            "content": "Then, the model takes input as a new adaptation task T , which consists of a small indomain data S tr for fine-tuning the model and a test set S te for testing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_59",
            "start": 119,
            "end": 278,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_59@2",
            "content": "The procedure is summarized in Algorithm 3. (Note that the discriminator is not needed for inference.)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_59",
            "start": 280,
            "end": 381,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_60@0",
            "content": "Algorithm",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_60",
            "start": 0,
            "end": 8,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_61@0",
            "content": "Experiment",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_61",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_62@0",
            "content": "In this section, we first detail the experimental setups.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_62",
            "start": 0,
            "end": 56,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_62@1",
            "content": "Then, we present our experimental results over multiple target domains.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_62",
            "start": 58,
            "end": 128,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_63@0",
            "content": "Datasets and Experimental Setups",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_63",
            "start": 0,
            "end": 31,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_64@0",
            "content": "In this experiment, we use the following four datasets from different domains: (i) IMDB movie review corpus (Diao et al., 2014).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_64",
            "start": 0,
            "end": 127,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_64@1",
            "content": "(ii) Yelp restaurant review dataset .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_64",
            "start": 129,
            "end": 165,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_64@2",
            "content": "(iii) Amazon product review dataset .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_64",
            "start": 167,
            "end": 203,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_64@3",
            "content": "(iv) YAHOO! Answers dataset (Li et al., 2019a), the amazon and yelp test sets each have 1k human annotations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_64",
            "start": 205,
            "end": 313,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_64@4",
            "content": "The statistics of these corpora are summarized in Table 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_64",
            "start": 314,
            "end": 371,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_65@0",
            "content": "For the S2S model, we take the T5 base model (Raffel et al., 2019) (220MB) for our experiments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_65",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_65@1",
            "content": "For style discriminator, we use 4-layer fully connected neural networks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_65",
            "start": 96,
            "end": 167,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_65@2",
            "content": "We train our framework using the Adam optimizer (Kingma and Ba, 2014)with the initial learning rate 1e-5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_65",
            "start": 169,
            "end": 273,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_65@3",
            "content": "The epoch is set to 50 for both stage 1 and stage 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_65",
            "start": 275,
            "end": 326,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_65@4",
            "content": "The inner learning rate \u03b1 is 0.0001, and the outer learning rate \u03b2 is 0.001.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_65",
            "start": 328,
            "end": 403,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_65@5",
            "content": "Following (Shankar et al., 2018;, we use the leave-one-out evaluation method by picking a domain as the target domain D new for the final evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_65",
            "start": 405,
            "end": 553,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_65@6",
            "content": "For each iteration of the training phase, two source domains are randomly selected as the meta-training domain D tr and the remaining domains as the meta-validation domain D val .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_65",
            "start": 555,
            "end": 733,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_66@0",
            "content": "In order to evaluate the model performance, we use three famous and widely adopted automatic metrics following previous work (Li et al., 2019a;Fu et al., 2017;Hu et al., 2017a) and a human metric.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_66",
            "start": 0,
            "end": 195,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_66@1",
            "content": "BLEU verifies whether the generated sentences retain the original content (Papineni et al., 2002).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_66",
            "start": 197,
            "end": 294,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_66@2",
            "content": "While IMDB and Amazon have no manual references, we compute the BLEU scores w.r.t the input sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_66",
            "start": 296,
            "end": 397,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_66@3",
            "content": "Style Control (S-Acc) measures the style accuracy of the transferred sentences with a style classifier that is pre-trained on the datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_66",
            "start": 399,
            "end": 537,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_66@4",
            "content": "Domain Control (D-Acc) verifies whether the generated sentences have the characteristics of the target domain with a pre-trained domain classifier to measure the percentage of generated sentences belonging to the target domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_66",
            "start": 539,
            "end": 765,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_66@5",
            "content": "Human Evaluation Following , We randomly sampled 100 sentences generated on the target domain and distributed a questionnaire at Amazon Mechanical Turk asking each worker to rank the content retention (0 to 5), style transfer(0 to 5 ) and fluency(0 to 5): human score = Average( score style + score content + score f luency ), human score \u2208 [0, 100] .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_66",
            "start": 767,
            "end": 1117,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_66@6",
            "content": "Five workers were recruited for human evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_66",
            "start": 1119,
            "end": 1167,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_66@7",
            "content": "The results of the other metrics are shown in the appendix.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_66",
            "start": 1169,
            "end": 1227,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_67@0",
            "content": "Baselines",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_67",
            "start": 0,
            "end": 8,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_68@0",
            "content": "In our experiments, for ATM model, we adopt five state-of-the-art TST models for comparison: Table 2: Evaluation results on restaurant domain(Yelp).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_68",
            "start": 0,
            "end": 147,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_68@1",
            "content": "The restaurant domain is used as the target domain and the other three domains as the source domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_68",
            "start": 149,
            "end": 248,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_68@2",
            "content": "G-score is the geometric mean of S-Acc and BLEU.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_68",
            "start": 250,
            "end": 297,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_69@0",
            "content": "Yelp(negative-to-positive) Yelp(positive-to-negative) Input there chips are ok , but their salsa is really bland.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_69",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_69@1",
            "content": "love their food and their passion.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_69",
            "start": 114,
            "end": 147,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_69@2",
            "content": "Joint-Training there are good , but their food is really good, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_69",
            "start": 149,
            "end": 212,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_69@3",
            "content": "laughable their food and bad food.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_69",
            "start": 214,
            "end": 247,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_69@4",
            "content": "Fine-Tuning there chips act very well.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_69",
            "start": 249,
            "end": 286,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_69@5",
            "content": "their food is hard to use.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_69",
            "start": 288,
            "end": 313,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_69@6",
            "content": "D-Shift there are usually dramatic exhibits.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_69",
            "start": 315,
            "end": 358,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_69@7",
            "content": "my husband and toilet smelled.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_69",
            "start": 360,
            "end": 389,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_69@8",
            "content": "MAML there chips are bad,but there salsa is really good.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_69",
            "start": 391,
            "end": 446,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_69@9",
            "content": "hate their food and their passion DAML-ATM(ours) there chips are surprised, and their salsa is really nice.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_69",
            "start": 448,
            "end": 554,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_69@10",
            "content": "hard to swallow food and serious discrespect.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_69",
            "start": 556,
            "end": 600,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_69@11",
            "content": "Table 4: Results on each of the remaining domains treated as target domain,every target domains using 1% data for fine-tuning, base model is AMT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_69",
            "start": 602,
            "end": 746,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_70@0",
            "content": "CrossAlign (Shen et al., 2017), ControlGen (Hu et al., 2017a), DAST (Li et al., 2019a), Cat-Gen (Wang et al., 2020a) and FGIM (Wang et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_70",
            "start": 0,
            "end": 145,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_70@1",
            "content": "They are jointly trained on the source domains and fine-tuned on the target domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_70",
            "start": 147,
            "end": 229,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_71@0",
            "content": "To well analyze our training method DAML, following , we also use five simple and effective domain adaptation settings with Con-trolGen (Hu et al., 2017a) (5) MAML method uses classical model agnostic meta-learning algorithm (Finn et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_71",
            "start": 0,
            "end": 244,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_72@0",
            "content": "Results and Analysis",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_72",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_73@0",
            "content": "For DAML-ATM, we first choose restaurant as the target domain and the other three as the source domains for observation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_73",
            "start": 0,
            "end": 119,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_73@1",
            "content": "of different methods and models under both the full-data and few-shot settings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_73",
            "start": 121,
            "end": 199,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_73@2",
            "content": "From this table, we can see that DAML-ATM outperforms all baselines in terms of S-Acc, BLEU, D-Acc and human evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_73",
            "start": 201,
            "end": 320,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_73@3",
            "content": "We attribute this to the fact that DAML-ATM explicitly simulates the domain shift during training via DAML, which helps adapt to the new target domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_73",
            "start": 322,
            "end": 472,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_73@4",
            "content": "We can also see that in the case of a few-shot setting, the results of Fine-tuning and Joint training are even worse than In-domain and DAML.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_73",
            "start": 474,
            "end": 614,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_73@5",
            "content": "The reason may be that the data size of the source domain is much larger than the target domain so that the model tends to remember the characteristics of the source domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_73",
            "start": 616,
            "end": 788,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_73@6",
            "content": "MAML achieves good performance in most metrics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_73",
            "start": 790,
            "end": 836,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_73@7",
            "content": "However, it does not balance meta-tasks across different source domains, performing poorly on D-acc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_73",
            "start": 838,
            "end": 937,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_74@0",
            "content": "Further, to verify the robustness of our method under the low-resource setting, we separately select the other three domains as the target domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_74",
            "start": 0,
            "end": 145,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_74@1",
            "content": "As shown in Table 4, our approach has achieved good performance on different target domains.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_74",
            "start": 147,
            "end": 238,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_75@0",
            "content": "We also provide some examples in Table 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_75",
            "start": 0,
            "end": 40,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_75@1",
            "content": "From the example, we can see intuitively that D-shift and Fine-tuning will lead to the misuse of domainspecific words due to lack of target domain information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_75",
            "start": 42,
            "end": 200,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_75@2",
            "content": "In addition, compared with Joint-training, the sentences generated by DAML-ATM are more consistent with the human reference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_75",
            "start": 202,
            "end": 325,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_75@3",
            "content": "Compared to MAML, DAML generates sentences that are more diverse and vivid due to the more balanced absorption of information from multiple domains.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_75",
            "start": 327,
            "end": 474,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_75@4",
            "content": "Figure 4 shows the system performance positively correlates with the amount of training data available in the target domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_75",
            "start": 476,
            "end": 599,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_75@5",
            "content": "To visualize how well DAML-ATM performs on the new unseen domain, we use t-SNE (Van der Maaten and Hinton, 2008) plots to analyze the degree of separation between the source domain sentences and the generated target domain sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_75",
            "start": 601,
            "end": 833,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_75@6",
            "content": "Figure 5 shows that as the training epoch increases, the sentences generated by DAML-ATM in the target domain are completely separated from the source domain in the latent space.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_75",
            "start": 835,
            "end": 1012,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_76@0",
            "content": "Ablation Study",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_76",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_77@0",
            "content": "To study the impact of different components on the overall performance, we further did an ablation study for our model, and the results are shown in Table 5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_77",
            "start": 0,
            "end": 156,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_77@1",
            "content": "After we disabled the reconstruction loss, our model failed to learn meaningful outputs and only learned to generate a word for any combination of input sentences and styles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_77",
            "start": 158,
            "end": 331,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_77@2",
            "content": "Then, when the discriminator loss is not used, the model degrades rapidly, simply copying the original sentence without any style modification.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_77",
            "start": 333,
            "end": 475,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_77@3",
            "content": "After not using the pre-training language model weights, the model's performance is reduced in the metric of content preservation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_77",
            "start": 477,
            "end": 606,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_77@4",
            "content": "When using gumble-softmax instead of hidden states for gradient descent, the model performs poorly in style accuracy because of the instability of gumble-softmax.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_77",
            "start": 608,
            "end": 769,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_77@5",
            "content": "In summary, each factor plays an essential role in the DAML-ATM training stage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_77",
            "start": 771,
            "end": 849,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_78@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_78",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_79@0",
            "content": "In this paper, we propose DAML-ATM, a novel training strategy combined with a new TST model for domain adaptation, which can be easily adapted to new domains with few shot data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_79",
            "start": 0,
            "end": 176,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_79@1",
            "content": "On four popular TST benchmarks, we found significant improvements against multiple baselines, verifying the effectiveness of our method.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_79",
            "start": 178,
            "end": 313,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_79@2",
            "content": "We explore extending this approach for other low resource NLP tasks in future work.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_79",
            "start": 315,
            "end": 397,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_80@0",
            "content": "A.1 More Details on Experiment Setups",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_80",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_81@0",
            "content": "Our model is initialized from T5 and Bart Raffel et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_81",
            "start": 0,
            "end": 62,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_81@1",
            "content": "Specifically, the encoder and decoder are all 12-layer transformers with 16 attention heads, hidden size 1,024 and feedforward filter size 4,096, which amounts to 406M trainable parameters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_81",
            "start": 64,
            "end": 252,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_81@2",
            "content": "We train our framework using the Adam optimizer (Kingma and Ba, 2014)with the initial learning rate 1e-5, and we employ a linear schedule for the learning rate, all models are trained on 8 RTX 3090 GPUs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_81",
            "start": 254,
            "end": 456,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_82@0",
            "content": "For the results generated by each method, following (Krishna et al., 2020), we randomly selected 100 sentences to be placed in the Amazon Mechanical Turk 1 questionnaire.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_82",
            "start": 0,
            "end": 169,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_82@1",
            "content": "We pay our workers 5 cents per sentence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_82",
            "start": 171,
            "end": 210,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_82@2",
            "content": "As shown in Figure 6, the questionnaire asked to judge the generated sentences on three dimensions: strength of style transfer, degree of content retention, and text fluency.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_82",
            "start": 212,
            "end": 385,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_82@3",
            "content": "To minimize the impact of spamming, we require each worker to be a native English speaker with a 95% or higher approval rate and a minimum of 1,000 hits.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_82",
            "start": 387,
            "end": 539,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_83@0",
            "content": "To verify that the general S2S models work well with our algorithm, we use bart (Lewis et al., 2019) as the S2S base model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_83",
            "start": 0,
            "end": 122,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_83@1",
            "content": "For the robustness of the experiment, we add a new metric J-(a,c,f) (Krishna et al., 2020) As can be seen from Table 6, our approach can be combined with other general pre-trained language models and performs well, proving our method's generality.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_83",
            "start": 124,
            "end": 370,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_83@2",
            "content": "Furthermore, as we can visually see from Table 7, our model also performs well on the J-(a,c,f) metric, which indicates that our model generates sentences in a specific style while having the right target style, preserving content, and being fluent.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_83",
            "start": 372,
            "end": 620,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_84@0",
            "content": "To demonstrate the robustness of our algorithm, we trained our algorithm on the Shakespeare dataset (Xu et al., 2012).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_84",
            "start": 0,
            "end": 117,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_84@1",
            "content": "We choose three of these plays, Hamlet, Macbeth, and Othello, as different domains.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_84",
            "start": 119,
            "end": 201,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_84@2",
            "content": "The results are shown in Table 7: Evaluation results on restaurant domain(Yelp).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_84",
            "start": 203,
            "end": 282,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_85@0",
            "content": "The restaurant domain is used as the target domain and the other three domains as the source domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_85",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_85@1",
            "content": "G-score is the geometric mean of S-Acc and BLEU.The evaluation metrics is J-(a,c,f) Table 11.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_85",
            "start": 101,
            "end": 193,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_86@0",
            "content": "As shown in Table 8, our approach achieves good results on the more difficult Shakespearean style transfer, which indicates that our algorithm generalizes nicely to other complex style transfer tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_86",
            "start": 0,
            "end": 199,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_87@0",
            "content": "To demonstrate more examples of generation to verify the effectiveness of the model, we selected 10 generated sentences from amazon and yelp each, as shown in Table 9 and Table 10 Table 8: Results of Shakespeare-style generation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_87",
            "start": 0,
            "end": 228,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_87@1",
            "content": "We choose one as the target domain and the others as the source domain, every target domain uses 1% data for fine-tuning, and the base model is ATM.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_87",
            "start": 230,
            "end": 377,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_88@0",
            "content": "UNKNOWN, None, 2020, Expertise style transfer: A new task towards better communication between experts and laymen, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_88",
            "start": 0,
            "end": 115,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_89@0",
            "content": "Keith Carlson, Allen Riddell, Daniel Rockmore, Evaluating prose style transfer with the bible, 2018, Royal Society open science, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_89",
            "start": 0,
            "end": 129,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_90@0",
            "content": "UNKNOWN, None, 2020, St\u0398 2: Smalldata text style transfer via multi-task meta-learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_90",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_91@0",
            "content": "UNKNOWN, None, 2019, Style transformer: Unpaired text style transfer without disentangled latent representation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_91",
            "start": 0,
            "end": 113,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_92@0",
            "content": "Qiming Diao, Minghui Qiu,  Chao-Yuan, Alexander Wu, Jing Smola, Chong Jiang,  Wang, Jointly modeling aspects, ratings and sentiments for movie recommendation (jmars), 2014, Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_92",
            "start": 0,
            "end": 273,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_93@0",
            "content": "UNKNOWN, None, 2017, Model-agnostic meta-learning for fast adaptation of deep networks, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_93",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_94@0",
            "content": "UNKNOWN, None, 2017, Style transfer in text: Exploration and evaluation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_94",
            "start": 0,
            "end": 73,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_95@0",
            "content": "UNKNOWN, None, 2019, Structuring latent spaces for stylized response generation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_95",
            "start": 0,
            "end": 81,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_96@0",
            "content": "Xavier Glorot, Antoine Bordes, Yoshua Bengio, Domain adaptation for large-scale sentiment classification: A deep learning approach, 2011, ICML, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_96",
            "start": 0,
            "end": 144,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_97@0",
            "content": "UNKNOWN, None, 2018, Meta-learning for lowresource neural machine translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_97",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_98@0",
            "content": "UNKNOWN, None, 2017, , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_98",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_99@0",
            "content": "Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan Salakhutdinov, Eric Xing, Toward controlled generation of text, 2017, International Conference on Machine Learning, PMLR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_99",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_100@0",
            "content": "Parag Jain, Abhijit Mishra, Amar Prakash Azad, Karthik Sankaranarayanan, Unsupervised controllable text formalization, 2019, Proceedings of the AAAI Conference on Artificial Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_100",
            "start": 0,
            "end": 188,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_101@0",
            "content": "UNKNOWN, None, 2017, Categorical reparameterization with gumbel-softmax, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_101",
            "start": 0,
            "end": 73,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_102@0",
            "content": "UNKNOWN, None, 2017, Shakespearizing modern language using copy-enriched sequence-to-sequence models, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_102",
            "start": 0,
            "end": 102,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_103@0",
            "content": "UNKNOWN, None, 2014, Adam: A method for stochastic optimization, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_103",
            "start": 0,
            "end": 65,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_104@0",
            "content": "UNKNOWN, None, , Bidisha Samanta, and Partha Talukdar. 2021. Fewshot controllable style transfer for low-resource settings: A study in indian languages, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_104",
            "start": 0,
            "end": 153,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_105@0",
            "content": "UNKNOWN, None, 2020, Reformulating unsupervised style transfer as paraphrase generation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_105",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_106@0",
            "content": "UNKNOWN, None, 2019, Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_106",
            "start": 0,
            "end": 130,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_107@0",
            "content": "UNKNOWN, None, 2019, Domain adaptive text style transfer, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_107",
            "start": 0,
            "end": 58,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_108@0",
            "content": "Jing Li, Shuo Shang, Ling Shao, Metaner: Named entity recognition with meta-learning, 2020, Proceedings of The Web Conference 2020, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_108",
            "start": 0,
            "end": 132,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_109@0",
            "content": "UNKNOWN, None, 2018, Delete, retrieve, generate: A simple approach to sentiment and style transfer, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_109",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_110@0",
            "content": "UNKNOWN, None, 2019, Feature-critic networks for heterogeneous domain generalization, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_110",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_111@0",
            "content": "UNKNOWN, None, 2019, Personalizing dialogue agents via meta-learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_111",
            "start": 0,
            "end": 70,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_112@0",
            "content": "Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer, Multilingual denoising pre-training for neural machine translation, 2020, Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_112",
            "start": 0,
            "end": 249,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_113@0",
            "content": "Andrea Madotto, Zhaojiang Lin, Chien-Sheng Wu, Pascale Fung, Personalizing dialogue agents via meta-learning, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_113",
            "start": 0,
            "end": 205,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_114@0",
            "content": "UNKNOWN, None, 2018, Large-scale hierarchical alignment for data-driven text rewriting, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_114",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_115@0",
            "content": "UNKNOWN, None, 2018, Polite dialogue generation without parallel data. Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_115",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_116@0",
            "content": "UNKNOWN, None, 2020, Zero-shot cross-lingual transfer with meta learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_116",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_117@0",
            "content": "Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, Bleu: a method for automatic evaluation of machine translation, 2002, Proceedings of the 40th annual meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_117",
            "start": 0,
            "end": 216,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_118@0",
            "content": "Reid Pryzant, Richard Martinez, Nathan Dass, Sadao Kurohashi, Dan Jurafsky, Diyi Yang, Automatically neutralizing subjective bias in text, 2020, Proceedings of the aaai conference on artificial intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_118",
            "start": 0,
            "end": 208,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_119@0",
            "content": "UNKNOWN, None, 2019, Domain adaptive dialog generation via meta learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_119",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_120@0",
            "content": "UNKNOWN, None, 2019, Exploring the limits of transfer learning with a unified text-to-text transformer, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_120",
            "start": 0,
            "end": 104,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_121@0",
            "content": "UNKNOWN, None, , David Uthus, and Zarana Parekh. 2021. Textsettr: Few-shot text style extraction and tunable targeted restyling, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_121",
            "start": 0,
            "end": 129,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_122@0",
            "content": "UNKNOWN, None, 2018, Generalizing across domains via cross-gradient training, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_122",
            "start": 0,
            "end": 78,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_123@0",
            "content": "Tianxiao Shen, Tao Lei, Regina Barzilay, Tommi Jaakkola, Style transfer from non-parallel text by cross-alignment, 2017, Advances in neural information processing systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_123",
            "start": 0,
            "end": 172,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_124@0",
            "content": "Bakhtiyar Syed, Gaurav Verma, Adapting language models for non-parallel author-stylized rewriting, 2020, AAAI, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_124",
            "start": 0,
            "end": 111,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_125@0",
            "content": "Laurens Van Der Maaten, Geoffrey Hinton, Visualizing data using t-sne, 2008, Journal of machine learning research, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_125",
            "start": 0,
            "end": 115,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_126@0",
            "content": "UNKNOWN, None, 2019, Controllable unsupervised text attribute transfer via editing entangled latent representation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_126",
            "start": 0,
            "end": 116,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_127@0",
            "content": "Rui Wang, Masao Utiyama, Lemao Liu, Kehai Chen, Eiichiro Sumita, Instance weighting for neural machine translation domain adaptation, 2017, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_127",
            "start": 0,
            "end": 228,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_128@0",
            "content": "UNKNOWN, None, , Cat-gen: Improving robustness in nlp models via controlled adversarial text generation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_128",
            "start": 0,
            "end": 105,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_129@0",
            "content": "Yunli Wang, Yu Wu, Lili Mou, Zhoujun Li, Wenhan Chao, Formality style transfer with shared latent space, 2020, Proceedings of the 28th International Conference on Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_129",
            "start": 0,
            "end": 190,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_130@0",
            "content": "Qianhui Wu, Zijia Lin, Guoxin Wang, Hui Chen, F B\u00f6rje, Biqing Karlsson, Chin-Yew Huang,  Lin, Enhanced meta-learning for cross-lingual named entity recognition with minimal resources, 2020, Proceedings of the AAAI Conference on Artificial Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_130",
            "start": 0,
            "end": 253,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_131@0",
            "content": "Wei Xu, Alan Ritter, Bill Dolan, Ralph Grishman, Colin Cherry, Paraphrasing for style, 2012, COL-ING, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_131",
            "start": 0,
            "end": 102,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_132@0",
            "content": "UNKNOWN, None, 2017, Adversarially regularized autoencoders, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_132",
            "start": 0,
            "end": 61,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_133@0",
            "content": "UNKNOWN, None, , Amazon (negative-to-positive) or (positive-to-negative) Input anker, don't like it, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_133",
            "start": 0,
            "end": 101,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_134@0",
            "content": ", Human Ref. anker is a fine product though i d never heard of it. Input but the back side looks terrible as well. cook sausages , hot dogs and hamburgers in it as well, , DAML-ATM anker is a great product, i like it, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_134",
            "start": 0,
            "end": 218,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_135@0",
            "content": ", Input synching is not too hard , with no passwords or codes required DAML-ATM synching is easy, with no passwords or codes required. Human Ref. synching is simple , with no passwords or codes required . Input they were flimsy DAML-ATM they were a bit flimsy, but they were ok. Human Ref. was concerned for the price that these measuring cups would be flimsy, , DAML-ATM i will not buy hamilton beach products again. Human Ref. i will never buy hamilton beach products again, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_135",
            "start": 0,
            "end": 477,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_136@0",
            "content": "UNKNOWN, None, , DAML-ATM it moves air very fast. Human Ref. it moves plenty of air , oscillating between two rooms . Input very ugly unit, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_136",
            "start": 0,
            "end": 140,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_137@0",
            "content": ", Human Ref. very nice unit , easy to assemble and operate . Input i would recommend this money case DAML-ATM i would not recommend this money case to anyone. Human Ref. i would never recommend this terrible waste of money case, , DAML-ATM very nice unit, easy to assemble and operate, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_137",
            "start": 0,
            "end": 286,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_138@0",
            "content": "UNKNOWN, None, , DAML-ATM and this is what you would need. Human Ref. and that would be what you would need, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_138",
            "start": 0,
            "end": 109,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_139@0",
            "content": "UNKNOWN, None, , More Transferred sentences on Amazon(few shot setting), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_139",
            "start": 0,
            "end": 73,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_140@0",
            "content": "UNKNOWN, None, , Yelp (negative-to-positive) or (positive-to-negative) Input Ever since joes has changed hands it's gotten better and better, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_140",
            "start": 0,
            "end": 142,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_141@0",
            "content": "UNKNOWN, None, , DAML-ATM ever since joes has changed hands it's gotten worse and worse. Human Ref. ever since joes has changed hands it 's just gotten worse and worse . Input There is so much room in that part of the venue DAML-ATM there is not enough room in that part of the venue. Human Ref. there is definitely not enough room in that part of the venue, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_141",
            "start": 0,
            "end": 359,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_142@0",
            "content": "UNKNOWN, None, , DAML-ATM it tasted watered down. Human Ref. so basically tasted watered down, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_142",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_143@0",
            "content": ", Input definitely not disappointed that i could use my birthday gift ! DAML-ATM definitely disappointed that i could not use my birthday gift! Human Ref. definitely disappointed that i could not use my birthday gift ! Input but it probably doesn't suck too ! DAML-ATM but it probably does suck too! Human Ref. but it probably sucks too ! Input the service was quick and responsive DAML-ATM the service was slow and not responsive. Human Ref. we sit down and we got some really slow and lazy service, , DAML-ATM this pharmacy is really a shithole. Human Ref. i ca n't believe how inconsiderate this pharmacy is, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_143",
            "start": 0,
            "end": 612,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_144@0",
            "content": "UNKNOWN, None, , Modern-to-Shakespeare) Input How are you , my golden girl ? DAML-ATM How now, my golden girl? Human Ref. How now , my metal of India ? Input Goodbye . DAML-ATM Farewell. Human Ref. Farewell . Input Sir Toby , I've, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_144",
            "start": 0,
            "end": 232,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_145@0",
            "content": "Daml-Atm Sir Toby, Sir Toby , I must be round with you . Input Well , I can not tell how my difficult life has weathered my face , but I will never let those difficulties subdue my courage, , I must be frank with you. Human Ref, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_145",
            "start": 0,
            "end": 229,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_146@0",
            "content": "UNKNOWN, None, , I can not tell how my fortune hath weathered my face, but I will never let those fortunes subdue my valor, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_146",
            "start": 0,
            "end": 124,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_147@0",
            "content": "UNKNOWN, None, , Well, I know not What counts harsh Fortune casts upon my face, But in my bosom shall she never come to make my heart her vassal. Input No , Pompey , I haven't had anything to drink, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_147",
            "start": 0,
            "end": 199,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_148@0",
            "content": "Pompey Daml-Atm No, Input Tell me , good grandmother , is our father dead ? DAML-ATM Tell us, good grandam, is our father dead? Human Ref. Good grandam , tell us , is our father dead ? Input Tell us when you wish to get married , and may God give you joy . DAML-ATM Tell us when you shall marry, and God give thee joy. Human Ref. Name the day of marriage , and God give thee joy . Input Oh , yes , I'm sorry , uncle. , If you'll excuse me , your grace . DAML-ATM I cry you mercy , uncle. By your Grace's pardon . Human Ref. I cry you mercy , uncle. , By your Grace's pardon, , I have nothing to drink. Human Ref. No , Pompey , I have kept me from the cup, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_148",
            "start": 0,
            "end": 656,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_149@0",
            "content": "UNKNOWN, None, , Come in with me, and I will tell you my course. Human Ref. Go in with me , and I will tell you my drift . Input He'll bring a lot of money to the person who owns him , that's for sure . DAML-ATM He shall bring a great sum to the man that owns him, and that's certain. Human Ref. He shall pay for him that hath him, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_149",
            "start": 0,
            "end": 332,
            "label": {}
        },
        {
            "ix": "185-ARR_v1_150@0",
            "content": "UNKNOWN, None, , More Transferred sentences on Shakespeare(few shot setting, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "185-ARR_v1_150",
            "start": 0,
            "end": 77,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "185-ARR_v1_0",
            "tgt_ix": "185-ARR_v1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_0",
            "tgt_ix": "185-ARR_v1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_1",
            "tgt_ix": "185-ARR_v1_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_1",
            "tgt_ix": "185-ARR_v1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_0",
            "tgt_ix": "185-ARR_v1_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_2",
            "tgt_ix": "185-ARR_v1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_4",
            "tgt_ix": "185-ARR_v1_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_5",
            "tgt_ix": "185-ARR_v1_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_6",
            "tgt_ix": "185-ARR_v1_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_7",
            "tgt_ix": "185-ARR_v1_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_8",
            "tgt_ix": "185-ARR_v1_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_9",
            "tgt_ix": "185-ARR_v1_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_10",
            "tgt_ix": "185-ARR_v1_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_3",
            "tgt_ix": "185-ARR_v1_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_3",
            "tgt_ix": "185-ARR_v1_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_3",
            "tgt_ix": "185-ARR_v1_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_3",
            "tgt_ix": "185-ARR_v1_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_3",
            "tgt_ix": "185-ARR_v1_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_3",
            "tgt_ix": "185-ARR_v1_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_3",
            "tgt_ix": "185-ARR_v1_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_3",
            "tgt_ix": "185-ARR_v1_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_3",
            "tgt_ix": "185-ARR_v1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_0",
            "tgt_ix": "185-ARR_v1_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_11",
            "tgt_ix": "185-ARR_v1_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_12",
            "tgt_ix": "185-ARR_v1_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_12",
            "tgt_ix": "185-ARR_v1_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_14",
            "tgt_ix": "185-ARR_v1_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_13",
            "tgt_ix": "185-ARR_v1_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_13",
            "tgt_ix": "185-ARR_v1_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_13",
            "tgt_ix": "185-ARR_v1_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_12",
            "tgt_ix": "185-ARR_v1_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_15",
            "tgt_ix": "185-ARR_v1_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_16",
            "tgt_ix": "185-ARR_v1_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_16",
            "tgt_ix": "185-ARR_v1_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_12",
            "tgt_ix": "185-ARR_v1_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_17",
            "tgt_ix": "185-ARR_v1_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_18",
            "tgt_ix": "185-ARR_v1_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_18",
            "tgt_ix": "185-ARR_v1_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_0",
            "tgt_ix": "185-ARR_v1_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_19",
            "tgt_ix": "185-ARR_v1_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_20",
            "tgt_ix": "185-ARR_v1_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_20",
            "tgt_ix": "185-ARR_v1_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_20",
            "tgt_ix": "185-ARR_v1_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_21",
            "tgt_ix": "185-ARR_v1_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_23",
            "tgt_ix": "185-ARR_v1_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_24",
            "tgt_ix": "185-ARR_v1_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_25",
            "tgt_ix": "185-ARR_v1_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_22",
            "tgt_ix": "185-ARR_v1_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_22",
            "tgt_ix": "185-ARR_v1_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_22",
            "tgt_ix": "185-ARR_v1_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_22",
            "tgt_ix": "185-ARR_v1_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_22",
            "tgt_ix": "185-ARR_v1_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_20",
            "tgt_ix": "185-ARR_v1_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_26",
            "tgt_ix": "185-ARR_v1_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_20",
            "tgt_ix": "185-ARR_v1_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_27",
            "tgt_ix": "185-ARR_v1_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_28",
            "tgt_ix": "185-ARR_v1_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_28",
            "tgt_ix": "185-ARR_v1_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_20",
            "tgt_ix": "185-ARR_v1_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_29",
            "tgt_ix": "185-ARR_v1_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_31",
            "tgt_ix": "185-ARR_v1_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_32",
            "tgt_ix": "185-ARR_v1_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_33",
            "tgt_ix": "185-ARR_v1_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_34",
            "tgt_ix": "185-ARR_v1_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_35",
            "tgt_ix": "185-ARR_v1_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_30",
            "tgt_ix": "185-ARR_v1_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_30",
            "tgt_ix": "185-ARR_v1_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_30",
            "tgt_ix": "185-ARR_v1_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_30",
            "tgt_ix": "185-ARR_v1_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_30",
            "tgt_ix": "185-ARR_v1_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_30",
            "tgt_ix": "185-ARR_v1_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_30",
            "tgt_ix": "185-ARR_v1_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_20",
            "tgt_ix": "185-ARR_v1_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_36",
            "tgt_ix": "185-ARR_v1_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_38",
            "tgt_ix": "185-ARR_v1_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_39",
            "tgt_ix": "185-ARR_v1_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_40",
            "tgt_ix": "185-ARR_v1_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_41",
            "tgt_ix": "185-ARR_v1_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_37",
            "tgt_ix": "185-ARR_v1_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_37",
            "tgt_ix": "185-ARR_v1_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_37",
            "tgt_ix": "185-ARR_v1_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_37",
            "tgt_ix": "185-ARR_v1_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_37",
            "tgt_ix": "185-ARR_v1_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_37",
            "tgt_ix": "185-ARR_v1_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_20",
            "tgt_ix": "185-ARR_v1_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_42",
            "tgt_ix": "185-ARR_v1_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_44",
            "tgt_ix": "185-ARR_v1_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_45",
            "tgt_ix": "185-ARR_v1_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_46",
            "tgt_ix": "185-ARR_v1_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_47",
            "tgt_ix": "185-ARR_v1_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_43",
            "tgt_ix": "185-ARR_v1_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_43",
            "tgt_ix": "185-ARR_v1_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_43",
            "tgt_ix": "185-ARR_v1_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_43",
            "tgt_ix": "185-ARR_v1_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_43",
            "tgt_ix": "185-ARR_v1_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_43",
            "tgt_ix": "185-ARR_v1_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_49",
            "tgt_ix": "185-ARR_v1_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_50",
            "tgt_ix": "185-ARR_v1_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_51",
            "tgt_ix": "185-ARR_v1_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_52",
            "tgt_ix": "185-ARR_v1_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_53",
            "tgt_ix": "185-ARR_v1_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_54",
            "tgt_ix": "185-ARR_v1_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_55",
            "tgt_ix": "185-ARR_v1_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_56",
            "tgt_ix": "185-ARR_v1_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_43",
            "tgt_ix": "185-ARR_v1_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_43",
            "tgt_ix": "185-ARR_v1_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_43",
            "tgt_ix": "185-ARR_v1_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_43",
            "tgt_ix": "185-ARR_v1_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_43",
            "tgt_ix": "185-ARR_v1_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_43",
            "tgt_ix": "185-ARR_v1_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_43",
            "tgt_ix": "185-ARR_v1_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_43",
            "tgt_ix": "185-ARR_v1_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_43",
            "tgt_ix": "185-ARR_v1_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_48",
            "tgt_ix": "185-ARR_v1_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_20",
            "tgt_ix": "185-ARR_v1_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_57",
            "tgt_ix": "185-ARR_v1_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_59",
            "tgt_ix": "185-ARR_v1_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_58",
            "tgt_ix": "185-ARR_v1_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_58",
            "tgt_ix": "185-ARR_v1_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_58",
            "tgt_ix": "185-ARR_v1_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_0",
            "tgt_ix": "185-ARR_v1_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_60",
            "tgt_ix": "185-ARR_v1_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_61",
            "tgt_ix": "185-ARR_v1_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_61",
            "tgt_ix": "185-ARR_v1_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_61",
            "tgt_ix": "185-ARR_v1_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_62",
            "tgt_ix": "185-ARR_v1_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_64",
            "tgt_ix": "185-ARR_v1_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_65",
            "tgt_ix": "185-ARR_v1_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_63",
            "tgt_ix": "185-ARR_v1_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_63",
            "tgt_ix": "185-ARR_v1_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_63",
            "tgt_ix": "185-ARR_v1_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_63",
            "tgt_ix": "185-ARR_v1_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_61",
            "tgt_ix": "185-ARR_v1_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_66",
            "tgt_ix": "185-ARR_v1_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_68",
            "tgt_ix": "185-ARR_v1_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_69",
            "tgt_ix": "185-ARR_v1_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_70",
            "tgt_ix": "185-ARR_v1_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_67",
            "tgt_ix": "185-ARR_v1_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_67",
            "tgt_ix": "185-ARR_v1_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_67",
            "tgt_ix": "185-ARR_v1_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_67",
            "tgt_ix": "185-ARR_v1_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_67",
            "tgt_ix": "185-ARR_v1_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_61",
            "tgt_ix": "185-ARR_v1_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_71",
            "tgt_ix": "185-ARR_v1_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_73",
            "tgt_ix": "185-ARR_v1_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_74",
            "tgt_ix": "185-ARR_v1_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_72",
            "tgt_ix": "185-ARR_v1_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_72",
            "tgt_ix": "185-ARR_v1_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_72",
            "tgt_ix": "185-ARR_v1_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_72",
            "tgt_ix": "185-ARR_v1_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_61",
            "tgt_ix": "185-ARR_v1_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_75",
            "tgt_ix": "185-ARR_v1_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_76",
            "tgt_ix": "185-ARR_v1_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_76",
            "tgt_ix": "185-ARR_v1_77",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_0",
            "tgt_ix": "185-ARR_v1_78",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_77",
            "tgt_ix": "185-ARR_v1_78",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_78",
            "tgt_ix": "185-ARR_v1_79",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_78",
            "tgt_ix": "185-ARR_v1_79",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_80",
            "tgt_ix": "185-ARR_v1_81",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_78",
            "tgt_ix": "185-ARR_v1_80",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_78",
            "tgt_ix": "185-ARR_v1_81",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_79",
            "tgt_ix": "185-ARR_v1_80",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_78",
            "tgt_ix": "185-ARR_v1_82",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_81",
            "tgt_ix": "185-ARR_v1_82",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_78",
            "tgt_ix": "185-ARR_v1_83",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_82",
            "tgt_ix": "185-ARR_v1_83",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_84",
            "tgt_ix": "185-ARR_v1_85",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_85",
            "tgt_ix": "185-ARR_v1_86",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_78",
            "tgt_ix": "185-ARR_v1_84",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_78",
            "tgt_ix": "185-ARR_v1_85",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_78",
            "tgt_ix": "185-ARR_v1_86",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_83",
            "tgt_ix": "185-ARR_v1_84",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_78",
            "tgt_ix": "185-ARR_v1_87",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_86",
            "tgt_ix": "185-ARR_v1_87",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "185-ARR_v1_0",
            "tgt_ix": "185-ARR_v1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_1",
            "tgt_ix": "185-ARR_v1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_2",
            "tgt_ix": "185-ARR_v1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_2",
            "tgt_ix": "185-ARR_v1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_2",
            "tgt_ix": "185-ARR_v1_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_2",
            "tgt_ix": "185-ARR_v1_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_2",
            "tgt_ix": "185-ARR_v1_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_2",
            "tgt_ix": "185-ARR_v1_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_2",
            "tgt_ix": "185-ARR_v1_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_3",
            "tgt_ix": "185-ARR_v1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_4",
            "tgt_ix": "185-ARR_v1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_5",
            "tgt_ix": "185-ARR_v1_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_5",
            "tgt_ix": "185-ARR_v1_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_5",
            "tgt_ix": "185-ARR_v1_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_5",
            "tgt_ix": "185-ARR_v1_5@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_6",
            "tgt_ix": "185-ARR_v1_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_6",
            "tgt_ix": "185-ARR_v1_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_6",
            "tgt_ix": "185-ARR_v1_6@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_7",
            "tgt_ix": "185-ARR_v1_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_7",
            "tgt_ix": "185-ARR_v1_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_7",
            "tgt_ix": "185-ARR_v1_7@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_7",
            "tgt_ix": "185-ARR_v1_7@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_8",
            "tgt_ix": "185-ARR_v1_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_8",
            "tgt_ix": "185-ARR_v1_8@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_8",
            "tgt_ix": "185-ARR_v1_8@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_8",
            "tgt_ix": "185-ARR_v1_8@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_9",
            "tgt_ix": "185-ARR_v1_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_9",
            "tgt_ix": "185-ARR_v1_9@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_9",
            "tgt_ix": "185-ARR_v1_9@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_9",
            "tgt_ix": "185-ARR_v1_9@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_9",
            "tgt_ix": "185-ARR_v1_9@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_9",
            "tgt_ix": "185-ARR_v1_9@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_10",
            "tgt_ix": "185-ARR_v1_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_10",
            "tgt_ix": "185-ARR_v1_10@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_11",
            "tgt_ix": "185-ARR_v1_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_12",
            "tgt_ix": "185-ARR_v1_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_13",
            "tgt_ix": "185-ARR_v1_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_14",
            "tgt_ix": "185-ARR_v1_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_14",
            "tgt_ix": "185-ARR_v1_14@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_14",
            "tgt_ix": "185-ARR_v1_14@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_14",
            "tgt_ix": "185-ARR_v1_14@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_14",
            "tgt_ix": "185-ARR_v1_14@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_14",
            "tgt_ix": "185-ARR_v1_14@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_15",
            "tgt_ix": "185-ARR_v1_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_15",
            "tgt_ix": "185-ARR_v1_15@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_15",
            "tgt_ix": "185-ARR_v1_15@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_16",
            "tgt_ix": "185-ARR_v1_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_17",
            "tgt_ix": "185-ARR_v1_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_17",
            "tgt_ix": "185-ARR_v1_17@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_17",
            "tgt_ix": "185-ARR_v1_17@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_17",
            "tgt_ix": "185-ARR_v1_17@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_17",
            "tgt_ix": "185-ARR_v1_17@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_18",
            "tgt_ix": "185-ARR_v1_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_19",
            "tgt_ix": "185-ARR_v1_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_19",
            "tgt_ix": "185-ARR_v1_19@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_19",
            "tgt_ix": "185-ARR_v1_19@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_19",
            "tgt_ix": "185-ARR_v1_19@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_19",
            "tgt_ix": "185-ARR_v1_19@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_19",
            "tgt_ix": "185-ARR_v1_19@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_19",
            "tgt_ix": "185-ARR_v1_19@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_20",
            "tgt_ix": "185-ARR_v1_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_21",
            "tgt_ix": "185-ARR_v1_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_21",
            "tgt_ix": "185-ARR_v1_21@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_22",
            "tgt_ix": "185-ARR_v1_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_23",
            "tgt_ix": "185-ARR_v1_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_24",
            "tgt_ix": "185-ARR_v1_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_25",
            "tgt_ix": "185-ARR_v1_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_25",
            "tgt_ix": "185-ARR_v1_25@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_25",
            "tgt_ix": "185-ARR_v1_25@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_26",
            "tgt_ix": "185-ARR_v1_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_26",
            "tgt_ix": "185-ARR_v1_26@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_26",
            "tgt_ix": "185-ARR_v1_26@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_26",
            "tgt_ix": "185-ARR_v1_26@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_27",
            "tgt_ix": "185-ARR_v1_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_28",
            "tgt_ix": "185-ARR_v1_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_29",
            "tgt_ix": "185-ARR_v1_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_29",
            "tgt_ix": "185-ARR_v1_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_29",
            "tgt_ix": "185-ARR_v1_29@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_29",
            "tgt_ix": "185-ARR_v1_29@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_30",
            "tgt_ix": "185-ARR_v1_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_31",
            "tgt_ix": "185-ARR_v1_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_31",
            "tgt_ix": "185-ARR_v1_31@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_31",
            "tgt_ix": "185-ARR_v1_31@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_31",
            "tgt_ix": "185-ARR_v1_31@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_32",
            "tgt_ix": "185-ARR_v1_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_33",
            "tgt_ix": "185-ARR_v1_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_34",
            "tgt_ix": "185-ARR_v1_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_35",
            "tgt_ix": "185-ARR_v1_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_35",
            "tgt_ix": "185-ARR_v1_35@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_36",
            "tgt_ix": "185-ARR_v1_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_36",
            "tgt_ix": "185-ARR_v1_36@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_36",
            "tgt_ix": "185-ARR_v1_36@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_36",
            "tgt_ix": "185-ARR_v1_36@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_37",
            "tgt_ix": "185-ARR_v1_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_38",
            "tgt_ix": "185-ARR_v1_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_38",
            "tgt_ix": "185-ARR_v1_38@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_38",
            "tgt_ix": "185-ARR_v1_38@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_38",
            "tgt_ix": "185-ARR_v1_38@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_39",
            "tgt_ix": "185-ARR_v1_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_40",
            "tgt_ix": "185-ARR_v1_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_40",
            "tgt_ix": "185-ARR_v1_40@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_41",
            "tgt_ix": "185-ARR_v1_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_42",
            "tgt_ix": "185-ARR_v1_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_42",
            "tgt_ix": "185-ARR_v1_42@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_43",
            "tgt_ix": "185-ARR_v1_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_44",
            "tgt_ix": "185-ARR_v1_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_44",
            "tgt_ix": "185-ARR_v1_44@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_44",
            "tgt_ix": "185-ARR_v1_44@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_44",
            "tgt_ix": "185-ARR_v1_44@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_44",
            "tgt_ix": "185-ARR_v1_44@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_45",
            "tgt_ix": "185-ARR_v1_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_46",
            "tgt_ix": "185-ARR_v1_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_46",
            "tgt_ix": "185-ARR_v1_46@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_47",
            "tgt_ix": "185-ARR_v1_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_48",
            "tgt_ix": "185-ARR_v1_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_48",
            "tgt_ix": "185-ARR_v1_48@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_49",
            "tgt_ix": "185-ARR_v1_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_49",
            "tgt_ix": "185-ARR_v1_49@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_50",
            "tgt_ix": "185-ARR_v1_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_51",
            "tgt_ix": "185-ARR_v1_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_52",
            "tgt_ix": "185-ARR_v1_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_52",
            "tgt_ix": "185-ARR_v1_52@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_52",
            "tgt_ix": "185-ARR_v1_52@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_52",
            "tgt_ix": "185-ARR_v1_52@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_53",
            "tgt_ix": "185-ARR_v1_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_54",
            "tgt_ix": "185-ARR_v1_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_55",
            "tgt_ix": "185-ARR_v1_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_56",
            "tgt_ix": "185-ARR_v1_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_57",
            "tgt_ix": "185-ARR_v1_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_57",
            "tgt_ix": "185-ARR_v1_57@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_57",
            "tgt_ix": "185-ARR_v1_57@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_58",
            "tgt_ix": "185-ARR_v1_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_59",
            "tgt_ix": "185-ARR_v1_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_59",
            "tgt_ix": "185-ARR_v1_59@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_59",
            "tgt_ix": "185-ARR_v1_59@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_60",
            "tgt_ix": "185-ARR_v1_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_61",
            "tgt_ix": "185-ARR_v1_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_62",
            "tgt_ix": "185-ARR_v1_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_62",
            "tgt_ix": "185-ARR_v1_62@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_63",
            "tgt_ix": "185-ARR_v1_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_64",
            "tgt_ix": "185-ARR_v1_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_64",
            "tgt_ix": "185-ARR_v1_64@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_64",
            "tgt_ix": "185-ARR_v1_64@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_64",
            "tgt_ix": "185-ARR_v1_64@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_64",
            "tgt_ix": "185-ARR_v1_64@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_65",
            "tgt_ix": "185-ARR_v1_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_65",
            "tgt_ix": "185-ARR_v1_65@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_65",
            "tgt_ix": "185-ARR_v1_65@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_65",
            "tgt_ix": "185-ARR_v1_65@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_65",
            "tgt_ix": "185-ARR_v1_65@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_65",
            "tgt_ix": "185-ARR_v1_65@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_65",
            "tgt_ix": "185-ARR_v1_65@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_66",
            "tgt_ix": "185-ARR_v1_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_66",
            "tgt_ix": "185-ARR_v1_66@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_66",
            "tgt_ix": "185-ARR_v1_66@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_66",
            "tgt_ix": "185-ARR_v1_66@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_66",
            "tgt_ix": "185-ARR_v1_66@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_66",
            "tgt_ix": "185-ARR_v1_66@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_66",
            "tgt_ix": "185-ARR_v1_66@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_66",
            "tgt_ix": "185-ARR_v1_66@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_67",
            "tgt_ix": "185-ARR_v1_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_68",
            "tgt_ix": "185-ARR_v1_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_68",
            "tgt_ix": "185-ARR_v1_68@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_68",
            "tgt_ix": "185-ARR_v1_68@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_69",
            "tgt_ix": "185-ARR_v1_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_69",
            "tgt_ix": "185-ARR_v1_69@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_69",
            "tgt_ix": "185-ARR_v1_69@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_69",
            "tgt_ix": "185-ARR_v1_69@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_69",
            "tgt_ix": "185-ARR_v1_69@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_69",
            "tgt_ix": "185-ARR_v1_69@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_69",
            "tgt_ix": "185-ARR_v1_69@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_69",
            "tgt_ix": "185-ARR_v1_69@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_69",
            "tgt_ix": "185-ARR_v1_69@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_69",
            "tgt_ix": "185-ARR_v1_69@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_69",
            "tgt_ix": "185-ARR_v1_69@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_69",
            "tgt_ix": "185-ARR_v1_69@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_70",
            "tgt_ix": "185-ARR_v1_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_70",
            "tgt_ix": "185-ARR_v1_70@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_71",
            "tgt_ix": "185-ARR_v1_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_72",
            "tgt_ix": "185-ARR_v1_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_73",
            "tgt_ix": "185-ARR_v1_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_73",
            "tgt_ix": "185-ARR_v1_73@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_73",
            "tgt_ix": "185-ARR_v1_73@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_73",
            "tgt_ix": "185-ARR_v1_73@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_73",
            "tgt_ix": "185-ARR_v1_73@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_73",
            "tgt_ix": "185-ARR_v1_73@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_73",
            "tgt_ix": "185-ARR_v1_73@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_73",
            "tgt_ix": "185-ARR_v1_73@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_74",
            "tgt_ix": "185-ARR_v1_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_74",
            "tgt_ix": "185-ARR_v1_74@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_75",
            "tgt_ix": "185-ARR_v1_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_75",
            "tgt_ix": "185-ARR_v1_75@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_75",
            "tgt_ix": "185-ARR_v1_75@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_75",
            "tgt_ix": "185-ARR_v1_75@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_75",
            "tgt_ix": "185-ARR_v1_75@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_75",
            "tgt_ix": "185-ARR_v1_75@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_75",
            "tgt_ix": "185-ARR_v1_75@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_76",
            "tgt_ix": "185-ARR_v1_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_77",
            "tgt_ix": "185-ARR_v1_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_77",
            "tgt_ix": "185-ARR_v1_77@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_77",
            "tgt_ix": "185-ARR_v1_77@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_77",
            "tgt_ix": "185-ARR_v1_77@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_77",
            "tgt_ix": "185-ARR_v1_77@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_77",
            "tgt_ix": "185-ARR_v1_77@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_78",
            "tgt_ix": "185-ARR_v1_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_79",
            "tgt_ix": "185-ARR_v1_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_79",
            "tgt_ix": "185-ARR_v1_79@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_79",
            "tgt_ix": "185-ARR_v1_79@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_80",
            "tgt_ix": "185-ARR_v1_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_81",
            "tgt_ix": "185-ARR_v1_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_81",
            "tgt_ix": "185-ARR_v1_81@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_81",
            "tgt_ix": "185-ARR_v1_81@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_82",
            "tgt_ix": "185-ARR_v1_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_82",
            "tgt_ix": "185-ARR_v1_82@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_82",
            "tgt_ix": "185-ARR_v1_82@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_82",
            "tgt_ix": "185-ARR_v1_82@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_83",
            "tgt_ix": "185-ARR_v1_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_83",
            "tgt_ix": "185-ARR_v1_83@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_83",
            "tgt_ix": "185-ARR_v1_83@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_84",
            "tgt_ix": "185-ARR_v1_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_84",
            "tgt_ix": "185-ARR_v1_84@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_84",
            "tgt_ix": "185-ARR_v1_84@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_85",
            "tgt_ix": "185-ARR_v1_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_85",
            "tgt_ix": "185-ARR_v1_85@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_86",
            "tgt_ix": "185-ARR_v1_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_87",
            "tgt_ix": "185-ARR_v1_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_87",
            "tgt_ix": "185-ARR_v1_87@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_88",
            "tgt_ix": "185-ARR_v1_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_89",
            "tgt_ix": "185-ARR_v1_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_90",
            "tgt_ix": "185-ARR_v1_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_91",
            "tgt_ix": "185-ARR_v1_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_92",
            "tgt_ix": "185-ARR_v1_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_93",
            "tgt_ix": "185-ARR_v1_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_94",
            "tgt_ix": "185-ARR_v1_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_95",
            "tgt_ix": "185-ARR_v1_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_96",
            "tgt_ix": "185-ARR_v1_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_97",
            "tgt_ix": "185-ARR_v1_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_98",
            "tgt_ix": "185-ARR_v1_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_99",
            "tgt_ix": "185-ARR_v1_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_100",
            "tgt_ix": "185-ARR_v1_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_101",
            "tgt_ix": "185-ARR_v1_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_102",
            "tgt_ix": "185-ARR_v1_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_103",
            "tgt_ix": "185-ARR_v1_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_104",
            "tgt_ix": "185-ARR_v1_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_105",
            "tgt_ix": "185-ARR_v1_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_106",
            "tgt_ix": "185-ARR_v1_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_107",
            "tgt_ix": "185-ARR_v1_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_108",
            "tgt_ix": "185-ARR_v1_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_109",
            "tgt_ix": "185-ARR_v1_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_110",
            "tgt_ix": "185-ARR_v1_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_111",
            "tgt_ix": "185-ARR_v1_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_112",
            "tgt_ix": "185-ARR_v1_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_113",
            "tgt_ix": "185-ARR_v1_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_114",
            "tgt_ix": "185-ARR_v1_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_115",
            "tgt_ix": "185-ARR_v1_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_116",
            "tgt_ix": "185-ARR_v1_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_117",
            "tgt_ix": "185-ARR_v1_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_118",
            "tgt_ix": "185-ARR_v1_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_119",
            "tgt_ix": "185-ARR_v1_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_120",
            "tgt_ix": "185-ARR_v1_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_121",
            "tgt_ix": "185-ARR_v1_121@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_122",
            "tgt_ix": "185-ARR_v1_122@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_123",
            "tgt_ix": "185-ARR_v1_123@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_124",
            "tgt_ix": "185-ARR_v1_124@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_125",
            "tgt_ix": "185-ARR_v1_125@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_126",
            "tgt_ix": "185-ARR_v1_126@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_127",
            "tgt_ix": "185-ARR_v1_127@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_128",
            "tgt_ix": "185-ARR_v1_128@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_129",
            "tgt_ix": "185-ARR_v1_129@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_130",
            "tgt_ix": "185-ARR_v1_130@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_131",
            "tgt_ix": "185-ARR_v1_131@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_132",
            "tgt_ix": "185-ARR_v1_132@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_133",
            "tgt_ix": "185-ARR_v1_133@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_134",
            "tgt_ix": "185-ARR_v1_134@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_135",
            "tgt_ix": "185-ARR_v1_135@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_136",
            "tgt_ix": "185-ARR_v1_136@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_137",
            "tgt_ix": "185-ARR_v1_137@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_138",
            "tgt_ix": "185-ARR_v1_138@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_139",
            "tgt_ix": "185-ARR_v1_139@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_140",
            "tgt_ix": "185-ARR_v1_140@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_141",
            "tgt_ix": "185-ARR_v1_141@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_142",
            "tgt_ix": "185-ARR_v1_142@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_143",
            "tgt_ix": "185-ARR_v1_143@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_144",
            "tgt_ix": "185-ARR_v1_144@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_145",
            "tgt_ix": "185-ARR_v1_145@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_146",
            "tgt_ix": "185-ARR_v1_146@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_147",
            "tgt_ix": "185-ARR_v1_147@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_148",
            "tgt_ix": "185-ARR_v1_148@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_149",
            "tgt_ix": "185-ARR_v1_149@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "185-ARR_v1_150",
            "tgt_ix": "185-ARR_v1_150@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 1391,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "position_tag_type": "from_draft",
        "doc_id": "185-ARR",
        "version": 1
    }
}