{
    "nodes": [
        {
            "ix": "59-ARR_v1_review3_0",
            "content": "59-ARR_v1_review3",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "59-ARR_v1_review3_1",
            "content": "paper_summary. The paper presents a new benchmark for Pre-trained Language Model (PLM) knowledge probing in the biomedical domain called MedLAMA and a new probing approach called Contrastive-Probe.\nThe dataset is based on the UMLS metathesaurus. It is composed of a set of 19 handpicked relations with 1k instances per relation. Based on these relations, the authors devised 19 prompts.\nThe paper also presents a new method for probing PLMs, called Contrastive-Probe. The method is a 2-step approach which begins by a light pre-training phase based on a cloze-stype self-retrieving task. Then the actual probing is performed using MedLAMA. Contrastive-Probe do not rely on the MLM head of the PLM being probed. The authors start by encoding the prompt and the available entities (extracted from UMLS). Then the 10 closest entity representations are selected with a Nearest Neighbor Search. One of the advantage of this approach is the possibility to easily include answers with multiple tokens.\nThe paper apply MedLAMA using Contrastive-Prove and other approaches on different PLMs (general and biomedical domain) and show that their approach allow to better measure the biomedical knowledge included in the models.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "59-ARR_v1_review3_2",
            "content": "summary_of_strengths. The paper is building on previous work in the relatively new domain of PLM knowledge probing (most citations are after 2020). The authors manage to take some distance with the domain and present a interesting overview of the current literature. They build upon this literature and present a new benchmark + a new method for knowledge probing.\nPrincipal strengths of the paper: 1. The paper present an in-depth state-of-the-art related to PLM knowledge probing. \n2. There is an extensive comparison to the literature. \n3. There is an interesting and extensive analysis of the proposed approach. \n4. The authors investigates how much knowledge is stored in each Transformer layer. \n5. The paper include robustness tests (sensitivity to the random seed).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "59-ARR_v1_review3_3",
            "content": "summary_of_weaknesses. 1. According to table 8, the authors performed 500 training steps during the rewire phase. Why is this hyper-parameter not optimized? It seems by looking at Figure 4 and 9, that the best performance append before reaching this point.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "59-ARR_v1_review3_4",
            "content": "comments,_suggestions_and_typos. None",
            "ntype": "p",
            "meta": null
        }
    ],
    "span_nodes": [
        {
            "ix": "59-ARR_v1_review3_0@0",
            "content": "59-ARR_v1_review3",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_0",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_1@0",
            "content": "paper_summary.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_1",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_1@1",
            "content": "The paper presents a new benchmark for Pre-trained Language Model (PLM) knowledge probing in the biomedical domain called MedLAMA and a new probing approach called Contrastive-Probe.\n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_1",
            "start": 15,
            "end": 197,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_1@2",
            "content": "The dataset is based on the UMLS metathesaurus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_1",
            "start": 198,
            "end": 244,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_1@3",
            "content": "It is composed of a set of 19 handpicked relations with 1k instances per relation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_1",
            "start": 246,
            "end": 327,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_1@4",
            "content": "Based on these relations, the authors devised 19 prompts.\n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_1",
            "start": 329,
            "end": 386,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_1@5",
            "content": "The paper also presents a new method for probing PLMs, called Contrastive-Probe.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_1",
            "start": 387,
            "end": 466,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_1@6",
            "content": "The method is a 2-step approach which begins by a light pre-training phase based on a cloze-stype self-retrieving task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_1",
            "start": 468,
            "end": 586,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_1@7",
            "content": "Then the actual probing is performed using MedLAMA.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_1",
            "start": 588,
            "end": 638,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_1@8",
            "content": "Contrastive-Probe do not rely on the MLM head of the PLM being probed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_1",
            "start": 640,
            "end": 709,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_1@9",
            "content": "The authors start by encoding the prompt and the available entities (extracted from UMLS).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_1",
            "start": 711,
            "end": 800,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_1@10",
            "content": "Then the 10 closest entity representations are selected with a Nearest Neighbor Search.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_1",
            "start": 802,
            "end": 888,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_1@11",
            "content": "One of the advantage of this approach is the possibility to easily include answers with multiple tokens.\n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_1",
            "start": 890,
            "end": 994,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_1@12",
            "content": "The paper apply MedLAMA using Contrastive-Prove and other approaches on different PLMs (general and biomedical domain) and show that their approach allow to better measure the biomedical knowledge included in the models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_1",
            "start": 995,
            "end": 1214,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_2@0",
            "content": "summary_of_strengths.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_2",
            "start": 0,
            "end": 20,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_2@1",
            "content": "The paper is building on previous work in the relatively new domain of PLM knowledge probing (most citations are after 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_2",
            "start": 22,
            "end": 146,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_2@2",
            "content": "The authors manage to take some distance with the domain and present a interesting overview of the current literature.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_2",
            "start": 148,
            "end": 265,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_2@3",
            "content": "They build upon this literature and present a new benchmark + a new method for knowledge probing.\n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_2",
            "start": 267,
            "end": 364,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_2@4",
            "content": "Principal strengths of the paper: 1. The paper present an in-depth state-of-the-art related to PLM knowledge probing. \n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_2",
            "start": 365,
            "end": 483,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_2@5",
            "content": "2. There is an extensive comparison to the literature. \n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_2",
            "start": 484,
            "end": 539,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_2@6",
            "content": "3. There is an interesting and extensive analysis of the proposed approach. \n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_2",
            "start": 540,
            "end": 616,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_2@7",
            "content": "4. The authors investigates how much knowledge is stored in each Transformer layer. \n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_2",
            "start": 617,
            "end": 701,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_2@8",
            "content": "5. The paper include robustness tests (sensitivity to the random seed).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_2",
            "start": 702,
            "end": 772,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_3@0",
            "content": "summary_of_weaknesses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_3",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_3@1",
            "content": "1. According to table 8, the authors performed 500 training steps during the rewire phase.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_3",
            "start": 23,
            "end": 112,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_3@2",
            "content": "Why is this hyper-parameter not optimized?",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_3",
            "start": 114,
            "end": 155,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_3@3",
            "content": "It seems by looking at Figure 4 and 9, that the best performance append before reaching this point.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_3",
            "start": 157,
            "end": 255,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_4@0",
            "content": "comments,_suggestions_and_typos.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_4",
            "start": 0,
            "end": 31,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review3_4@1",
            "content": "None",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review3_4",
            "start": 33,
            "end": 36,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "59-ARR_v1_review3_0",
            "tgt_ix": "59-ARR_v1_review3_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "59-ARR_v1_review3_0",
            "tgt_ix": "59-ARR_v1_review3_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "59-ARR_v1_review3_0",
            "tgt_ix": "59-ARR_v1_review3_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "59-ARR_v1_review3_0",
            "tgt_ix": "59-ARR_v1_review3_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "59-ARR_v1_review3_0",
            "tgt_ix": "59-ARR_v1_review3_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "59-ARR_v1_review3_1",
            "tgt_ix": "59-ARR_v1_review3_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "59-ARR_v1_review3_2",
            "tgt_ix": "59-ARR_v1_review3_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "59-ARR_v1_review3_3",
            "tgt_ix": "59-ARR_v1_review3_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "59-ARR_v1_review3_0",
            "tgt_ix": "59-ARR_v1_review3_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_1",
            "tgt_ix": "59-ARR_v1_review3_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_1",
            "tgt_ix": "59-ARR_v1_review3_1@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_1",
            "tgt_ix": "59-ARR_v1_review3_1@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_1",
            "tgt_ix": "59-ARR_v1_review3_1@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_1",
            "tgt_ix": "59-ARR_v1_review3_1@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_1",
            "tgt_ix": "59-ARR_v1_review3_1@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_1",
            "tgt_ix": "59-ARR_v1_review3_1@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_1",
            "tgt_ix": "59-ARR_v1_review3_1@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_1",
            "tgt_ix": "59-ARR_v1_review3_1@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_1",
            "tgt_ix": "59-ARR_v1_review3_1@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_1",
            "tgt_ix": "59-ARR_v1_review3_1@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_1",
            "tgt_ix": "59-ARR_v1_review3_1@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_1",
            "tgt_ix": "59-ARR_v1_review3_1@12",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_2",
            "tgt_ix": "59-ARR_v1_review3_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_2",
            "tgt_ix": "59-ARR_v1_review3_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_2",
            "tgt_ix": "59-ARR_v1_review3_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_2",
            "tgt_ix": "59-ARR_v1_review3_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_2",
            "tgt_ix": "59-ARR_v1_review3_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_2",
            "tgt_ix": "59-ARR_v1_review3_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_2",
            "tgt_ix": "59-ARR_v1_review3_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_2",
            "tgt_ix": "59-ARR_v1_review3_2@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_2",
            "tgt_ix": "59-ARR_v1_review3_2@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_3",
            "tgt_ix": "59-ARR_v1_review3_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_3",
            "tgt_ix": "59-ARR_v1_review3_3@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_3",
            "tgt_ix": "59-ARR_v1_review3_3@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_3",
            "tgt_ix": "59-ARR_v1_review3_3@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_4",
            "tgt_ix": "59-ARR_v1_review3_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review3_4",
            "tgt_ix": "59-ARR_v1_review3_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "59-ARR_v1_review3",
    "meta": {
        "ix_counter": 33,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy"
    }
}