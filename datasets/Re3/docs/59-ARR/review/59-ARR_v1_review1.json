{
    "nodes": [
        {
            "ix": "59-ARR_v1_review1_0",
            "content": "59-ARR_v1_review1",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "59-ARR_v1_review1_1",
            "content": "paper_summary. This paper consists of two main parts. First, the authors constructed MedLAMA, a biomedical knowledge probing benchmark dataset based on the UMLS knowledge graph. Second, the authors proposed a contrastive-probe method based on retrieval-based probing and self-supervised contrastive learning. When the authors applied several conventional proving methods with existing pre-trained language models (PLMs) to MedLAMA, other methods showed poor performances, because they have weaknesses in handling multi-token answers. The authors insisted that the proposed contrastive-probe method achieved significant improvement on probing with MedLAMA data. The authors also performed extensive experiments including human expert evaluation to demonstrate characteristics of their dataset and method.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "59-ARR_v1_review1_2",
            "content": "summary_of_strengths. - The authors constructed a new biomedical knowledge probing benchmark dataset MedLAMA.\n-The authors proposed a contrastive-probe method, which can be used without labelled data.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "59-ARR_v1_review1_3",
            "content": "summary_of_weaknesses. - The performance of the contrastive-probe method in the main result using MedLAMA was significantly better than other methods (mask average), while the performances using BioLAMA were similar between mask average and the contrastive-probe method. Thus, the authors need to clearly show why the performances in two datasets are different.    -The authors mentioned \u201c2Prompt-based probing approaches such as Auto-Prompt (Shin et al., 2020a), SoftPrompt (Qin and Eisner, 2021), and OptiPrompt (Zhong et al., 2021) need additional labelled data for fine-tuning prompts, but we restrict the scope of our investigation to methods that do not require task data.\u201c However, it might be better to show the performances of these methods on the MedLAMA dataset, in order to show the validity of the MedLAMA dataset.\n-Additionally, it seems to be an unfair comparison because only the contrastive-probe method was additionally pre-trained for the cloze-style task.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "59-ARR_v1_review1_4",
            "content": "comments,_suggestions_and_typos. - It would be better that comparison with BioLAMA is placed in the main result, not in the Appendix.",
            "ntype": "p",
            "meta": null
        }
    ],
    "span_nodes": [
        {
            "ix": "59-ARR_v1_review1_0@0",
            "content": "59-ARR_v1_review1",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review1_0",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review1_1@0",
            "content": "paper_summary.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review1_1",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review1_1@1",
            "content": "This paper consists of two main parts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review1_1",
            "start": 15,
            "end": 52,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review1_1@2",
            "content": "First, the authors constructed MedLAMA, a biomedical knowledge probing benchmark dataset based on the UMLS knowledge graph.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review1_1",
            "start": 54,
            "end": 176,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review1_1@3",
            "content": "Second, the authors proposed a contrastive-probe method based on retrieval-based probing and self-supervised contrastive learning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review1_1",
            "start": 178,
            "end": 307,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review1_1@4",
            "content": "When the authors applied several conventional proving methods with existing pre-trained language models (PLMs) to MedLAMA, other methods showed poor performances, because they have weaknesses in handling multi-token answers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review1_1",
            "start": 309,
            "end": 532,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review1_1@5",
            "content": "The authors insisted that the proposed contrastive-probe method achieved significant improvement on probing with MedLAMA data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review1_1",
            "start": 534,
            "end": 659,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review1_1@6",
            "content": "The authors also performed extensive experiments including human expert evaluation to demonstrate characteristics of their dataset and method.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review1_1",
            "start": 661,
            "end": 802,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review1_2@0",
            "content": "summary_of_strengths. - The authors constructed a new biomedical knowledge probing benchmark dataset MedLAMA.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review1_2",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review1_2@1",
            "content": "\n-The authors proposed a contrastive-probe method, which can be used without labelled data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review1_2",
            "start": 109,
            "end": 199,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review1_3@0",
            "content": "summary_of_weaknesses. - The performance of the contrastive-probe method in the main result using MedLAMA was significantly better than other methods (mask average), while the performances using BioLAMA were similar between mask average and the contrastive-probe method.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review1_3",
            "start": 0,
            "end": 269,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review1_3@1",
            "content": "Thus, the authors need to clearly show why the performances in two datasets are different.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review1_3",
            "start": 271,
            "end": 360,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review1_3@2",
            "content": "   -The authors mentioned \u201c2Prompt-based probing approaches such as Auto-Prompt (Shin et al., 2020a), SoftPrompt (Qin and Eisner, 2021), and OptiPrompt (Zhong et al., 2021) need additional labelled data for fine-tuning prompts, but we restrict the scope of our investigation to methods that do not require task data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review1_3",
            "start": 362,
            "end": 677,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review1_3@3",
            "content": "\u201c However, it might be better to show the performances of these methods on the MedLAMA dataset, in order to show the validity of the MedLAMA dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review1_3",
            "start": 678,
            "end": 826,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review1_3@4",
            "content": "\n-Additionally, it seems to be an unfair comparison because only the contrastive-probe method was additionally pre-trained for the cloze-style task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review1_3",
            "start": 827,
            "end": 974,
            "label": {}
        },
        {
            "ix": "59-ARR_v1_review1_4@0",
            "content": "comments,_suggestions_and_typos. - It would be better that comparison with BioLAMA is placed in the main result, not in the Appendix.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "59-ARR_v1_review1_4",
            "start": 0,
            "end": 132,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "59-ARR_v1_review1_0",
            "tgt_ix": "59-ARR_v1_review1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "59-ARR_v1_review1_0",
            "tgt_ix": "59-ARR_v1_review1_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "59-ARR_v1_review1_0",
            "tgt_ix": "59-ARR_v1_review1_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "59-ARR_v1_review1_0",
            "tgt_ix": "59-ARR_v1_review1_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "59-ARR_v1_review1_0",
            "tgt_ix": "59-ARR_v1_review1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "59-ARR_v1_review1_1",
            "tgt_ix": "59-ARR_v1_review1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "59-ARR_v1_review1_2",
            "tgt_ix": "59-ARR_v1_review1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "59-ARR_v1_review1_3",
            "tgt_ix": "59-ARR_v1_review1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "59-ARR_v1_review1_0",
            "tgt_ix": "59-ARR_v1_review1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review1_1",
            "tgt_ix": "59-ARR_v1_review1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review1_1",
            "tgt_ix": "59-ARR_v1_review1_1@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review1_1",
            "tgt_ix": "59-ARR_v1_review1_1@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review1_1",
            "tgt_ix": "59-ARR_v1_review1_1@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review1_1",
            "tgt_ix": "59-ARR_v1_review1_1@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review1_1",
            "tgt_ix": "59-ARR_v1_review1_1@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review1_1",
            "tgt_ix": "59-ARR_v1_review1_1@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review1_2",
            "tgt_ix": "59-ARR_v1_review1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review1_2",
            "tgt_ix": "59-ARR_v1_review1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review1_3",
            "tgt_ix": "59-ARR_v1_review1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review1_3",
            "tgt_ix": "59-ARR_v1_review1_3@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review1_3",
            "tgt_ix": "59-ARR_v1_review1_3@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review1_3",
            "tgt_ix": "59-ARR_v1_review1_3@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review1_3",
            "tgt_ix": "59-ARR_v1_review1_3@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "59-ARR_v1_review1_4",
            "tgt_ix": "59-ARR_v1_review1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "59-ARR_v1_review1",
    "meta": {
        "ix_counter": 20,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy"
    }
}