{
    "nodes": [
        {
            "ix": "183-ARR_v2_0",
            "content": "Platt-Bin: Efficient Posterior Calibrated Training for NLP Classifiers",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_2",
            "content": "Modern NLP classifiers are known to return uncalibrated estimations of class posteriors. Existing methods for posterior calibration rescale the predicted probabilities but often have an adverse impact on final classification accuracy, thus leading to poorer generalization. We propose an end-to-end trained calibrator, Platt-Binning, that directly optimizes the objective while minimizing the difference between the predicted and empirical posterior probabilities. Our method leverages the sample efficiency of Platt scaling and the verification guarantees of histogram binning, thus not only reducing the calibration error but also improving task performance. In contrast to existing calibrators, we perform this efficient calibration during training. Empirical evaluation of benchmark NLP classification tasks echoes the efficacy of our proposal.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "183-ARR_v2_4",
            "content": "Deep learning has proven to be tremendously attractive for researchers in fields such as physics, biology, and manufacturing, to name a few (Baldi et al., 2014;Anjos et al., 2015;Bergmann et al., 2014). However, these are fields in which representing model uncertainty is of crucial importance (Gal and Ghahramani, 2016). A common way to incorporate DNNs in other fields is to use the predictions of a trained classifier for decision making in a downstream task. In some cases the effectiveness of the decisions depends on a utility function and it is not enough to simply predict the most likely label for each example. What is needed instead is to quantify model uncertainty about the predictions. Despite promising performance in supervised learning benchmarks in terms of accuracy, DNNs are poor at quantifying predictive uncertainty, and tend to produce overconfident predictions. Overconfident incorrect predictions can be harmful or offensive in NLP applications (Amodei et al., 2016), hence proper uncertainty quantification is crucial in practice. Probabilistic uncertainty in machine learning translates to estimation of the probability mass function p(y|x) by the model, where x is the input sample and y is a class label. Recent works have shown that stateof-the art structured prediction models are poorly calibrated. Therefore, blindly using the output of the softmax function output as the model uncertainty is misleading (Kumar and Sarawagi, 2019;Dong et al., 2018;Nguyen and O'Connor, 2015).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_5",
            "content": "We are interested in calibrating the posterior estimates, i.e. we wish to get posterior probability estimations that reflect the true probability of the classes. The probability that a system outputs for an event should reflect the true frequency of that event: if an automated diagnosis system says 1,000 patients have cancer with probability 0.1, approximately 100 of them should indeed have cancer . Even if the actual mechanism might be difficult to interpret, a calibrated model at least gives us a signal that it \"knows what it doesn't know,\" thereby making these models easier to deploy in practice (Jiang et al., 2012). We define perfect calibration as follows.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_6",
            "content": "P(y|f (x)) = f (x)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_7",
            "content": "where f : X \u2192 \u25b3 K\u22121 is the probabilistic classifier that maps the samples x \u2208 X to the Kdimensional simplex. As majority of the current state-of-the art machine learning models, such as DNNs, do not output calibrated probabilities out of the box (Kuleshov et al., 2018), existing works rely on re-calibration methods that take the output of an uncalibrated model, and transform it into a calibrated probability. One way of addressing this is to use Scaling approaches for re-calibration such as Platt scaling (Platt et al., 1999), isotonic regression (Zadrozny and Elkan, 2002), and temperature scaling (Guo et al., 2017). These methods are widely used and require very few samples, however it is challenging to calibrate posterior estimates with sub-optimal binning schemes ). An alternative approach, histogram binning (Zadrozny and Elkan, 2001), outputs probabilities from a finite set. Histogram binning can produce a model that is calibrated, and unlike scaling methods we can measure its calibration error, but it is sample inefficient. In particular, the number of samples required for calibration scales linearly with the number of classes for which probability estimates need to be generated.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_8",
            "content": "Irrespective of the choice of the calibration method, existing works generally calibrate the posterior distribution predicted from the classifier after training. These post-processing calibration methods re-learn an appropriate distribution from a held-out validation set and then apply it to an unseen test set. The fixed split of the data sets and insufficient number of samples for training the calibration function adversely affects the generalization of post-hoc calibrated classifiers and reduce their accuracy. In this paper we try to address some of the existing challenges in achieving apt calibration. In particular our contributions are:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_9",
            "content": "\u2022 We propose a training technique that optimizes a classification objective for an NLP task by calibrating the posterior distribution while training. \u2022 We leverage the advantages of both scaling and binning methods and propose a calibration method for NLP classification task which is both sample efficient and verifiable. \u2022 We demonstrate how the proposed method not only calibrates but also improves the performance of benchmark NLP classification tasks.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_10",
            "content": "Related Works",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "183-ARR_v2_11",
            "content": "Model uncertainty estimation and posterior calibration is a topic of continued interest not only in the fields of machine learning and statistics, but also in meteorology (Br\u00f6cker, 2009), fairness (Liu et al., 2019), healthcare (Jiang et al., 2012), reinforcement learning (Malik et al., 2019), natural language processing (Card and Smith, 2018), speech recognition (Yu et al., 2011) and economics (Gneiting et al., 2007). In probabilistic models, the principal goal of estimation of the posterior p(y|x) given a sample x \u2208 X and a label y \u2208 [K], is to assign low confidence to samples that were not explained well by the training data. One common way to calibrate multi-class posteriors after training the classifier f : X \u2192 R is to treat the problem as K one-vs-all binary problems. In this case, model uncertainty is quantified by normalizing the estimation of p(y = k|f (x) k ) where f (x) k is the output score of the classifier for sample x and class k. Generalization of calibration tests with kernel methods can be found in (Widmann et al., 2019). Various binary calibration methods can be used to estimate the marginal posterior over a calibration dataset, ranging from parametric approaches (e.g. Platt scaling, temperature scaling, vector scaling (Platt et al., 1999;Guo et al., 2017)), to non-parametric methods (e.g. quantile or bayesian binning (Zadrozny and Elkan, 2001;Naeini et al., 2015), and isotonic regression (Zadrozny and Elkan, 2002).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_12",
            "content": "Another way to reduce the problem to binary calibration is by estimating model accuracy conditioned on its confidence, p(y = \u0177| max k\u2208[K] f (x) k ). Multi-class calibration aims to estimate the distribution of class labels conditioned on the estimated probability vector, p(y|f (x)). In this case the sample complexity is exponential in the number of classes and therefore with large number of classes, the main challenge is to constrain the hypothesis space with regularization. Some of the proposed methods for this purpose are matrix scaling and Dirichlet scaling which both use linear models for estimation of p(y = k|f (x)) (Guo et al., 2017;Kull et al., 2019), and MLP and order preserving functions (Rahimi et al., 2020a,b).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_13",
            "content": "Another approach is to account for model uncertainty via bayesian models. In Bayesian Neural Networks (BNNs) the predictive uncertainty will naturally be high in regions where training data is scarce (MacKay, 1992). However, the marginalization of the weights in BNN is intractable in general.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_14",
            "content": "Consequently, following papers propose various approximations such as variational inference (VI) (Graves, 2011;Blundell et al., 2015). Although BNNs are theoretically proven to control the overconfidence of the model in unseen regions of data space (Kristiadi et al., 2020), they require expensive approximations which limit their application in most modern NLP architectures. For instance, in (Joo et al., 2020) the authors model the distribution on posterior probability using a Dirichlet prior distribution and variational inference. MCDropout is a variational approximation of Gaussian processes that avoids explicit modeling of the posterior distribution (Gal and Ghahramani, 2016). Both of these methods require modification of training of the network.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_15",
            "content": "In NLP, tasks with structured outputs posterior calibration are particularly challenging. This is because the number of classes are exponentially large and estimation of every posterior density or marginal posterior density is not possible. Previous works such as (Jung et al., 2020;Nguyen and O'Connor, 2015) propose to use the downstream task with small number of classes to perform calibration and estimation of the calibration error. In structured prediction models, calibration is also important for the generation of the structured outputs as the decoding algorithm relies on the posterior estimates to efficiently search through the space of sequences. However, estimation of the sequence calibration error and its correction is intractable.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_16",
            "content": "To cope with this problem, approximate calibration methods using a set of interesting events and feature based calibration are proposed in (Kuleshov and Liang, 2015;Jagannatha and Yu, 2020) and an alternative calibration error estimator was proposed using sequence precision scoring function BLEU in (Kumar and Sarawagi, 2019). We are considering the first class of problems and leave the structured calibration to future work.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_17",
            "content": "Method",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "183-ARR_v2_18",
            "content": "In general, NLP classifiers work by first predicting a posterior probability distribution over all classes and then selecting the class with the largest estimated probability. However, these models are often poorly calibrated. Existing calibration methods re-learn an appropriate distribution from a heldout validation set and then apply it to an unseen test set which degrades the model performance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_19",
            "content": "Alternatively, we can dynamically estimate the required statistics for calibration from the train set during training iterations, thereby minimizing cross-entropy as well as the calibration error as a multi-task setup (Jung et al., 2020). Given a training set D = {(x 1 , y 1 )..(x n , y n )}, where x i is an n-dimensional vector of input features and y i is a K-dimensional one-hot vector corresponding to its true label (with K classes), we minimize the loss L train :",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_20",
            "content": "L train = L class + \u03bbL cal (1)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_21",
            "content": "Here L class is the classification loss (for eg. crossentropy) based on the predicted probability p ik updated during training for sample i and class k:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_22",
            "content": "L class = \u2212 N i=1 K k=1 y ik log(p ik )",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_23",
            "content": "L cal is the calibration loss which acts as a regularizer. It essentially tries to minimize the difference between the updated probability p and true posterior probabilities q via a distance function d (eg. mean squared error, KL-divergence, etc.):",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_24",
            "content": "L cal = N i=1 K k=1 d(p ik , q ik )",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_25",
            "content": "One crucial step here is to estimate the empirical probability q, which can be done by histogram binning method. Here, we measure the ratio of true labels for each bin split by the predicted posterior p from each update. This refers to CalEmpProb() function in algorithm 1. We store the results in Empirical Probability Matrix Q \u2208 R B\u00d7K , where B is the number of bins used for each posterior dimension. Histogram binning outputs probabilities from a finite set. Unlike scaling methods, it can produce a model that is calibrated and measure its calibration error. However, the number of samples required to calibrate scales linearly with the number of distinct probabilities B the model can output which can be large in the multi-class setting (Naeini et al., 2014).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_26",
            "content": "In this work, we propose an adaptive binning method that circumvents this bottleneck. We leverage the sample efficiency of Platt scaling (Platt et al., 1999) and the verification guarantees of histogram binning (Zadrozny and Elkan, 2001) by defining the Platt-Binning Calibrator. The problem with scaling methods is we cannot estimate their calibration error. The upside of scaling methods is that if the function family has at least one function that can achieve calibration error \u03f5 they require O(1/\u03f5 2 ) samples to reach calibration error \u03f5, while histogram binning requires O(B/\u03f5 2 ) samples. Platt-Binning Calibrator facilitates estimation of calibration error while being sampleefficient at the same time.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_27",
            "content": "Platt scaling calibrator: Since most modern deep learning classifiers do not output calibrated probabilities out of the box, recalibration methods take the output of an uncalibrated model, and transform it into a calibrated probability. That is, given a trained model f : X \u2192 [0, 1], let z = f (x). We are given recalibration data T = {(z i , y i )} n i=1 corresponding to model logits and the labels, and we wish to learn a calibrator g : [0, 1] \u2192 [0, 1] such that g \u2022 f is well-calibrated. Conventional Scaling methods, for example Platt scaling, output a function g:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_28",
            "content": "g = arg min g\u2208G (z,y)\u2208T l(g(z), y)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_29",
            "content": "where G is a the hypothesis class, g \u2208 G is differentiable, and l is a loss function, for example the log-loss or mean-squared error. The advantage of such methods is that they converge very quickly since they only fit a small number of parameters. Histogram binning calibrator, on the other hand, constructs a set of bins that partitions [0, 1] via a binning scheme. A binning scheme B of size B is a set of B intervals I 1 , ...I B that partitions [0, 1]. We use the notation \u03c3 to denote the softmax function. Given p = \u03c3(z) k \u2208 [0, 1], let \u03b2(z) = j, where j is the interval that p lands in (p \u2208 I j ). The binning scheme, B typically corresponds to choosing bins of equal widths (called equal width binning) or so that each bin contains an equal number of z i values in the calibration dataset (called uniform mass binning). Histogram binning then outputs the average y i value in each bin.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_30",
            "content": "Platt-Binning Calibrator builds at the intersection of the above two methods. Given a recalibration data T of size n, Platt-Binning Calibrator outputs \u011d\u03b2 such that \u011d\u03b2 \u2022 f has a low calibration error by using the following procedure:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_31",
            "content": "Step 1: Select g:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_32",
            "content": "g = arg min g\u2208G (z,y)\u2208T (y \u2212 g(z)) 2",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_33",
            "content": "(2)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_34",
            "content": "Step 2: Choose the bins so that an equal number of g(z i ) in T land in each bin b j for each j \u2208 1, ..., B",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_35",
            "content": "ECE = 1 K K k=1 B b=1 N kb N k |Q bk \u2212 pbk |",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_36",
            "content": "where pbk is the average posterior estimate for class k for samples in b-th bin. N kb and N k are the number of samples of class k assigned to bin b and in total, respectively. Contrary to equal-width binning, uniform-mass binning is a well-balanced binning scheme with guarantees on error bounds of estimated Expected Calibration Error, ECE .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_37",
            "content": "Step 3: Discretize g, by outputting the average g value in each bin. Let \u00b5(S) = 1 |S| s\u2208S s denote the mean of a set of values S. We set \u011d\u03b2 (z) = \u00b5(\u03b2(g(z)))we output the mean value of the bins that g(z) falls in.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_38",
            "content": "The motivation behind our method is that the g values in each bin are in a narrower range than the label values y, so when we take the average we incur lower estimation error. If G is well chosen, our method requires O( 1 \u03f5 2 + B)samples to achieve calibration error \u03f5 instead of O( B \u03f5 2 ) samples for histogram binning. All these steps are performed during training as explained in the pseudo-code in Algorithm 1. To the best of our knowledge, such a formulation is novel among existing calibrators that tackle the problem during training. Also, the whole approach is the first to be utilised to calibrate classifiers in the NLP domain. In the following section we prove the efficacy of our method by carrying out extensive evaluation of the performance of pretrained transformer models such as BERT (Devlin et al., 2019) on simple multi-class text classification tasks. Our motivation comes from the analysis in (Desai and Durrett, 2020) which shows that pretrained models are significantly better calibrated when used out-of-the-box.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_39",
            "content": "Experiments",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "183-ARR_v2_40",
            "content": "In the experiments we fine-tune the parameters on pre-trained BERT classifier using the regularized loss in equation (1). We compare our method to the following baselines:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_41",
            "content": "\u2022 MLE is the baseline with maximum likelihood training without calibration where we simply report the results of vanilla BERT classifier on the chosen tasks. \u2022 Platt scaling (posPS) is a post-hoc calibration method where we calibrate the posterior estimations of MLE classifier using Platt scaling (Platt et al., 1999).",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_42",
            "content": "if i mod u == 0 then p(x) = max k \u03c3(\u0398, D) k , \u2200x \u2208 D. \u0177 = arg max k \u03c3(\u0398, D) k , \u2200x \u2208 D.",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_43",
            "content": "Select g using equation 2.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_44",
            "content": "Uniform-mass binning over g(p i ).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_45",
            "content": "Discretize g:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_46",
            "content": "\u011d\u03b2 (p i ) = \u00b5[\u03b2(g(p i ))] Q \u2190 CalEmpProb(p;b j ) end \u0398 \u2190 \u0398 \u2212 \u03b7\u2207 \u0398 L train (\u0398, \u011d\u03b2 (p i ), b)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_47",
            "content": "end end \u03c3(f (x)) k for class kwe return the calibrated value g(f (x)) as the class probability. Despite its simplicity this method is competitive with the more complex methods when implemented post-hoc (Guo et al., 2017).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_48",
            "content": "\u2022 PosCal end-to-end training calibration using histogram binning (Jung et al., 2020). In this method we have a nested training procedure where in the outer loop we fit a histogram binning scheme with fix widths to each dimension of the posterior estimates of the BERT model. We use Q bk -the ratio of samples of kth class that were assigned to bth bin-as the empirical probability distribution q. In the inner loop we perform the ordinary training iterations over mini-batches of training dataset with cross-entropy loss and regularization term in equation (1) using KL-divergence between softmax output and the estimated empirical distribution.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_49",
            "content": "L cal = N i=1 K k=1 log \u03c3(z i ) k Q bin(z ik )k",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_50",
            "content": "where bin(.) returns the index of bin assigned to its input. In the experiments we used \u03bb = 1.0, 10 bin for discretisation of q and we update Q after every training epoch.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_51",
            "content": "We test the baselines and our method on the benchmark on NLP classification tasks: xSLUE (Kang and Hovy, 2019). xSLUE contains classification benchmark on different types of styles such as a level of humor, formality and even demographics of authors. We train our method with two types of calibrators: in the first calibration task we train a calibrator for the most confident prediction of the classifier and call this version plattbintop (PBtop). The pseudocode of this version is illustrated in algorithm (1). In the second version we train a separate Platt scaler and histogram binning for each class in a one-vs-all manner and we call this version of calibration plattbin (PB). While this version is exactly the same as plattbintop for binary tasks, it results in a very different solution for tasks with K > 2. The pseudocode of this version is omitted due to being mainly similar to the other version with one additional loop over the classes at line 7 of algorithm (1) and conversion of label y and \u0177 to one-vs-all binary labels. We report task accuracy, F1 score and ECE as the evaluation metrics.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_52",
            "content": "Results and Discussion",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "183-ARR_v2_53",
            "content": "Table 1 shows task performance and calibration error on xSLUE benchmark datasets. In general, our method outperforms MLE, Poscal and posPS on more than 50% of the datasets, in terms of both model performance and calibration error. For the rest of the datasets, our method gives competitive results. In seven out of nine cases, we reduce the calibration error ECE as compared to PosCal.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_54",
            "content": "In cases such as DailyDialog, SentiTreeBank and ShortHumor, the achieved reduction in ECE as compared to all baselines is significant. Note that this reduction has not compromised the model performance. In fact, cases like SentiTreeBank and ShortRomance even witness a significant improvement in the performance of the model when ECE is reduced. These observations prove the efficacy of our method in maintaining a perfect balance between model performance and model uncertainitya testimony of an ideal calibrator. Post-hoc methods such as posPS might achieve lower calibration error on a couple of datasets, but they fail to attain competitive performance in terms of accuracy. 1).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_55",
            "content": "We now analyse how our method behaves in comparison to MLE at sample level during test time.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_56",
            "content": "Table 2 shows a detailed analysis of misclassification made by MLE and Platt-Binning (PB). We see that both the methods have almost comparable performance in columns A1 and A2, with A2 being slightly higher. As such, the number of samples for which MLE and PB gave different predictions (column M ) is actually a small fraction of the total number of test samples used of evaluation of the methods (column T est). We further analyse the number of samples where MLE gave correct predictions while PB failed to do so (column P 1) and vice-versa (column P 2). In 8 out of 9 datasets, PB demonstrates superior or similar performance (P2 \u2265 P1). The difference is insignificant compared to the total size of the test set for the reverse scenario. This quantitative analysis reinstates that our method, PB, has better model performance at test time, thereby establishing that it generalizes well while reducing calibration error.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_57",
            "content": "We extend the discussion above by analysing qualitative results in Table 3. We consider three datasetsa two-class classification task StanfordPoliteness, a three-class classification task HateOffensive and a multi-class classification task (K > 3) DailyDialog, and include few test samples where MLE and PB disagreed on the predictions. The corresponding p along with the true label is also depicted.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_58",
            "content": "In the first two cases from StanfordPoliteness dataset, the level of politeness (e.g., \"Hey!\" in S1) or arrogance (e.g., \"What?\" in S2) indicated on phrases is not captured well by MLE, so it predicts the incorrect label while PB gives a correct prediction. However, for the rest two cases, MLE gives confident correct predictions taking into account phrases such as \"like\" in S1 or a slightly difficult example in S2 but PB fails (only slightly in S2 though) to give correct predictions. Arguing on similar lines for the multi-class case, we witness cases where MLE fails to classify correctly (eg. S1 and S2 in HateOffensive) but PB gives highly confident predictions and vice-versa. From our manual investigation above, we find that statistical knowledge about posterior probability helps correct p while training PB, so making p switch its prediction. For further analysis, we provide more examples in Appendix ??.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_59",
            "content": "In Figure 1 we show the calibration plots for three datasets: DailyDialog, HateOffensive, and Stan-fordPoliteness. We divide test samples according to the most confident estimated posterior into 10 bins. We plot the accuracy of the classifier versus the average classification confidence in each one of the bins in the top row. We also plot the number of samples in each calibration bin versus the classification confidence in the bottom row. Ideally, a calibrated classifier would assign a probability to the top class that is equivalent to its accuracy. Therefore, the accuracy-confidence curve of a calibrated classifier is close to the dashed grey curve in the top row. When Platt-bin and Platt-bin-top are further away from the calibration line it is because the number of samples in corresponding bins are low or even 0 in some cases. The bins with 0 samples in them can be ignored as they don't play a role in the classifier predictions.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_60",
            "content": "However, the distance of the curves is not enough to determine model calibration as most of the samples are assigned to the bin with highest estimated posterior. Thus, correcting the calibration error in the bins with more samples is more effective in improving the expected calibration error. Platt-Binning and Platt-Binning-Top algorithms increase the number of samples with lower classification confidence in all three of the illustrated tasks, while in comparison to MLE with no regularization they only reduce classification accuracy by a negligible amount and even increase the accuracy for HateOffensive task. Although, the classifier become visibily underconfident in HateOffensive task where post-hoc Platt scaling has a more calibrated output. While the ECE doesn't improve in StanfordPoliteness, Platt-Binning algorithm doesn't increase the ECE as much as PosCal regularization. We conjecture that such a behavior is demonstrated due to better sample efficiency of our algorithm.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_61",
            "content": "We conclude our analysis by observing the effect of two important parameters to this discussion-B: number of histogram bins used for calibration, and \u03bb: strength of the regularization. Figure 2 shows how calibration error (ECE) vary when the number of bins B is varied as {10, ...100}. We see that the calibration error of all the methods have an increasing trend as B is increased. One plausible explanation can be that as we increase the number of bins, we don't have enough samples per bin to estimate the empirical probabilities accurately.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_62",
            "content": "Since calibrated probabilities are used as an estimation of the true probabilities of the classes in case of PosCal and PB, it adds to the error if they are estimated wrongly. Thus, smaller number of bins is preferred, and as evident in Fig. 2, PB achieves lower ECE than PosCal when number of bins is low. The accuracy and F1 scores do not vary much with the number of the bins. Similarly, the performance is not impacted significantly by variations in the value of \u03bb (see Appendix ??)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_63",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "183-ARR_v2_64",
            "content": "In this work we proposed a simple yet effective method called Platt-Binning calibrator for better posterior calibration. Our method has theoretically lower sample complexity than histogram binning, giving us the best of scaling and binning methods.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_65",
            "content": "And unlike the existing post-processing calibration methods, Platt-Binning directly penalizes the difference between the predicted and the true (empirical) posterior probabilities dynamically over the training steps. Our empirical analysis corroborates that Platt-Binning can not only reduce the calibration error but also increase the task performance on the classification benchmarks. For tasks where the reduction in calibration error is low, our method maintains the performance of the model instead of degrading it as seen for other existing calibrators. Moreover, our method can be extended to any classification model as an additional component in the loss function, thus jointly optimised during training. There are many exciting avenues for future works in this regard. It will be interesting to assess how our method can provide advantages in the scenarios of domain adaptation and transfer learning. Moreover, exploring alternatives to the model family G from which estimate \u011d is considered can be a direction of improvement. Lastly, optimizing the overall method for huge datasets can be an essential extension. Our method may also assist in analysing the bias and fairness aspects of the predictions made by NLP classifiers. This can facilitate ethical deployment of NLP models for real-world applications.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "183-ARR_v2_66",
            "content": "UNKNOWN, None, 2016, Concrete problems in ai safety, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": null,
                "title": null,
                "pub_date": "2016",
                "pub_title": "Concrete problems in ai safety",
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_67",
            "content": "Of\u00e9lia Anjos, Carla Iglesias, F\u00e1tima Peres, Javier Mart\u00ednez, \u00c1ngela Garc\u00eda, Javier Taboada, Neural networks applied to discriminate botanical origin of honeys, 2015, Food chemistry, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Of\u00e9lia Anjos",
                    "Carla Iglesias",
                    "F\u00e1tima Peres",
                    "Javier Mart\u00ednez",
                    "\u00c1ngela Garc\u00eda",
                    "Javier Taboada"
                ],
                "title": "Neural networks applied to discriminate botanical origin of honeys",
                "pub_date": "2015",
                "pub_title": "Food chemistry",
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_68",
            "content": "Pierre Baldi, Peter Sadowski, Daniel Whiteson, Searching for exotic particles in high-energy physics with deep learning, 2014, Nature communications, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "Pierre Baldi",
                    "Peter Sadowski",
                    "Daniel Whiteson"
                ],
                "title": "Searching for exotic particles in high-energy physics with deep learning",
                "pub_date": "2014",
                "pub_title": "Nature communications",
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_69",
            "content": "S\u00f6ren Bergmann, S\u00f6ren Stelzer, Steffen Strassburger, On the use of artificial neural networks in simulation-based manufacturing control, 2014, Journal of Simulation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "S\u00f6ren Bergmann",
                    "S\u00f6ren Stelzer",
                    "Steffen Strassburger"
                ],
                "title": "On the use of artificial neural networks in simulation-based manufacturing control",
                "pub_date": "2014",
                "pub_title": "Journal of Simulation",
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_70",
            "content": "UNKNOWN, None, 2015, Weight uncertainty in neural network. In International conference on machine learning, PMLR.",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": null,
                "title": null,
                "pub_date": "2015",
                "pub_title": "Weight uncertainty in neural network. In International conference on machine learning",
                "pub": "PMLR"
            }
        },
        {
            "ix": "183-ARR_v2_71",
            "content": "Jochen Br\u00f6cker, Reliability, sufficiency, and the decomposition of proper scores, 2009, Quarterly Journal of the Royal Meteorological Society: A journal of the atmospheric sciences, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "Jochen Br\u00f6cker"
                ],
                "title": "Reliability, sufficiency, and the decomposition of proper scores",
                "pub_date": "2009",
                "pub_title": "Quarterly Journal of the Royal Meteorological Society: A journal of the atmospheric sciences",
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_72",
            "content": "Dallas Card, A Noah,  Smith, The importance of calibration for estimating proportions from annotations, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "Dallas Card",
                    "A Noah",
                    " Smith"
                ],
                "title": "The importance of calibration for estimating proportions from annotations",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "183-ARR_v2_73",
            "content": "Shrey Desai, Greg Durrett, Calibration of pre-trained transformers, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Shrey Desai",
                    "Greg Durrett"
                ],
                "title": "Calibration of pre-trained transformers",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_74",
            "content": "UNKNOWN, None, , , .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": null,
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_75",
            "content": "Kristina Toutanova, Bert: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long and Short Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Kristina Toutanova"
                ],
                "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Long and Short Papers"
            }
        },
        {
            "ix": "183-ARR_v2_76",
            "content": "Li Dong, Chris Quirk, Mirella Lapata, Confidence modeling for neural semantic parsing, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Li Dong",
                    "Chris Quirk",
                    "Mirella Lapata"
                ],
                "title": "Confidence modeling for neural semantic parsing",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "183-ARR_v2_77",
            "content": "Yarin Gal, Zoubin Ghahramani, Dropout as a bayesian approximation: Representing model uncertainty in deep learning, 2016, international conference on machine learning, PMLR.",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Yarin Gal",
                    "Zoubin Ghahramani"
                ],
                "title": "Dropout as a bayesian approximation: Representing model uncertainty in deep learning",
                "pub_date": "2016",
                "pub_title": "international conference on machine learning",
                "pub": "PMLR"
            }
        },
        {
            "ix": "183-ARR_v2_78",
            "content": "Tilmann Gneiting, Fadoua Balabdaoui, Adrian Raftery, Probabilistic forecasts, calibration and sharpness, 2007, Journal of the Royal Statistical Society: Series B (Statistical Methodology), .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Tilmann Gneiting",
                    "Fadoua Balabdaoui",
                    "Adrian Raftery"
                ],
                "title": "Probabilistic forecasts, calibration and sharpness",
                "pub_date": "2007",
                "pub_title": "Journal of the Royal Statistical Society: Series B (Statistical Methodology)",
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_79",
            "content": "Alex Graves, Practical variational inference for neural networks, 2011, Advances in neural information processing systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    "Alex Graves"
                ],
                "title": "Practical variational inference for neural networks",
                "pub_date": "2011",
                "pub_title": "Advances in neural information processing systems",
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_80",
            "content": "Chuan Guo, Geoff Pleiss, Yu Sun, Kilian Q Weinberger, On calibration of modern neural networks, 2017, International Conference on Machine Learning, PMLR.",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Chuan Guo",
                    "Geoff Pleiss",
                    "Yu Sun",
                    "Kilian Q Weinberger"
                ],
                "title": "On calibration of modern neural networks",
                "pub_date": "2017",
                "pub_title": "International Conference on Machine Learning",
                "pub": "PMLR"
            }
        },
        {
            "ix": "183-ARR_v2_81",
            "content": "Abhyuday Jagannatha, Hong Yu, Calibrating structured output predictors for natural language processing, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Abhyuday Jagannatha",
                    "Hong Yu"
                ],
                "title": "Calibrating structured output predictors for natural language processing",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_82",
            "content": "Xiaoqian Jiang, Melanie Osl, Jihoon Kim, Lucila Ohno-Machado, Calibrating predictive model estimates to support personalized medicine, 2012, Journal of the American Medical Informatics Association, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "Xiaoqian Jiang",
                    "Melanie Osl",
                    "Jihoon Kim",
                    "Lucila Ohno-Machado"
                ],
                "title": "Calibrating predictive model estimates to support personalized medicine",
                "pub_date": "2012",
                "pub_title": "Journal of the American Medical Informatics Association",
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_83",
            "content": "Taejong Joo, Uijung Chung, Min-Gwan Seo, Being bayesian about categorical probability, 2020, International Conference on Machine Learning, PMLR.",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Taejong Joo",
                    "Uijung Chung",
                    "Min-Gwan Seo"
                ],
                "title": "Being bayesian about categorical probability",
                "pub_date": "2020",
                "pub_title": "International Conference on Machine Learning",
                "pub": "PMLR"
            }
        },
        {
            "ix": "183-ARR_v2_84",
            "content": "Taehee Jung, Dongyeop Kang, Hua Cheng, Lucas Mentch, Thomas Schaaf, Posterior calibrated training on sentence classification tasks, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Taehee Jung",
                    "Dongyeop Kang",
                    "Hua Cheng",
                    "Lucas Mentch",
                    "Thomas Schaaf"
                ],
                "title": "Posterior calibrated training on sentence classification tasks",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_85",
            "content": "UNKNOWN, None, 2019, xslue: A benchmark and analysis platform for cross-style language understanding and evaluation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "xslue: A benchmark and analysis platform for cross-style language understanding and evaluation",
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_86",
            "content": "Agustinus Kristiadi, Matthias Hein, Philipp Hennig, Being bayesian, even just a bit, fixes overconfidence in relu networks, 2020, International conference on machine learning, PMLR.",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Agustinus Kristiadi",
                    "Matthias Hein",
                    "Philipp Hennig"
                ],
                "title": "Being bayesian, even just a bit, fixes overconfidence in relu networks",
                "pub_date": "2020",
                "pub_title": "International conference on machine learning",
                "pub": "PMLR"
            }
        },
        {
            "ix": "183-ARR_v2_87",
            "content": "Volodymyr Kuleshov, Nathan Fenner, Stefano Ermon, Accurate uncertainties for deep learning using calibrated regression, 2018, International conference on machine learning, PMLR.",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "Volodymyr Kuleshov",
                    "Nathan Fenner",
                    "Stefano Ermon"
                ],
                "title": "Accurate uncertainties for deep learning using calibrated regression",
                "pub_date": "2018",
                "pub_title": "International conference on machine learning",
                "pub": "PMLR"
            }
        },
        {
            "ix": "183-ARR_v2_88",
            "content": "Volodymyr Kuleshov, S Percy,  Liang, Calibrated structured prediction, 2015, Advances in Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Volodymyr Kuleshov",
                    "S Percy",
                    " Liang"
                ],
                "title": "Calibrated structured prediction",
                "pub_date": "2015",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_89",
            "content": "Meelis Kull, Miquel Nieto, Markus K\u00e4ngsepp, Telmo Silva Filho, Hao Song, Peter Flach, Beyond temperature scaling: Obtaining well-calibrated multi-class probabilities with dirichlet calibration, 2019, Advances in Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Meelis Kull",
                    "Miquel Nieto",
                    "Markus K\u00e4ngsepp",
                    "Telmo Silva Filho",
                    "Hao Song",
                    "Peter Flach"
                ],
                "title": "Beyond temperature scaling: Obtaining well-calibrated multi-class probabilities with dirichlet calibration",
                "pub_date": "2019",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_90",
            "content": "Ananya Kumar, S Percy, Tengyu Liang,  Ma, Verified uncertainty calibration, 2019, Advances in Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Ananya Kumar",
                    "S Percy",
                    "Tengyu Liang",
                    " Ma"
                ],
                "title": "Verified uncertainty calibration",
                "pub_date": "2019",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_91",
            "content": "UNKNOWN, None, 2019, Calibration of encoder decoder models for neural machine translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Calibration of encoder decoder models for neural machine translation",
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_92",
            "content": "T Lydia, Max Liu, Moritz Simchowitz,  Hardt, The implicit fairness criterion of unconstrained learning, 2019, International Conference on Machine Learning, PMLR.",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": [
                    "T Lydia",
                    "Max Liu",
                    "Moritz Simchowitz",
                    " Hardt"
                ],
                "title": "The implicit fairness criterion of unconstrained learning",
                "pub_date": "2019",
                "pub_title": "International Conference on Machine Learning",
                "pub": "PMLR"
            }
        },
        {
            "ix": "183-ARR_v2_93",
            "content": "J David,  Mackay, The evidence framework applied to classification networks, 1992, Neural computation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": [
                    "J David",
                    " Mackay"
                ],
                "title": "The evidence framework applied to classification networks",
                "pub_date": "1992",
                "pub_title": "Neural computation",
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_94",
            "content": "Ali Malik, Volodymyr Kuleshov, Jiaming Song, Danny Nemer, Harlan Seymour, Stefano Ermon, Calibrated model-based deep reinforcement learning, 2019, International Conference on Machine Learning, PMLR.",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Ali Malik",
                    "Volodymyr Kuleshov",
                    "Jiaming Song",
                    "Danny Nemer",
                    "Harlan Seymour",
                    "Stefano Ermon"
                ],
                "title": "Calibrated model-based deep reinforcement learning",
                "pub_date": "2019",
                "pub_title": "International Conference on Machine Learning",
                "pub": "PMLR"
            }
        },
        {
            "ix": "183-ARR_v2_95",
            "content": "UNKNOWN, None, 2014, Binary classifier calibration: Nonparametric approach, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": null,
                "title": null,
                "pub_date": "2014",
                "pub_title": "Binary classifier calibration: Nonparametric approach",
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_96",
            "content": "Mahdi Pakdaman Naeini, F Gregory, Milos Cooper,  Hauskrecht, Obtaining well calibrated probabilities using bayesian binning, 2015, Proceedings of the, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": [
                    " Mahdi Pakdaman Naeini",
                    "F Gregory",
                    "Milos Cooper",
                    " Hauskrecht"
                ],
                "title": "Obtaining well calibrated probabilities using bayesian binning",
                "pub_date": "2015",
                "pub_title": "Proceedings of the",
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_97",
            "content": "UNKNOWN, None, , AAAI Conference on Artificial Intelligence. AAAI Conference on Artificial Intelligence, NIH Public Access.",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "AAAI Conference on Artificial Intelligence. AAAI Conference on Artificial Intelligence",
                "pub": "NIH Public Access"
            }
        },
        {
            "ix": "183-ARR_v2_98",
            "content": "Khanh Nguyen, O' Brendan,  Connor, Posterior calibration and exploratory analysis for natural language processing models, 2015, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": [
                    "Khanh Nguyen",
                    "O' Brendan",
                    " Connor"
                ],
                "title": "Posterior calibration and exploratory analysis for natural language processing models",
                "pub_date": "2015",
                "pub_title": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_99",
            "content": "John Platt, Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods, 1999, Advances in large margin classifiers, .",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": [
                    "John Platt"
                ],
                "title": "Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods",
                "pub_date": "1999",
                "pub_title": "Advances in large margin classifiers",
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_100",
            "content": "UNKNOWN, None, 2020, Post-hoc calibration of neural networks, .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Post-hoc calibration of neural networks",
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_101",
            "content": "Amir Rahimi, Amirreza Shaban, Ching-An Cheng, Richard Hartley, Byron Boots, Intra orderpreserving functions for calibration of multi-class neural networks, 2020, Advances in Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": [
                    "Amir Rahimi",
                    "Amirreza Shaban",
                    "Ching-An Cheng",
                    "Richard Hartley",
                    "Byron Boots"
                ],
                "title": "Intra orderpreserving functions for calibration of multi-class neural networks",
                "pub_date": "2020",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_102",
            "content": "David Widmann, Fredrik Lindsten, Dave Zachariah, Calibration tests in multi-class classification: A unifying framework, 2019, Advances in Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "David Widmann",
                    "Fredrik Lindsten",
                    "Dave Zachariah"
                ],
                "title": "Calibration tests in multi-class classification: A unifying framework",
                "pub_date": "2019",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_103",
            "content": "Dong Yu, Jinyu Li, Li Deng, Calibration of confidence measures in speech recognition, 2011, IEEE Transactions on Audio, Speech, and Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": [
                    "Dong Yu",
                    "Jinyu Li",
                    "Li Deng"
                ],
                "title": "Calibration of confidence measures in speech recognition",
                "pub_date": "2011",
                "pub_title": "IEEE Transactions on Audio, Speech, and Language Processing",
                "pub": null
            }
        },
        {
            "ix": "183-ARR_v2_104",
            "content": "Bianca Zadrozny, Charles Elkan, Obtaining calibrated probability estimates from decision trees and naive bayesian classifiers, 2001, Icml, Citeseer.",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": [
                    "Bianca Zadrozny",
                    "Charles Elkan"
                ],
                "title": "Obtaining calibrated probability estimates from decision trees and naive bayesian classifiers",
                "pub_date": "2001",
                "pub_title": "Icml",
                "pub": "Citeseer"
            }
        },
        {
            "ix": "183-ARR_v2_105",
            "content": "Bianca Zadrozny, Charles Elkan, Transforming classifier scores into accurate multiclass probability estimates, 2002, Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, .",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": [
                    "Bianca Zadrozny",
                    "Charles Elkan"
                ],
                "title": "Transforming classifier scores into accurate multiclass probability estimates",
                "pub_date": "2002",
                "pub_title": "Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "183-ARR_v2_0@0",
            "content": "Platt-Bin: Efficient Posterior Calibrated Training for NLP Classifiers",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_0",
            "start": 0,
            "end": 69,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_2@0",
            "content": "Modern NLP classifiers are known to return uncalibrated estimations of class posteriors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_2",
            "start": 0,
            "end": 87,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_2@1",
            "content": "Existing methods for posterior calibration rescale the predicted probabilities but often have an adverse impact on final classification accuracy, thus leading to poorer generalization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_2",
            "start": 89,
            "end": 272,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_2@2",
            "content": "We propose an end-to-end trained calibrator, Platt-Binning, that directly optimizes the objective while minimizing the difference between the predicted and empirical posterior probabilities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_2",
            "start": 274,
            "end": 463,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_2@3",
            "content": "Our method leverages the sample efficiency of Platt scaling and the verification guarantees of histogram binning, thus not only reducing the calibration error but also improving task performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_2",
            "start": 465,
            "end": 659,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_2@4",
            "content": "In contrast to existing calibrators, we perform this efficient calibration during training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_2",
            "start": 661,
            "end": 751,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_2@5",
            "content": "Empirical evaluation of benchmark NLP classification tasks echoes the efficacy of our proposal.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_2",
            "start": 753,
            "end": 847,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_4@0",
            "content": "Deep learning has proven to be tremendously attractive for researchers in fields such as physics, biology, and manufacturing, to name a few (Baldi et al., 2014;Anjos et al., 2015;Bergmann et al., 2014).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_4",
            "start": 0,
            "end": 201,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_4@1",
            "content": "However, these are fields in which representing model uncertainty is of crucial importance (Gal and Ghahramani, 2016).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_4",
            "start": 203,
            "end": 320,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_4@2",
            "content": "A common way to incorporate DNNs in other fields is to use the predictions of a trained classifier for decision making in a downstream task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_4",
            "start": 322,
            "end": 461,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_4@3",
            "content": "In some cases the effectiveness of the decisions depends on a utility function and it is not enough to simply predict the most likely label for each example.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_4",
            "start": 463,
            "end": 619,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_4@4",
            "content": "What is needed instead is to quantify model uncertainty about the predictions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_4",
            "start": 621,
            "end": 698,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_4@5",
            "content": "Despite promising performance in supervised learning benchmarks in terms of accuracy, DNNs are poor at quantifying predictive uncertainty, and tend to produce overconfident predictions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_4",
            "start": 700,
            "end": 884,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_4@6",
            "content": "Overconfident incorrect predictions can be harmful or offensive in NLP applications (Amodei et al., 2016), hence proper uncertainty quantification is crucial in practice.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_4",
            "start": 886,
            "end": 1055,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_4@7",
            "content": "Probabilistic uncertainty in machine learning translates to estimation of the probability mass function p(y|x) by the model, where x is the input sample and y is a class label.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_4",
            "start": 1057,
            "end": 1232,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_4@8",
            "content": "Recent works have shown that stateof-the art structured prediction models are poorly calibrated.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_4",
            "start": 1234,
            "end": 1329,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_4@9",
            "content": "Therefore, blindly using the output of the softmax function output as the model uncertainty is misleading (Kumar and Sarawagi, 2019;Dong et al., 2018;Nguyen and O'Connor, 2015).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_4",
            "start": 1331,
            "end": 1507,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_5@0",
            "content": "We are interested in calibrating the posterior estimates, i.e. we wish to get posterior probability estimations that reflect the true probability of the classes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_5",
            "start": 0,
            "end": 160,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_5@1",
            "content": "The probability that a system outputs for an event should reflect the true frequency of that event: if an automated diagnosis system says 1,000 patients have cancer with probability 0.1, approximately 100 of them should indeed have cancer .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_5",
            "start": 162,
            "end": 401,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_5@2",
            "content": "Even if the actual mechanism might be difficult to interpret, a calibrated model at least gives us a signal that it \"knows what it doesn't know,\" thereby making these models easier to deploy in practice (Jiang et al., 2012).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_5",
            "start": 403,
            "end": 626,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_5@3",
            "content": "We define perfect calibration as follows.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_5",
            "start": 628,
            "end": 668,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_6@0",
            "content": "P(y|f (x)) = f (x)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_6",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_7@0",
            "content": "where f : X \u2192 \u25b3 K\u22121 is the probabilistic classifier that maps the samples x \u2208 X to the Kdimensional simplex.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_7",
            "start": 0,
            "end": 107,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_7@1",
            "content": "As majority of the current state-of-the art machine learning models, such as DNNs, do not output calibrated probabilities out of the box (Kuleshov et al., 2018), existing works rely on re-calibration methods that take the output of an uncalibrated model, and transform it into a calibrated probability.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_7",
            "start": 109,
            "end": 410,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_7@2",
            "content": "One way of addressing this is to use Scaling approaches for re-calibration such as Platt scaling (Platt et al., 1999), isotonic regression (Zadrozny and Elkan, 2002), and temperature scaling (Guo et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_7",
            "start": 412,
            "end": 621,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_7@3",
            "content": "These methods are widely used and require very few samples, however it is challenging to calibrate posterior estimates with sub-optimal binning schemes ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_7",
            "start": 623,
            "end": 776,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_7@4",
            "content": "An alternative approach, histogram binning (Zadrozny and Elkan, 2001), outputs probabilities from a finite set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_7",
            "start": 778,
            "end": 888,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_7@5",
            "content": "Histogram binning can produce a model that is calibrated, and unlike scaling methods we can measure its calibration error, but it is sample inefficient.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_7",
            "start": 890,
            "end": 1041,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_7@6",
            "content": "In particular, the number of samples required for calibration scales linearly with the number of classes for which probability estimates need to be generated.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_7",
            "start": 1043,
            "end": 1200,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_8@0",
            "content": "Irrespective of the choice of the calibration method, existing works generally calibrate the posterior distribution predicted from the classifier after training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_8",
            "start": 0,
            "end": 160,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_8@1",
            "content": "These post-processing calibration methods re-learn an appropriate distribution from a held-out validation set and then apply it to an unseen test set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_8",
            "start": 162,
            "end": 311,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_8@2",
            "content": "The fixed split of the data sets and insufficient number of samples for training the calibration function adversely affects the generalization of post-hoc calibrated classifiers and reduce their accuracy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_8",
            "start": 313,
            "end": 516,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_8@3",
            "content": "In this paper we try to address some of the existing challenges in achieving apt calibration.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_8",
            "start": 518,
            "end": 610,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_8@4",
            "content": "In particular our contributions are:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_8",
            "start": 612,
            "end": 647,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_9@0",
            "content": "\u2022 We propose a training technique that optimizes a classification objective for an NLP task by calibrating the posterior distribution while training. \u2022 We leverage the advantages of both scaling and binning methods and propose a calibration method for NLP classification task which is both sample efficient and verifiable. \u2022 We demonstrate how the proposed method not only calibrates but also improves the performance of benchmark NLP classification tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_9",
            "start": 0,
            "end": 455,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_10@0",
            "content": "Related Works",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_10",
            "start": 0,
            "end": 12,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_11@0",
            "content": "Model uncertainty estimation and posterior calibration is a topic of continued interest not only in the fields of machine learning and statistics, but also in meteorology (Br\u00f6cker, 2009), fairness (Liu et al., 2019), healthcare (Jiang et al., 2012), reinforcement learning (Malik et al., 2019), natural language processing (Card and Smith, 2018), speech recognition (Yu et al., 2011) and economics (Gneiting et al., 2007).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_11",
            "start": 0,
            "end": 421,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_11@1",
            "content": "In probabilistic models, the principal goal of estimation of the posterior p(y|x) given a sample x \u2208 X and a label y \u2208 [K], is to assign low confidence to samples that were not explained well by the training data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_11",
            "start": 423,
            "end": 635,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_11@2",
            "content": "One common way to calibrate multi-class posteriors after training the classifier f : X \u2192 R is to treat the problem as K one-vs-all binary problems.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_11",
            "start": 637,
            "end": 783,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_11@3",
            "content": "In this case, model uncertainty is quantified by normalizing the estimation of p(y = k|f (x) k ) where f (x) k is the output score of the classifier for sample x and class k. Generalization of calibration tests with kernel methods can be found in (Widmann et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_11",
            "start": 785,
            "end": 1054,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_11@4",
            "content": "Various binary calibration methods can be used to estimate the marginal posterior over a calibration dataset, ranging from parametric approaches (e.g. Platt scaling, temperature scaling, vector scaling (Platt et al., 1999;Guo et al., 2017)), to non-parametric methods (e.g. quantile or bayesian binning (Zadrozny and Elkan, 2001;Naeini et al., 2015), and isotonic regression (Zadrozny and Elkan, 2002).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_11",
            "start": 1056,
            "end": 1457,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_12@0",
            "content": "Another way to reduce the problem to binary calibration is by estimating model accuracy conditioned on its confidence, p(y = \u0177| max k\u2208[K] f (x) k ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_12",
            "start": 0,
            "end": 147,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_12@1",
            "content": "Multi-class calibration aims to estimate the distribution of class labels conditioned on the estimated probability vector, p(y|f (x)).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_12",
            "start": 149,
            "end": 282,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_12@2",
            "content": "In this case the sample complexity is exponential in the number of classes and therefore with large number of classes, the main challenge is to constrain the hypothesis space with regularization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_12",
            "start": 284,
            "end": 478,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_12@3",
            "content": "Some of the proposed methods for this purpose are matrix scaling and Dirichlet scaling which both use linear models for estimation of p(y = k|f (x)) (Guo et al., 2017;Kull et al., 2019), and MLP and order preserving functions (Rahimi et al., 2020a,b).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_12",
            "start": 480,
            "end": 730,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_13@0",
            "content": "Another approach is to account for model uncertainty via bayesian models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_13",
            "start": 0,
            "end": 72,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_13@1",
            "content": "In Bayesian Neural Networks (BNNs) the predictive uncertainty will naturally be high in regions where training data is scarce (MacKay, 1992).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_13",
            "start": 74,
            "end": 214,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_13@2",
            "content": "However, the marginalization of the weights in BNN is intractable in general.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_13",
            "start": 216,
            "end": 292,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_14@0",
            "content": "Consequently, following papers propose various approximations such as variational inference (VI) (Graves, 2011;Blundell et al., 2015).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_14",
            "start": 0,
            "end": 133,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_14@1",
            "content": "Although BNNs are theoretically proven to control the overconfidence of the model in unseen regions of data space (Kristiadi et al., 2020), they require expensive approximations which limit their application in most modern NLP architectures.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_14",
            "start": 135,
            "end": 375,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_14@2",
            "content": "For instance, in (Joo et al., 2020) the authors model the distribution on posterior probability using a Dirichlet prior distribution and variational inference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_14",
            "start": 377,
            "end": 535,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_14@3",
            "content": "MCDropout is a variational approximation of Gaussian processes that avoids explicit modeling of the posterior distribution (Gal and Ghahramani, 2016).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_14",
            "start": 537,
            "end": 686,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_14@4",
            "content": "Both of these methods require modification of training of the network.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_14",
            "start": 688,
            "end": 757,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_15@0",
            "content": "In NLP, tasks with structured outputs posterior calibration are particularly challenging.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_15",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_15@1",
            "content": "This is because the number of classes are exponentially large and estimation of every posterior density or marginal posterior density is not possible.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_15",
            "start": 90,
            "end": 239,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_15@2",
            "content": "Previous works such as (Jung et al., 2020;Nguyen and O'Connor, 2015) propose to use the downstream task with small number of classes to perform calibration and estimation of the calibration error.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_15",
            "start": 241,
            "end": 436,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_15@3",
            "content": "In structured prediction models, calibration is also important for the generation of the structured outputs as the decoding algorithm relies on the posterior estimates to efficiently search through the space of sequences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_15",
            "start": 438,
            "end": 658,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_15@4",
            "content": "However, estimation of the sequence calibration error and its correction is intractable.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_15",
            "start": 660,
            "end": 747,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_16@0",
            "content": "To cope with this problem, approximate calibration methods using a set of interesting events and feature based calibration are proposed in (Kuleshov and Liang, 2015;Jagannatha and Yu, 2020) and an alternative calibration error estimator was proposed using sequence precision scoring function BLEU in (Kumar and Sarawagi, 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_16",
            "start": 0,
            "end": 326,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_16@1",
            "content": "We are considering the first class of problems and leave the structured calibration to future work.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_16",
            "start": 328,
            "end": 426,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_17@0",
            "content": "Method",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_17",
            "start": 0,
            "end": 5,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_18@0",
            "content": "In general, NLP classifiers work by first predicting a posterior probability distribution over all classes and then selecting the class with the largest estimated probability.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_18",
            "start": 0,
            "end": 174,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_18@1",
            "content": "However, these models are often poorly calibrated.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_18",
            "start": 176,
            "end": 225,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_18@2",
            "content": "Existing calibration methods re-learn an appropriate distribution from a heldout validation set and then apply it to an unseen test set which degrades the model performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_18",
            "start": 227,
            "end": 399,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_19@0",
            "content": "Alternatively, we can dynamically estimate the required statistics for calibration from the train set during training iterations, thereby minimizing cross-entropy as well as the calibration error as a multi-task setup (Jung et al., 2020). Given a training set D = {(x 1 , y 1 )..(x n , y n )}, where x i is an n-dimensional vector of input features and y i is a K-dimensional one-hot vector corresponding to its true label (with K classes), we minimize the loss L train :",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_19",
            "start": 0,
            "end": 470,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_20@0",
            "content": "L train = L class + \u03bbL cal (1)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_20",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_21@0",
            "content": "Here L class is the classification loss (for eg. crossentropy) based on the predicted probability p ik updated during training for sample i and class k:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_21",
            "start": 0,
            "end": 151,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_22@0",
            "content": "L class = \u2212 N i=1 K k=1 y ik log(p ik )",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_22",
            "start": 0,
            "end": 38,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_23@0",
            "content": "L cal is the calibration loss which acts as a regularizer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_23",
            "start": 0,
            "end": 57,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_23@1",
            "content": "It essentially tries to minimize the difference between the updated probability p and true posterior probabilities q via a distance function d (eg. mean squared error, KL-divergence, etc.):",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_23",
            "start": 59,
            "end": 247,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_24@0",
            "content": "L cal = N i=1 K k=1 d(p ik , q ik )",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_24",
            "start": 0,
            "end": 34,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_25@0",
            "content": "One crucial step here is to estimate the empirical probability q, which can be done by histogram binning method.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_25",
            "start": 0,
            "end": 111,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_25@1",
            "content": "Here, we measure the ratio of true labels for each bin split by the predicted posterior p from each update.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_25",
            "start": 113,
            "end": 219,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_25@2",
            "content": "This refers to CalEmpProb() function in algorithm 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_25",
            "start": 221,
            "end": 272,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_25@3",
            "content": "We store the results in Empirical Probability Matrix Q \u2208 R B\u00d7K , where B is the number of bins used for each posterior dimension.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_25",
            "start": 274,
            "end": 402,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_25@4",
            "content": "Histogram binning outputs probabilities from a finite set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_25",
            "start": 404,
            "end": 461,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_25@5",
            "content": "Unlike scaling methods, it can produce a model that is calibrated and measure its calibration error.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_25",
            "start": 463,
            "end": 562,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_25@6",
            "content": "However, the number of samples required to calibrate scales linearly with the number of distinct probabilities B the model can output which can be large in the multi-class setting (Naeini et al., 2014).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_25",
            "start": 564,
            "end": 765,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_26@0",
            "content": "In this work, we propose an adaptive binning method that circumvents this bottleneck.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_26",
            "start": 0,
            "end": 84,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_26@1",
            "content": "We leverage the sample efficiency of Platt scaling (Platt et al., 1999) and the verification guarantees of histogram binning (Zadrozny and Elkan, 2001) by defining the Platt-Binning Calibrator.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_26",
            "start": 86,
            "end": 278,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_26@2",
            "content": "The problem with scaling methods is we cannot estimate their calibration error.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_26",
            "start": 280,
            "end": 358,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_26@3",
            "content": "The upside of scaling methods is that if the function family has at least one function that can achieve calibration error \u03f5 they require O(1/\u03f5 2 ) samples to reach calibration error \u03f5, while histogram binning requires O(B/\u03f5 2 ) samples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_26",
            "start": 360,
            "end": 595,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_26@4",
            "content": "Platt-Binning Calibrator facilitates estimation of calibration error while being sampleefficient at the same time.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_26",
            "start": 597,
            "end": 710,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_27@0",
            "content": "Platt scaling calibrator: Since most modern deep learning classifiers do not output calibrated probabilities out of the box, recalibration methods take the output of an uncalibrated model, and transform it into a calibrated probability.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_27",
            "start": 0,
            "end": 235,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_27@1",
            "content": "That is, given a trained model f : X \u2192 [0, 1], let z = f (x).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_27",
            "start": 237,
            "end": 297,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_27@2",
            "content": "We are given recalibration data T = {(z i , y i )} n i=1 corresponding to model logits and the labels, and we wish to learn a calibrator g : [0, 1] \u2192 [0, 1] such that g \u2022 f is well-calibrated.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_27",
            "start": 299,
            "end": 490,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_27@3",
            "content": "Conventional Scaling methods, for example Platt scaling, output a function g:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_27",
            "start": 492,
            "end": 568,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_28@0",
            "content": "g = arg min g\u2208G (z,y)\u2208T l(g(z), y)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_28",
            "start": 0,
            "end": 33,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_29@0",
            "content": "where G is a the hypothesis class, g \u2208 G is differentiable, and l is a loss function, for example the log-loss or mean-squared error.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_29",
            "start": 0,
            "end": 132,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_29@1",
            "content": "The advantage of such methods is that they converge very quickly since they only fit a small number of parameters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_29",
            "start": 134,
            "end": 247,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_29@2",
            "content": "Histogram binning calibrator, on the other hand, constructs a set of bins that partitions [0, 1] via a binning scheme.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_29",
            "start": 249,
            "end": 366,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_29@3",
            "content": "A binning scheme B of size B is a set of B intervals I 1 , ...I B that partitions [0, 1].",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_29",
            "start": 368,
            "end": 456,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_29@4",
            "content": "We use the notation \u03c3 to denote the softmax function.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_29",
            "start": 458,
            "end": 510,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_29@5",
            "content": "Given p = \u03c3(z) k \u2208 [0, 1], let \u03b2(z) = j, where j is the interval that p lands in (p \u2208 I j ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_29",
            "start": 512,
            "end": 603,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_29@6",
            "content": "The binning scheme, B typically corresponds to choosing bins of equal widths (called equal width binning) or so that each bin contains an equal number of z i values in the calibration dataset (called uniform mass binning).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_29",
            "start": 605,
            "end": 826,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_29@7",
            "content": "Histogram binning then outputs the average y i value in each bin.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_29",
            "start": 828,
            "end": 892,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_30@0",
            "content": "Platt-Binning Calibrator builds at the intersection of the above two methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_30",
            "start": 0,
            "end": 76,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_30@1",
            "content": "Given a recalibration data T of size n, Platt-Binning Calibrator outputs \u011d\u03b2 such that \u011d\u03b2 \u2022 f has a low calibration error by using the following procedure:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_30",
            "start": 78,
            "end": 231,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_31@0",
            "content": "Step 1: Select g:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_31",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_32@0",
            "content": "g = arg min g\u2208G (z,y)\u2208T (y \u2212 g(z)) 2",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_32",
            "start": 0,
            "end": 35,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_33@0",
            "content": "(2)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_33",
            "start": 0,
            "end": 2,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_34@0",
            "content": "Step 2: Choose the bins so that an equal number of g(z i ) in T land in each bin b j for each j \u2208 1, ..., B",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_34",
            "start": 0,
            "end": 106,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_35@0",
            "content": "ECE = 1 K K k=1 B b=1 N kb N k |Q bk \u2212 pbk |",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_35",
            "start": 0,
            "end": 43,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_36@0",
            "content": "where pbk is the average posterior estimate for class k for samples in b-th bin.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_36",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_36@1",
            "content": "N kb and N k are the number of samples of class k assigned to bin b and in total, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_36",
            "start": 81,
            "end": 175,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_36@2",
            "content": "Contrary to equal-width binning, uniform-mass binning is a well-balanced binning scheme with guarantees on error bounds of estimated Expected Calibration Error, ECE .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_36",
            "start": 177,
            "end": 342,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_37@0",
            "content": "Step 3: Discretize g, by outputting the average g value in each bin.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_37",
            "start": 0,
            "end": 67,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_37@1",
            "content": "Let \u00b5(S) = 1 |S| s\u2208S s denote the mean of a set of values S. We set \u011d\u03b2 (z) = \u00b5(\u03b2(g(z)))we output the mean value of the bins that g(z) falls in.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_37",
            "start": 69,
            "end": 211,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_38@0",
            "content": "The motivation behind our method is that the g values in each bin are in a narrower range than the label values y, so when we take the average we incur lower estimation error.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_38",
            "start": 0,
            "end": 174,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_38@1",
            "content": "If G is well chosen, our method requires O( 1 \u03f5 2 + B)samples to achieve calibration error \u03f5 instead of O( B \u03f5 2 ) samples for histogram binning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_38",
            "start": 176,
            "end": 320,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_38@2",
            "content": "All these steps are performed during training as explained in the pseudo-code in Algorithm 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_38",
            "start": 322,
            "end": 414,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_38@3",
            "content": "To the best of our knowledge, such a formulation is novel among existing calibrators that tackle the problem during training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_38",
            "start": 416,
            "end": 540,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_38@4",
            "content": "Also, the whole approach is the first to be utilised to calibrate classifiers in the NLP domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_38",
            "start": 542,
            "end": 637,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_38@5",
            "content": "In the following section we prove the efficacy of our method by carrying out extensive evaluation of the performance of pretrained transformer models such as BERT (Devlin et al., 2019) on simple multi-class text classification tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_38",
            "start": 639,
            "end": 871,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_38@6",
            "content": "Our motivation comes from the analysis in (Desai and Durrett, 2020) which shows that pretrained models are significantly better calibrated when used out-of-the-box.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_38",
            "start": 873,
            "end": 1036,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_39@0",
            "content": "Experiments",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_39",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_40@0",
            "content": "In the experiments we fine-tune the parameters on pre-trained BERT classifier using the regularized loss in equation (1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_40",
            "start": 0,
            "end": 120,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_40@1",
            "content": "We compare our method to the following baselines:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_40",
            "start": 122,
            "end": 170,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_41@0",
            "content": "\u2022 MLE is the baseline with maximum likelihood training without calibration where we simply report the results of vanilla BERT classifier on the chosen tasks. \u2022 Platt scaling (posPS) is a post-hoc calibration method where we calibrate the posterior estimations of MLE classifier using Platt scaling (Platt et al., 1999).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_41",
            "start": 0,
            "end": 318,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_42@0",
            "content": "if i mod u == 0 then p(x) = max k \u03c3(\u0398, D) k , \u2200x \u2208 D. \u0177 = arg max k \u03c3(\u0398, D) k , \u2200x \u2208 D.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_42",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_43@0",
            "content": "Select g using equation 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_43",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_44@0",
            "content": "Uniform-mass binning over g(p i ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_44",
            "start": 0,
            "end": 33,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_45@0",
            "content": "Discretize g:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_45",
            "start": 0,
            "end": 12,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_46@0",
            "content": "\u011d\u03b2 (p i ) = \u00b5[\u03b2(g(p i ))] Q \u2190 CalEmpProb(p;b j ) end \u0398 \u2190 \u0398 \u2212 \u03b7\u2207 \u0398 L train (\u0398, \u011d\u03b2 (p i ), b)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_46",
            "start": 0,
            "end": 90,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_47@0",
            "content": "end end \u03c3(f (x)) k for class kwe return the calibrated value g(f (x)) as the class probability.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_47",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_47@1",
            "content": "Despite its simplicity this method is competitive with the more complex methods when implemented post-hoc (Guo et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_47",
            "start": 96,
            "end": 220,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_48@0",
            "content": "\u2022 PosCal end-to-end training calibration using histogram binning (Jung et al., 2020). In this method we have a nested training procedure where in the outer loop we fit a histogram binning scheme with fix widths to each dimension of the posterior estimates of the BERT model. We use Q bk -the ratio of samples of kth class that were assigned to bth bin-as the empirical probability distribution q. In the inner loop we perform the ordinary training iterations over mini-batches of training dataset with cross-entropy loss and regularization term in equation (1) using KL-divergence between softmax output and the estimated empirical distribution.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_48",
            "start": 0,
            "end": 644,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_49@0",
            "content": "L cal = N i=1 K k=1 log \u03c3(z i ) k Q bin(z ik )k",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_49",
            "start": 0,
            "end": 46,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_50@0",
            "content": "where bin(.) returns the index of bin assigned to its input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_50",
            "start": 0,
            "end": 59,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_50@1",
            "content": "In the experiments we used \u03bb = 1.0, 10 bin for discretisation of q and we update Q after every training epoch.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_50",
            "start": 61,
            "end": 170,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_51@0",
            "content": "We test the baselines and our method on the benchmark on NLP classification tasks: xSLUE (Kang and Hovy, 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_51",
            "start": 0,
            "end": 110,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_51@1",
            "content": "xSLUE contains classification benchmark on different types of styles such as a level of humor, formality and even demographics of authors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_51",
            "start": 112,
            "end": 249,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_51@2",
            "content": "We train our method with two types of calibrators: in the first calibration task we train a calibrator for the most confident prediction of the classifier and call this version plattbintop (PBtop).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_51",
            "start": 251,
            "end": 447,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_51@3",
            "content": "The pseudocode of this version is illustrated in algorithm (1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_51",
            "start": 449,
            "end": 511,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_51@4",
            "content": "In the second version we train a separate Platt scaler and histogram binning for each class in a one-vs-all manner and we call this version of calibration plattbin (PB).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_51",
            "start": 513,
            "end": 681,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_51@5",
            "content": "While this version is exactly the same as plattbintop for binary tasks, it results in a very different solution for tasks with K > 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_51",
            "start": 683,
            "end": 815,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_51@6",
            "content": "The pseudocode of this version is omitted due to being mainly similar to the other version with one additional loop over the classes at line 7 of algorithm (1) and conversion of label y and \u0177 to one-vs-all binary labels.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_51",
            "start": 817,
            "end": 1036,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_51@7",
            "content": "We report task accuracy, F1 score and ECE as the evaluation metrics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_51",
            "start": 1038,
            "end": 1105,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_52@0",
            "content": "Results and Discussion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_52",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_53@0",
            "content": "Table 1 shows task performance and calibration error on xSLUE benchmark datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_53",
            "start": 0,
            "end": 80,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_53@1",
            "content": "In general, our method outperforms MLE, Poscal and posPS on more than 50% of the datasets, in terms of both model performance and calibration error.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_53",
            "start": 82,
            "end": 229,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_53@2",
            "content": "For the rest of the datasets, our method gives competitive results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_53",
            "start": 231,
            "end": 297,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_53@3",
            "content": "In seven out of nine cases, we reduce the calibration error ECE as compared to PosCal.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_53",
            "start": 299,
            "end": 384,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_54@0",
            "content": "In cases such as DailyDialog, SentiTreeBank and ShortHumor, the achieved reduction in ECE as compared to all baselines is significant.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_54",
            "start": 0,
            "end": 133,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_54@1",
            "content": "Note that this reduction has not compromised the model performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_54",
            "start": 135,
            "end": 201,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_54@2",
            "content": "In fact, cases like SentiTreeBank and ShortRomance even witness a significant improvement in the performance of the model when ECE is reduced.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_54",
            "start": 203,
            "end": 344,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_54@3",
            "content": "These observations prove the efficacy of our method in maintaining a perfect balance between model performance and model uncertainitya testimony of an ideal calibrator.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_54",
            "start": 346,
            "end": 513,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_54@4",
            "content": "Post-hoc methods such as posPS might achieve lower calibration error on a couple of datasets, but they fail to attain competitive performance in terms of accuracy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_54",
            "start": 515,
            "end": 677,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_54@5",
            "content": "1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_54",
            "start": 679,
            "end": 681,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_55@0",
            "content": "We now analyse how our method behaves in comparison to MLE at sample level during test time.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_55",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_56@0",
            "content": "Table 2 shows a detailed analysis of misclassification made by MLE and Platt-Binning (PB).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_56",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_56@1",
            "content": "We see that both the methods have almost comparable performance in columns A1 and A2, with A2 being slightly higher.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_56",
            "start": 91,
            "end": 206,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_56@2",
            "content": "As such, the number of samples for which MLE and PB gave different predictions (column M ) is actually a small fraction of the total number of test samples used of evaluation of the methods (column T est).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_56",
            "start": 208,
            "end": 412,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_56@3",
            "content": "We further analyse the number of samples where MLE gave correct predictions while PB failed to do so (column P 1) and vice-versa (column P 2).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_56",
            "start": 414,
            "end": 555,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_56@4",
            "content": "In 8 out of 9 datasets, PB demonstrates superior or similar performance (P2 \u2265 P1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_56",
            "start": 557,
            "end": 638,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_56@5",
            "content": "The difference is insignificant compared to the total size of the test set for the reverse scenario.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_56",
            "start": 640,
            "end": 739,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_56@6",
            "content": "This quantitative analysis reinstates that our method, PB, has better model performance at test time, thereby establishing that it generalizes well while reducing calibration error.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_56",
            "start": 741,
            "end": 921,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_57@0",
            "content": "We extend the discussion above by analysing qualitative results in Table 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_57",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_57@1",
            "content": "We consider three datasetsa two-class classification task StanfordPoliteness, a three-class classification task HateOffensive and a multi-class classification task (K > 3) DailyDialog, and include few test samples where MLE and PB disagreed on the predictions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_57",
            "start": 76,
            "end": 335,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_57@2",
            "content": "The corresponding p along with the true label is also depicted.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_57",
            "start": 337,
            "end": 399,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_58@0",
            "content": "In the first two cases from StanfordPoliteness dataset, the level of politeness (e.g., \"Hey!\" in S1) or arrogance (e.g., \"What?\" in S2) indicated on phrases is not captured well by MLE, so it predicts the incorrect label while PB gives a correct prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_58",
            "start": 0,
            "end": 256,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_58@1",
            "content": "However, for the rest two cases, MLE gives confident correct predictions taking into account phrases such as \"like\" in S1 or a slightly difficult example in S2 but PB fails (only slightly in S2 though) to give correct predictions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_58",
            "start": 258,
            "end": 487,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_58@2",
            "content": "Arguing on similar lines for the multi-class case, we witness cases where MLE fails to classify correctly (eg. S1 and S2 in HateOffensive) but PB gives highly confident predictions and vice-versa.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_58",
            "start": 489,
            "end": 684,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_58@3",
            "content": "From our manual investigation above, we find that statistical knowledge about posterior probability helps correct p while training PB, so making p switch its prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_58",
            "start": 686,
            "end": 854,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_58@4",
            "content": "For further analysis, we provide more examples in Appendix ??",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_58",
            "start": 856,
            "end": 916,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_58@5",
            "content": ".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_58",
            "start": 917,
            "end": 917,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_59@0",
            "content": "In Figure 1 we show the calibration plots for three datasets: DailyDialog, HateOffensive, and Stan-fordPoliteness.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_59",
            "start": 0,
            "end": 113,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_59@1",
            "content": "We divide test samples according to the most confident estimated posterior into 10 bins.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_59",
            "start": 115,
            "end": 202,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_59@2",
            "content": "We plot the accuracy of the classifier versus the average classification confidence in each one of the bins in the top row.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_59",
            "start": 204,
            "end": 326,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_59@3",
            "content": "We also plot the number of samples in each calibration bin versus the classification confidence in the bottom row.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_59",
            "start": 328,
            "end": 441,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_59@4",
            "content": "Ideally, a calibrated classifier would assign a probability to the top class that is equivalent to its accuracy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_59",
            "start": 443,
            "end": 554,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_59@5",
            "content": "Therefore, the accuracy-confidence curve of a calibrated classifier is close to the dashed grey curve in the top row.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_59",
            "start": 556,
            "end": 672,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_59@6",
            "content": "When Platt-bin and Platt-bin-top are further away from the calibration line it is because the number of samples in corresponding bins are low or even 0 in some cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_59",
            "start": 674,
            "end": 839,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_59@7",
            "content": "The bins with 0 samples in them can be ignored as they don't play a role in the classifier predictions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_59",
            "start": 841,
            "end": 943,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_60@0",
            "content": "However, the distance of the curves is not enough to determine model calibration as most of the samples are assigned to the bin with highest estimated posterior.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_60",
            "start": 0,
            "end": 160,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_60@1",
            "content": "Thus, correcting the calibration error in the bins with more samples is more effective in improving the expected calibration error.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_60",
            "start": 162,
            "end": 292,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_60@2",
            "content": "Platt-Binning and Platt-Binning-Top algorithms increase the number of samples with lower classification confidence in all three of the illustrated tasks, while in comparison to MLE with no regularization they only reduce classification accuracy by a negligible amount and even increase the accuracy for HateOffensive task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_60",
            "start": 294,
            "end": 615,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_60@3",
            "content": "Although, the classifier become visibily underconfident in HateOffensive task where post-hoc Platt scaling has a more calibrated output.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_60",
            "start": 617,
            "end": 752,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_60@4",
            "content": "While the ECE doesn't improve in StanfordPoliteness, Platt-Binning algorithm doesn't increase the ECE as much as PosCal regularization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_60",
            "start": 754,
            "end": 888,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_60@5",
            "content": "We conjecture that such a behavior is demonstrated due to better sample efficiency of our algorithm.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_60",
            "start": 890,
            "end": 989,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_61@0",
            "content": "We conclude our analysis by observing the effect of two important parameters to this discussion-B: number of histogram bins used for calibration, and \u03bb: strength of the regularization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_61",
            "start": 0,
            "end": 183,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_61@1",
            "content": "Figure 2 shows how calibration error (ECE) vary when the number of bins B is varied as {10, ...100}. We see that the calibration error of all the methods have an increasing trend as B is increased.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_61",
            "start": 185,
            "end": 381,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_61@2",
            "content": "One plausible explanation can be that as we increase the number of bins, we don't have enough samples per bin to estimate the empirical probabilities accurately.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_61",
            "start": 383,
            "end": 543,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_62@0",
            "content": "Since calibrated probabilities are used as an estimation of the true probabilities of the classes in case of PosCal and PB, it adds to the error if they are estimated wrongly.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_62",
            "start": 0,
            "end": 174,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_62@1",
            "content": "Thus, smaller number of bins is preferred, and as evident in Fig. 2, PB achieves lower ECE than PosCal when number of bins is low.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_62",
            "start": 176,
            "end": 305,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_62@2",
            "content": "The accuracy and F1 scores do not vary much with the number of the bins.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_62",
            "start": 307,
            "end": 378,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_62@3",
            "content": "Similarly, the performance is not impacted significantly by variations in the value of \u03bb (see Appendix ??)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_62",
            "start": 380,
            "end": 485,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_63@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_63",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_64@0",
            "content": "In this work we proposed a simple yet effective method called Platt-Binning calibrator for better posterior calibration.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_64",
            "start": 0,
            "end": 119,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_64@1",
            "content": "Our method has theoretically lower sample complexity than histogram binning, giving us the best of scaling and binning methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_64",
            "start": 121,
            "end": 247,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_65@0",
            "content": "And unlike the existing post-processing calibration methods, Platt-Binning directly penalizes the difference between the predicted and the true (empirical) posterior probabilities dynamically over the training steps.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_65",
            "start": 0,
            "end": 215,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_65@1",
            "content": "Our empirical analysis corroborates that Platt-Binning can not only reduce the calibration error but also increase the task performance on the classification benchmarks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_65",
            "start": 217,
            "end": 385,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_65@2",
            "content": "For tasks where the reduction in calibration error is low, our method maintains the performance of the model instead of degrading it as seen for other existing calibrators.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_65",
            "start": 387,
            "end": 558,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_65@3",
            "content": "Moreover, our method can be extended to any classification model as an additional component in the loss function, thus jointly optimised during training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_65",
            "start": 560,
            "end": 712,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_65@4",
            "content": "There are many exciting avenues for future works in this regard.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_65",
            "start": 714,
            "end": 777,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_65@5",
            "content": "It will be interesting to assess how our method can provide advantages in the scenarios of domain adaptation and transfer learning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_65",
            "start": 779,
            "end": 909,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_65@6",
            "content": "Moreover, exploring alternatives to the model family G from which estimate \u011d is considered can be a direction of improvement.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_65",
            "start": 911,
            "end": 1035,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_65@7",
            "content": "Lastly, optimizing the overall method for huge datasets can be an essential extension.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_65",
            "start": 1037,
            "end": 1122,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_65@8",
            "content": "Our method may also assist in analysing the bias and fairness aspects of the predictions made by NLP classifiers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_65",
            "start": 1124,
            "end": 1236,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_65@9",
            "content": "This can facilitate ethical deployment of NLP models for real-world applications.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_65",
            "start": 1238,
            "end": 1318,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_66@0",
            "content": "UNKNOWN, None, 2016, Concrete problems in ai safety, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_66",
            "start": 0,
            "end": 53,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_67@0",
            "content": "Of\u00e9lia Anjos, Carla Iglesias, F\u00e1tima Peres, Javier Mart\u00ednez, \u00c1ngela Garc\u00eda, Javier Taboada, Neural networks applied to discriminate botanical origin of honeys, 2015, Food chemistry, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_67",
            "start": 0,
            "end": 182,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_68@0",
            "content": "Pierre Baldi, Peter Sadowski, Daniel Whiteson, Searching for exotic particles in high-energy physics with deep learning, 2014, Nature communications, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_68",
            "start": 0,
            "end": 150,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_69@0",
            "content": "S\u00f6ren Bergmann, S\u00f6ren Stelzer, Steffen Strassburger, On the use of artificial neural networks in simulation-based manufacturing control, 2014, Journal of Simulation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_69",
            "start": 0,
            "end": 166,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_70@0",
            "content": "UNKNOWN, None, 2015, Weight uncertainty in neural network. In International conference on machine learning, PMLR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_70",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_71@0",
            "content": "Jochen Br\u00f6cker, Reliability, sufficiency, and the decomposition of proper scores, 2009, Quarterly Journal of the Royal Meteorological Society: A journal of the atmospheric sciences, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_71",
            "start": 0,
            "end": 182,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_72@0",
            "content": "Dallas Card, A Noah,  Smith, The importance of calibration for estimating proportions from annotations, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_72",
            "start": 0,
            "end": 265,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_73@0",
            "content": "Shrey Desai, Greg Durrett, Calibration of pre-trained transformers, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_73",
            "start": 0,
            "end": 170,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_74@0",
            "content": "UNKNOWN, None, , , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_74",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_75@0",
            "content": "Kristina Toutanova, Bert: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long and Short Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_75",
            "start": 0,
            "end": 273,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_76@0",
            "content": "Li Dong, Chris Quirk, Mirella Lapata, Confidence modeling for neural semantic parsing, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_76",
            "start": 0,
            "end": 193,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_77@0",
            "content": "Yarin Gal, Zoubin Ghahramani, Dropout as a bayesian approximation: Representing model uncertainty in deep learning, 2016, international conference on machine learning, PMLR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_77",
            "start": 0,
            "end": 172,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_78@0",
            "content": "Tilmann Gneiting, Fadoua Balabdaoui, Adrian Raftery, Probabilistic forecasts, calibration and sharpness, 2007, Journal of the Royal Statistical Society: Series B (Statistical Methodology), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_78",
            "start": 0,
            "end": 189,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_79@0",
            "content": "Alex Graves, Practical variational inference for neural networks, 2011, Advances in neural information processing systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_79",
            "start": 0,
            "end": 123,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_80@0",
            "content": "Chuan Guo, Geoff Pleiss, Yu Sun, Kilian Q Weinberger, On calibration of modern neural networks, 2017, International Conference on Machine Learning, PMLR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_80",
            "start": 0,
            "end": 152,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_81@0",
            "content": "Abhyuday Jagannatha, Hong Yu, Calibrating structured output predictors for natural language processing, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_81",
            "start": 0,
            "end": 199,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_82@0",
            "content": "Xiaoqian Jiang, Melanie Osl, Jihoon Kim, Lucila Ohno-Machado, Calibrating predictive model estimates to support personalized medicine, 2012, Journal of the American Medical Informatics Association, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_82",
            "start": 0,
            "end": 198,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_83@0",
            "content": "Taejong Joo, Uijung Chung, Min-Gwan Seo, Being bayesian about categorical probability, 2020, International Conference on Machine Learning, PMLR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_83",
            "start": 0,
            "end": 143,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_84@0",
            "content": "Taehee Jung, Dongyeop Kang, Hua Cheng, Lucas Mentch, Thomas Schaaf, Posterior calibrated training on sentence classification tasks, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_84",
            "start": 0,
            "end": 227,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_85@0",
            "content": "UNKNOWN, None, 2019, xslue: A benchmark and analysis platform for cross-style language understanding and evaluation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_85",
            "start": 0,
            "end": 117,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_86@0",
            "content": "Agustinus Kristiadi, Matthias Hein, Philipp Hennig, Being bayesian, even just a bit, fixes overconfidence in relu networks, 2020, International conference on machine learning, PMLR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_86",
            "start": 0,
            "end": 180,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_87@0",
            "content": "Volodymyr Kuleshov, Nathan Fenner, Stefano Ermon, Accurate uncertainties for deep learning using calibrated regression, 2018, International conference on machine learning, PMLR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_87",
            "start": 0,
            "end": 176,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_88@0",
            "content": "Volodymyr Kuleshov, S Percy,  Liang, Calibrated structured prediction, 2015, Advances in Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_88",
            "start": 0,
            "end": 128,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_89@0",
            "content": "Meelis Kull, Miquel Nieto, Markus K\u00e4ngsepp, Telmo Silva Filho, Hao Song, Peter Flach, Beyond temperature scaling: Obtaining well-calibrated multi-class probabilities with dirichlet calibration, 2019, Advances in Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_89",
            "start": 0,
            "end": 251,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_90@0",
            "content": "Ananya Kumar, S Percy, Tengyu Liang,  Ma, Verified uncertainty calibration, 2019, Advances in Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_90",
            "start": 0,
            "end": 133,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_91@0",
            "content": "UNKNOWN, None, 2019, Calibration of encoder decoder models for neural machine translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_91",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_92@0",
            "content": "T Lydia, Max Liu, Moritz Simchowitz,  Hardt, The implicit fairness criterion of unconstrained learning, 2019, International Conference on Machine Learning, PMLR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_92",
            "start": 0,
            "end": 160,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_93@0",
            "content": "J David,  Mackay, The evidence framework applied to classification networks, 1992, Neural computation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_93",
            "start": 0,
            "end": 103,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_94@0",
            "content": "Ali Malik, Volodymyr Kuleshov, Jiaming Song, Danny Nemer, Harlan Seymour, Stefano Ermon, Calibrated model-based deep reinforcement learning, 2019, International Conference on Machine Learning, PMLR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_94",
            "start": 0,
            "end": 197,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_95@0",
            "content": "UNKNOWN, None, 2014, Binary classifier calibration: Nonparametric approach, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_95",
            "start": 0,
            "end": 76,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_96@0",
            "content": "Mahdi Pakdaman Naeini, F Gregory, Milos Cooper,  Hauskrecht, Obtaining well calibrated probabilities using bayesian binning, 2015, Proceedings of the, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_96",
            "start": 0,
            "end": 151,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_97@0",
            "content": "UNKNOWN, None, , AAAI Conference on Artificial Intelligence. AAAI Conference on Artificial Intelligence, NIH Public Access.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_97",
            "start": 0,
            "end": 122,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_98@0",
            "content": "Khanh Nguyen, O' Brendan,  Connor, Posterior calibration and exploratory analysis for natural language processing models, 2015, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_98",
            "start": 0,
            "end": 216,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_99@0",
            "content": "John Platt, Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods, 1999, Advances in large margin classifiers, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_99",
            "start": 0,
            "end": 157,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_100@0",
            "content": "UNKNOWN, None, 2020, Post-hoc calibration of neural networks, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_100",
            "start": 0,
            "end": 62,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_101@0",
            "content": "Amir Rahimi, Amirreza Shaban, Ching-An Cheng, Richard Hartley, Byron Boots, Intra orderpreserving functions for calibration of multi-class neural networks, 2020, Advances in Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_101",
            "start": 0,
            "end": 213,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_102@0",
            "content": "David Widmann, Fredrik Lindsten, Dave Zachariah, Calibration tests in multi-class classification: A unifying framework, 2019, Advances in Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_102",
            "start": 0,
            "end": 177,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_103@0",
            "content": "Dong Yu, Jinyu Li, Li Deng, Calibration of confidence measures in speech recognition, 2011, IEEE Transactions on Audio, Speech, and Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_103",
            "start": 0,
            "end": 153,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_104@0",
            "content": "Bianca Zadrozny, Charles Elkan, Obtaining calibrated probability estimates from decision trees and naive bayesian classifiers, 2001, Icml, Citeseer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_104",
            "start": 0,
            "end": 147,
            "label": {}
        },
        {
            "ix": "183-ARR_v2_105@0",
            "content": "Bianca Zadrozny, Charles Elkan, Transforming classifier scores into accurate multiclass probability estimates, 2002, Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "183-ARR_v2_105",
            "start": 0,
            "end": 219,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "183-ARR_v2_0",
            "tgt_ix": "183-ARR_v2_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_0",
            "tgt_ix": "183-ARR_v2_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_1",
            "tgt_ix": "183-ARR_v2_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_1",
            "tgt_ix": "183-ARR_v2_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_0",
            "tgt_ix": "183-ARR_v2_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_2",
            "tgt_ix": "183-ARR_v2_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_4",
            "tgt_ix": "183-ARR_v2_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_5",
            "tgt_ix": "183-ARR_v2_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_6",
            "tgt_ix": "183-ARR_v2_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_7",
            "tgt_ix": "183-ARR_v2_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_8",
            "tgt_ix": "183-ARR_v2_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_3",
            "tgt_ix": "183-ARR_v2_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_3",
            "tgt_ix": "183-ARR_v2_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_3",
            "tgt_ix": "183-ARR_v2_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_3",
            "tgt_ix": "183-ARR_v2_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_3",
            "tgt_ix": "183-ARR_v2_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_3",
            "tgt_ix": "183-ARR_v2_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_3",
            "tgt_ix": "183-ARR_v2_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_0",
            "tgt_ix": "183-ARR_v2_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_11",
            "tgt_ix": "183-ARR_v2_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_12",
            "tgt_ix": "183-ARR_v2_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_13",
            "tgt_ix": "183-ARR_v2_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_14",
            "tgt_ix": "183-ARR_v2_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_15",
            "tgt_ix": "183-ARR_v2_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_10",
            "tgt_ix": "183-ARR_v2_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_10",
            "tgt_ix": "183-ARR_v2_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_10",
            "tgt_ix": "183-ARR_v2_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_10",
            "tgt_ix": "183-ARR_v2_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_10",
            "tgt_ix": "183-ARR_v2_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_10",
            "tgt_ix": "183-ARR_v2_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_10",
            "tgt_ix": "183-ARR_v2_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_0",
            "tgt_ix": "183-ARR_v2_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_16",
            "tgt_ix": "183-ARR_v2_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_18",
            "tgt_ix": "183-ARR_v2_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_19",
            "tgt_ix": "183-ARR_v2_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_20",
            "tgt_ix": "183-ARR_v2_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_21",
            "tgt_ix": "183-ARR_v2_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_22",
            "tgt_ix": "183-ARR_v2_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_23",
            "tgt_ix": "183-ARR_v2_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_24",
            "tgt_ix": "183-ARR_v2_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_25",
            "tgt_ix": "183-ARR_v2_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_26",
            "tgt_ix": "183-ARR_v2_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_27",
            "tgt_ix": "183-ARR_v2_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_28",
            "tgt_ix": "183-ARR_v2_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_29",
            "tgt_ix": "183-ARR_v2_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_30",
            "tgt_ix": "183-ARR_v2_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_31",
            "tgt_ix": "183-ARR_v2_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_32",
            "tgt_ix": "183-ARR_v2_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_33",
            "tgt_ix": "183-ARR_v2_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_34",
            "tgt_ix": "183-ARR_v2_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_35",
            "tgt_ix": "183-ARR_v2_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_36",
            "tgt_ix": "183-ARR_v2_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_37",
            "tgt_ix": "183-ARR_v2_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_17",
            "tgt_ix": "183-ARR_v2_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_17",
            "tgt_ix": "183-ARR_v2_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_17",
            "tgt_ix": "183-ARR_v2_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_17",
            "tgt_ix": "183-ARR_v2_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_17",
            "tgt_ix": "183-ARR_v2_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_17",
            "tgt_ix": "183-ARR_v2_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_17",
            "tgt_ix": "183-ARR_v2_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_17",
            "tgt_ix": "183-ARR_v2_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_17",
            "tgt_ix": "183-ARR_v2_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_17",
            "tgt_ix": "183-ARR_v2_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_17",
            "tgt_ix": "183-ARR_v2_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_17",
            "tgt_ix": "183-ARR_v2_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_17",
            "tgt_ix": "183-ARR_v2_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_17",
            "tgt_ix": "183-ARR_v2_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_17",
            "tgt_ix": "183-ARR_v2_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_17",
            "tgt_ix": "183-ARR_v2_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_17",
            "tgt_ix": "183-ARR_v2_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_17",
            "tgt_ix": "183-ARR_v2_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_17",
            "tgt_ix": "183-ARR_v2_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_17",
            "tgt_ix": "183-ARR_v2_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_17",
            "tgt_ix": "183-ARR_v2_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_17",
            "tgt_ix": "183-ARR_v2_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_0",
            "tgt_ix": "183-ARR_v2_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_38",
            "tgt_ix": "183-ARR_v2_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_40",
            "tgt_ix": "183-ARR_v2_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_42",
            "tgt_ix": "183-ARR_v2_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_43",
            "tgt_ix": "183-ARR_v2_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_44",
            "tgt_ix": "183-ARR_v2_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_45",
            "tgt_ix": "183-ARR_v2_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_46",
            "tgt_ix": "183-ARR_v2_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_47",
            "tgt_ix": "183-ARR_v2_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_49",
            "tgt_ix": "183-ARR_v2_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_50",
            "tgt_ix": "183-ARR_v2_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_39",
            "tgt_ix": "183-ARR_v2_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_39",
            "tgt_ix": "183-ARR_v2_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_39",
            "tgt_ix": "183-ARR_v2_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_39",
            "tgt_ix": "183-ARR_v2_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_39",
            "tgt_ix": "183-ARR_v2_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_39",
            "tgt_ix": "183-ARR_v2_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_39",
            "tgt_ix": "183-ARR_v2_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_39",
            "tgt_ix": "183-ARR_v2_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_39",
            "tgt_ix": "183-ARR_v2_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_39",
            "tgt_ix": "183-ARR_v2_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_39",
            "tgt_ix": "183-ARR_v2_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_39",
            "tgt_ix": "183-ARR_v2_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_39",
            "tgt_ix": "183-ARR_v2_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_0",
            "tgt_ix": "183-ARR_v2_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_51",
            "tgt_ix": "183-ARR_v2_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_53",
            "tgt_ix": "183-ARR_v2_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_54",
            "tgt_ix": "183-ARR_v2_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_55",
            "tgt_ix": "183-ARR_v2_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_56",
            "tgt_ix": "183-ARR_v2_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_57",
            "tgt_ix": "183-ARR_v2_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_58",
            "tgt_ix": "183-ARR_v2_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_59",
            "tgt_ix": "183-ARR_v2_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_60",
            "tgt_ix": "183-ARR_v2_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_61",
            "tgt_ix": "183-ARR_v2_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_52",
            "tgt_ix": "183-ARR_v2_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_52",
            "tgt_ix": "183-ARR_v2_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_52",
            "tgt_ix": "183-ARR_v2_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_52",
            "tgt_ix": "183-ARR_v2_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_52",
            "tgt_ix": "183-ARR_v2_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_52",
            "tgt_ix": "183-ARR_v2_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_52",
            "tgt_ix": "183-ARR_v2_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_52",
            "tgt_ix": "183-ARR_v2_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_52",
            "tgt_ix": "183-ARR_v2_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_52",
            "tgt_ix": "183-ARR_v2_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_52",
            "tgt_ix": "183-ARR_v2_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_0",
            "tgt_ix": "183-ARR_v2_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_62",
            "tgt_ix": "183-ARR_v2_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_64",
            "tgt_ix": "183-ARR_v2_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_63",
            "tgt_ix": "183-ARR_v2_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_63",
            "tgt_ix": "183-ARR_v2_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_63",
            "tgt_ix": "183-ARR_v2_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "183-ARR_v2_0",
            "tgt_ix": "183-ARR_v2_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_1",
            "tgt_ix": "183-ARR_v2_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_2",
            "tgt_ix": "183-ARR_v2_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_2",
            "tgt_ix": "183-ARR_v2_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_2",
            "tgt_ix": "183-ARR_v2_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_2",
            "tgt_ix": "183-ARR_v2_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_2",
            "tgt_ix": "183-ARR_v2_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_2",
            "tgt_ix": "183-ARR_v2_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_3",
            "tgt_ix": "183-ARR_v2_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_4",
            "tgt_ix": "183-ARR_v2_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_4",
            "tgt_ix": "183-ARR_v2_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_4",
            "tgt_ix": "183-ARR_v2_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_4",
            "tgt_ix": "183-ARR_v2_4@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_4",
            "tgt_ix": "183-ARR_v2_4@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_4",
            "tgt_ix": "183-ARR_v2_4@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_4",
            "tgt_ix": "183-ARR_v2_4@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_4",
            "tgt_ix": "183-ARR_v2_4@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_4",
            "tgt_ix": "183-ARR_v2_4@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_4",
            "tgt_ix": "183-ARR_v2_4@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_5",
            "tgt_ix": "183-ARR_v2_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_5",
            "tgt_ix": "183-ARR_v2_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_5",
            "tgt_ix": "183-ARR_v2_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_5",
            "tgt_ix": "183-ARR_v2_5@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_6",
            "tgt_ix": "183-ARR_v2_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_7",
            "tgt_ix": "183-ARR_v2_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_7",
            "tgt_ix": "183-ARR_v2_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_7",
            "tgt_ix": "183-ARR_v2_7@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_7",
            "tgt_ix": "183-ARR_v2_7@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_7",
            "tgt_ix": "183-ARR_v2_7@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_7",
            "tgt_ix": "183-ARR_v2_7@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_7",
            "tgt_ix": "183-ARR_v2_7@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_8",
            "tgt_ix": "183-ARR_v2_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_8",
            "tgt_ix": "183-ARR_v2_8@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_8",
            "tgt_ix": "183-ARR_v2_8@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_8",
            "tgt_ix": "183-ARR_v2_8@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_8",
            "tgt_ix": "183-ARR_v2_8@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_9",
            "tgt_ix": "183-ARR_v2_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_10",
            "tgt_ix": "183-ARR_v2_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_11",
            "tgt_ix": "183-ARR_v2_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_11",
            "tgt_ix": "183-ARR_v2_11@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_11",
            "tgt_ix": "183-ARR_v2_11@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_11",
            "tgt_ix": "183-ARR_v2_11@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_11",
            "tgt_ix": "183-ARR_v2_11@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_12",
            "tgt_ix": "183-ARR_v2_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_12",
            "tgt_ix": "183-ARR_v2_12@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_12",
            "tgt_ix": "183-ARR_v2_12@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_12",
            "tgt_ix": "183-ARR_v2_12@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_13",
            "tgt_ix": "183-ARR_v2_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_13",
            "tgt_ix": "183-ARR_v2_13@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_13",
            "tgt_ix": "183-ARR_v2_13@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_14",
            "tgt_ix": "183-ARR_v2_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_14",
            "tgt_ix": "183-ARR_v2_14@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_14",
            "tgt_ix": "183-ARR_v2_14@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_14",
            "tgt_ix": "183-ARR_v2_14@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_14",
            "tgt_ix": "183-ARR_v2_14@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_15",
            "tgt_ix": "183-ARR_v2_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_15",
            "tgt_ix": "183-ARR_v2_15@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_15",
            "tgt_ix": "183-ARR_v2_15@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_15",
            "tgt_ix": "183-ARR_v2_15@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_15",
            "tgt_ix": "183-ARR_v2_15@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_16",
            "tgt_ix": "183-ARR_v2_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_16",
            "tgt_ix": "183-ARR_v2_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_17",
            "tgt_ix": "183-ARR_v2_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_18",
            "tgt_ix": "183-ARR_v2_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_18",
            "tgt_ix": "183-ARR_v2_18@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_18",
            "tgt_ix": "183-ARR_v2_18@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_19",
            "tgt_ix": "183-ARR_v2_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_20",
            "tgt_ix": "183-ARR_v2_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_21",
            "tgt_ix": "183-ARR_v2_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_22",
            "tgt_ix": "183-ARR_v2_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_23",
            "tgt_ix": "183-ARR_v2_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_23",
            "tgt_ix": "183-ARR_v2_23@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_24",
            "tgt_ix": "183-ARR_v2_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_25",
            "tgt_ix": "183-ARR_v2_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_25",
            "tgt_ix": "183-ARR_v2_25@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_25",
            "tgt_ix": "183-ARR_v2_25@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_25",
            "tgt_ix": "183-ARR_v2_25@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_25",
            "tgt_ix": "183-ARR_v2_25@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_25",
            "tgt_ix": "183-ARR_v2_25@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_25",
            "tgt_ix": "183-ARR_v2_25@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_26",
            "tgt_ix": "183-ARR_v2_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_26",
            "tgt_ix": "183-ARR_v2_26@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_26",
            "tgt_ix": "183-ARR_v2_26@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_26",
            "tgt_ix": "183-ARR_v2_26@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_26",
            "tgt_ix": "183-ARR_v2_26@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_27",
            "tgt_ix": "183-ARR_v2_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_27",
            "tgt_ix": "183-ARR_v2_27@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_27",
            "tgt_ix": "183-ARR_v2_27@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_27",
            "tgt_ix": "183-ARR_v2_27@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_28",
            "tgt_ix": "183-ARR_v2_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_29",
            "tgt_ix": "183-ARR_v2_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_29",
            "tgt_ix": "183-ARR_v2_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_29",
            "tgt_ix": "183-ARR_v2_29@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_29",
            "tgt_ix": "183-ARR_v2_29@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_29",
            "tgt_ix": "183-ARR_v2_29@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_29",
            "tgt_ix": "183-ARR_v2_29@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_29",
            "tgt_ix": "183-ARR_v2_29@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_29",
            "tgt_ix": "183-ARR_v2_29@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_30",
            "tgt_ix": "183-ARR_v2_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_30",
            "tgt_ix": "183-ARR_v2_30@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_31",
            "tgt_ix": "183-ARR_v2_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_32",
            "tgt_ix": "183-ARR_v2_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_33",
            "tgt_ix": "183-ARR_v2_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_34",
            "tgt_ix": "183-ARR_v2_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_35",
            "tgt_ix": "183-ARR_v2_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_36",
            "tgt_ix": "183-ARR_v2_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_36",
            "tgt_ix": "183-ARR_v2_36@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_36",
            "tgt_ix": "183-ARR_v2_36@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_37",
            "tgt_ix": "183-ARR_v2_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_37",
            "tgt_ix": "183-ARR_v2_37@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_38",
            "tgt_ix": "183-ARR_v2_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_38",
            "tgt_ix": "183-ARR_v2_38@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_38",
            "tgt_ix": "183-ARR_v2_38@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_38",
            "tgt_ix": "183-ARR_v2_38@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_38",
            "tgt_ix": "183-ARR_v2_38@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_38",
            "tgt_ix": "183-ARR_v2_38@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_38",
            "tgt_ix": "183-ARR_v2_38@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_39",
            "tgt_ix": "183-ARR_v2_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_40",
            "tgt_ix": "183-ARR_v2_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_40",
            "tgt_ix": "183-ARR_v2_40@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_41",
            "tgt_ix": "183-ARR_v2_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_42",
            "tgt_ix": "183-ARR_v2_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_43",
            "tgt_ix": "183-ARR_v2_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_44",
            "tgt_ix": "183-ARR_v2_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_45",
            "tgt_ix": "183-ARR_v2_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_46",
            "tgt_ix": "183-ARR_v2_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_47",
            "tgt_ix": "183-ARR_v2_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_47",
            "tgt_ix": "183-ARR_v2_47@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_48",
            "tgt_ix": "183-ARR_v2_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_49",
            "tgt_ix": "183-ARR_v2_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_50",
            "tgt_ix": "183-ARR_v2_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_50",
            "tgt_ix": "183-ARR_v2_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_51",
            "tgt_ix": "183-ARR_v2_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_51",
            "tgt_ix": "183-ARR_v2_51@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_51",
            "tgt_ix": "183-ARR_v2_51@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_51",
            "tgt_ix": "183-ARR_v2_51@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_51",
            "tgt_ix": "183-ARR_v2_51@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_51",
            "tgt_ix": "183-ARR_v2_51@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_51",
            "tgt_ix": "183-ARR_v2_51@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_51",
            "tgt_ix": "183-ARR_v2_51@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_52",
            "tgt_ix": "183-ARR_v2_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_53",
            "tgt_ix": "183-ARR_v2_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_53",
            "tgt_ix": "183-ARR_v2_53@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_53",
            "tgt_ix": "183-ARR_v2_53@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_53",
            "tgt_ix": "183-ARR_v2_53@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_54",
            "tgt_ix": "183-ARR_v2_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_54",
            "tgt_ix": "183-ARR_v2_54@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_54",
            "tgt_ix": "183-ARR_v2_54@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_54",
            "tgt_ix": "183-ARR_v2_54@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_54",
            "tgt_ix": "183-ARR_v2_54@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_54",
            "tgt_ix": "183-ARR_v2_54@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_55",
            "tgt_ix": "183-ARR_v2_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_56",
            "tgt_ix": "183-ARR_v2_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_56",
            "tgt_ix": "183-ARR_v2_56@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_56",
            "tgt_ix": "183-ARR_v2_56@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_56",
            "tgt_ix": "183-ARR_v2_56@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_56",
            "tgt_ix": "183-ARR_v2_56@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_56",
            "tgt_ix": "183-ARR_v2_56@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_56",
            "tgt_ix": "183-ARR_v2_56@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_57",
            "tgt_ix": "183-ARR_v2_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_57",
            "tgt_ix": "183-ARR_v2_57@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_57",
            "tgt_ix": "183-ARR_v2_57@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_58",
            "tgt_ix": "183-ARR_v2_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_58",
            "tgt_ix": "183-ARR_v2_58@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_58",
            "tgt_ix": "183-ARR_v2_58@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_58",
            "tgt_ix": "183-ARR_v2_58@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_58",
            "tgt_ix": "183-ARR_v2_58@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_58",
            "tgt_ix": "183-ARR_v2_58@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_59",
            "tgt_ix": "183-ARR_v2_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_59",
            "tgt_ix": "183-ARR_v2_59@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_59",
            "tgt_ix": "183-ARR_v2_59@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_59",
            "tgt_ix": "183-ARR_v2_59@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_59",
            "tgt_ix": "183-ARR_v2_59@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_59",
            "tgt_ix": "183-ARR_v2_59@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_59",
            "tgt_ix": "183-ARR_v2_59@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_59",
            "tgt_ix": "183-ARR_v2_59@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_60",
            "tgt_ix": "183-ARR_v2_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_60",
            "tgt_ix": "183-ARR_v2_60@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_60",
            "tgt_ix": "183-ARR_v2_60@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_60",
            "tgt_ix": "183-ARR_v2_60@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_60",
            "tgt_ix": "183-ARR_v2_60@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_60",
            "tgt_ix": "183-ARR_v2_60@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_61",
            "tgt_ix": "183-ARR_v2_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_61",
            "tgt_ix": "183-ARR_v2_61@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_61",
            "tgt_ix": "183-ARR_v2_61@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_62",
            "tgt_ix": "183-ARR_v2_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_62",
            "tgt_ix": "183-ARR_v2_62@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_62",
            "tgt_ix": "183-ARR_v2_62@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_62",
            "tgt_ix": "183-ARR_v2_62@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_63",
            "tgt_ix": "183-ARR_v2_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_64",
            "tgt_ix": "183-ARR_v2_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_64",
            "tgt_ix": "183-ARR_v2_64@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_65",
            "tgt_ix": "183-ARR_v2_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_65",
            "tgt_ix": "183-ARR_v2_65@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_65",
            "tgt_ix": "183-ARR_v2_65@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_65",
            "tgt_ix": "183-ARR_v2_65@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_65",
            "tgt_ix": "183-ARR_v2_65@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_65",
            "tgt_ix": "183-ARR_v2_65@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_65",
            "tgt_ix": "183-ARR_v2_65@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_65",
            "tgt_ix": "183-ARR_v2_65@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_65",
            "tgt_ix": "183-ARR_v2_65@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_65",
            "tgt_ix": "183-ARR_v2_65@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_66",
            "tgt_ix": "183-ARR_v2_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_67",
            "tgt_ix": "183-ARR_v2_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_68",
            "tgt_ix": "183-ARR_v2_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_69",
            "tgt_ix": "183-ARR_v2_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_70",
            "tgt_ix": "183-ARR_v2_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_71",
            "tgt_ix": "183-ARR_v2_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_72",
            "tgt_ix": "183-ARR_v2_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_73",
            "tgt_ix": "183-ARR_v2_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_74",
            "tgt_ix": "183-ARR_v2_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_75",
            "tgt_ix": "183-ARR_v2_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_76",
            "tgt_ix": "183-ARR_v2_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_77",
            "tgt_ix": "183-ARR_v2_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_78",
            "tgt_ix": "183-ARR_v2_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_79",
            "tgt_ix": "183-ARR_v2_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_80",
            "tgt_ix": "183-ARR_v2_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_81",
            "tgt_ix": "183-ARR_v2_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_82",
            "tgt_ix": "183-ARR_v2_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_83",
            "tgt_ix": "183-ARR_v2_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_84",
            "tgt_ix": "183-ARR_v2_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_85",
            "tgt_ix": "183-ARR_v2_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_86",
            "tgt_ix": "183-ARR_v2_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_87",
            "tgt_ix": "183-ARR_v2_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_88",
            "tgt_ix": "183-ARR_v2_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_89",
            "tgt_ix": "183-ARR_v2_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_90",
            "tgt_ix": "183-ARR_v2_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_91",
            "tgt_ix": "183-ARR_v2_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_92",
            "tgt_ix": "183-ARR_v2_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_93",
            "tgt_ix": "183-ARR_v2_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_94",
            "tgt_ix": "183-ARR_v2_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_95",
            "tgt_ix": "183-ARR_v2_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_96",
            "tgt_ix": "183-ARR_v2_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_97",
            "tgt_ix": "183-ARR_v2_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_98",
            "tgt_ix": "183-ARR_v2_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_99",
            "tgt_ix": "183-ARR_v2_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_100",
            "tgt_ix": "183-ARR_v2_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_101",
            "tgt_ix": "183-ARR_v2_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_102",
            "tgt_ix": "183-ARR_v2_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_103",
            "tgt_ix": "183-ARR_v2_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_104",
            "tgt_ix": "183-ARR_v2_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "183-ARR_v2_105",
            "tgt_ix": "183-ARR_v2_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 740,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "doc_id": "183-ARR",
        "version": 2
    }
}