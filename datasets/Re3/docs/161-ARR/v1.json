{
    "nodes": [
        {
            "ix": "161-ARR_v1_0",
            "content": "On Efficiently Acquiring Annotations for Multilingual Models",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_2",
            "content": "When tasked with supporting multiple languages for a given problem, two approaches have arisen: training a model for each language with the annotation budget divided equally among them, and training on a high-resource language followed by zero-shot transfer to the remaining languages. In this work, we show that the strategy of joint learning across multiple languages using a single model performs substantially better than the aforementioned alternatives. We also demonstrate that active learning provides additional, complementary benefits. We show that this simple approach enables the model to be data efficient by allowing it to arbitrate its annotation budget to query languages it is less certain on. We illustrate the effectiveness of our proposed method on a diverse set of tasks: a classification task with 4 languages, a sequence tagging task with 4 languages and a dependency parsing task with 5 languages. Our proposed method, whilst simple, substantially outperforms the other viable alternatives for building a model in a multilingual setting under constrained budgets.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_3",
            "content": "Anthony Brew, Derek Greene, and P\u00e1draig Cunningham.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_4",
            "content": "2010. Using crowdsourcing and active learning to track sentiment in online media. In ECAI.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_5",
            "content": "Yoeng-Jin Chu. 1965. On the shortest arborescence of a directed graph. Scientia Sinica, 14.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_6",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "161-ARR_v1_7",
            "content": "While neural networks have become the de-facto method of tackling NLP tasks, they often require a lot of annotated data to do so. This task of data annotation is especially challenging while building systems aimed at serving numerous languages. Motivated by this, in this paper, we tackle the following problem:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_8",
            "content": "Given the requirement of building systems for an NLP task in a multilingual setting with a fixed annotation budget, how can we efficiently acquire annotations to perform the task well across multiple languages?",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_9",
            "content": "The traditional approach to this problem has been building a separate model to serve each language. In this scenario, the annotation budget is split equally for all languages, and a model is trained for each one separately. Recently, another direction that has gained popularity has been leveraging multilingaul pre-trained language models (MPLMs) which inherently map multiple languages to a common embedding space (Devlin et al., 2019;Conneau et al., 2020). The popular method for leveraging these models has been leveraging their zero-shot transfer ability: training on an English-only corpus for the task, and then using the models zero-shot for the other languages.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_10",
            "content": "Another orthogonal line of work aimed at building models under a constrained budget has been active learning (AL) (Shen et al., 2018;Ein-Dor et al., 2020). While this has shown to improve annotation efficiency, the predominant approach has been to train one model per language, using the (language specific) model for AL (Shen et al., 2018;Erdmann et al., 2019).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_11",
            "content": "In this work, we show that a single MPLM trained on all languages simultaneously performs much better than training independent models for specific languages for a fixed total annotation budget. Further, while the benefits of using AL in conjunction with MPLMs has been studied for a monolingual setup (Ein-Dor et al., 2020), we show that AL also yields benefits in the multilingual setup. Concretely, we show that an AL acquisition on a single language helps improve zero-shot performance on all other languages, regardless of the language of the seed data. Furthermore, we show that AL also yields benefits for our proposed single model scenario. We demonstrate that our results are consistent on 3 different tasks across multiple languages: classification, sequence tagging and dependency parsing. Our approach removes the requirement of maintaining n different models, and uses 1{n th the parameters than when independent models are trained. Our analysis reveals that the model arbitrates between different languages based on its performance to form a multilingual curriculum. We release our code at URL.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_12",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "161-ARR_v1_13",
            "content": "Effective utilization of annotation budgets has been the area of focus for numerous active learning works, showing improvements for different tasks like POS tagging (Ringger et al., 2007), sentiment analysis (Karlos et al., 2012;Li et al., 2013;Brew et al., 2010;Ju and Li, 2012), syntactic parsing (Duong et al., 2018), and named entity recognition (Settles and Craven, 2008;Shen et al., 2018). The focus of most of these works, however, has been on learning for a single language (often English). Prior work on AL that uses a multilingual setup or cross-lingual information sharing and that goes beyond training a separate model for each language has thus been limited. The closest work where multiple languages influence each other's acquisition is that of Qian et al. (2014); however, they still train a separate model for each language.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_14",
            "content": "For transfer to multiple languages, recent advances in building MPLMs (Devlin et al., 2019;Conneau et al., 2020;Liu et al., 2020;Xue et al., 2020) have been extremely effective, especially in zero-shot transfer (Pires et al., 2019;Liu et al., 2020). Ein-Dor et al. (2020) studied the dataeffectiveness of these models when used in conjunction with AL, but, as with other AL work, with a single language focus. Finally, Lauscher et al. (2020) studied the effectiveness of the zero-shot setup, showing that adding a few examples to a model trained on English improves performance over zero-shot transfer. However, this assumes the availability of a full English task-specific corpus.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_15",
            "content": "Methodology",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "161-ARR_v1_16",
            "content": "Task Specific Models:",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "161-ARR_v1_17",
            "content": "We use the multilingual-BERT-cased model (mBERT) as the base model for all the tasks. We use the standard training methodology for the tasks: for classification, we use a single layer over the [CLS] embedding, for sequence tagging, we use a single layer for each word to predict its tag, and for dependency parsing, we follow Kondratyuk and Straka (2019) and use mBERT embeddings with the graph-based bi-affine attention parser (Dozat and Manning, 2017); refer Appendix A for details.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_18",
            "content": "Budget Allocation Settings",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "161-ARR_v1_19",
            "content": "To understand data acquisition in a multilingual setting, we consider multilingual datasets in the 3 tasks. For each task t, let L be the set of languages (n \" |L|). We then define s t to be the seed size, b t to be the total annotation budget and v t to be total number of annotated validation examples available to t. We compare our proposed Single Model Acquisition (SMA) setup to two baseline settings-Monolingual Acquisition (MonoA) and Multi Model Acquisition (MMA):",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_20",
            "content": "MonoA: In this setting, the seed data as well as the validation data (s t , v t ) is acquired from a single language. Further, the entire annotation budget (b t ) is assigned to the same language. We evaluate the test data performance on that language and on the other n \u00b41 languages in a zero-shot setting.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_21",
            "content": "MMA: For this setting, we train n individual models, one for each language. Each model starts with a seed of s t {n, a validation set of v t {n, and is assigned an acquisition budget of b t {n. At test time, we evaluate the performance of the model on the language it was trained with.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_22",
            "content": "SMA: For this setting, we consider a single model for which both training and acquisition is done on all n languages simultaneously. The seed data and the validation set comprises of a random subset drawn from data corresponding to all languages. The whole of s t , b t and v t are thus assigned to this single model. We compute the performance on the test data of each of the languages.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_23",
            "content": "Active Learning Acquisition Strategies:",
            "ntype": "title",
            "meta": {
                "section": "3.3"
            }
        },
        {
            "ix": "161-ARR_v1_24",
            "content": "The field of active AL tends not to reveal explicit winners-though there is a general consensus that AL does indeed outperform passive learning (Settles, 2009). Thus, we adopt the simplest confidence based strategies to demonstrate their efficacy for each task : Least Confidence (LC) for classification, Maximum Normalized Log Probability (MNLP) (Shen et al., 2018) for sequence tagging, and normalized log probability of decoded tree (NLPDT) (Li et al., 2016) for dependency parsing. Please see Appendix B for more details. To the best of our knowledge, this is the first work to explore an ALaugmented single model for multiple languages.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_25",
            "content": "Experiments",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "161-ARR_v1_26",
            "content": "Dataset Details",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "161-ARR_v1_27",
            "content": "Classification: We consider Sentiment Analysis, using the Amazon Reviews dataset (Prettenhofer and Stein, 2010). The dataset consists of reviews and their binary sentiments for 4 languages: English (en), French (fr), Japanese (ja), German (de).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_28",
            "content": "Sequence Tagging: We choose Named Entity Recognition, and use the CoNLL02/03 datasets",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_29",
            "content": "Experimental Settings",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "161-ARR_v1_30",
            "content": "For each experiment, we run 4 training rounds: one training on initial seed data, followed by 3 acquisition rounds. We set s t \"b t \"v t in all cases. For classification, we set s t =300 sentences. For NER and Dependency Parsing, we use s t \"\"10k and s t \"\"17.5k tokens respectively (refer Appendix C). We report accuracy for classification, F1-Score for the NER, and unlabeled and labeled attachment scores (UAS and LAS) for dependency parsing.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_31",
            "content": "For each task, we run the 3 settings ( \u00a73.2) across multiple languages. For each setting, we also train an AL model with a task-specific acquisition function ( \u00a73.3). In addition, we train both the SMA and MMA with all available data, i.e., we use all data to train one model for all languages and one model per language respectively. We report an average of 5 runs for each experiment. Refer Appendix D for hyperparameters and training details.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_32",
            "content": "Results and Analysis",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "161-ARR_v1_33",
            "content": "Model Performance: Figure 1 shows the performance of NER on Spanish (refer Appendix H for the plots of all other languages and tasks). Although acquiring data independently per language (MMA) performs well, SMA outperforms MMA. Unsurprisingly, MonoA with es performs the best in the category, since it allocates its entire budget to acquiring es data; it thus forms an upper-bound of the model performance. However, SMA outperforms MonoA when its seed language and inference language differ. Finally, AL consistently provides gains over random acquisition.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_34",
            "content": "To analyze the performance across all languages, we present the performance for each round of acquisition, aggregated across all languages for Classification (Figure 2) (refer Appendix H for Dependency Parsing and NER plots). Here, SMA consistently outperforms MMA for every round of acquisition because MMA suffers from a poorly utilized budget, potentially wasting annotation budget on languages where the task is easier. In contrast, SMA improves budget utilization while also benefiting from cross-lingual information. Finally, SMA, by virtue of performing well irrespective of language, consistently outperforms MonoA.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_35",
            "content": "For a concise overview, we present the aggregate metrics across all rounds for each task in Table 1. We observe that SMA does much better compared to its counterparts; both with and without AL. We also observe these models to be extremely data efficient: with AL, a model with access to less than 5% of the data achieves a (relative) performance of around 88% accuracy (for classification), 95.5% F1-score (for NER) and 93.5% LAS (for dependency parsing) when compared to a model trained with all available data. Further, along with its superior performance, SMA also affords substantial parameter savings: requiring only a single model, compared to a number of models linear in n (thereby using 1 n th parameters compared to MMA). MM Full vs SM Full: To analyze how effectively a single model performs on the languages in question despite using 1{n th the parameters, we UAS 76.4 72.9 73.9 72.9 44.3 84.8 86.0 76.9 73.0 74.0 73.4 44.2 84.5 86.3 91.3 91.3 LAS 67.2 62.3 62.8 61.8 31.8 78.0 79.3 67.5 62.4 62.7 62.3 30.8 77.8 79.7 87.1 87.1 Table 1: Average results across all rounds (5%, 10%, 15% and 20% data) and all languages. train a single model on all data and compare it with n language-specific models, where each of the n models has the same number of parameters as the single model; this also serves as an upper-bound for our AL experiments. The rightmost columns of Table 1 show that having a single model does not adversely impact performance. A more detailed discussion is present in Appendix E.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_36",
            "content": "The effectiveness of AL in MonoA: We consistently observe AL in the source language improving performance across all languages, irrespective of whether inference is being run for the source language or zero-shot on a different target language, both for NER and classification (Table 1). We hypothesize that the model selects semantically difficult or ambiguous examples that generalize across languages by virtue of mBERT's shared embedding representation. To the best of our knowledge, this work is the first to demonstrate that AL can improve the data efficiency of both classification and NER in a zero-shot inference setup.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_37",
            "content": "In the case of dependency parsing, we observe mixed results when the source and target languages differ. We hypothesize that this is because dependency parsing is a syntactic problem, making it more language specific, and zero-shot inference inherently harder. This is in contrast with both classification and NER, which are more semantic, making hard examples more generalizable across languages. Refer Appendix F for more details. What does SMA+AL acquire? One advantage of the SMA+AL setup is that the model can arbitrate between allocating its acquisition budget across different languages as training progresses. This is in contrast with training one model per language, where the models for languages with a high performance waste the overall budget by acquiring more than necessary, while models on languages where performance isn't as good under-acquire.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_38",
            "content": "To investigate this, for each language and each round, we plot the relative difference (%) between cumulative tokens acquired by the SMA+AL model for that language, and the tokens acquired in expectation if acquisition was done randomly (refer Appendix G for more details). For each language, we also plot the relative performance difference of the language at that round compared to the performance when 100% data is available.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_39",
            "content": "Figure 3 reveals the added benefit of SMA+AL for data acquisition for NER (refer Appendix G for other tasks): a single model can arbitrate between instances across languages automatically. The model initially acquires data from the high resource language (English). But as the training proceeds, the model favors acquiring data from languages it is uncertain about. This \"multilingual curriculum\" thus allows the model to be more effective in its use of the annotation budget. We find SMA+AL eventually achieves a similar relative difference from 100% data performance for all languages consistently across tasks as a consequence.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_40",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "161-ARR_v1_41",
            "content": "In this work, we consider the problem of efficiently building models that solve a task across multiple languages. We show that, contrary to traditional approaches, a single model arbitrating between multiple languages for data acquisition considerably improves performance in a constrained budget scenario, with AL providing additional benefits.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_42",
            "content": "In this section, we elaborate on the task specific adaptations: Classification: As is common practice, we use a single linear layer over [CLS] embeddings generated by the BERT model to generate logits for the classification task, and the model is trained to minimize the cross-entropy loss.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_43",
            "content": "Sequence Tagging: We apply a linear layer to the word embeddings 1 generated by the BERT model to generate the tag logits, and the model is trained to minimize the negative log-likelihood of the observed tags.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_44",
            "content": "Dependency Parsing: We use a graph-based biaffine attention parser introduced in (Dozat and Manning, 2017). Following (Kondratyuk and Straka, 2019), we use the output of the last BERT layer in place of the embeddings generated by the Bi-LSTM layers. These embeddings are then concatenated with the POS embeddings. A head feed-forward network and a child feed-forward network then generate embeddings for each head and dependant word of a dependency respectively. This is combined with a biaffine attention module to generate a probability distribution for each word to predict its head, as well as a bilinear layer to predict the label for each dependency relationship. Let \u03c4 piq \" tph pi,jq , d pi,jq , l pi,jq |h pi,jq \u00f1 d pi,jq with label l pi,jq u be the i th gold dependency tree in the dataset. The model is then trained to maximize the log probability of the gold tree as :",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_45",
            "content": "max \u00ff i \u00ff j log `Pph pi,jq |d pi,jq q log `Ppl pi,jq |h pi,jq \u00f1 d pi,jq q \u02d8(1)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_46",
            "content": "During inference, the best dependency parse is generated by decoding with Chu-Liu/Edmonds algorithm (Chu, 1965;Edmonds, 1967).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_47",
            "content": "For all the models mentioned above, all layers of mBERT are fine-tuned during training.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_48",
            "content": "We mention the acquisition functions used below:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_49",
            "content": "1 Following (Devlin et al., 2019) For words generating multiple wordpieces, we use the embedding of the first wordpiece.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_50",
            "content": "Maximum Normalized Log Probability (MNLP): This strategy chooses instances for which the log probability of the model prediction, normalized by sequence length, is the lowest. This AL strategy has been shown to be extremely effective for NER (Shen et al., 2018) and hence we adopt it in our setting.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_51",
            "content": "Least Confidence (LC): This strategy chooses those instances for which the model confidence corresponding to the predicted class is the least. This acquisition strategy has been commonly applied in classification tasks, and although simple, has been consistently shown to often perform extremely well (Settles, 2009); consequently, we adopt it in our setting.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_52",
            "content": "Normalized Log Probability of the Decoded Tree (NLPDT): This strategy selects the instances with the minimum log probability of the decoded tree; i.e given d \u02dato be the tree generated by the Chu-Liu/Edmonds algorithm, the log probability, as computed by Eqn. 1. Following (Li et al., 2016), we also normalize this score by N , where N indicates the number of tokens. We also tried normalizing by N 2 , as well as a globally normalized probability of d \u02da(probability of the tree over all possible valid trees, with the partition function computed using the Matrix Tree Theorem (Koo et al., 2007;Smith and Smith, 2007)), but found both to perform worse.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_53",
            "content": "We report the detailed dataset statistics in Table 2. Note that the seed was chosen to be roughly 5% of the size of the English training data, shown in the rightmost column of the table.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_54",
            "content": "Hyperparameters All experiments performed in this paper are averaged over 5 runs. For each experiment, we perform an LR search over (1e-5, 2e-5, 3e-5, 4e-5 and 5e-5), and choose the best LR according to the performance on the appropriate validation (sub)set, as recommended in (Devlin et al., 2019). In all experiments, we set the batch size to 32 and use an Adam (Kingma and Ba, 2015) optimizer. Each round of training is run with a patience of 25 epochs, for at most 75 epochs in total.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_55",
            "content": "Data Preprocessing To avoid out-of-memory issues on the GPU, we pre-process the data so that the examples in the train set of length larger than 175 and with larger than 256 word-pieces are filtered out for the NER. For classification, we simply truncate all instances at 256 word-pieces. We also de-duplicate the train set, to ensure that during all AL acquisition stages, no duplicates are selected at any point.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_56",
            "content": "Code All code used in this work was implemented using Python, PyTorch and AllenNLP (Gardner et al., 2018), using pre-trained models released by HuggingFace (Wolf et al., 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_57",
            "content": "Given that the SMA setup uses 1{n th the number of parameters, an interesting question is whether fewer parameters leads to a loss in any expressive power for the single model, which might potentially lead to poorer performance (curse of multilinguality (Conneau et al., 2020)). To answer this question, we train a single model on all data and compare it with n language-specific models, where each of the n models has the same number of parameters as the single model.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_58",
            "content": "From the 100% (rightmost) columns of Table 1, we find that having a single model does not adversely impact performance and these trends hold irrespective of whether all the languages in the task are etymologically close (as in NER) or distant (ja for classification and dependency parsing). This might not be the case when there are a large number of languages, however; investigating how well this observation scales with the number of languages would be an interesting line of future work.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_59",
            "content": "An interesting observation from Table 1 is that AL in the source language helps improve performance across all languages, irrespective of whether the inference is being run for the source language in question or zero-shot on a different target language without any training. We observe this to be the case consistently for both the NER and the classification tasks (refer Figure 4 for classification and Appendix I for the other tasks), regardless of the source language. We hypothesize that this is because the model selects semantically difficult or ambiguous examples that generalize across languages by virtue of mBERT's shared embedding representation, in contrast with random selection where easy examples the model can already tackle might be selected. We observe this even in the case of etymologically distant languages, such as when the model is trained in English and zero-shot inference is done in Japanese (or vice versa). Thus, the AL selection does not overfit on the specific language in question, instead choosing difficult but generalizable examples.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_60",
            "content": "We observe mixed results for the MonoA setup for dependency parsing: AL improves substantially over Random when the target language and the source language are the same; however, when they differ, the results are mixed. We hypothesize that this discrepancy is a consequence of dependency parsing being a syntactic problem, making it more language specific, in turn making zero-shot an inherently harder problem. This is in contrast with both classification and NER, which are more semantic tasks. Consequently, hard examples for the latter tasks might be more generalizable across languages, resulting in their improved AL performance, when compared with the dependency parsing task. In this section, we describe the analysis of investigating the acquisitions of SMA+AL in more detail. Let \u03b1 1 \u00a8\u00a8\u00a8\u03b1 n be the language specific amount of data present in the entire dataset (i.e \u03b1 i \" 0.3 implies that 30% of the entire dataset (training + unlabeled) is of language i), and let \u03b2 1,1 \u00a8\u00a8\u00a8\u03b2 m,n represent the amount of data acquired for every language at every round (i.e \u03b2 i,j indicates the amount of data acquired by language j at round i). Then, for a task t, for each round i and language j, we plot p \u0159 i k\"1 \u03b2 k,j q\u00b4\u03b1 j 9 bt 9 i \u03b1 j 9 bt 9 i .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_61",
            "content": "Figures 5 and 6 show the acquisition (as described in Appendix G for both the classification and NER tasks. We observe a similar for both the tasks as that for dependency parsing.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_62",
            "content": "This section the additional plots as well as the detailed tables and results for all the experiments presented in the paper.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_63",
            "content": "Tables 3, 4, 5 and 6 show the performance of the different AL settings on English, Spanish, Dutch and German respectively. Each table shows the F-score across 4 acquisition rounds, both with and without MNLP ( \u00a73.2). This section shows the plots for the performance of an mBERT model trained on de (the source language) in a MonoAL setting relative to the performance of an mBERT model trained on all de data available (100% data, without AL). The performance plots are shown for the dependency parsing (Figure 24) and NER (Figure 25) tasks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "161-ARR_v1_64",
            "content": "A David, Noah A Smith,  Smith, Probabilistic models of nonprojective dependency trees, 2007, EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "A David",
                    "Noah A Smith",
                    " Smith"
                ],
                "title": "Probabilistic models of nonprojective dependency trees",
                "pub_date": "2007",
                "pub_title": "EMNLP",
                "pub": null
            }
        },
        {
            "ix": "161-ARR_v1_65",
            "content": "Erik Tjong, Kim Sang, Fien De Meulder, Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition, 2003, NAACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Erik Tjong",
                    "Kim Sang",
                    "Fien De Meulder"
                ],
                "title": "Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition",
                "pub_date": "2003",
                "pub_title": "NAACL",
                "pub": null
            }
        },
        {
            "ix": "161-ARR_v1_66",
            "content": "Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Clara Patrick Von Platen, Yacine Ma, Julien Jernite, Canwen Plu,  Xu, Transformers: State-of-the-art natural language processing, 2020, EMNLP: System Demo, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "Thomas Wolf",
                    "Lysandre Debut",
                    "Victor Sanh",
                    "Julien Chaumond",
                    "Clement Delangue",
                    "Anthony Moi",
                    "Pierric Cistac",
                    "Tim Rault",
                    "Remi Louf",
                    "Morgan Funtowicz",
                    "Joe Davison",
                    "Sam Shleifer",
                    "Clara Patrick Von Platen",
                    "Yacine Ma",
                    "Julien Jernite",
                    "Canwen Plu",
                    " Xu"
                ],
                "title": "Transformers: State-of-the-art natural language processing",
                "pub_date": "2020",
                "pub_title": "EMNLP: System Demo",
                "pub": null
            }
        },
        {
            "ix": "161-ARR_v1_67",
            "content": "UNKNOWN, None, , Aditya Barua, and Colin Raffel. 2020. mt5: A massively multilingual pre-trained text-to-text transformer, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Aditya Barua, and Colin Raffel. 2020. mt5: A massively multilingual pre-trained text-to-text transformer",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "161-ARR_v1_0@0",
            "content": "On Efficiently Acquiring Annotations for Multilingual Models",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_0",
            "start": 0,
            "end": 59,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_2@0",
            "content": "When tasked with supporting multiple languages for a given problem, two approaches have arisen: training a model for each language with the annotation budget divided equally among them, and training on a high-resource language followed by zero-shot transfer to the remaining languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_2",
            "start": 0,
            "end": 284,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_2@1",
            "content": "In this work, we show that the strategy of joint learning across multiple languages using a single model performs substantially better than the aforementioned alternatives.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_2",
            "start": 286,
            "end": 457,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_2@2",
            "content": "We also demonstrate that active learning provides additional, complementary benefits.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_2",
            "start": 459,
            "end": 543,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_2@3",
            "content": "We show that this simple approach enables the model to be data efficient by allowing it to arbitrate its annotation budget to query languages it is less certain on.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_2",
            "start": 545,
            "end": 708,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_2@4",
            "content": "We illustrate the effectiveness of our proposed method on a diverse set of tasks: a classification task with 4 languages, a sequence tagging task with 4 languages and a dependency parsing task with 5 languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_2",
            "start": 710,
            "end": 919,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_2@5",
            "content": "Our proposed method, whilst simple, substantially outperforms the other viable alternatives for building a model in a multilingual setting under constrained budgets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_2",
            "start": 921,
            "end": 1085,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_3@0",
            "content": "Anthony Brew, Derek Greene, and P\u00e1draig Cunningham.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_3",
            "start": 0,
            "end": 50,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_4@0",
            "content": "2010.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_4",
            "start": 0,
            "end": 4,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_4@1",
            "content": "Using crowdsourcing and active learning to track sentiment in online media.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_4",
            "start": 6,
            "end": 80,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_4@2",
            "content": "In ECAI.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_4",
            "start": 82,
            "end": 89,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_5@0",
            "content": "Yoeng-Jin Chu. 1965.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_5",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_5@1",
            "content": "On the shortest arborescence of a directed graph.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_5",
            "start": 21,
            "end": 69,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_5@2",
            "content": "Scientia Sinica, 14.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_5",
            "start": 71,
            "end": 90,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_6@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_6",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_7@0",
            "content": "While neural networks have become the de-facto method of tackling NLP tasks, they often require a lot of annotated data to do so.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_7",
            "start": 0,
            "end": 128,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_7@1",
            "content": "This task of data annotation is especially challenging while building systems aimed at serving numerous languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_7",
            "start": 130,
            "end": 243,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_7@2",
            "content": "Motivated by this, in this paper, we tackle the following problem:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_7",
            "start": 245,
            "end": 310,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_8@0",
            "content": "Given the requirement of building systems for an NLP task in a multilingual setting with a fixed annotation budget, how can we efficiently acquire annotations to perform the task well across multiple languages?",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_8",
            "start": 0,
            "end": 209,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_9@0",
            "content": "The traditional approach to this problem has been building a separate model to serve each language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_9",
            "start": 0,
            "end": 98,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_9@1",
            "content": "In this scenario, the annotation budget is split equally for all languages, and a model is trained for each one separately.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_9",
            "start": 100,
            "end": 222,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_9@2",
            "content": "Recently, another direction that has gained popularity has been leveraging multilingaul pre-trained language models (MPLMs) which inherently map multiple languages to a common embedding space (Devlin et al., 2019;Conneau et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_9",
            "start": 224,
            "end": 458,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_9@3",
            "content": "The popular method for leveraging these models has been leveraging their zero-shot transfer ability: training on an English-only corpus for the task, and then using the models zero-shot for the other languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_9",
            "start": 460,
            "end": 669,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_10@0",
            "content": "Another orthogonal line of work aimed at building models under a constrained budget has been active learning (AL) (Shen et al., 2018;Ein-Dor et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_10",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_10@1",
            "content": "While this has shown to improve annotation efficiency, the predominant approach has been to train one model per language, using the (language specific) model for AL (Shen et al., 2018;Erdmann et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_10",
            "start": 156,
            "end": 361,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_11@0",
            "content": "In this work, we show that a single MPLM trained on all languages simultaneously performs much better than training independent models for specific languages for a fixed total annotation budget.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_11",
            "start": 0,
            "end": 193,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_11@1",
            "content": "Further, while the benefits of using AL in conjunction with MPLMs has been studied for a monolingual setup (Ein-Dor et al., 2020), we show that AL also yields benefits in the multilingual setup.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_11",
            "start": 195,
            "end": 388,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_11@2",
            "content": "Concretely, we show that an AL acquisition on a single language helps improve zero-shot performance on all other languages, regardless of the language of the seed data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_11",
            "start": 390,
            "end": 557,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_11@3",
            "content": "Furthermore, we show that AL also yields benefits for our proposed single model scenario.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_11",
            "start": 559,
            "end": 647,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_11@4",
            "content": "We demonstrate that our results are consistent on 3 different tasks across multiple languages: classification, sequence tagging and dependency parsing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_11",
            "start": 649,
            "end": 799,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_11@5",
            "content": "Our approach removes the requirement of maintaining n different models, and uses 1{n th the parameters than when independent models are trained.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_11",
            "start": 801,
            "end": 944,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_11@6",
            "content": "Our analysis reveals that the model arbitrates between different languages based on its performance to form a multilingual curriculum.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_11",
            "start": 946,
            "end": 1079,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_11@7",
            "content": "We release our code at URL.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_11",
            "start": 1081,
            "end": 1107,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_12@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_12",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_13@0",
            "content": "Effective utilization of annotation budgets has been the area of focus for numerous active learning works, showing improvements for different tasks like POS tagging (Ringger et al., 2007), sentiment analysis (Karlos et al., 2012;Li et al., 2013;Brew et al., 2010;Ju and Li, 2012), syntactic parsing (Duong et al., 2018), and named entity recognition (Settles and Craven, 2008;Shen et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_13",
            "start": 0,
            "end": 394,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_13@1",
            "content": "The focus of most of these works, however, has been on learning for a single language (often English).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_13",
            "start": 396,
            "end": 497,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_13@2",
            "content": "Prior work on AL that uses a multilingual setup or cross-lingual information sharing and that goes beyond training a separate model for each language has thus been limited.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_13",
            "start": 499,
            "end": 670,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_13@3",
            "content": "The closest work where multiple languages influence each other's acquisition is that of Qian et al. (2014); however, they still train a separate model for each language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_13",
            "start": 672,
            "end": 840,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_14@0",
            "content": "For transfer to multiple languages, recent advances in building MPLMs (Devlin et al., 2019;Conneau et al., 2020;Liu et al., 2020;Xue et al., 2020) have been extremely effective, especially in zero-shot transfer (Pires et al., 2019;Liu et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_14",
            "start": 0,
            "end": 248,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_14@1",
            "content": "Ein-Dor et al. (2020) studied the dataeffectiveness of these models when used in conjunction with AL, but, as with other AL work, with a single language focus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_14",
            "start": 250,
            "end": 408,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_14@2",
            "content": "Finally, Lauscher et al. (2020) studied the effectiveness of the zero-shot setup, showing that adding a few examples to a model trained on English improves performance over zero-shot transfer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_14",
            "start": 410,
            "end": 601,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_14@3",
            "content": "However, this assumes the availability of a full English task-specific corpus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_14",
            "start": 603,
            "end": 680,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_15@0",
            "content": "Methodology",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_15",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_16@0",
            "content": "Task Specific Models:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_16",
            "start": 0,
            "end": 20,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_17@0",
            "content": "We use the multilingual-BERT-cased model (mBERT) as the base model for all the tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_17",
            "start": 0,
            "end": 84,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_17@1",
            "content": "We use the standard training methodology for the tasks: for classification, we use a single layer over the [CLS] embedding, for sequence tagging, we use a single layer for each word to predict its tag, and for dependency parsing, we follow Kondratyuk and Straka (2019) and use mBERT embeddings with the graph-based bi-affine attention parser (Dozat and Manning, 2017); refer Appendix A for details.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_17",
            "start": 86,
            "end": 483,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_18@0",
            "content": "Budget Allocation Settings",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_18",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_19@0",
            "content": "To understand data acquisition in a multilingual setting, we consider multilingual datasets in the 3 tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_19",
            "start": 0,
            "end": 106,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_19@1",
            "content": "For each task t, let L be the set of languages (n \" |L|).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_19",
            "start": 108,
            "end": 164,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_19@2",
            "content": "We then define s t to be the seed size, b t to be the total annotation budget and v t to be total number of annotated validation examples available to t.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_19",
            "start": 166,
            "end": 318,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_19@3",
            "content": "We compare our proposed Single Model Acquisition (SMA) setup to two baseline settings-Monolingual Acquisition (MonoA) and Multi Model Acquisition (MMA):",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_19",
            "start": 320,
            "end": 471,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_20@0",
            "content": "MonoA: In this setting, the seed data as well as the validation data (s t , v t ) is acquired from a single language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_20",
            "start": 0,
            "end": 116,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_20@1",
            "content": "Further, the entire annotation budget (b t ) is assigned to the same language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_20",
            "start": 118,
            "end": 195,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_20@2",
            "content": "We evaluate the test data performance on that language and on the other n \u00b41 languages in a zero-shot setting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_20",
            "start": 197,
            "end": 306,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_21@0",
            "content": "MMA: For this setting, we train n individual models, one for each language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_21",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_21@1",
            "content": "Each model starts with a seed of s t {n, a validation set of v t {n, and is assigned an acquisition budget of b t {n. At test time, we evaluate the performance of the model on the language it was trained with.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_21",
            "start": 76,
            "end": 284,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_22@0",
            "content": "SMA: For this setting, we consider a single model for which both training and acquisition is done on all n languages simultaneously.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_22",
            "start": 0,
            "end": 131,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_22@1",
            "content": "The seed data and the validation set comprises of a random subset drawn from data corresponding to all languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_22",
            "start": 133,
            "end": 245,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_22@2",
            "content": "The whole of s t , b t and v t are thus assigned to this single model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_22",
            "start": 247,
            "end": 316,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_22@3",
            "content": "We compute the performance on the test data of each of the languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_22",
            "start": 318,
            "end": 386,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_23@0",
            "content": "Active Learning Acquisition Strategies:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_23",
            "start": 0,
            "end": 38,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_24@0",
            "content": "The field of active AL tends not to reveal explicit winners-though there is a general consensus that AL does indeed outperform passive learning (Settles, 2009).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_24",
            "start": 0,
            "end": 159,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_24@1",
            "content": "Thus, we adopt the simplest confidence based strategies to demonstrate their efficacy for each task : Least Confidence (LC) for classification, Maximum Normalized Log Probability (MNLP) (Shen et al., 2018) for sequence tagging, and normalized log probability of decoded tree (NLPDT) (Li et al., 2016) for dependency parsing. Please see Appendix B for more details.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_24",
            "start": 161,
            "end": 524,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_24@2",
            "content": "To the best of our knowledge, this is the first work to explore an ALaugmented single model for multiple languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_24",
            "start": 526,
            "end": 640,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_25@0",
            "content": "Experiments",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_25",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_26@0",
            "content": "Dataset Details",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_26",
            "start": 0,
            "end": 14,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_27@0",
            "content": "Classification: We consider Sentiment Analysis, using the Amazon Reviews dataset (Prettenhofer and Stein, 2010).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_27",
            "start": 0,
            "end": 111,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_27@1",
            "content": "The dataset consists of reviews and their binary sentiments for 4 languages: English (en), French (fr), Japanese (ja), German (de).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_27",
            "start": 113,
            "end": 243,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_28@0",
            "content": "Sequence Tagging: We choose Named Entity Recognition, and use the CoNLL02/03 datasets",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_28",
            "start": 0,
            "end": 84,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_29@0",
            "content": "Experimental Settings",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_29",
            "start": 0,
            "end": 20,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_30@0",
            "content": "For each experiment, we run 4 training rounds: one training on initial seed data, followed by 3 acquisition rounds.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_30",
            "start": 0,
            "end": 114,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_30@1",
            "content": "We set s t \"b t \"v t in all cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_30",
            "start": 116,
            "end": 149,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_30@2",
            "content": "For classification, we set s t =300 sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_30",
            "start": 151,
            "end": 196,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_30@3",
            "content": "For NER and Dependency Parsing, we use s t \"\"10k and s t \"\"17.5k tokens respectively (refer Appendix C).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_30",
            "start": 198,
            "end": 301,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_30@4",
            "content": "We report accuracy for classification, F1-Score for the NER, and unlabeled and labeled attachment scores (UAS and LAS) for dependency parsing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_30",
            "start": 303,
            "end": 444,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_31@0",
            "content": "For each task, we run the 3 settings ( \u00a73.2) across multiple languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_31",
            "start": 0,
            "end": 70,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_31@1",
            "content": "For each setting, we also train an AL model with a task-specific acquisition function ( \u00a73.3).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_31",
            "start": 72,
            "end": 165,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_31@2",
            "content": "In addition, we train both the SMA and MMA with all available data, i.e., we use all data to train one model for all languages and one model per language respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_31",
            "start": 167,
            "end": 333,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_31@3",
            "content": "We report an average of 5 runs for each experiment.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_31",
            "start": 335,
            "end": 385,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_31@4",
            "content": "Refer Appendix D for hyperparameters and training details.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_31",
            "start": 387,
            "end": 444,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_32@0",
            "content": "Results and Analysis",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_32",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_33@0",
            "content": "Model Performance: Figure 1 shows the performance of NER on Spanish (refer Appendix H for the plots of all other languages and tasks).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_33",
            "start": 0,
            "end": 133,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_33@1",
            "content": "Although acquiring data independently per language (MMA) performs well, SMA outperforms MMA.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_33",
            "start": 135,
            "end": 226,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_33@2",
            "content": "Unsurprisingly, MonoA with es performs the best in the category, since it allocates its entire budget to acquiring es data; it thus forms an upper-bound of the model performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_33",
            "start": 228,
            "end": 405,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_33@3",
            "content": "However, SMA outperforms MonoA when its seed language and inference language differ.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_33",
            "start": 407,
            "end": 490,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_33@4",
            "content": "Finally, AL consistently provides gains over random acquisition.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_33",
            "start": 492,
            "end": 555,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_34@0",
            "content": "To analyze the performance across all languages, we present the performance for each round of acquisition, aggregated across all languages for Classification (Figure 2) (refer Appendix H for Dependency Parsing and NER plots).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_34",
            "start": 0,
            "end": 224,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_34@1",
            "content": "Here, SMA consistently outperforms MMA for every round of acquisition because MMA suffers from a poorly utilized budget, potentially wasting annotation budget on languages where the task is easier.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_34",
            "start": 226,
            "end": 422,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_34@2",
            "content": "In contrast, SMA improves budget utilization while also benefiting from cross-lingual information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_34",
            "start": 424,
            "end": 521,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_34@3",
            "content": "Finally, SMA, by virtue of performing well irrespective of language, consistently outperforms MonoA.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_34",
            "start": 523,
            "end": 622,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_35@0",
            "content": "For a concise overview, we present the aggregate metrics across all rounds for each task in Table 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_35",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_35@1",
            "content": "We observe that SMA does much better compared to its counterparts; both with and without AL.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_35",
            "start": 101,
            "end": 192,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_35@2",
            "content": "We also observe these models to be extremely data efficient: with AL, a model with access to less than 5% of the data achieves a (relative) performance of around 88% accuracy (for classification), 95.5% F1-score (for NER) and 93.5% LAS (for dependency parsing) when compared to a model trained with all available data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_35",
            "start": 194,
            "end": 511,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_35@3",
            "content": "Further, along with its superior performance, SMA also affords substantial parameter savings: requiring only a single model, compared to a number of models linear in n (thereby using 1 n th parameters compared to MMA).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_35",
            "start": 513,
            "end": 730,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_35@4",
            "content": "MM Full vs SM Full: To analyze how effectively a single model performs on the languages in question despite using 1{n th the parameters, we UAS 76.4 72.9 73.9 72.9 44.3 84.8 86.0 76.9 73.0 74.0 73.4 44.2 84.5 86.3 91.3 91.3 LAS 67.2 62.3 62.8 61.8 31.8 78.0 79.3 67.5 62.4 62.7 62.3 30.8 77.8 79.7 87.1 87.1 Table 1: Average results across all rounds (5%, 10%, 15% and 20% data) and all languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_35",
            "start": 732,
            "end": 1128,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_35@5",
            "content": "train a single model on all data and compare it with n language-specific models, where each of the n models has the same number of parameters as the single model; this also serves as an upper-bound for our AL experiments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_35",
            "start": 1130,
            "end": 1350,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_35@6",
            "content": "The rightmost columns of Table 1 show that having a single model does not adversely impact performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_35",
            "start": 1352,
            "end": 1454,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_35@7",
            "content": "A more detailed discussion is present in Appendix E.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_35",
            "start": 1456,
            "end": 1507,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_36@0",
            "content": "The effectiveness of AL in MonoA: We consistently observe AL in the source language improving performance across all languages, irrespective of whether inference is being run for the source language or zero-shot on a different target language, both for NER and classification (Table 1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_36",
            "start": 0,
            "end": 285,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_36@1",
            "content": "We hypothesize that the model selects semantically difficult or ambiguous examples that generalize across languages by virtue of mBERT's shared embedding representation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_36",
            "start": 287,
            "end": 455,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_36@2",
            "content": "To the best of our knowledge, this work is the first to demonstrate that AL can improve the data efficiency of both classification and NER in a zero-shot inference setup.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_36",
            "start": 457,
            "end": 626,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_37@0",
            "content": "In the case of dependency parsing, we observe mixed results when the source and target languages differ.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_37",
            "start": 0,
            "end": 103,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_37@1",
            "content": "We hypothesize that this is because dependency parsing is a syntactic problem, making it more language specific, and zero-shot inference inherently harder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_37",
            "start": 105,
            "end": 259,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_37@2",
            "content": "This is in contrast with both classification and NER, which are more semantic, making hard examples more generalizable across languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_37",
            "start": 261,
            "end": 396,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_37@3",
            "content": "Refer Appendix F for more details.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_37",
            "start": 398,
            "end": 431,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_37@4",
            "content": "What does SMA+AL acquire?",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_37",
            "start": 433,
            "end": 457,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_37@5",
            "content": "One advantage of the SMA+AL setup is that the model can arbitrate between allocating its acquisition budget across different languages as training progresses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_37",
            "start": 459,
            "end": 616,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_37@6",
            "content": "This is in contrast with training one model per language, where the models for languages with a high performance waste the overall budget by acquiring more than necessary, while models on languages where performance isn't as good under-acquire.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_37",
            "start": 618,
            "end": 861,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_38@0",
            "content": "To investigate this, for each language and each round, we plot the relative difference (%) between cumulative tokens acquired by the SMA+AL model for that language, and the tokens acquired in expectation if acquisition was done randomly (refer Appendix G for more details).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_38",
            "start": 0,
            "end": 272,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_38@1",
            "content": "For each language, we also plot the relative performance difference of the language at that round compared to the performance when 100% data is available.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_38",
            "start": 274,
            "end": 427,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_39@0",
            "content": "Figure 3 reveals the added benefit of SMA+AL for data acquisition for NER (refer Appendix G for other tasks): a single model can arbitrate between instances across languages automatically.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_39",
            "start": 0,
            "end": 187,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_39@1",
            "content": "The model initially acquires data from the high resource language (English). But as the training proceeds, the model favors acquiring data from languages it is uncertain about.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_39",
            "start": 189,
            "end": 364,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_39@2",
            "content": "This \"multilingual curriculum\" thus allows the model to be more effective in its use of the annotation budget.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_39",
            "start": 366,
            "end": 475,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_39@3",
            "content": "We find SMA+AL eventually achieves a similar relative difference from 100% data performance for all languages consistently across tasks as a consequence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_39",
            "start": 477,
            "end": 629,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_40@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_40",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_41@0",
            "content": "In this work, we consider the problem of efficiently building models that solve a task across multiple languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_41",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_41@1",
            "content": "We show that, contrary to traditional approaches, a single model arbitrating between multiple languages for data acquisition considerably improves performance in a constrained budget scenario, with AL providing additional benefits.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_41",
            "start": 114,
            "end": 344,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_42@0",
            "content": "In this section, we elaborate on the task specific adaptations: Classification: As is common practice, we use a single linear layer over [CLS] embeddings generated by the BERT model to generate logits for the classification task, and the model is trained to minimize the cross-entropy loss.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_42",
            "start": 0,
            "end": 289,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_43@0",
            "content": "Sequence Tagging: We apply a linear layer to the word embeddings 1 generated by the BERT model to generate the tag logits, and the model is trained to minimize the negative log-likelihood of the observed tags.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_43",
            "start": 0,
            "end": 208,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_44@0",
            "content": "Dependency Parsing: We use a graph-based biaffine attention parser introduced in (Dozat and Manning, 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_44",
            "start": 0,
            "end": 106,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_44@1",
            "content": "Following (Kondratyuk and Straka, 2019), we use the output of the last BERT layer in place of the embeddings generated by the Bi-LSTM layers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_44",
            "start": 108,
            "end": 248,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_44@2",
            "content": "These embeddings are then concatenated with the POS embeddings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_44",
            "start": 250,
            "end": 312,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_44@3",
            "content": "A head feed-forward network and a child feed-forward network then generate embeddings for each head and dependant word of a dependency respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_44",
            "start": 314,
            "end": 461,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_44@4",
            "content": "This is combined with a biaffine attention module to generate a probability distribution for each word to predict its head, as well as a bilinear layer to predict the label for each dependency relationship.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_44",
            "start": 463,
            "end": 668,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_44@5",
            "content": "Let \u03c4 piq \" tph pi,jq , d pi,jq , l pi,jq |h pi,jq \u00f1 d pi,jq with label l pi,jq u be the i th gold dependency tree in the dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_44",
            "start": 670,
            "end": 799,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_44@6",
            "content": "The model is then trained to maximize the log probability of the gold tree as :",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_44",
            "start": 801,
            "end": 879,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_45@0",
            "content": "max \u00ff i \u00ff j log `Pph pi,jq |d pi,jq q log `Ppl pi,jq |h pi,jq \u00f1 d pi,jq q \u02d8(1)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_45",
            "start": 0,
            "end": 77,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_46@0",
            "content": "During inference, the best dependency parse is generated by decoding with Chu-Liu/Edmonds algorithm (Chu, 1965;Edmonds, 1967).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_46",
            "start": 0,
            "end": 125,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_47@0",
            "content": "For all the models mentioned above, all layers of mBERT are fine-tuned during training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_47",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_48@0",
            "content": "We mention the acquisition functions used below:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_48",
            "start": 0,
            "end": 47,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_49@0",
            "content": "1 Following (Devlin et al., 2019) For words generating multiple wordpieces, we use the embedding of the first wordpiece.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_49",
            "start": 0,
            "end": 119,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_50@0",
            "content": "Maximum Normalized Log Probability (MNLP): This strategy chooses instances for which the log probability of the model prediction, normalized by sequence length, is the lowest.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_50",
            "start": 0,
            "end": 174,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_50@1",
            "content": "This AL strategy has been shown to be extremely effective for NER (Shen et al., 2018) and hence we adopt it in our setting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_50",
            "start": 176,
            "end": 298,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_51@0",
            "content": "Least Confidence (LC): This strategy chooses those instances for which the model confidence corresponding to the predicted class is the least.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_51",
            "start": 0,
            "end": 141,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_51@1",
            "content": "This acquisition strategy has been commonly applied in classification tasks, and although simple, has been consistently shown to often perform extremely well (Settles, 2009); consequently, we adopt it in our setting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_51",
            "start": 143,
            "end": 358,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_52@0",
            "content": "Normalized Log Probability of the Decoded Tree (NLPDT): This strategy selects the instances with the minimum log probability of the decoded tree; i.e given d \u02dato be the tree generated by the Chu-Liu/Edmonds algorithm, the log probability, as computed by Eqn.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_52",
            "start": 0,
            "end": 257,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_52@1",
            "content": "1. Following (Li et al., 2016), we also normalize this score by N , where N indicates the number of tokens.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_52",
            "start": 259,
            "end": 365,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_52@2",
            "content": "We also tried normalizing by N 2 , as well as a globally normalized probability of d \u02da(probability of the tree over all possible valid trees, with the partition function computed using the Matrix Tree Theorem (Koo et al., 2007;Smith and Smith, 2007)), but found both to perform worse.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_52",
            "start": 367,
            "end": 650,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_53@0",
            "content": "We report the detailed dataset statistics in Table 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_53",
            "start": 0,
            "end": 52,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_53@1",
            "content": "Note that the seed was chosen to be roughly 5% of the size of the English training data, shown in the rightmost column of the table.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_53",
            "start": 54,
            "end": 185,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_54@0",
            "content": "Hyperparameters All experiments performed in this paper are averaged over 5 runs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_54",
            "start": 0,
            "end": 80,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_54@1",
            "content": "For each experiment, we perform an LR search over (1e-5, 2e-5, 3e-5, 4e-5 and 5e-5), and choose the best LR according to the performance on the appropriate validation (sub)set, as recommended in (Devlin et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_54",
            "start": 82,
            "end": 298,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_54@2",
            "content": "In all experiments, we set the batch size to 32 and use an Adam (Kingma and Ba, 2015) optimizer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_54",
            "start": 300,
            "end": 395,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_54@3",
            "content": "Each round of training is run with a patience of 25 epochs, for at most 75 epochs in total.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_54",
            "start": 397,
            "end": 487,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_55@0",
            "content": "Data Preprocessing To avoid out-of-memory issues on the GPU, we pre-process the data so that the examples in the train set of length larger than 175 and with larger than 256 word-pieces are filtered out for the NER.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_55",
            "start": 0,
            "end": 214,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_55@1",
            "content": "For classification, we simply truncate all instances at 256 word-pieces.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_55",
            "start": 216,
            "end": 287,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_55@2",
            "content": "We also de-duplicate the train set, to ensure that during all AL acquisition stages, no duplicates are selected at any point.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_55",
            "start": 289,
            "end": 413,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_56@0",
            "content": "Code All code used in this work was implemented using Python, PyTorch and AllenNLP (Gardner et al., 2018), using pre-trained models released by HuggingFace (Wolf et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_56",
            "start": 0,
            "end": 175,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_57@0",
            "content": "Given that the SMA setup uses 1{n th the number of parameters, an interesting question is whether fewer parameters leads to a loss in any expressive power for the single model, which might potentially lead to poorer performance (curse of multilinguality (Conneau et al., 2020)).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_57",
            "start": 0,
            "end": 277,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_57@1",
            "content": "To answer this question, we train a single model on all data and compare it with n language-specific models, where each of the n models has the same number of parameters as the single model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_57",
            "start": 279,
            "end": 468,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_58@0",
            "content": "From the 100% (rightmost) columns of Table 1, we find that having a single model does not adversely impact performance and these trends hold irrespective of whether all the languages in the task are etymologically close (as in NER) or distant (ja for classification and dependency parsing).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_58",
            "start": 0,
            "end": 289,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_58@1",
            "content": "This might not be the case when there are a large number of languages, however; investigating how well this observation scales with the number of languages would be an interesting line of future work.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_58",
            "start": 291,
            "end": 490,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_59@0",
            "content": "An interesting observation from Table 1 is that AL in the source language helps improve performance across all languages, irrespective of whether the inference is being run for the source language in question or zero-shot on a different target language without any training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_59",
            "start": 0,
            "end": 273,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_59@1",
            "content": "We observe this to be the case consistently for both the NER and the classification tasks (refer Figure 4 for classification and Appendix I for the other tasks), regardless of the source language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_59",
            "start": 275,
            "end": 470,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_59@2",
            "content": "We hypothesize that this is because the model selects semantically difficult or ambiguous examples that generalize across languages by virtue of mBERT's shared embedding representation, in contrast with random selection where easy examples the model can already tackle might be selected.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_59",
            "start": 472,
            "end": 758,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_59@3",
            "content": "We observe this even in the case of etymologically distant languages, such as when the model is trained in English and zero-shot inference is done in Japanese (or vice versa).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_59",
            "start": 760,
            "end": 934,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_59@4",
            "content": "Thus, the AL selection does not overfit on the specific language in question, instead choosing difficult but generalizable examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_59",
            "start": 936,
            "end": 1067,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_60@0",
            "content": "We observe mixed results for the MonoA setup for dependency parsing: AL improves substantially over Random when the target language and the source language are the same; however, when they differ, the results are mixed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_60",
            "start": 0,
            "end": 218,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_60@1",
            "content": "We hypothesize that this discrepancy is a consequence of dependency parsing being a syntactic problem, making it more language specific, in turn making zero-shot an inherently harder problem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_60",
            "start": 220,
            "end": 410,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_60@2",
            "content": "This is in contrast with both classification and NER, which are more semantic tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_60",
            "start": 412,
            "end": 495,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_60@3",
            "content": "Consequently, hard examples for the latter tasks might be more generalizable across languages, resulting in their improved AL performance, when compared with the dependency parsing task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_60",
            "start": 497,
            "end": 682,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_60@4",
            "content": "In this section, we describe the analysis of investigating the acquisitions of SMA+AL in more detail.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_60",
            "start": 684,
            "end": 784,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_60@5",
            "content": "Let \u03b1 1 \u00a8\u00a8\u00a8\u03b1 n be the language specific amount of data present in the entire dataset (i.e \u03b1 i \" 0.3 implies that 30% of the entire dataset (training + unlabeled) is of language i), and let \u03b2 1,1 \u00a8\u00a8\u00a8\u03b2 m,n represent the amount of data acquired for every language at every round (i.e \u03b2 i,j indicates the amount of data acquired by language j at round i). Then, for a task t, for each round i and language j, we plot p \u0159 i k\"1 \u03b2 k,j q\u00b4\u03b1 j 9 bt 9 i \u03b1 j 9 bt 9 i .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_60",
            "start": 786,
            "end": 1243,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_61@0",
            "content": "Figures 5 and 6 show the acquisition (as described in Appendix G for both the classification and NER tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_61",
            "start": 0,
            "end": 106,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_61@1",
            "content": "We observe a similar for both the tasks as that for dependency parsing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_61",
            "start": 108,
            "end": 178,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_62@0",
            "content": "This section the additional plots as well as the detailed tables and results for all the experiments presented in the paper.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_62",
            "start": 0,
            "end": 123,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_63@0",
            "content": "Tables 3, 4, 5 and 6 show the performance of the different AL settings on English, Spanish, Dutch and German respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_63",
            "start": 0,
            "end": 121,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_63@1",
            "content": "Each table shows the F-score across 4 acquisition rounds, both with and without MNLP ( \u00a73.2).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_63",
            "start": 123,
            "end": 215,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_63@2",
            "content": "This section shows the plots for the performance of an mBERT model trained on de (the source language) in a MonoAL setting relative to the performance of an mBERT model trained on all de data available (100% data, without AL).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_63",
            "start": 217,
            "end": 442,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_63@3",
            "content": "The performance plots are shown for the dependency parsing (Figure 24) and NER (Figure 25) tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_63",
            "start": 444,
            "end": 540,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_64@0",
            "content": "A David, Noah A Smith,  Smith, Probabilistic models of nonprojective dependency trees, 2007, EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_64",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_65@0",
            "content": "Erik Tjong, Kim Sang, Fien De Meulder, Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition, 2003, NAACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_65",
            "start": 0,
            "end": 143,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_66@0",
            "content": "Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Clara Patrick Von Platen, Yacine Ma, Julien Jernite, Canwen Plu,  Xu, Transformers: State-of-the-art natural language processing, 2020, EMNLP: System Demo, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_66",
            "start": 0,
            "end": 329,
            "label": {}
        },
        {
            "ix": "161-ARR_v1_67@0",
            "content": "UNKNOWN, None, , Aditya Barua, and Colin Raffel. 2020. mt5: A massively multilingual pre-trained text-to-text transformer, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "161-ARR_v1_67",
            "start": 0,
            "end": 123,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "161-ARR_v1_0",
            "tgt_ix": "161-ARR_v1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_0",
            "tgt_ix": "161-ARR_v1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_1",
            "tgt_ix": "161-ARR_v1_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_1",
            "tgt_ix": "161-ARR_v1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_1",
            "tgt_ix": "161-ARR_v1_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_2",
            "tgt_ix": "161-ARR_v1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_1",
            "tgt_ix": "161-ARR_v1_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_3",
            "tgt_ix": "161-ARR_v1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_1",
            "tgt_ix": "161-ARR_v1_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_4",
            "tgt_ix": "161-ARR_v1_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_0",
            "tgt_ix": "161-ARR_v1_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_5",
            "tgt_ix": "161-ARR_v1_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_7",
            "tgt_ix": "161-ARR_v1_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_8",
            "tgt_ix": "161-ARR_v1_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_9",
            "tgt_ix": "161-ARR_v1_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_10",
            "tgt_ix": "161-ARR_v1_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_6",
            "tgt_ix": "161-ARR_v1_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_6",
            "tgt_ix": "161-ARR_v1_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_6",
            "tgt_ix": "161-ARR_v1_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_6",
            "tgt_ix": "161-ARR_v1_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_6",
            "tgt_ix": "161-ARR_v1_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_6",
            "tgt_ix": "161-ARR_v1_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_0",
            "tgt_ix": "161-ARR_v1_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_11",
            "tgt_ix": "161-ARR_v1_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_13",
            "tgt_ix": "161-ARR_v1_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_12",
            "tgt_ix": "161-ARR_v1_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_12",
            "tgt_ix": "161-ARR_v1_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_12",
            "tgt_ix": "161-ARR_v1_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_0",
            "tgt_ix": "161-ARR_v1_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_14",
            "tgt_ix": "161-ARR_v1_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_15",
            "tgt_ix": "161-ARR_v1_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_15",
            "tgt_ix": "161-ARR_v1_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_16",
            "tgt_ix": "161-ARR_v1_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_16",
            "tgt_ix": "161-ARR_v1_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_15",
            "tgt_ix": "161-ARR_v1_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_17",
            "tgt_ix": "161-ARR_v1_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_19",
            "tgt_ix": "161-ARR_v1_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_20",
            "tgt_ix": "161-ARR_v1_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_21",
            "tgt_ix": "161-ARR_v1_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_18",
            "tgt_ix": "161-ARR_v1_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_18",
            "tgt_ix": "161-ARR_v1_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_18",
            "tgt_ix": "161-ARR_v1_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_18",
            "tgt_ix": "161-ARR_v1_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_18",
            "tgt_ix": "161-ARR_v1_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_15",
            "tgt_ix": "161-ARR_v1_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_22",
            "tgt_ix": "161-ARR_v1_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_23",
            "tgt_ix": "161-ARR_v1_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_23",
            "tgt_ix": "161-ARR_v1_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_0",
            "tgt_ix": "161-ARR_v1_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_24",
            "tgt_ix": "161-ARR_v1_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_25",
            "tgt_ix": "161-ARR_v1_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_25",
            "tgt_ix": "161-ARR_v1_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_27",
            "tgt_ix": "161-ARR_v1_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_26",
            "tgt_ix": "161-ARR_v1_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_26",
            "tgt_ix": "161-ARR_v1_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_26",
            "tgt_ix": "161-ARR_v1_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_25",
            "tgt_ix": "161-ARR_v1_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_28",
            "tgt_ix": "161-ARR_v1_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_30",
            "tgt_ix": "161-ARR_v1_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_29",
            "tgt_ix": "161-ARR_v1_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_29",
            "tgt_ix": "161-ARR_v1_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_29",
            "tgt_ix": "161-ARR_v1_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_0",
            "tgt_ix": "161-ARR_v1_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_31",
            "tgt_ix": "161-ARR_v1_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_33",
            "tgt_ix": "161-ARR_v1_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_34",
            "tgt_ix": "161-ARR_v1_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_35",
            "tgt_ix": "161-ARR_v1_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_36",
            "tgt_ix": "161-ARR_v1_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_37",
            "tgt_ix": "161-ARR_v1_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_38",
            "tgt_ix": "161-ARR_v1_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_32",
            "tgt_ix": "161-ARR_v1_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_32",
            "tgt_ix": "161-ARR_v1_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_32",
            "tgt_ix": "161-ARR_v1_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_32",
            "tgt_ix": "161-ARR_v1_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_32",
            "tgt_ix": "161-ARR_v1_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_32",
            "tgt_ix": "161-ARR_v1_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_32",
            "tgt_ix": "161-ARR_v1_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_32",
            "tgt_ix": "161-ARR_v1_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_0",
            "tgt_ix": "161-ARR_v1_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_39",
            "tgt_ix": "161-ARR_v1_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_40",
            "tgt_ix": "161-ARR_v1_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_40",
            "tgt_ix": "161-ARR_v1_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_42",
            "tgt_ix": "161-ARR_v1_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_43",
            "tgt_ix": "161-ARR_v1_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_44",
            "tgt_ix": "161-ARR_v1_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_45",
            "tgt_ix": "161-ARR_v1_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_46",
            "tgt_ix": "161-ARR_v1_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_40",
            "tgt_ix": "161-ARR_v1_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_40",
            "tgt_ix": "161-ARR_v1_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_40",
            "tgt_ix": "161-ARR_v1_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_40",
            "tgt_ix": "161-ARR_v1_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_40",
            "tgt_ix": "161-ARR_v1_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_40",
            "tgt_ix": "161-ARR_v1_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_41",
            "tgt_ix": "161-ARR_v1_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_48",
            "tgt_ix": "161-ARR_v1_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_49",
            "tgt_ix": "161-ARR_v1_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_50",
            "tgt_ix": "161-ARR_v1_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_51",
            "tgt_ix": "161-ARR_v1_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_40",
            "tgt_ix": "161-ARR_v1_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_40",
            "tgt_ix": "161-ARR_v1_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_40",
            "tgt_ix": "161-ARR_v1_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_40",
            "tgt_ix": "161-ARR_v1_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_40",
            "tgt_ix": "161-ARR_v1_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_47",
            "tgt_ix": "161-ARR_v1_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_40",
            "tgt_ix": "161-ARR_v1_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_52",
            "tgt_ix": "161-ARR_v1_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_54",
            "tgt_ix": "161-ARR_v1_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_55",
            "tgt_ix": "161-ARR_v1_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_40",
            "tgt_ix": "161-ARR_v1_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_40",
            "tgt_ix": "161-ARR_v1_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_40",
            "tgt_ix": "161-ARR_v1_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_53",
            "tgt_ix": "161-ARR_v1_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_57",
            "tgt_ix": "161-ARR_v1_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_40",
            "tgt_ix": "161-ARR_v1_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_40",
            "tgt_ix": "161-ARR_v1_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_56",
            "tgt_ix": "161-ARR_v1_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_59",
            "tgt_ix": "161-ARR_v1_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_40",
            "tgt_ix": "161-ARR_v1_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_40",
            "tgt_ix": "161-ARR_v1_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_58",
            "tgt_ix": "161-ARR_v1_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_40",
            "tgt_ix": "161-ARR_v1_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_60",
            "tgt_ix": "161-ARR_v1_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_40",
            "tgt_ix": "161-ARR_v1_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_61",
            "tgt_ix": "161-ARR_v1_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_40",
            "tgt_ix": "161-ARR_v1_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_62",
            "tgt_ix": "161-ARR_v1_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "161-ARR_v1_0",
            "tgt_ix": "161-ARR_v1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_1",
            "tgt_ix": "161-ARR_v1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_2",
            "tgt_ix": "161-ARR_v1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_2",
            "tgt_ix": "161-ARR_v1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_2",
            "tgt_ix": "161-ARR_v1_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_2",
            "tgt_ix": "161-ARR_v1_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_2",
            "tgt_ix": "161-ARR_v1_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_2",
            "tgt_ix": "161-ARR_v1_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_3",
            "tgt_ix": "161-ARR_v1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_4",
            "tgt_ix": "161-ARR_v1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_4",
            "tgt_ix": "161-ARR_v1_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_4",
            "tgt_ix": "161-ARR_v1_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_5",
            "tgt_ix": "161-ARR_v1_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_5",
            "tgt_ix": "161-ARR_v1_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_5",
            "tgt_ix": "161-ARR_v1_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_6",
            "tgt_ix": "161-ARR_v1_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_7",
            "tgt_ix": "161-ARR_v1_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_7",
            "tgt_ix": "161-ARR_v1_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_7",
            "tgt_ix": "161-ARR_v1_7@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_8",
            "tgt_ix": "161-ARR_v1_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_9",
            "tgt_ix": "161-ARR_v1_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_9",
            "tgt_ix": "161-ARR_v1_9@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_9",
            "tgt_ix": "161-ARR_v1_9@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_9",
            "tgt_ix": "161-ARR_v1_9@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_10",
            "tgt_ix": "161-ARR_v1_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_10",
            "tgt_ix": "161-ARR_v1_10@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_11",
            "tgt_ix": "161-ARR_v1_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_11",
            "tgt_ix": "161-ARR_v1_11@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_11",
            "tgt_ix": "161-ARR_v1_11@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_11",
            "tgt_ix": "161-ARR_v1_11@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_11",
            "tgt_ix": "161-ARR_v1_11@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_11",
            "tgt_ix": "161-ARR_v1_11@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_11",
            "tgt_ix": "161-ARR_v1_11@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_11",
            "tgt_ix": "161-ARR_v1_11@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_12",
            "tgt_ix": "161-ARR_v1_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_13",
            "tgt_ix": "161-ARR_v1_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_13",
            "tgt_ix": "161-ARR_v1_13@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_13",
            "tgt_ix": "161-ARR_v1_13@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_13",
            "tgt_ix": "161-ARR_v1_13@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_14",
            "tgt_ix": "161-ARR_v1_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_14",
            "tgt_ix": "161-ARR_v1_14@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_14",
            "tgt_ix": "161-ARR_v1_14@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_14",
            "tgt_ix": "161-ARR_v1_14@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_15",
            "tgt_ix": "161-ARR_v1_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_16",
            "tgt_ix": "161-ARR_v1_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_17",
            "tgt_ix": "161-ARR_v1_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_17",
            "tgt_ix": "161-ARR_v1_17@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_18",
            "tgt_ix": "161-ARR_v1_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_19",
            "tgt_ix": "161-ARR_v1_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_19",
            "tgt_ix": "161-ARR_v1_19@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_19",
            "tgt_ix": "161-ARR_v1_19@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_19",
            "tgt_ix": "161-ARR_v1_19@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_20",
            "tgt_ix": "161-ARR_v1_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_20",
            "tgt_ix": "161-ARR_v1_20@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_20",
            "tgt_ix": "161-ARR_v1_20@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_21",
            "tgt_ix": "161-ARR_v1_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_21",
            "tgt_ix": "161-ARR_v1_21@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_22",
            "tgt_ix": "161-ARR_v1_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_22",
            "tgt_ix": "161-ARR_v1_22@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_22",
            "tgt_ix": "161-ARR_v1_22@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_22",
            "tgt_ix": "161-ARR_v1_22@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_23",
            "tgt_ix": "161-ARR_v1_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_24",
            "tgt_ix": "161-ARR_v1_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_24",
            "tgt_ix": "161-ARR_v1_24@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_24",
            "tgt_ix": "161-ARR_v1_24@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_25",
            "tgt_ix": "161-ARR_v1_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_26",
            "tgt_ix": "161-ARR_v1_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_27",
            "tgt_ix": "161-ARR_v1_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_27",
            "tgt_ix": "161-ARR_v1_27@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_28",
            "tgt_ix": "161-ARR_v1_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_29",
            "tgt_ix": "161-ARR_v1_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_30",
            "tgt_ix": "161-ARR_v1_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_30",
            "tgt_ix": "161-ARR_v1_30@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_30",
            "tgt_ix": "161-ARR_v1_30@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_30",
            "tgt_ix": "161-ARR_v1_30@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_30",
            "tgt_ix": "161-ARR_v1_30@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_31",
            "tgt_ix": "161-ARR_v1_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_31",
            "tgt_ix": "161-ARR_v1_31@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_31",
            "tgt_ix": "161-ARR_v1_31@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_31",
            "tgt_ix": "161-ARR_v1_31@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_31",
            "tgt_ix": "161-ARR_v1_31@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_32",
            "tgt_ix": "161-ARR_v1_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_33",
            "tgt_ix": "161-ARR_v1_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_33",
            "tgt_ix": "161-ARR_v1_33@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_33",
            "tgt_ix": "161-ARR_v1_33@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_33",
            "tgt_ix": "161-ARR_v1_33@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_33",
            "tgt_ix": "161-ARR_v1_33@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_34",
            "tgt_ix": "161-ARR_v1_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_34",
            "tgt_ix": "161-ARR_v1_34@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_34",
            "tgt_ix": "161-ARR_v1_34@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_34",
            "tgt_ix": "161-ARR_v1_34@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_35",
            "tgt_ix": "161-ARR_v1_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_35",
            "tgt_ix": "161-ARR_v1_35@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_35",
            "tgt_ix": "161-ARR_v1_35@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_35",
            "tgt_ix": "161-ARR_v1_35@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_35",
            "tgt_ix": "161-ARR_v1_35@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_35",
            "tgt_ix": "161-ARR_v1_35@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_35",
            "tgt_ix": "161-ARR_v1_35@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_35",
            "tgt_ix": "161-ARR_v1_35@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_36",
            "tgt_ix": "161-ARR_v1_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_36",
            "tgt_ix": "161-ARR_v1_36@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_36",
            "tgt_ix": "161-ARR_v1_36@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_37",
            "tgt_ix": "161-ARR_v1_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_37",
            "tgt_ix": "161-ARR_v1_37@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_37",
            "tgt_ix": "161-ARR_v1_37@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_37",
            "tgt_ix": "161-ARR_v1_37@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_37",
            "tgt_ix": "161-ARR_v1_37@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_37",
            "tgt_ix": "161-ARR_v1_37@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_37",
            "tgt_ix": "161-ARR_v1_37@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_38",
            "tgt_ix": "161-ARR_v1_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_38",
            "tgt_ix": "161-ARR_v1_38@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_39",
            "tgt_ix": "161-ARR_v1_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_39",
            "tgt_ix": "161-ARR_v1_39@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_39",
            "tgt_ix": "161-ARR_v1_39@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_39",
            "tgt_ix": "161-ARR_v1_39@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_40",
            "tgt_ix": "161-ARR_v1_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_41",
            "tgt_ix": "161-ARR_v1_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_41",
            "tgt_ix": "161-ARR_v1_41@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_42",
            "tgt_ix": "161-ARR_v1_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_43",
            "tgt_ix": "161-ARR_v1_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_44",
            "tgt_ix": "161-ARR_v1_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_44",
            "tgt_ix": "161-ARR_v1_44@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_44",
            "tgt_ix": "161-ARR_v1_44@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_44",
            "tgt_ix": "161-ARR_v1_44@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_44",
            "tgt_ix": "161-ARR_v1_44@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_44",
            "tgt_ix": "161-ARR_v1_44@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_44",
            "tgt_ix": "161-ARR_v1_44@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_45",
            "tgt_ix": "161-ARR_v1_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_46",
            "tgt_ix": "161-ARR_v1_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_47",
            "tgt_ix": "161-ARR_v1_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_48",
            "tgt_ix": "161-ARR_v1_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_49",
            "tgt_ix": "161-ARR_v1_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_50",
            "tgt_ix": "161-ARR_v1_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_50",
            "tgt_ix": "161-ARR_v1_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_51",
            "tgt_ix": "161-ARR_v1_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_51",
            "tgt_ix": "161-ARR_v1_51@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_52",
            "tgt_ix": "161-ARR_v1_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_52",
            "tgt_ix": "161-ARR_v1_52@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_52",
            "tgt_ix": "161-ARR_v1_52@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_53",
            "tgt_ix": "161-ARR_v1_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_53",
            "tgt_ix": "161-ARR_v1_53@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_54",
            "tgt_ix": "161-ARR_v1_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_54",
            "tgt_ix": "161-ARR_v1_54@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_54",
            "tgt_ix": "161-ARR_v1_54@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_54",
            "tgt_ix": "161-ARR_v1_54@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_55",
            "tgt_ix": "161-ARR_v1_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_55",
            "tgt_ix": "161-ARR_v1_55@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_55",
            "tgt_ix": "161-ARR_v1_55@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_56",
            "tgt_ix": "161-ARR_v1_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_57",
            "tgt_ix": "161-ARR_v1_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_57",
            "tgt_ix": "161-ARR_v1_57@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_58",
            "tgt_ix": "161-ARR_v1_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_58",
            "tgt_ix": "161-ARR_v1_58@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_59",
            "tgt_ix": "161-ARR_v1_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_59",
            "tgt_ix": "161-ARR_v1_59@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_59",
            "tgt_ix": "161-ARR_v1_59@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_59",
            "tgt_ix": "161-ARR_v1_59@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_59",
            "tgt_ix": "161-ARR_v1_59@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_60",
            "tgt_ix": "161-ARR_v1_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_60",
            "tgt_ix": "161-ARR_v1_60@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_60",
            "tgt_ix": "161-ARR_v1_60@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_60",
            "tgt_ix": "161-ARR_v1_60@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_60",
            "tgt_ix": "161-ARR_v1_60@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_60",
            "tgt_ix": "161-ARR_v1_60@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_61",
            "tgt_ix": "161-ARR_v1_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_61",
            "tgt_ix": "161-ARR_v1_61@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_62",
            "tgt_ix": "161-ARR_v1_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_63",
            "tgt_ix": "161-ARR_v1_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_63",
            "tgt_ix": "161-ARR_v1_63@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_63",
            "tgt_ix": "161-ARR_v1_63@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_63",
            "tgt_ix": "161-ARR_v1_63@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_64",
            "tgt_ix": "161-ARR_v1_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_65",
            "tgt_ix": "161-ARR_v1_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_66",
            "tgt_ix": "161-ARR_v1_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "161-ARR_v1_67",
            "tgt_ix": "161-ARR_v1_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 944,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "position_tag_type": "from_draft",
        "doc_id": "161-ARR",
        "version": 1
    }
}