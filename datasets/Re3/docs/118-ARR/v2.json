{
    "nodes": [
        {
            "ix": "118-ARR_v2_0",
            "content": "MINER: Improving Out-of-Vocabulary Named Entity Recognition from an Information Theoretic Perspective",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_2",
            "content": "NER model has achieved promising performance on standard NER benchmarks. However, recent studies show that previous approaches may over-rely on entity mention information, resulting in poor performance on out-of-vocabulary (OOV) entity recognition. In this work, we propose MINER, a novel NER learning framework, to remedy this issue from an information-theoretic perspective. The proposed approach contains two mutual information-based training objectives: i) generalizing information maximization, which enhances representation via deep understanding of context and entity surface forms; ii) superfluous information minimization, which discourages representation from rote memorizing entity names or exploiting biased cues in data. Experiments on various settings and datasets demonstrate that it achieves better performance in predicting OOV entities.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "118-ARR_v2_4",
            "content": "Named Entity Recognition (NER) aims to identify and classify entity mentions from unstructured text, e.g., extracting location mention \"Berlin\" from the sentence \"Berlin is wonderful in the winter\". NER is a key component in information retrieval (Tan et al., 2021), question answering (Min et al., 2021), dialog systems , etc. Traditional NER models are feature-engineering and machine learning based (Zhou and Su, 2002;Takeuchi and Collier, 2002;Agerri and Rigau, 2016). Benefiting from the development of deep learning, neuralnetwork-based NER models have achieved stateof-the-art results on several public benchmarks (Lample et al., 2016;Peters et al., 2018;Devlin et al., 2018;Yamada et al., 2020;Yan et al., 2021).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_5",
            "content": "Recent studies (Lin et al., 2020;Agarwal et al., 2021) show that, context does influence predictions Table 1: The comparison between the in-dictionary and out-of-dictionary parts of the CoNLL 2003 baseline (Lin et al., 2020), which was tested on Bert-CRF. It is obvious that the performance gap between InDict and OutDict is significantly large.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_6",
            "content": "of NER models, but the main factor driving high performance is learning the named tokens themselves. Consequently, NER models underperform when predicting entities that have not been seen during training (Fu et al., 2020;Lin et al., 2020), which is referred to as an Out-of-Vocabulary (OOV) problem.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_7",
            "content": "There are three classical strategies to alleviate the OOV problem: external knowledge, OOV word embedding, and contextualized embedding. The first one is to introduce additional features, e.g., entity lexicons (Zhang and Yang, 2018), part-ofspeech tags , which alleviates the model's dependence on word embeddings. However, the external knowledge is not always easy to obtain. The second strategy is to get a better OOV word embedding (Peng et al., 2019;Fukuda et al., 2020). The strategy is learning a static OOV embedding representation, but not directly utilizing the context. Last one is fine-tune pre-trained models, e.g., ELMo (Peters et al., 2018), BERT (Devlin et al., 2018), which provide contextualized word representations. Unfortunately, Agarwal et al. (2021) shows that the higher performance of pretrained models could be the results of learning the subword structure better.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_8",
            "content": "How do we make the model focus on contextual information to tackle the OOV problem? Motivated by the information bottleneck principle (Tishby et al., 2000), we propose a novel learning framework -Mutual Information based Named Entity Recognition (MINER). The proposed method provides an information-theoretic perspective to the OOV problem by training an encoder to minimize task-irrelevant nuisances while keeping predictive information. Specifically, MINER contains two mutual information based learning objectives: i) generalizing information maximization, which aims to maximize the mutual information between representations and well-generalizing features, i.e., context and entity surface forms; ii) superfluous information minimization, which prevents the model from rote memorizing the entity names or exploiting biased cues via eliminating entity name information. Our codes 1 are publicly available.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_9",
            "content": "Our main contributions are summarized as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_10",
            "content": "1. We propose a novel learning framework, i.e., MINER, from an information theory perspective, aiming to improve the robustness of entity changes by eliminating entity-specific and maximizing wellgeneralizing information.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_11",
            "content": "2. We show its effectiveness on several settings and benchmarks, and suggest that MINER is a reliable approach to better OOV entity recognition.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_12",
            "content": "Background",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "118-ARR_v2_13",
            "content": "In this section, we highlight the information bottleneck principle. Subsequently, the analysis of possible issues was provided when applying it to OOV entity recognition. Furthermore, we review related techniques in deriving our framework.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_14",
            "content": "Information Bottleneck (IB) principle originated in information theory, and provides a theoretical framework for analyzing deep neural networks. It formulates the goal of representation learning as an information trade-off between predictive power and representation compression. Given the input dataset (X,Y), it seeks to learn the internal representation Z of some intermediate layers by:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_15",
            "content": "L IB = \u2212I(Z; Y ) + \u03b2 * I(Z; X),",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_16",
            "content": "where I represents the mutual information(MI), a measure of the mutual dependence between the two variables. The trade-off between the two MI terms is controlled by the Lagrange multiplier \u03b2. A low loss indicates that representation Z does not keep too much information from X while still retaining enough information to predict Y.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_17",
            "content": "Section 5 suggests that directly applying IB to NER can not bring obvious improvement. We argue that IB cannot guarantee well-generalizing representation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_18",
            "content": "On the one hand, it has been shown that it is challenging to find a trade-off between high compression and high predictive power (Tishby et al., 2000;Wang et al., 2019;Piran et al., 2020). When compressing task-irrelevant nuisances, however, useful information will inevitably be left out. On the other hand, it is unclear for the IB principle which parts of features are well-generalizing and which are not, as we usually train a classifier to solely maximize accuracy. Consequently, neural networks tend to use any accessible signal to do so (Ilyas et al., 2019), which is referred to as a shortcut learning problem (Geirhos et al., 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_19",
            "content": "For training sets with limited size, it may be easier for neural networks to memorize entity names rather than to classify them by context and common entity features (Agarwal et al., 2021). In Section 4, we demonstrate how we extend IB to the NER task and address these issues.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_20",
            "content": "Model Architecture",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "118-ARR_v2_21",
            "content": "In recent years, NER systems have undergone a paradigm shift from sequence labeling, which formulates NER as a token-level tagging task (Chiu and Nichols, 2016;Akbik et al., 2018;Yan et al., 2019), to span prediction (SpanNER), which regards NER as a span-level classification task (Mengge et al., 2020;Yamada et al., 2020;Fu et al., 2021). We choose SpanNER as base architecture for two reasons: 1) SpanNER can yield the whole span representation, which can be directly used for optimize information. 2) Compared with sequence labeling, SpanNER does better in sentences with more OOV words (Fu et al., 2021).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_22",
            "content": "Overall, SpanNER consists of three major modules: token representation layer, span representation layer, and span classification layer. Besides, our method inserts a bottleneck layer to the architecture for information optimization.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_23",
            "content": "Token Representation Layer",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "118-ARR_v2_24",
            "content": "Let X = {x 1 , x 2 , \u2022 \u2022 \u2022 , x n } represents the input sentence, thus, the token representation h i is as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_25",
            "content": "u 1 , \u2022 \u2022 \u2022 , u n = Embedding(x 1 , \u2022 \u2022 \u2022 , x n ) (1) h 1 , \u2022 \u2022 \u2022 , h n = Encoder(u 1 , \u2022 \u2022 \u2022 , u n ) (2)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_26",
            "content": "where Embedding() is the non-contextualized word embeddings, e.g., Glove (Pennington et al., 2014) or contextualized word embeddings, e.g., ELMo (Peters et al., 2018), BERT (Devlin et al., 2018). Encoder() can be any network structures with context encoding function, e.g., LSTM (Hochreiter and Schmidhuber, 1997), CNN (LeCun et al., 1995), transformer (Vaswani et al., 2017), and so on.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_27",
            "content": "Span Representation Layer",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "118-ARR_v2_28",
            "content": "For all possible spans S = {s 1 , s 2 , \u2022 \u2022 \u2022 , s m } of sentence X, we re-assign a label y \u2208 Y for each span. Take \"Berlin is wonderful\" as an example, its possible spans and labels are {(1, 1), (1, 2), (1, 3), (2, 2), (2, 3), (3, 3)} and {LOC, O, O, O, O, O}, respectively.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_29",
            "content": "Given the start index b i and end index e i , the representation of span s i can be calculated by two parts: boundary embedding and span length embedding.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_30",
            "content": "Boundary embedding: This part is calculated by concatenating the start and end tokens' representation",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_31",
            "content": "t b i = [h b i ; h e i ].",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_32",
            "content": "Span length embedding: In order to introduce the length feature, we additionally provide the length embedding t l i , which can be obtained by a learnable look-up table.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_33",
            "content": "Finally, the span representation can be obtained as:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_34",
            "content": "t i = [t b i ; t l i ].",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_35",
            "content": "Information Bottleneck Layer",
            "ntype": "title",
            "meta": {
                "section": "3.3"
            }
        },
        {
            "ix": "118-ARR_v2_36",
            "content": "In order to optimize the information in the span representation, our method additionally adds an information bottleneck layer of the form:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_37",
            "content": "p(z|t) = N z | f \u00b5 e (t), f \u03a3 e (t)(3)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_38",
            "content": "where f e is an MLP which outputs both the Kdimensional mean \u00b5 of z as well as the K * K covariance matrix \u03a3. Then we can use the reparameterization trick ((Kingma and Welling, 2013)) to get the compressed representation z i .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_39",
            "content": "Span Classification Layer",
            "ntype": "title",
            "meta": {
                "section": "3.4"
            }
        },
        {
            "ix": "118-ARR_v2_40",
            "content": "Once the information bottleneck layer is finished, z i is fed into the classifier to obtain the probability of its label y i . Based on the probability, the basic loss function can be calculated as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_41",
            "content": "L base = \u2212 score(z i , y i ) y \u2032 \u2208Y score(z i , y \u2032 ) ,(4)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_42",
            "content": "where score() is a function that measures the compatibility between a specified label and a span representation:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_43",
            "content": "score(z i , y k ) = exp(z T i y k ),(5)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_44",
            "content": "where y k is a learnable representation of class k.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_45",
            "content": "Heuristic Decoding A heuristic decoding solution for the flat NER is provided to avoid the prediction of over-lapped spans. For those overlapped spans, we keep the span with the highest prediction probability and drop the others.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_46",
            "content": "It's worth noting that our method is flexible and can be used with any other NER model based on span classification. In next section, we will introduce two additional objectives to tackle the OOV problem of NER.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_47",
            "content": "MI-based objectives",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "118-ARR_v2_48",
            "content": "Motivated by IB (Tishby et al., 2000;Federici et al., 2020), we can subdivide I(X; Z) into two components by using the chain rule of mutual information(MI):",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_49",
            "content": "I(X; Z) = I(Y ; Z) predictive + I(X; Z|Y ) superf luous ,(6)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_50",
            "content": "The first term determines how much information about Y is accessible from Z. While the second term, conditional mutual information term I(X; Z|Y ), denotes the information in Z that is not predictive of Y .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_51",
            "content": "For NER, which parts of the information retrieved from input are useful and which are redundant?",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_52",
            "content": "From human intuition, text context should be the main predictive information for NER. For example, \"The CEO of X resigned\", the type of X in each of these contexts should always be \"ORG\". Besides, entity mentions also provide much information for entity recognition. For example, nearly all person names capitalize the first letter and follow the \"firstName lastName\" or \"lastName firstName\" patterns. However, entity name is not a well-generalizing features. By simply memorizing the fact which span is an entity, it may be possible for it to fit the training set, but it is impossible to predict entities that have never been seen before.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_53",
            "content": "We convert the targets of Eq. ( 6) into a form that is easier to solve via a contrastive strategy. Specifically, consider x 1 and x 2 are two contrastive samples of similar context, and contains different entity mentions of the same entity category, i.e., s 1 and s 2 , respectively. Assuming both x 1 and x 2 are both sufficient for inferring label y. The mutual information between x 1 and z 1 can be factorized to two parts.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_54",
            "content": "I(x 1 ; z 1 ) = I(z 1 ; x 2 ) consistent + I(x 1 ; z 1 |x 2 ) specif ic ,(7)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_55",
            "content": "where z 1 and z 2 are span representations of s 1 and s 2 , respectively, I(z 1 ; x 2 ) denotes the information that isn't entity-specific. And I(x 1 ; z 1 |x 2 ) represents the information in z 1 which is unique to x 1 but is not predictable by sentence x 2 , i.e., entityspecific information.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_56",
            "content": "Thus any representation z containing all information shared from both sentences would also contain the necessary label information, and sentencespecific information is superfluous. So Eq. ( 6) can be approximated by Eq. ( 7) by:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_57",
            "content": "maximize I(z 1 ; y) \u223c I(z 1 ; x 2 ), (8",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_58",
            "content": ") minimize I(x 1 ; z 1 |y) \u223c I(x 1 ; z 1 |x 2 ),(9)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_59",
            "content": "The target of Eq. ( 8) is defined as generalizing information maximization. We proved that I(z 1 ; z 2 ) is a lower bound of I(z 1 ; x 2 )(proof could be found in appendix 7). InfoNCE (Oord et al., 2018) was used as a lower bound on MI and can be used to approximate I(z 1 ; z 2 ). Subsequently, it can be optimized by:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_60",
            "content": "Lgi = \u2212Ep gw(z1, z2) \u2212 E p \u2032 log z \u2032 exp gw(z1, z \u2032 ) ,(10)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_61",
            "content": "where g w (\u2022, \u2022) is a compatible score function approximated by a neural network, z 2 are the positive entity representations from the joint distribution p of original sample and corresponding generated sample, z \u2032 are the negative entity representations drawn from the joint distribution of the original sample and other samples.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_62",
            "content": "The target of Eq. ( 9) is defined as superfluous information minimization. To restrict this term, we can minimize an upper bound of I(x 1 ; z 1 |x 2 ) (proofs could be found in appendix 7) as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_63",
            "content": "L si = E x 1 ,x 2 E z 1 ,z 2 [D JS [p z 1 ||p z 2 ]] ,(11)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_64",
            "content": "where D JS means Jensen-Shannon divergence, p z 1 and p z 2 represent p(z 1 |x 1 ) and p(z 2 |x 2 ), respectively. In practice, Eq. ( 11) encourage z to be invariant to entity changes. The resulting Mutual Information based Named Entity Recognition model is visualized in Figure 1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_65",
            "content": "Contrastive sample generation",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "118-ARR_v2_66",
            "content": "It is difficult to obtain samples with similar contexts but different entity words. We generate contrastive samples by the mention replacement mechanism (Dai and Adel, 2020). For each mention in the sentence, we replace it by another mention from the original training set, which has the same entity type. The corresponding span label can be changed accordingly. For example, \"LOC\" mention \"Berlin\" in sentence \"Berlin is wonderful in the winter\" is replaced by \"Iceland\".",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_67",
            "content": "Training",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "118-ARR_v2_68",
            "content": "Combine Eq. ( 4), (10), and (11), we can get the following objective function, which try to minimize:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_69",
            "content": "L = L base + \u03b3 * L gi + \u03b2 * L si ,(12)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_70",
            "content": "where \u03b3 and \u03b2 are the weights of the generalizing information loss and superfluous information loss, respectively.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_71",
            "content": "Experiment",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "118-ARR_v2_72",
            "content": "In this section, we verify the performance of the proposed method on five OOV datasets, and compared it with other methods. In addition, We tested the universality of the proposed method in various pre-trained models.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_73",
            "content": "Datasets and Metrics",
            "ntype": "title",
            "meta": {
                "section": "5.1"
            }
        },
        {
            "ix": "118-ARR_v2_74",
            "content": "Datasets We performed experiments on:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_75",
            "content": "1. WNUT2017 (Derczynski et al., 2017), a dataset focus on unusual, previous-unseen entities in training data, and is collected from social media.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_76",
            "content": "2. TwitterNER , an English NER dataset created from Tweets.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_77",
            "content": "3. BioNER (Kim et al., 2004) Metrics We measured the entity-level micro average F1 score on the test set to compare the results of different models. 2020) share the same intuition as us, enriching word representations with context. However, the work is neither open source nor reported on the same dataset, so this method cannot be compared with MINER. We compare our method with baselines as follows: \u2022 Li et al. (2021) (MIN), which utilizes both segment-level information and word-level dependencies, and incorporates an interaction mechanism to support information sharing between boundary detection and type prediction, enhancing the performance for the NER task.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_78",
            "content": "Baseline methods",
            "ntype": "title",
            "meta": {
                "section": "5.2"
            }
        },
        {
            "ix": "118-ARR_v2_79",
            "content": "\u2022 Fukuda et al. (2020) (CoFEE), which refer to pre-trained word embeddings for known words with similar surfaces to target OOV words. \u2022 Nie et al. (2020) (SA-NER), which utilize semantic enhancement methods to reduce the negative impact of data sparsity problems. Specifically, the method obtains the augmented semantic information from a largescale corpus, and proposes an attentive semantic augmentation module and a gate module to encode and aggregate such information, respectively.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_80",
            "content": "To verify the universality of our method, we measured its performance on various pre-trained models, i.e., Bert (Devlin et al., 2018), Roberta (Liu et al., 2019), Albert (Lan et al., 2019).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_81",
            "content": "Implementation Details",
            "ntype": "title",
            "meta": {
                "section": "5.3"
            }
        },
        {
            "ix": "118-ARR_v2_82",
            "content": "Bert-large released by Devlin et al. (2018) is selected as our base encoder. The learning rate is set to 5e-5, and the dropout is set to 0.2. The output dim of the information bottleneck layer is 50. In order to make a trade-off for the performance and efficiency, on the one hand, we truncate the part of the sentence whose tokens exceeds 128. On the other hand, we count the length distribution of entity length in different datasets, and finally choose 4 as the maximum enumerated entity length. The values of \u03b2 and \u03b3 differ for different datasets. Empirically, 1e-5 for \u03b2 and 0.01 for \u03b3 can get promised results. The model is trained in an NVIDIA GeForce RTX 2080Ti GPU. Checkpoints with top-3 performance are finally evaluated on the test set to report averaged results.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_83",
            "content": "Main Results",
            "ntype": "title",
            "meta": {
                "section": "5.4"
            }
        },
        {
            "ix": "118-ARR_v2_84",
            "content": "We demonstrate the effectiveness of MINER against other state-of-the-art models. As shown in table 3, we conducted the following comparison and analysis:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_85",
            "content": "1) Our baseline model, i.e., SpanNER, does an excellent job of predicting OOV entities. Compared with sequence labeling, the span classification could model the relation of entity tokens directly;2) The performance of SpanNER is further boosted with our proposed approach, which proved the effectiveness of our method. As shown in table 3, MINER almost outperforms all other SOTA methods without any external resource;3) Compared with Typos data transformation, it is more difficult for models to predict OOV words. The results are obtained by testing MINER (Bert large) on TwitterNER . We fix \u03b2 = 1e03, and the orange line is f1 score when \u03b3 = 0. The results are obtained by testing MINER (Bert large) on TwitterNER . We fix \u03b3 = 1e04, and the orange line is f1 score when \u03b2 = 0.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_86",
            "content": "To pre-trained model, typos word may not appear in training set, but they share most subwords with the original token. Moreover, the subword of OOV entity may be rare; 4) It seems that the traditional information bottleneck will not significantly improve the OOV prediction ability of the model. We argue that the traditional information bottlenecks will indiscriminately compress the information in the representation, leading to underfitting; 5) Our model has significantly improved the performance of the model on the entity perturbed methods of typos and OOV, demonstrating that MI improve the robustness substantially in the face of noise; 6) It is clear that our proposed method is universal and can further improve OOV prediction performance for different embedding models, as we get improvements on Bert, Roberta, and Albert stably.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_87",
            "content": "Ablation Study",
            "ntype": "title",
            "meta": {
                "section": "5.5"
            }
        },
        {
            "ix": "118-ARR_v2_88",
            "content": "We also perform ablation studies to validate the effectiveness of each part in MINER.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_89",
            "content": "Sensitivity Analysis of \u03b2 and \u03b3",
            "ntype": "title",
            "meta": {
                "section": "5.6"
            }
        },
        {
            "ix": "118-ARR_v2_90",
            "content": "To show the different influence of our proposed training objectives L gi and L si , we conduct sensitivity analysis of the coefficient \u03b2 and \u03b3. Figure 2 shows the performance change under different settings of the two coefficients. The yellow line denotes ablation results without the corresponding loss functions (with \u03b2=0 or \u03b3=0). From Figure 2 we can observe that the performance is significantly enhanced with a small rate of \u03b2 or \u03b3, where the best performance is achieved when \u03b2=1e-3 and \u03b3=1e-4, respectively. It probes the effectiveness of our proposed training objectives that enhances representation via deep understanding of context and entity surface forms and discourages representation from rote memorizing entity names or exploiting biased cues in data. As the coefficient rate increases continuously, the performance shows a declining trend, which means the over-constraint of L gi or L si will hurt the generalizing ability of predicting the OOV entities.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_91",
            "content": "Interpretable Analysis",
            "ntype": "title",
            "meta": {
                "section": "5.7"
            }
        },
        {
            "ix": "118-ARR_v2_92",
            "content": "The above experiments show the promising performance of MINER on predicting the unseen entities. To further investigate which part of the sentence MINER focuses on, we visualize the attention weights over entities and contexts. We demonstrate an example in Figure 4 , where is selected from TwitterNER. The attention score is calculated by averaging the attention weight of the 0th layer of BERT. Take the attention weights of the entity \"State Street\" as an example, it is obvious that baseline model, i.e., SpanNER, focus on entity words themselves. While the scores of our model are more average, it means that our method concerns more context information.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_93",
            "content": "6 Related Work",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_94",
            "content": "External Knowledge",
            "ntype": "title",
            "meta": {
                "section": "6.1"
            }
        },
        {
            "ix": "118-ARR_v2_95",
            "content": "This group of methods makes it easier to predict OOV entities using external knowledge. Zhang and Yang (2018) utilize a dictionary to list numerous entity mentions. It is possible to get stronger \"lookup\" models by integrating dictionary information, but there is no guarantee that entities outside the training set and vocabulary will be correctly identified. To diminish the model's dependency on OOV embedding, introduce partof-speech tags. External resources are not always available, which is a limitation of this strategy.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_96",
            "content": "OOV word Embedding",
            "ntype": "title",
            "meta": {
                "section": "6.2"
            }
        },
        {
            "ix": "118-ARR_v2_97",
            "content": "The OOV problem can be alleviated by improving the OOV word embedding. The character ngram of each word is used by Bojanowski et al. (2017) to represent the OOV word embedding. Pinter et al. (2017) captures morphological features using character-level RNN. Another technique is to first match the OOV words with the words that have been seen in training, then replace the OOV words' embedding with the seen words' embedding. Peng et al. (2019) trains a student network to predict the closest word representation to the OOV term. Fukuda et al. (2020) referring to pre-trained word embeddings for known words with similar surfaces to target OOV words. This kind of method is learning a static OOV embedding representation, and does not directly utilize the context.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_98",
            "content": "Contextualized Embedding",
            "ntype": "title",
            "meta": {
                "section": "6.3"
            }
        },
        {
            "ix": "118-ARR_v2_99",
            "content": "Contextual information is used to enhance the representation of OOV words in this strategy. (Hu et al., 2019) formulate the OOV problem as a Kshot regression problem and learns to predict the OOV embedding by aggregating only K contexts and morphological features. Pre-trained models contextualized word embeddings via pretraining on large background corpora. Furthermore, contextualized word embeddings can be provided by the pre-trained models, which are pre-trained on large background corpora (Peters et al., 2018;Devlin et al., 2018;Liu et al., 2019). Yan et al. (2021) shows that BERT is not always better at capturing context as compared to Gloe-based BiLSTM-CRFs. Their higher performance could be the result of learning the subword structure better.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_100",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "7"
            }
        },
        {
            "ix": "118-ARR_v2_101",
            "content": "Based on the recent studies of NER, we analyze how to improve the OOV entity recognition. In this work, we propose a novel and flexible learning framework -MINER, to tackle OOV entities recognition issue from an information-theoretic perspective. On the one hand, this method can enhance the context information of the output of the encoder. On the other hand, it can safely eliminate task-irrelevant nuisances and prevents the model from rote memorizing the entities. Specifically, the proposed approach contains two mutual information based training objectives: generalizing information maximization, and superfluous information minimization. Experiments on various datasets demonstrate that MINER achieves much better performance in predicting out-of-vocabulary entities.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "118-ARR_v2_102",
            "content": "Oshin Agarwal, Yinfei Yang, C Byron, Ani Wallace,  Nenkova, Interpretability analysis for named entity recognition to understand system predictions and how they can improve, 2021, Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "Oshin Agarwal",
                    "Yinfei Yang",
                    "C Byron",
                    "Ani Wallace",
                    " Nenkova"
                ],
                "title": "Interpretability analysis for named entity recognition to understand system predictions and how they can improve",
                "pub_date": "2021",
                "pub_title": "Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_103",
            "content": "Rodrigo Agerri, German Rigau, Robust multilingual named entity recognition with shallow semisupervised features, 2016, Artificial Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Rodrigo Agerri",
                    "German Rigau"
                ],
                "title": "Robust multilingual named entity recognition with shallow semisupervised features",
                "pub_date": "2016",
                "pub_title": "Artificial Intelligence",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_104",
            "content": "Alan Akbik, Duncan Blythe, Roland Vollgraf, Contextual string embeddings for sequence labeling, 2018, Proceedings of the 27th international conference on computational linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "Alan Akbik",
                    "Duncan Blythe",
                    "Roland Vollgraf"
                ],
                "title": "Contextual string embeddings for sequence labeling",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 27th international conference on computational linguistics",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_105",
            "content": "UNKNOWN, None, 2016, Deep variational information bottleneck, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": null,
                "title": null,
                "pub_date": "2016",
                "pub_title": "Deep variational information bottleneck",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_106",
            "content": "Piotr Bojanowski, Edouard Grave, Armand Joulin, Tomas Mikolov, Enriching word vectors with subword information, 2017, Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Piotr Bojanowski",
                    "Edouard Grave",
                    "Armand Joulin",
                    "Tomas Mikolov"
                ],
                "title": "Enriching word vectors with subword information",
                "pub_date": "2017",
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_107",
            "content": "P Jason, Eric Chiu,  Nichols, Named entity recognition with bidirectional lstm-cnns, 2016, Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "P Jason",
                    "Eric Chiu",
                    " Nichols"
                ],
                "title": "Named entity recognition with bidirectional lstm-cnns",
                "pub_date": "2016",
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_108",
            "content": "UNKNOWN, None, 2020, An analysis of simple data augmentation for named entity recognition, .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "An analysis of simple data augmentation for named entity recognition",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_109",
            "content": "Leon Derczynski, Eric Nichols, Marieke Van Erp, Nut Limsopatham, Results of the wnut2017 shared task on novel and emerging entity recognition, 2017, Proceedings of the 3rd Workshop on Noisy Usergenerated Text, .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Leon Derczynski",
                    "Eric Nichols",
                    "Marieke Van Erp",
                    "Nut Limsopatham"
                ],
                "title": "Results of the wnut2017 shared task on novel and emerging entity recognition",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 3rd Workshop on Noisy Usergenerated Text",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_110",
            "content": "UNKNOWN, None, 2018, Bert: Pre-training of deep bidirectional transformers for language understanding, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_111",
            "content": "UNKNOWN, None, , Nate Kushman, and Zeynep Akata. 2020. Learning robust representations via multi-view information bottleneck, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Nate Kushman, and Zeynep Akata. 2020. Learning robust representations via multi-view information bottleneck",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_112",
            "content": "Jinlan Fu, Xuanjing Huang, Pengfei Liu, SpanNER: Named entity re-/recognition as span prediction, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Jinlan Fu",
                    "Xuanjing Huang",
                    "Pengfei Liu"
                ],
                "title": "SpanNER: Named entity re-/recognition as span prediction",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "118-ARR_v2_113",
            "content": "Jinlan Fu, Pengfei Liu, Qi Zhang, Rethinking generalization of neural models: A named entity recognition case study, 2020, Proceedings of the AAAI Conference on Artificial Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Jinlan Fu",
                    "Pengfei Liu",
                    "Qi Zhang"
                ],
                "title": "Rethinking generalization of neural models: A named entity recognition case study",
                "pub_date": "2020",
                "pub_title": "Proceedings of the AAAI Conference on Artificial Intelligence",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_114",
            "content": "Nobukazu Fukuda, Naoki Yoshinaga, Masaru Kitsuregawa, Robust Backed-off Estimation of Out-of-Vocabulary Embeddings, 2020, Findings of the Association for Computational Linguistics: EMNLP 2020, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Nobukazu Fukuda",
                    "Naoki Yoshinaga",
                    "Masaru Kitsuregawa"
                ],
                "title": "Robust Backed-off Estimation of Out-of-Vocabulary Embeddings",
                "pub_date": "2020",
                "pub_title": "Findings of the Association for Computational Linguistics: EMNLP 2020",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "118-ARR_v2_115",
            "content": "Robert Geirhos, J\u00f6rn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, Felix Wichmann, Shortcut learning in deep neural networks, 2020, Nature Machine Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    "Robert Geirhos",
                    "J\u00f6rn-Henrik Jacobsen",
                    "Claudio Michaelis",
                    "Richard Zemel",
                    "Wieland Brendel",
                    "Matthias Bethge",
                    "Felix Wichmann"
                ],
                "title": "Shortcut learning in deep neural networks",
                "pub_date": "2020",
                "pub_title": "Nature Machine Intelligence",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_116",
            "content": "Sepp Hochreiter, J\u00fcrgen Schmidhuber, Long short-term memory, 1997, Neural computation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Sepp Hochreiter",
                    "J\u00fcrgen Schmidhuber"
                ],
                "title": "Long short-term memory",
                "pub_date": "1997",
                "pub_title": "Neural computation",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_117",
            "content": "Ziniu Hu, Ting Chen, Kai-Wei Chang, Yizhou Sun, Few-shot representation learning for outof-vocabulary words, 2019, Proceedings of the 57th, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Ziniu Hu",
                    "Ting Chen",
                    "Kai-Wei Chang",
                    "Yizhou Sun"
                ],
                "title": "Few-shot representation learning for outof-vocabulary words",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_118",
            "content": "UNKNOWN, None, , Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "118-ARR_v2_119",
            "content": "UNKNOWN, None, 2019, Adversarial examples are not bugs, they are features, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Adversarial examples are not bugs, they are features",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_120",
            "content": "Jin-Dong Kim, Tomoko Ohta, Yoshimasa Tsuruoka, Yuka Tateisi, Nigel Collier, Introduction to the bio-entity recognition task at jnlpba, 2004, Proceedings of the international joint workshop on natural language processing in biomedicine and its applications, Citeseer.",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Jin-Dong Kim",
                    "Tomoko Ohta",
                    "Yoshimasa Tsuruoka",
                    "Yuka Tateisi",
                    "Nigel Collier"
                ],
                "title": "Introduction to the bio-entity recognition task at jnlpba",
                "pub_date": "2004",
                "pub_title": "Proceedings of the international joint workshop on natural language processing in biomedicine and its applications",
                "pub": "Citeseer"
            }
        },
        {
            "ix": "118-ARR_v2_121",
            "content": "UNKNOWN, None, 2013, Autoencoding variational bayes, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": null,
                "title": null,
                "pub_date": "2013",
                "pub_title": "Autoencoding variational bayes",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_122",
            "content": "Guillaume Lample, Miguel Ballesteros, Sandeep Subramanian, Kazuya Kawakami, Chris Dyer, Neural architectures for named entity recognition, 2016, Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Guillaume Lample",
                    "Miguel Ballesteros",
                    "Sandeep Subramanian",
                    "Kazuya Kawakami",
                    "Chris Dyer"
                ],
                "title": "Neural architectures for named entity recognition",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "118-ARR_v2_123",
            "content": "UNKNOWN, None, 2019, Albert: A lite bert for self-supervised learning of language representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Albert: A lite bert for self-supervised learning of language representations",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_124",
            "content": "UNKNOWN, None, 1995, Convolutional networks for images, speech, and time series. The handbook of brain theory and neural networks, .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": null,
                "title": null,
                "pub_date": "1995",
                "pub_title": "Convolutional networks for images, speech, and time series. The handbook of brain theory and neural networks",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_125",
            "content": "Changliang Li, Liang Li, Ji Qi, A selfattentive model with gate mechanism for spoken language understanding, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Changliang Li",
                    "Liang Li",
                    "Ji Qi"
                ],
                "title": "A selfattentive model with gate mechanism for spoken language understanding",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "118-ARR_v2_126",
            "content": "Fei Li, Zheng Wang, Siu Hui, Lejian Liao, Dandan Song, Jing Xu, Guoxiu He, Meihuizi Jia, Modularized interaction network for named entity recognition, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Fei Li",
                    "Zheng Wang",
                    "Siu Hui",
                    "Lejian Liao",
                    "Dandan Song",
                    "Jing Xu",
                    "Guoxiu He",
                    "Meihuizi Jia"
                ],
                "title": "Modularized interaction network for named entity recognition",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "118-ARR_v2_127",
            "content": "Yangming Li, Han Li, Kaisheng Yao, Xiaolong Li, Handling rare entities for neural sequence labeling, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Yangming Li",
                    "Han Li",
                    "Kaisheng Yao",
                    "Xiaolong Li"
                ],
                "title": "Handling rare entities for neural sequence labeling",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "118-ARR_v2_128",
            "content": "Hongyu Lin, Yaojie Lu, Jialong Tang, Xianpei Han, Le Sun, Zhicheng Wei, Nicholas Jing Yuan, A rigorous study on named entity recognition: Can fine-tuning pretrained model lead to the promised land?, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": [
                    "Hongyu Lin",
                    "Yaojie Lu",
                    "Jialong Tang",
                    "Xianpei Han",
                    "Le Sun",
                    "Zhicheng Wei",
                    "Nicholas Jing Yuan"
                ],
                "title": "A rigorous study on named entity recognition: Can fine-tuning pretrained model lead to the promised land?",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_129",
            "content": "UNKNOWN, None, 2019, Roberta: A robustly optimized bert pretraining approach, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Roberta: A robustly optimized bert pretraining approach",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_130",
            "content": "Xue Mengge, Bowen Yu, Zhenyu Zhang, Tingwen Liu, Yue Zhang, Bin Wang, Coarse-to-Fine Pretraining for Named Entity Recognition, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Xue Mengge",
                    "Bowen Yu",
                    "Zhenyu Zhang",
                    "Tingwen Liu",
                    "Yue Zhang",
                    "Bin Wang"
                ],
                "title": "Coarse-to-Fine Pretraining for Named Entity Recognition",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "118-ARR_v2_131",
            "content": "Sewon Min, Kenton Lee, Ming-Wei Chang, Kristina Toutanova, Hannaneh Hajishirzi, Joint passage ranking for diverse multi-answer retrieval, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "Sewon Min",
                    "Kenton Lee",
                    "Ming-Wei Chang",
                    "Kristina Toutanova",
                    "Hannaneh Hajishirzi"
                ],
                "title": "Joint passage ranking for diverse multi-answer retrieval",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "118-ARR_v2_132",
            "content": "UNKNOWN, None, 2020, Named entity recognition for social media texts with semantic augmentation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Named entity recognition for social media texts with semantic augmentation",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_133",
            "content": "UNKNOWN, None, 2018, Representation learning with contrastive predictive coding, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Representation learning with contrastive predictive coding",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_134",
            "content": "UNKNOWN, None, 2019, Learning taskspecific representation for novel words in sequence labeling, .",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Learning taskspecific representation for novel words in sequence labeling",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_135",
            "content": "Jeffrey Pennington, Richard Socher, Christopher Manning, GloVe: Global vectors for word representation, 2014, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": [
                    "Jeffrey Pennington",
                    "Richard Socher",
                    "Christopher Manning"
                ],
                "title": "GloVe: Global vectors for word representation",
                "pub_date": "2014",
                "pub_title": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "118-ARR_v2_136",
            "content": "Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer, Deep contextualized word representations, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": [
                    "Matthew Peters",
                    "Mark Neumann",
                    "Mohit Iyyer",
                    "Matt Gardner",
                    "Christopher Clark",
                    "Kenton Lee",
                    "Luke Zettlemoyer"
                ],
                "title": "Deep contextualized word representations",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "118-ARR_v2_137",
            "content": "Yuval Pinter, Robert Guthrie, Jacob Eisenstein, Mimicking word embeddings using subword RNNs, 2017, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": [
                    "Yuval Pinter",
                    "Robert Guthrie",
                    "Jacob Eisenstein"
                ],
                "title": "Mimicking word embeddings using subword RNNs",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "118-ARR_v2_138",
            "content": "UNKNOWN, None, 2020, The dual information bottleneck, .",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "The dual information bottleneck",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_139",
            "content": "Erik , Kim Sang, Fien De Meulder, Introduction to the conll-2003 shared task: Languageindependent named entity recognition, 2003, Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003, .",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": [
                    "Erik ",
                    "Kim Sang",
                    "Fien De Meulder"
                ],
                "title": "Introduction to the conll-2003 shared task: Languageindependent named entity recognition",
                "pub_date": "2003",
                "pub_title": "Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_140",
            "content": "Moemmur Shahzad, Ayesha Amin, Diego Esteves, Axel-Cyrille , Inferner: an attentive model leveraging the sentence-level information for named entity recognition in microblogs, 2021, The International FLAIRS Conference Proceedings, .",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": [
                    "Moemmur Shahzad",
                    "Ayesha Amin",
                    "Diego Esteves",
                    "Axel-Cyrille "
                ],
                "title": "Inferner: an attentive model leveraging the sentence-level information for named entity recognition in microblogs",
                "pub_date": "2021",
                "pub_title": "The International FLAIRS Conference Proceedings",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_141",
            "content": "Koichi Takeuchi, Nigel Collier, Use of support vector machines in extended named entity recognition, 2002, COLING-02: The 6th Conference on Natural Language Learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": [
                    "Koichi Takeuchi",
                    "Nigel Collier"
                ],
                "title": "Use of support vector machines in extended named entity recognition",
                "pub_date": "2002",
                "pub_title": "COLING-02: The 6th Conference on Natural Language Learning",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_142",
            "content": "Xingwei Tan, Gabriele Pergola, Yulan He, Extracting event temporal relations via hyperbolic geometry, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b40",
                "authors": [
                    "Xingwei Tan",
                    "Gabriele Pergola",
                    "Yulan He"
                ],
                "title": "Extracting event temporal relations via hyperbolic geometry",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "118-ARR_v2_143",
            "content": "UNKNOWN, None, 2000, The information bottleneck method, .",
            "ntype": "ref",
            "meta": {
                "xid": "b41",
                "authors": null,
                "title": null,
                "pub_date": "2000",
                "pub_title": "The information bottleneck method",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_144",
            "content": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Attention is all you need, 2017, Advances in neural information processing systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b42",
                "authors": [
                    "Ashish Vaswani",
                    "Noam Shazeer",
                    "Niki Parmar",
                    "Jakob Uszkoreit",
                    "Llion Jones",
                    "Aidan Gomez",
                    "\u0141ukasz Kaiser",
                    "Illia Polosukhin"
                ],
                "title": "Attention is all you need",
                "pub_date": "2017",
                "pub_title": "Advances in neural information processing systems",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_145",
            "content": "Kai Wang, Junfeng Tian, Rui Wang, Xiaojun Quan, Jianxing Yu, Multi-domain dialogue acts and response co-generation, 2020, Proceedings of the 58th, .",
            "ntype": "ref",
            "meta": {
                "xid": "b43",
                "authors": [
                    "Kai Wang",
                    "Junfeng Tian",
                    "Rui Wang",
                    "Xiaojun Quan",
                    "Jianxing Yu"
                ],
                "title": "Multi-domain dialogue acts and response co-generation",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_146",
            "content": "UNKNOWN, None, , Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b44",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Annual Meeting of the Association for Computational Linguistics",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "118-ARR_v2_147",
            "content": "Qi Wang, Claire Boudreau, Qixing Luo, Pang-Ning Tan, Jiayu Zhou, Deep multi-view information bottleneck, 2019, Proceedings of the 2019 SIAM International Conference on Data Mining, SIAM.",
            "ntype": "ref",
            "meta": {
                "xid": "b45",
                "authors": [
                    "Qi Wang",
                    "Claire Boudreau",
                    "Qixing Luo",
                    "Pang-Ning Tan",
                    "Jiayu Zhou"
                ],
                "title": "Deep multi-view information bottleneck",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 SIAM International Conference on Data Mining",
                "pub": "SIAM"
            }
        },
        {
            "ix": "118-ARR_v2_148",
            "content": "Xiao Wang, Qin Liu, Tao Gui, Qi Zhang, Yicheng Zou, Xin Zhou, Jiacheng Ye, Yongxin Zhang, Rui Zheng, Zexiong Pang, Textflint: Unified multilingual robustness evaluation toolkit for natural language processing, 2021, Proceedings of the 59th, .",
            "ntype": "ref",
            "meta": {
                "xid": "b46",
                "authors": [
                    "Xiao Wang",
                    "Qin Liu",
                    "Tao Gui",
                    "Qi Zhang",
                    "Yicheng Zou",
                    "Xin Zhou",
                    "Jiacheng Ye",
                    "Yongxin Zhang",
                    "Rui Zheng",
                    "Zexiong Pang"
                ],
                "title": "Textflint: Unified multilingual robustness evaluation toolkit for natural language processing",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 59th",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_149",
            "content": "UNKNOWN, None, , Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b47",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_150",
            "content": "Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, Yuji Matsumoto, LUKE: Deep contextualized entity representations with entityaware self-attention, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b48",
                "authors": [
                    "Ikuya Yamada",
                    "Akari Asai",
                    "Hiroyuki Shindo",
                    "Hideaki Takeda",
                    "Yuji Matsumoto"
                ],
                "title": "LUKE: Deep contextualized entity representations with entityaware self-attention",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "118-ARR_v2_151",
            "content": "UNKNOWN, None, 2019, Tener: adapting transformer encoder for named entity recognition, .",
            "ntype": "ref",
            "meta": {
                "xid": "b49",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Tener: adapting transformer encoder for named entity recognition",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_152",
            "content": "Hang Yan, Tao Gui, Junqi Dai, Qipeng Guo, Zheng Zhang, Xipeng Qiu, A unified generative framework for various NER subtasks, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b50",
                "authors": [
                    "Hang Yan",
                    "Tao Gui",
                    "Junqi Dai",
                    "Qipeng Guo",
                    "Zheng Zhang",
                    "Xipeng Qiu"
                ],
                "title": "A unified generative framework for various NER subtasks",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "118-ARR_v2_153",
            "content": "Qi Zhang, Jinlan Fu, Xiaoyu Liu, Xuanjing Huang, Adaptive co-attention network for named entity recognition in tweets, 2018, Thirty-Second AAAI Conference on Artificial Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b51",
                "authors": [
                    "Qi Zhang",
                    "Jinlan Fu",
                    "Xiaoyu Liu",
                    "Xuanjing Huang"
                ],
                "title": "Adaptive co-attention network for named entity recognition in tweets",
                "pub_date": "2018",
                "pub_title": "Thirty-Second AAAI Conference on Artificial Intelligence",
                "pub": null
            }
        },
        {
            "ix": "118-ARR_v2_154",
            "content": "Yue Zhang, Jie Yang, Chinese NER using lattice LSTM, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b52",
                "authors": [
                    "Yue Zhang",
                    "Jie Yang"
                ],
                "title": "Chinese NER using lattice LSTM",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "118-ARR_v2_155",
            "content": "Guodong Zhou, Jian Su, Named entity recognition using an hmm-based chunk tagger, 2002, Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b53",
                "authors": [
                    "Guodong Zhou",
                    "Jian Su"
                ],
                "title": "Named entity recognition using an hmm-based chunk tagger",
                "pub_date": "2002",
                "pub_title": "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "118-ARR_v2_0@0",
            "content": "MINER: Improving Out-of-Vocabulary Named Entity Recognition from an Information Theoretic Perspective",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_0",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_2@0",
            "content": "NER model has achieved promising performance on standard NER benchmarks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_2",
            "start": 0,
            "end": 71,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_2@1",
            "content": "However, recent studies show that previous approaches may over-rely on entity mention information, resulting in poor performance on out-of-vocabulary (OOV) entity recognition.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_2",
            "start": 73,
            "end": 247,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_2@2",
            "content": "In this work, we propose MINER, a novel NER learning framework, to remedy this issue from an information-theoretic perspective.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_2",
            "start": 249,
            "end": 375,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_2@3",
            "content": "The proposed approach contains two mutual information-based training objectives: i) generalizing information maximization, which enhances representation via deep understanding of context and entity surface forms; ii) superfluous information minimization, which discourages representation from rote memorizing entity names or exploiting biased cues in data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_2",
            "start": 377,
            "end": 732,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_2@4",
            "content": "Experiments on various settings and datasets demonstrate that it achieves better performance in predicting OOV entities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_2",
            "start": 734,
            "end": 853,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_4@0",
            "content": "Named Entity Recognition (NER) aims to identify and classify entity mentions from unstructured text, e.g., extracting location mention \"Berlin\" from the sentence \"Berlin is wonderful in the winter\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_4",
            "start": 0,
            "end": 197,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_4@1",
            "content": "NER is a key component in information retrieval (Tan et al., 2021), question answering (Min et al., 2021), dialog systems , etc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_4",
            "start": 199,
            "end": 326,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_4@2",
            "content": "Traditional NER models are feature-engineering and machine learning based (Zhou and Su, 2002;Takeuchi and Collier, 2002;Agerri and Rigau, 2016).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_4",
            "start": 328,
            "end": 471,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_4@3",
            "content": "Benefiting from the development of deep learning, neuralnetwork-based NER models have achieved stateof-the-art results on several public benchmarks (Lample et al., 2016;Peters et al., 2018;Devlin et al., 2018;Yamada et al., 2020;Yan et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_4",
            "start": 473,
            "end": 719,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_5@0",
            "content": "Recent studies (Lin et al., 2020;Agarwal et al., 2021) show that, context does influence predictions Table 1: The comparison between the in-dictionary and out-of-dictionary parts of the CoNLL 2003 baseline (Lin et al., 2020), which was tested on Bert-CRF.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_5",
            "start": 0,
            "end": 254,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_5@1",
            "content": "It is obvious that the performance gap between InDict and OutDict is significantly large.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_5",
            "start": 256,
            "end": 344,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_6@0",
            "content": "of NER models, but the main factor driving high performance is learning the named tokens themselves.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_6",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_6@1",
            "content": "Consequently, NER models underperform when predicting entities that have not been seen during training (Fu et al., 2020;Lin et al., 2020), which is referred to as an Out-of-Vocabulary (OOV) problem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_6",
            "start": 101,
            "end": 298,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_7@0",
            "content": "There are three classical strategies to alleviate the OOV problem: external knowledge, OOV word embedding, and contextualized embedding.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_7",
            "start": 0,
            "end": 135,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_7@1",
            "content": "The first one is to introduce additional features, e.g., entity lexicons (Zhang and Yang, 2018), part-ofspeech tags , which alleviates the model's dependence on word embeddings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_7",
            "start": 137,
            "end": 313,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_7@2",
            "content": "However, the external knowledge is not always easy to obtain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_7",
            "start": 315,
            "end": 375,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_7@3",
            "content": "The second strategy is to get a better OOV word embedding (Peng et al., 2019;Fukuda et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_7",
            "start": 377,
            "end": 474,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_7@4",
            "content": "The strategy is learning a static OOV embedding representation, but not directly utilizing the context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_7",
            "start": 476,
            "end": 578,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_7@5",
            "content": "Last one is fine-tune pre-trained models, e.g., ELMo (Peters et al., 2018), BERT (Devlin et al., 2018), which provide contextualized word representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_7",
            "start": 580,
            "end": 733,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_7@6",
            "content": "Unfortunately, Agarwal et al. (2021) shows that the higher performance of pretrained models could be the results of learning the subword structure better.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_7",
            "start": 735,
            "end": 888,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_8@0",
            "content": "How do we make the model focus on contextual information to tackle the OOV problem? Motivated by the information bottleneck principle (Tishby et al., 2000), we propose a novel learning framework -Mutual Information based Named Entity Recognition (MINER).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_8",
            "start": 0,
            "end": 253,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_8@1",
            "content": "The proposed method provides an information-theoretic perspective to the OOV problem by training an encoder to minimize task-irrelevant nuisances while keeping predictive information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_8",
            "start": 255,
            "end": 437,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_8@2",
            "content": "Specifically, MINER contains two mutual information based learning objectives: i) generalizing information maximization, which aims to maximize the mutual information between representations and well-generalizing features, i.e., context and entity surface forms; ii) superfluous information minimization, which prevents the model from rote memorizing the entity names or exploiting biased cues via eliminating entity name information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_8",
            "start": 439,
            "end": 872,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_8@3",
            "content": "Our codes 1 are publicly available.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_8",
            "start": 874,
            "end": 908,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_9@0",
            "content": "Our main contributions are summarized as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_9",
            "start": 0,
            "end": 48,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_10@0",
            "content": "1. We propose a novel learning framework, i.e., MINER, from an information theory perspective, aiming to improve the robustness of entity changes by eliminating entity-specific and maximizing wellgeneralizing information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_10",
            "start": 0,
            "end": 220,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_11@0",
            "content": "2. We show its effectiveness on several settings and benchmarks, and suggest that MINER is a reliable approach to better OOV entity recognition.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_11",
            "start": 0,
            "end": 143,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_12@0",
            "content": "Background",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_12",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_13@0",
            "content": "In this section, we highlight the information bottleneck principle.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_13",
            "start": 0,
            "end": 66,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_13@1",
            "content": "Subsequently, the analysis of possible issues was provided when applying it to OOV entity recognition.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_13",
            "start": 68,
            "end": 169,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_13@2",
            "content": "Furthermore, we review related techniques in deriving our framework.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_13",
            "start": 171,
            "end": 238,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_14@0",
            "content": "Information Bottleneck (IB) principle originated in information theory, and provides a theoretical framework for analyzing deep neural networks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_14",
            "start": 0,
            "end": 143,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_14@1",
            "content": "It formulates the goal of representation learning as an information trade-off between predictive power and representation compression.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_14",
            "start": 145,
            "end": 278,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_14@2",
            "content": "Given the input dataset (X,Y), it seeks to learn the internal representation Z of some intermediate layers by:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_14",
            "start": 280,
            "end": 389,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_15@0",
            "content": "L IB = \u2212I(Z; Y ) + \u03b2 * I(Z; X),",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_15",
            "start": 0,
            "end": 30,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_16@0",
            "content": "where I represents the mutual information(MI), a measure of the mutual dependence between the two variables.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_16",
            "start": 0,
            "end": 107,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_16@1",
            "content": "The trade-off between the two MI terms is controlled by the Lagrange multiplier \u03b2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_16",
            "start": 109,
            "end": 190,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_16@2",
            "content": "A low loss indicates that representation Z does not keep too much information from X while still retaining enough information to predict Y.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_16",
            "start": 192,
            "end": 330,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_17@0",
            "content": "Section 5 suggests that directly applying IB to NER can not bring obvious improvement.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_17",
            "start": 0,
            "end": 85,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_17@1",
            "content": "We argue that IB cannot guarantee well-generalizing representation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_17",
            "start": 87,
            "end": 153,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_18@0",
            "content": "On the one hand, it has been shown that it is challenging to find a trade-off between high compression and high predictive power (Tishby et al., 2000;Wang et al., 2019;Piran et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_18",
            "start": 0,
            "end": 187,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_18@1",
            "content": "When compressing task-irrelevant nuisances, however, useful information will inevitably be left out.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_18",
            "start": 189,
            "end": 288,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_18@2",
            "content": "On the other hand, it is unclear for the IB principle which parts of features are well-generalizing and which are not, as we usually train a classifier to solely maximize accuracy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_18",
            "start": 290,
            "end": 469,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_18@3",
            "content": "Consequently, neural networks tend to use any accessible signal to do so (Ilyas et al., 2019), which is referred to as a shortcut learning problem (Geirhos et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_18",
            "start": 471,
            "end": 640,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_19@0",
            "content": "For training sets with limited size, it may be easier for neural networks to memorize entity names rather than to classify them by context and common entity features (Agarwal et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_19",
            "start": 0,
            "end": 188,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_19@1",
            "content": "In Section 4, we demonstrate how we extend IB to the NER task and address these issues.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_19",
            "start": 190,
            "end": 276,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_20@0",
            "content": "Model Architecture",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_20",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_21@0",
            "content": "In recent years, NER systems have undergone a paradigm shift from sequence labeling, which formulates NER as a token-level tagging task (Chiu and Nichols, 2016;Akbik et al., 2018;Yan et al., 2019), to span prediction (SpanNER), which regards NER as a span-level classification task (Mengge et al., 2020;Yamada et al., 2020;Fu et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_21",
            "start": 0,
            "end": 339,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_21@1",
            "content": "We choose SpanNER as base architecture for two reasons: 1) SpanNER can yield the whole span representation, which can be directly used for optimize information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_21",
            "start": 341,
            "end": 500,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_21@2",
            "content": "2) Compared with sequence labeling, SpanNER does better in sentences with more OOV words (Fu et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_21",
            "start": 502,
            "end": 608,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_22@0",
            "content": "Overall, SpanNER consists of three major modules: token representation layer, span representation layer, and span classification layer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_22",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_22@1",
            "content": "Besides, our method inserts a bottleneck layer to the architecture for information optimization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_22",
            "start": 136,
            "end": 231,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_23@0",
            "content": "Token Representation Layer",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_23",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_24@0",
            "content": "Let X = {x 1 , x 2 , \u2022 \u2022 \u2022 , x n } represents the input sentence, thus, the token representation h i is as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_24",
            "start": 0,
            "end": 114,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_25@0",
            "content": "u 1 , \u2022 \u2022 \u2022 , u n = Embedding(x 1 , \u2022 \u2022 \u2022 , x n ) (1) h 1 , \u2022 \u2022 \u2022 , h n = Encoder(u 1 , \u2022 \u2022 \u2022 , u n ) (2)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_25",
            "start": 0,
            "end": 104,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_26@0",
            "content": "where Embedding() is the non-contextualized word embeddings, e.g., Glove (Pennington et al., 2014) or contextualized word embeddings, e.g., ELMo (Peters et al., 2018), BERT (Devlin et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_26",
            "start": 0,
            "end": 194,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_26@1",
            "content": "Encoder() can be any network structures with context encoding function, e.g., LSTM (Hochreiter and Schmidhuber, 1997), CNN (LeCun et al., 1995), transformer (Vaswani et al., 2017), and so on.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_26",
            "start": 196,
            "end": 386,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_27@0",
            "content": "Span Representation Layer",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_27",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_28@0",
            "content": "For all possible spans S = {s 1 , s 2 , \u2022 \u2022 \u2022 , s m } of sentence X, we re-assign a label y \u2208 Y for each span.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_28",
            "start": 0,
            "end": 109,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_28@1",
            "content": "Take \"Berlin is wonderful\" as an example, its possible spans and labels are {(1, 1), (1, 2), (1, 3), (2, 2), (2, 3), (3, 3)} and {LOC, O, O, O, O, O}, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_28",
            "start": 111,
            "end": 274,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_29@0",
            "content": "Given the start index b i and end index e i , the representation of span s i can be calculated by two parts: boundary embedding and span length embedding.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_29",
            "start": 0,
            "end": 153,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_30@0",
            "content": "Boundary embedding: This part is calculated by concatenating the start and end tokens' representation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_30",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_31@0",
            "content": "t b i = [h b i ; h e i ].",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_31",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_32@0",
            "content": "Span length embedding: In order to introduce the length feature, we additionally provide the length embedding t l i , which can be obtained by a learnable look-up table.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_32",
            "start": 0,
            "end": 168,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_33@0",
            "content": "Finally, the span representation can be obtained as:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_33",
            "start": 0,
            "end": 51,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_34@0",
            "content": "t i = [t b i ; t l i ].",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_34",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_35@0",
            "content": "Information Bottleneck Layer",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_35",
            "start": 0,
            "end": 27,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_36@0",
            "content": "In order to optimize the information in the span representation, our method additionally adds an information bottleneck layer of the form:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_36",
            "start": 0,
            "end": 137,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_37@0",
            "content": "p(z|t) = N z | f \u00b5 e (t), f \u03a3 e (t)(3)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_37",
            "start": 0,
            "end": 37,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_38@0",
            "content": "where f e is an MLP which outputs both the Kdimensional mean \u00b5 of z as well as the K * K covariance matrix \u03a3. Then we can use the reparameterization trick ((Kingma and Welling, 2013)) to get the compressed representation z i .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_38",
            "start": 0,
            "end": 225,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_39@0",
            "content": "Span Classification Layer",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_39",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_40@0",
            "content": "Once the information bottleneck layer is finished, z i is fed into the classifier to obtain the probability of its label y i .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_40",
            "start": 0,
            "end": 125,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_40@1",
            "content": "Based on the probability, the basic loss function can be calculated as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_40",
            "start": 127,
            "end": 205,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_41@0",
            "content": "L base = \u2212 score(z i , y i ) y \u2032 \u2208Y score(z i , y \u2032 ) ,(4)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_41",
            "start": 0,
            "end": 57,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_42@0",
            "content": "where score() is a function that measures the compatibility between a specified label and a span representation:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_42",
            "start": 0,
            "end": 111,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_43@0",
            "content": "score(z i , y k ) = exp(z T i y k ),(5)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_43",
            "start": 0,
            "end": 38,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_44@0",
            "content": "where y k is a learnable representation of class k.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_44",
            "start": 0,
            "end": 50,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_45@0",
            "content": "Heuristic Decoding A heuristic decoding solution for the flat NER is provided to avoid the prediction of over-lapped spans.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_45",
            "start": 0,
            "end": 122,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_45@1",
            "content": "For those overlapped spans, we keep the span with the highest prediction probability and drop the others.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_45",
            "start": 124,
            "end": 228,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_46@0",
            "content": "It's worth noting that our method is flexible and can be used with any other NER model based on span classification.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_46",
            "start": 0,
            "end": 115,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_46@1",
            "content": "In next section, we will introduce two additional objectives to tackle the OOV problem of NER.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_46",
            "start": 117,
            "end": 210,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_47@0",
            "content": "MI-based objectives",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_47",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_48@0",
            "content": "Motivated by IB (Tishby et al., 2000;Federici et al., 2020), we can subdivide I(X; Z) into two components by using the chain rule of mutual information(MI):",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_48",
            "start": 0,
            "end": 155,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_49@0",
            "content": "I(X; Z) = I(Y ; Z) predictive + I(X; Z|Y ) superf luous ,(6)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_49",
            "start": 0,
            "end": 59,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_50@0",
            "content": "The first term determines how much information about Y is accessible from Z. While the second term, conditional mutual information term I(X; Z|Y ), denotes the information in Z that is not predictive of Y .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_50",
            "start": 0,
            "end": 205,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_51@0",
            "content": "For NER, which parts of the information retrieved from input are useful and which are redundant?",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_51",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_52@0",
            "content": "From human intuition, text context should be the main predictive information for NER.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_52",
            "start": 0,
            "end": 84,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_52@1",
            "content": "For example, \"The CEO of X resigned\", the type of X in each of these contexts should always be \"ORG\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_52",
            "start": 86,
            "end": 186,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_52@2",
            "content": "Besides, entity mentions also provide much information for entity recognition.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_52",
            "start": 188,
            "end": 265,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_52@3",
            "content": "For example, nearly all person names capitalize the first letter and follow the \"firstName lastName\" or \"lastName firstName\" patterns.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_52",
            "start": 267,
            "end": 400,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_52@4",
            "content": "However, entity name is not a well-generalizing features.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_52",
            "start": 402,
            "end": 458,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_52@5",
            "content": "By simply memorizing the fact which span is an entity, it may be possible for it to fit the training set, but it is impossible to predict entities that have never been seen before.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_52",
            "start": 460,
            "end": 639,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_53@0",
            "content": "We convert the targets of Eq. ( 6) into a form that is easier to solve via a contrastive strategy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_53",
            "start": 0,
            "end": 97,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_53@1",
            "content": "Specifically, consider x 1 and x 2 are two contrastive samples of similar context, and contains different entity mentions of the same entity category, i.e., s 1 and s 2 , respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_53",
            "start": 99,
            "end": 282,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_53@2",
            "content": "Assuming both x 1 and x 2 are both sufficient for inferring label y. The mutual information between x 1 and z 1 can be factorized to two parts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_53",
            "start": 284,
            "end": 426,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_54@0",
            "content": "I(x 1 ; z 1 ) = I(z 1 ; x 2 ) consistent + I(x 1 ; z 1 |x 2 ) specif ic ,(7)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_54",
            "start": 0,
            "end": 75,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_55@0",
            "content": "where z 1 and z 2 are span representations of s 1 and s 2 , respectively, I(z 1 ; x 2 ) denotes the information that isn't entity-specific. And I(x 1 ; z 1 |x 2 ) represents the information in z 1 which is unique to x 1 but is not predictable by sentence x 2 , i.e., entityspecific information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_55",
            "start": 0,
            "end": 293,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_56@0",
            "content": "Thus any representation z containing all information shared from both sentences would also contain the necessary label information, and sentencespecific information is superfluous.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_56",
            "start": 0,
            "end": 179,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_56@1",
            "content": "So Eq. ( 6) can be approximated by Eq. ( 7) by:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_56",
            "start": 181,
            "end": 227,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_57@0",
            "content": "maximize I(z 1 ; y) \u223c I(z 1 ; x 2 ), (8",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_57",
            "start": 0,
            "end": 38,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_58@0",
            "content": ") minimize I(x 1 ; z 1 |y) \u223c I(x 1 ; z 1 |x 2 ),(9)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_58",
            "start": 0,
            "end": 50,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_59@0",
            "content": "The target of Eq. ( 8) is defined as generalizing information maximization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_59",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_59@1",
            "content": "We proved that I(z 1 ; z 2 ) is a lower bound of I(z 1 ; x 2 )(proof could be found in appendix 7).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_59",
            "start": 76,
            "end": 174,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_59@2",
            "content": "InfoNCE (Oord et al., 2018) was used as a lower bound on MI and can be used to approximate I(z 1 ; z 2 ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_59",
            "start": 176,
            "end": 280,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_59@3",
            "content": "Subsequently, it can be optimized by:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_59",
            "start": 282,
            "end": 318,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_60@0",
            "content": "Lgi = \u2212Ep gw(z1, z2) \u2212 E p \u2032 log z \u2032 exp gw(z1, z \u2032 ) ,(10)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_60",
            "start": 0,
            "end": 58,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_61@0",
            "content": "where g w (\u2022, \u2022) is a compatible score function approximated by a neural network, z 2 are the positive entity representations from the joint distribution p of original sample and corresponding generated sample, z \u2032 are the negative entity representations drawn from the joint distribution of the original sample and other samples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_61",
            "start": 0,
            "end": 329,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_62@0",
            "content": "The target of Eq. ( 9) is defined as superfluous information minimization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_62",
            "start": 0,
            "end": 73,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_62@1",
            "content": "To restrict this term, we can minimize an upper bound of I(x 1 ; z 1 |x 2 ) (proofs could be found in appendix 7) as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_62",
            "start": 75,
            "end": 199,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_63@0",
            "content": "L si = E x 1 ,x 2 E z 1 ,z 2 [D JS [p z 1 ||p z 2 ]] ,(11)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_63",
            "start": 0,
            "end": 57,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_64@0",
            "content": "where D JS means Jensen-Shannon divergence, p z 1 and p z 2 represent p(z 1 |x 1 ) and p(z 2 |x 2 ), respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_64",
            "start": 0,
            "end": 113,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_64@1",
            "content": "In practice, Eq. ( 11) encourage z to be invariant to entity changes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_64",
            "start": 115,
            "end": 183,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_64@2",
            "content": "The resulting Mutual Information based Named Entity Recognition model is visualized in Figure 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_64",
            "start": 185,
            "end": 280,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_65@0",
            "content": "Contrastive sample generation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_65",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_66@0",
            "content": "It is difficult to obtain samples with similar contexts but different entity words.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_66",
            "start": 0,
            "end": 82,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_66@1",
            "content": "We generate contrastive samples by the mention replacement mechanism (Dai and Adel, 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_66",
            "start": 84,
            "end": 173,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_66@2",
            "content": "For each mention in the sentence, we replace it by another mention from the original training set, which has the same entity type.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_66",
            "start": 175,
            "end": 304,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_66@3",
            "content": "The corresponding span label can be changed accordingly.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_66",
            "start": 306,
            "end": 361,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_66@4",
            "content": "For example, \"LOC\" mention \"Berlin\" in sentence \"Berlin is wonderful in the winter\" is replaced by \"Iceland\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_66",
            "start": 363,
            "end": 471,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_67@0",
            "content": "Training",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_67",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_68@0",
            "content": "Combine Eq. ( 4), (10), and (11), we can get the following objective function, which try to minimize:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_68",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_69@0",
            "content": "L = L base + \u03b3 * L gi + \u03b2 * L si ,(12)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_69",
            "start": 0,
            "end": 37,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_70@0",
            "content": "where \u03b3 and \u03b2 are the weights of the generalizing information loss and superfluous information loss, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_70",
            "start": 0,
            "end": 113,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_71@0",
            "content": "Experiment",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_71",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_72@0",
            "content": "In this section, we verify the performance of the proposed method on five OOV datasets, and compared it with other methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_72",
            "start": 0,
            "end": 122,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_72@1",
            "content": "In addition, We tested the universality of the proposed method in various pre-trained models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_72",
            "start": 124,
            "end": 216,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_73@0",
            "content": "Datasets and Metrics",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_73",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_74@0",
            "content": "Datasets We performed experiments on:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_74",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_75@0",
            "content": "1. WNUT2017 (Derczynski et al., 2017), a dataset focus on unusual, previous-unseen entities in training data, and is collected from social media.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_75",
            "start": 0,
            "end": 144,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_76@0",
            "content": "2. TwitterNER , an English NER dataset created from Tweets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_76",
            "start": 0,
            "end": 58,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_77@0",
            "content": "3. BioNER (Kim et al., 2004) Metrics We measured the entity-level micro average F1 score on the test set to compare the results of different models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_77",
            "start": 0,
            "end": 147,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_77@1",
            "content": "2020) share the same intuition as us, enriching word representations with context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_77",
            "start": 149,
            "end": 230,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_77@2",
            "content": "However, the work is neither open source nor reported on the same dataset, so this method cannot be compared with MINER.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_77",
            "start": 232,
            "end": 351,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_77@3",
            "content": "We compare our method with baselines as follows: \u2022 Li et al. (2021) (MIN), which utilizes both segment-level information and word-level dependencies, and incorporates an interaction mechanism to support information sharing between boundary detection and type prediction, enhancing the performance for the NER task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_77",
            "start": 353,
            "end": 666,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_78@0",
            "content": "Baseline methods",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_78",
            "start": 0,
            "end": 15,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_79@0",
            "content": "\u2022 Fukuda et al. (2020) (CoFEE), which refer to pre-trained word embeddings for known words with similar surfaces to target OOV words. \u2022 Nie et al. (2020) (SA-NER), which utilize semantic enhancement methods to reduce the negative impact of data sparsity problems. Specifically, the method obtains the augmented semantic information from a largescale corpus, and proposes an attentive semantic augmentation module and a gate module to encode and aggregate such information, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_79",
            "start": 0,
            "end": 485,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_80@0",
            "content": "To verify the universality of our method, we measured its performance on various pre-trained models, i.e., Bert (Devlin et al., 2018), Roberta (Liu et al., 2019), Albert (Lan et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_80",
            "start": 0,
            "end": 188,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_81@0",
            "content": "Implementation Details",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_81",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_82@0",
            "content": "Bert-large released by Devlin et al. (2018) is selected as our base encoder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_82",
            "start": 0,
            "end": 75,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_82@1",
            "content": "The learning rate is set to 5e-5, and the dropout is set to 0.2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_82",
            "start": 77,
            "end": 140,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_82@2",
            "content": "The output dim of the information bottleneck layer is 50.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_82",
            "start": 142,
            "end": 198,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_82@3",
            "content": "In order to make a trade-off for the performance and efficiency, on the one hand, we truncate the part of the sentence whose tokens exceeds 128.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_82",
            "start": 200,
            "end": 343,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_82@4",
            "content": "On the other hand, we count the length distribution of entity length in different datasets, and finally choose 4 as the maximum enumerated entity length.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_82",
            "start": 345,
            "end": 497,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_82@5",
            "content": "The values of \u03b2 and \u03b3 differ for different datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_82",
            "start": 499,
            "end": 550,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_82@6",
            "content": "Empirically, 1e-5 for \u03b2 and 0.01 for \u03b3 can get promised results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_82",
            "start": 552,
            "end": 615,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_82@7",
            "content": "The model is trained in an NVIDIA GeForce RTX 2080Ti GPU.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_82",
            "start": 617,
            "end": 673,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_82@8",
            "content": "Checkpoints with top-3 performance are finally evaluated on the test set to report averaged results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_82",
            "start": 675,
            "end": 774,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_83@0",
            "content": "Main Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_83",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_84@0",
            "content": "We demonstrate the effectiveness of MINER against other state-of-the-art models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_84",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_84@1",
            "content": "As shown in table 3, we conducted the following comparison and analysis:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_84",
            "start": 81,
            "end": 152,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_85@0",
            "content": "1) Our baseline model, i.e., SpanNER, does an excellent job of predicting OOV entities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_85",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_85@1",
            "content": "Compared with sequence labeling, the span classification could model the relation of entity tokens directly;2) The performance of SpanNER is further boosted with our proposed approach, which proved the effectiveness of our method.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_85",
            "start": 88,
            "end": 317,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_85@2",
            "content": "As shown in table 3, MINER almost outperforms all other SOTA methods without any external resource;3) Compared with Typos data transformation, it is more difficult for models to predict OOV words.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_85",
            "start": 319,
            "end": 514,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_85@3",
            "content": "The results are obtained by testing MINER (Bert large) on TwitterNER .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_85",
            "start": 516,
            "end": 585,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_85@4",
            "content": "We fix \u03b2 = 1e03, and the orange line is f1 score when \u03b3 = 0.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_85",
            "start": 587,
            "end": 646,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_85@5",
            "content": "The results are obtained by testing MINER (Bert large) on TwitterNER .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_85",
            "start": 648,
            "end": 717,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_85@6",
            "content": "We fix \u03b3 = 1e04, and the orange line is f1 score when \u03b2 = 0.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_85",
            "start": 719,
            "end": 778,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_86@0",
            "content": "To pre-trained model, typos word may not appear in training set, but they share most subwords with the original token.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_86",
            "start": 0,
            "end": 117,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_86@1",
            "content": "Moreover, the subword of OOV entity may be rare; 4) It seems that the traditional information bottleneck will not significantly improve the OOV prediction ability of the model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_86",
            "start": 119,
            "end": 294,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_86@2",
            "content": "We argue that the traditional information bottlenecks will indiscriminately compress the information in the representation, leading to underfitting; 5) Our model has significantly improved the performance of the model on the entity perturbed methods of typos and OOV, demonstrating that MI improve the robustness substantially in the face of noise; 6) It is clear that our proposed method is universal and can further improve OOV prediction performance for different embedding models, as we get improvements on Bert, Roberta, and Albert stably.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_86",
            "start": 296,
            "end": 839,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_87@0",
            "content": "Ablation Study",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_87",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_88@0",
            "content": "We also perform ablation studies to validate the effectiveness of each part in MINER.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_88",
            "start": 0,
            "end": 84,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_89@0",
            "content": "Sensitivity Analysis of \u03b2 and \u03b3",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_89",
            "start": 0,
            "end": 30,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_90@0",
            "content": "To show the different influence of our proposed training objectives L gi and L si , we conduct sensitivity analysis of the coefficient \u03b2 and \u03b3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_90",
            "start": 0,
            "end": 142,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_90@1",
            "content": "Figure 2 shows the performance change under different settings of the two coefficients.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_90",
            "start": 144,
            "end": 230,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_90@2",
            "content": "The yellow line denotes ablation results without the corresponding loss functions (with \u03b2=0 or \u03b3=0).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_90",
            "start": 232,
            "end": 331,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_90@3",
            "content": "From Figure 2 we can observe that the performance is significantly enhanced with a small rate of \u03b2 or \u03b3, where the best performance is achieved when \u03b2=1e-3 and \u03b3=1e-4, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_90",
            "start": 333,
            "end": 513,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_90@4",
            "content": "It probes the effectiveness of our proposed training objectives that enhances representation via deep understanding of context and entity surface forms and discourages representation from rote memorizing entity names or exploiting biased cues in data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_90",
            "start": 515,
            "end": 765,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_90@5",
            "content": "As the coefficient rate increases continuously, the performance shows a declining trend, which means the over-constraint of L gi or L si will hurt the generalizing ability of predicting the OOV entities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_90",
            "start": 767,
            "end": 969,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_91@0",
            "content": "Interpretable Analysis",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_91",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_92@0",
            "content": "The above experiments show the promising performance of MINER on predicting the unseen entities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_92",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_92@1",
            "content": "To further investigate which part of the sentence MINER focuses on, we visualize the attention weights over entities and contexts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_92",
            "start": 97,
            "end": 226,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_92@2",
            "content": "We demonstrate an example in Figure 4 , where is selected from TwitterNER.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_92",
            "start": 228,
            "end": 301,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_92@3",
            "content": "The attention score is calculated by averaging the attention weight of the 0th layer of BERT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_92",
            "start": 303,
            "end": 395,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_92@4",
            "content": "Take the attention weights of the entity \"State Street\" as an example, it is obvious that baseline model, i.e., SpanNER, focus on entity words themselves.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_92",
            "start": 397,
            "end": 550,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_92@5",
            "content": "While the scores of our model are more average, it means that our method concerns more context information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_92",
            "start": 552,
            "end": 658,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_93@0",
            "content": "6 Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_93",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_94@0",
            "content": "External Knowledge",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_94",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_95@0",
            "content": "This group of methods makes it easier to predict OOV entities using external knowledge.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_95",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_95@1",
            "content": "Zhang and Yang (2018) utilize a dictionary to list numerous entity mentions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_95",
            "start": 88,
            "end": 163,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_95@2",
            "content": "It is possible to get stronger \"lookup\" models by integrating dictionary information, but there is no guarantee that entities outside the training set and vocabulary will be correctly identified.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_95",
            "start": 165,
            "end": 359,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_95@3",
            "content": "To diminish the model's dependency on OOV embedding, introduce partof-speech tags.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_95",
            "start": 361,
            "end": 442,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_95@4",
            "content": "External resources are not always available, which is a limitation of this strategy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_95",
            "start": 444,
            "end": 527,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_96@0",
            "content": "OOV word Embedding",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_96",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_97@0",
            "content": "The OOV problem can be alleviated by improving the OOV word embedding.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_97",
            "start": 0,
            "end": 69,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_97@1",
            "content": "The character ngram of each word is used by Bojanowski et al. (2017) to represent the OOV word embedding.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_97",
            "start": 71,
            "end": 175,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_97@2",
            "content": "Pinter et al. (2017) captures morphological features using character-level RNN.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_97",
            "start": 177,
            "end": 255,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_97@3",
            "content": "Another technique is to first match the OOV words with the words that have been seen in training, then replace the OOV words' embedding with the seen words' embedding.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_97",
            "start": 257,
            "end": 423,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_97@4",
            "content": "Peng et al. (2019) trains a student network to predict the closest word representation to the OOV term.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_97",
            "start": 425,
            "end": 527,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_97@5",
            "content": "Fukuda et al. (2020) referring to pre-trained word embeddings for known words with similar surfaces to target OOV words.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_97",
            "start": 529,
            "end": 648,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_97@6",
            "content": "This kind of method is learning a static OOV embedding representation, and does not directly utilize the context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_97",
            "start": 650,
            "end": 762,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_98@0",
            "content": "Contextualized Embedding",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_98",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_99@0",
            "content": "Contextual information is used to enhance the representation of OOV words in this strategy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_99",
            "start": 0,
            "end": 90,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_99@1",
            "content": "(Hu et al., 2019) formulate the OOV problem as a Kshot regression problem and learns to predict the OOV embedding by aggregating only K contexts and morphological features.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_99",
            "start": 92,
            "end": 263,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_99@2",
            "content": "Pre-trained models contextualized word embeddings via pretraining on large background corpora.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_99",
            "start": 265,
            "end": 358,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_99@3",
            "content": "Furthermore, contextualized word embeddings can be provided by the pre-trained models, which are pre-trained on large background corpora (Peters et al., 2018;Devlin et al., 2018;Liu et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_99",
            "start": 360,
            "end": 555,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_99@4",
            "content": "Yan et al. (2021) shows that BERT is not always better at capturing context as compared to Gloe-based BiLSTM-CRFs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_99",
            "start": 557,
            "end": 670,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_99@5",
            "content": "Their higher performance could be the result of learning the subword structure better.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_99",
            "start": 672,
            "end": 757,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_100@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_100",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_101@0",
            "content": "Based on the recent studies of NER, we analyze how to improve the OOV entity recognition.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_101",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_101@1",
            "content": "In this work, we propose a novel and flexible learning framework -MINER, to tackle OOV entities recognition issue from an information-theoretic perspective.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_101",
            "start": 90,
            "end": 245,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_101@2",
            "content": "On the one hand, this method can enhance the context information of the output of the encoder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_101",
            "start": 247,
            "end": 340,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_101@3",
            "content": "On the other hand, it can safely eliminate task-irrelevant nuisances and prevents the model from rote memorizing the entities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_101",
            "start": 342,
            "end": 467,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_101@4",
            "content": "Specifically, the proposed approach contains two mutual information based training objectives: generalizing information maximization, and superfluous information minimization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_101",
            "start": 469,
            "end": 643,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_101@5",
            "content": "Experiments on various datasets demonstrate that MINER achieves much better performance in predicting out-of-vocabulary entities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_101",
            "start": 645,
            "end": 773,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_102@0",
            "content": "Oshin Agarwal, Yinfei Yang, C Byron, Ani Wallace,  Nenkova, Interpretability analysis for named entity recognition to understand system predictions and how they can improve, 2021, Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_102",
            "start": 0,
            "end": 207,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_103@0",
            "content": "Rodrigo Agerri, German Rigau, Robust multilingual named entity recognition with shallow semisupervised features, 2016, Artificial Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_103",
            "start": 0,
            "end": 144,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_104@0",
            "content": "Alan Akbik, Duncan Blythe, Roland Vollgraf, Contextual string embeddings for sequence labeling, 2018, Proceedings of the 27th international conference on computational linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_104",
            "start": 0,
            "end": 181,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_105@0",
            "content": "UNKNOWN, None, 2016, Deep variational information bottleneck, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_105",
            "start": 0,
            "end": 62,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_106@0",
            "content": "Piotr Bojanowski, Edouard Grave, Armand Joulin, Tomas Mikolov, Enriching word vectors with subword information, 2017, Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_106",
            "start": 0,
            "end": 181,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_107@0",
            "content": "P Jason, Eric Chiu,  Nichols, Named entity recognition with bidirectional lstm-cnns, 2016, Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_107",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_108@0",
            "content": "UNKNOWN, None, 2020, An analysis of simple data augmentation for named entity recognition, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_108",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_109@0",
            "content": "Leon Derczynski, Eric Nichols, Marieke Van Erp, Nut Limsopatham, Results of the wnut2017 shared task on novel and emerging entity recognition, 2017, Proceedings of the 3rd Workshop on Noisy Usergenerated Text, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_109",
            "start": 0,
            "end": 210,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_110@0",
            "content": "UNKNOWN, None, 2018, Bert: Pre-training of deep bidirectional transformers for language understanding, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_110",
            "start": 0,
            "end": 103,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_111@0",
            "content": "UNKNOWN, None, , Nate Kushman, and Zeynep Akata. 2020. Learning robust representations via multi-view information bottleneck, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_111",
            "start": 0,
            "end": 126,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_112@0",
            "content": "Jinlan Fu, Xuanjing Huang, Pengfei Liu, SpanNER: Named entity re-/recognition as span prediction, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_112",
            "start": 0,
            "end": 317,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_113@0",
            "content": "Jinlan Fu, Pengfei Liu, Qi Zhang, Rethinking generalization of neural models: A named entity recognition case study, 2020, Proceedings of the AAAI Conference on Artificial Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_113",
            "start": 0,
            "end": 186,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_114@0",
            "content": "Nobukazu Fukuda, Naoki Yoshinaga, Masaru Kitsuregawa, Robust Backed-off Estimation of Out-of-Vocabulary Embeddings, 2020, Findings of the Association for Computational Linguistics: EMNLP 2020, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_114",
            "start": 0,
            "end": 242,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_115@0",
            "content": "Robert Geirhos, J\u00f6rn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, Felix Wichmann, Shortcut learning in deep neural networks, 2020, Nature Machine Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_115",
            "start": 0,
            "end": 200,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_116@0",
            "content": "Sepp Hochreiter, J\u00fcrgen Schmidhuber, Long short-term memory, 1997, Neural computation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_116",
            "start": 0,
            "end": 87,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_117@0",
            "content": "Ziniu Hu, Ting Chen, Kai-Wei Chang, Yizhou Sun, Few-shot representation learning for outof-vocabulary words, 2019, Proceedings of the 57th, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_117",
            "start": 0,
            "end": 140,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_118@0",
            "content": "UNKNOWN, None, , Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_118",
            "start": 0,
            "end": 123,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_119@0",
            "content": "UNKNOWN, None, 2019, Adversarial examples are not bugs, they are features, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_119",
            "start": 0,
            "end": 75,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_120@0",
            "content": "Jin-Dong Kim, Tomoko Ohta, Yoshimasa Tsuruoka, Yuka Tateisi, Nigel Collier, Introduction to the bio-entity recognition task at jnlpba, 2004, Proceedings of the international joint workshop on natural language processing in biomedicine and its applications, Citeseer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_120",
            "start": 0,
            "end": 265,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_121@0",
            "content": "UNKNOWN, None, 2013, Autoencoding variational bayes, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_121",
            "start": 0,
            "end": 53,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_122@0",
            "content": "Guillaume Lample, Miguel Ballesteros, Sandeep Subramanian, Kazuya Kawakami, Chris Dyer, Neural architectures for named entity recognition, 2016, Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_122",
            "start": 0,
            "end": 330,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_123@0",
            "content": "UNKNOWN, None, 2019, Albert: A lite bert for self-supervised learning of language representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_123",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_124@0",
            "content": "UNKNOWN, None, 1995, Convolutional networks for images, speech, and time series. The handbook of brain theory and neural networks, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_124",
            "start": 0,
            "end": 131,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_125@0",
            "content": "Changliang Li, Liang Li, Ji Qi, A selfattentive model with gate mechanism for spoken language understanding, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_125",
            "start": 0,
            "end": 244,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_126@0",
            "content": "Fei Li, Zheng Wang, Siu Hui, Lejian Liao, Dandan Song, Jing Xu, Guoxiu He, Meihuizi Jia, Modularized interaction network for named entity recognition, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_126",
            "start": 0,
            "end": 332,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_127@0",
            "content": "Yangming Li, Han Li, Kaisheng Yao, Xiaolong Li, Handling rare entities for neural sequence labeling, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_127",
            "start": 0,
            "end": 245,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_128@0",
            "content": "Hongyu Lin, Yaojie Lu, Jialong Tang, Xianpei Han, Le Sun, Zhicheng Wei, Nicholas Jing Yuan, A rigorous study on named entity recognition: Can fine-tuning pretrained model lead to the promised land?, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_128",
            "start": 0,
            "end": 301,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_129@0",
            "content": "UNKNOWN, None, 2019, Roberta: A robustly optimized bert pretraining approach, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_129",
            "start": 0,
            "end": 78,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_130@0",
            "content": "Xue Mengge, Bowen Yu, Zhenyu Zhang, Tingwen Liu, Yue Zhang, Bin Wang, Coarse-to-Fine Pretraining for Named Entity Recognition, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_130",
            "start": 0,
            "end": 278,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_131@0",
            "content": "Sewon Min, Kenton Lee, Ming-Wei Chang, Kristina Toutanova, Hannaneh Hajishirzi, Joint passage ranking for diverse multi-answer retrieval, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_131",
            "start": 0,
            "end": 273,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_132@0",
            "content": "UNKNOWN, None, 2020, Named entity recognition for social media texts with semantic augmentation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_132",
            "start": 0,
            "end": 97,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_133@0",
            "content": "UNKNOWN, None, 2018, Representation learning with contrastive predictive coding, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_133",
            "start": 0,
            "end": 81,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_134@0",
            "content": "UNKNOWN, None, 2019, Learning taskspecific representation for novel words in sequence labeling, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_134",
            "start": 0,
            "end": 96,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_135@0",
            "content": "Jeffrey Pennington, Richard Socher, Christopher Manning, GloVe: Global vectors for word representation, 2014, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_135",
            "start": 0,
            "end": 247,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_136@0",
            "content": "Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer, Deep contextualized word representations, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_136",
            "start": 0,
            "end": 309,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_137@0",
            "content": "Yuval Pinter, Robert Guthrie, Jacob Eisenstein, Mimicking word embeddings using subword RNNs, 2017, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_137",
            "start": 0,
            "end": 229,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_138@0",
            "content": "UNKNOWN, None, 2020, The dual information bottleneck, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_138",
            "start": 0,
            "end": 54,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_139@0",
            "content": "Erik , Kim Sang, Fien De Meulder, Introduction to the conll-2003 shared task: Languageindependent named entity recognition, 2003, Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_139",
            "start": 0,
            "end": 216,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_140@0",
            "content": "Moemmur Shahzad, Ayesha Amin, Diego Esteves, Axel-Cyrille , Inferner: an attentive model leveraging the sentence-level information for named entity recognition in microblogs, 2021, The International FLAIRS Conference Proceedings, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_140",
            "start": 0,
            "end": 230,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_141@0",
            "content": "Koichi Takeuchi, Nigel Collier, Use of support vector machines in extended named entity recognition, 2002, COLING-02: The 6th Conference on Natural Language Learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_141",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_142@0",
            "content": "Xingwei Tan, Gabriele Pergola, Yulan He, Extracting event temporal relations via hyperbolic geometry, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_142",
            "start": 0,
            "end": 237,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_143@0",
            "content": "UNKNOWN, None, 2000, The information bottleneck method, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_143",
            "start": 0,
            "end": 56,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_144@0",
            "content": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Attention is all you need, 2017, Advances in neural information processing systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_144",
            "start": 0,
            "end": 203,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_145@0",
            "content": "Kai Wang, Junfeng Tian, Rui Wang, Xiaojun Quan, Jianxing Yu, Multi-domain dialogue acts and response co-generation, 2020, Proceedings of the 58th, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_145",
            "start": 0,
            "end": 147,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_146@0",
            "content": "UNKNOWN, None, , Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_146",
            "start": 0,
            "end": 131,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_147@0",
            "content": "Qi Wang, Claire Boudreau, Qixing Luo, Pang-Ning Tan, Jiayu Zhou, Deep multi-view information bottleneck, 2019, Proceedings of the 2019 SIAM International Conference on Data Mining, SIAM.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_147",
            "start": 0,
            "end": 185,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_148@0",
            "content": "Xiao Wang, Qin Liu, Tao Gui, Qi Zhang, Yicheng Zou, Xin Zhou, Jiacheng Ye, Yongxin Zhang, Rui Zheng, Zexiong Pang, Textflint: Unified multilingual robustness evaluation toolkit for natural language processing, 2021, Proceedings of the 59th, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_148",
            "start": 0,
            "end": 241,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_149@0",
            "content": "UNKNOWN, None, , Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_149",
            "start": 0,
            "end": 180,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_150@0",
            "content": "Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, Yuji Matsumoto, LUKE: Deep contextualized entity representations with entityaware self-attention, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_150",
            "start": 0,
            "end": 308,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_151@0",
            "content": "UNKNOWN, None, 2019, Tener: adapting transformer encoder for named entity recognition, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_151",
            "start": 0,
            "end": 87,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_152@0",
            "content": "Hang Yan, Tao Gui, Junqi Dai, Qipeng Guo, Zheng Zhang, Xipeng Qiu, A unified generative framework for various NER subtasks, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_152",
            "start": 0,
            "end": 305,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_153@0",
            "content": "Qi Zhang, Jinlan Fu, Xiaoyu Liu, Xuanjing Huang, Adaptive co-attention network for named entity recognition in tweets, 2018, Thirty-Second AAAI Conference on Artificial Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_153",
            "start": 0,
            "end": 183,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_154@0",
            "content": "Yue Zhang, Jie Yang, Chinese NER using lattice LSTM, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_154",
            "start": 0,
            "end": 189,
            "label": {}
        },
        {
            "ix": "118-ARR_v2_155@0",
            "content": "Guodong Zhou, Jian Su, Named entity recognition using an hmm-based chunk tagger, 2002, Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "118-ARR_v2_155",
            "start": 0,
            "end": 176,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "118-ARR_v2_0",
            "tgt_ix": "118-ARR_v2_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_0",
            "tgt_ix": "118-ARR_v2_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_1",
            "tgt_ix": "118-ARR_v2_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_1",
            "tgt_ix": "118-ARR_v2_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_0",
            "tgt_ix": "118-ARR_v2_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_2",
            "tgt_ix": "118-ARR_v2_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_4",
            "tgt_ix": "118-ARR_v2_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_5",
            "tgt_ix": "118-ARR_v2_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_6",
            "tgt_ix": "118-ARR_v2_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_7",
            "tgt_ix": "118-ARR_v2_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_8",
            "tgt_ix": "118-ARR_v2_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_9",
            "tgt_ix": "118-ARR_v2_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_10",
            "tgt_ix": "118-ARR_v2_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_3",
            "tgt_ix": "118-ARR_v2_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_3",
            "tgt_ix": "118-ARR_v2_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_3",
            "tgt_ix": "118-ARR_v2_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_3",
            "tgt_ix": "118-ARR_v2_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_3",
            "tgt_ix": "118-ARR_v2_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_3",
            "tgt_ix": "118-ARR_v2_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_3",
            "tgt_ix": "118-ARR_v2_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_3",
            "tgt_ix": "118-ARR_v2_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_3",
            "tgt_ix": "118-ARR_v2_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_0",
            "tgt_ix": "118-ARR_v2_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_11",
            "tgt_ix": "118-ARR_v2_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_13",
            "tgt_ix": "118-ARR_v2_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_14",
            "tgt_ix": "118-ARR_v2_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_15",
            "tgt_ix": "118-ARR_v2_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_16",
            "tgt_ix": "118-ARR_v2_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_17",
            "tgt_ix": "118-ARR_v2_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_18",
            "tgt_ix": "118-ARR_v2_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_12",
            "tgt_ix": "118-ARR_v2_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_12",
            "tgt_ix": "118-ARR_v2_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_12",
            "tgt_ix": "118-ARR_v2_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_12",
            "tgt_ix": "118-ARR_v2_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_12",
            "tgt_ix": "118-ARR_v2_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_12",
            "tgt_ix": "118-ARR_v2_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_12",
            "tgt_ix": "118-ARR_v2_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_12",
            "tgt_ix": "118-ARR_v2_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_0",
            "tgt_ix": "118-ARR_v2_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_19",
            "tgt_ix": "118-ARR_v2_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_21",
            "tgt_ix": "118-ARR_v2_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_20",
            "tgt_ix": "118-ARR_v2_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_20",
            "tgt_ix": "118-ARR_v2_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_20",
            "tgt_ix": "118-ARR_v2_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_20",
            "tgt_ix": "118-ARR_v2_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_22",
            "tgt_ix": "118-ARR_v2_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_24",
            "tgt_ix": "118-ARR_v2_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_25",
            "tgt_ix": "118-ARR_v2_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_23",
            "tgt_ix": "118-ARR_v2_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_23",
            "tgt_ix": "118-ARR_v2_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_23",
            "tgt_ix": "118-ARR_v2_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_23",
            "tgt_ix": "118-ARR_v2_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_20",
            "tgt_ix": "118-ARR_v2_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_26",
            "tgt_ix": "118-ARR_v2_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_28",
            "tgt_ix": "118-ARR_v2_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_29",
            "tgt_ix": "118-ARR_v2_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_30",
            "tgt_ix": "118-ARR_v2_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_31",
            "tgt_ix": "118-ARR_v2_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_32",
            "tgt_ix": "118-ARR_v2_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_33",
            "tgt_ix": "118-ARR_v2_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_27",
            "tgt_ix": "118-ARR_v2_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_27",
            "tgt_ix": "118-ARR_v2_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_27",
            "tgt_ix": "118-ARR_v2_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_27",
            "tgt_ix": "118-ARR_v2_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_27",
            "tgt_ix": "118-ARR_v2_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_27",
            "tgt_ix": "118-ARR_v2_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_27",
            "tgt_ix": "118-ARR_v2_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_27",
            "tgt_ix": "118-ARR_v2_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_20",
            "tgt_ix": "118-ARR_v2_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_34",
            "tgt_ix": "118-ARR_v2_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_36",
            "tgt_ix": "118-ARR_v2_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_37",
            "tgt_ix": "118-ARR_v2_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_35",
            "tgt_ix": "118-ARR_v2_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_35",
            "tgt_ix": "118-ARR_v2_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_35",
            "tgt_ix": "118-ARR_v2_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_35",
            "tgt_ix": "118-ARR_v2_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_20",
            "tgt_ix": "118-ARR_v2_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_38",
            "tgt_ix": "118-ARR_v2_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_40",
            "tgt_ix": "118-ARR_v2_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_41",
            "tgt_ix": "118-ARR_v2_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_42",
            "tgt_ix": "118-ARR_v2_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_43",
            "tgt_ix": "118-ARR_v2_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_44",
            "tgt_ix": "118-ARR_v2_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_45",
            "tgt_ix": "118-ARR_v2_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_39",
            "tgt_ix": "118-ARR_v2_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_39",
            "tgt_ix": "118-ARR_v2_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_39",
            "tgt_ix": "118-ARR_v2_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_39",
            "tgt_ix": "118-ARR_v2_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_39",
            "tgt_ix": "118-ARR_v2_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_39",
            "tgt_ix": "118-ARR_v2_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_39",
            "tgt_ix": "118-ARR_v2_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_39",
            "tgt_ix": "118-ARR_v2_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_0",
            "tgt_ix": "118-ARR_v2_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_46",
            "tgt_ix": "118-ARR_v2_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_48",
            "tgt_ix": "118-ARR_v2_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_49",
            "tgt_ix": "118-ARR_v2_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_50",
            "tgt_ix": "118-ARR_v2_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_51",
            "tgt_ix": "118-ARR_v2_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_52",
            "tgt_ix": "118-ARR_v2_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_53",
            "tgt_ix": "118-ARR_v2_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_54",
            "tgt_ix": "118-ARR_v2_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_55",
            "tgt_ix": "118-ARR_v2_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_56",
            "tgt_ix": "118-ARR_v2_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_57",
            "tgt_ix": "118-ARR_v2_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_58",
            "tgt_ix": "118-ARR_v2_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_59",
            "tgt_ix": "118-ARR_v2_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_60",
            "tgt_ix": "118-ARR_v2_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_61",
            "tgt_ix": "118-ARR_v2_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_62",
            "tgt_ix": "118-ARR_v2_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_63",
            "tgt_ix": "118-ARR_v2_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_47",
            "tgt_ix": "118-ARR_v2_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_47",
            "tgt_ix": "118-ARR_v2_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_47",
            "tgt_ix": "118-ARR_v2_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_47",
            "tgt_ix": "118-ARR_v2_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_47",
            "tgt_ix": "118-ARR_v2_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_47",
            "tgt_ix": "118-ARR_v2_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_47",
            "tgt_ix": "118-ARR_v2_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_47",
            "tgt_ix": "118-ARR_v2_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_47",
            "tgt_ix": "118-ARR_v2_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_47",
            "tgt_ix": "118-ARR_v2_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_47",
            "tgt_ix": "118-ARR_v2_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_47",
            "tgt_ix": "118-ARR_v2_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_47",
            "tgt_ix": "118-ARR_v2_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_47",
            "tgt_ix": "118-ARR_v2_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_47",
            "tgt_ix": "118-ARR_v2_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_47",
            "tgt_ix": "118-ARR_v2_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_47",
            "tgt_ix": "118-ARR_v2_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_47",
            "tgt_ix": "118-ARR_v2_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_47",
            "tgt_ix": "118-ARR_v2_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_64",
            "tgt_ix": "118-ARR_v2_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_65",
            "tgt_ix": "118-ARR_v2_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_65",
            "tgt_ix": "118-ARR_v2_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_47",
            "tgt_ix": "118-ARR_v2_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_66",
            "tgt_ix": "118-ARR_v2_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_68",
            "tgt_ix": "118-ARR_v2_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_69",
            "tgt_ix": "118-ARR_v2_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_67",
            "tgt_ix": "118-ARR_v2_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_67",
            "tgt_ix": "118-ARR_v2_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_67",
            "tgt_ix": "118-ARR_v2_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_67",
            "tgt_ix": "118-ARR_v2_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_0",
            "tgt_ix": "118-ARR_v2_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_70",
            "tgt_ix": "118-ARR_v2_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_71",
            "tgt_ix": "118-ARR_v2_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_71",
            "tgt_ix": "118-ARR_v2_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_71",
            "tgt_ix": "118-ARR_v2_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_72",
            "tgt_ix": "118-ARR_v2_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_74",
            "tgt_ix": "118-ARR_v2_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_75",
            "tgt_ix": "118-ARR_v2_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_76",
            "tgt_ix": "118-ARR_v2_77",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_73",
            "tgt_ix": "118-ARR_v2_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_73",
            "tgt_ix": "118-ARR_v2_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_73",
            "tgt_ix": "118-ARR_v2_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_73",
            "tgt_ix": "118-ARR_v2_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_73",
            "tgt_ix": "118-ARR_v2_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_71",
            "tgt_ix": "118-ARR_v2_78",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_77",
            "tgt_ix": "118-ARR_v2_78",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_78",
            "tgt_ix": "118-ARR_v2_79",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_78",
            "tgt_ix": "118-ARR_v2_80",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_78",
            "tgt_ix": "118-ARR_v2_79",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_71",
            "tgt_ix": "118-ARR_v2_81",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_80",
            "tgt_ix": "118-ARR_v2_81",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_81",
            "tgt_ix": "118-ARR_v2_82",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_81",
            "tgt_ix": "118-ARR_v2_82",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_71",
            "tgt_ix": "118-ARR_v2_83",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_82",
            "tgt_ix": "118-ARR_v2_83",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_84",
            "tgt_ix": "118-ARR_v2_85",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_85",
            "tgt_ix": "118-ARR_v2_86",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_83",
            "tgt_ix": "118-ARR_v2_84",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_83",
            "tgt_ix": "118-ARR_v2_85",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_83",
            "tgt_ix": "118-ARR_v2_86",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_83",
            "tgt_ix": "118-ARR_v2_84",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_71",
            "tgt_ix": "118-ARR_v2_87",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_86",
            "tgt_ix": "118-ARR_v2_87",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_87",
            "tgt_ix": "118-ARR_v2_88",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_87",
            "tgt_ix": "118-ARR_v2_88",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_71",
            "tgt_ix": "118-ARR_v2_89",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_88",
            "tgt_ix": "118-ARR_v2_89",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_89",
            "tgt_ix": "118-ARR_v2_90",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_89",
            "tgt_ix": "118-ARR_v2_90",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_71",
            "tgt_ix": "118-ARR_v2_91",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_90",
            "tgt_ix": "118-ARR_v2_91",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_92",
            "tgt_ix": "118-ARR_v2_93",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_91",
            "tgt_ix": "118-ARR_v2_92",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_91",
            "tgt_ix": "118-ARR_v2_93",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_91",
            "tgt_ix": "118-ARR_v2_92",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_0",
            "tgt_ix": "118-ARR_v2_94",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_93",
            "tgt_ix": "118-ARR_v2_94",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_94",
            "tgt_ix": "118-ARR_v2_95",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_94",
            "tgt_ix": "118-ARR_v2_95",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_0",
            "tgt_ix": "118-ARR_v2_96",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_95",
            "tgt_ix": "118-ARR_v2_96",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_96",
            "tgt_ix": "118-ARR_v2_97",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_96",
            "tgt_ix": "118-ARR_v2_97",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_0",
            "tgt_ix": "118-ARR_v2_98",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_97",
            "tgt_ix": "118-ARR_v2_98",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_98",
            "tgt_ix": "118-ARR_v2_99",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_98",
            "tgt_ix": "118-ARR_v2_99",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_0",
            "tgt_ix": "118-ARR_v2_100",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_99",
            "tgt_ix": "118-ARR_v2_100",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_100",
            "tgt_ix": "118-ARR_v2_101",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_100",
            "tgt_ix": "118-ARR_v2_101",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "118-ARR_v2_0",
            "tgt_ix": "118-ARR_v2_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_1",
            "tgt_ix": "118-ARR_v2_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_2",
            "tgt_ix": "118-ARR_v2_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_2",
            "tgt_ix": "118-ARR_v2_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_2",
            "tgt_ix": "118-ARR_v2_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_2",
            "tgt_ix": "118-ARR_v2_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_2",
            "tgt_ix": "118-ARR_v2_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_3",
            "tgt_ix": "118-ARR_v2_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_4",
            "tgt_ix": "118-ARR_v2_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_4",
            "tgt_ix": "118-ARR_v2_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_4",
            "tgt_ix": "118-ARR_v2_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_4",
            "tgt_ix": "118-ARR_v2_4@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_5",
            "tgt_ix": "118-ARR_v2_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_5",
            "tgt_ix": "118-ARR_v2_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_6",
            "tgt_ix": "118-ARR_v2_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_6",
            "tgt_ix": "118-ARR_v2_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_7",
            "tgt_ix": "118-ARR_v2_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_7",
            "tgt_ix": "118-ARR_v2_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_7",
            "tgt_ix": "118-ARR_v2_7@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_7",
            "tgt_ix": "118-ARR_v2_7@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_7",
            "tgt_ix": "118-ARR_v2_7@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_7",
            "tgt_ix": "118-ARR_v2_7@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_7",
            "tgt_ix": "118-ARR_v2_7@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_8",
            "tgt_ix": "118-ARR_v2_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_8",
            "tgt_ix": "118-ARR_v2_8@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_8",
            "tgt_ix": "118-ARR_v2_8@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_8",
            "tgt_ix": "118-ARR_v2_8@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_9",
            "tgt_ix": "118-ARR_v2_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_10",
            "tgt_ix": "118-ARR_v2_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_11",
            "tgt_ix": "118-ARR_v2_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_12",
            "tgt_ix": "118-ARR_v2_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_13",
            "tgt_ix": "118-ARR_v2_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_13",
            "tgt_ix": "118-ARR_v2_13@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_13",
            "tgt_ix": "118-ARR_v2_13@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_14",
            "tgt_ix": "118-ARR_v2_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_14",
            "tgt_ix": "118-ARR_v2_14@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_14",
            "tgt_ix": "118-ARR_v2_14@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_15",
            "tgt_ix": "118-ARR_v2_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_16",
            "tgt_ix": "118-ARR_v2_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_16",
            "tgt_ix": "118-ARR_v2_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_16",
            "tgt_ix": "118-ARR_v2_16@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_17",
            "tgt_ix": "118-ARR_v2_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_17",
            "tgt_ix": "118-ARR_v2_17@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_18",
            "tgt_ix": "118-ARR_v2_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_18",
            "tgt_ix": "118-ARR_v2_18@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_18",
            "tgt_ix": "118-ARR_v2_18@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_18",
            "tgt_ix": "118-ARR_v2_18@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_19",
            "tgt_ix": "118-ARR_v2_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_19",
            "tgt_ix": "118-ARR_v2_19@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_20",
            "tgt_ix": "118-ARR_v2_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_21",
            "tgt_ix": "118-ARR_v2_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_21",
            "tgt_ix": "118-ARR_v2_21@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_21",
            "tgt_ix": "118-ARR_v2_21@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_22",
            "tgt_ix": "118-ARR_v2_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_22",
            "tgt_ix": "118-ARR_v2_22@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_23",
            "tgt_ix": "118-ARR_v2_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_24",
            "tgt_ix": "118-ARR_v2_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_25",
            "tgt_ix": "118-ARR_v2_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_26",
            "tgt_ix": "118-ARR_v2_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_26",
            "tgt_ix": "118-ARR_v2_26@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_27",
            "tgt_ix": "118-ARR_v2_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_28",
            "tgt_ix": "118-ARR_v2_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_28",
            "tgt_ix": "118-ARR_v2_28@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_29",
            "tgt_ix": "118-ARR_v2_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_30",
            "tgt_ix": "118-ARR_v2_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_31",
            "tgt_ix": "118-ARR_v2_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_32",
            "tgt_ix": "118-ARR_v2_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_33",
            "tgt_ix": "118-ARR_v2_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_34",
            "tgt_ix": "118-ARR_v2_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_35",
            "tgt_ix": "118-ARR_v2_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_36",
            "tgt_ix": "118-ARR_v2_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_37",
            "tgt_ix": "118-ARR_v2_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_38",
            "tgt_ix": "118-ARR_v2_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_39",
            "tgt_ix": "118-ARR_v2_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_40",
            "tgt_ix": "118-ARR_v2_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_40",
            "tgt_ix": "118-ARR_v2_40@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_41",
            "tgt_ix": "118-ARR_v2_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_42",
            "tgt_ix": "118-ARR_v2_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_43",
            "tgt_ix": "118-ARR_v2_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_44",
            "tgt_ix": "118-ARR_v2_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_45",
            "tgt_ix": "118-ARR_v2_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_45",
            "tgt_ix": "118-ARR_v2_45@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_46",
            "tgt_ix": "118-ARR_v2_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_46",
            "tgt_ix": "118-ARR_v2_46@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_47",
            "tgt_ix": "118-ARR_v2_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_48",
            "tgt_ix": "118-ARR_v2_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_49",
            "tgt_ix": "118-ARR_v2_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_50",
            "tgt_ix": "118-ARR_v2_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_51",
            "tgt_ix": "118-ARR_v2_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_52",
            "tgt_ix": "118-ARR_v2_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_52",
            "tgt_ix": "118-ARR_v2_52@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_52",
            "tgt_ix": "118-ARR_v2_52@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_52",
            "tgt_ix": "118-ARR_v2_52@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_52",
            "tgt_ix": "118-ARR_v2_52@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_52",
            "tgt_ix": "118-ARR_v2_52@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_53",
            "tgt_ix": "118-ARR_v2_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_53",
            "tgt_ix": "118-ARR_v2_53@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_53",
            "tgt_ix": "118-ARR_v2_53@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_54",
            "tgt_ix": "118-ARR_v2_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_55",
            "tgt_ix": "118-ARR_v2_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_56",
            "tgt_ix": "118-ARR_v2_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_56",
            "tgt_ix": "118-ARR_v2_56@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_57",
            "tgt_ix": "118-ARR_v2_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_58",
            "tgt_ix": "118-ARR_v2_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_59",
            "tgt_ix": "118-ARR_v2_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_59",
            "tgt_ix": "118-ARR_v2_59@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_59",
            "tgt_ix": "118-ARR_v2_59@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_59",
            "tgt_ix": "118-ARR_v2_59@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_60",
            "tgt_ix": "118-ARR_v2_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_61",
            "tgt_ix": "118-ARR_v2_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_62",
            "tgt_ix": "118-ARR_v2_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_62",
            "tgt_ix": "118-ARR_v2_62@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_63",
            "tgt_ix": "118-ARR_v2_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_64",
            "tgt_ix": "118-ARR_v2_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_64",
            "tgt_ix": "118-ARR_v2_64@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_64",
            "tgt_ix": "118-ARR_v2_64@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_65",
            "tgt_ix": "118-ARR_v2_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_66",
            "tgt_ix": "118-ARR_v2_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_66",
            "tgt_ix": "118-ARR_v2_66@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_66",
            "tgt_ix": "118-ARR_v2_66@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_66",
            "tgt_ix": "118-ARR_v2_66@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_66",
            "tgt_ix": "118-ARR_v2_66@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_67",
            "tgt_ix": "118-ARR_v2_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_68",
            "tgt_ix": "118-ARR_v2_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_69",
            "tgt_ix": "118-ARR_v2_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_70",
            "tgt_ix": "118-ARR_v2_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_71",
            "tgt_ix": "118-ARR_v2_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_72",
            "tgt_ix": "118-ARR_v2_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_72",
            "tgt_ix": "118-ARR_v2_72@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_73",
            "tgt_ix": "118-ARR_v2_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_74",
            "tgt_ix": "118-ARR_v2_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_75",
            "tgt_ix": "118-ARR_v2_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_76",
            "tgt_ix": "118-ARR_v2_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_77",
            "tgt_ix": "118-ARR_v2_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_77",
            "tgt_ix": "118-ARR_v2_77@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_77",
            "tgt_ix": "118-ARR_v2_77@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_77",
            "tgt_ix": "118-ARR_v2_77@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_78",
            "tgt_ix": "118-ARR_v2_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_79",
            "tgt_ix": "118-ARR_v2_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_80",
            "tgt_ix": "118-ARR_v2_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_81",
            "tgt_ix": "118-ARR_v2_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_82",
            "tgt_ix": "118-ARR_v2_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_82",
            "tgt_ix": "118-ARR_v2_82@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_82",
            "tgt_ix": "118-ARR_v2_82@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_82",
            "tgt_ix": "118-ARR_v2_82@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_82",
            "tgt_ix": "118-ARR_v2_82@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_82",
            "tgt_ix": "118-ARR_v2_82@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_82",
            "tgt_ix": "118-ARR_v2_82@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_82",
            "tgt_ix": "118-ARR_v2_82@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_82",
            "tgt_ix": "118-ARR_v2_82@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_83",
            "tgt_ix": "118-ARR_v2_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_84",
            "tgt_ix": "118-ARR_v2_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_84",
            "tgt_ix": "118-ARR_v2_84@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_85",
            "tgt_ix": "118-ARR_v2_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_85",
            "tgt_ix": "118-ARR_v2_85@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_85",
            "tgt_ix": "118-ARR_v2_85@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_85",
            "tgt_ix": "118-ARR_v2_85@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_85",
            "tgt_ix": "118-ARR_v2_85@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_85",
            "tgt_ix": "118-ARR_v2_85@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_85",
            "tgt_ix": "118-ARR_v2_85@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_86",
            "tgt_ix": "118-ARR_v2_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_86",
            "tgt_ix": "118-ARR_v2_86@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_86",
            "tgt_ix": "118-ARR_v2_86@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_87",
            "tgt_ix": "118-ARR_v2_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_88",
            "tgt_ix": "118-ARR_v2_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_89",
            "tgt_ix": "118-ARR_v2_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_90",
            "tgt_ix": "118-ARR_v2_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_90",
            "tgt_ix": "118-ARR_v2_90@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_90",
            "tgt_ix": "118-ARR_v2_90@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_90",
            "tgt_ix": "118-ARR_v2_90@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_90",
            "tgt_ix": "118-ARR_v2_90@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_90",
            "tgt_ix": "118-ARR_v2_90@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_91",
            "tgt_ix": "118-ARR_v2_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_92",
            "tgt_ix": "118-ARR_v2_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_92",
            "tgt_ix": "118-ARR_v2_92@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_92",
            "tgt_ix": "118-ARR_v2_92@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_92",
            "tgt_ix": "118-ARR_v2_92@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_92",
            "tgt_ix": "118-ARR_v2_92@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_92",
            "tgt_ix": "118-ARR_v2_92@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_93",
            "tgt_ix": "118-ARR_v2_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_94",
            "tgt_ix": "118-ARR_v2_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_95",
            "tgt_ix": "118-ARR_v2_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_95",
            "tgt_ix": "118-ARR_v2_95@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_95",
            "tgt_ix": "118-ARR_v2_95@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_95",
            "tgt_ix": "118-ARR_v2_95@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_95",
            "tgt_ix": "118-ARR_v2_95@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_96",
            "tgt_ix": "118-ARR_v2_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_97",
            "tgt_ix": "118-ARR_v2_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_97",
            "tgt_ix": "118-ARR_v2_97@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_97",
            "tgt_ix": "118-ARR_v2_97@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_97",
            "tgt_ix": "118-ARR_v2_97@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_97",
            "tgt_ix": "118-ARR_v2_97@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_97",
            "tgt_ix": "118-ARR_v2_97@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_97",
            "tgt_ix": "118-ARR_v2_97@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_98",
            "tgt_ix": "118-ARR_v2_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_99",
            "tgt_ix": "118-ARR_v2_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_99",
            "tgt_ix": "118-ARR_v2_99@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_99",
            "tgt_ix": "118-ARR_v2_99@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_99",
            "tgt_ix": "118-ARR_v2_99@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_99",
            "tgt_ix": "118-ARR_v2_99@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_99",
            "tgt_ix": "118-ARR_v2_99@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_100",
            "tgt_ix": "118-ARR_v2_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_101",
            "tgt_ix": "118-ARR_v2_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_101",
            "tgt_ix": "118-ARR_v2_101@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_101",
            "tgt_ix": "118-ARR_v2_101@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_101",
            "tgt_ix": "118-ARR_v2_101@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_101",
            "tgt_ix": "118-ARR_v2_101@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_101",
            "tgt_ix": "118-ARR_v2_101@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_102",
            "tgt_ix": "118-ARR_v2_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_103",
            "tgt_ix": "118-ARR_v2_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_104",
            "tgt_ix": "118-ARR_v2_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_105",
            "tgt_ix": "118-ARR_v2_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_106",
            "tgt_ix": "118-ARR_v2_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_107",
            "tgt_ix": "118-ARR_v2_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_108",
            "tgt_ix": "118-ARR_v2_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_109",
            "tgt_ix": "118-ARR_v2_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_110",
            "tgt_ix": "118-ARR_v2_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_111",
            "tgt_ix": "118-ARR_v2_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_112",
            "tgt_ix": "118-ARR_v2_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_113",
            "tgt_ix": "118-ARR_v2_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_114",
            "tgt_ix": "118-ARR_v2_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_115",
            "tgt_ix": "118-ARR_v2_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_116",
            "tgt_ix": "118-ARR_v2_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_117",
            "tgt_ix": "118-ARR_v2_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_118",
            "tgt_ix": "118-ARR_v2_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_119",
            "tgt_ix": "118-ARR_v2_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_120",
            "tgt_ix": "118-ARR_v2_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_121",
            "tgt_ix": "118-ARR_v2_121@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_122",
            "tgt_ix": "118-ARR_v2_122@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_123",
            "tgt_ix": "118-ARR_v2_123@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_124",
            "tgt_ix": "118-ARR_v2_124@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_125",
            "tgt_ix": "118-ARR_v2_125@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_126",
            "tgt_ix": "118-ARR_v2_126@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_127",
            "tgt_ix": "118-ARR_v2_127@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_128",
            "tgt_ix": "118-ARR_v2_128@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_129",
            "tgt_ix": "118-ARR_v2_129@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_130",
            "tgt_ix": "118-ARR_v2_130@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_131",
            "tgt_ix": "118-ARR_v2_131@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_132",
            "tgt_ix": "118-ARR_v2_132@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_133",
            "tgt_ix": "118-ARR_v2_133@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_134",
            "tgt_ix": "118-ARR_v2_134@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_135",
            "tgt_ix": "118-ARR_v2_135@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_136",
            "tgt_ix": "118-ARR_v2_136@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_137",
            "tgt_ix": "118-ARR_v2_137@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_138",
            "tgt_ix": "118-ARR_v2_138@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_139",
            "tgt_ix": "118-ARR_v2_139@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_140",
            "tgt_ix": "118-ARR_v2_140@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_141",
            "tgt_ix": "118-ARR_v2_141@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_142",
            "tgt_ix": "118-ARR_v2_142@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_143",
            "tgt_ix": "118-ARR_v2_143@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_144",
            "tgt_ix": "118-ARR_v2_144@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_145",
            "tgt_ix": "118-ARR_v2_145@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_146",
            "tgt_ix": "118-ARR_v2_146@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_147",
            "tgt_ix": "118-ARR_v2_147@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_148",
            "tgt_ix": "118-ARR_v2_148@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_149",
            "tgt_ix": "118-ARR_v2_149@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_150",
            "tgt_ix": "118-ARR_v2_150@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_151",
            "tgt_ix": "118-ARR_v2_151@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_152",
            "tgt_ix": "118-ARR_v2_152@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_153",
            "tgt_ix": "118-ARR_v2_153@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_154",
            "tgt_ix": "118-ARR_v2_154@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "118-ARR_v2_155",
            "tgt_ix": "118-ARR_v2_155@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 886,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "doc_id": "118-ARR",
        "version": 2
    }
}