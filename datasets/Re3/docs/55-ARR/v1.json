{
    "nodes": [
        {
            "ix": "55-ARR_v1_0",
            "content": "Thai Nested Named Entity Recognition Corpus",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_2",
            "content": "This paper presents the first Thai Nested Named Entity Recognition (N-NER) dataset. Thai N-NER consists of 264,798 mentions, 104 classes, and a maximum depth of 8 layers obtained from 4,894 documents in the domains of news articles and restaurant reviews. Our work, to the best of our knowledge, presents the largest non-English N-NER dataset and the first non-English one with fine-grained classes. To understand the new challenges our proposed dataset brings to the field, we conduct an experimental study on (i) cutting edge N-NER models with the state-of-the-art accuracy in English and (ii) baseline methods based on wellknown language model architectures. From the experimental results, we obtained two key findings. First, all models produced poor F1 scores in the tail region of the class distribution. There is little or no performance improvement provided by these models with respect to the baseline methods with our Thai dataset. These findings suggest that further investigation is required to make a multilingual N-NER solution that works well across different languages.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "55-ARR_v1_4",
            "content": "Named Entity Recognition (NER) is a task of extracting named entities from given text. It identifies the span of each entity and categorizes the identified span into an entity category. NER is essential in many downstream tasks, e.g., entity linking, question answering, and knowledge graph. In addition, Yamada et al. (2020) show that the contextualized representations that include entity information can improve many downstream tasks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_5",
            "content": "The conventional NER paradigm can only label one entity type for each entity span. For example, the entity \"Chiang Mai University\" will be considered as a single span ignoring the nested structure of the term \"Chiang Mai,\" which is the name of the town that the university is situated in. As a result, we may overlook critical information that may have an impact on the language understanding in a downstream task. To mitigate this drawback, one may introduce a nested structure into the NER problem. Let us again consider the \"Chiang Mai University\" example. In addition to annotating the entire span as an organization, N-NER also identifies the sub-entity of \"Chiang Mai\" as a location. This feature can be useful in a downstream task that requires linking an entity to useful references, e.g., a university to its affiliated city.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_6",
            "content": "Considerable research attention has been dedicated to formulating a technique to solve the N-NER problem (Strakov\u00e1 et al., 2019a,b\u037e Lin et al., 2019\u037e Wang et al., 2020a\u037e Luo and Zhao, 2020\u037e Shibuya and Hovy, 2020\u037e Wang et al., 2020b. One can use an N-NER model to recursively decompose a complex entity into a tree structure of sub-entities and have them annotated accordingly.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_7",
            "content": "While N-NER has many potential benefits to downstream tasks that require deep language understanding, there is still a lack of datasets for low-resource languages to help develop reliable N-NER models. In order to train N-NER models, we need a dataset with hierarchical information of each named entity. N-NER datasets are available in several languages. Especially, English, a high resource language, has a few N-NER datasets available for multiple domains (Doddington et al., 2004\u037e Walker et al., 2006\u037e Kim et al., 2003\u037e Ringland et al., 2019 including news, social media, and molecular biology.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_8",
            "content": "The diversity of N-NER corpora is only available in English. N-NER datasets are not as widely available for other languages, let alone the diversity of corpora. In German, another high-resource language, there is only one N-NER dataset available (Benikova et al., 2014). For low-resource languages, such as Vietnamese, the two available datasets Luong, 2016\u037e Nguyen et al., 2018) are still small compared to a large N-NER dataset in English (Ringland et al., 2019).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_9",
            "content": "In this paper, we address the scarcity of non-English N-NER resources by introducing a Thai N-NER dataset. Despite over 58 million internet users 1 , the Thai language suffers from the lack of annotated resources to build NLP systems. We propose a Thai N-NER dataset comprising 264,798 entity mentions obtained from 4,894 documents. In addition to the nested entity structure, we also have more than one hundred classes providing great fidelity in entity categorization as shown in Figure 1. The number of entity mentions and variety of entity classes are comparable to a large N-NER dataset in English (Ringland et al., 2019). Our dataset contains text samples, in both formal and colloquial settings, from news articles and restaurant reviews. Additionally, our corpus allows for the multilingual evaluation of \"language-agnostic\" deep learning models, which is the current NLP research trend. To facilitate future N-NER research, we make the dataset, the annotation guideline, and the model weights publicly available.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_10",
            "content": "To summarize, our contributions are as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_11",
            "content": "\u2022 We create the first Thai N-NER dataset annotated with extensive tagsets that cover a wide range of use cases. \u2022 We evaluate three recent state-of-the-art (SOTA) N-NER models on our dataset and study the effect of long-tail classes. \u2022 We develop an N-NER benchmark comprising strong baselines for the Thai language that learn each annotation layer separately and achieve performance comparable with the three recent SOTA N-NER models.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_12",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "55-ARR_v1_13",
            "content": "In this section, we discuss various attempts on N-NER corpora. As shown in Table 1, existing N-NER corpora are mostly high-resource languages, i.e., English and German, while Vietnamese is the only Asian language that has an N-NER dataset.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_14",
            "content": "In terms of the number of classes, it is also worthnoting that three out of six corpora has less than ten and only NNE (Ringland et al., 2019) has more than 100 classes. The details of these corpora are given as follows. ACE-2004 (Doddington et al., 2004) and ACE-2005 (Walker et al., 2006) are early examples of N-NER datasets. ACE-2005 (Walker et al., 2006) dataset comprises 30,966 mentions from 12,548 sentences with 7 coarse-grained entity types. In addition to N-NER annotations, ACE-2005 also contains labels for other tasks such as recognition of relation and event extraction. GENIA introduces an N-NER data for bioinformatics. This project provides a high-quality corpus annotated for biological entity names. The dataset composed of 2,000 abstracts, 92,681 mentions from 9,533 sentences with 32 entity types.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_15",
            "content": "NNE (Ringland et al., 2019) is a recent large finegrained N-NER dataset composed of 114 classes. Unlike previous N-NER corpora, the NNE dataset annotates entities with more details. For example, \"6 September 2019\", a date named entity mention, in the NNE dataset, each element in this mention is annotated with finer detail, \"6\" is annotated with day tag, \"September\" with month tag, and \"2019\" with year tag. NoSta-D (Benikova et al., 2014) DAN+ (Plank et al., 2020) presents the first N-NER dataset for Danish. This work investigates the possibility of transfer-learning between languages for the N-NER task. Moreover, DAN+ is a multi-domain dataset\u037e they also study the challenges of domain-shift in their dataset. The dataset contains 6,425 mentions, 130,095 tokens, 4 classes from 6,867 sentences, obtained from multiple domains such as news and social media (Reddit, Twitter, and Arto). NoSta-D, VLSP-2018, and DAN+ have a modest corpus size and a small number of entity types comparing to the NNE dataset. This shows that there is still a resource gap for non-English corpora. On the other hand, for Thai, there are only coarsegrained flatten-NER datasets which are publicly available.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_16",
            "content": "Thai N-NER corpus",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "55-ARR_v1_17",
            "content": "In this section, we introduce Thai N-NER-the first Thai-Nested Named Entity Recognition dataset.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_18",
            "content": "Our dataset is comparable to the NNE corpus (Ringland et al., 2019), which is the most elaborate English N-NER dataset in terms of the number of mentions, depth, and the number of classes. In particular, Thai N-NER comprises 264,798 mentions organized into 104 classes and has a maximum depth of 8 layers.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_19",
            "content": "Data Collection Procedure",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "55-ARR_v1_20",
            "content": "To create the dataset, we gathered 4,894 documents from two different domains: news articles and restaurant reviews. In particular, we obtained 3,196 news articles from Prachathai 3 , a news website, and 1,698 restaurant reviews from Wongnai 4 , a crowd-sourced restaurant review platform.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_21",
            "content": "The Thai language poses a challenge to the annotation process. Previous work often conducts the annotation at the token level, which is quite convenient for more accurate annotation. However, the lack of clear word boundaries in the Thai writing system does not allow us to easily annotate at the word-level because the data must be word-segmented first, automatically or not. Automatic word segmentation often makes errors around out-of-vocabulary words, which are exactly what we need to annotate. Consequently, the annotation at the word level is not suitable for our purposes if the data are not manually segmented first, which incurs more cost of annotation. Annotating character-level data does not solve the problem either, because annotators are more prone to make an error.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_22",
            "content": "To ease and reduce annotation errors from entity span for the annotators, we provided our annotators with syllable-segmented data instead. Aroonmanakun (2002) shows that syllable level could resolve many word-level ambiguities in Thai. Plus, automatic syllable segmentation can be done at a near-perfect accuracy because the task is mostly solved by orthographic rules, assuming few typos exist in the data (Chormai et al., 2020). With syllable boundary indicators, we can avoid errors from word segmentation. In addition, syllablesegmented data reduces the number of indices drastically, which in turn reduces annotation errors.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_23",
            "content": "Annotation Guideline",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "55-ARR_v1_24",
            "content": "Inspired by the guideline from (Ringland et al., 2019), we designed an N-NER annotation guide- To cover a wide range of use cases, our N-NER tagsets comprises coarsegrained and fine-grained categories. While finegrained categories create extra burden for the annotation and may result in more errors, the tradeoff is worth it because finer-grained categories lend themselves to be nested within a coarser category. For example, as shown in Figure 2, \u0e1e.\u0e15.\u0e2d.\u0e1b\u0e23\u0e30\u0e40\u0e27\u0e28\u0e19\u0e4c \u0e21\u0e39 \u0e25\u0e1b\u0e23\u0e30\u0e21\u0e38 \u0e02 (p h an.tamr\u00f9at.P\u00e8k pr\u00e0w\u00ea:t mu:npr\u00e0m\u00fak) 'Police Colonel Prawet Munpramuk' is tagged with PER-a coarse-grained class which encapsulates other fine-grained classes related to person name. Within a coarse-grained mention, we include nested fine-grained information to each nested named-entity element to give more detail. For example, we annotated Apart from the description for each entity class, 5 we will provide the link to the guideline in the camera ready version. We have attached our guideline along with the dataset in this submission we provided annotators with case studies for common annotating complications. One frequent complication that we found during the annotation process is ambiguous named entities that change their categories depending on the context. The same string annotated as one category in one context might be annotated as another in a different context. To illustrate this complication, we provide the following example:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_25",
            "content": "(1) \u0e17\u0e2b\u0e32\u0e23 t h \u00e1h\u01ce:n military In the example above, the word \u0e17\u0e2b\u0e32\u0e23\u0e44\u0e17\u0e22 (t h \u00e1h\u01ce:n t h aj) 'Thai military' is not always a named entity depending on the context. In example sentence (1) \u0e17\u0e2b\u0e32\u0e23\u0e44\u0e17\u0e22\u0e42\u0e14\u0e19\u0e08\u0e31 \u0e1a (t h \u00e1h\u01ce:n t h aj do:n tC\u00e0p) 'Thai military is arrested', 'Thai military' is not a named entity because 'Thai military' refers to a Thai soldier. In contrast, the example sentence (2) \u0e17\u0e2b\u0e32\u0e23\u0e44\u0e17\u0e22\u0e2a\u0e31 \u0e48 \u0e07\u0e2b\u0e49 \u0e32\u0e21\u0e2d\u0e2d\u0e01\u0e08\u0e32\u0e01\u0e1a\u0e49 \u0e32\u0e19 (t h \u00e1h\u01ce:n t h aj s\u00e0\u014b h\u00e2:m \u00d2:k tC\u00e0:k b\u00e2:n) 'Thai military prohibits going outside of the house', 'Thai military' is a named entity because it refers to the Thai military institution.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_26",
            "content": "A named entity mention that is composed of nested named entities can be regarded as a tree structure. Specifically, the first level of a mention is the outermost or the largest entity span of the mention. The nested entities within the mention in each level must not overlap and can-not span outside of the mention. We provide an example of an issue that arises from overlapping annotations in Appendix A.3. Each coarse-grained entity type can appear in any level of the nested structure. However, finegrained entity type must be nested under its coarse-grained entity type. As shown in Table 2, \u0e1b\u0e23\u0e30\u0e18\u0e32\u0e19\u0e04\u0e13\u0e30\u0e01\u0e23\u0e23\u0e21\u0e01\u0e32\u0e23 40 \u0e1b\u0e35 14 \u0e15\u0e38 \u0e25\u0e32\u0e40\u0e1e\u0e37 \u0e48 \u0e2d\u0e1b\u0e23\u0e30\u0e0a\u0e32\u0e18\u0e34 \u0e1b\u0e44\u0e15\u0e22\u0e2a\u0e21\u0e1a\u0e39 \u0e23\u0e13\u0e4c (pr\u00e0t h a:n.k h \u00e1n\u00e1.kamm\u00e1ka:n s\u00ec:s\u00ecp pi: s\u00ecps\u00ec: t\u00f9la: p h \u0174a pr\u00e0tC h a:t h \u00edpp\u00e0taj s\u01d2mbu:n) 'The 40-year 14 Oct for complete democracy committee president' is the first level of a named-entity mention which is annotated as a role type and the nested structure also contained other coarse-grained mentions such as date or duration. However, fine-grained entity mentions, such as day and month, can only be nested inside the date class.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_27",
            "content": "Annotation Quality Control Procedure",
            "ntype": "title",
            "meta": {
                "section": "3.3"
            }
        },
        {
            "ix": "55-ARR_v1_28",
            "content": "To make our dataset reliable, we required that annotators have a background in linguistics and are properly trained to annotate under our guidelines. We also did quality control and evaluation to verify the quality of our dataset.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_29",
            "content": "Annotators",
            "ntype": "title",
            "meta": {
                "section": "3.3.1"
            }
        },
        {
            "ix": "55-ARR_v1_30",
            "content": "The dataset was manually annotated by 47 linguistically trained annotators. The annotators met the linguistic background requirement and passed the N-NER guideline understanding test. We provided a communication channel to discuss annotation issues among the annotators and the project manager. We used Datasaur.ai 6 platform for the annotators to label the data according to our guideline, using syllable span highlighting to designate each span as a specific entity.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_31",
            "content": "Annotation Verification Process",
            "ntype": "title",
            "meta": {
                "section": "3.4"
            }
        },
        {
            "ix": "55-ARR_v1_32",
            "content": "Firstly, we manually checked the quality of annotated randomly data to find common mistakes. To find more annotation errors, we extracted only the first layer to train a simple flatten CRF model. Then we use the CRF model to filter its prediction errors for further error analysis. Combining the errors found by both humans and the model, we conducted an error analysis to find the pattern of mistakes from annotators. We found prominent annotation mistake patterns, for example, inconsistency tagging, incorrect tagging, and failure to follow the guideline. Then we compiled a list of annotation errors and sent it back to the annotators to reassess.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_33",
            "content": "After the first update, we used a rule-based program to filter overlapping annotations, which did not follow our guideline, then listed all the documents with overlapping annotations. Moreover, we employed a gazetteer to filter mislabeled entities. Later, we reported the list of overlapping documents and the list of mislabeled entities to the annotators to correct all the annotation errors.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_34",
            "content": "After the second update, to inspect our dataset quality, we trained an N-NER model from Shibuya and Hovy (2020) to see whether our data can be used to trained the model and to filter out more annotation errors. The test score is 75.44% F1 score.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_35",
            "content": "We then used the model's prediction errors to filter out more annotation mistakes and reported them to the annotators for another correction session.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_36",
            "content": "Then, we split our dataset into 80% for a training set and 20% for a testing set, then re-annotated all the testing set with two annotators to validate. Finally, the third annotator corrected the annotation mismatches between the first two annotators.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_37",
            "content": "We used the Cohen's Kappa agreement score to benchmark the reliability of our dataset. We computed the inter-annotator agreement using eight sampled documents composed of 2,922 tokens. We calculated the Cohen's Kappa agreement score using two labeling schemes: CoNLL and Pyramidal, see Appendix A.4 for further descriptions. The agreement scores are given as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_38",
            "content": "\u2022 CoNLL: 0.79\u037e \u2022 Pyramidal: 0.85\u037e These high agreement scores imply that our dataset is of good quality.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_39",
            "content": "Data Format",
            "ntype": "title",
            "meta": {
                "section": "3.5"
            }
        },
        {
            "ix": "55-ARR_v1_40",
            "content": "To make our dataset convenient for research usage, we provide our dataset in CoNLL-format as shown in Table 2. We define the word boundaries in the dataset by using a maximal matching tokenizer from PyThaiNLP (Phatthiyaphaibun et al., 2016). In addition, we employ the BIOES tagging scheme to indicate the boundary of each named entity mention. Furthermore, we replace each empty space token with \"_\" in order to keep the integrity of the original text when we convert the CoNLL version back to the original text with no tokenization.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_41",
            "content": "Data Statistics",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "55-ARR_v1_42",
            "content": "This section discusses the dataset statistics and analyzes the distribution of classes in the dataset. Ta- The Thai N-NER dataset contains a nested structure for each named-entity mention. The first three layers contain 125,180, 120,909, and 16,500 mentions accounted for 99.2% and mentions all other levels contain 2,209 mentions combined accounted for only 0.8%. The 125,180 first-layer mentions can be divided into 67,168 nested mentions and 58,012 non-nested mentions. We split our dataset into training set, development set, and test set with proportion of 60%, 20%, and 20% respectively. The test set contains all the 104 classes appeared in the training set.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_43",
            "content": "We compare our dataset with other N-NER datasets in other langauges. Table 1 shows the statistics of N-NER datasets between NNE, GENIA, ACE-2005 (English), VLSP-2018 (Vietnamese), Dan+ (Danish), and our dataset (Thai). It should be noted that our dataset is comparable to the existing N-NER datasets in term of the number of tokens and the number of entity types.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_44",
            "content": "One of the challenges in this dataset is class imbalance. Due to the number of classes, the scarcity of data for rare classes contribute to the severity of class imbalance. We visualize the distribution of classes in training set in Figure 3 In conclusion, we introduce a dataset for Thai N-NER that is comparable to the standard N-NER dataset in English. Additionally, we point out a challenging long-tail distribution problem in N-NER that allows researchers to explore.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_45",
            "content": "Experimental Settings and Results",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "55-ARR_v1_46",
            "content": "The objectives of the experimental studies are as follows: the first objective is to help researchers understand how existing techniques perform on our dataset and to help them choose the most appropriate baseline for future research. The second objective is concerned with the distribution of classes which follows the 80-20 Pareto principle. As shown in Figure 3, the top 20% most frequent classes account for 80% of the mentions. We also study how these techniques perform differently at the head, body, and tail parts of the distribution. The third objective is to compare how existing models perform on our Thai dataset with respect to results from existing studies conducted on English datasets.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_47",
            "content": "Comparative N-NER Models",
            "ntype": "title",
            "meta": {
                "section": "5.1"
            }
        },
        {
            "ix": "55-ARR_v1_48",
            "content": "Since there is no existing Thai N-NER model, we formulate comparative solutions based on three approaches. The first approach is to build a baseline N-NER method from a classical machine learning technique. The second approach is applying a Thai language model to perform a span classification task. The third approach is to adapt existing N-NER methods to Thai by replacing their encoders with a Thai language model. For ease of comparison, we apply the best existing Thai language model called WangchanBERTa (Lowphansirikul et al., 2021) to second and third approaches.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_49",
            "content": "Classical ML baseline: CRF model (Minh, 2018) We train multiple CRF models, each model is dedicated to each layer. Then, we merge the prediction results from all layers to form the final N-NER result. For this model, we use the IOB tagging scheme because our dataset has a large number of classes\u037e hence the IOBES scheme will take longer to train.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_50",
            "content": "Deep learning baseline: WangchanBERTa and XLM-RoBERTa. We finetune language model (LM) encoders on our corpus with two architectural variants, LM-separate and LM-shared as shown in Figure 4a and 4b, respectively. For both model, we simply use a fully-connected linear layer as a decoder. For separate-weight (sp) version, we assign one encoder-decoder model for each layer. For shared-weight (sh) version, we use multiple decoders, one for each layer, while sharing the same encoder. We provide more information about parameter settings in Appendix A.1. To compare the performances between monolingual and multilingual BERT variants, we run experiments on both WangchanBERTa (Thai) and XLM-RoBERTa (multilingual).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_51",
            "content": "State-of-the-art Models: We select three recent SOTA N-NER models with open-source accesses and train them on our corpus. To get these models to work for Thai, we replace their encoders with the same Thai language model as the deep learning baselines (Lowphansirikul et al., 2021). For parameter configurations, we use GENIA's parameter configurations to make it possible to do sanity check by reproducing previous results on GENIA Second-best-learning (Shibuya and Hovy, 2020): This model learns to recursively decode the nested named entities from the outer to the inner nested entities. It is commonly used as a baseline in recent N-NER research. It has strong results for English N-NER.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_52",
            "content": "Pyramid (Wang et al., 2020a): This model learns hierarchical representation from multiple nested levels by using pyramid and inverse pyramid mechanisms. This model currently has the highest score on the NNE dataset.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_53",
            "content": "Locate and Label (Shen et al., 2021): This model divides entity detection into two stages: (i) it locates the entity spans\u037e (ii) it assigns a label to each entity span. It is the most recent state-of-theart model, it has top-performing scores on ACE-2004 and GENIA corpora.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_54",
            "content": "Evaluation Settings",
            "ntype": "title",
            "meta": {
                "section": "5.2"
            }
        },
        {
            "ix": "55-ARR_v1_55",
            "content": "We follow the evaluation methodology from (Shibuya and Hovy, 2020), they consider a prediction as a true positive if both the predicted entity span and type are correct. In order to examine the long-tail issue as mentioned in Section 4, we evaluated the effect of long-tail distribution by dividing classes into three groups: head, body, and tail.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_56",
            "content": "Thai N-NER Results",
            "ntype": "title",
            "meta": {
                "section": "5.3"
            }
        },
        {
            "ix": "55-ARR_v1_57",
            "content": "Table 4 shows the results on different parts of the long-tailed distribution, as well as the overall results on our dataset. Among the three existing SOTA models, the Second-best-learning model has the highest overall performance. It obtains higher F1 scores on the head and body parts of the long-tail distribution, while the Pyramid model obtains the highest F1 score on the tail part.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_58",
            "content": "Interestingly, the deep learning baseline model, WangchanBERTa-sh, outperforms all the current SOTA models.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_59",
            "content": "The results show that both WangchanBERTa and XLM-R, while they perform poorer on the head part of the long-tailed distribution, they perform much better on less frequent classes. As shown in Table 4, the performances of WangchanBERTa models on the body and tail parts, and XLM-R models on the tail part are superior to the best SOTA model.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_60",
            "content": "By having better performances on body and tail parts, while maintaining a competitive performance on the head part, WangchanBERTa-sh outperforms all the SOTA models on our corpus.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_61",
            "content": "The performances of models based on the multilingual encoder (XLM-R) are superior to Pyramid and Locate and label models. However, compared to the monolingual encoder (WangchanBERTa), XLM-R models' performances are only slightly poorer than the monolingual models. This suggests the possibility of cross-lingual N-NER tasks. (e.g. transferring cultural-specific named-entity knowledge from English to Thai). The long-tailed distribution of classes poses a challenge for the N-NER task. The performances across all models quickly deteriorate as we move from the head part of the long-tailed distribution, which represents common classes, to the tail part, which represents infrequent classes. Additionally, notice there are gaps between precision and recall for all models. These gaps imply that all models have a tendency to generate false negatives more than false positives. We can also see that the precision-recall gap has a tendency to increase as we move from the head to the tail part of the distribution. This result suggests that to improve the overall performance, we should pay attention to the recall.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_62",
            "content": "In addition, comparing to the results on English N-NER corpora, there is a performance gap for the Thai language. For example, the F1 score of the Pyramid model on the NNE corpus is 94.68, while its performance on our corpus is only 78.50. For the full comparison, see Appendix A.5.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_63",
            "content": "Error Analysis",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "55-ARR_v1_64",
            "content": "To understand the limitation of current N-NER solutions, we investigate reoccurring mistake patterns from the WangchanBERTa-sp models used in the experimental studies. We categorize the common prediction mistakes into four groups as follows: (1) Incorrect span prediction: out of 5,165 prediction errors, 2,977 errors are from span length mismatch as shown in Figure 5. (2) Ambiguous entity mentions: mentions with higher class distribution entropy have more error rates. (3) Ambiguity between fine-grained classes: there are 1,149 fewer errors when evaluated with coarse-grained ground truths. (4) Scarcity of training samples: the model only made 1,422 prediction attempts for mentions in tail classes. While 1,101 of the predictions are correct, there are 3,680 ground truths. The previous section also reveals this issue via the poor recall scores in the tail part of the long-tail distribution. We provide the description of each error pattern along with examples in Appendix A.7.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_65",
            "content": "Summary",
            "ntype": "title",
            "meta": {
                "section": "7"
            }
        },
        {
            "ix": "55-ARR_v1_66",
            "content": "We present the first Thai N-NER corpus with 104 classes. It has 1,272,381 words, and 264,798 mentions. The size of our corpus is comparable to one of the large N-NER corpora in English. Unlike other Thai NER corpora, in addition to nested structure information, our dataset is annotated with fine-grained entity types to provide more detail of the named entities. This corpus addresses the data scarcity issue for Thai NLP. In addition, it allows NLP researchers to benchmark their methods in a multilingual setting. Moreover, this dataset allows researchers to explore the effect of long-tail distribution. We hope that our dataset will encourage researchers to include Thai in their benchmark and reduce the disparity between Thai and high resource languages.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_67",
            "content": "Our dataset consists of raw text data from two publicly available corpora: Prachatai-67k and Wongnai review. These corpora use public copyright licenses (LGPL and Creative Commons) that enable free distribution. The data has a minimal risk for privacy violation since all the data were published in a public space, such as a news site and a restaurant review site. All the news articles and restaurant reviews are meant to be shared publicly, not privately. Hence, the dataset does not contain any confidential information. Our preprocessing step, which includes cleaning data and tokenization, does not alter the original contents of the texts. On average, the annotators were compensated at least twice the local minimum wage. The annotators were paid by the number of entity-mentions annotated and the number of documents that they have read. We distributed the same amount of documents for each annotator for fair consideration. This dataset addresses the data scarcity issue for Thai, which can be considered as a lower-resource language. However, this dataset only includes the central Thai dialect, which most Thai understand. It is also the dialect for official usage and is often used as a written language by Thai users. It reduces the language technology disparity gap between Thai and high-resource languages. In addition, it can facilitate researchers and the NLP community to investigate the N-NER task in a multilingual setting. We will open-source the dataset and distribute it publicly under the CC by SA 3.0 license. We will also publish the source code and all the models' weights from our experiments to assist the NLP community in N-NER research and reduce unnecessary energy usage from training the models.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_68",
            "content": "For all the deep learning baselines, we use the following parameter configuration: We employ Adam optimizer with a learning rate of 1e-5. We utilize a learning rate decay scheduler that reduces the learning rate every 50 epochs by multiplying the decay factor of 0.1. The maximum training epoch is 500, and we early stop if there is no improvement for 16 epochs.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_69",
            "content": "For the Locate and Label model, we made further modifications to the model to use it for the Thai language. Unlike the original work, the sequence length limitation of WangchanBERTa is lower than BERT-large version (Devlin et al., 2019), we use only ten words from each neighboring sentence as the context words to keep the input sequence length within the limitation. In addition, apart from contextualized word embeddings, Locate and Labels also includes static word embeddings-GloVE. We replace the GloVE word embeddings with the static word embeddings layer of thai2fit (Polpanumas and Phatthiyaphaibun, 2021). thai2fit was trained on wisesightsentiment 7 , prachathai-64k 8 , and TH-wikipedia 9 .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_70",
            "content": "Table 5 compares the WangchanBERTa-sh model's performances between the coarse-grained and fine-grained ground truths. We converted finegrained labels to their respective coarse-grained labels to examine the negative effect from the ambiguity between fine-grained classes. Table 5 shows that there is a small gap between coarsegrained and fine-grained evaluations. It suggests that adding fine-grained information to the dataset does not introduce a major challenge for N-NER models. Nevertheless, errors from ambiguity between fine-grained classes still constitute a considerable amount of models' prediction errors.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_71",
            "content": "Similar to a morphological parse tree, a nested entity annotation structure does not allow overlapping between entities in the same depth level. For example, in Figure 6, \u0e23\u0e2d\u0e07\u0e42\u0e06\u0e29\u0e01\u0e1b\u0e23\u0e30\u0e08\u0e4d \u0e32 \u0e2a\u0e4d \u0e32\u0e19\u0e31 \u0e01\u0e19\u0e32\u0e22\u0e01\u0e23\u0e31 \u0e10\u0e21\u0e19\u0e15\u0e23\u0e35 (rO:\u014b k h o:s\u00f2k pr\u00e0tCam s\u01cemn\u00e1k. Table 6: The performances of the recent SOTA N-NER models on English datasets, we include the performances from their original papers.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_72",
            "content": "CoNLL: we format our dataset according to the CoNLL schema, then calculate the Cohen's Kappa by comparing agreements of annotated entities layer by layer. The CoNLL schema takes the mention's token length into account. For each disagreed mention, we count each disagreed token as one disagreement. Therefore, mentions with more token length may have more disagreement counts. In addition, if there is a mismatch within the same layer, we count it as a disagreement even though the annotations might agree if we were to compare them from different layers. Pyramidal: we format the labels in a pyramidal manner, where we generate all possible n-gram entity span candidates for each text sequence and assign them to layers according to their lengths in the same fashion as the Pyramid model (Wang et al., 2020a). Then we compare agreements of annotated candidates between the two annotated data. We calculated the score on both character level and token level, and found no difference. We report the score on the token level. Pyramidal scheme counts each disagreed mention as one disagreement despite its length. Since Thai has no word boundary, the pyramid scheme always provides a consistent score despite using it on a different word segmentation that varies the token length.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_73",
            "content": "This study compares the performances of the N-NER models between Thai and English N-NER datasets. Table 4 shows the results on the Thai N-NER dataset, and Table 6 shows the results on English N-NER datasets. We can see that, when compared to the English results, all N-NER models performed poorer on the Thai dataset. For example, the F1-score of Pyramid on the NNE dataset (the most similar dataset compared to our work) is 94.68%, while the overall F1-score of Pyramid for Thai N-NER is only 78.50%. Although both datasets are similar in size, design, and diversity of entity classes, the performance gap is 16.18%. Experimental results verify that there is a performance gap between Thai and English N-NER. Furthermore, some model is based on the BERTlarge model, but Thai has only one BERT-based pretrained model which is based on RoBERTa (WangchanBERTa). This may have a direct affect on the performance gap. For example, the Locate and Label is based on the BERT-large model\u037e replacing BERT-large with WangchanBERTa can effect the performance directly. Despite having the best performances across multiple English N-NER datasets, Locate and Label has the lowest score on the Thai N-NER dataset when compared to other SOTA models.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_74",
            "content": "Table 7 shows the mention frequency of each finegrained entity type in our corpus before the traintest split. For each nested structure, we count all annotated mentions, not just the outermost mention. This table reveals classes with extremely low frequency which contribute to poor performances on the tail part of the long-tailed distribution.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_75",
            "content": "Incorrect span prediction: mismatches between the length of the predicted spans and the ground truths contribute to a large chunk of prediction errors.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_76",
            "content": "Figure 5 shows that out of 48,009 predicted mentions, 5,165 are incorrect. 2,977 out of 5,165 incorrect predicted mentions are due to the fact that the positions of the predicted spans are not correctly aligned with the positions of the ground truths. Often, we can find this error in the predictions for entity mentions that are very long. For example, consider the following text segment:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_77",
            "content": "(1) \u0e2d\u0e32\u0e04\u0e32\u0e23 Pa:ka:n. building \u0e23\u0e31 \u0e10\u0e1b\u0e23\u0e30\u0e28\u0e32\u0e2a\u0e19\u0e20\u0e31 \u0e01\u0e14\u0e35 r\u00e1tt h \u00e0pr\u00e0s\u00e0:ts\u00e0n\u00e1p h \u00e1kdi: Ratthaprasatsanaphakdi",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "55-ARR_v1_78",
            "content": "Wirote Aroonmanakun, Collocation and thai word segmentation, 2002, Proc. SNLP and Oriental CO-COSDA Workshop, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "Wirote Aroonmanakun"
                ],
                "title": "Collocation and thai word segmentation",
                "pub_date": "2002",
                "pub_title": "Proc. SNLP and Oriental CO-COSDA Workshop",
                "pub": null
            }
        },
        {
            "ix": "55-ARR_v1_79",
            "content": "Darina Benikova, Chris Biemann, Marc Reznicek, NoSta-D named entity annotation for German: Guidelines and dataset, 2014, Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC'14), .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Darina Benikova",
                    "Chris Biemann",
                    "Marc Reznicek"
                ],
                "title": "NoSta-D named entity annotation for German: Guidelines and dataset",
                "pub_date": "2014",
                "pub_title": "Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC'14)",
                "pub": null
            }
        },
        {
            "ix": "55-ARR_v1_80",
            "content": "UNKNOWN, None, 2020, , .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": null,
                "pub": null
            }
        },
        {
            "ix": "55-ARR_v1_81",
            "content": ", Syllable-based neural Thai word segmentation, , Proceedings of the 28th International Conference on Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [],
                "title": "Syllable-based neural Thai word segmentation",
                "pub_date": null,
                "pub_title": "Proceedings of the 28th International Conference on Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "55-ARR_v1_82",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long and Short Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Jacob Devlin",
                    "Ming-Wei Chang",
                    "Kenton Lee",
                    "Kristina Toutanova"
                ],
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Long and Short Papers"
            }
        },
        {
            "ix": "55-ARR_v1_83",
            "content": "George Doddington, Alexis Mitchell, Mark Przybocki, Lance Ramshaw, Stephanie Strassel, Ralph Weischedel, The automatic content extraction (ACE) program -tasks, data, and evaluation, 2004, Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC'04), .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "George Doddington",
                    "Alexis Mitchell",
                    "Mark Przybocki",
                    "Lance Ramshaw",
                    "Stephanie Strassel",
                    "Ralph Weischedel"
                ],
                "title": "The automatic content extraction (ACE) program -tasks, data, and evaluation",
                "pub_date": "2004",
                "pub_title": "Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC'04)",
                "pub": null
            }
        },
        {
            "ix": "55-ARR_v1_84",
            "content": "Minh Nguyen Thi,  Huyen,  Vu Xuan,  Luong, VLSP 2016 shared task: Named entity recognition, 2016, Proceedings of Vietnamese Speech and Language Processing, VLSP.",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "Minh Nguyen Thi",
                    " Huyen",
                    " Vu Xuan",
                    " Luong"
                ],
                "title": "VLSP 2016 shared task: Named entity recognition",
                "pub_date": "2016",
                "pub_title": "Proceedings of Vietnamese Speech and Language Processing",
                "pub": "VLSP"
            }
        },
        {
            "ix": "55-ARR_v1_85",
            "content": "J-D Kim, Tomoko Ohta, Yuka Tateisi, Jun'ichi Tsujii, Genia corpus-a semantically annotated corpus for bio-textmining, 2003, Bioinformatics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "J-D Kim",
                    "Tomoko Ohta",
                    "Yuka Tateisi",
                    "Jun'ichi Tsujii"
                ],
                "title": "Genia corpus-a semantically annotated corpus for bio-textmining",
                "pub_date": "2003",
                "pub_title": "Bioinformatics",
                "pub": null
            }
        },
        {
            "ix": "55-ARR_v1_86",
            "content": "Hongyu Lin, Yaojie Lu, Xianpei Han, Le Sun, Sequence-to-nuggets: Nested entity mention detection via anchor-region networks, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Hongyu Lin",
                    "Yaojie Lu",
                    "Xianpei Han",
                    "Le Sun"
                ],
                "title": "Sequence-to-nuggets: Nested entity mention detection via anchor-region networks",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "55-ARR_v1_87",
            "content": "UNKNOWN, None, 2021, Wangchanberta: Pretraining transformer-based thai language models. arXiv e-prints, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Wangchanberta: Pretraining transformer-based thai language models. arXiv e-prints",
                "pub": null
            }
        },
        {
            "ix": "55-ARR_v1_88",
            "content": "Ying Luo, Hai Zhao, Bipartite flat-graph network for nested named entity recognition, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Ying Luo",
                    "Hai Zhao"
                ],
                "title": "Bipartite flat-graph network for nested named entity recognition",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "55-ARR_v1_89",
            "content": "Nhat Pham Quang,  Minh, A feature-based model for nested named-entity recognition at vlsp-2018 ner evaluation campaign, 2018, Journal of Computer Science and Cybernetics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Nhat Pham Quang",
                    " Minh"
                ],
                "title": "A feature-based model for nested named-entity recognition at vlsp-2018 ner evaluation campaign",
                "pub_date": "2018",
                "pub_title": "Journal of Computer Science and Cybernetics",
                "pub": null
            }
        },
        {
            "ix": "55-ARR_v1_90",
            "content": "T Huyen, Quyen Nguyen,  Ngo, X Luong,  Vu, M Vu, Hien Tt Tran,  Nguyen, Vlsp shared task: Named entity recognition, 2018, Journal of Computer Science and Cybernetics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "T Huyen",
                    "Quyen Nguyen",
                    " Ngo",
                    "X Luong",
                    " Vu",
                    "M Vu",
                    "Hien Tt Tran",
                    " Nguyen"
                ],
                "title": "Vlsp shared task: Named entity recognition",
                "pub_date": "2018",
                "pub_title": "Journal of Computer Science and Cybernetics",
                "pub": null
            }
        },
        {
            "ix": "55-ARR_v1_91",
            "content": "UNKNOWN, None, 2016, PyThaiNLP: Thai Natural Language Processing in Python, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": null,
                "title": null,
                "pub_date": "2016",
                "pub_title": "PyThaiNLP: Thai Natural Language Processing in Python",
                "pub": null
            }
        },
        {
            "ix": "55-ARR_v1_92",
            "content": "Barbara Plank, Kristian Jensen, Rob Van Der Goot, DaN+: Danish nested named entities and lexical normalization, 2020, Proceedings of the 28th International Conference on Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Barbara Plank",
                    "Kristian Jensen",
                    "Rob Van Der Goot"
                ],
                "title": "DaN+: Danish nested named entities and lexical normalization",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 28th International Conference on Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "55-ARR_v1_93",
            "content": "UNKNOWN, None, , Charin Polpanumas and Wannaphong Phatthiyaphaibun. 2021. thai2fit: Thai language implementation of ulmfit, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Charin Polpanumas and Wannaphong Phatthiyaphaibun. 2021. thai2fit: Thai language implementation of ulmfit",
                "pub": null
            }
        },
        {
            "ix": "55-ARR_v1_94",
            "content": "Nicky Ringland, Xiang Dai, Ben Hachey, Sarvnaz Karimi, Cecile Paris, James Curran, NNE: A dataset for nested named entity recognition in English newswire, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "Nicky Ringland",
                    "Xiang Dai",
                    "Ben Hachey",
                    "Sarvnaz Karimi",
                    "Cecile Paris",
                    "James Curran"
                ],
                "title": "NNE: A dataset for nested named entity recognition in English newswire",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "55-ARR_v1_95",
            "content": "Yongliang Shen, Xinyin Ma, Zeqi Tan, Shuai Zhang, Wen Wang, Weiming Lu, Locate and label: A two-stage identifier for nested named entity recognition, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Yongliang Shen",
                    "Xinyin Ma",
                    "Zeqi Tan",
                    "Shuai Zhang",
                    "Wen Wang",
                    "Weiming Lu"
                ],
                "title": "Locate and label: A two-stage identifier for nested named entity recognition",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "55-ARR_v1_96",
            "content": "UNKNOWN, None, 2020, Nested named entity recognition via second-best sequence learning and decoding. Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Nested named entity recognition via second-best sequence learning and decoding. Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "55-ARR_v1_97",
            "content": "Jana Strakov\u00e1, Milan Straka, Neural architectures for nested ner through linearization, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "Jana Strakov\u00e1",
                    "Milan Straka"
                ],
                "title": "Neural architectures for nested ner through linearization",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "55-ARR_v1_98",
            "content": "Jana Strakov\u00e1, Milan Straka, Neural architectures for nested NER through linearization, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Jana Strakov\u00e1",
                    "Milan Straka"
                ],
                "title": "Neural architectures for nested NER through linearization",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "55-ARR_v1_99",
            "content": "Erik Tjong, Kim Sang, Fien De Meulder, Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition, 2003, Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "Erik Tjong",
                    "Kim Sang",
                    "Fien De Meulder"
                ],
                "title": "Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition",
                "pub_date": "2003",
                "pub_title": "Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003",
                "pub": null
            }
        },
        {
            "ix": "55-ARR_v1_100",
            "content": "UNKNOWN, None, 2006, ACE 2005 Multilingual Training Corpus LDC2006T06, .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": null,
                "title": null,
                "pub_date": "2006",
                "pub_title": "ACE 2005 Multilingual Training Corpus LDC2006T06",
                "pub": null
            }
        },
        {
            "ix": "55-ARR_v1_101",
            "content": "Jue Wang, Lidan Shou, Ke Chen, Gang Chen, Pyramid: A layered model for nested named entity recognition, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Jue Wang",
                    "Lidan Shou",
                    "Ke Chen",
                    "Gang Chen"
                ],
                "title": "Pyramid: A layered model for nested named entity recognition",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "55-ARR_v1_102",
            "content": "Yu Wang, Yun Li, Hanghang Tong, Ziye Zhu, HIT: Nested named entity recognition via head-tail pair and token interaction, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Yu Wang",
                    "Yun Li",
                    "Hanghang Tong",
                    "Ziye Zhu"
                ],
                "title": "HIT: Nested named entity recognition via head-tail pair and token interaction",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "55-ARR_v1_103",
            "content": "Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, Yuji Matsumoto, LUKE: Deep contextualized entity representations with entityaware self-attention, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Ikuya Yamada",
                    "Akari Asai",
                    "Hiroyuki Shindo",
                    "Hideaki Takeda",
                    "Yuji Matsumoto"
                ],
                "title": "LUKE: Deep contextualized entity representations with entityaware self-attention",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": "Association for Computational Linguistics"
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "55-ARR_v1_0@0",
            "content": "Thai Nested Named Entity Recognition Corpus",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_0",
            "start": 0,
            "end": 42,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_2@0",
            "content": "This paper presents the first Thai Nested Named Entity Recognition (N-NER) dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_2",
            "start": 0,
            "end": 82,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_2@1",
            "content": "Thai N-NER consists of 264,798 mentions, 104 classes, and a maximum depth of 8 layers obtained from 4,894 documents in the domains of news articles and restaurant reviews.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_2",
            "start": 84,
            "end": 254,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_2@2",
            "content": "Our work, to the best of our knowledge, presents the largest non-English N-NER dataset and the first non-English one with fine-grained classes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_2",
            "start": 256,
            "end": 398,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_2@3",
            "content": "To understand the new challenges our proposed dataset brings to the field, we conduct an experimental study on (i) cutting edge N-NER models with the state-of-the-art accuracy in English and (ii) baseline methods based on wellknown language model architectures.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_2",
            "start": 400,
            "end": 660,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_2@4",
            "content": "From the experimental results, we obtained two key findings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_2",
            "start": 662,
            "end": 721,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_2@5",
            "content": "First, all models produced poor F1 scores in the tail region of the class distribution.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_2",
            "start": 723,
            "end": 809,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_2@6",
            "content": "There is little or no performance improvement provided by these models with respect to the baseline methods with our Thai dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_2",
            "start": 811,
            "end": 940,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_2@7",
            "content": "These findings suggest that further investigation is required to make a multilingual N-NER solution that works well across different languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_2",
            "start": 942,
            "end": 1084,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_4@0",
            "content": "Named Entity Recognition (NER) is a task of extracting named entities from given text.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_4",
            "start": 0,
            "end": 85,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_4@1",
            "content": "It identifies the span of each entity and categorizes the identified span into an entity category.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_4",
            "start": 87,
            "end": 184,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_4@2",
            "content": "NER is essential in many downstream tasks, e.g., entity linking, question answering, and knowledge graph.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_4",
            "start": 186,
            "end": 290,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_4@3",
            "content": "In addition, Yamada et al. (2020) show that the contextualized representations that include entity information can improve many downstream tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_4",
            "start": 292,
            "end": 436,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_5@0",
            "content": "The conventional NER paradigm can only label one entity type for each entity span.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_5",
            "start": 0,
            "end": 81,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_5@1",
            "content": "For example, the entity \"Chiang Mai University\" will be considered as a single span ignoring the nested structure of the term \"Chiang Mai,\" which is the name of the town that the university is situated in.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_5",
            "start": 83,
            "end": 287,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_5@2",
            "content": "As a result, we may overlook critical information that may have an impact on the language understanding in a downstream task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_5",
            "start": 289,
            "end": 413,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_5@3",
            "content": "To mitigate this drawback, one may introduce a nested structure into the NER problem. Let us again consider the \"Chiang Mai University\" example.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_5",
            "start": 415,
            "end": 558,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_5@4",
            "content": "In addition to annotating the entire span as an organization, N-NER also identifies the sub-entity of \"Chiang Mai\" as a location.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_5",
            "start": 560,
            "end": 688,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_5@5",
            "content": "This feature can be useful in a downstream task that requires linking an entity to useful references, e.g., a university to its affiliated city.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_5",
            "start": 690,
            "end": 833,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_6@0",
            "content": "Considerable research attention has been dedicated to formulating a technique to solve the N-NER problem (Strakov\u00e1 et al., 2019a,b\u037e Lin et al., 2019\u037e Wang et al., 2020a\u037e Luo and Zhao, 2020\u037e Shibuya and Hovy, 2020\u037e Wang et al., 2020b.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_6",
            "start": 0,
            "end": 232,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_6@1",
            "content": "One can use an N-NER model to recursively decompose a complex entity into a tree structure of sub-entities and have them annotated accordingly.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_6",
            "start": 234,
            "end": 376,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_7@0",
            "content": "While N-NER has many potential benefits to downstream tasks that require deep language understanding, there is still a lack of datasets for low-resource languages to help develop reliable N-NER models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_7",
            "start": 0,
            "end": 200,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_7@1",
            "content": "In order to train N-NER models, we need a dataset with hierarchical information of each named entity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_7",
            "start": 202,
            "end": 302,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_7@2",
            "content": "N-NER datasets are available in several languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_7",
            "start": 304,
            "end": 353,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_7@3",
            "content": "Especially, English, a high resource language, has a few N-NER datasets available for multiple domains (Doddington et al., 2004\u037e Walker et al., 2006\u037e Kim et al., 2003\u037e Ringland et al., 2019 including news, social media, and molecular biology.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_7",
            "start": 355,
            "end": 596,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_8@0",
            "content": "The diversity of N-NER corpora is only available in English.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_8",
            "start": 0,
            "end": 59,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_8@1",
            "content": "N-NER datasets are not as widely available for other languages, let alone the diversity of corpora.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_8",
            "start": 61,
            "end": 159,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_8@2",
            "content": "In German, another high-resource language, there is only one N-NER dataset available (Benikova et al., 2014).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_8",
            "start": 161,
            "end": 269,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_8@3",
            "content": "For low-resource languages, such as Vietnamese, the two available datasets Luong, 2016\u037e Nguyen et al., 2018) are still small compared to a large N-NER dataset in English (Ringland et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_8",
            "start": 271,
            "end": 464,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_9@0",
            "content": "In this paper, we address the scarcity of non-English N-NER resources by introducing a Thai N-NER dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_9",
            "start": 0,
            "end": 105,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_9@1",
            "content": "Despite over 58 million internet users 1 , the Thai language suffers from the lack of annotated resources to build NLP systems.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_9",
            "start": 107,
            "end": 233,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_9@2",
            "content": "We propose a Thai N-NER dataset comprising 264,798 entity mentions obtained from 4,894 documents.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_9",
            "start": 235,
            "end": 331,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_9@3",
            "content": "In addition to the nested entity structure, we also have more than one hundred classes providing great fidelity in entity categorization as shown in Figure 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_9",
            "start": 333,
            "end": 490,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_9@4",
            "content": "The number of entity mentions and variety of entity classes are comparable to a large N-NER dataset in English (Ringland et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_9",
            "start": 492,
            "end": 626,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_9@5",
            "content": "Our dataset contains text samples, in both formal and colloquial settings, from news articles and restaurant reviews.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_9",
            "start": 628,
            "end": 744,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_9@6",
            "content": "Additionally, our corpus allows for the multilingual evaluation of \"language-agnostic\" deep learning models, which is the current NLP research trend.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_9",
            "start": 746,
            "end": 894,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_9@7",
            "content": "To facilitate future N-NER research, we make the dataset, the annotation guideline, and the model weights publicly available.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_9",
            "start": 896,
            "end": 1020,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_10@0",
            "content": "To summarize, our contributions are as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_10",
            "start": 0,
            "end": 46,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_11@0",
            "content": "\u2022 We create the first Thai N-NER dataset annotated with extensive tagsets that cover a wide range of use cases. \u2022 We evaluate three recent state-of-the-art (SOTA) N-NER models on our dataset and study the effect of long-tail classes. \u2022 We develop an N-NER benchmark comprising strong baselines for the Thai language that learn each annotation layer separately and achieve performance comparable with the three recent SOTA N-NER models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_11",
            "start": 0,
            "end": 434,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_12@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_12",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_13@0",
            "content": "In this section, we discuss various attempts on N-NER corpora.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_13",
            "start": 0,
            "end": 61,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_13@1",
            "content": "As shown in Table 1, existing N-NER corpora are mostly high-resource languages, i.e., English and German, while Vietnamese is the only Asian language that has an N-NER dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_13",
            "start": 63,
            "end": 238,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_14@0",
            "content": "In terms of the number of classes, it is also worthnoting that three out of six corpora has less than ten and only NNE (Ringland et al., 2019) has more than 100 classes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_14",
            "start": 0,
            "end": 168,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_14@1",
            "content": "The details of these corpora are given as follows.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_14",
            "start": 170,
            "end": 219,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_14@2",
            "content": "ACE-2004 (Doddington et al., 2004) and ACE-2005 (Walker et al., 2006) are early examples of N-NER datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_14",
            "start": 221,
            "end": 327,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_14@3",
            "content": "ACE-2005 (Walker et al., 2006) dataset comprises 30,966 mentions from 12,548 sentences with 7 coarse-grained entity types.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_14",
            "start": 329,
            "end": 450,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_14@4",
            "content": "In addition to N-NER annotations, ACE-2005 also contains labels for other tasks such as recognition of relation and event extraction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_14",
            "start": 452,
            "end": 584,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_14@5",
            "content": "GENIA introduces an N-NER data for bioinformatics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_14",
            "start": 586,
            "end": 635,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_14@6",
            "content": "This project provides a high-quality corpus annotated for biological entity names.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_14",
            "start": 637,
            "end": 718,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_14@7",
            "content": "The dataset composed of 2,000 abstracts, 92,681 mentions from 9,533 sentences with 32 entity types.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_14",
            "start": 720,
            "end": 818,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_15@0",
            "content": "NNE (Ringland et al., 2019) is a recent large finegrained N-NER dataset composed of 114 classes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_15",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_15@1",
            "content": "Unlike previous N-NER corpora, the NNE dataset annotates entities with more details.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_15",
            "start": 97,
            "end": 180,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_15@2",
            "content": "For example, \"6 September 2019\", a date named entity mention, in the NNE dataset, each element in this mention is annotated with finer detail, \"6\" is annotated with day tag, \"September\" with month tag, and \"2019\" with year tag.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_15",
            "start": 182,
            "end": 408,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_15@3",
            "content": "NoSta-D (Benikova et al., 2014) DAN+ (Plank et al., 2020) presents the first N-NER dataset for Danish.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_15",
            "start": 410,
            "end": 511,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_15@4",
            "content": "This work investigates the possibility of transfer-learning between languages for the N-NER task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_15",
            "start": 513,
            "end": 609,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_15@5",
            "content": "Moreover, DAN+ is a multi-domain dataset\u037e they also study the challenges of domain-shift in their dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_15",
            "start": 611,
            "end": 716,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_15@6",
            "content": "The dataset contains 6,425 mentions, 130,095 tokens, 4 classes from 6,867 sentences, obtained from multiple domains such as news and social media (Reddit, Twitter, and Arto).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_15",
            "start": 718,
            "end": 891,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_15@7",
            "content": "NoSta-D, VLSP-2018, and DAN+ have a modest corpus size and a small number of entity types comparing to the NNE dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_15",
            "start": 893,
            "end": 1011,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_15@8",
            "content": "This shows that there is still a resource gap for non-English corpora.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_15",
            "start": 1013,
            "end": 1082,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_15@9",
            "content": "On the other hand, for Thai, there are only coarsegrained flatten-NER datasets which are publicly available.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_15",
            "start": 1084,
            "end": 1191,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_16@0",
            "content": "Thai N-NER corpus",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_16",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_17@0",
            "content": "In this section, we introduce Thai N-NER-the first Thai-Nested Named Entity Recognition dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_17",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_18@0",
            "content": "Our dataset is comparable to the NNE corpus (Ringland et al., 2019), which is the most elaborate English N-NER dataset in terms of the number of mentions, depth, and the number of classes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_18",
            "start": 0,
            "end": 187,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_18@1",
            "content": "In particular, Thai N-NER comprises 264,798 mentions organized into 104 classes and has a maximum depth of 8 layers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_18",
            "start": 189,
            "end": 304,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_19@0",
            "content": "Data Collection Procedure",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_19",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_20@0",
            "content": "To create the dataset, we gathered 4,894 documents from two different domains: news articles and restaurant reviews.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_20",
            "start": 0,
            "end": 115,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_20@1",
            "content": "In particular, we obtained 3,196 news articles from Prachathai 3 , a news website, and 1,698 restaurant reviews from Wongnai 4 , a crowd-sourced restaurant review platform.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_20",
            "start": 117,
            "end": 288,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_21@0",
            "content": "The Thai language poses a challenge to the annotation process.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_21",
            "start": 0,
            "end": 61,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_21@1",
            "content": "Previous work often conducts the annotation at the token level, which is quite convenient for more accurate annotation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_21",
            "start": 63,
            "end": 181,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_21@2",
            "content": "However, the lack of clear word boundaries in the Thai writing system does not allow us to easily annotate at the word-level because the data must be word-segmented first, automatically or not.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_21",
            "start": 183,
            "end": 375,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_21@3",
            "content": "Automatic word segmentation often makes errors around out-of-vocabulary words, which are exactly what we need to annotate.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_21",
            "start": 377,
            "end": 498,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_21@4",
            "content": "Consequently, the annotation at the word level is not suitable for our purposes if the data are not manually segmented first, which incurs more cost of annotation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_21",
            "start": 500,
            "end": 662,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_21@5",
            "content": "Annotating character-level data does not solve the problem either, because annotators are more prone to make an error.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_21",
            "start": 664,
            "end": 781,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_22@0",
            "content": "To ease and reduce annotation errors from entity span for the annotators, we provided our annotators with syllable-segmented data instead.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_22",
            "start": 0,
            "end": 137,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_22@1",
            "content": "Aroonmanakun (2002) shows that syllable level could resolve many word-level ambiguities in Thai.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_22",
            "start": 139,
            "end": 234,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_22@2",
            "content": "Plus, automatic syllable segmentation can be done at a near-perfect accuracy because the task is mostly solved by orthographic rules, assuming few typos exist in the data (Chormai et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_22",
            "start": 236,
            "end": 429,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_22@3",
            "content": "With syllable boundary indicators, we can avoid errors from word segmentation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_22",
            "start": 431,
            "end": 508,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_22@4",
            "content": "In addition, syllablesegmented data reduces the number of indices drastically, which in turn reduces annotation errors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_22",
            "start": 510,
            "end": 628,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_23@0",
            "content": "Annotation Guideline",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_23",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_24@0",
            "content": "Inspired by the guideline from (Ringland et al., 2019), we designed an N-NER annotation guide- To cover a wide range of use cases, our N-NER tagsets comprises coarsegrained and fine-grained categories.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_24",
            "start": 0,
            "end": 200,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_24@1",
            "content": "While finegrained categories create extra burden for the annotation and may result in more errors, the tradeoff is worth it because finer-grained categories lend themselves to be nested within a coarser category. For example, as shown in Figure 2, \u0e1e.\u0e15.\u0e2d.\u0e1b\u0e23\u0e30\u0e40\u0e27\u0e28\u0e19\u0e4c \u0e21\u0e39 \u0e25\u0e1b\u0e23\u0e30\u0e21\u0e38 \u0e02 (p h an.tamr\u00f9at.P\u00e8k pr\u00e0w\u00ea:t mu:npr\u00e0m\u00fak) 'Police Colonel Prawet Munpramuk' is tagged with PER-a coarse-grained class which encapsulates other fine-grained classes related to person name.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_24",
            "start": 202,
            "end": 661,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_24@2",
            "content": "Within a coarse-grained mention, we include nested fine-grained information to each nested named-entity element to give more detail.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_24",
            "start": 663,
            "end": 794,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_24@3",
            "content": "For example, we annotated Apart from the description for each entity class, 5 we will provide the link to the guideline in the camera ready version.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_24",
            "start": 796,
            "end": 943,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_24@4",
            "content": "We have attached our guideline along with the dataset in this submission we provided annotators with case studies for common annotating complications.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_24",
            "start": 945,
            "end": 1094,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_24@5",
            "content": "One frequent complication that we found during the annotation process is ambiguous named entities that change their categories depending on the context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_24",
            "start": 1096,
            "end": 1247,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_24@6",
            "content": "The same string annotated as one category in one context might be annotated as another in a different context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_24",
            "start": 1249,
            "end": 1358,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_24@7",
            "content": "To illustrate this complication, we provide the following example:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_24",
            "start": 1360,
            "end": 1425,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_25@0",
            "content": "(1) \u0e17\u0e2b\u0e32\u0e23 t h \u00e1h\u01ce:n military In the example above, the word \u0e17\u0e2b\u0e32\u0e23\u0e44\u0e17\u0e22 (t h \u00e1h\u01ce:n t h aj) 'Thai military' is not always a named entity depending on the context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_25",
            "start": 0,
            "end": 155,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_25@1",
            "content": "In example sentence (1) \u0e17\u0e2b\u0e32\u0e23\u0e44\u0e17\u0e22\u0e42\u0e14\u0e19\u0e08\u0e31 \u0e1a (t h \u00e1h\u01ce:n t h aj do:n tC\u00e0p) 'Thai military is arrested', 'Thai military' is not a named entity because 'Thai military' refers to a Thai soldier.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_25",
            "start": 157,
            "end": 340,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_25@2",
            "content": "In contrast, the example sentence (2) \u0e17\u0e2b\u0e32\u0e23\u0e44\u0e17\u0e22\u0e2a\u0e31 \u0e48 \u0e07\u0e2b\u0e49 \u0e32\u0e21\u0e2d\u0e2d\u0e01\u0e08\u0e32\u0e01\u0e1a\u0e49 \u0e32\u0e19 (t h \u00e1h\u01ce:n t h aj s\u00e0\u014b h\u00e2:m \u00d2:k tC\u00e0:k b\u00e2:n) 'Thai military prohibits going outside of the house', 'Thai military' is a named entity because it refers to the Thai military institution.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_25",
            "start": 342,
            "end": 591,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_26@0",
            "content": "A named entity mention that is composed of nested named entities can be regarded as a tree structure.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_26",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_26@1",
            "content": "Specifically, the first level of a mention is the outermost or the largest entity span of the mention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_26",
            "start": 102,
            "end": 203,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_26@2",
            "content": "The nested entities within the mention in each level must not overlap and can-not span outside of the mention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_26",
            "start": 205,
            "end": 314,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_26@3",
            "content": "We provide an example of an issue that arises from overlapping annotations in Appendix A.3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_26",
            "start": 316,
            "end": 406,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_26@4",
            "content": "Each coarse-grained entity type can appear in any level of the nested structure.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_26",
            "start": 408,
            "end": 487,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_26@5",
            "content": "However, finegrained entity type must be nested under its coarse-grained entity type.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_26",
            "start": 489,
            "end": 573,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_26@6",
            "content": "As shown in Table 2, \u0e1b\u0e23\u0e30\u0e18\u0e32\u0e19\u0e04\u0e13\u0e30\u0e01\u0e23\u0e23\u0e21\u0e01\u0e32\u0e23 40 \u0e1b\u0e35 14 \u0e15\u0e38 \u0e25\u0e32\u0e40\u0e1e\u0e37 \u0e48 \u0e2d\u0e1b\u0e23\u0e30\u0e0a\u0e32\u0e18\u0e34 \u0e1b\u0e44\u0e15\u0e22\u0e2a\u0e21\u0e1a\u0e39 \u0e23\u0e13\u0e4c (pr\u00e0t h a:n.k h \u00e1n\u00e1.kamm\u00e1ka:n s\u00ec:s\u00ecp pi: s\u00ecps\u00ec: t\u00f9la: p h \u0174a pr\u00e0tC h a:t h \u00edpp\u00e0taj s\u01d2mbu:n) 'The 40-year 14 Oct for complete democracy committee president' is the first level of a named-entity mention which is annotated as a role type and the nested structure also contained other coarse-grained mentions such as date or duration.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_26",
            "start": 575,
            "end": 984,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_26@7",
            "content": "However, fine-grained entity mentions, such as day and month, can only be nested inside the date class.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_26",
            "start": 986,
            "end": 1088,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_27@0",
            "content": "Annotation Quality Control Procedure",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_27",
            "start": 0,
            "end": 35,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_28@0",
            "content": "To make our dataset reliable, we required that annotators have a background in linguistics and are properly trained to annotate under our guidelines.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_28",
            "start": 0,
            "end": 148,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_28@1",
            "content": "We also did quality control and evaluation to verify the quality of our dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_28",
            "start": 150,
            "end": 229,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_29@0",
            "content": "Annotators",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_29",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_30@0",
            "content": "The dataset was manually annotated by 47 linguistically trained annotators.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_30",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_30@1",
            "content": "The annotators met the linguistic background requirement and passed the N-NER guideline understanding test.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_30",
            "start": 76,
            "end": 182,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_30@2",
            "content": "We provided a communication channel to discuss annotation issues among the annotators and the project manager.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_30",
            "start": 184,
            "end": 293,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_30@3",
            "content": "We used Datasaur.ai 6 platform for the annotators to label the data according to our guideline, using syllable span highlighting to designate each span as a specific entity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_30",
            "start": 295,
            "end": 467,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_31@0",
            "content": "Annotation Verification Process",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_31",
            "start": 0,
            "end": 30,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_32@0",
            "content": "Firstly, we manually checked the quality of annotated randomly data to find common mistakes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_32",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_32@1",
            "content": "To find more annotation errors, we extracted only the first layer to train a simple flatten CRF model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_32",
            "start": 93,
            "end": 194,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_32@2",
            "content": "Then we use the CRF model to filter its prediction errors for further error analysis.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_32",
            "start": 196,
            "end": 280,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_32@3",
            "content": "Combining the errors found by both humans and the model, we conducted an error analysis to find the pattern of mistakes from annotators.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_32",
            "start": 282,
            "end": 417,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_32@4",
            "content": "We found prominent annotation mistake patterns, for example, inconsistency tagging, incorrect tagging, and failure to follow the guideline.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_32",
            "start": 419,
            "end": 557,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_32@5",
            "content": "Then we compiled a list of annotation errors and sent it back to the annotators to reassess.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_32",
            "start": 559,
            "end": 650,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_33@0",
            "content": "After the first update, we used a rule-based program to filter overlapping annotations, which did not follow our guideline, then listed all the documents with overlapping annotations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_33",
            "start": 0,
            "end": 182,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_33@1",
            "content": "Moreover, we employed a gazetteer to filter mislabeled entities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_33",
            "start": 184,
            "end": 247,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_33@2",
            "content": "Later, we reported the list of overlapping documents and the list of mislabeled entities to the annotators to correct all the annotation errors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_33",
            "start": 249,
            "end": 392,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_34@0",
            "content": "After the second update, to inspect our dataset quality, we trained an N-NER model from Shibuya and Hovy (2020) to see whether our data can be used to trained the model and to filter out more annotation errors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_34",
            "start": 0,
            "end": 209,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_34@1",
            "content": "The test score is 75.44% F1 score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_34",
            "start": 211,
            "end": 244,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_35@0",
            "content": "We then used the model's prediction errors to filter out more annotation mistakes and reported them to the annotators for another correction session.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_35",
            "start": 0,
            "end": 148,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_36@0",
            "content": "Then, we split our dataset into 80% for a training set and 20% for a testing set, then re-annotated all the testing set with two annotators to validate.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_36",
            "start": 0,
            "end": 151,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_36@1",
            "content": "Finally, the third annotator corrected the annotation mismatches between the first two annotators.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_36",
            "start": 153,
            "end": 250,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_37@0",
            "content": "We used the Cohen's Kappa agreement score to benchmark the reliability of our dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_37",
            "start": 0,
            "end": 85,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_37@1",
            "content": "We computed the inter-annotator agreement using eight sampled documents composed of 2,922 tokens.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_37",
            "start": 87,
            "end": 183,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_37@2",
            "content": "We calculated the Cohen's Kappa agreement score using two labeling schemes: CoNLL and Pyramidal, see Appendix A.4 for further descriptions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_37",
            "start": 185,
            "end": 323,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_37@3",
            "content": "The agreement scores are given as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_37",
            "start": 325,
            "end": 366,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_38@0",
            "content": "\u2022 CoNLL: 0.79\u037e \u2022 Pyramidal: 0.85\u037e These high agreement scores imply that our dataset is of good quality.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_38",
            "start": 0,
            "end": 103,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_39@0",
            "content": "Data Format",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_39",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_40@0",
            "content": "To make our dataset convenient for research usage, we provide our dataset in CoNLL-format as shown in Table 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_40",
            "start": 0,
            "end": 109,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_40@1",
            "content": "We define the word boundaries in the dataset by using a maximal matching tokenizer from PyThaiNLP (Phatthiyaphaibun et al., 2016).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_40",
            "start": 111,
            "end": 240,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_40@2",
            "content": "In addition, we employ the BIOES tagging scheme to indicate the boundary of each named entity mention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_40",
            "start": 242,
            "end": 343,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_40@3",
            "content": "Furthermore, we replace each empty space token with \"_\" in order to keep the integrity of the original text when we convert the CoNLL version back to the original text with no tokenization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_40",
            "start": 345,
            "end": 533,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_41@0",
            "content": "Data Statistics",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_41",
            "start": 0,
            "end": 14,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_42@0",
            "content": "This section discusses the dataset statistics and analyzes the distribution of classes in the dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_42",
            "start": 0,
            "end": 101,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_42@1",
            "content": "Ta- The Thai N-NER dataset contains a nested structure for each named-entity mention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_42",
            "start": 103,
            "end": 187,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_42@2",
            "content": "The first three layers contain 125,180, 120,909, and 16,500 mentions accounted for 99.2% and mentions all other levels contain 2,209 mentions combined accounted for only 0.8%.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_42",
            "start": 189,
            "end": 363,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_42@3",
            "content": "The 125,180 first-layer mentions can be divided into 67,168 nested mentions and 58,012 non-nested mentions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_42",
            "start": 365,
            "end": 471,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_42@4",
            "content": "We split our dataset into training set, development set, and test set with proportion of 60%, 20%, and 20% respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_42",
            "start": 473,
            "end": 592,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_42@5",
            "content": "The test set contains all the 104 classes appeared in the training set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_42",
            "start": 594,
            "end": 664,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_43@0",
            "content": "We compare our dataset with other N-NER datasets in other langauges.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_43",
            "start": 0,
            "end": 67,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_43@1",
            "content": "Table 1 shows the statistics of N-NER datasets between NNE, GENIA, ACE-2005 (English), VLSP-2018 (Vietnamese), Dan+ (Danish), and our dataset (Thai).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_43",
            "start": 69,
            "end": 217,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_43@2",
            "content": "It should be noted that our dataset is comparable to the existing N-NER datasets in term of the number of tokens and the number of entity types.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_43",
            "start": 219,
            "end": 362,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_44@0",
            "content": "One of the challenges in this dataset is class imbalance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_44",
            "start": 0,
            "end": 56,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_44@1",
            "content": "Due to the number of classes, the scarcity of data for rare classes contribute to the severity of class imbalance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_44",
            "start": 58,
            "end": 171,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_44@2",
            "content": "We visualize the distribution of classes in training set in Figure 3 In conclusion, we introduce a dataset for Thai N-NER that is comparable to the standard N-NER dataset in English.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_44",
            "start": 173,
            "end": 354,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_44@3",
            "content": "Additionally, we point out a challenging long-tail distribution problem in N-NER that allows researchers to explore.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_44",
            "start": 356,
            "end": 471,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_45@0",
            "content": "Experimental Settings and Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_45",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_46@0",
            "content": "The objectives of the experimental studies are as follows: the first objective is to help researchers understand how existing techniques perform on our dataset and to help them choose the most appropriate baseline for future research.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_46",
            "start": 0,
            "end": 233,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_46@1",
            "content": "The second objective is concerned with the distribution of classes which follows the 80-20 Pareto principle.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_46",
            "start": 235,
            "end": 342,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_46@2",
            "content": "As shown in Figure 3, the top 20% most frequent classes account for 80% of the mentions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_46",
            "start": 344,
            "end": 431,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_46@3",
            "content": "We also study how these techniques perform differently at the head, body, and tail parts of the distribution.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_46",
            "start": 433,
            "end": 541,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_46@4",
            "content": "The third objective is to compare how existing models perform on our Thai dataset with respect to results from existing studies conducted on English datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_46",
            "start": 543,
            "end": 700,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_47@0",
            "content": "Comparative N-NER Models",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_47",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_48@0",
            "content": "Since there is no existing Thai N-NER model, we formulate comparative solutions based on three approaches.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_48",
            "start": 0,
            "end": 105,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_48@1",
            "content": "The first approach is to build a baseline N-NER method from a classical machine learning technique.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_48",
            "start": 107,
            "end": 205,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_48@2",
            "content": "The second approach is applying a Thai language model to perform a span classification task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_48",
            "start": 207,
            "end": 298,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_48@3",
            "content": "The third approach is to adapt existing N-NER methods to Thai by replacing their encoders with a Thai language model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_48",
            "start": 300,
            "end": 416,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_48@4",
            "content": "For ease of comparison, we apply the best existing Thai language model called WangchanBERTa (Lowphansirikul et al., 2021) to second and third approaches.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_48",
            "start": 418,
            "end": 570,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_49@0",
            "content": "Classical ML baseline: CRF model (Minh, 2018) We train multiple CRF models, each model is dedicated to each layer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_49",
            "start": 0,
            "end": 113,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_49@1",
            "content": "Then, we merge the prediction results from all layers to form the final N-NER result.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_49",
            "start": 115,
            "end": 199,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_49@2",
            "content": "For this model, we use the IOB tagging scheme because our dataset has a large number of classes\u037e hence the IOBES scheme will take longer to train.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_49",
            "start": 201,
            "end": 346,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_50@0",
            "content": "Deep learning baseline: WangchanBERTa and XLM-RoBERTa.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_50",
            "start": 0,
            "end": 53,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_50@1",
            "content": "We finetune language model (LM) encoders on our corpus with two architectural variants, LM-separate and LM-shared as shown in Figure 4a and 4b, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_50",
            "start": 55,
            "end": 211,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_50@2",
            "content": "For both model, we simply use a fully-connected linear layer as a decoder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_50",
            "start": 213,
            "end": 286,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_50@3",
            "content": "For separate-weight (sp) version, we assign one encoder-decoder model for each layer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_50",
            "start": 288,
            "end": 372,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_50@4",
            "content": "For shared-weight (sh) version, we use multiple decoders, one for each layer, while sharing the same encoder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_50",
            "start": 374,
            "end": 482,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_50@5",
            "content": "We provide more information about parameter settings in Appendix A.1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_50",
            "start": 484,
            "end": 552,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_50@6",
            "content": "To compare the performances between monolingual and multilingual BERT variants, we run experiments on both WangchanBERTa (Thai) and XLM-RoBERTa (multilingual).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_50",
            "start": 554,
            "end": 712,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_51@0",
            "content": "State-of-the-art Models: We select three recent SOTA N-NER models with open-source accesses and train them on our corpus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_51",
            "start": 0,
            "end": 120,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_51@1",
            "content": "To get these models to work for Thai, we replace their encoders with the same Thai language model as the deep learning baselines (Lowphansirikul et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_51",
            "start": 122,
            "end": 280,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_51@2",
            "content": "For parameter configurations, we use GENIA's parameter configurations to make it possible to do sanity check by reproducing previous results on GENIA Second-best-learning (Shibuya and Hovy, 2020): This model learns to recursively decode the nested named entities from the outer to the inner nested entities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_51",
            "start": 282,
            "end": 588,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_51@3",
            "content": "It is commonly used as a baseline in recent N-NER research.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_51",
            "start": 590,
            "end": 648,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_51@4",
            "content": "It has strong results for English N-NER.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_51",
            "start": 650,
            "end": 689,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_52@0",
            "content": "Pyramid (Wang et al., 2020a): This model learns hierarchical representation from multiple nested levels by using pyramid and inverse pyramid mechanisms.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_52",
            "start": 0,
            "end": 151,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_52@1",
            "content": "This model currently has the highest score on the NNE dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_52",
            "start": 153,
            "end": 214,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_53@0",
            "content": "Locate and Label (Shen et al., 2021): This model divides entity detection into two stages: (i) it locates the entity spans\u037e (ii) it assigns a label to each entity span.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_53",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_53@1",
            "content": "It is the most recent state-of-theart model, it has top-performing scores on ACE-2004 and GENIA corpora.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_53",
            "start": 169,
            "end": 272,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_54@0",
            "content": "Evaluation Settings",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_54",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_55@0",
            "content": "We follow the evaluation methodology from (Shibuya and Hovy, 2020), they consider a prediction as a true positive if both the predicted entity span and type are correct.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_55",
            "start": 0,
            "end": 168,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_55@1",
            "content": "In order to examine the long-tail issue as mentioned in Section 4, we evaluated the effect of long-tail distribution by dividing classes into three groups: head, body, and tail.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_55",
            "start": 170,
            "end": 346,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_56@0",
            "content": "Thai N-NER Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_56",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_57@0",
            "content": "Table 4 shows the results on different parts of the long-tailed distribution, as well as the overall results on our dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_57",
            "start": 0,
            "end": 123,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_57@1",
            "content": "Among the three existing SOTA models, the Second-best-learning model has the highest overall performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_57",
            "start": 125,
            "end": 229,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_57@2",
            "content": "It obtains higher F1 scores on the head and body parts of the long-tail distribution, while the Pyramid model obtains the highest F1 score on the tail part.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_57",
            "start": 231,
            "end": 386,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_58@0",
            "content": "Interestingly, the deep learning baseline model, WangchanBERTa-sh, outperforms all the current SOTA models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_58",
            "start": 0,
            "end": 106,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_59@0",
            "content": "The results show that both WangchanBERTa and XLM-R, while they perform poorer on the head part of the long-tailed distribution, they perform much better on less frequent classes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_59",
            "start": 0,
            "end": 177,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_59@1",
            "content": "As shown in Table 4, the performances of WangchanBERTa models on the body and tail parts, and XLM-R models on the tail part are superior to the best SOTA model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_59",
            "start": 179,
            "end": 338,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_60@0",
            "content": "By having better performances on body and tail parts, while maintaining a competitive performance on the head part, WangchanBERTa-sh outperforms all the SOTA models on our corpus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_60",
            "start": 0,
            "end": 178,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_61@0",
            "content": "The performances of models based on the multilingual encoder (XLM-R) are superior to Pyramid and Locate and label models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_61",
            "start": 0,
            "end": 120,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_61@1",
            "content": "However, compared to the monolingual encoder (WangchanBERTa), XLM-R models' performances are only slightly poorer than the monolingual models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_61",
            "start": 122,
            "end": 263,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_61@2",
            "content": "This suggests the possibility of cross-lingual N-NER tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_61",
            "start": 265,
            "end": 323,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_61@3",
            "content": "(e.g. transferring cultural-specific named-entity knowledge from English to Thai).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_61",
            "start": 325,
            "end": 406,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_61@4",
            "content": "The long-tailed distribution of classes poses a challenge for the N-NER task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_61",
            "start": 408,
            "end": 484,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_61@5",
            "content": "The performances across all models quickly deteriorate as we move from the head part of the long-tailed distribution, which represents common classes, to the tail part, which represents infrequent classes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_61",
            "start": 486,
            "end": 690,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_61@6",
            "content": "Additionally, notice there are gaps between precision and recall for all models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_61",
            "start": 692,
            "end": 771,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_61@7",
            "content": "These gaps imply that all models have a tendency to generate false negatives more than false positives.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_61",
            "start": 773,
            "end": 875,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_61@8",
            "content": "We can also see that the precision-recall gap has a tendency to increase as we move from the head to the tail part of the distribution.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_61",
            "start": 877,
            "end": 1011,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_61@9",
            "content": "This result suggests that to improve the overall performance, we should pay attention to the recall.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_61",
            "start": 1013,
            "end": 1112,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_62@0",
            "content": "In addition, comparing to the results on English N-NER corpora, there is a performance gap for the Thai language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_62",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_62@1",
            "content": "For example, the F1 score of the Pyramid model on the NNE corpus is 94.68, while its performance on our corpus is only 78.50.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_62",
            "start": 114,
            "end": 238,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_62@2",
            "content": "For the full comparison, see Appendix A.5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_62",
            "start": 240,
            "end": 281,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_63@0",
            "content": "Error Analysis",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_63",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_64@0",
            "content": "To understand the limitation of current N-NER solutions, we investigate reoccurring mistake patterns from the WangchanBERTa-sp models used in the experimental studies.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_64",
            "start": 0,
            "end": 166,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_64@1",
            "content": "We categorize the common prediction mistakes into four groups as follows: (1) Incorrect span prediction: out of 5,165 prediction errors, 2,977 errors are from span length mismatch as shown in Figure 5. (2) Ambiguous entity mentions: mentions with higher class distribution entropy have more error rates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_64",
            "start": 168,
            "end": 470,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_64@2",
            "content": "(3) Ambiguity between fine-grained classes: there are 1,149 fewer errors when evaluated with coarse-grained ground truths.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_64",
            "start": 472,
            "end": 593,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_64@3",
            "content": "(4) Scarcity of training samples: the model only made 1,422 prediction attempts for mentions in tail classes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_64",
            "start": 595,
            "end": 703,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_64@4",
            "content": "While 1,101 of the predictions are correct, there are 3,680 ground truths.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_64",
            "start": 705,
            "end": 778,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_64@5",
            "content": "The previous section also reveals this issue via the poor recall scores in the tail part of the long-tail distribution.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_64",
            "start": 780,
            "end": 898,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_64@6",
            "content": "We provide the description of each error pattern along with examples in Appendix A.7.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_64",
            "start": 900,
            "end": 984,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_65@0",
            "content": "Summary",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_65",
            "start": 0,
            "end": 6,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_66@0",
            "content": "We present the first Thai N-NER corpus with 104 classes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_66",
            "start": 0,
            "end": 55,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_66@1",
            "content": "It has 1,272,381 words, and 264,798 mentions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_66",
            "start": 57,
            "end": 101,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_66@2",
            "content": "The size of our corpus is comparable to one of the large N-NER corpora in English.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_66",
            "start": 103,
            "end": 184,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_66@3",
            "content": "Unlike other Thai NER corpora, in addition to nested structure information, our dataset is annotated with fine-grained entity types to provide more detail of the named entities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_66",
            "start": 186,
            "end": 362,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_66@4",
            "content": "This corpus addresses the data scarcity issue for Thai NLP.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_66",
            "start": 364,
            "end": 422,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_66@5",
            "content": "In addition, it allows NLP researchers to benchmark their methods in a multilingual setting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_66",
            "start": 424,
            "end": 515,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_66@6",
            "content": "Moreover, this dataset allows researchers to explore the effect of long-tail distribution.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_66",
            "start": 517,
            "end": 606,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_66@7",
            "content": "We hope that our dataset will encourage researchers to include Thai in their benchmark and reduce the disparity between Thai and high resource languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_66",
            "start": 608,
            "end": 760,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_67@0",
            "content": "Our dataset consists of raw text data from two publicly available corpora: Prachatai-67k and Wongnai review.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_67",
            "start": 0,
            "end": 107,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_67@1",
            "content": "These corpora use public copyright licenses (LGPL and Creative Commons) that enable free distribution.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_67",
            "start": 109,
            "end": 210,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_67@2",
            "content": "The data has a minimal risk for privacy violation since all the data were published in a public space, such as a news site and a restaurant review site.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_67",
            "start": 212,
            "end": 363,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_67@3",
            "content": "All the news articles and restaurant reviews are meant to be shared publicly, not privately.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_67",
            "start": 365,
            "end": 456,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_67@4",
            "content": "Hence, the dataset does not contain any confidential information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_67",
            "start": 458,
            "end": 522,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_67@5",
            "content": "Our preprocessing step, which includes cleaning data and tokenization, does not alter the original contents of the texts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_67",
            "start": 524,
            "end": 644,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_67@6",
            "content": "On average, the annotators were compensated at least twice the local minimum wage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_67",
            "start": 646,
            "end": 727,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_67@7",
            "content": "The annotators were paid by the number of entity-mentions annotated and the number of documents that they have read.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_67",
            "start": 729,
            "end": 844,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_67@8",
            "content": "We distributed the same amount of documents for each annotator for fair consideration.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_67",
            "start": 846,
            "end": 931,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_67@9",
            "content": "This dataset addresses the data scarcity issue for Thai, which can be considered as a lower-resource language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_67",
            "start": 933,
            "end": 1042,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_67@10",
            "content": "However, this dataset only includes the central Thai dialect, which most Thai understand.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_67",
            "start": 1044,
            "end": 1132,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_67@11",
            "content": "It is also the dialect for official usage and is often used as a written language by Thai users.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_67",
            "start": 1134,
            "end": 1229,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_67@12",
            "content": "It reduces the language technology disparity gap between Thai and high-resource languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_67",
            "start": 1231,
            "end": 1320,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_67@13",
            "content": "In addition, it can facilitate researchers and the NLP community to investigate the N-NER task in a multilingual setting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_67",
            "start": 1322,
            "end": 1442,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_67@14",
            "content": "We will open-source the dataset and distribute it publicly under the CC by SA 3.0 license.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_67",
            "start": 1444,
            "end": 1533,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_67@15",
            "content": "We will also publish the source code and all the models' weights from our experiments to assist the NLP community in N-NER research and reduce unnecessary energy usage from training the models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_67",
            "start": 1535,
            "end": 1727,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_68@0",
            "content": "For all the deep learning baselines, we use the following parameter configuration: We employ Adam optimizer with a learning rate of 1e-5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_68",
            "start": 0,
            "end": 136,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_68@1",
            "content": "We utilize a learning rate decay scheduler that reduces the learning rate every 50 epochs by multiplying the decay factor of 0.1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_68",
            "start": 138,
            "end": 266,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_68@2",
            "content": "The maximum training epoch is 500, and we early stop if there is no improvement for 16 epochs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_68",
            "start": 268,
            "end": 361,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_69@0",
            "content": "For the Locate and Label model, we made further modifications to the model to use it for the Thai language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_69",
            "start": 0,
            "end": 106,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_69@1",
            "content": "Unlike the original work, the sequence length limitation of WangchanBERTa is lower than BERT-large version (Devlin et al., 2019), we use only ten words from each neighboring sentence as the context words to keep the input sequence length within the limitation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_69",
            "start": 108,
            "end": 367,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_69@2",
            "content": "In addition, apart from contextualized word embeddings, Locate and Labels also includes static word embeddings-GloVE.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_69",
            "start": 369,
            "end": 485,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_69@3",
            "content": "We replace the GloVE word embeddings with the static word embeddings layer of thai2fit (Polpanumas and Phatthiyaphaibun, 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_69",
            "start": 487,
            "end": 613,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_69@4",
            "content": "thai2fit was trained on wisesightsentiment 7 , prachathai-64k 8 , and TH-wikipedia 9 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_69",
            "start": 615,
            "end": 700,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_70@0",
            "content": "Table 5 compares the WangchanBERTa-sh model's performances between the coarse-grained and fine-grained ground truths.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_70",
            "start": 0,
            "end": 116,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_70@1",
            "content": "We converted finegrained labels to their respective coarse-grained labels to examine the negative effect from the ambiguity between fine-grained classes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_70",
            "start": 118,
            "end": 270,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_70@2",
            "content": "Table 5 shows that there is a small gap between coarsegrained and fine-grained evaluations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_70",
            "start": 272,
            "end": 362,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_70@3",
            "content": "It suggests that adding fine-grained information to the dataset does not introduce a major challenge for N-NER models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_70",
            "start": 364,
            "end": 481,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_70@4",
            "content": "Nevertheless, errors from ambiguity between fine-grained classes still constitute a considerable amount of models' prediction errors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_70",
            "start": 483,
            "end": 615,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_71@0",
            "content": "Similar to a morphological parse tree, a nested entity annotation structure does not allow overlapping between entities in the same depth level.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_71",
            "start": 0,
            "end": 143,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_71@1",
            "content": "For example, in Figure 6, \u0e23\u0e2d\u0e07\u0e42\u0e06\u0e29\u0e01\u0e1b\u0e23\u0e30\u0e08\u0e4d \u0e32 \u0e2a\u0e4d \u0e32\u0e19\u0e31 \u0e01\u0e19\u0e32\u0e22\u0e01\u0e23\u0e31 \u0e10\u0e21\u0e19\u0e15\u0e23\u0e35 (rO:\u014b k h o:s\u00f2k pr\u00e0tCam s\u01cemn\u00e1k.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_71",
            "start": 145,
            "end": 238,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_71@2",
            "content": "Table 6: The performances of the recent SOTA N-NER models on English datasets, we include the performances from their original papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_71",
            "start": 240,
            "end": 373,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_72@0",
            "content": "CoNLL: we format our dataset according to the CoNLL schema, then calculate the Cohen's Kappa by comparing agreements of annotated entities layer by layer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_72",
            "start": 0,
            "end": 153,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_72@1",
            "content": "The CoNLL schema takes the mention's token length into account.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_72",
            "start": 155,
            "end": 217,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_72@2",
            "content": "For each disagreed mention, we count each disagreed token as one disagreement.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_72",
            "start": 219,
            "end": 296,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_72@3",
            "content": "Therefore, mentions with more token length may have more disagreement counts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_72",
            "start": 298,
            "end": 374,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_72@4",
            "content": "In addition, if there is a mismatch within the same layer, we count it as a disagreement even though the annotations might agree if we were to compare them from different layers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_72",
            "start": 376,
            "end": 553,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_72@5",
            "content": "Pyramidal: we format the labels in a pyramidal manner, where we generate all possible n-gram entity span candidates for each text sequence and assign them to layers according to their lengths in the same fashion as the Pyramid model (Wang et al., 2020a).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_72",
            "start": 555,
            "end": 808,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_72@6",
            "content": "Then we compare agreements of annotated candidates between the two annotated data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_72",
            "start": 810,
            "end": 891,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_72@7",
            "content": "We calculated the score on both character level and token level, and found no difference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_72",
            "start": 893,
            "end": 981,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_72@8",
            "content": "We report the score on the token level.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_72",
            "start": 983,
            "end": 1021,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_72@9",
            "content": "Pyramidal scheme counts each disagreed mention as one disagreement despite its length.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_72",
            "start": 1023,
            "end": 1108,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_72@10",
            "content": "Since Thai has no word boundary, the pyramid scheme always provides a consistent score despite using it on a different word segmentation that varies the token length.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_72",
            "start": 1110,
            "end": 1275,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_73@0",
            "content": "This study compares the performances of the N-NER models between Thai and English N-NER datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_73",
            "start": 0,
            "end": 96,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_73@1",
            "content": "Table 4 shows the results on the Thai N-NER dataset, and Table 6 shows the results on English N-NER datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_73",
            "start": 98,
            "end": 206,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_73@2",
            "content": "We can see that, when compared to the English results, all N-NER models performed poorer on the Thai dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_73",
            "start": 208,
            "end": 316,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_73@3",
            "content": "For example, the F1-score of Pyramid on the NNE dataset (the most similar dataset compared to our work) is 94.68%, while the overall F1-score of Pyramid for Thai N-NER is only 78.50%.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_73",
            "start": 318,
            "end": 500,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_73@4",
            "content": "Although both datasets are similar in size, design, and diversity of entity classes, the performance gap is 16.18%.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_73",
            "start": 502,
            "end": 616,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_73@5",
            "content": "Experimental results verify that there is a performance gap between Thai and English N-NER.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_73",
            "start": 618,
            "end": 708,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_73@6",
            "content": "Furthermore, some model is based on the BERTlarge model, but Thai has only one BERT-based pretrained model which is based on RoBERTa (WangchanBERTa).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_73",
            "start": 710,
            "end": 858,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_73@7",
            "content": "This may have a direct affect on the performance gap.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_73",
            "start": 860,
            "end": 912,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_73@8",
            "content": "For example, the Locate and Label is based on the BERT-large model\u037e replacing BERT-large with WangchanBERTa can effect the performance directly.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_73",
            "start": 914,
            "end": 1057,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_73@9",
            "content": "Despite having the best performances across multiple English N-NER datasets, Locate and Label has the lowest score on the Thai N-NER dataset when compared to other SOTA models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_73",
            "start": 1059,
            "end": 1234,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_74@0",
            "content": "Table 7 shows the mention frequency of each finegrained entity type in our corpus before the traintest split.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_74",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_74@1",
            "content": "For each nested structure, we count all annotated mentions, not just the outermost mention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_74",
            "start": 110,
            "end": 200,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_74@2",
            "content": "This table reveals classes with extremely low frequency which contribute to poor performances on the tail part of the long-tailed distribution.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_74",
            "start": 202,
            "end": 344,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_75@0",
            "content": "Incorrect span prediction: mismatches between the length of the predicted spans and the ground truths contribute to a large chunk of prediction errors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_75",
            "start": 0,
            "end": 150,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_76@0",
            "content": "Figure 5 shows that out of 48,009 predicted mentions, 5,165 are incorrect.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_76",
            "start": 0,
            "end": 73,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_76@1",
            "content": "2,977 out of 5,165 incorrect predicted mentions are due to the fact that the positions of the predicted spans are not correctly aligned with the positions of the ground truths.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_76",
            "start": 75,
            "end": 250,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_76@2",
            "content": "Often, we can find this error in the predictions for entity mentions that are very long.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_76",
            "start": 252,
            "end": 339,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_76@3",
            "content": "For example, consider the following text segment:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_76",
            "start": 341,
            "end": 389,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_77@0",
            "content": "(1) \u0e2d\u0e32\u0e04\u0e32\u0e23 Pa:ka:n. building \u0e23\u0e31 \u0e10\u0e1b\u0e23\u0e30\u0e28\u0e32\u0e2a\u0e19\u0e20\u0e31 \u0e01\u0e14\u0e35 r\u00e1tt h \u00e0pr\u00e0s\u00e0:ts\u00e0n\u00e1p h \u00e1kdi: Ratthaprasatsanaphakdi",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_77",
            "start": 0,
            "end": 96,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_78@0",
            "content": "Wirote Aroonmanakun, Collocation and thai word segmentation, 2002, Proc. SNLP and Oriental CO-COSDA Workshop, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_78",
            "start": 0,
            "end": 110,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_79@0",
            "content": "Darina Benikova, Chris Biemann, Marc Reznicek, NoSta-D named entity annotation for German: Guidelines and dataset, 2014, Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC'14), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_79",
            "start": 0,
            "end": 219,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_80@0",
            "content": "UNKNOWN, None, 2020, , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_80",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_81@0",
            "content": ", Syllable-based neural Thai word segmentation, , Proceedings of the 28th International Conference on Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_81",
            "start": 0,
            "end": 129,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_82@0",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long and Short Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_82",
            "start": 0,
            "end": 315,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_83@0",
            "content": "George Doddington, Alexis Mitchell, Mark Przybocki, Lance Ramshaw, Stephanie Strassel, Ralph Weischedel, The automatic content extraction (ACE) program -tasks, data, and evaluation, 2004, Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC'04), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_83",
            "start": 0,
            "end": 287,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_84@0",
            "content": "Minh Nguyen Thi,  Huyen,  Vu Xuan,  Luong, VLSP 2016 shared task: Named entity recognition, 2016, Proceedings of Vietnamese Speech and Language Processing, VLSP.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_84",
            "start": 0,
            "end": 160,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_85@0",
            "content": "J-D Kim, Tomoko Ohta, Yuka Tateisi, Jun'ichi Tsujii, Genia corpus-a semantically annotated corpus for bio-textmining, 2003, Bioinformatics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_85",
            "start": 0,
            "end": 140,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_86@0",
            "content": "Hongyu Lin, Yaojie Lu, Xianpei Han, Le Sun, Sequence-to-nuggets: Nested entity mention detection via anchor-region networks, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_86",
            "start": 0,
            "end": 261,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_87@0",
            "content": "UNKNOWN, None, 2021, Wangchanberta: Pretraining transformer-based thai language models. arXiv e-prints, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_87",
            "start": 0,
            "end": 104,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_88@0",
            "content": "Ying Luo, Hai Zhao, Bipartite flat-graph network for nested named entity recognition, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_88",
            "start": 0,
            "end": 181,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_89@0",
            "content": "Nhat Pham Quang,  Minh, A feature-based model for nested named-entity recognition at vlsp-2018 ner evaluation campaign, 2018, Journal of Computer Science and Cybernetics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_89",
            "start": 0,
            "end": 171,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_90@0",
            "content": "T Huyen, Quyen Nguyen,  Ngo, X Luong,  Vu, M Vu, Hien Tt Tran,  Nguyen, Vlsp shared task: Named entity recognition, 2018, Journal of Computer Science and Cybernetics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_90",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_91@0",
            "content": "UNKNOWN, None, 2016, PyThaiNLP: Thai Natural Language Processing in Python, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_91",
            "start": 0,
            "end": 76,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_92@0",
            "content": "Barbara Plank, Kristian Jensen, Rob Van Der Goot, DaN+: Danish nested named entities and lexical normalization, 2020, Proceedings of the 28th International Conference on Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_92",
            "start": 0,
            "end": 197,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_93@0",
            "content": "UNKNOWN, None, , Charin Polpanumas and Wannaphong Phatthiyaphaibun. 2021. thai2fit: Thai language implementation of ulmfit, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_93",
            "start": 0,
            "end": 124,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_94@0",
            "content": "Nicky Ringland, Xiang Dai, Ben Hachey, Sarvnaz Karimi, Cecile Paris, James Curran, NNE: A dataset for nested named entity recognition in English newswire, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_94",
            "start": 0,
            "end": 250,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_95@0",
            "content": "Yongliang Shen, Xinyin Ma, Zeqi Tan, Shuai Zhang, Wen Wang, Weiming Lu, Locate and label: A two-stage identifier for nested named entity recognition, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_95",
            "start": 0,
            "end": 331,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_96@0",
            "content": "UNKNOWN, None, 2020, Nested named entity recognition via second-best sequence learning and decoding. Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_96",
            "start": 0,
            "end": 164,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_97@0",
            "content": "Jana Strakov\u00e1, Milan Straka, Neural architectures for nested ner through linearization, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_97",
            "start": 0,
            "end": 183,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_98@0",
            "content": "Jana Strakov\u00e1, Milan Straka, Neural architectures for nested NER through linearization, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_98",
            "start": 0,
            "end": 224,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_99@0",
            "content": "Erik Tjong, Kim Sang, Fien De Meulder, Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition, 2003, Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_99",
            "start": 0,
            "end": 222,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_100@0",
            "content": "UNKNOWN, None, 2006, ACE 2005 Multilingual Training Corpus LDC2006T06, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_100",
            "start": 0,
            "end": 71,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_101@0",
            "content": "Jue Wang, Lidan Shou, Ke Chen, Gang Chen, Pyramid: A layered model for nested named entity recognition, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_101",
            "start": 0,
            "end": 248,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_102@0",
            "content": "Yu Wang, Yun Li, Hanghang Tong, Ziye Zhu, HIT: Nested named entity recognition via head-tail pair and token interaction, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_102",
            "start": 0,
            "end": 223,
            "label": {}
        },
        {
            "ix": "55-ARR_v1_103@0",
            "content": "Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, Yuji Matsumoto, LUKE: Deep contextualized entity representations with entityaware self-attention, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "55-ARR_v1_103",
            "start": 0,
            "end": 300,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "55-ARR_v1_0",
            "tgt_ix": "55-ARR_v1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_0",
            "tgt_ix": "55-ARR_v1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_1",
            "tgt_ix": "55-ARR_v1_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_1",
            "tgt_ix": "55-ARR_v1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_0",
            "tgt_ix": "55-ARR_v1_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_2",
            "tgt_ix": "55-ARR_v1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_4",
            "tgt_ix": "55-ARR_v1_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_5",
            "tgt_ix": "55-ARR_v1_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_6",
            "tgt_ix": "55-ARR_v1_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_7",
            "tgt_ix": "55-ARR_v1_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_8",
            "tgt_ix": "55-ARR_v1_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_9",
            "tgt_ix": "55-ARR_v1_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_10",
            "tgt_ix": "55-ARR_v1_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_3",
            "tgt_ix": "55-ARR_v1_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_3",
            "tgt_ix": "55-ARR_v1_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_3",
            "tgt_ix": "55-ARR_v1_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_3",
            "tgt_ix": "55-ARR_v1_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_3",
            "tgt_ix": "55-ARR_v1_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_3",
            "tgt_ix": "55-ARR_v1_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_3",
            "tgt_ix": "55-ARR_v1_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_3",
            "tgt_ix": "55-ARR_v1_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_3",
            "tgt_ix": "55-ARR_v1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_0",
            "tgt_ix": "55-ARR_v1_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_13",
            "tgt_ix": "55-ARR_v1_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_14",
            "tgt_ix": "55-ARR_v1_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_12",
            "tgt_ix": "55-ARR_v1_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_12",
            "tgt_ix": "55-ARR_v1_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_12",
            "tgt_ix": "55-ARR_v1_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_12",
            "tgt_ix": "55-ARR_v1_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_0",
            "tgt_ix": "55-ARR_v1_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_15",
            "tgt_ix": "55-ARR_v1_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_17",
            "tgt_ix": "55-ARR_v1_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_16",
            "tgt_ix": "55-ARR_v1_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_16",
            "tgt_ix": "55-ARR_v1_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_16",
            "tgt_ix": "55-ARR_v1_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_16",
            "tgt_ix": "55-ARR_v1_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_18",
            "tgt_ix": "55-ARR_v1_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_20",
            "tgt_ix": "55-ARR_v1_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_21",
            "tgt_ix": "55-ARR_v1_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_19",
            "tgt_ix": "55-ARR_v1_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_19",
            "tgt_ix": "55-ARR_v1_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_19",
            "tgt_ix": "55-ARR_v1_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_19",
            "tgt_ix": "55-ARR_v1_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_16",
            "tgt_ix": "55-ARR_v1_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_22",
            "tgt_ix": "55-ARR_v1_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_24",
            "tgt_ix": "55-ARR_v1_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_25",
            "tgt_ix": "55-ARR_v1_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_23",
            "tgt_ix": "55-ARR_v1_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_23",
            "tgt_ix": "55-ARR_v1_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_23",
            "tgt_ix": "55-ARR_v1_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_23",
            "tgt_ix": "55-ARR_v1_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_16",
            "tgt_ix": "55-ARR_v1_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_26",
            "tgt_ix": "55-ARR_v1_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_27",
            "tgt_ix": "55-ARR_v1_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_27",
            "tgt_ix": "55-ARR_v1_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_16",
            "tgt_ix": "55-ARR_v1_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_28",
            "tgt_ix": "55-ARR_v1_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_29",
            "tgt_ix": "55-ARR_v1_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_29",
            "tgt_ix": "55-ARR_v1_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_16",
            "tgt_ix": "55-ARR_v1_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_30",
            "tgt_ix": "55-ARR_v1_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_32",
            "tgt_ix": "55-ARR_v1_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_33",
            "tgt_ix": "55-ARR_v1_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_34",
            "tgt_ix": "55-ARR_v1_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_35",
            "tgt_ix": "55-ARR_v1_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_36",
            "tgt_ix": "55-ARR_v1_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_37",
            "tgt_ix": "55-ARR_v1_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_31",
            "tgt_ix": "55-ARR_v1_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_31",
            "tgt_ix": "55-ARR_v1_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_31",
            "tgt_ix": "55-ARR_v1_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_31",
            "tgt_ix": "55-ARR_v1_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_31",
            "tgt_ix": "55-ARR_v1_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_31",
            "tgt_ix": "55-ARR_v1_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_31",
            "tgt_ix": "55-ARR_v1_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_31",
            "tgt_ix": "55-ARR_v1_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_16",
            "tgt_ix": "55-ARR_v1_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_39",
            "tgt_ix": "55-ARR_v1_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_39",
            "tgt_ix": "55-ARR_v1_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_0",
            "tgt_ix": "55-ARR_v1_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_40",
            "tgt_ix": "55-ARR_v1_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_42",
            "tgt_ix": "55-ARR_v1_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_43",
            "tgt_ix": "55-ARR_v1_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_41",
            "tgt_ix": "55-ARR_v1_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_41",
            "tgt_ix": "55-ARR_v1_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_41",
            "tgt_ix": "55-ARR_v1_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_41",
            "tgt_ix": "55-ARR_v1_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_0",
            "tgt_ix": "55-ARR_v1_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_44",
            "tgt_ix": "55-ARR_v1_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_45",
            "tgt_ix": "55-ARR_v1_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_45",
            "tgt_ix": "55-ARR_v1_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_45",
            "tgt_ix": "55-ARR_v1_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_46",
            "tgt_ix": "55-ARR_v1_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_48",
            "tgt_ix": "55-ARR_v1_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_49",
            "tgt_ix": "55-ARR_v1_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_50",
            "tgt_ix": "55-ARR_v1_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_51",
            "tgt_ix": "55-ARR_v1_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_52",
            "tgt_ix": "55-ARR_v1_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_47",
            "tgt_ix": "55-ARR_v1_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_47",
            "tgt_ix": "55-ARR_v1_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_47",
            "tgt_ix": "55-ARR_v1_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_47",
            "tgt_ix": "55-ARR_v1_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_47",
            "tgt_ix": "55-ARR_v1_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_47",
            "tgt_ix": "55-ARR_v1_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_47",
            "tgt_ix": "55-ARR_v1_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_45",
            "tgt_ix": "55-ARR_v1_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_53",
            "tgt_ix": "55-ARR_v1_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_54",
            "tgt_ix": "55-ARR_v1_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_54",
            "tgt_ix": "55-ARR_v1_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_45",
            "tgt_ix": "55-ARR_v1_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_55",
            "tgt_ix": "55-ARR_v1_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_57",
            "tgt_ix": "55-ARR_v1_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_58",
            "tgt_ix": "55-ARR_v1_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_59",
            "tgt_ix": "55-ARR_v1_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_60",
            "tgt_ix": "55-ARR_v1_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_61",
            "tgt_ix": "55-ARR_v1_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_56",
            "tgt_ix": "55-ARR_v1_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_56",
            "tgt_ix": "55-ARR_v1_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_56",
            "tgt_ix": "55-ARR_v1_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_56",
            "tgt_ix": "55-ARR_v1_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_56",
            "tgt_ix": "55-ARR_v1_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_56",
            "tgt_ix": "55-ARR_v1_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_56",
            "tgt_ix": "55-ARR_v1_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_0",
            "tgt_ix": "55-ARR_v1_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_62",
            "tgt_ix": "55-ARR_v1_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_63",
            "tgt_ix": "55-ARR_v1_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_63",
            "tgt_ix": "55-ARR_v1_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_0",
            "tgt_ix": "55-ARR_v1_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_64",
            "tgt_ix": "55-ARR_v1_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_65",
            "tgt_ix": "55-ARR_v1_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_65",
            "tgt_ix": "55-ARR_v1_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_65",
            "tgt_ix": "55-ARR_v1_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_66",
            "tgt_ix": "55-ARR_v1_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_68",
            "tgt_ix": "55-ARR_v1_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_65",
            "tgt_ix": "55-ARR_v1_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_65",
            "tgt_ix": "55-ARR_v1_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_67",
            "tgt_ix": "55-ARR_v1_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_65",
            "tgt_ix": "55-ARR_v1_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_69",
            "tgt_ix": "55-ARR_v1_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_65",
            "tgt_ix": "55-ARR_v1_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_70",
            "tgt_ix": "55-ARR_v1_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_65",
            "tgt_ix": "55-ARR_v1_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_71",
            "tgt_ix": "55-ARR_v1_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_65",
            "tgt_ix": "55-ARR_v1_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_72",
            "tgt_ix": "55-ARR_v1_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_65",
            "tgt_ix": "55-ARR_v1_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_73",
            "tgt_ix": "55-ARR_v1_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_75",
            "tgt_ix": "55-ARR_v1_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_76",
            "tgt_ix": "55-ARR_v1_77",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_65",
            "tgt_ix": "55-ARR_v1_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_65",
            "tgt_ix": "55-ARR_v1_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_65",
            "tgt_ix": "55-ARR_v1_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_74",
            "tgt_ix": "55-ARR_v1_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "55-ARR_v1_0",
            "tgt_ix": "55-ARR_v1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_1",
            "tgt_ix": "55-ARR_v1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_2",
            "tgt_ix": "55-ARR_v1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_2",
            "tgt_ix": "55-ARR_v1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_2",
            "tgt_ix": "55-ARR_v1_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_2",
            "tgt_ix": "55-ARR_v1_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_2",
            "tgt_ix": "55-ARR_v1_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_2",
            "tgt_ix": "55-ARR_v1_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_2",
            "tgt_ix": "55-ARR_v1_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_2",
            "tgt_ix": "55-ARR_v1_2@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_3",
            "tgt_ix": "55-ARR_v1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_4",
            "tgt_ix": "55-ARR_v1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_4",
            "tgt_ix": "55-ARR_v1_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_4",
            "tgt_ix": "55-ARR_v1_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_4",
            "tgt_ix": "55-ARR_v1_4@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_5",
            "tgt_ix": "55-ARR_v1_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_5",
            "tgt_ix": "55-ARR_v1_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_5",
            "tgt_ix": "55-ARR_v1_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_5",
            "tgt_ix": "55-ARR_v1_5@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_5",
            "tgt_ix": "55-ARR_v1_5@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_5",
            "tgt_ix": "55-ARR_v1_5@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_6",
            "tgt_ix": "55-ARR_v1_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_6",
            "tgt_ix": "55-ARR_v1_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_7",
            "tgt_ix": "55-ARR_v1_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_7",
            "tgt_ix": "55-ARR_v1_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_7",
            "tgt_ix": "55-ARR_v1_7@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_7",
            "tgt_ix": "55-ARR_v1_7@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_8",
            "tgt_ix": "55-ARR_v1_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_8",
            "tgt_ix": "55-ARR_v1_8@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_8",
            "tgt_ix": "55-ARR_v1_8@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_8",
            "tgt_ix": "55-ARR_v1_8@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_9",
            "tgt_ix": "55-ARR_v1_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_9",
            "tgt_ix": "55-ARR_v1_9@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_9",
            "tgt_ix": "55-ARR_v1_9@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_9",
            "tgt_ix": "55-ARR_v1_9@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_9",
            "tgt_ix": "55-ARR_v1_9@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_9",
            "tgt_ix": "55-ARR_v1_9@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_9",
            "tgt_ix": "55-ARR_v1_9@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_9",
            "tgt_ix": "55-ARR_v1_9@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_10",
            "tgt_ix": "55-ARR_v1_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_11",
            "tgt_ix": "55-ARR_v1_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_12",
            "tgt_ix": "55-ARR_v1_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_13",
            "tgt_ix": "55-ARR_v1_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_13",
            "tgt_ix": "55-ARR_v1_13@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_14",
            "tgt_ix": "55-ARR_v1_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_14",
            "tgt_ix": "55-ARR_v1_14@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_14",
            "tgt_ix": "55-ARR_v1_14@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_14",
            "tgt_ix": "55-ARR_v1_14@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_14",
            "tgt_ix": "55-ARR_v1_14@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_14",
            "tgt_ix": "55-ARR_v1_14@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_14",
            "tgt_ix": "55-ARR_v1_14@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_14",
            "tgt_ix": "55-ARR_v1_14@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_15",
            "tgt_ix": "55-ARR_v1_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_15",
            "tgt_ix": "55-ARR_v1_15@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_15",
            "tgt_ix": "55-ARR_v1_15@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_15",
            "tgt_ix": "55-ARR_v1_15@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_15",
            "tgt_ix": "55-ARR_v1_15@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_15",
            "tgt_ix": "55-ARR_v1_15@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_15",
            "tgt_ix": "55-ARR_v1_15@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_15",
            "tgt_ix": "55-ARR_v1_15@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_15",
            "tgt_ix": "55-ARR_v1_15@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_15",
            "tgt_ix": "55-ARR_v1_15@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_16",
            "tgt_ix": "55-ARR_v1_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_17",
            "tgt_ix": "55-ARR_v1_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_18",
            "tgt_ix": "55-ARR_v1_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_18",
            "tgt_ix": "55-ARR_v1_18@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_19",
            "tgt_ix": "55-ARR_v1_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_20",
            "tgt_ix": "55-ARR_v1_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_20",
            "tgt_ix": "55-ARR_v1_20@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_21",
            "tgt_ix": "55-ARR_v1_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_21",
            "tgt_ix": "55-ARR_v1_21@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_21",
            "tgt_ix": "55-ARR_v1_21@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_21",
            "tgt_ix": "55-ARR_v1_21@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_21",
            "tgt_ix": "55-ARR_v1_21@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_21",
            "tgt_ix": "55-ARR_v1_21@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_22",
            "tgt_ix": "55-ARR_v1_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_22",
            "tgt_ix": "55-ARR_v1_22@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_22",
            "tgt_ix": "55-ARR_v1_22@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_22",
            "tgt_ix": "55-ARR_v1_22@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_22",
            "tgt_ix": "55-ARR_v1_22@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_23",
            "tgt_ix": "55-ARR_v1_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_24",
            "tgt_ix": "55-ARR_v1_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_24",
            "tgt_ix": "55-ARR_v1_24@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_24",
            "tgt_ix": "55-ARR_v1_24@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_24",
            "tgt_ix": "55-ARR_v1_24@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_24",
            "tgt_ix": "55-ARR_v1_24@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_24",
            "tgt_ix": "55-ARR_v1_24@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_24",
            "tgt_ix": "55-ARR_v1_24@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_24",
            "tgt_ix": "55-ARR_v1_24@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_25",
            "tgt_ix": "55-ARR_v1_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_25",
            "tgt_ix": "55-ARR_v1_25@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_25",
            "tgt_ix": "55-ARR_v1_25@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_26",
            "tgt_ix": "55-ARR_v1_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_26",
            "tgt_ix": "55-ARR_v1_26@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_26",
            "tgt_ix": "55-ARR_v1_26@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_26",
            "tgt_ix": "55-ARR_v1_26@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_26",
            "tgt_ix": "55-ARR_v1_26@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_26",
            "tgt_ix": "55-ARR_v1_26@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_26",
            "tgt_ix": "55-ARR_v1_26@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_26",
            "tgt_ix": "55-ARR_v1_26@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_27",
            "tgt_ix": "55-ARR_v1_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_28",
            "tgt_ix": "55-ARR_v1_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_28",
            "tgt_ix": "55-ARR_v1_28@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_29",
            "tgt_ix": "55-ARR_v1_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_30",
            "tgt_ix": "55-ARR_v1_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_30",
            "tgt_ix": "55-ARR_v1_30@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_30",
            "tgt_ix": "55-ARR_v1_30@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_30",
            "tgt_ix": "55-ARR_v1_30@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_31",
            "tgt_ix": "55-ARR_v1_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_32",
            "tgt_ix": "55-ARR_v1_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_32",
            "tgt_ix": "55-ARR_v1_32@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_32",
            "tgt_ix": "55-ARR_v1_32@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_32",
            "tgt_ix": "55-ARR_v1_32@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_32",
            "tgt_ix": "55-ARR_v1_32@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_32",
            "tgt_ix": "55-ARR_v1_32@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_33",
            "tgt_ix": "55-ARR_v1_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_33",
            "tgt_ix": "55-ARR_v1_33@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_33",
            "tgt_ix": "55-ARR_v1_33@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_34",
            "tgt_ix": "55-ARR_v1_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_34",
            "tgt_ix": "55-ARR_v1_34@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_35",
            "tgt_ix": "55-ARR_v1_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_36",
            "tgt_ix": "55-ARR_v1_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_36",
            "tgt_ix": "55-ARR_v1_36@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_37",
            "tgt_ix": "55-ARR_v1_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_37",
            "tgt_ix": "55-ARR_v1_37@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_37",
            "tgt_ix": "55-ARR_v1_37@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_37",
            "tgt_ix": "55-ARR_v1_37@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_38",
            "tgt_ix": "55-ARR_v1_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_39",
            "tgt_ix": "55-ARR_v1_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_40",
            "tgt_ix": "55-ARR_v1_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_40",
            "tgt_ix": "55-ARR_v1_40@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_40",
            "tgt_ix": "55-ARR_v1_40@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_40",
            "tgt_ix": "55-ARR_v1_40@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_41",
            "tgt_ix": "55-ARR_v1_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_42",
            "tgt_ix": "55-ARR_v1_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_42",
            "tgt_ix": "55-ARR_v1_42@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_42",
            "tgt_ix": "55-ARR_v1_42@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_42",
            "tgt_ix": "55-ARR_v1_42@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_42",
            "tgt_ix": "55-ARR_v1_42@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_42",
            "tgt_ix": "55-ARR_v1_42@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_43",
            "tgt_ix": "55-ARR_v1_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_43",
            "tgt_ix": "55-ARR_v1_43@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_43",
            "tgt_ix": "55-ARR_v1_43@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_44",
            "tgt_ix": "55-ARR_v1_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_44",
            "tgt_ix": "55-ARR_v1_44@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_44",
            "tgt_ix": "55-ARR_v1_44@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_44",
            "tgt_ix": "55-ARR_v1_44@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_45",
            "tgt_ix": "55-ARR_v1_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_46",
            "tgt_ix": "55-ARR_v1_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_46",
            "tgt_ix": "55-ARR_v1_46@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_46",
            "tgt_ix": "55-ARR_v1_46@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_46",
            "tgt_ix": "55-ARR_v1_46@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_46",
            "tgt_ix": "55-ARR_v1_46@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_47",
            "tgt_ix": "55-ARR_v1_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_48",
            "tgt_ix": "55-ARR_v1_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_48",
            "tgt_ix": "55-ARR_v1_48@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_48",
            "tgt_ix": "55-ARR_v1_48@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_48",
            "tgt_ix": "55-ARR_v1_48@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_48",
            "tgt_ix": "55-ARR_v1_48@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_49",
            "tgt_ix": "55-ARR_v1_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_49",
            "tgt_ix": "55-ARR_v1_49@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_49",
            "tgt_ix": "55-ARR_v1_49@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_50",
            "tgt_ix": "55-ARR_v1_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_50",
            "tgt_ix": "55-ARR_v1_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_50",
            "tgt_ix": "55-ARR_v1_50@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_50",
            "tgt_ix": "55-ARR_v1_50@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_50",
            "tgt_ix": "55-ARR_v1_50@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_50",
            "tgt_ix": "55-ARR_v1_50@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_50",
            "tgt_ix": "55-ARR_v1_50@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_51",
            "tgt_ix": "55-ARR_v1_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_51",
            "tgt_ix": "55-ARR_v1_51@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_51",
            "tgt_ix": "55-ARR_v1_51@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_51",
            "tgt_ix": "55-ARR_v1_51@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_51",
            "tgt_ix": "55-ARR_v1_51@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_52",
            "tgt_ix": "55-ARR_v1_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_52",
            "tgt_ix": "55-ARR_v1_52@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_53",
            "tgt_ix": "55-ARR_v1_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_53",
            "tgt_ix": "55-ARR_v1_53@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_54",
            "tgt_ix": "55-ARR_v1_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_55",
            "tgt_ix": "55-ARR_v1_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_55",
            "tgt_ix": "55-ARR_v1_55@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_56",
            "tgt_ix": "55-ARR_v1_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_57",
            "tgt_ix": "55-ARR_v1_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_57",
            "tgt_ix": "55-ARR_v1_57@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_57",
            "tgt_ix": "55-ARR_v1_57@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_58",
            "tgt_ix": "55-ARR_v1_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_59",
            "tgt_ix": "55-ARR_v1_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_59",
            "tgt_ix": "55-ARR_v1_59@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_60",
            "tgt_ix": "55-ARR_v1_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_61",
            "tgt_ix": "55-ARR_v1_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_61",
            "tgt_ix": "55-ARR_v1_61@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_61",
            "tgt_ix": "55-ARR_v1_61@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_61",
            "tgt_ix": "55-ARR_v1_61@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_61",
            "tgt_ix": "55-ARR_v1_61@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_61",
            "tgt_ix": "55-ARR_v1_61@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_61",
            "tgt_ix": "55-ARR_v1_61@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_61",
            "tgt_ix": "55-ARR_v1_61@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_61",
            "tgt_ix": "55-ARR_v1_61@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_61",
            "tgt_ix": "55-ARR_v1_61@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_62",
            "tgt_ix": "55-ARR_v1_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_62",
            "tgt_ix": "55-ARR_v1_62@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_62",
            "tgt_ix": "55-ARR_v1_62@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_63",
            "tgt_ix": "55-ARR_v1_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_64",
            "tgt_ix": "55-ARR_v1_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_64",
            "tgt_ix": "55-ARR_v1_64@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_64",
            "tgt_ix": "55-ARR_v1_64@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_64",
            "tgt_ix": "55-ARR_v1_64@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_64",
            "tgt_ix": "55-ARR_v1_64@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_64",
            "tgt_ix": "55-ARR_v1_64@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_64",
            "tgt_ix": "55-ARR_v1_64@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_65",
            "tgt_ix": "55-ARR_v1_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_66",
            "tgt_ix": "55-ARR_v1_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_66",
            "tgt_ix": "55-ARR_v1_66@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_66",
            "tgt_ix": "55-ARR_v1_66@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_66",
            "tgt_ix": "55-ARR_v1_66@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_66",
            "tgt_ix": "55-ARR_v1_66@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_66",
            "tgt_ix": "55-ARR_v1_66@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_66",
            "tgt_ix": "55-ARR_v1_66@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_66",
            "tgt_ix": "55-ARR_v1_66@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_67",
            "tgt_ix": "55-ARR_v1_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_67",
            "tgt_ix": "55-ARR_v1_67@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_67",
            "tgt_ix": "55-ARR_v1_67@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_67",
            "tgt_ix": "55-ARR_v1_67@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_67",
            "tgt_ix": "55-ARR_v1_67@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_67",
            "tgt_ix": "55-ARR_v1_67@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_67",
            "tgt_ix": "55-ARR_v1_67@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_67",
            "tgt_ix": "55-ARR_v1_67@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_67",
            "tgt_ix": "55-ARR_v1_67@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_67",
            "tgt_ix": "55-ARR_v1_67@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_67",
            "tgt_ix": "55-ARR_v1_67@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_67",
            "tgt_ix": "55-ARR_v1_67@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_67",
            "tgt_ix": "55-ARR_v1_67@12",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_67",
            "tgt_ix": "55-ARR_v1_67@13",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_67",
            "tgt_ix": "55-ARR_v1_67@14",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_67",
            "tgt_ix": "55-ARR_v1_67@15",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_68",
            "tgt_ix": "55-ARR_v1_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_68",
            "tgt_ix": "55-ARR_v1_68@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_68",
            "tgt_ix": "55-ARR_v1_68@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_69",
            "tgt_ix": "55-ARR_v1_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_69",
            "tgt_ix": "55-ARR_v1_69@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_69",
            "tgt_ix": "55-ARR_v1_69@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_69",
            "tgt_ix": "55-ARR_v1_69@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_69",
            "tgt_ix": "55-ARR_v1_69@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_70",
            "tgt_ix": "55-ARR_v1_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_70",
            "tgt_ix": "55-ARR_v1_70@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_70",
            "tgt_ix": "55-ARR_v1_70@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_70",
            "tgt_ix": "55-ARR_v1_70@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_70",
            "tgt_ix": "55-ARR_v1_70@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_71",
            "tgt_ix": "55-ARR_v1_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_71",
            "tgt_ix": "55-ARR_v1_71@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_71",
            "tgt_ix": "55-ARR_v1_71@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_72",
            "tgt_ix": "55-ARR_v1_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_72",
            "tgt_ix": "55-ARR_v1_72@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_72",
            "tgt_ix": "55-ARR_v1_72@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_72",
            "tgt_ix": "55-ARR_v1_72@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_72",
            "tgt_ix": "55-ARR_v1_72@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_72",
            "tgt_ix": "55-ARR_v1_72@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_72",
            "tgt_ix": "55-ARR_v1_72@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_72",
            "tgt_ix": "55-ARR_v1_72@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_72",
            "tgt_ix": "55-ARR_v1_72@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_72",
            "tgt_ix": "55-ARR_v1_72@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_72",
            "tgt_ix": "55-ARR_v1_72@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_73",
            "tgt_ix": "55-ARR_v1_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_73",
            "tgt_ix": "55-ARR_v1_73@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_73",
            "tgt_ix": "55-ARR_v1_73@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_73",
            "tgt_ix": "55-ARR_v1_73@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_73",
            "tgt_ix": "55-ARR_v1_73@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_73",
            "tgt_ix": "55-ARR_v1_73@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_73",
            "tgt_ix": "55-ARR_v1_73@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_73",
            "tgt_ix": "55-ARR_v1_73@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_73",
            "tgt_ix": "55-ARR_v1_73@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_73",
            "tgt_ix": "55-ARR_v1_73@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_74",
            "tgt_ix": "55-ARR_v1_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_74",
            "tgt_ix": "55-ARR_v1_74@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_74",
            "tgt_ix": "55-ARR_v1_74@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_75",
            "tgt_ix": "55-ARR_v1_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_76",
            "tgt_ix": "55-ARR_v1_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_76",
            "tgt_ix": "55-ARR_v1_76@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_76",
            "tgt_ix": "55-ARR_v1_76@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_76",
            "tgt_ix": "55-ARR_v1_76@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_77",
            "tgt_ix": "55-ARR_v1_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_78",
            "tgt_ix": "55-ARR_v1_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_79",
            "tgt_ix": "55-ARR_v1_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_80",
            "tgt_ix": "55-ARR_v1_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_81",
            "tgt_ix": "55-ARR_v1_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_82",
            "tgt_ix": "55-ARR_v1_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_83",
            "tgt_ix": "55-ARR_v1_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_84",
            "tgt_ix": "55-ARR_v1_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_85",
            "tgt_ix": "55-ARR_v1_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_86",
            "tgt_ix": "55-ARR_v1_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_87",
            "tgt_ix": "55-ARR_v1_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_88",
            "tgt_ix": "55-ARR_v1_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_89",
            "tgt_ix": "55-ARR_v1_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_90",
            "tgt_ix": "55-ARR_v1_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_91",
            "tgt_ix": "55-ARR_v1_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_92",
            "tgt_ix": "55-ARR_v1_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_93",
            "tgt_ix": "55-ARR_v1_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_94",
            "tgt_ix": "55-ARR_v1_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_95",
            "tgt_ix": "55-ARR_v1_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_96",
            "tgt_ix": "55-ARR_v1_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_97",
            "tgt_ix": "55-ARR_v1_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_98",
            "tgt_ix": "55-ARR_v1_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_99",
            "tgt_ix": "55-ARR_v1_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_100",
            "tgt_ix": "55-ARR_v1_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_101",
            "tgt_ix": "55-ARR_v1_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_102",
            "tgt_ix": "55-ARR_v1_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "55-ARR_v1_103",
            "tgt_ix": "55-ARR_v1_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 1884,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "position_tag_type": "from_draft",
        "doc_id": "55-ARR",
        "version": 1
    }
}