{
    "nodes": [
        {
            "ix": "218-ARR_v1_0",
            "content": "On the Use of Bert for Automated Essay Scoring: Joint Learning of Multi-Scale Essay Representation",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_2",
            "content": "In recent years, the pre-trained model has become dominant in most natural language processing (NLP) tasks. However, most researchers in the area of Automated Essay Scoring (AES) have not been able to properly use the pre-trained model such as BERT to outperform other deep learning models such as LSTM. In this paper, we introduce a novel multi-scale essay representation for BERT to jointly learn. To further improve the performance of our model, we also employ multiple losses and transfer learning from out-domain essays. Experiment results show that our approach derives much benefit from joint learning of multi-scale essay representation and obtains the state-ofthe-art results in the ASAP 1 task. Multi-scale essay representation also generalizes well to CommonLit Readability Prize (CRP 2 ) data set, which indicates that our novel text representation is a new choice for long text tasks when equipped with BERT.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "218-ARR_v1_4",
            "content": "AES is a very valuable task, which can promote the development of automated assessment and help teachers reduce the heavy burden of assessment. With the rise of online education in recent years, more and more researchers begin to pay attention to this field.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_5",
            "content": "AES systems mainly consist of two modules, which are essay representation and essay scoring modules. The essay representation module extracts features to represent an essay and the essay scoring module rates the essay with the extracted features.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_6",
            "content": "The dominant approaches in AES can be grouped into three categories:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_7",
            "content": "\u2022 Traditional AES usually uses regressors or ranking systems with complicated handcrafted features to rate an essay (Larkey, 1998;Rudner and Liang, 2002;Attali and Burstein, 2006;Yannakoudakis et al., 2011;Chen and He, 2013;Phandi et al., 2015;Cozma et al., 2018). These handcrafted features are based on the prior knowledge of linguists. Therefore they can achieve good performance even with small amounts of data. \u2022 Deep Neural Networks AES. The handcrafted features are effective in representing domain knowledge but are complicated to implement. Careful manual design makes these features less portable. Recently, deep neural network approaches for AES have made great progress and achieved comparable results with traditional AES (Taghipour and Ng, 2016;Dong and Zhang, 2016;Dong et al., 2017;Alikaniotis et al., 2016;Wang et al., 2018;Tay et al., 2018;Farag et al., 2018;Song et al., 2020;Ridley et al., 2021;Rodriguez et al., 2019;Mayfield and Black, 2020). Deep neural networks such as LSTM or CNN can automatically discover and learn complex features of essays, which makes AES an end-to-end task. Saving much time to design features, deep neural networks can transfer well among different AES tasks. By ensembling traditional and deep neural network approaches, AES can even obtain a better result, which benefits from both representations (Jin et al., 2018;Dasgupta et al., 2018;Uto et al., 2020). However, ensemble way still needs handcrafted features which cost numerous energy of researchers. \u2022 Pre-training AES uses the pre-trained language model as the initial essay representation module and fine-tune the model on the essay training set. Though the pre-trained methods have achieved the state-of-the-art performance in most NLP tasks, most of them (Uto et al., 2020;Rodriguez et al., 2019;Mayfield and Black, 2020) fail to show an advantage over other deep learning methods (Dong et al., 2017;Tay et al., 2018) As most pre-training AES methods fail to show an advantage over other deep learning methods, (Yang et al., 2020) considers the essay length is long while (Mayfield and Black, 2020) considers the hyper parameter optimization and curriculum learning are complex. (Rodriguez et al., 2019) suggests that the AES has reached its ceiling in terms of modeling. We additionally consider that the pretrained models are usually trained on sentences, and fail to learn enough knowledge of essays. Besides, the AES training data is quite limited, and it's not a good choice to fine-tune the pre-trained models which are learned from sentence data directly in order to learn better representation of essays. Instead, we can explicitly model more effective representations as well as leveraging the knowledge learned from numerous sentence data.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_8",
            "content": "When a teacher rates an essay, the scores are often affected by multi-scale features of the essay, such as token level, sentence level and paragraph level, etc. For example, the features may include the numbers of words, the essay structure, the master degree of vocabulary and syntactic complexity, etc. These features come from different scales of the essay. However, the researchers who used pretrained models in previous work simply made use of the single scale features. This inspires us to extract multi-scale features from the essays which represent multi-level characteristics of the essays.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_9",
            "content": "Most of the deep neural networks approaches use LSTM or CNN in their work. Some researchers (Uto et al., 2020;Rodriguez et al., 2019;Mayfield and Black, 2020) attempt to use BERT (Devlin et al., 2019) in their AES systems but fail to achieve competitive results as previous state-of-the-art results of deep neural networks methods. We consider it caused by that multi-scale features are not effectively constructed in the representation layer of pre-trained model due to the lack of data for fine-tuning in the AES task. We need to explicitly model the multi-scale information of the essay data and combine it with the powerful linguistic knowledge of pre-trained model.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_10",
            "content": "In addition, the loss function commonly used in the AES task is Mean Squared Error (MSE). For the AES task, the distribution of the sample population and the sorting properties between samples are also important issues for selecting the loss functions. They imitate the psychological process of teachers rating essays from overall student level considerations. Different optimization directions also can bring diversity to the final overall score distribution and contribute to the effect of ensemble learning.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_11",
            "content": "In this paper, we introduce the joint learning of multi-scale essay representation into the AES task with BERT. To introduce the diversity of essay scoring distribution, we combine two other loss functions with MSE. As the training data is limited, we also employ transfer learning from outdomain essays which is inspired by (Song et al., 2020). Through the above attempts, our model outperforms the state-of-the-art deep learning models based on LSTM (Dong et al., 2017;Tay et al., 2018). When training our model with multiple losses and transfer learning using R-Drop, we almost achieve the state-of-the-art result among all deep learning models.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_12",
            "content": "In summary, the contribution of this work is as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_13",
            "content": "\u2022 We propose a novel essay scoring approach to jointly learn multi-scale essay representation with BERT, which significantly improve the result compared to traditionally using pretrained language models. \u2022 Our method shows significant advantages in long text tasks and obtains almost the state-ofthe-art result among all deep learning models in the ASAP task. \u2022 We introduce two other loss functions which are inspired by the mental process of teacher rating essays, and employ transfer learning from out-domain essays with R-Drop , which further improves the performance for rating essays.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_14",
            "content": "Approach",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "218-ARR_v1_15",
            "content": "Task Formulation",
            "ntype": "title",
            "meta": {
                "section": "2.1"
            }
        },
        {
            "ix": "218-ARR_v1_16",
            "content": "The AES task is defined as following:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_17",
            "content": "Given an essay with n words X = {X i } n i=1 , we need to output one score y as a result of measuring the level of this essay.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_18",
            "content": "Quadratic Weighted Kappa (QWK) (Cohen, 1968) metric is commonly used to evaluate AES systems by researchers, which measures the agreement between the scoring results of two raters.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_19",
            "content": "Multi-scale Essay Representation",
            "ntype": "title",
            "meta": {
                "section": "2.2"
            }
        },
        {
            "ix": "218-ARR_v1_20",
            "content": "We decompose multi-scale into token-scale, segment-scale and document-scale. We will obtain the essay representation from these three scales.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_21",
            "content": "Token-scale and Document-scale Input We apply one pre-trained BERT (Devlin et al., 2019) model for token-scale and document-scale essay representations. The BERT tokenizer is used to split the essay into a token sequence",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_22",
            "content": "T 1 = [t 1 , t 2 , ......t n ]",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_23",
            "content": ", where t i is the i th token and n is the number of the tokens in the essay. The token we mentioned in this paper all refer to WordPiece, which is obtained by the subword tokenization algorithm used for BERT. We construct a new sequence T 2 from T 1 as following. L is set to 510, which is the max sequence length supported by BERT except the token [CLS] and [SEP ].",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_24",
            "content": "T2 = [CLS]+[t1, t2, .., tL] + [SEP] n > L [CLS]+T1+[SEP] n = L [CLS]+T1+[PAD] * (L \u2212 n)+[SEP] n < L",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_25",
            "content": "The final input representation are the sum of the token embeddings, the segmentation embeddings and the position embeddings. A detailed description can be found in the work of BERT (Devlin et al., 2019).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_26",
            "content": "Document-scale The document-scale representation is obtained by the [CLS] output of the BERT model. As the [CLS] output aggregates the whole sequence representation, it attempts to extract the essay information from the most global granularity.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_27",
            "content": "Token-scale As the BERT model is pre-trained by Masked Language Modeling (Devlin et al., 2019), the sequence outputs can capture the context information to represent each token. An essay often consists of hundreds of tokens, thus RNN is not the proper choice to combine all the token information due to the gradients vanishing problem. Instead, we utilize a max-pooling operation to all the sequence outputs and obtain the combined token-scale essay representation. Specifically, the max-pooling layer generates a d-dimensional vector W = [w 1 , w 2 , ..., w j , ..., w d ] and the element w j is computed as below:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_28",
            "content": "w j = max{h 1,j , h 2,j , ..., h n,j }",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_29",
            "content": "where d is the hidden size of the BERT model. As we use the pre-trained BERT model bert-baseuncased 3 , the hidden size d is 768. All the n sequence outputs of the BERT model are annotated as [h 1 , h 2 , ..., h i , ..., h n ], where h i is a d-dimensional vector [h i,1 , h i,2 , ..., h i,d ] representing the i th sequence output, and h i,j is the j th element in h i .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_30",
            "content": "Segment-scale Assuming the segment-scale value set is",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_31",
            "content": "K = [k 1 , k 2 , ...k i , ..., k S ],",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_32",
            "content": "where S is the number of segment scales we want to explore, and k i is the i th segment-scale in K. Given a token sequence T 1 = [t 1 , t 2 , ......t n ] for an essay, we obtain the segment-scale essay representation corresponding scale k i as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_33",
            "content": "1. We define n p as the maximum number of tokens corresponding to each essay prompt p.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_34",
            "content": "We truncate the token sequence to n p tokens if the essay length is longer than n p , otherwise we pad [P AD] to the sequence to reach the length n p .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_35",
            "content": "2. Divide the token sequence into m = \u2308n p /k i \u2309 segments and each segment is of length k i except for the last segment, which is similar to the work of (Mulyar et al., 2019).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_36",
            "content": "3. Input each of the m segment tokens into the BERT model, and get m segment representation vectors from the [CLS] output.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_37",
            "content": "4. Use an LSTM model to process the sequence of m segments representations, followed by attention pooling operation on the hidden states of the LSTM output to obtain the segmentscale essay representation corresponding to scale k i .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_38",
            "content": "The LSTM cell units process the sequence of segment representations and generate the hidden states as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_39",
            "content": "i t = \u03c3(Q i \u2022 s t + U i \u2022 h t\u22121 + b i ) f t = \u03c3(Q f \u2022 s t + U f \u2022 h t\u22121 + b f ) \u0109t = tanh(Q c \u2022 s t + U c \u2022 h t\u22121 + b c ) c t = i t \u2022 \u0109t + f t \u2022 c t\u22121 o t = \u03c3(Q o \u2022 s t + U o \u2022 h t\u22121 + b o ) h t = o t \u2022 tanh(c t )",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_40",
            "content": "where s t is the t th segment representation from BERT [CLS] output and h t is the t th hidden state generated from LSTM. The attention pooling operation we use is similar to the work of (Dong et al., 2017), which is defined as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_41",
            "content": "Q i , Q f , Q c , Q o , U i , U f ,",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_42",
            "content": "\u03b1i = tanh(Q a \u2022 h i + b a ) \u03b1 i = e qa\u2022 \u03b1i e qa\u2022 \u03b1j o= \u03b1 i \u2022 h i",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_43",
            "content": "o is the segment-scale essay representation corresponding to the scale k i . \u03b1 i is the attention weight for hidden state h i . Q a , b a , q a are the weight matrix, bias and weight vector respectively.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_44",
            "content": "Model Architecture",
            "ntype": "title",
            "meta": {
                "section": "2.3"
            }
        },
        {
            "ix": "218-ARR_v1_45",
            "content": "The model architecture is depicted in Figure 1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_46",
            "content": "We apply one BERT model to obtain the document-scale and token-scale essay representation. The concatenation of them is input into a dense regression layer which predicts the score corresponding to the document-scale and token-scale. For each segment-scale k with number of segments m, we apply another BERT model to get m CLS outputs, and apply an LST M model followed by an attention layer to get the segment-scale representation. We input the segment-scale representation into another dense regression layer to get the scores corresponding to segment-scale k. The final score is obtained by adding the scores of all S segmentscales and the score of the document-scale and token-scale, which is illustrated as below:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_47",
            "content": "y = y k + y doc,tok y k = \u0174seg \u2022 o k + b seg y doc,tok = \u0174doc,tok \u2022 H doc,tok + b doc,tok",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_48",
            "content": "H doc,tok = w doc W y k is the predicted score corresponding to segment-scale k. y doc,tok is the predicted score corresponding to the document-scale and tokenscale. \u0174seg and b seg are weight matrix and bias for segment-scale respectively. W doc,tok and b doc,tok are weight matrix and bias for document and tokenscales, o k is the segment-scale essay representation with the scale k. w doc is the document-scale essay representation. W is the word-scale essay representation. H doc,tok is the concatenation of documentscale and word-scale essay representations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_49",
            "content": "Loss Function",
            "ntype": "title",
            "meta": {
                "section": "2.4"
            }
        },
        {
            "ix": "218-ARR_v1_50",
            "content": "We use three loss functions to train the model.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_51",
            "content": "MSE measures the average value of square errors between predicted scores and labels, which is defined as below:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_52",
            "content": "M SE(y, \u0177) = 1 N (y i \u2212 \u0177i ) 2",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_53",
            "content": "where y i and \u0177i are the predicted score and the label for the i th essay respectively, N is the number of the essays.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_54",
            "content": "Similarity (SIM) measures whether two vectors are similar or dissimilar by using cosine function. A teacher will take into account the overall level distribution of all the students when rating an essay. Following such intuition, we introduce the SIM loss to the AES task. In each training step, we take the predicted scores of the essays in the batch as the predicted vector y, and the labels as the label vector \u0177. The SIM loss awards the similar vector pairs to make the model think more about the correlation among the batch of essays. The SIM loss is defined as below:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_55",
            "content": "SIM (y, \u0177) = 1 \u2212 cos(y, \u0177) y = [y 1 , y 2 , ..., y n ] \u0177 = [\u0177 1 , \u01772 , ..., \u0177N ]",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_56",
            "content": "where y i and \u0177i are the predicted score and label for the i th essay respectively, N is the number of the essays.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_57",
            "content": "Margin Ranking (MR) measures the ranking orders for each essay pair in the batch. We intuitively introduce MR loss because the sorting property between essays is a key factor to scoring. For each batch of essays, we first enumerate all the essay pairs, and then compute the MR loss as follows.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_58",
            "content": "The MR loss attempts to make the model penalize wrong order.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_59",
            "content": "M R(y, \u0177) = 1 N max(0, \u2212r ij (y i \u2212 y j ) + b) r ij = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 1 \u0177i > \u0177j -1 \u0177i < \u0177j -sgn(y i \u2212 y j ) \u0177i = \u0177j",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_60",
            "content": "y i and \u0177i are the predicted score and label for the i th essay respectively. N is the number of the essays. b is a hyper parameter, which is set to 0 in our experiment. For each sample pair (i, j), when the label \u0177i is larger than \u0177j , the predicted result y i should be larger than y j , otherwise, the pair contributes y j \u2212 y i to the loss. When \u0177i is equal to \u0177j , the loss is actually |y i \u2212 y j |. The combined loss is described as below: Loss total (y, \u0177) = \u03b1M SE(y, \u0177)+\u03b2M R(y, \u0177)+ \u03b3SIM (y, \u0177).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_61",
            "content": "\u03b1, \u03b2, \u03b3 are weight parameters which are tuned according to the performance on develop set.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_62",
            "content": "Experiment",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "218-ARR_v1_63",
            "content": "Data and Evaluation",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "218-ARR_v1_64",
            "content": "ASAP data set is widely used in the AES task, which contains eight different prompts. A detailed description can be seen in Table 1. For each prompt, the WordPiece length indicates the smallest number which is bigger than the length of 90% of the essays in terms of WordPiece number. We evaluate the scoring performance using QWK on ASAP data set, which is the official metric in the ASAP competition.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_65",
            "content": "CRP data set provides 2834 excerpts from several time periods and reading ease scores which range from -3.68 to 1.72. The average length of the excerpts is 175 and the WordPiece length is 252. We also use 5-fold cross validation to evaluate our system with a 60/20/20 split for train, develop and test sets on CRP data set. As the RMSE mertic is used in CRP competition, we also use it to evaluate our system in ease score prediction task.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_66",
            "content": "Baseline",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "218-ARR_v1_67",
            "content": "The baseline models for comparison are described as follows.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_68",
            "content": "EASE 4 is the best open-source system that participated in the ASAP competition and ranked the third place among 154 participants. EASE uses regression techniques with handcrafted features. Results of EASE with the settings of Support Vector Regression (SVR) and Bayesian Linear Ridge Regression (BLRR) are reported in (Phandi et al., 2015).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_69",
            "content": "CNN+RNN Various deep neural networks based on CNN and RNN for AES are studied by (Taghipour and Ng, 2016). They combine CNN ensembles and LSTM ensembles over 10 runs and get the best result in their experiment.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_70",
            "content": "Hierarchical LSTM-CNN-Attention (Dong et al., 2017) builds a hierarchical sentencedocument model, which uses CNN to encode sentences and LSTM to encode texts. The attention mechanism is used to automatically determine the relative weights of words and sentences in generating sentence representations and text representations respectively. They obtain the state-of-theart result among all neural models without pretraining.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_71",
            "content": "SKIPFLOW (Tay et al., 2018) proposes to use SKIPFLOW mechanism to model the relationships between snapshots of the hidden representations of an LSTM. The work of (Tay et al., 2018) also obtains the state-of-the-art result among all neural models without pre-training.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_72",
            "content": "Dilated LSTM with Reinforcement Learning (Wang et al., 2018) proposes a method using a dilated LSTM network in a reinforcement learning framework. They attempt to directly optimize the model using the QWK metric which considers the rating schema.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_73",
            "content": "BERT+SST+DAT and HA-LSTM+SST+DAT proposes to use two selfsupervised tasks and a domain adversarial training technique to optimize their training, which is the first work to use pre-trained language model to outperform LSTM based methods. They experiment with both hierarchical LSTM model and BERT in their work, which are HA\u2212LST M +SST +DAT and BERT + SST + DAT respectively.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_74",
            "content": "BERT 2 (Yang et al., 2020) combine regression and ranking to fine-tune BERT model which also outperform LSTM based methods and even obtain the new state-of-the-art.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_75",
            "content": "Settings",
            "ntype": "title",
            "meta": {
                "section": "3.3"
            }
        },
        {
            "ix": "218-ARR_v1_76",
            "content": "To compare with the baseline models and further study the effectiveness of multi-scale essay representations, losses and transfer learning, we conduct the following experiments.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_77",
            "content": "Multi-Scale Models. These models are optimized with MSE loss, and BERT-DOC represents essays with document-scale features based on BERT. BERT-TOK represents essays with token-scale features based on BERT. BERT-DOC-TOK represents essays with both document-scale and token-scale features based on BERT. BERT-DOC-TOK-SEG represents essays with documentscale, token-scale, and multiple segment-scale features based on BERT. Longformer (Beltagy et al., 2020) is an extension for transformers with an attention mechanism that scales linearly with sequence length, making it easy to process long documents. We conduct experiments to show that our multi-scale features also works with Longformer and can further improve the performance in long text tasks. Longformer-DOC-TOK-SEG uses document-scale, token-scale, and multiple segmentscale features to represent essays, but based on Longformer instead of BERT. Longformer-DOC represents essays with document-scale features based on Longformer.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_78",
            "content": "Models with Transfer Learning. To transfer learn from the out-domain essays 5 , we additionally employ a pre-training stage, which is similar to the work of (Song et al., 2020). In this stage, we scale all the labels of essays from out-domain data into range 0-1 and pre-train them with MSE loss. After the pre-training stage, we continue to finetune the model on in-domain essays. Tran-BERT-MS has the same modules as BERT-DOC-TOK-SEG with pre-training on out-domain data. MS means multiple scale features.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_79",
            "content": "Models with Multiple Losses. Based on Tran-BERT-MS model, we explore the performance of adding multiple loss functions. Tran-BERT-MS-ML additionally employs MR loss and SIM loss. ML means multiple losses. Tran-BERT-MS-ML-R incorporates R-Drop strategy in training based on Tran-BERT-MS-ML model.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_80",
            "content": "For the proposed model architecture which is depicted in Figure 1, the BERT model in the left part are shared by the document-scale and token-scale essay representations, and the other BERT model in the right part are shared by all segment-scale essay representations. We use the \"bert-base-uncased\" which includes 12 transformer layers and the hidden size is 768. In the training stage, we freeze all the layers in the BERT models except the last layer, which is more task related than other layers. The Longformer model used in our work is \"longformer-base-4096\". For the MR loss, we set b to 0. The weights \u03b1, \u03b2 and \u03b3 are tuned according to the performance on develop set. We use Adam optimizer (Kingma and Ba, 2015) to fine-tune model parameters in an end-to-end fashion with learning rate of 6e-5, \u03b21=0.9, \u03b22=0.999, L2 weight decay of 0.005. The coefficient weight \u03b1 in R-Drop is 9. We set the batch size to 32. We use dropout in the training stage and the drop rate is set to 0.1. We train all the models for 80 epochs, and select the best model according the performance on the develop set. We use a greedy search method to find the best combination of segment scales, which is shown in detail in Appendix A. Following , we perform the significance test for (Phandi et al., 2015) 0.781 0.621 0.630 0.749 0.782 0.771 0.727 0.534 0.699 2 EASE(BLRR) (Phandi et al., 2015) 0.761 0.606 0.621 0.742 0.784 0.775 0.730 0.617 0.705 3 CNN(10 runs) + LSTM(10 runs) (Taghipour and Ng, 2016) our models.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_81",
            "content": "ID Models P1 P2 P3 P4 P5 P6 P7 P8 Average 1 ASE(SVR)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_82",
            "content": "Results",
            "ntype": "title",
            "meta": {
                "section": "3.4"
            }
        },
        {
            "ix": "218-ARR_v1_83",
            "content": "Table 2 shows the performance of baseline models and our proposed models with joint learning of multi-scale essay representation. Table 3 shows the results of our model and the state-of-the-art models on essays in prompt 1, 2 and 8, whose averaged WordPiece lengths are longer than 510.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_84",
            "content": "We summarize some findings from the experiment results.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_85",
            "content": "\u2022 Our model 12 almost obtains the published state-of-the-art for neural approaches. For the prompts 1,2 and 8, the essays in which have more than 510 tokens, we improve the result from 0.761 to 0.772. The results demonstrate the effectiveness of the proposed framework for encoding and scoring essays. Before that, the conventional way of using BERT can not surpass the performance of models 4 and 6. We further re-implement BERT 2 proposed by (Yang et al., 2020), and the performance is not so strong as the published state-of-theart like models 9, 10 and 12. Though (Uto et al., 2020) obtain a much better result(QWK 0.801), our method perform much better than their system with only neural features(QWK 0.730), which demonstrates the strong essay encoding ability of our neural approach. \u2022 Compared to the models 4 and 6, our model 11 uses multi-scale features to encode essays instead of LSTM based models, and we use the same regression loss to optimize the model. Our model simply changes the representation way and significantly improves the result from 0.764 to 0.782, which demonstrates the strong encoding ability armed by multi-scale representation for long text.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_86",
            "content": "Further analysis",
            "ntype": "title",
            "meta": {
                "section": "3.5"
            }
        },
        {
            "ix": "218-ARR_v1_87",
            "content": "Multi-scale representation We further analyze the effectiveness of employing each scale essay representation to the joint learning process. 5 show the performance of our models to represent essays on different feature scales, which are trained with MSE loss and without transfer learning. Table 4 shows the performance on ASAP data set while Table 5 shows the performance on CRP data set. The improvement of BERT-DOC-TOK-SEG over BERT-DOC, BERT-TOK, BERT-DOC-TOK are significant (p<0.0001) on CRP data set, and are significant (p<0.0001) in most cases on ASAP data set. Results on both table indicates the similar findings.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_88",
            "content": "\u2022 Combining the features from document-scale and token-scale, BERT-DOC-TOK outperforms the models BERT-DOC and BERT-TOK, which only use one scale features. This demonstrates that our proposed framework can benefit from multi-scale essay representation even with only two scales. \u2022 By additionally incorporating multiple segment-scale features, BERT-DOC-TOK-SEG performs much better than BERT-DOC-TOK. This demonstrates the effectiveness and generalization ability of our multi-scale essay representation on multiple tasks.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_89",
            "content": "Average QWK Longformer-DOC 0.746 Longformer-DOC-TOK-SEG 0.771 Reasons for Effectiness of Multi-scale representation Though the experiment shows the effectiveness of multi-scale representation, we further explore the reason. We could doubt that the effectiveness comes from supporting long sequences, not the multi-scale itself. As Longformer is good at dealing with long texts, we compare the results between Longformer-DOC and Longformer-DOC-TOK-SEG. The results of the significance test show that the improvement of Longformer-DOC-TOK-SEG over Longformer-DOC are significantly (p<0.0001) in most cases. Performance of the two models are shown in Table 6, we get the following findings.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_90",
            "content": "\u2022 Though Longformer-DOC supports long sequences encoding, it performs poor, which indicates us that supporting long sequence ability is not enough for a good essay scoring system. \u2022 Longformer-DOC-TOK-SEG outperforms Longformer-DOC significantly, which indicates the effectiveness of our model comes from encoding essays by multi-scale features, not only comes from the ability to deal with long texts.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_91",
            "content": "These results are consistent with our intuition that our approach takes into account different level features of essays and predict the scores more accurately. We consider it caused by that multi-scale features are not effectively constructed in the representation layer of pre-trained model due to the lack of data for fine-tuning in the AES task. Therefore, we need to explicitly model the multi-scale information of the essay data and combine it with the powerful linguistic knowledge of pre-trained model. Transfer Learning with Multiple Losses and R-Drop We further explore the effectiveness of pretraining with adding multiple loss functions and employing R-Drop. As is shown in table 7, by incorporating the pre-training stage which learns the knowledge from out-domain data, Tran-BERT-MS model improves the result from 0.782 to to 0.788 compared to BERT-DOC-TOK-SEG model. The model Tran-BERT-MS-ML which jointly learns with multiple loss functions further improves the performance from 0.788 to 0.790. We consider it due to the reason that MR brings ranking information and SIM takes into account the overall score distribution information. Diverse losses bring different but positive influence on the optimization direction and act as an ensembler. By employing R-Drop, Tran-BERT-MS-ML-R improves the QWK slightly, which comes from the fact that R-Drop plays a regularization role.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_92",
            "content": "Conclusion and Future Work",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "218-ARR_v1_93",
            "content": "In this paper, we propose a novel multi-scale representation approach based on pre-trained language model, and employ multiple losses and transfer learning. We obtain the state-of-the-art results among deep learning models. In particular, multiscale representation has a very significant advantage in dealing with long text.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_94",
            "content": "One of the future directions can be exploring more efficient and soft multi-scale representation. Introducing linguistic knowledge to segment a more reasonable scale may bring further improvement.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "218-ARR_v1_95",
            "content": "Dimitrios Alikaniotis, Helen Yannakoudakis, Marek Rei, Automatic text scoring using neural networks, 2016, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "Dimitrios Alikaniotis",
                    "Helen Yannakoudakis",
                    "Marek Rei"
                ],
                "title": "Automatic text scoring using neural networks",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_96",
            "content": "Yigal Attali, Jill Burstein, Automated essay scoring with e-rater\u00ae v.2. The Journal of Technology, 2006, Learning, and Assessment, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Yigal Attali",
                    "Jill Burstein"
                ],
                "title": "Automated essay scoring with e-rater\u00ae v.2. The Journal of Technology",
                "pub_date": "2006",
                "pub_title": "Learning, and Assessment",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_97",
            "content": "Iz Beltagy, Matthew Peters, Arman Cohan, Longformer: The long-document transformer, 2020, arXiv: Computation and Language, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "Iz Beltagy",
                    "Matthew Peters",
                    "Arman Cohan"
                ],
                "title": "Longformer: The long-document transformer",
                "pub_date": "2020",
                "pub_title": "arXiv: Computation and Language",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_98",
            "content": "Yue Cao, Hanqi Jin, Xiaojun Wan, Zhiwei Yu, Domain-adaptive neural automated essay scoring, 2020, SIGIR '20: Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Yue Cao",
                    "Hanqi Jin",
                    "Xiaojun Wan",
                    "Zhiwei Yu"
                ],
                "title": "Domain-adaptive neural automated essay scoring",
                "pub_date": "2020",
                "pub_title": "SIGIR '20: Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_99",
            "content": "Hongbo Chen, Ben He, Automated essay scoring by maximizing human-machine agreement, 2013, Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Hongbo Chen",
                    "Ben He"
                ],
                "title": "Automated essay scoring by maximizing human-machine agreement",
                "pub_date": "2013",
                "pub_title": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_100",
            "content": "J Cohen, Weighted kappa: nominal scale agreement provision for scaled disagreement partial credit, 1968, Psychological bulletin, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "J Cohen"
                ],
                "title": "Weighted kappa: nominal scale agreement provision for scaled disagreement partial credit",
                "pub_date": "1968",
                "pub_title": "Psychological bulletin",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_101",
            "content": "M\u0203d\u0203lina Cozma, Andrei Butnaru, Radu Tudor Ionescu, Automated essay scoring with string kernels and word embeddings, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "M\u0203d\u0203lina Cozma",
                    "Andrei Butnaru",
                    "Radu Tudor Ionescu"
                ],
                "title": "Automated essay scoring with string kernels and word embeddings",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_102",
            "content": "Tirthankar Dasgupta, Abir Naskar, Rupsa Saha, Lipika Dey, Augmenting textual qualitative features in deep convolution recurrent neural network for automatic essay scoring, 2018, Proceedings of the 5th Workshop on Natural Language Processing Techniques for Educational Applications, .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Tirthankar Dasgupta",
                    "Abir Naskar",
                    "Rupsa Saha",
                    "Lipika Dey"
                ],
                "title": "Augmenting textual qualitative features in deep convolution recurrent neural network for automatic essay scoring",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 5th Workshop on Natural Language Processing Techniques for Educational Applications",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_103",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, Bert: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Jacob Devlin",
                    "Ming-Wei Chang",
                    "Kenton Lee",
                    "Kristina Toutanova"
                ],
                "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_104",
            "content": "Fei Dong, Yue Zhang, Automatic features for essay scoring -an empirical study, 2016, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Fei Dong",
                    "Yue Zhang"
                ],
                "title": "Automatic features for essay scoring -an empirical study",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_105",
            "content": "Fei Dong, Yue Zhang, Jie Yang, Attentionbased recurrent convolutional neural network for automatic essay scoring, 2017, Proceedings of the 21st Conference on Computational Natural Language Learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Fei Dong",
                    "Yue Zhang",
                    "Jie Yang"
                ],
                "title": "Attentionbased recurrent convolutional neural network for automatic essay scoring",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 21st Conference on Computational Natural Language Learning",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_106",
            "content": "Youmna Farag, Helen Yannakoudakis, Ted Briscoe, Neural automated essay scoring and coherence modeling for adversarially crafted input, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technolog, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Youmna Farag",
                    "Helen Yannakoudakis",
                    "Ted Briscoe"
                ],
                "title": "Neural automated essay scoring and coherence modeling for adversarially crafted input",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technolog",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_107",
            "content": "Cancan Jin, Ben He, Kai Hui, Le Sun, Tdnn: A two-stage deep neural network for promptindependent automated essay scoring, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Cancan Jin",
                    "Ben He",
                    "Kai Hui",
                    "Le Sun"
                ],
                "title": "Tdnn: A two-stage deep neural network for promptindependent automated essay scoring",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_108",
            "content": "P Diederik, Jimmy Kingma,  Ba, Adam: A method for stochastic optimization, 2015, 3rd International Conference for Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    "P Diederik",
                    "Jimmy Kingma",
                    " Ba"
                ],
                "title": "Adam: A method for stochastic optimization",
                "pub_date": "2015",
                "pub_title": "3rd International Conference for Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_109",
            "content": "S Leah,  Larkey, Automatic essay grading using text categorization techniques, 1998, SIGIR '98 Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieva, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "S Leah",
                    " Larkey"
                ],
                "title": "Automatic essay grading using text categorization techniques",
                "pub_date": "1998",
                "pub_title": "SIGIR '98 Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieva",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_110",
            "content": "UNKNOWN, None, 2021, R-drop: Regularized dropout for neural networks, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "R-drop: Regularized dropout for neural networks",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_111",
            "content": "Elijah Mayfield, Alan Black, Should you fine-tune bert for automated essay scoring?, 2020, Proceedings of the 15th Workshop on Innovative Use of NLP for Building Educational Applications, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "Elijah Mayfield",
                    "Alan Black"
                ],
                "title": "Should you fine-tune bert for automated essay scoring?",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 15th Workshop on Innovative Use of NLP for Building Educational Applications",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_112",
            "content": "Andriy Mulyar, Elliot Schumacher, Masoud Rouhizadeh, Mark Dredze, Phenotyping of clinical notes with improved document classification models using contextualized neural language models, 2019, 33rd Conference on Neural Information Processing Systems (NeurIPS), .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Andriy Mulyar",
                    "Elliot Schumacher",
                    "Masoud Rouhizadeh",
                    "Mark Dredze"
                ],
                "title": "Phenotyping of clinical notes with improved document classification models using contextualized neural language models",
                "pub_date": "2019",
                "pub_title": "33rd Conference on Neural Information Processing Systems (NeurIPS)",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_113",
            "content": "Peter Phandi, Ming Kian, Hwee Tou Chai,  Ng, Flexible domain adaptation for automated essay scoring using correlated linear regression, 2015, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Peter Phandi",
                    "Ming Kian",
                    "Hwee Tou Chai",
                    " Ng"
                ],
                "title": "Flexible domain adaptation for automated essay scoring using correlated linear regression",
                "pub_date": "2015",
                "pub_title": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_114",
            "content": "Robert Ridley, Liang He, Xinyu Dai, Shujian Huang, Jiajun Chen, Automated cross-prompt scoring of essay traits, 2021, Proceedings of the AAAI Conference on Artificial Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "Robert Ridley",
                    "Liang He",
                    "Xinyu Dai",
                    "Shujian Huang",
                    "Jiajun Chen"
                ],
                "title": "Automated cross-prompt scoring of essay traits",
                "pub_date": "2021",
                "pub_title": "Proceedings of the AAAI Conference on Artificial Intelligence",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_115",
            "content": "Pedro Rodriguez, Amir Jafari, Christopher Ormerod, Language models and automated essay scoring, 2019, arXiv: Computation and Language, .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Pedro Rodriguez",
                    "Amir Jafari",
                    "Christopher Ormerod"
                ],
                "title": "Language models and automated essay scoring",
                "pub_date": "2019",
                "pub_title": "arXiv: Computation and Language",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_116",
            "content": "M Lawrence, Tahung Rudner,  Liang, Automated essay scoring using bayes' theorem, 2002, The Journal of Technology, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "M Lawrence",
                    "Tahung Rudner",
                    " Liang"
                ],
                "title": "Automated essay scoring using bayes' theorem",
                "pub_date": "2002",
                "pub_title": "The Journal of Technology",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_117",
            "content": "Wei Song, Kai Zhang, Ruiji Fu, Lizhen Liu, Ting Liu, Miaomiao Cheng, Multi-stage pre-training for automated chinese essay scoring, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Wei Song",
                    "Kai Zhang",
                    "Ruiji Fu",
                    "Lizhen Liu",
                    "Ting Liu",
                    "Miaomiao Cheng"
                ],
                "title": "Multi-stage pre-training for automated chinese essay scoring",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_118",
            "content": "Kaveh Taghipour, Hwee Tou Ng, A neural approach to automated essay scoring, 2016, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Kaveh Taghipour",
                    "Hwee Tou Ng"
                ],
                "title": "A neural approach to automated essay scoring",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_119",
            "content": "Yi Tay, Minh Phan, Anh Luu, Siu Cheung Tuan,  Hui, Skipflow:incorporating neural coherence features for end-to-end automatic text scoring, 2018, Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Yi Tay",
                    "Minh Phan",
                    "Anh Luu",
                    "Siu Cheung Tuan",
                    " Hui"
                ],
                "title": "Skipflow:incorporating neural coherence features for end-to-end automatic text scoring",
                "pub_date": "2018",
                "pub_title": "Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_120",
            "content": "Masaki Uto, Yikuan Xie, Maomi Ueno, Neural automated essay scoring incorporating handcrafted features, 2020, Proceedings of the 28th International Conference on Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Masaki Uto",
                    "Yikuan Xie",
                    "Maomi Ueno"
                ],
                "title": "Neural automated essay scoring incorporating handcrafted features",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 28th International Conference on Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_121",
            "content": "Yucheng Wang, Zhongyu Wei, Yaqian Zhou, Xuanjing Huang, Automatic essay scoring incorporating rating schema via reinforcement learning, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": [
                    "Yucheng Wang",
                    "Zhongyu Wei",
                    "Yaqian Zhou",
                    "Xuanjing Huang"
                ],
                "title": "Automatic essay scoring incorporating rating schema via reinforcement learning",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_122",
            "content": "Ruosong Yang, Jiannong Cao, Zhiyuan Wen, Youzheng Wu, Xiaodong He, Enhancing automated essay scoring performance via fine-tuning pre-trained language models with combination of regression and ranking, 2020, Findings of the Association for Computational Linguistics: EMNLP 2020, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": [
                    "Ruosong Yang",
                    "Jiannong Cao",
                    "Zhiyuan Wen",
                    "Youzheng Wu",
                    "Xiaodong He"
                ],
                "title": "Enhancing automated essay scoring performance via fine-tuning pre-trained language models with combination of regression and ranking",
                "pub_date": "2020",
                "pub_title": "Findings of the Association for Computational Linguistics: EMNLP 2020",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_123",
            "content": "Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, V Quoc,  Le, Xlnet: Generalized autoregressive pretraining for language understanding, 2019, 33rd Conference on Neural Information Processing Systems (NeurIPS), .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Zhilin Yang",
                    "Zihang Dai",
                    "Yiming Yang",
                    "Jaime Carbonell",
                    "Ruslan Salakhutdinov",
                    "V Quoc",
                    " Le"
                ],
                "title": "Xlnet: Generalized autoregressive pretraining for language understanding",
                "pub_date": "2019",
                "pub_title": "33rd Conference on Neural Information Processing Systems (NeurIPS)",
                "pub": null
            }
        },
        {
            "ix": "218-ARR_v1_124",
            "content": "Helen Yannakoudakis, Ted Briscoe, Ben Medlock, A new dataset and method for automatically grading esol texts, 2011, HLT '11 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "Helen Yannakoudakis",
                    "Ted Briscoe",
                    "Ben Medlock"
                ],
                "title": "A new dataset and method for automatically grading esol texts",
                "pub_date": "2011",
                "pub_title": "HLT '11 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "218-ARR_v1_0@0",
            "content": "On the Use of Bert for Automated Essay Scoring: Joint Learning of Multi-Scale Essay Representation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_0",
            "start": 0,
            "end": 97,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_2@0",
            "content": "In recent years, the pre-trained model has become dominant in most natural language processing (NLP) tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_2",
            "start": 0,
            "end": 106,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_2@1",
            "content": "However, most researchers in the area of Automated Essay Scoring (AES) have not been able to properly use the pre-trained model such as BERT to outperform other deep learning models such as LSTM.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_2",
            "start": 108,
            "end": 302,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_2@2",
            "content": "In this paper, we introduce a novel multi-scale essay representation for BERT to jointly learn.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_2",
            "start": 304,
            "end": 398,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_2@3",
            "content": "To further improve the performance of our model, we also employ multiple losses and transfer learning from out-domain essays.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_2",
            "start": 400,
            "end": 524,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_2@4",
            "content": "Experiment results show that our approach derives much benefit from joint learning of multi-scale essay representation and obtains the state-ofthe-art results in the ASAP 1 task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_2",
            "start": 526,
            "end": 703,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_2@5",
            "content": "Multi-scale essay representation also generalizes well to CommonLit Readability Prize (CRP 2 ) data set, which indicates that our novel text representation is a new choice for long text tasks when equipped with BERT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_2",
            "start": 705,
            "end": 920,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_4@0",
            "content": "AES is a very valuable task, which can promote the development of automated assessment and help teachers reduce the heavy burden of assessment.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_4",
            "start": 0,
            "end": 142,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_4@1",
            "content": "With the rise of online education in recent years, more and more researchers begin to pay attention to this field.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_4",
            "start": 144,
            "end": 257,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_5@0",
            "content": "AES systems mainly consist of two modules, which are essay representation and essay scoring modules.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_5",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_5@1",
            "content": "The essay representation module extracts features to represent an essay and the essay scoring module rates the essay with the extracted features.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_5",
            "start": 101,
            "end": 245,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_6@0",
            "content": "The dominant approaches in AES can be grouped into three categories:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_6",
            "start": 0,
            "end": 67,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_7@0",
            "content": "\u2022 Traditional AES usually uses regressors or ranking systems with complicated handcrafted features to rate an essay (Larkey, 1998;Rudner and Liang, 2002;Attali and Burstein, 2006;Yannakoudakis et al., 2011;Chen and He, 2013;Phandi et al., 2015;Cozma et al., 2018). These handcrafted features are based on the prior knowledge of linguists. Therefore they can achieve good performance even with small amounts of data. \u2022 Deep Neural Networks AES. The handcrafted features are effective in representing domain knowledge but are complicated to implement. Careful manual design makes these features less portable. Recently, deep neural network approaches for AES have made great progress and achieved comparable results with traditional AES (Taghipour and Ng, 2016;Dong and Zhang, 2016;Dong et al., 2017;Alikaniotis et al., 2016;Wang et al., 2018;Tay et al., 2018;Farag et al., 2018;Song et al., 2020;Ridley et al., 2021;Rodriguez et al., 2019;Mayfield and Black, 2020). Deep neural networks such as LSTM or CNN can automatically discover and learn complex features of essays, which makes AES an end-to-end task. Saving much time to design features, deep neural networks can transfer well among different AES tasks. By ensembling traditional and deep neural network approaches, AES can even obtain a better result, which benefits from both representations (Jin et al., 2018;Dasgupta et al., 2018;Uto et al., 2020). However, ensemble way still needs handcrafted features which cost numerous energy of researchers. \u2022 Pre-training AES uses the pre-trained language model as the initial essay representation module and fine-tune the model on the essay training set. Though the pre-trained methods have achieved the state-of-the-art performance in most NLP tasks, most of them (Uto et al., 2020;Rodriguez et al., 2019;Mayfield and Black, 2020) fail to show an advantage over other deep learning methods (Dong et al., 2017;Tay et al., 2018) As most pre-training AES methods fail to show an advantage over other deep learning methods, (Yang et al., 2020) considers the essay length is long while (Mayfield and Black, 2020) considers the hyper parameter optimization and curriculum learning are complex. (Rodriguez et al., 2019) suggests that the AES has reached its ceiling in terms of modeling. We additionally consider that the pretrained models are usually trained on sentences, and fail to learn enough knowledge of essays. Besides, the AES training data is quite limited, and it's not a good choice to fine-tune the pre-trained models which are learned from sentence data directly in order to learn better representation of essays. Instead, we can explicitly model more effective representations as well as leveraging the knowledge learned from numerous sentence data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_7",
            "start": 0,
            "end": 2759,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_8@0",
            "content": "When a teacher rates an essay, the scores are often affected by multi-scale features of the essay, such as token level, sentence level and paragraph level, etc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_8",
            "start": 0,
            "end": 159,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_8@1",
            "content": "For example, the features may include the numbers of words, the essay structure, the master degree of vocabulary and syntactic complexity, etc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_8",
            "start": 161,
            "end": 303,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_8@2",
            "content": "These features come from different scales of the essay.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_8",
            "start": 305,
            "end": 359,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_8@3",
            "content": "However, the researchers who used pretrained models in previous work simply made use of the single scale features.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_8",
            "start": 361,
            "end": 474,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_8@4",
            "content": "This inspires us to extract multi-scale features from the essays which represent multi-level characteristics of the essays.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_8",
            "start": 476,
            "end": 598,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_9@0",
            "content": "Most of the deep neural networks approaches use LSTM or CNN in their work.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_9",
            "start": 0,
            "end": 73,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_9@1",
            "content": "Some researchers (Uto et al., 2020;Rodriguez et al., 2019;Mayfield and Black, 2020) attempt to use BERT (Devlin et al., 2019) in their AES systems but fail to achieve competitive results as previous state-of-the-art results of deep neural networks methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_9",
            "start": 75,
            "end": 330,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_9@2",
            "content": "We consider it caused by that multi-scale features are not effectively constructed in the representation layer of pre-trained model due to the lack of data for fine-tuning in the AES task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_9",
            "start": 332,
            "end": 519,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_9@3",
            "content": "We need to explicitly model the multi-scale information of the essay data and combine it with the powerful linguistic knowledge of pre-trained model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_9",
            "start": 521,
            "end": 669,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_10@0",
            "content": "In addition, the loss function commonly used in the AES task is Mean Squared Error (MSE).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_10",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_10@1",
            "content": "For the AES task, the distribution of the sample population and the sorting properties between samples are also important issues for selecting the loss functions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_10",
            "start": 90,
            "end": 251,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_10@2",
            "content": "They imitate the psychological process of teachers rating essays from overall student level considerations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_10",
            "start": 253,
            "end": 359,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_10@3",
            "content": "Different optimization directions also can bring diversity to the final overall score distribution and contribute to the effect of ensemble learning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_10",
            "start": 361,
            "end": 509,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_11@0",
            "content": "In this paper, we introduce the joint learning of multi-scale essay representation into the AES task with BERT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_11",
            "start": 0,
            "end": 110,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_11@1",
            "content": "To introduce the diversity of essay scoring distribution, we combine two other loss functions with MSE.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_11",
            "start": 112,
            "end": 214,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_11@2",
            "content": "As the training data is limited, we also employ transfer learning from outdomain essays which is inspired by (Song et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_11",
            "start": 216,
            "end": 344,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_11@3",
            "content": "Through the above attempts, our model outperforms the state-of-the-art deep learning models based on LSTM (Dong et al., 2017;Tay et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_11",
            "start": 346,
            "end": 488,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_11@4",
            "content": "When training our model with multiple losses and transfer learning using R-Drop, we almost achieve the state-of-the-art result among all deep learning models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_11",
            "start": 490,
            "end": 647,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_12@0",
            "content": "In summary, the contribution of this work is as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_12",
            "start": 0,
            "end": 55,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_13@0",
            "content": "\u2022 We propose a novel essay scoring approach to jointly learn multi-scale essay representation with BERT, which significantly improve the result compared to traditionally using pretrained language models. \u2022 Our method shows significant advantages in long text tasks and obtains almost the state-ofthe-art result among all deep learning models in the ASAP task. \u2022 We introduce two other loss functions which are inspired by the mental process of teacher rating essays, and employ transfer learning from out-domain essays with R-Drop , which further improves the performance for rating essays.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_13",
            "start": 0,
            "end": 589,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_14@0",
            "content": "Approach",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_14",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_15@0",
            "content": "Task Formulation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_15",
            "start": 0,
            "end": 15,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_16@0",
            "content": "The AES task is defined as following:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_16",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_17@0",
            "content": "Given an essay with n words X = {X i } n i=1 , we need to output one score y as a result of measuring the level of this essay.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_17",
            "start": 0,
            "end": 125,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_18@0",
            "content": "Quadratic Weighted Kappa (QWK) (Cohen, 1968) metric is commonly used to evaluate AES systems by researchers, which measures the agreement between the scoring results of two raters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_18",
            "start": 0,
            "end": 179,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_19@0",
            "content": "Multi-scale Essay Representation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_19",
            "start": 0,
            "end": 31,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_20@0",
            "content": "We decompose multi-scale into token-scale, segment-scale and document-scale.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_20",
            "start": 0,
            "end": 75,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_20@1",
            "content": "We will obtain the essay representation from these three scales.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_20",
            "start": 77,
            "end": 140,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_21@0",
            "content": "Token-scale and Document-scale Input We apply one pre-trained BERT (Devlin et al., 2019) model for token-scale and document-scale essay representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_21",
            "start": 0,
            "end": 151,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_21@1",
            "content": "The BERT tokenizer is used to split the essay into a token sequence",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_21",
            "start": 153,
            "end": 219,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_22@0",
            "content": "T 1 = [t 1 , t 2 , ......t n ]",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_22",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_23@0",
            "content": ", where t i is the i th token and n is the number of the tokens in the essay.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_23",
            "start": 0,
            "end": 76,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_23@1",
            "content": "The token we mentioned in this paper all refer to WordPiece, which is obtained by the subword tokenization algorithm used for BERT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_23",
            "start": 78,
            "end": 208,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_23@2",
            "content": "We construct a new sequence T 2 from T 1 as following.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_23",
            "start": 210,
            "end": 263,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_23@3",
            "content": "L is set to 510, which is the max sequence length supported by BERT except the token [CLS] and [SEP ].",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_23",
            "start": 265,
            "end": 366,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_24@0",
            "content": "T2 = [CLS]+[t1, t2, .., tL] + [SEP] n > L [CLS]+T1+[SEP] n = L [CLS]+T1+[PAD] * (L \u2212 n)+[SEP] n < L",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_24",
            "start": 0,
            "end": 98,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_25@0",
            "content": "The final input representation are the sum of the token embeddings, the segmentation embeddings and the position embeddings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_25",
            "start": 0,
            "end": 123,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_25@1",
            "content": "A detailed description can be found in the work of BERT (Devlin et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_25",
            "start": 125,
            "end": 202,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_26@0",
            "content": "Document-scale The document-scale representation is obtained by the [CLS] output of the BERT model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_26",
            "start": 0,
            "end": 98,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_26@1",
            "content": "As the [CLS] output aggregates the whole sequence representation, it attempts to extract the essay information from the most global granularity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_26",
            "start": 100,
            "end": 243,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_27@0",
            "content": "Token-scale As the BERT model is pre-trained by Masked Language Modeling (Devlin et al., 2019), the sequence outputs can capture the context information to represent each token.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_27",
            "start": 0,
            "end": 176,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_27@1",
            "content": "An essay often consists of hundreds of tokens, thus RNN is not the proper choice to combine all the token information due to the gradients vanishing problem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_27",
            "start": 178,
            "end": 334,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_27@2",
            "content": "Instead, we utilize a max-pooling operation to all the sequence outputs and obtain the combined token-scale essay representation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_27",
            "start": 336,
            "end": 464,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_27@3",
            "content": "Specifically, the max-pooling layer generates a d-dimensional vector W = [w 1 , w 2 , ..., w j , ..., w d ] and the element w j is computed as below:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_27",
            "start": 466,
            "end": 614,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_28@0",
            "content": "w j = max{h 1,j , h 2,j , ..., h n,j }",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_28",
            "start": 0,
            "end": 37,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_29@0",
            "content": "where d is the hidden size of the BERT model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_29",
            "start": 0,
            "end": 44,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_29@1",
            "content": "As we use the pre-trained BERT model bert-baseuncased 3 , the hidden size d is 768.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_29",
            "start": 46,
            "end": 128,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_29@2",
            "content": "All the n sequence outputs of the BERT model are annotated as [h 1 , h 2 , ..., h i , ..., h n ], where h i is a d-dimensional vector [h i,1 , h i,2 , ..., h i,d ] representing the i th sequence output, and h i,j is the j th element in h i .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_29",
            "start": 130,
            "end": 370,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_30@0",
            "content": "Segment-scale Assuming the segment-scale value set is",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_30",
            "start": 0,
            "end": 52,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_31@0",
            "content": "K = [k 1 , k 2 , ...k i , ..., k S ],",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_31",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_32@0",
            "content": "where S is the number of segment scales we want to explore, and k i is the i th segment-scale in K. Given a token sequence T 1 = [t 1 , t 2 , ......t n ] for an essay, we obtain the segment-scale essay representation corresponding scale k i as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_32",
            "start": 0,
            "end": 251,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_33@0",
            "content": "1. We define n p as the maximum number of tokens corresponding to each essay prompt p.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_33",
            "start": 0,
            "end": 85,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_34@0",
            "content": "We truncate the token sequence to n p tokens if the essay length is longer than n p , otherwise we pad [P AD] to the sequence to reach the length n p .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_34",
            "start": 0,
            "end": 150,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_35@0",
            "content": "2. Divide the token sequence into m = \u2308n p /k i \u2309 segments and each segment is of length k i except for the last segment, which is similar to the work of (Mulyar et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_35",
            "start": 0,
            "end": 175,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_36@0",
            "content": "3. Input each of the m segment tokens into the BERT model, and get m segment representation vectors from the [CLS] output.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_36",
            "start": 0,
            "end": 121,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_37@0",
            "content": "4. Use an LSTM model to process the sequence of m segments representations, followed by attention pooling operation on the hidden states of the LSTM output to obtain the segmentscale essay representation corresponding to scale k i .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_37",
            "start": 0,
            "end": 231,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_38@0",
            "content": "The LSTM cell units process the sequence of segment representations and generate the hidden states as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_38",
            "start": 0,
            "end": 109,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_39@0",
            "content": "i t = \u03c3(Q i \u2022 s t + U i \u2022 h t\u22121 + b i ) f t = \u03c3(Q f \u2022 s t + U f \u2022 h t\u22121 + b f ) \u0109t = tanh(Q c \u2022 s t + U c \u2022 h t\u22121 + b c ) c t = i t \u2022 \u0109t + f t \u2022 c t\u22121 o t = \u03c3(Q o \u2022 s t + U o \u2022 h t\u22121 + b o ) h t = o t \u2022 tanh(c t )",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_39",
            "start": 0,
            "end": 212,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_40@0",
            "content": "where s t is the t th segment representation from BERT [CLS] output and h t is the t th hidden state generated from LSTM.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_40",
            "start": 0,
            "end": 120,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_40@1",
            "content": "The attention pooling operation we use is similar to the work of (Dong et al., 2017), which is defined as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_40",
            "start": 122,
            "end": 235,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_41@0",
            "content": "Q i , Q f , Q c , Q o , U i , U f ,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_41",
            "start": 0,
            "end": 34,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_42@0",
            "content": "\u03b1i = tanh(Q a \u2022 h i + b a ) \u03b1 i = e qa\u2022 \u03b1i e qa\u2022 \u03b1j o= \u03b1 i \u2022 h i",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_42",
            "start": 0,
            "end": 63,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_43@0",
            "content": "o is the segment-scale essay representation corresponding to the scale k i .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_43",
            "start": 0,
            "end": 75,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_43@1",
            "content": "\u03b1 i is the attention weight for hidden state h i .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_43",
            "start": 77,
            "end": 126,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_43@2",
            "content": "Q a , b a , q a are the weight matrix, bias and weight vector respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_43",
            "start": 128,
            "end": 202,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_44@0",
            "content": "Model Architecture",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_44",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_45@0",
            "content": "The model architecture is depicted in Figure 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_45",
            "start": 0,
            "end": 46,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_46@0",
            "content": "We apply one BERT model to obtain the document-scale and token-scale essay representation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_46",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_46@1",
            "content": "The concatenation of them is input into a dense regression layer which predicts the score corresponding to the document-scale and token-scale.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_46",
            "start": 91,
            "end": 232,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_46@2",
            "content": "For each segment-scale k with number of segments m, we apply another BERT model to get m CLS outputs, and apply an LST M model followed by an attention layer to get the segment-scale representation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_46",
            "start": 234,
            "end": 431,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_46@3",
            "content": "We input the segment-scale representation into another dense regression layer to get the scores corresponding to segment-scale k. The final score is obtained by adding the scores of all S segmentscales and the score of the document-scale and token-scale, which is illustrated as below:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_46",
            "start": 433,
            "end": 717,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_47@0",
            "content": "y = y k + y doc,tok y k = \u0174seg \u2022 o k + b seg y doc,tok = \u0174doc,tok \u2022 H doc,tok + b doc,tok",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_47",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_48@0",
            "content": "H doc,tok = w doc W y k is the predicted score corresponding to segment-scale k.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_48",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_48@1",
            "content": "y doc,tok is the predicted score corresponding to the document-scale and tokenscale.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_48",
            "start": 81,
            "end": 164,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_48@2",
            "content": "\u0174seg and b seg are weight matrix and bias for segment-scale respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_48",
            "start": 166,
            "end": 238,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_48@3",
            "content": "W doc,tok and b doc,tok are weight matrix and bias for document and tokenscales, o k is the segment-scale essay representation with the scale k.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_48",
            "start": 240,
            "end": 383,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_48@4",
            "content": "w doc is the document-scale essay representation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_48",
            "start": 385,
            "end": 433,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_48@5",
            "content": "W is the word-scale essay representation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_48",
            "start": 435,
            "end": 475,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_48@6",
            "content": "H doc,tok is the concatenation of documentscale and word-scale essay representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_48",
            "start": 477,
            "end": 561,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_49@0",
            "content": "Loss Function",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_49",
            "start": 0,
            "end": 12,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_50@0",
            "content": "We use three loss functions to train the model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_50",
            "start": 0,
            "end": 46,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_51@0",
            "content": "MSE measures the average value of square errors between predicted scores and labels, which is defined as below:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_51",
            "start": 0,
            "end": 110,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_52@0",
            "content": "M SE(y, \u0177) = 1 N (y i \u2212 \u0177i ) 2",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_52",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_53@0",
            "content": "where y i and \u0177i are the predicted score and the label for the i th essay respectively, N is the number of the essays.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_53",
            "start": 0,
            "end": 117,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_54@0",
            "content": "Similarity (SIM) measures whether two vectors are similar or dissimilar by using cosine function.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_54",
            "start": 0,
            "end": 96,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_54@1",
            "content": "A teacher will take into account the overall level distribution of all the students when rating an essay.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_54",
            "start": 98,
            "end": 202,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_54@2",
            "content": "Following such intuition, we introduce the SIM loss to the AES task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_54",
            "start": 204,
            "end": 271,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_54@3",
            "content": "In each training step, we take the predicted scores of the essays in the batch as the predicted vector y, and the labels as the label vector \u0177.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_54",
            "start": 273,
            "end": 415,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_54@4",
            "content": "The SIM loss awards the similar vector pairs to make the model think more about the correlation among the batch of essays.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_54",
            "start": 417,
            "end": 538,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_54@5",
            "content": "The SIM loss is defined as below:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_54",
            "start": 540,
            "end": 572,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_55@0",
            "content": "SIM (y, \u0177) = 1 \u2212 cos(y, \u0177) y = [y 1 , y 2 , ..., y n ] \u0177 = [\u0177 1 , \u01772 , ..., \u0177N ]",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_55",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_56@0",
            "content": "where y i and \u0177i are the predicted score and label for the i th essay respectively, N is the number of the essays.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_56",
            "start": 0,
            "end": 113,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_57@0",
            "content": "Margin Ranking (MR) measures the ranking orders for each essay pair in the batch.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_57",
            "start": 0,
            "end": 80,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_57@1",
            "content": "We intuitively introduce MR loss because the sorting property between essays is a key factor to scoring.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_57",
            "start": 82,
            "end": 185,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_57@2",
            "content": "For each batch of essays, we first enumerate all the essay pairs, and then compute the MR loss as follows.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_57",
            "start": 187,
            "end": 292,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_58@0",
            "content": "The MR loss attempts to make the model penalize wrong order.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_58",
            "start": 0,
            "end": 59,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_59@0",
            "content": "M R(y, \u0177) = 1 N max(0, \u2212r ij (y i \u2212 y j ) + b) r ij = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 1 \u0177i > \u0177j -1 \u0177i < \u0177j -sgn(y i \u2212 y j ) \u0177i = \u0177j",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_59",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_60@0",
            "content": "y i and \u0177i are the predicted score and label for the i th essay respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_60",
            "start": 0,
            "end": 76,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_60@1",
            "content": "N is the number of the essays.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_60",
            "start": 78,
            "end": 107,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_60@2",
            "content": "b is a hyper parameter, which is set to 0 in our experiment.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_60",
            "start": 109,
            "end": 168,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_60@3",
            "content": "For each sample pair (i, j), when the label \u0177i is larger than \u0177j , the predicted result y i should be larger than y j , otherwise, the pair contributes y j \u2212 y i to the loss.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_60",
            "start": 170,
            "end": 343,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_60@4",
            "content": "When \u0177i is equal to \u0177j , the loss is actually |y i \u2212 y j |.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_60",
            "start": 345,
            "end": 403,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_60@5",
            "content": "The combined loss is described as below: Loss total (y, \u0177) = \u03b1M SE(y, \u0177)+\u03b2M R(y, \u0177)+ \u03b3SIM (y, \u0177).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_60",
            "start": 405,
            "end": 501,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_61@0",
            "content": "\u03b1, \u03b2, \u03b3 are weight parameters which are tuned according to the performance on develop set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_61",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_62@0",
            "content": "Experiment",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_62",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_63@0",
            "content": "Data and Evaluation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_63",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_64@0",
            "content": "ASAP data set is widely used in the AES task, which contains eight different prompts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_64",
            "start": 0,
            "end": 84,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_64@1",
            "content": "A detailed description can be seen in Table 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_64",
            "start": 86,
            "end": 131,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_64@2",
            "content": "For each prompt, the WordPiece length indicates the smallest number which is bigger than the length of 90% of the essays in terms of WordPiece number.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_64",
            "start": 133,
            "end": 282,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_64@3",
            "content": "We evaluate the scoring performance using QWK on ASAP data set, which is the official metric in the ASAP competition.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_64",
            "start": 284,
            "end": 400,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_65@0",
            "content": "CRP data set provides 2834 excerpts from several time periods and reading ease scores which range from -3.68 to 1.72.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_65",
            "start": 0,
            "end": 116,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_65@1",
            "content": "The average length of the excerpts is 175 and the WordPiece length is 252.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_65",
            "start": 118,
            "end": 191,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_65@2",
            "content": "We also use 5-fold cross validation to evaluate our system with a 60/20/20 split for train, develop and test sets on CRP data set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_65",
            "start": 193,
            "end": 322,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_65@3",
            "content": "As the RMSE mertic is used in CRP competition, we also use it to evaluate our system in ease score prediction task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_65",
            "start": 324,
            "end": 438,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_66@0",
            "content": "Baseline",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_66",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_67@0",
            "content": "The baseline models for comparison are described as follows.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_67",
            "start": 0,
            "end": 59,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_68@0",
            "content": "EASE 4 is the best open-source system that participated in the ASAP competition and ranked the third place among 154 participants.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_68",
            "start": 0,
            "end": 129,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_68@1",
            "content": "EASE uses regression techniques with handcrafted features.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_68",
            "start": 131,
            "end": 188,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_68@2",
            "content": "Results of EASE with the settings of Support Vector Regression (SVR) and Bayesian Linear Ridge Regression (BLRR) are reported in (Phandi et al., 2015).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_68",
            "start": 190,
            "end": 340,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_69@0",
            "content": "CNN+RNN Various deep neural networks based on CNN and RNN for AES are studied by (Taghipour and Ng, 2016).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_69",
            "start": 0,
            "end": 105,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_69@1",
            "content": "They combine CNN ensembles and LSTM ensembles over 10 runs and get the best result in their experiment.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_69",
            "start": 107,
            "end": 209,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_70@0",
            "content": "Hierarchical LSTM-CNN-Attention (Dong et al., 2017) builds a hierarchical sentencedocument model, which uses CNN to encode sentences and LSTM to encode texts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_70",
            "start": 0,
            "end": 157,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_70@1",
            "content": "The attention mechanism is used to automatically determine the relative weights of words and sentences in generating sentence representations and text representations respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_70",
            "start": 159,
            "end": 338,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_70@2",
            "content": "They obtain the state-of-theart result among all neural models without pretraining.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_70",
            "start": 340,
            "end": 422,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_71@0",
            "content": "SKIPFLOW (Tay et al., 2018) proposes to use SKIPFLOW mechanism to model the relationships between snapshots of the hidden representations of an LSTM.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_71",
            "start": 0,
            "end": 148,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_71@1",
            "content": "The work of (Tay et al., 2018) also obtains the state-of-the-art result among all neural models without pre-training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_71",
            "start": 150,
            "end": 266,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_72@0",
            "content": "Dilated LSTM with Reinforcement Learning (Wang et al., 2018) proposes a method using a dilated LSTM network in a reinforcement learning framework.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_72",
            "start": 0,
            "end": 145,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_72@1",
            "content": "They attempt to directly optimize the model using the QWK metric which considers the rating schema.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_72",
            "start": 147,
            "end": 245,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_73@0",
            "content": "BERT+SST+DAT and HA-LSTM+SST+DAT proposes to use two selfsupervised tasks and a domain adversarial training technique to optimize their training, which is the first work to use pre-trained language model to outperform LSTM based methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_73",
            "start": 0,
            "end": 236,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_73@1",
            "content": "They experiment with both hierarchical LSTM model and BERT in their work, which are HA\u2212LST M +SST +DAT and BERT + SST + DAT respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_73",
            "start": 238,
            "end": 374,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_74@0",
            "content": "BERT 2 (Yang et al., 2020) combine regression and ranking to fine-tune BERT model which also outperform LSTM based methods and even obtain the new state-of-the-art.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_74",
            "start": 0,
            "end": 163,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_75@0",
            "content": "Settings",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_75",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_76@0",
            "content": "To compare with the baseline models and further study the effectiveness of multi-scale essay representations, losses and transfer learning, we conduct the following experiments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_76",
            "start": 0,
            "end": 176,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_77@0",
            "content": "Multi-Scale Models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_77",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_77@1",
            "content": "These models are optimized with MSE loss, and BERT-DOC represents essays with document-scale features based on BERT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_77",
            "start": 20,
            "end": 135,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_77@2",
            "content": "BERT-TOK represents essays with token-scale features based on BERT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_77",
            "start": 137,
            "end": 203,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_77@3",
            "content": "BERT-DOC-TOK represents essays with both document-scale and token-scale features based on BERT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_77",
            "start": 205,
            "end": 299,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_77@4",
            "content": "BERT-DOC-TOK-SEG represents essays with documentscale, token-scale, and multiple segment-scale features based on BERT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_77",
            "start": 301,
            "end": 418,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_77@5",
            "content": "Longformer (Beltagy et al., 2020) is an extension for transformers with an attention mechanism that scales linearly with sequence length, making it easy to process long documents.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_77",
            "start": 420,
            "end": 598,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_77@6",
            "content": "We conduct experiments to show that our multi-scale features also works with Longformer and can further improve the performance in long text tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_77",
            "start": 600,
            "end": 746,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_77@7",
            "content": "Longformer-DOC-TOK-SEG uses document-scale, token-scale, and multiple segmentscale features to represent essays, but based on Longformer instead of BERT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_77",
            "start": 748,
            "end": 900,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_77@8",
            "content": "Longformer-DOC represents essays with document-scale features based on Longformer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_77",
            "start": 902,
            "end": 983,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_78@0",
            "content": "Models with Transfer Learning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_78",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_78@1",
            "content": "To transfer learn from the out-domain essays 5 , we additionally employ a pre-training stage, which is similar to the work of (Song et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_78",
            "start": 31,
            "end": 176,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_78@2",
            "content": "In this stage, we scale all the labels of essays from out-domain data into range 0-1 and pre-train them with MSE loss.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_78",
            "start": 178,
            "end": 295,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_78@3",
            "content": "After the pre-training stage, we continue to finetune the model on in-domain essays.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_78",
            "start": 297,
            "end": 380,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_78@4",
            "content": "Tran-BERT-MS has the same modules as BERT-DOC-TOK-SEG with pre-training on out-domain data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_78",
            "start": 382,
            "end": 472,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_78@5",
            "content": "MS means multiple scale features.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_78",
            "start": 474,
            "end": 506,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_79@0",
            "content": "Models with Multiple Losses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_79",
            "start": 0,
            "end": 27,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_79@1",
            "content": "Based on Tran-BERT-MS model, we explore the performance of adding multiple loss functions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_79",
            "start": 29,
            "end": 118,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_79@2",
            "content": "Tran-BERT-MS-ML additionally employs MR loss and SIM loss.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_79",
            "start": 120,
            "end": 177,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_79@3",
            "content": "ML means multiple losses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_79",
            "start": 179,
            "end": 203,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_79@4",
            "content": "Tran-BERT-MS-ML-R incorporates R-Drop strategy in training based on Tran-BERT-MS-ML model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_79",
            "start": 205,
            "end": 294,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_80@0",
            "content": "For the proposed model architecture which is depicted in Figure 1, the BERT model in the left part are shared by the document-scale and token-scale essay representations, and the other BERT model in the right part are shared by all segment-scale essay representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_80",
            "start": 0,
            "end": 267,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_80@1",
            "content": "We use the \"bert-base-uncased\" which includes 12 transformer layers and the hidden size is 768.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_80",
            "start": 269,
            "end": 363,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_80@2",
            "content": "In the training stage, we freeze all the layers in the BERT models except the last layer, which is more task related than other layers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_80",
            "start": 365,
            "end": 499,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_80@3",
            "content": "The Longformer model used in our work is \"longformer-base-4096\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_80",
            "start": 501,
            "end": 564,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_80@4",
            "content": "For the MR loss, we set b to 0.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_80",
            "start": 566,
            "end": 596,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_80@5",
            "content": "The weights \u03b1, \u03b2 and \u03b3 are tuned according to the performance on develop set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_80",
            "start": 598,
            "end": 674,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_80@6",
            "content": "We use Adam optimizer (Kingma and Ba, 2015) to fine-tune model parameters in an end-to-end fashion with learning rate of 6e-5, \u03b21=0.9, \u03b22=0.999, L2 weight decay of 0.005.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_80",
            "start": 676,
            "end": 845,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_80@7",
            "content": "The coefficient weight \u03b1 in R-Drop is",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_80",
            "start": 847,
            "end": 883,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_80@8",
            "content": "9. We set the batch size to 32.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_80",
            "start": 885,
            "end": 915,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_80@9",
            "content": "We use dropout in the training stage and the drop rate is set to 0.1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_80",
            "start": 917,
            "end": 985,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_80@10",
            "content": "We train all the models for 80 epochs, and select the best model according the performance on the develop set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_80",
            "start": 987,
            "end": 1096,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_80@11",
            "content": "We use a greedy search method to find the best combination of segment scales, which is shown in detail in Appendix A. Following , we perform the significance test for (Phandi et al., 2015) 0.781 0.621 0.630 0.749 0.782 0.771 0.727 0.534 0.699 2 EASE(BLRR) (Phandi et al., 2015) 0.761 0.606 0.621 0.742 0.784 0.775 0.730 0.617 0.705 3 CNN(10 runs) + LSTM(10 runs) (Taghipour and Ng, 2016) our models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_80",
            "start": 1098,
            "end": 1496,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_81@0",
            "content": "ID Models P1 P2 P3 P4 P5 P6 P7 P8 Average 1 ASE(SVR)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_81",
            "start": 0,
            "end": 51,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_82@0",
            "content": "Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_82",
            "start": 0,
            "end": 6,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_83@0",
            "content": "Table 2 shows the performance of baseline models and our proposed models with joint learning of multi-scale essay representation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_83",
            "start": 0,
            "end": 128,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_83@1",
            "content": "Table 3 shows the results of our model and the state-of-the-art models on essays in prompt 1, 2 and 8, whose averaged WordPiece lengths are longer than 510.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_83",
            "start": 130,
            "end": 285,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_84@0",
            "content": "We summarize some findings from the experiment results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_84",
            "start": 0,
            "end": 54,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_85@0",
            "content": "\u2022 Our model 12 almost obtains the published state-of-the-art for neural approaches. For the prompts 1,2 and 8, the essays in which have more than 510 tokens, we improve the result from 0.761 to 0.772. The results demonstrate the effectiveness of the proposed framework for encoding and scoring essays. Before that, the conventional way of using BERT can not surpass the performance of models 4 and 6. We further re-implement BERT 2 proposed by (Yang et al., 2020), and the performance is not so strong as the published state-of-theart like models 9, 10 and 12. Though (Uto et al., 2020) obtain a much better result(QWK 0.801), our method perform much better than their system with only neural features(QWK 0.730), which demonstrates the strong essay encoding ability of our neural approach. \u2022 Compared to the models 4 and 6, our model 11 uses multi-scale features to encode essays instead of LSTM based models, and we use the same regression loss to optimize the model. Our model simply changes the representation way and significantly improves the result from 0.764 to 0.782, which demonstrates the strong encoding ability armed by multi-scale representation for long text.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_85",
            "start": 0,
            "end": 1173,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_86@0",
            "content": "Further analysis",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_86",
            "start": 0,
            "end": 15,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_87@0",
            "content": "Multi-scale representation We further analyze the effectiveness of employing each scale essay representation to the joint learning process.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_87",
            "start": 0,
            "end": 138,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_87@1",
            "content": "5 show the performance of our models to represent essays on different feature scales, which are trained with MSE loss and without transfer learning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_87",
            "start": 140,
            "end": 287,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_87@2",
            "content": "Table 4 shows the performance on ASAP data set while Table 5 shows the performance on CRP data set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_87",
            "start": 289,
            "end": 387,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_87@3",
            "content": "The improvement of BERT-DOC-TOK-SEG over BERT-DOC, BERT-TOK, BERT-DOC-TOK are significant (p<0.0001) on CRP data set, and are significant (p<0.0001) in most cases on ASAP data set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_87",
            "start": 389,
            "end": 568,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_87@4",
            "content": "Results on both table indicates the similar findings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_87",
            "start": 570,
            "end": 622,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_88@0",
            "content": "\u2022 Combining the features from document-scale and token-scale, BERT-DOC-TOK outperforms the models BERT-DOC and BERT-TOK, which only use one scale features. This demonstrates that our proposed framework can benefit from multi-scale essay representation even with only two scales. \u2022 By additionally incorporating multiple segment-scale features, BERT-DOC-TOK-SEG performs much better than BERT-DOC-TOK. This demonstrates the effectiveness and generalization ability of our multi-scale essay representation on multiple tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_88",
            "start": 0,
            "end": 521,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_89@0",
            "content": "Average QWK Longformer-DOC 0.746 Longformer-DOC-TOK-SEG 0.771 Reasons for Effectiness of Multi-scale representation Though the experiment shows the effectiveness of multi-scale representation, we further explore the reason.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_89",
            "start": 0,
            "end": 222,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_89@1",
            "content": "We could doubt that the effectiveness comes from supporting long sequences, not the multi-scale itself.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_89",
            "start": 224,
            "end": 326,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_89@2",
            "content": "As Longformer is good at dealing with long texts, we compare the results between Longformer-DOC and Longformer-DOC-TOK-SEG.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_89",
            "start": 328,
            "end": 450,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_89@3",
            "content": "The results of the significance test show that the improvement of Longformer-DOC-TOK-SEG over Longformer-DOC are significantly (p<0.0001) in most cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_89",
            "start": 452,
            "end": 603,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_89@4",
            "content": "Performance of the two models are shown in Table 6, we get the following findings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_89",
            "start": 605,
            "end": 686,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_90@0",
            "content": "\u2022 Though Longformer-DOC supports long sequences encoding, it performs poor, which indicates us that supporting long sequence ability is not enough for a good essay scoring system. \u2022 Longformer-DOC-TOK-SEG outperforms Longformer-DOC significantly, which indicates the effectiveness of our model comes from encoding essays by multi-scale features, not only comes from the ability to deal with long texts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_90",
            "start": 0,
            "end": 401,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_91@0",
            "content": "These results are consistent with our intuition that our approach takes into account different level features of essays and predict the scores more accurately.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_91",
            "start": 0,
            "end": 158,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_91@1",
            "content": "We consider it caused by that multi-scale features are not effectively constructed in the representation layer of pre-trained model due to the lack of data for fine-tuning in the AES task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_91",
            "start": 160,
            "end": 347,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_91@2",
            "content": "Therefore, we need to explicitly model the multi-scale information of the essay data and combine it with the powerful linguistic knowledge of pre-trained model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_91",
            "start": 349,
            "end": 508,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_91@3",
            "content": "Transfer Learning with Multiple Losses and R-Drop We further explore the effectiveness of pretraining with adding multiple loss functions and employing R-Drop.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_91",
            "start": 510,
            "end": 668,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_91@4",
            "content": "As is shown in table 7, by incorporating the pre-training stage which learns the knowledge from out-domain data, Tran-BERT-MS model improves the result from 0.782 to to 0.788 compared to BERT-DOC-TOK-SEG model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_91",
            "start": 670,
            "end": 879,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_91@5",
            "content": "The model Tran-BERT-MS-ML which jointly learns with multiple loss functions further improves the performance from 0.788 to 0.790.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_91",
            "start": 881,
            "end": 1009,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_91@6",
            "content": "We consider it due to the reason that MR brings ranking information and SIM takes into account the overall score distribution information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_91",
            "start": 1011,
            "end": 1148,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_91@7",
            "content": "Diverse losses bring different but positive influence on the optimization direction and act as an ensembler.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_91",
            "start": 1150,
            "end": 1257,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_91@8",
            "content": "By employing R-Drop, Tran-BERT-MS-ML-R improves the QWK slightly, which comes from the fact that R-Drop plays a regularization role.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_91",
            "start": 1259,
            "end": 1390,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_92@0",
            "content": "Conclusion and Future Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_92",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_93@0",
            "content": "In this paper, we propose a novel multi-scale representation approach based on pre-trained language model, and employ multiple losses and transfer learning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_93",
            "start": 0,
            "end": 155,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_93@1",
            "content": "We obtain the state-of-the-art results among deep learning models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_93",
            "start": 157,
            "end": 222,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_93@2",
            "content": "In particular, multiscale representation has a very significant advantage in dealing with long text.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_93",
            "start": 224,
            "end": 323,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_94@0",
            "content": "One of the future directions can be exploring more efficient and soft multi-scale representation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_94",
            "start": 0,
            "end": 96,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_94@1",
            "content": "Introducing linguistic knowledge to segment a more reasonable scale may bring further improvement.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_94",
            "start": 98,
            "end": 195,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_95@0",
            "content": "Dimitrios Alikaniotis, Helen Yannakoudakis, Marek Rei, Automatic text scoring using neural networks, 2016, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_95",
            "start": 0,
            "end": 196,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_96@0",
            "content": "Yigal Attali, Jill Burstein, Automated essay scoring with e-rater\u00ae v.2. The Journal of Technology, 2006, Learning, and Assessment, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_96",
            "start": 0,
            "end": 131,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_97@0",
            "content": "Iz Beltagy, Matthew Peters, Arman Cohan, Longformer: The long-document transformer, 2020, arXiv: Computation and Language, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_97",
            "start": 0,
            "end": 123,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_98@0",
            "content": "Yue Cao, Hanqi Jin, Xiaojun Wan, Zhiwei Yu, Domain-adaptive neural automated essay scoring, 2020, SIGIR '20: Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_98",
            "start": 0,
            "end": 212,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_99@0",
            "content": "Hongbo Chen, Ben He, Automated essay scoring by maximizing human-machine agreement, 2013, Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_99",
            "start": 0,
            "end": 178,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_100@0",
            "content": "J Cohen, Weighted kappa: nominal scale agreement provision for scaled disagreement partial credit, 1968, Psychological bulletin, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_100",
            "start": 0,
            "end": 129,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_101@0",
            "content": "M\u0203d\u0203lina Cozma, Andrei Butnaru, Radu Tudor Ionescu, Automated essay scoring with string kernels and word embeddings, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_101",
            "start": 0,
            "end": 212,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_102@0",
            "content": "Tirthankar Dasgupta, Abir Naskar, Rupsa Saha, Lipika Dey, Augmenting textual qualitative features in deep convolution recurrent neural network for automatic essay scoring, 2018, Proceedings of the 5th Workshop on Natural Language Processing Techniques for Educational Applications, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_102",
            "start": 0,
            "end": 282,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_103@0",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, Bert: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_103",
            "start": 0,
            "end": 294,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_104@0",
            "content": "Fei Dong, Yue Zhang, Automatic features for essay scoring -an empirical study, 2016, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_104",
            "start": 0,
            "end": 173,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_105@0",
            "content": "Fei Dong, Yue Zhang, Jie Yang, Attentionbased recurrent convolutional neural network for automatic essay scoring, 2017, Proceedings of the 21st Conference on Computational Natural Language Learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_105",
            "start": 0,
            "end": 199,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_106@0",
            "content": "Youmna Farag, Helen Yannakoudakis, Ted Briscoe, Neural automated essay scoring and coherence modeling for adversarially crafted input, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technolog, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_106",
            "start": 0,
            "end": 282,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_107@0",
            "content": "Cancan Jin, Ben He, Kai Hui, Le Sun, Tdnn: A two-stage deep neural network for promptindependent automated essay scoring, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_107",
            "start": 0,
            "end": 217,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_108@0",
            "content": "P Diederik, Jimmy Kingma,  Ba, Adam: A method for stochastic optimization, 2015, 3rd International Conference for Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_108",
            "start": 0,
            "end": 140,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_109@0",
            "content": "S Leah,  Larkey, Automatic essay grading using text categorization techniques, 1998, SIGIR '98 Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieva, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_109",
            "start": 0,
            "end": 214,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_110@0",
            "content": "UNKNOWN, None, 2021, R-drop: Regularized dropout for neural networks, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_110",
            "start": 0,
            "end": 70,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_111@0",
            "content": "Elijah Mayfield, Alan Black, Should you fine-tune bert for automated essay scoring?, 2020, Proceedings of the 15th Workshop on Innovative Use of NLP for Building Educational Applications, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_111",
            "start": 0,
            "end": 188,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_112@0",
            "content": "Andriy Mulyar, Elliot Schumacher, Masoud Rouhizadeh, Mark Dredze, Phenotyping of clinical notes with improved document classification models using contextualized neural language models, 2019, 33rd Conference on Neural Information Processing Systems (NeurIPS), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_112",
            "start": 0,
            "end": 260,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_113@0",
            "content": "Peter Phandi, Ming Kian, Hwee Tou Chai,  Ng, Flexible domain adaptation for automated essay scoring using correlated linear regression, 2015, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_113",
            "start": 0,
            "end": 230,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_114@0",
            "content": "Robert Ridley, Liang He, Xinyu Dai, Shujian Huang, Jiajun Chen, Automated cross-prompt scoring of essay traits, 2021, Proceedings of the AAAI Conference on Artificial Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_114",
            "start": 0,
            "end": 181,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_115@0",
            "content": "Pedro Rodriguez, Amir Jafari, Christopher Ormerod, Language models and automated essay scoring, 2019, arXiv: Computation and Language, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_115",
            "start": 0,
            "end": 135,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_116@0",
            "content": "M Lawrence, Tahung Rudner,  Liang, Automated essay scoring using bayes' theorem, 2002, The Journal of Technology, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_116",
            "start": 0,
            "end": 114,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_117@0",
            "content": "Wei Song, Kai Zhang, Ruiji Fu, Lizhen Liu, Ting Liu, Miaomiao Cheng, Multi-stage pre-training for automated chinese essay scoring, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_117",
            "start": 0,
            "end": 233,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_118@0",
            "content": "Kaveh Taghipour, Hwee Tou Ng, A neural approach to automated essay scoring, 2016, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_118",
            "start": 0,
            "end": 170,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_119@0",
            "content": "Yi Tay, Minh Phan, Anh Luu, Siu Cheung Tuan,  Hui, Skipflow:incorporating neural coherence features for end-to-end automatic text scoring, 2018, Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_119",
            "start": 0,
            "end": 222,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_120@0",
            "content": "Masaki Uto, Yikuan Xie, Maomi Ueno, Neural automated essay scoring incorporating handcrafted features, 2020, Proceedings of the 28th International Conference on Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_120",
            "start": 0,
            "end": 188,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_121@0",
            "content": "Yucheng Wang, Zhongyu Wei, Yaqian Zhou, Xuanjing Huang, Automatic essay scoring incorporating rating schema via reinforcement learning, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_121",
            "start": 0,
            "end": 230,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_122@0",
            "content": "Ruosong Yang, Jiannong Cao, Zhiyuan Wen, Youzheng Wu, Xiaodong He, Enhancing automated essay scoring performance via fine-tuning pre-trained language models with combination of regression and ranking, 2020, Findings of the Association for Computational Linguistics: EMNLP 2020, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_122",
            "start": 0,
            "end": 278,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_123@0",
            "content": "Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, V Quoc,  Le, Xlnet: Generalized autoregressive pretraining for language understanding, 2019, 33rd Conference on Neural Information Processing Systems (NeurIPS), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_123",
            "start": 0,
            "end": 238,
            "label": {}
        },
        {
            "ix": "218-ARR_v1_124@0",
            "content": "Helen Yannakoudakis, Ted Briscoe, Ben Medlock, A new dataset and method for automatically grading esol texts, 2011, HLT '11 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "218-ARR_v1_124",
            "start": 0,
            "end": 242,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "218-ARR_v1_0",
            "tgt_ix": "218-ARR_v1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_0",
            "tgt_ix": "218-ARR_v1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_1",
            "tgt_ix": "218-ARR_v1_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_1",
            "tgt_ix": "218-ARR_v1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_0",
            "tgt_ix": "218-ARR_v1_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_2",
            "tgt_ix": "218-ARR_v1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_4",
            "tgt_ix": "218-ARR_v1_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_5",
            "tgt_ix": "218-ARR_v1_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_6",
            "tgt_ix": "218-ARR_v1_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_8",
            "tgt_ix": "218-ARR_v1_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_9",
            "tgt_ix": "218-ARR_v1_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_10",
            "tgt_ix": "218-ARR_v1_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_11",
            "tgt_ix": "218-ARR_v1_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_12",
            "tgt_ix": "218-ARR_v1_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_3",
            "tgt_ix": "218-ARR_v1_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_3",
            "tgt_ix": "218-ARR_v1_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_3",
            "tgt_ix": "218-ARR_v1_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_3",
            "tgt_ix": "218-ARR_v1_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_3",
            "tgt_ix": "218-ARR_v1_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_3",
            "tgt_ix": "218-ARR_v1_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_3",
            "tgt_ix": "218-ARR_v1_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_3",
            "tgt_ix": "218-ARR_v1_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_3",
            "tgt_ix": "218-ARR_v1_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_3",
            "tgt_ix": "218-ARR_v1_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_3",
            "tgt_ix": "218-ARR_v1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_0",
            "tgt_ix": "218-ARR_v1_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_14",
            "tgt_ix": "218-ARR_v1_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_14",
            "tgt_ix": "218-ARR_v1_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_16",
            "tgt_ix": "218-ARR_v1_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_17",
            "tgt_ix": "218-ARR_v1_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_15",
            "tgt_ix": "218-ARR_v1_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_15",
            "tgt_ix": "218-ARR_v1_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_15",
            "tgt_ix": "218-ARR_v1_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_15",
            "tgt_ix": "218-ARR_v1_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_14",
            "tgt_ix": "218-ARR_v1_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_18",
            "tgt_ix": "218-ARR_v1_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_20",
            "tgt_ix": "218-ARR_v1_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_21",
            "tgt_ix": "218-ARR_v1_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_22",
            "tgt_ix": "218-ARR_v1_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_23",
            "tgt_ix": "218-ARR_v1_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_24",
            "tgt_ix": "218-ARR_v1_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_25",
            "tgt_ix": "218-ARR_v1_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_26",
            "tgt_ix": "218-ARR_v1_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_27",
            "tgt_ix": "218-ARR_v1_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_28",
            "tgt_ix": "218-ARR_v1_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_29",
            "tgt_ix": "218-ARR_v1_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_30",
            "tgt_ix": "218-ARR_v1_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_31",
            "tgt_ix": "218-ARR_v1_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_32",
            "tgt_ix": "218-ARR_v1_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_33",
            "tgt_ix": "218-ARR_v1_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_34",
            "tgt_ix": "218-ARR_v1_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_35",
            "tgt_ix": "218-ARR_v1_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_36",
            "tgt_ix": "218-ARR_v1_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_37",
            "tgt_ix": "218-ARR_v1_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_38",
            "tgt_ix": "218-ARR_v1_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_39",
            "tgt_ix": "218-ARR_v1_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_40",
            "tgt_ix": "218-ARR_v1_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_41",
            "tgt_ix": "218-ARR_v1_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_42",
            "tgt_ix": "218-ARR_v1_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_14",
            "tgt_ix": "218-ARR_v1_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_43",
            "tgt_ix": "218-ARR_v1_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_45",
            "tgt_ix": "218-ARR_v1_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_46",
            "tgt_ix": "218-ARR_v1_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_47",
            "tgt_ix": "218-ARR_v1_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_44",
            "tgt_ix": "218-ARR_v1_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_44",
            "tgt_ix": "218-ARR_v1_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_44",
            "tgt_ix": "218-ARR_v1_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_44",
            "tgt_ix": "218-ARR_v1_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_44",
            "tgt_ix": "218-ARR_v1_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_14",
            "tgt_ix": "218-ARR_v1_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_48",
            "tgt_ix": "218-ARR_v1_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_50",
            "tgt_ix": "218-ARR_v1_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_51",
            "tgt_ix": "218-ARR_v1_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_52",
            "tgt_ix": "218-ARR_v1_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_53",
            "tgt_ix": "218-ARR_v1_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_54",
            "tgt_ix": "218-ARR_v1_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_55",
            "tgt_ix": "218-ARR_v1_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_56",
            "tgt_ix": "218-ARR_v1_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_57",
            "tgt_ix": "218-ARR_v1_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_58",
            "tgt_ix": "218-ARR_v1_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_59",
            "tgt_ix": "218-ARR_v1_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_60",
            "tgt_ix": "218-ARR_v1_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_49",
            "tgt_ix": "218-ARR_v1_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_49",
            "tgt_ix": "218-ARR_v1_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_49",
            "tgt_ix": "218-ARR_v1_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_49",
            "tgt_ix": "218-ARR_v1_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_49",
            "tgt_ix": "218-ARR_v1_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_49",
            "tgt_ix": "218-ARR_v1_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_49",
            "tgt_ix": "218-ARR_v1_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_49",
            "tgt_ix": "218-ARR_v1_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_49",
            "tgt_ix": "218-ARR_v1_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_49",
            "tgt_ix": "218-ARR_v1_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_49",
            "tgt_ix": "218-ARR_v1_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_49",
            "tgt_ix": "218-ARR_v1_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_49",
            "tgt_ix": "218-ARR_v1_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_0",
            "tgt_ix": "218-ARR_v1_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_61",
            "tgt_ix": "218-ARR_v1_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_62",
            "tgt_ix": "218-ARR_v1_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_62",
            "tgt_ix": "218-ARR_v1_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_64",
            "tgt_ix": "218-ARR_v1_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_63",
            "tgt_ix": "218-ARR_v1_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_63",
            "tgt_ix": "218-ARR_v1_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_63",
            "tgt_ix": "218-ARR_v1_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_62",
            "tgt_ix": "218-ARR_v1_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_65",
            "tgt_ix": "218-ARR_v1_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_67",
            "tgt_ix": "218-ARR_v1_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_68",
            "tgt_ix": "218-ARR_v1_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_69",
            "tgt_ix": "218-ARR_v1_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_70",
            "tgt_ix": "218-ARR_v1_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_71",
            "tgt_ix": "218-ARR_v1_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_72",
            "tgt_ix": "218-ARR_v1_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_73",
            "tgt_ix": "218-ARR_v1_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_66",
            "tgt_ix": "218-ARR_v1_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_66",
            "tgt_ix": "218-ARR_v1_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_66",
            "tgt_ix": "218-ARR_v1_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_66",
            "tgt_ix": "218-ARR_v1_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_66",
            "tgt_ix": "218-ARR_v1_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_66",
            "tgt_ix": "218-ARR_v1_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_66",
            "tgt_ix": "218-ARR_v1_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_66",
            "tgt_ix": "218-ARR_v1_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_66",
            "tgt_ix": "218-ARR_v1_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_62",
            "tgt_ix": "218-ARR_v1_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_74",
            "tgt_ix": "218-ARR_v1_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_76",
            "tgt_ix": "218-ARR_v1_77",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_77",
            "tgt_ix": "218-ARR_v1_78",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_78",
            "tgt_ix": "218-ARR_v1_79",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_79",
            "tgt_ix": "218-ARR_v1_80",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_80",
            "tgt_ix": "218-ARR_v1_81",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_75",
            "tgt_ix": "218-ARR_v1_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_75",
            "tgt_ix": "218-ARR_v1_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_75",
            "tgt_ix": "218-ARR_v1_78",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_75",
            "tgt_ix": "218-ARR_v1_79",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_75",
            "tgt_ix": "218-ARR_v1_80",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_75",
            "tgt_ix": "218-ARR_v1_81",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_75",
            "tgt_ix": "218-ARR_v1_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_62",
            "tgt_ix": "218-ARR_v1_82",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_81",
            "tgt_ix": "218-ARR_v1_82",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_83",
            "tgt_ix": "218-ARR_v1_84",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_84",
            "tgt_ix": "218-ARR_v1_85",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_82",
            "tgt_ix": "218-ARR_v1_83",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_82",
            "tgt_ix": "218-ARR_v1_84",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_82",
            "tgt_ix": "218-ARR_v1_85",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_82",
            "tgt_ix": "218-ARR_v1_83",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_62",
            "tgt_ix": "218-ARR_v1_86",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_87",
            "tgt_ix": "218-ARR_v1_88",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_86",
            "tgt_ix": "218-ARR_v1_87",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_86",
            "tgt_ix": "218-ARR_v1_88",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_86",
            "tgt_ix": "218-ARR_v1_87",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_89",
            "tgt_ix": "218-ARR_v1_90",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_86",
            "tgt_ix": "218-ARR_v1_89",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_86",
            "tgt_ix": "218-ARR_v1_90",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_86",
            "tgt_ix": "218-ARR_v1_91",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_0",
            "tgt_ix": "218-ARR_v1_92",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_91",
            "tgt_ix": "218-ARR_v1_92",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_93",
            "tgt_ix": "218-ARR_v1_94",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_92",
            "tgt_ix": "218-ARR_v1_93",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_92",
            "tgt_ix": "218-ARR_v1_94",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_92",
            "tgt_ix": "218-ARR_v1_93",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "218-ARR_v1_0",
            "tgt_ix": "218-ARR_v1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_1",
            "tgt_ix": "218-ARR_v1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_2",
            "tgt_ix": "218-ARR_v1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_2",
            "tgt_ix": "218-ARR_v1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_2",
            "tgt_ix": "218-ARR_v1_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_2",
            "tgt_ix": "218-ARR_v1_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_2",
            "tgt_ix": "218-ARR_v1_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_2",
            "tgt_ix": "218-ARR_v1_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_3",
            "tgt_ix": "218-ARR_v1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_4",
            "tgt_ix": "218-ARR_v1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_4",
            "tgt_ix": "218-ARR_v1_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_5",
            "tgt_ix": "218-ARR_v1_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_5",
            "tgt_ix": "218-ARR_v1_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_6",
            "tgt_ix": "218-ARR_v1_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_7",
            "tgt_ix": "218-ARR_v1_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_8",
            "tgt_ix": "218-ARR_v1_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_8",
            "tgt_ix": "218-ARR_v1_8@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_8",
            "tgt_ix": "218-ARR_v1_8@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_8",
            "tgt_ix": "218-ARR_v1_8@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_8",
            "tgt_ix": "218-ARR_v1_8@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_9",
            "tgt_ix": "218-ARR_v1_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_9",
            "tgt_ix": "218-ARR_v1_9@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_9",
            "tgt_ix": "218-ARR_v1_9@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_9",
            "tgt_ix": "218-ARR_v1_9@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_10",
            "tgt_ix": "218-ARR_v1_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_10",
            "tgt_ix": "218-ARR_v1_10@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_10",
            "tgt_ix": "218-ARR_v1_10@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_10",
            "tgt_ix": "218-ARR_v1_10@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_11",
            "tgt_ix": "218-ARR_v1_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_11",
            "tgt_ix": "218-ARR_v1_11@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_11",
            "tgt_ix": "218-ARR_v1_11@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_11",
            "tgt_ix": "218-ARR_v1_11@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_11",
            "tgt_ix": "218-ARR_v1_11@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_12",
            "tgt_ix": "218-ARR_v1_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_13",
            "tgt_ix": "218-ARR_v1_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_14",
            "tgt_ix": "218-ARR_v1_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_15",
            "tgt_ix": "218-ARR_v1_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_16",
            "tgt_ix": "218-ARR_v1_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_17",
            "tgt_ix": "218-ARR_v1_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_18",
            "tgt_ix": "218-ARR_v1_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_19",
            "tgt_ix": "218-ARR_v1_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_20",
            "tgt_ix": "218-ARR_v1_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_20",
            "tgt_ix": "218-ARR_v1_20@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_21",
            "tgt_ix": "218-ARR_v1_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_21",
            "tgt_ix": "218-ARR_v1_21@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_22",
            "tgt_ix": "218-ARR_v1_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_23",
            "tgt_ix": "218-ARR_v1_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_23",
            "tgt_ix": "218-ARR_v1_23@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_23",
            "tgt_ix": "218-ARR_v1_23@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_23",
            "tgt_ix": "218-ARR_v1_23@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_24",
            "tgt_ix": "218-ARR_v1_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_25",
            "tgt_ix": "218-ARR_v1_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_25",
            "tgt_ix": "218-ARR_v1_25@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_26",
            "tgt_ix": "218-ARR_v1_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_26",
            "tgt_ix": "218-ARR_v1_26@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_27",
            "tgt_ix": "218-ARR_v1_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_27",
            "tgt_ix": "218-ARR_v1_27@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_27",
            "tgt_ix": "218-ARR_v1_27@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_27",
            "tgt_ix": "218-ARR_v1_27@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_28",
            "tgt_ix": "218-ARR_v1_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_29",
            "tgt_ix": "218-ARR_v1_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_29",
            "tgt_ix": "218-ARR_v1_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_29",
            "tgt_ix": "218-ARR_v1_29@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_30",
            "tgt_ix": "218-ARR_v1_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_31",
            "tgt_ix": "218-ARR_v1_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_32",
            "tgt_ix": "218-ARR_v1_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_33",
            "tgt_ix": "218-ARR_v1_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_34",
            "tgt_ix": "218-ARR_v1_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_35",
            "tgt_ix": "218-ARR_v1_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_36",
            "tgt_ix": "218-ARR_v1_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_37",
            "tgt_ix": "218-ARR_v1_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_38",
            "tgt_ix": "218-ARR_v1_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_39",
            "tgt_ix": "218-ARR_v1_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_40",
            "tgt_ix": "218-ARR_v1_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_40",
            "tgt_ix": "218-ARR_v1_40@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_41",
            "tgt_ix": "218-ARR_v1_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_42",
            "tgt_ix": "218-ARR_v1_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_43",
            "tgt_ix": "218-ARR_v1_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_43",
            "tgt_ix": "218-ARR_v1_43@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_43",
            "tgt_ix": "218-ARR_v1_43@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_44",
            "tgt_ix": "218-ARR_v1_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_45",
            "tgt_ix": "218-ARR_v1_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_46",
            "tgt_ix": "218-ARR_v1_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_46",
            "tgt_ix": "218-ARR_v1_46@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_46",
            "tgt_ix": "218-ARR_v1_46@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_46",
            "tgt_ix": "218-ARR_v1_46@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_47",
            "tgt_ix": "218-ARR_v1_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_48",
            "tgt_ix": "218-ARR_v1_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_48",
            "tgt_ix": "218-ARR_v1_48@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_48",
            "tgt_ix": "218-ARR_v1_48@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_48",
            "tgt_ix": "218-ARR_v1_48@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_48",
            "tgt_ix": "218-ARR_v1_48@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_48",
            "tgt_ix": "218-ARR_v1_48@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_48",
            "tgt_ix": "218-ARR_v1_48@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_49",
            "tgt_ix": "218-ARR_v1_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_50",
            "tgt_ix": "218-ARR_v1_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_51",
            "tgt_ix": "218-ARR_v1_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_52",
            "tgt_ix": "218-ARR_v1_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_53",
            "tgt_ix": "218-ARR_v1_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_54",
            "tgt_ix": "218-ARR_v1_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_54",
            "tgt_ix": "218-ARR_v1_54@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_54",
            "tgt_ix": "218-ARR_v1_54@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_54",
            "tgt_ix": "218-ARR_v1_54@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_54",
            "tgt_ix": "218-ARR_v1_54@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_54",
            "tgt_ix": "218-ARR_v1_54@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_55",
            "tgt_ix": "218-ARR_v1_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_56",
            "tgt_ix": "218-ARR_v1_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_57",
            "tgt_ix": "218-ARR_v1_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_57",
            "tgt_ix": "218-ARR_v1_57@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_57",
            "tgt_ix": "218-ARR_v1_57@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_58",
            "tgt_ix": "218-ARR_v1_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_59",
            "tgt_ix": "218-ARR_v1_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_60",
            "tgt_ix": "218-ARR_v1_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_60",
            "tgt_ix": "218-ARR_v1_60@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_60",
            "tgt_ix": "218-ARR_v1_60@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_60",
            "tgt_ix": "218-ARR_v1_60@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_60",
            "tgt_ix": "218-ARR_v1_60@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_60",
            "tgt_ix": "218-ARR_v1_60@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_61",
            "tgt_ix": "218-ARR_v1_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_62",
            "tgt_ix": "218-ARR_v1_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_63",
            "tgt_ix": "218-ARR_v1_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_64",
            "tgt_ix": "218-ARR_v1_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_64",
            "tgt_ix": "218-ARR_v1_64@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_64",
            "tgt_ix": "218-ARR_v1_64@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_64",
            "tgt_ix": "218-ARR_v1_64@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_65",
            "tgt_ix": "218-ARR_v1_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_65",
            "tgt_ix": "218-ARR_v1_65@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_65",
            "tgt_ix": "218-ARR_v1_65@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_65",
            "tgt_ix": "218-ARR_v1_65@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_66",
            "tgt_ix": "218-ARR_v1_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_67",
            "tgt_ix": "218-ARR_v1_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_68",
            "tgt_ix": "218-ARR_v1_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_68",
            "tgt_ix": "218-ARR_v1_68@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_68",
            "tgt_ix": "218-ARR_v1_68@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_69",
            "tgt_ix": "218-ARR_v1_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_69",
            "tgt_ix": "218-ARR_v1_69@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_70",
            "tgt_ix": "218-ARR_v1_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_70",
            "tgt_ix": "218-ARR_v1_70@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_70",
            "tgt_ix": "218-ARR_v1_70@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_71",
            "tgt_ix": "218-ARR_v1_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_71",
            "tgt_ix": "218-ARR_v1_71@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_72",
            "tgt_ix": "218-ARR_v1_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_72",
            "tgt_ix": "218-ARR_v1_72@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_73",
            "tgt_ix": "218-ARR_v1_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_73",
            "tgt_ix": "218-ARR_v1_73@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_74",
            "tgt_ix": "218-ARR_v1_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_75",
            "tgt_ix": "218-ARR_v1_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_76",
            "tgt_ix": "218-ARR_v1_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_77",
            "tgt_ix": "218-ARR_v1_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_77",
            "tgt_ix": "218-ARR_v1_77@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_77",
            "tgt_ix": "218-ARR_v1_77@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_77",
            "tgt_ix": "218-ARR_v1_77@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_77",
            "tgt_ix": "218-ARR_v1_77@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_77",
            "tgt_ix": "218-ARR_v1_77@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_77",
            "tgt_ix": "218-ARR_v1_77@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_77",
            "tgt_ix": "218-ARR_v1_77@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_77",
            "tgt_ix": "218-ARR_v1_77@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_78",
            "tgt_ix": "218-ARR_v1_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_78",
            "tgt_ix": "218-ARR_v1_78@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_78",
            "tgt_ix": "218-ARR_v1_78@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_78",
            "tgt_ix": "218-ARR_v1_78@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_78",
            "tgt_ix": "218-ARR_v1_78@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_78",
            "tgt_ix": "218-ARR_v1_78@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_79",
            "tgt_ix": "218-ARR_v1_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_79",
            "tgt_ix": "218-ARR_v1_79@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_79",
            "tgt_ix": "218-ARR_v1_79@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_79",
            "tgt_ix": "218-ARR_v1_79@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_79",
            "tgt_ix": "218-ARR_v1_79@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_80",
            "tgt_ix": "218-ARR_v1_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_80",
            "tgt_ix": "218-ARR_v1_80@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_80",
            "tgt_ix": "218-ARR_v1_80@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_80",
            "tgt_ix": "218-ARR_v1_80@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_80",
            "tgt_ix": "218-ARR_v1_80@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_80",
            "tgt_ix": "218-ARR_v1_80@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_80",
            "tgt_ix": "218-ARR_v1_80@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_80",
            "tgt_ix": "218-ARR_v1_80@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_80",
            "tgt_ix": "218-ARR_v1_80@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_80",
            "tgt_ix": "218-ARR_v1_80@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_80",
            "tgt_ix": "218-ARR_v1_80@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_80",
            "tgt_ix": "218-ARR_v1_80@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_81",
            "tgt_ix": "218-ARR_v1_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_82",
            "tgt_ix": "218-ARR_v1_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_83",
            "tgt_ix": "218-ARR_v1_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_83",
            "tgt_ix": "218-ARR_v1_83@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_84",
            "tgt_ix": "218-ARR_v1_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_85",
            "tgt_ix": "218-ARR_v1_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_86",
            "tgt_ix": "218-ARR_v1_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_87",
            "tgt_ix": "218-ARR_v1_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_87",
            "tgt_ix": "218-ARR_v1_87@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_87",
            "tgt_ix": "218-ARR_v1_87@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_87",
            "tgt_ix": "218-ARR_v1_87@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_87",
            "tgt_ix": "218-ARR_v1_87@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_88",
            "tgt_ix": "218-ARR_v1_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_89",
            "tgt_ix": "218-ARR_v1_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_89",
            "tgt_ix": "218-ARR_v1_89@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_89",
            "tgt_ix": "218-ARR_v1_89@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_89",
            "tgt_ix": "218-ARR_v1_89@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_89",
            "tgt_ix": "218-ARR_v1_89@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_90",
            "tgt_ix": "218-ARR_v1_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_91",
            "tgt_ix": "218-ARR_v1_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_91",
            "tgt_ix": "218-ARR_v1_91@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_91",
            "tgt_ix": "218-ARR_v1_91@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_91",
            "tgt_ix": "218-ARR_v1_91@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_91",
            "tgt_ix": "218-ARR_v1_91@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_91",
            "tgt_ix": "218-ARR_v1_91@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_91",
            "tgt_ix": "218-ARR_v1_91@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_91",
            "tgt_ix": "218-ARR_v1_91@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_91",
            "tgt_ix": "218-ARR_v1_91@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_92",
            "tgt_ix": "218-ARR_v1_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_93",
            "tgt_ix": "218-ARR_v1_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_93",
            "tgt_ix": "218-ARR_v1_93@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_93",
            "tgt_ix": "218-ARR_v1_93@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_94",
            "tgt_ix": "218-ARR_v1_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_94",
            "tgt_ix": "218-ARR_v1_94@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_95",
            "tgt_ix": "218-ARR_v1_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_96",
            "tgt_ix": "218-ARR_v1_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_97",
            "tgt_ix": "218-ARR_v1_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_98",
            "tgt_ix": "218-ARR_v1_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_99",
            "tgt_ix": "218-ARR_v1_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_100",
            "tgt_ix": "218-ARR_v1_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_101",
            "tgt_ix": "218-ARR_v1_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_102",
            "tgt_ix": "218-ARR_v1_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_103",
            "tgt_ix": "218-ARR_v1_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_104",
            "tgt_ix": "218-ARR_v1_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_105",
            "tgt_ix": "218-ARR_v1_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_106",
            "tgt_ix": "218-ARR_v1_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_107",
            "tgt_ix": "218-ARR_v1_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_108",
            "tgt_ix": "218-ARR_v1_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_109",
            "tgt_ix": "218-ARR_v1_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_110",
            "tgt_ix": "218-ARR_v1_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_111",
            "tgt_ix": "218-ARR_v1_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_112",
            "tgt_ix": "218-ARR_v1_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_113",
            "tgt_ix": "218-ARR_v1_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_114",
            "tgt_ix": "218-ARR_v1_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_115",
            "tgt_ix": "218-ARR_v1_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_116",
            "tgt_ix": "218-ARR_v1_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_117",
            "tgt_ix": "218-ARR_v1_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_118",
            "tgt_ix": "218-ARR_v1_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_119",
            "tgt_ix": "218-ARR_v1_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_120",
            "tgt_ix": "218-ARR_v1_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_121",
            "tgt_ix": "218-ARR_v1_121@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_122",
            "tgt_ix": "218-ARR_v1_122@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_123",
            "tgt_ix": "218-ARR_v1_123@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "218-ARR_v1_124",
            "tgt_ix": "218-ARR_v1_124@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 1334,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "position_tag_type": "from_draft",
        "doc_id": "218-ARR",
        "version": 1
    }
}