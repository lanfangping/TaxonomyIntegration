{
    "nodes": [
        {
            "ix": "202-ARR_v2_0",
            "content": "Hyperlink-induced Pre-training for Passage Retrieval in Open-domain Question Answering",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_2",
            "content": "To alleviate the data scarcity problem in training question answering systems, recent works propose additional intermediate pre-training for dense passage retrieval (DPR). However, there still remains a large discrepancy between the provided upstream signals and the downstream question-passage relevance, which leads to less improvement. To bridge this gap, we propose the HyperLink-induced Pre-training (HLP), a method to pre-train the dense retriever with the text relevance induced by hyperlink-based topology within Web documents. We demonstrate that the hyperlink-based structures of dual-link and co-mention can provide effective relevance signals for large-scale pre-training that better facilitate downstream passage retrieval. We investigate the effectiveness of our approach across a wide range of open-domain QA datasets under zero-shot, few-shot, multihop, and out-of-domain scenarios. The experiments show our HLP outperforms the BM25 by up to 7 points as well as other pre-training methods by more than 10 points in terms of top-20 retrieval accuracy under the zero-shot scenario. Furthermore, HLP significantly outperforms other pre-training methods under the other scenarios.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "202-ARR_v2_4",
            "content": "Open-domain question answering (OpenQA) aims to answer factual open questions with a large external corpus of passages. Current approaches to OpenQA usually adopt a two-stage retriever-reader paradigm (Chen et al., 2017;Zhu et al., 2021) to fetch the final answer span. The performance of OpenQA systems is largely bounded by the retriever as it determines the evidential documents for the reader to examine. Traditional retrievers, such as TF-IDF and BM25 (Robertson and Zaragoza, 2009), are considered incapable of adapting to sce-Our code and trained models are available at https: //github.com/jzhoubu/HLP.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_5",
            "content": "Letters to Santa (film)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_6",
            "content": "Human Query",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_7",
            "content": "Our HLP Query",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_8",
            "content": "The action takes place during one single Christmas Eve, when a few adults find the loves of their lives.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_9",
            "content": "ICT Query",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_10",
            "content": "The city area measures 517 km2 (200 sq mi) and comprises 18 boroughs.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_11",
            "content": "In-doc contextual Doc-wise contextual Figure 1: An example of different kinds of pseudo Q-P pairs. Underlined texts are hypertexts that linked to other Wikipedia pages. The ICT query is a random sentence originated from the passage and the WLP query is a sentence from the first section of an out-link document of the given passage. The text highlighted in green gives evidence to answer the human query, and our proposed HLP query can be a better surrogate of the human query. narios where deep semantic understanding is required. Recent works Karpukhin et al., 2020;Qu et al., 2021) show that by finetuning pre-trained language models on sufficient downstream data, dense retrievers can significantly outperform traditional term-based retrievers.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_12",
            "content": "Considering the data-hungry nature of the neural retrieval models, extensive efforts Sachan et al., 2021) have been made to design self-supervised tasks to pre-train the retriever. However, these pre-training tasks construct relevance signals largely depending on easily attainable sentence-level or document-level contextual relationships. For example, the relationship between a sentence and its originated context (shown by the ICT query in Figure 1) may not be sufficient enough to facilitate question-passage matching for the tasks of OpenQA. We also find that these pretrained retrievers still fall far behind BM25 in our pilot study on the zero-shot experiment.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_13",
            "content": "In order to address the shortcomings of the matching-oriented pre-training tasks as mentioned above, we propose a pre-training method with better surrogates of real natural question-passage (Q-P) pairs. We consider two conditions of relevance within Q-P pairs, which is similar to the process of distantly supervised retriever learning (Mintz et al., 2009;Chen et al., 2017).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_14",
            "content": "The evidence, such as entities and their corresponding relations, should exist across the query and the targeted passage as they both discuss similar facts or events related to the answer.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_15",
            "content": "should contain the answer of the query, which means that a text span within the passage can provide the information-seeking target of the query.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_16",
            "content": "In this paper, we propose HyperLink-induced Pre-training (HLP), a pre-training method to learn effective Q-P relevance induced by the hyperlink topology within naturally-occurring Web documents. Specifically, these Q-P pairs are automatically extracted from the online documents with relevance adequately designed via hyperlink-based topology to facilitate downstream retrieval for question answering. Figure 1 shows an example of comparison between the human-written query and different pseudo queries. By the guidance of hyperlinks, our HLP query hold the relevance of answer containing with the passage (query title occurs in the passage). Meanwhile, the HLP query can introduce far more effective relevance of evidence existence than other pseudo queries by deeply mining the hyperlink topology, e.g., the dual-link structure. In figure 1, both HLP query and the passage both contain information corresponding to the same fact of \"Mitja Okorn directed the film of Letters to Santa\". This makes our pseudo query low-cost and a good surrogate for the manually written query.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_17",
            "content": "Our contributions are two-fold. First, we present a hyperlink-induced relevance construction methodology that can better facilitate downstream passage retrieval for question answering, and specifically, we propose a pre-training method: Hyperlink-induced Pre-training (HLP). Second, we conduct evaluations on six popular QA datasets, investigating the effectiveness of our approach under zero-shot, few-shot, multi-hop, and out-of-domain (OOD) scenarios. The experiments show HLP outperforms BM25 in most of the cases under the zero-shot scenario and other pre-training methods under all scenarios.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_18",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "202-ARR_v2_19",
            "content": "Dense Retriever Pre-training Previous works have attempted to conduct additional pre-training for dense retrievers on various weakly supervised data. Borisov et al. (2016) and Dehghani et al. (2017) pre-trained ranking models on click-logs and BM25-induced signals respectively for web search. proposed the inverse cloze task (ICT) to pre-train a dense retrieval model, which randomly selects sentences as pseudo queries, and matched them to the passages that they originate from. Besides, proposed the pre-training task of wiki link prediction (WLP) and body first selection (BFS) tasks. Similar to our work, the WLP task also leveraged the hyperlinks within Wikipedia to construct relevant text pairs. However, as shown in figure 1, the WLP pseudo query can only ensure the weak doc-wise contextual relationship with the passage. Guu et al. (2020) et al. (2021) reveals that the QG models tend to generate questions with high lexical overlap which amplify the bias of QA dataset. Different to these studies, our method focuses on a more general setting where the retriever is only trained with the naturally occurring web documents, and has no access to any downstream datasets. 3 Hyperlink-induced Pre-training (HLP)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_20",
            "content": "In this section, we firstly discuss the background of OpenQA retrieval, then our methodology and training framework.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_21",
            "content": "Preliminaries",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "202-ARR_v2_22",
            "content": "Passage Retrieval Given a question q, passage retrieval aims to provide a set of relevant passages p from a large corpus D. Our work adopts Wikipedia as source corpus and each passage is a disjoint segment within a document from D. OpenQA Q-P Relevance For OpenQA, a passage p is considered relevant to the query q if p conveys similar facts and contains the answer to q. These two conditions of relevance, namely evidence existence and answer containing, are properly introduced into the HLP Q-P pairs under the guidance of desired hyperlink structure. We will discuss more in this section.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_23",
            "content": "To better formulate the relevance of pseudo Q-P pairs, we denote the sequence of passages within a document as A = [a 1 , a 2 , ..., a n A ] where A \u2208 D. The corresponding topical entity and the title of document A and its passage splits are denoted as e A and t A , respectively. We use m A to indicate a mention of entity e A , which is a hypertext span linking to document A. Note that the mention span m A is usually identical to the document title t A or a variant version of it. Further, we define F (p) as the entity-level factual information conveyed by the passage p, which is a set consists of the topical entity e P and the entities mentioned within passage p.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_24",
            "content": "Evidence Existence in HLP With appropriately designed hyperlink topologies, our HLP Q-P pairs guarantee the co-occurrence of entities which are presented as hypertext or topics in q and p. This is considered as evidence across the Q-P pairs:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_25",
            "content": "F (q) \u2229 F (p) \u0338 = \u2205(1)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_26",
            "content": "Furthermore, we conjecture that HLP is more likely to achieve fact-level relevance than entitylevel overlap. We conduct human evaluation in Section 6.3 and case studies in Appendix G to support this conjecture. Moreover, we demonstrate that any Q-P pair containing hyperlink-induced factual evidence, which can be represented as triples, is included in our proposed topologies, which are included in Appendix E. Answer Containing in HLP We consider the document title t Q as the information-seeking target of q. Accordingly, the relevance of answer containing can be formulated as",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_27",
            "content": "t Q \u2286 p (2)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_28",
            "content": "The rationale behind this is that both the natural question and the Wikipedia document are intended to describe related facts and events regarding a targeted object, whereas the object is an answer for a question but a topical entity for a Wikipedia document. This similarity leads us to take the document title as the information-seeking target of its context.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_29",
            "content": "Hyperlink-induced Q-P Pairs",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "202-ARR_v2_30",
            "content": "Based on analysis of how queries match their evidential passages in the NQ (Kwiatkowski et al., 2019) dataset, we propose two kinds of hyperlink topology for relevance construction: Dual-link and Co-mention. We present our exploratory data analysis on NQ dataset in Appendix C. Here we discuss the desired hyperlink topologies and the corresponding relevance of the pseudo Q-P pairs. Dual-link (DL) Among all NQ training samples, 55% of questions mention the title of their corresponding golden passage. This observation motivates us to leverage the topology of dual-link (DL) for relevance construction. We consider a passage pair (a i , b j ) follows the dual-link topology if they link to each other. An example of a DL pair (a i , b j ) is shown in Figure 2, in which passage b j mentions the title of document A as m A , satisfying the condition of answer containing:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_31",
            "content": "t A \u2248 m A and m A \u2286 b j (3)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_32",
            "content": "Further, since the passages a i and b j both mention the topical entity of the other, the entities e A and e B appear in both passages as evidence:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_33",
            "content": "{e A , e B } \u2286 F (a i ) \u2229 F (b j )(4)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_34",
            "content": "Co-mention (CM) Among all NQ training samples, about 40% of questions fail to match the duallink condition but mention the same third-party entity as their corresponding golden passages. In light of this observation, we utilize another topology of Co-mention (CM). We consider that a passage pair (c k , d l ) follows the Co-mention topology if they both link to a third-party document E and d l links to c k . Figure 2 illustrates a CM pair (c l , d k )",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_35",
            "content": "where answer containing is ensured as the title of c k occurs in d l :",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_36",
            "content": "t C \u2248 m C and m C \u2286 d l(5)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_37",
            "content": "Since both c l and d k mention a third-party entity e E , and that e C is a topical entity in c l while a mentioned entity in d k , we have entity-level evidence across c l and d k as:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_38",
            "content": "{e C , e E } \u2286 F (c k ) \u2229 F (d l )(6)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_39",
            "content": "In practice, we use sentence-level queries which contain the corresponding evidential hypertext, and we do not prepend the title to the passage in order to reduce the superficial entity-level overlap. To improve the quality of CM pairs, we filter out those with a co-mentioned entity which has a top 10% highest-ranked in-degree among the Wikipedia entity. We also present pseudo code in Appendix D to illustrate how we construct our pseudo Q-P pairs. Furthermore, we highlight that HLP has the following advantages: 1) it introduces more semantic variants and paraphrasing for better text matching.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_40",
            "content": "2) The hypertext reflects potential interests or needs of users in relevant information, which is consistent to the downstream information-seeking propose.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_41",
            "content": "Bi-encoder Training",
            "ntype": "title",
            "meta": {
                "section": "3.3"
            }
        },
        {
            "ix": "202-ARR_v2_42",
            "content": "We adopt a BERT-based bi-encoder to encode queries and passages separately into d-dimension vectors. The output representation is derived from the last hidden state of the [CLS] token and the final matching score is measured by the inner product:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_43",
            "content": "h q = BERT Q (q)([CLS]) h p = BERT P (p)([CLS]) S(p, q) = h T q \u2022 h p Let B = {\u27e8q i , p + i , p \u2212 i \u27e9} n i=1",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_44",
            "content": "be a mini-batch with n instances. Each instance contains a question q i paired with a positive passage p + i and a negative passage p \u2212 i . With in-batch negative sampling, each question q i considers all the passages in B except its own gold p + i as negatives, resulting in 2n \u2212 1 negatives per question in total. We use the negative log likelihood of the positive passage as our loss for optimization:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_45",
            "content": "L(q i , p + i , p \u2212 i,1 , ..., p \u2212 i,2n\u22121 ) = \u2212 log e S(q i ,p + i )",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_46",
            "content": "e S(q i ,p + i ) + 2n\u22121 j=1 e S(q i ,p \u2212 i,j )",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_47",
            "content": "Experimental Setup",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "202-ARR_v2_48",
            "content": "In this session, we discuss the pre-training corpus preparation, downstream datasets, the hyperparameter and the basic setup for our experiments.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_49",
            "content": "Pre-training Corpus",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "202-ARR_v2_50",
            "content": "We adopt Wikipedia as our source corpus D for pretraining as it is the largest encyclopedia covering diverse topics with good content quality and linking structures. We choose the snapshot 03-01-2021 of an English Wikipedia dump, and process it with WikiExtractor 2 to obtain clean context. After filtering out documents with blank text or a title less than three letters, following previous work (Karpukhin et al., 2020), we split the remaining documents into disjoint chunks of 100 words as passages, resulting in over 22 million passages in the end.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_51",
            "content": "Downstream Datasets",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "202-ARR_v2_52",
            "content": "We",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_53",
            "content": "Implementation Details",
            "ntype": "title",
            "meta": {
                "section": "4.3"
            }
        },
        {
            "ix": "202-ARR_v2_54",
            "content": "During the pre-training, we train the bi-encoder for 5 epochs with parameters shared, using a batch size of 400 and an Adam optimizer (Kingma and Ba, 2014) with a learning rate 2 \u00d7 10 \u22125 , linear scheduling with 10% warm-up steps. Our HLP and all the reproduced baselines are trained on 20 million Q-P pairs with in-batch negative sampling, and the best checkpoints are selected based on the average rank of gold passages evaluated on the NQ dev set.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_55",
            "content": "The pre-training takes around 3 days using eight NVIDIA V100 32GB GPUs.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_56",
            "content": "For the downstream, we use the same hyperparameters for all experiments. Specifically, we fine-tune the pre-trained models for 40 epochs with a batch size of 256 and the same optimizer and learning rate settings to the pre-training. We conduct evaluation on respective dev sets to select best checkpoints, and we use the last checkpoint if there is no dev set or test set (e.g. HotpotQA). More details can be found in the Appendix A.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_57",
            "content": "Baselines",
            "ntype": "title",
            "meta": {
                "section": "4.4"
            }
        },
        {
            "ix": "202-ARR_v2_58",
            "content": "Most existing baselines have been implemented under different experimental settings, which have a substantial effect on the retrieval performance. To ensure fairness, we reproduce several pre-training methods (ICT, WLP, BFS, and their combination) under the same experimental setting, such as batch size, base model, amount of pre-training data, and so on. The only difference between our method and the re-implemented baselines is the self-supervision signal derived from the respective pre-training samples. Our reproduced BM25 baseline is better than that reported in Karpukhin et al. (2020), and the re-implemented pre-training methods also perform better than those reported by the recent work 3 . In addition, we include the work REALM (Guu et al., 2020) as a baseline which has recently been reproduced by Sachan et al. ( 2021) using 240 GPUs and is named masked salient spans (MSS). We note that most related works gain improvements from varying downstream setting or synthetic pre-training with access to the downstream data of respective domain, which is out of the scope of our interests.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_59",
            "content": "Experiments",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "202-ARR_v2_60",
            "content": "Main Results",
            "ntype": "title",
            "meta": {
                "section": "5.1"
            }
        },
        {
            "ix": "202-ARR_v2_61",
            "content": "Table 1 shows the retrieval accuracy of different models on three popular QA datasets under zeroshot and full-set fine-tuning settings.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_62",
            "content": "Under zero-shot setting, HLP consistently outperforms BM25 except for the top-5 retrieval accuracy of TriviaQA, while all other pre-training baselines are far behind. We attribute the minor improvement over BM25 on TriviaQA to a high overlap between questions and passages, which gives term-based retriever a clear advantage. We investigate the coverage of the question tokens that appear in the gold passage and find that the overlap is indeed higher in TriviaQA (62.8%) than NQ (60.7%) and WQ (57.5%).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_63",
            "content": "After fine-tuning, all models with intermediate pre-training give better results than the vanilla DPR while our HLP achieves the best in nearly all cases. Among ICT, WLP and BFS, we observe that WLP is the most competitive with or without fine-tuning, and additional improvements can be achieved by combining three of them. This observation indicates that pre-training with diverse relevance leads to better generalization to downstream tasks, while document-wise relevance is more adaptable for the OpenQA retrieval. The advantage of documentwise relevance may come from the fact that texts in different documents are likely written by different parties, providing less superficial cues for text matching, which is beneficial for the downstream retrieval. Our HLP learns both coarse-grained document-wise relationships as well as the finegrained entity-level evidence, which results in a significant improvement.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_64",
            "content": "Few-shot Learning",
            "ntype": "title",
            "meta": {
                "section": "5.2"
            }
        },
        {
            "ix": "202-ARR_v2_65",
            "content": "To investigate the retrieval effectiveness in a more realistic scenario, we conduct experiments for few-shot learning. Specifically, we fine-tune the pre-trained models on large datasets (NQ, Triv-iaQA) with m (m \u2208 {16, 256, 1024}) samples and present the few-shot retrieval results in Table 2. With only a few hundred labeled data for fine-tuning, all the models with intermediate pretraining perform better than those without, and HLP outperforms the others by a larger margin when m is smaller. Moreover, among three reimplemented baselines, WLP gains the largest improvement with increasing number of samples, outperforming ICT and BFS when a thousand labelled samples are provided for fine-tuning.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_66",
            "content": "Multi-hop Retrieval",
            "ntype": "title",
            "meta": {
                "section": "5.4"
            }
        },
        {
            "ix": "202-ARR_v2_67",
            "content": "While HLP aims to acquires the ability in matching document-wise concepts and facts, it raises our interest in its capability for multi-hop scenarios. We evaluate our methods on HotpotQA in a single-hop manner. Specifically, for each query, we randomly selects one golden passage from the two as a positive passage and one additional passage with high TF-IDF scores as a negative passage. Our models are further fine-tuned on the HotpotQA training set and evaluated on the bridge and the comparison type questions from the development set, respectively. The results of our study are shown in Table 5 which reveals that HLP consistently outperforms others methods, with up to a 11-point improvement on top-5 retrieval accuracy of bridge questions. Furthermore, WLP yields a 4-point advantages in average over ICT and BFS on bridge questions, showing that document-wise relevance contributes to better associative abilities. We include a case study in Appendix F. Table 5: Retrieval accuracy on questions from Hot-potQA dev set, measured as the percentage of top-k retrieved passages which include both golds.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_68",
            "content": "6 Analysis",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_69",
            "content": "Ablation Study",
            "ntype": "title",
            "meta": {
                "section": "6.1"
            }
        },
        {
            "ix": "202-ARR_v2_70",
            "content": "To better understand how different key factors affect the results, we conduct ablation experiments with results shown in Table 3.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_71",
            "content": "Our proposed dual-link (DL) and co-mention (CM) Q-P pairs, provide evidence induced by different hyperlinkbased topologies. To examine their respective effectiveness, we pre-train retrievers on Q-P pairs derived from each topology and their combinations. We present zero-shot retrieval results in Table 3, which show that retrievers pre-trained on DL pairs has a distinct advantage over that on CM pairs, while combining both gives extra improvement. Negative Passage In practice, negative sampling is essential for learning a high-quality encoder. Besides in-batch negative, our reported HLP employs one additional negative for each query. We further explore the impact of the additional negatives during pre-training. In our ablation study, pre-training with additional negatives improves the results significantly, which may be attributed to using more in-batch pairs for text matching. More details on implementation and negative sampling strategies can be found in Appendix B.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_72",
            "content": "Analysis on Q-P Overlap",
            "ntype": "title",
            "meta": {
                "section": "6.2"
            }
        },
        {
            "ix": "202-ARR_v2_73",
            "content": "We carry out extensive analysis on the Q-P lexical overlap in the task of retrieval. Specifically, we tokenize q, p using the BERT tokenizer and measure the Q-P overlap as the proportion of the question tokens that appear in the corresponding passage. Based on the degree of Q-P overlap, we divided the NQ dev set into five categories for further analysis. Distribution of Q-P Overlap Figure 3 shows both the and the retrieved pairs of HLP have a more similar overlap distribution with the downstream NQ dataset than the other methods, which implies the consistency between the relevance provided by HLP and that in real informationseeking scenario. Retrieval Performance vs. Q-P Overlap Figure 4 shows the top-20 retrieval accuracy on the samples with varying degrees of Q-P overlap. Both figures show that the retrievers are more likely to return answer-containing passages when there is higher Q-P overlap, suggesting that all these models can exploit lexical overlap for passage retrieval. Under the zero-shot setting, HLP outperforms all the methods except BM25 when r is larger than 0.8, which reflects the strong reasoning ability of HLP and the overlap-dependent nature of the termbased retrievers. After fine-tuning, models with additional pre-training perform better than the vanilla DPR while HLP outperforms all other methods in most of the cases. It is important to note that HLP is pre-trained on more high-overlap text pairs while it performs better than all the other methods when fewer overlaps are provided. We speculate that this is because the overlapping in HLP Q-P pairs mostly comes from the factual information, such as entity, which introduces fewer superficial cues, allowing for better adaptation to the downstream cases.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_74",
            "content": "Human Evaluation on Q-P pairs",
            "ntype": "title",
            "meta": {
                "section": "6.3"
            }
        },
        {
            "ix": "202-ARR_v2_75",
            "content": "We conduct human evaluation to investigate the proportion of Q-P pairs that convey the similar factlevel information. Specially, we randomly selected one hundred examples from our constructed Q-P pairs and asked annotators to identify whether the query and the corresponding passage convey similar facts. Each case is evaluated by three annotators and the result is determined by their votes. Our results are shown in",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_76",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "7"
            }
        },
        {
            "ix": "202-ARR_v2_77",
            "content": "This paper proposes Hyperlink-induced Pretraining (HLP), a pre-training method for OpenQA passage retrieval by leveraging the online textual relevance induced by hyperlink-based topology. Our experiments show that HLP gains significant improvements across multiple QA datasets under different scenarios, consistently outperforming other pre-training methods. Our method provides insights into OpenQA passage retrieval by analyzing the underlying bi-text relevance. Future work involves addressing tasks like MS MARCO where the granularity of the information-seeking target is at the passage level.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_78",
            "content": "For the pre-training, all models we reproduced are trained with 20 million Q-P pairs. Specifically, our reported HLP is trained on the combination of 10 million DL pairs and 10 million CM pairs while the HLP (DL) and HLP (CM) reported in",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_79",
            "content": "We discuss how we conduct data analysis to determine the hyperlink-based topology. Driven by a strong interest in what roles the Q-P overlapping spans play, we conduct exploratory data analysis on the widely-used NQ dataset. Specifically, we extract all entities and mentions from the Q-P pairs using TagMe (Ferragina and Scaiella, 2010) for further investigation. We observe about 55% queries q either explicitly mentions the titles of p or successfully links to the document via TagMe. This observation motivates us to construct the dual-link topology where the pseudo queries q mention p via a hypertext. Moreover, we observe about 45% queries q do not mention the titles of q but instead they share the same mentions. This encourages us to adopt the co-mention topology where the pseudo q and p both mention a third-party document through hypertext.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_80",
            "content": "Algorithm 1: HLP Pairs Identification Notation: q, p \u2190 Wikipedia passages t Q \u2190 Topical entity of passage q M(q) \u2190 The set of entities mentioned in q d in (q) \u2190 in-degree of the Wikipedia entity t Q K \u2190 in-degree threshold for CM pairs Def IsDL(q, p):",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_81",
            "content": "if t P \u2208 M(q) & t Q \u2208 M(p) then return 1 else return 0 ; Def IsCM(q, p): foreach m \u2208 M(q) do if d in (m) < K & m \u2208 M (p) & t Q \u2208 M (p) then return 1 else return 0 E Fact-level Evidence Reduction",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_82",
            "content": "Intuitively, we assume any mentioned entity, let's say e Y mentioned in a Wikipedia document X, is used to describe the topical entity e X of this document. In other words, e Y is likely to attend in a topically relevant fact or event related to e X , which can be represented as a triple <e X , r XY , e Y > where r XY is a latent relation between e X and e Y . Given any passage pair (q, p) from Wikipedia, we consider q and p have fact-level evidence if they both entail a fact that can be represented as a triple, let's say <e X , r XY , e Y >. Further, if both passages q and p contain representative hypertext or topic of e X and e Y , we consider such fact-level evidence can be induced by hyperlink-based topology, namely hyperlink-induced fact. Below we show that any Q-P pair with hyperlink-induced fact while satisfying answer containing is within either DL or CM hyperlink-based topology.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_83",
            "content": "Following the example above, given q and p containing a factual triple <e X , r XY , e Y >, we have facts <e Q , r QX , e X >, <e Q , r QY , e Y > at q-side while <e P , r P X , e X >, <e P , r P Y , e Y > at p-side. Further, p entails <e P , r P Q , e Q > because of the answer containing property.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_84",
            "content": "Case1: e P = e X or e P = e Y . Then q entails facts <e Q , r QP , e P >. Note that r QP is likely but not necessarily to be identical to r P Q in p. In this case, (q, p) fits in the Dual-link topology in our definition.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_85",
            "content": "Case2: e P \u0338 = e X and e P \u0338 = e Y . Then given the facts <e Q , r QX , e X > at q-side, and <e P , r P X , e X > at p-side, (q, p) fits in the Co-mention topology.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_86",
            "content": "We evaluate HLP on multi-hop scenario where knowledge from different documents need to be associated. Besides significant improvements shown in Table 5, we conduct case study to investigate its capability on knowledge-intensive retrieval. In Table 8, a complex question is proposed, requiring the retriever firstly to retrieve the document \"Apple Remote\" and then \"Front Row (software)\". HLP successfully retrieves both golds in the top-10 retrieved passages while the vanilla DPR fails. We find 6 items retrieved by HLP are related to the brand \"Apple\" while 4 by DPR, which indicates stronger comprehension and associative ability of HLP.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_87",
            "content": "We present case studies on the constructed HLP Q-P pairs in Table 9 and Table 10. As we can see,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v2_88",
            "content": "Jonathan Berant, Andrew Chou, Roy Frostig, Percy Liang, Semantic parsing on Freebase from question-answer pairs, 2013, Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "Jonathan Berant",
                    "Andrew Chou",
                    "Roy Frostig",
                    "Percy Liang"
                ],
                "title": "Semantic parsing on Freebase from question-answer pairs",
                "pub_date": "2013",
                "pub_title": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v2_89",
            "content": "Alexey Borisov, Ilya Markov, Pavel Maarten De Rijke,  Serdyukov, A neural click model for web search, 2016-04-11, Proceedings of the 25th International Conference on World Wide Web, WWW 2016, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Alexey Borisov",
                    "Ilya Markov",
                    "Pavel Maarten De Rijke",
                    " Serdyukov"
                ],
                "title": "A neural click model for web search",
                "pub_date": "2016-04-11",
                "pub_title": "Proceedings of the 25th International Conference on World Wide Web, WWW 2016",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v2_90",
            "content": "Wei-Cheng Chang, Yu Felix, Yin-Wen Chang, Yiming Yang, Sanjiv Kumar, Pre-training tasks for embedding-based large-scale retrieval, 2019, International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "Wei-Cheng Chang",
                    "Yu Felix",
                    "Yin-Wen Chang",
                    "Yiming Yang",
                    "Sanjiv Kumar"
                ],
                "title": "Pre-training tasks for embedding-based large-scale retrieval",
                "pub_date": "2019",
                "pub_title": "International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v2_91",
            "content": "Danqi Chen, Adam Fisch, Jason Weston, Antoine Bordes, Reading Wikipedia to answer opendomain questions, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Danqi Chen",
                    "Adam Fisch",
                    "Jason Weston",
                    "Antoine Bordes"
                ],
                "title": "Reading Wikipedia to answer opendomain questions",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "202-ARR_v2_92",
            "content": "Mostafa Dehghani, Hamed Zamani, Aliaksei Severyn, Jaap Kamps, W Croft, Neural ranking models with weak supervision, 2017-08-07, Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Mostafa Dehghani",
                    "Hamed Zamani",
                    "Aliaksei Severyn",
                    "Jaap Kamps",
                    "W Croft"
                ],
                "title": "Neural ranking models with weak supervision",
                "pub_date": "2017-08-07",
                "pub_title": "Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v2_93",
            "content": "Paolo Ferragina, Ugo Scaiella, Tagme: on-thefly annotation of short text fragments (by wikipedia entities), 2010, Proceedings of the 19th ACM international conference on Information and knowledge management, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "Paolo Ferragina",
                    "Ugo Scaiella"
                ],
                "title": "Tagme: on-thefly annotation of short text fragments (by wikipedia entities)",
                "pub_date": "2010",
                "pub_title": "Proceedings of the 19th ACM international conference on Information and knowledge management",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v2_94",
            "content": "Ana Suchin Gururangan, Swabha Marasovi\u0107, Kyle Swayamdipta, Iz Lo, Doug Beltagy, Noah Downey,  Smith, 2020. Don't stop pretraining: Adapt language models to domains and tasks, , Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "Ana Suchin Gururangan",
                    "Swabha Marasovi\u0107",
                    "Kyle Swayamdipta",
                    "Iz Lo",
                    "Doug Beltagy",
                    "Noah Downey",
                    " Smith"
                ],
                "title": "2020. Don't stop pretraining: Adapt language models to domains and tasks",
                "pub_date": null,
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "202-ARR_v2_95",
            "content": "Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Mingwei Chang. 2020. Retrieval augmented language model pre-training, , International Conference on Machine Learning, PMLR.",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Kelvin Guu",
                    "Kenton Lee",
                    "Zora Tung"
                ],
                "title": "Panupong Pasupat, and Mingwei Chang. 2020. Retrieval augmented language model pre-training",
                "pub_date": null,
                "pub_title": "International Conference on Machine Learning",
                "pub": "PMLR"
            }
        },
        {
            "ix": "202-ARR_v2_96",
            "content": "Mandar Joshi, Eunsol Choi, Daniel Weld, Luke Zettlemoyer, TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Mandar Joshi",
                    "Eunsol Choi",
                    "Daniel Weld",
                    "Luke Zettlemoyer"
                ],
                "title": "TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "202-ARR_v2_97",
            "content": "Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, Wen-Tau Yih, Dense passage retrieval for opendomain question answering, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Vladimir Karpukhin",
                    "Barlas Oguz",
                    "Sewon Min",
                    "Patrick Lewis",
                    "Ledell Wu",
                    "Sergey Edunov",
                    "Danqi Chen",
                    "Wen-Tau Yih"
                ],
                "title": "Dense passage retrieval for opendomain question answering",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "202-ARR_v2_98",
            "content": "UNKNOWN, None, 2014, Adam: A method for stochastic optimization, .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": null,
                "title": null,
                "pub_date": "2014",
                "pub_title": "Adam: A method for stochastic optimization",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v2_99",
            "content": "Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Natural questions: a benchmark for question answering research, 2019, Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Tom Kwiatkowski",
                    "Jennimaria Palomaki",
                    "Olivia Redfield",
                    "Michael Collins",
                    "Ankur Parikh",
                    "Chris Alberti",
                    "Danielle Epstein",
                    "Illia Polosukhin",
                    "Jacob Devlin",
                    "Kenton Lee"
                ],
                "title": "Natural questions: a benchmark for question answering research",
                "pub_date": "2019",
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v2_100",
            "content": "Kenton Lee, Ming-Wei Chang, Kristina Toutanova, Latent retrieval for weakly supervised open domain question answering, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Kenton Lee",
                    "Ming-Wei Chang",
                    "Kristina Toutanova"
                ],
                "title": "Latent retrieval for weakly supervised open domain question answering",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "202-ARR_v2_101",
            "content": "UNKNOWN, None, 2021, PAQ: 65 million probably-asked questions and what you can do with them, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "PAQ: 65 million probably-asked questions and what you can do with them",
                "pub": "CoRR"
            }
        },
        {
            "ix": "202-ARR_v2_102",
            "content": "Ji Ma, Ivan Korotkov, Yinfei Yang, Keith Hall, Ryan Mcdonald, Zero-shot neural passage retrieval via domain-targeted synthetic question generation, 2021-04-19, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, EACL 2021, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Ji Ma",
                    "Ivan Korotkov",
                    "Yinfei Yang",
                    "Keith Hall",
                    "Ryan Mcdonald"
                ],
                "title": "Zero-shot neural passage retrieval via domain-targeted synthetic question generation",
                "pub_date": "2021-04-19",
                "pub_title": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, EACL 2021",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v2_103",
            "content": "Mike Mintz, Steven Bills, Rion Snow, Dan Jurafsky, Distant supervision for relation extraction without labeled data, 2009, Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Mike Mintz",
                    "Steven Bills",
                    "Rion Snow",
                    "Dan Jurafsky"
                ],
                "title": "Distant supervision for relation extraction without labeled data",
                "pub_date": "2009",
                "pub_title": "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v2_104",
            "content": "Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, Li Deng, Ms marco: A human generated machine reading comprehension dataset, 2016, CoCo@ NIPS, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "Tri Nguyen",
                    "Mir Rosenberg",
                    "Xia Song",
                    "Jianfeng Gao",
                    "Saurabh Tiwary",
                    "Rangan Majumder",
                    "Li Deng"
                ],
                "title": "Ms marco: A human generated machine reading comprehension dataset",
                "pub_date": "2016",
                "pub_title": "CoCo@ NIPS",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v2_105",
            "content": "UNKNOWN, None, 2021, Domain-matched pretraining tasks for dense retrieval, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Domain-matched pretraining tasks for dense retrieval",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v2_106",
            "content": "Yingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang Ren, Wayne Zhao, Daxiang Dong, Hua Wu, Haifeng Wang, RocketQA: An optimized training approach to dense passage retrieval for opendomain question answering, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Yingqi Qu",
                    "Yuchen Ding",
                    "Jing Liu",
                    "Kai Liu",
                    "Ruiyang Ren",
                    "Wayne Zhao",
                    "Daxiang Dong",
                    "Hua Wu",
                    "Haifeng Wang"
                ],
                "title": "RocketQA: An optimized training approach to dense passage retrieval for opendomain question answering",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "202-ARR_v2_107",
            "content": "UNKNOWN, None, 2021, Towards robust neural retrieval models with synthetic pre-training, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Towards robust neural retrieval models with synthetic pre-training",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v2_108",
            "content": "UNKNOWN, None, 2009, The probabilistic relevance framework: BM25 and beyond, Now Publishers Inc.",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": null,
                "title": null,
                "pub_date": "2009",
                "pub_title": "The probabilistic relevance framework: BM25 and beyond",
                "pub": "Now Publishers Inc"
            }
        },
        {
            "ix": "202-ARR_v2_109",
            "content": "UNKNOWN, None, 2021, End-to-end training of neural retrievers for open-domain question answering, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "End-to-end training of neural retrievers for open-domain question answering",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v2_110",
            "content": "Kazutoshi Shinoda, Saku Sugawara, Akiko Aizawa, Can question generation debias question answering models? a case study on question-context lexical overlap, 2021, Proceedings of the 3rd Workshop on Machine Reading for Question Answering, .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Kazutoshi Shinoda",
                    "Saku Sugawara",
                    "Akiko Aizawa"
                ],
                "title": "Can question generation debias question answering models? a case study on question-context lexical overlap",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 3rd Workshop on Machine Reading for Question Answering",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v2_111",
            "content": "George Tsatsaronis, Georgios Balikas, Prodromos Malakasiotis, Ioannis Partalas, Matthias Zschunke, Dirk Michael R Alvers, Anastasia Weissenborn, Sergios Krithara, Dimitris Petridis,  Polychronopoulos, An overview of the bioasq large-scale biomedical semantic indexing and question answering competition, 2015, BMC bioinformatics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "George Tsatsaronis",
                    "Georgios Balikas",
                    "Prodromos Malakasiotis",
                    "Ioannis Partalas",
                    "Matthias Zschunke",
                    "Dirk Michael R Alvers",
                    "Anastasia Weissenborn",
                    "Sergios Krithara",
                    "Dimitris Petridis",
                    " Polychronopoulos"
                ],
                "title": "An overview of the bioasq large-scale biomedical semantic indexing and question answering competition",
                "pub_date": "2015",
                "pub_title": "BMC bioinformatics",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v2_112",
            "content": "Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, Christopher Manning, HotpotQA: A dataset for diverse, explainable multi-hop question answering, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Zhilin Yang",
                    "Peng Qi",
                    "Saizheng Zhang",
                    "Yoshua Bengio",
                    "William Cohen",
                    "Ruslan Salakhutdinov",
                    "Christopher Manning"
                ],
                "title": "HotpotQA: A dataset for diverse, explainable multi-hop question answering",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v2_113",
            "content": "UNKNOWN, None, , Soujanya Poria, and Tat-Seng Chua. 2021. Retrieving and reading: A comprehensive survey on open-domain question answering, .",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Soujanya Poria, and Tat-Seng Chua. 2021. Retrieving and reading: A comprehensive survey on open-domain question answering",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "202-ARR_v2_0@0",
            "content": "Hyperlink-induced Pre-training for Passage Retrieval in Open-domain Question Answering",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_0",
            "start": 0,
            "end": 85,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_2@0",
            "content": "To alleviate the data scarcity problem in training question answering systems, recent works propose additional intermediate pre-training for dense passage retrieval (DPR).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_2",
            "start": 0,
            "end": 170,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_2@1",
            "content": "However, there still remains a large discrepancy between the provided upstream signals and the downstream question-passage relevance, which leads to less improvement.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_2",
            "start": 172,
            "end": 337,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_2@2",
            "content": "To bridge this gap, we propose the HyperLink-induced Pre-training (HLP), a method to pre-train the dense retriever with the text relevance induced by hyperlink-based topology within Web documents.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_2",
            "start": 339,
            "end": 534,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_2@3",
            "content": "We demonstrate that the hyperlink-based structures of dual-link and co-mention can provide effective relevance signals for large-scale pre-training that better facilitate downstream passage retrieval.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_2",
            "start": 536,
            "end": 735,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_2@4",
            "content": "We investigate the effectiveness of our approach across a wide range of open-domain QA datasets under zero-shot, few-shot, multihop, and out-of-domain scenarios.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_2",
            "start": 737,
            "end": 897,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_2@5",
            "content": "The experiments show our HLP outperforms the BM25 by up to 7 points as well as other pre-training methods by more than 10 points in terms of top-20 retrieval accuracy under the zero-shot scenario.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_2",
            "start": 899,
            "end": 1094,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_2@6",
            "content": "Furthermore, HLP significantly outperforms other pre-training methods under the other scenarios.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_2",
            "start": 1096,
            "end": 1191,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_4@0",
            "content": "Open-domain question answering (OpenQA) aims to answer factual open questions with a large external corpus of passages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_4",
            "start": 0,
            "end": 118,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_4@1",
            "content": "Current approaches to OpenQA usually adopt a two-stage retriever-reader paradigm (Chen et al., 2017;Zhu et al., 2021) to fetch the final answer span.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_4",
            "start": 120,
            "end": 268,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_4@2",
            "content": "The performance of OpenQA systems is largely bounded by the retriever as it determines the evidential documents for the reader to examine.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_4",
            "start": 270,
            "end": 407,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_4@3",
            "content": "Traditional retrievers, such as TF-IDF and BM25 (Robertson and Zaragoza, 2009), are considered incapable of adapting to sce-Our code and trained models are available at https: //github.com/jzhoubu/HLP.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_4",
            "start": 409,
            "end": 609,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_5@0",
            "content": "Letters to Santa (film)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_5",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_6@0",
            "content": "Human Query",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_6",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_7@0",
            "content": "Our HLP Query",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_7",
            "start": 0,
            "end": 12,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_8@0",
            "content": "The action takes place during one single Christmas Eve, when a few adults find the loves of their lives.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_8",
            "start": 0,
            "end": 103,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_9@0",
            "content": "ICT Query",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_9",
            "start": 0,
            "end": 8,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_10@0",
            "content": "The city area measures 517 km2 (200 sq mi) and comprises 18 boroughs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_10",
            "start": 0,
            "end": 68,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_11@0",
            "content": "In-doc contextual Doc-wise contextual Figure 1: An example of different kinds of pseudo Q-P pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_11",
            "start": 0,
            "end": 97,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_11@1",
            "content": "Underlined texts are hypertexts that linked to other Wikipedia pages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_11",
            "start": 99,
            "end": 167,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_11@2",
            "content": "The ICT query is a random sentence originated from the passage and the WLP query is a sentence from the first section of an out-link document of the given passage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_11",
            "start": 169,
            "end": 331,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_11@3",
            "content": "The text highlighted in green gives evidence to answer the human query, and our proposed HLP query can be a better surrogate of the human query.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_11",
            "start": 333,
            "end": 476,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_11@4",
            "content": "narios where deep semantic understanding is required.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_11",
            "start": 478,
            "end": 530,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_11@5",
            "content": "Recent works Karpukhin et al., 2020;Qu et al., 2021) show that by finetuning pre-trained language models on sufficient downstream data, dense retrievers can significantly outperform traditional term-based retrievers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_11",
            "start": 532,
            "end": 747,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_12@0",
            "content": "Considering the data-hungry nature of the neural retrieval models, extensive efforts Sachan et al., 2021) have been made to design self-supervised tasks to pre-train the retriever.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_12",
            "start": 0,
            "end": 179,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_12@1",
            "content": "However, these pre-training tasks construct relevance signals largely depending on easily attainable sentence-level or document-level contextual relationships.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_12",
            "start": 181,
            "end": 339,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_12@2",
            "content": "For example, the relationship between a sentence and its originated context (shown by the ICT query in Figure 1) may not be sufficient enough to facilitate question-passage matching for the tasks of OpenQA.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_12",
            "start": 341,
            "end": 546,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_12@3",
            "content": "We also find that these pretrained retrievers still fall far behind BM25 in our pilot study on the zero-shot experiment.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_12",
            "start": 548,
            "end": 667,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_13@0",
            "content": "In order to address the shortcomings of the matching-oriented pre-training tasks as mentioned above, we propose a pre-training method with better surrogates of real natural question-passage (Q-P) pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_13",
            "start": 0,
            "end": 201,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_13@1",
            "content": "We consider two conditions of relevance within Q-P pairs, which is similar to the process of distantly supervised retriever learning (Mintz et al., 2009;Chen et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_13",
            "start": 203,
            "end": 374,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_14@0",
            "content": "The evidence, such as entities and their corresponding relations, should exist across the query and the targeted passage as they both discuss similar facts or events related to the answer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_14",
            "start": 0,
            "end": 187,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_15@0",
            "content": "should contain the answer of the query, which means that a text span within the passage can provide the information-seeking target of the query.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_15",
            "start": 0,
            "end": 143,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_16@0",
            "content": "In this paper, we propose HyperLink-induced Pre-training (HLP), a pre-training method to learn effective Q-P relevance induced by the hyperlink topology within naturally-occurring Web documents.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_16",
            "start": 0,
            "end": 193,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_16@1",
            "content": "Specifically, these Q-P pairs are automatically extracted from the online documents with relevance adequately designed via hyperlink-based topology to facilitate downstream retrieval for question answering.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_16",
            "start": 195,
            "end": 400,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_16@2",
            "content": "Figure 1 shows an example of comparison between the human-written query and different pseudo queries.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_16",
            "start": 402,
            "end": 502,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_16@3",
            "content": "By the guidance of hyperlinks, our HLP query hold the relevance of answer containing with the passage (query title occurs in the passage).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_16",
            "start": 504,
            "end": 641,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_16@4",
            "content": "Meanwhile, the HLP query can introduce far more effective relevance of evidence existence than other pseudo queries by deeply mining the hyperlink topology, e.g., the dual-link structure.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_16",
            "start": 643,
            "end": 829,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_16@5",
            "content": "In figure 1, both HLP query and the passage both contain information corresponding to the same fact of \"Mitja Okorn directed the film of Letters to Santa\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_16",
            "start": 831,
            "end": 985,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_16@6",
            "content": "This makes our pseudo query low-cost and a good surrogate for the manually written query.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_16",
            "start": 987,
            "end": 1075,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_17@0",
            "content": "Our contributions are two-fold.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_17",
            "start": 0,
            "end": 30,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_17@1",
            "content": "First, we present a hyperlink-induced relevance construction methodology that can better facilitate downstream passage retrieval for question answering, and specifically, we propose a pre-training method: Hyperlink-induced Pre-training (HLP).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_17",
            "start": 32,
            "end": 273,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_17@2",
            "content": "Second, we conduct evaluations on six popular QA datasets, investigating the effectiveness of our approach under zero-shot, few-shot, multi-hop, and out-of-domain (OOD) scenarios.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_17",
            "start": 275,
            "end": 453,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_17@3",
            "content": "The experiments show HLP outperforms BM25 in most of the cases under the zero-shot scenario and other pre-training methods under all scenarios.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_17",
            "start": 455,
            "end": 597,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_18@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_18",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_19@0",
            "content": "Dense Retriever Pre-training Previous works have attempted to conduct additional pre-training for dense retrievers on various weakly supervised data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_19",
            "start": 0,
            "end": 148,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_19@1",
            "content": "Borisov et al. (2016) and Dehghani et al. (2017) pre-trained ranking models on click-logs and BM25-induced signals respectively for web search.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_19",
            "start": 150,
            "end": 292,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_19@2",
            "content": "proposed the inverse cloze task (ICT) to pre-train a dense retrieval model, which randomly selects sentences as pseudo queries, and matched them to the passages that they originate from.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_19",
            "start": 294,
            "end": 479,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_19@3",
            "content": "Besides, proposed the pre-training task of wiki link prediction (WLP) and body first selection (BFS) tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_19",
            "start": 481,
            "end": 587,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_19@4",
            "content": "Similar to our work, the WLP task also leveraged the hyperlinks within Wikipedia to construct relevant text pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_19",
            "start": 589,
            "end": 702,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_19@5",
            "content": "However, as shown in figure 1, the WLP pseudo query can only ensure the weak doc-wise contextual relationship with the passage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_19",
            "start": 704,
            "end": 830,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_19@6",
            "content": "Guu et al. (2020) et al. (2021) reveals that the QG models tend to generate questions with high lexical overlap which amplify the bias of QA dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_19",
            "start": 832,
            "end": 980,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_19@7",
            "content": "Different to these studies, our method focuses on a more general setting where the retriever is only trained with the naturally occurring web documents, and has no access to any downstream datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_19",
            "start": 982,
            "end": 1179,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_19@8",
            "content": "3 Hyperlink-induced Pre-training (HLP)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_19",
            "start": 1181,
            "end": 1218,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_20@0",
            "content": "In this section, we firstly discuss the background of OpenQA retrieval, then our methodology and training framework.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_20",
            "start": 0,
            "end": 115,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_21@0",
            "content": "Preliminaries",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_21",
            "start": 0,
            "end": 12,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_22@0",
            "content": "Passage Retrieval Given a question q, passage retrieval aims to provide a set of relevant passages p from a large corpus D. Our work adopts Wikipedia as source corpus and each passage is a disjoint segment within a document from D. OpenQA Q-P Relevance For OpenQA, a passage p is considered relevant to the query q if p conveys similar facts and contains the answer to q. These two conditions of relevance, namely evidence existence and answer containing, are properly introduced into the HLP Q-P pairs under the guidance of desired hyperlink structure.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_22",
            "start": 0,
            "end": 552,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_22@1",
            "content": "We will discuss more in this section.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_22",
            "start": 554,
            "end": 590,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_23@0",
            "content": "To better formulate the relevance of pseudo Q-P pairs, we denote the sequence of passages within a document as A = [a 1 , a 2 , ..., a n A ] where A \u2208 D. The corresponding topical entity and the title of document A and its passage splits are denoted as e A and t A , respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_23",
            "start": 0,
            "end": 279,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_23@1",
            "content": "We use m A to indicate a mention of entity e A , which is a hypertext span linking to document A. Note that the mention span m A is usually identical to the document title t A or a variant version of it.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_23",
            "start": 281,
            "end": 483,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_23@2",
            "content": "Further, we define F (p) as the entity-level factual information conveyed by the passage p, which is a set consists of the topical entity e P and the entities mentioned within passage p.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_23",
            "start": 485,
            "end": 670,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_24@0",
            "content": "Evidence Existence in HLP With appropriately designed hyperlink topologies, our HLP Q-P pairs guarantee the co-occurrence of entities which are presented as hypertext or topics in q and p. This is considered as evidence across the Q-P pairs:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_24",
            "start": 0,
            "end": 240,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_25@0",
            "content": "F (q) \u2229 F (p) \u0338 = \u2205(1)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_25",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_26@0",
            "content": "Furthermore, we conjecture that HLP is more likely to achieve fact-level relevance than entitylevel overlap.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_26",
            "start": 0,
            "end": 107,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_26@1",
            "content": "We conduct human evaluation in Section 6.3 and case studies in Appendix G to support this conjecture.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_26",
            "start": 109,
            "end": 209,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_26@2",
            "content": "Moreover, we demonstrate that any Q-P pair containing hyperlink-induced factual evidence, which can be represented as triples, is included in our proposed topologies, which are included in Appendix E. Answer Containing in HLP We consider the document title t Q as the information-seeking target of q. Accordingly, the relevance of answer containing can be formulated as",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_26",
            "start": 211,
            "end": 579,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_27@0",
            "content": "t Q \u2286 p (2)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_27",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_28@0",
            "content": "The rationale behind this is that both the natural question and the Wikipedia document are intended to describe related facts and events regarding a targeted object, whereas the object is an answer for a question but a topical entity for a Wikipedia document.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_28",
            "start": 0,
            "end": 258,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_28@1",
            "content": "This similarity leads us to take the document title as the information-seeking target of its context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_28",
            "start": 260,
            "end": 360,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_29@0",
            "content": "Hyperlink-induced Q-P Pairs",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_29",
            "start": 0,
            "end": 26,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_30@0",
            "content": "Based on analysis of how queries match their evidential passages in the NQ (Kwiatkowski et al., 2019) dataset, we propose two kinds of hyperlink topology for relevance construction: Dual-link and Co-mention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_30",
            "start": 0,
            "end": 206,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_30@1",
            "content": "We present our exploratory data analysis on NQ dataset in Appendix C. Here we discuss the desired hyperlink topologies and the corresponding relevance of the pseudo Q-P pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_30",
            "start": 208,
            "end": 382,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_30@2",
            "content": "Dual-link (DL) Among all NQ training samples, 55% of questions mention the title of their corresponding golden passage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_30",
            "start": 384,
            "end": 502,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_30@3",
            "content": "This observation motivates us to leverage the topology of dual-link (DL) for relevance construction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_30",
            "start": 504,
            "end": 603,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_30@4",
            "content": "We consider a passage pair (a i , b j ) follows the dual-link topology if they link to each other.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_30",
            "start": 605,
            "end": 702,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_30@5",
            "content": "An example of a DL pair (a i , b j ) is shown in Figure 2, in which passage b j mentions the title of document A as m A , satisfying the condition of answer containing:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_30",
            "start": 704,
            "end": 871,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_31@0",
            "content": "t A \u2248 m A and m A \u2286 b j (3)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_31",
            "start": 0,
            "end": 26,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_32@0",
            "content": "Further, since the passages a i and b j both mention the topical entity of the other, the entities e A and e B appear in both passages as evidence:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_32",
            "start": 0,
            "end": 146,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_33@0",
            "content": "{e A , e B } \u2286 F (a i ) \u2229 F (b j )(4)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_33",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_34@0",
            "content": "Co-mention (CM) Among all NQ training samples, about 40% of questions fail to match the duallink condition but mention the same third-party entity as their corresponding golden passages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_34",
            "start": 0,
            "end": 185,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_34@1",
            "content": "In light of this observation, we utilize another topology of Co-mention (CM).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_34",
            "start": 187,
            "end": 263,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_34@2",
            "content": "We consider that a passage pair (c k , d l ) follows the Co-mention topology if they both link to a third-party document E and d l links to c k .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_34",
            "start": 265,
            "end": 409,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_34@3",
            "content": "Figure 2 illustrates a CM pair (c l , d k )",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_34",
            "start": 411,
            "end": 453,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_35@0",
            "content": "where answer containing is ensured as the title of c k occurs in d l :",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_35",
            "start": 0,
            "end": 69,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_36@0",
            "content": "t C \u2248 m C and m C \u2286 d l(5)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_36",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_37@0",
            "content": "Since both c l and d k mention a third-party entity e E , and that e C is a topical entity in c l while a mentioned entity in d k , we have entity-level evidence across c l and d k as:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_37",
            "start": 0,
            "end": 183,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_38@0",
            "content": "{e C , e E } \u2286 F (c k ) \u2229 F (d l )(6)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_38",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_39@0",
            "content": "In practice, we use sentence-level queries which contain the corresponding evidential hypertext, and we do not prepend the title to the passage in order to reduce the superficial entity-level overlap.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_39",
            "start": 0,
            "end": 199,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_39@1",
            "content": "To improve the quality of CM pairs, we filter out those with a co-mentioned entity which has a top 10% highest-ranked in-degree among the Wikipedia entity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_39",
            "start": 201,
            "end": 355,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_39@2",
            "content": "We also present pseudo code in Appendix D to illustrate how we construct our pseudo Q-P pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_39",
            "start": 357,
            "end": 450,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_39@3",
            "content": "Furthermore, we highlight that HLP has the following advantages: 1) it introduces more semantic variants and paraphrasing for better text matching.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_39",
            "start": 452,
            "end": 598,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_40@0",
            "content": "2) The hypertext reflects potential interests or needs of users in relevant information, which is consistent to the downstream information-seeking propose.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_40",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_41@0",
            "content": "Bi-encoder Training",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_41",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_42@0",
            "content": "We adopt a BERT-based bi-encoder to encode queries and passages separately into d-dimension vectors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_42",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_42@1",
            "content": "The output representation is derived from the last hidden state of the [CLS] token and the final matching score is measured by the inner product:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_42",
            "start": 101,
            "end": 245,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_43@0",
            "content": "h q = BERT Q (q)([CLS]) h p = BERT P (p)([CLS]) S(p, q) = h T q \u2022 h p Let B = {\u27e8q i , p + i , p \u2212 i \u27e9} n i=1",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_43",
            "start": 0,
            "end": 107,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_44@0",
            "content": "be a mini-batch with n instances.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_44",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_44@1",
            "content": "Each instance contains a question q i paired with a positive passage p + i and a negative passage p \u2212 i .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_44",
            "start": 34,
            "end": 138,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_44@2",
            "content": "With in-batch negative sampling, each question q i considers all the passages in B except its own gold p + i as negatives, resulting in 2n \u2212 1 negatives per question in total.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_44",
            "start": 140,
            "end": 314,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_44@3",
            "content": "We use the negative log likelihood of the positive passage as our loss for optimization:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_44",
            "start": 316,
            "end": 403,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_45@0",
            "content": "L(q i , p + i , p \u2212 i,1 , ..., p \u2212 i,2n\u22121 ) = \u2212 log e S(q i ,p + i )",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_45",
            "start": 0,
            "end": 67,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_46@0",
            "content": "e S(q i ,p + i ) + 2n\u22121 j=1 e S(q i ,p \u2212 i,j )",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_46",
            "start": 0,
            "end": 45,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_47@0",
            "content": "Experimental Setup",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_47",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_48@0",
            "content": "In this session, we discuss the pre-training corpus preparation, downstream datasets, the hyperparameter and the basic setup for our experiments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_48",
            "start": 0,
            "end": 144,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_49@0",
            "content": "Pre-training Corpus",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_49",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_50@0",
            "content": "We adopt Wikipedia as our source corpus D for pretraining as it is the largest encyclopedia covering diverse topics with good content quality and linking structures.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_50",
            "start": 0,
            "end": 164,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_50@1",
            "content": "We choose the snapshot 03-01-2021 of an English Wikipedia dump, and process it with WikiExtractor 2 to obtain clean context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_50",
            "start": 166,
            "end": 289,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_50@2",
            "content": "After filtering out documents with blank text or a title less than three letters, following previous work (Karpukhin et al., 2020), we split the remaining documents into disjoint chunks of 100 words as passages, resulting in over 22 million passages in the end.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_50",
            "start": 291,
            "end": 551,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_51@0",
            "content": "Downstream Datasets",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_51",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_52@0",
            "content": "We",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_52",
            "start": 0,
            "end": 1,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_53@0",
            "content": "Implementation Details",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_53",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_54@0",
            "content": "During the pre-training, we train the bi-encoder for 5 epochs with parameters shared, using a batch size of 400 and an Adam optimizer (Kingma and Ba, 2014) with a learning rate 2 \u00d7 10 \u22125 , linear scheduling with 10% warm-up steps.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_54",
            "start": 0,
            "end": 229,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_54@1",
            "content": "Our HLP and all the reproduced baselines are trained on 20 million Q-P pairs with in-batch negative sampling, and the best checkpoints are selected based on the average rank of gold passages evaluated on the NQ dev set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_54",
            "start": 231,
            "end": 449,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_55@0",
            "content": "The pre-training takes around 3 days using eight NVIDIA V100 32GB GPUs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_55",
            "start": 0,
            "end": 70,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_56@0",
            "content": "For the downstream, we use the same hyperparameters for all experiments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_56",
            "start": 0,
            "end": 71,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_56@1",
            "content": "Specifically, we fine-tune the pre-trained models for 40 epochs with a batch size of 256 and the same optimizer and learning rate settings to the pre-training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_56",
            "start": 73,
            "end": 231,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_56@2",
            "content": "We conduct evaluation on respective dev sets to select best checkpoints, and we use the last checkpoint if there is no dev set or test set (e.g. HotpotQA).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_56",
            "start": 233,
            "end": 387,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_56@3",
            "content": "More details can be found in the Appendix A.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_56",
            "start": 389,
            "end": 432,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_57@0",
            "content": "Baselines",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_57",
            "start": 0,
            "end": 8,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_58@0",
            "content": "Most existing baselines have been implemented under different experimental settings, which have a substantial effect on the retrieval performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_58",
            "start": 0,
            "end": 145,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_58@1",
            "content": "To ensure fairness, we reproduce several pre-training methods (ICT, WLP, BFS, and their combination) under the same experimental setting, such as batch size, base model, amount of pre-training data, and so on.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_58",
            "start": 147,
            "end": 355,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_58@2",
            "content": "The only difference between our method and the re-implemented baselines is the self-supervision signal derived from the respective pre-training samples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_58",
            "start": 357,
            "end": 508,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_58@3",
            "content": "Our reproduced BM25 baseline is better than that reported in Karpukhin et al. (2020), and the re-implemented pre-training methods also perform better than those reported by the recent work 3 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_58",
            "start": 510,
            "end": 701,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_58@4",
            "content": "In addition, we include the work REALM (Guu et al., 2020) as a baseline which has recently been reproduced by Sachan et al. ( 2021) using 240 GPUs and is named masked salient spans (MSS).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_58",
            "start": 703,
            "end": 889,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_58@5",
            "content": "We note that most related works gain improvements from varying downstream setting or synthetic pre-training with access to the downstream data of respective domain, which is out of the scope of our interests.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_58",
            "start": 891,
            "end": 1098,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_59@0",
            "content": "Experiments",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_59",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_60@0",
            "content": "Main Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_60",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_61@0",
            "content": "Table 1 shows the retrieval accuracy of different models on three popular QA datasets under zeroshot and full-set fine-tuning settings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_61",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_62@0",
            "content": "Under zero-shot setting, HLP consistently outperforms BM25 except for the top-5 retrieval accuracy of TriviaQA, while all other pre-training baselines are far behind.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_62",
            "start": 0,
            "end": 165,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_62@1",
            "content": "We attribute the minor improvement over BM25 on TriviaQA to a high overlap between questions and passages, which gives term-based retriever a clear advantage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_62",
            "start": 167,
            "end": 324,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_62@2",
            "content": "We investigate the coverage of the question tokens that appear in the gold passage and find that the overlap is indeed higher in TriviaQA (62.8%) than NQ (60.7%) and WQ (57.5%).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_62",
            "start": 326,
            "end": 502,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_63@0",
            "content": "After fine-tuning, all models with intermediate pre-training give better results than the vanilla DPR while our HLP achieves the best in nearly all cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_63",
            "start": 0,
            "end": 153,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_63@1",
            "content": "Among ICT, WLP and BFS, we observe that WLP is the most competitive with or without fine-tuning, and additional improvements can be achieved by combining three of them.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_63",
            "start": 155,
            "end": 322,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_63@2",
            "content": "This observation indicates that pre-training with diverse relevance leads to better generalization to downstream tasks, while document-wise relevance is more adaptable for the OpenQA retrieval.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_63",
            "start": 324,
            "end": 516,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_63@3",
            "content": "The advantage of documentwise relevance may come from the fact that texts in different documents are likely written by different parties, providing less superficial cues for text matching, which is beneficial for the downstream retrieval.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_63",
            "start": 518,
            "end": 755,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_63@4",
            "content": "Our HLP learns both coarse-grained document-wise relationships as well as the finegrained entity-level evidence, which results in a significant improvement.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_63",
            "start": 757,
            "end": 912,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_64@0",
            "content": "Few-shot Learning",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_64",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_65@0",
            "content": "To investigate the retrieval effectiveness in a more realistic scenario, we conduct experiments for few-shot learning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_65",
            "start": 0,
            "end": 117,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_65@1",
            "content": "Specifically, we fine-tune the pre-trained models on large datasets (NQ, Triv-iaQA) with m (m \u2208 {16, 256, 1024}) samples and present the few-shot retrieval results in Table 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_65",
            "start": 119,
            "end": 293,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_65@2",
            "content": "With only a few hundred labeled data for fine-tuning, all the models with intermediate pretraining perform better than those without, and HLP outperforms the others by a larger margin when m is smaller.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_65",
            "start": 295,
            "end": 496,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_65@3",
            "content": "Moreover, among three reimplemented baselines, WLP gains the largest improvement with increasing number of samples, outperforming ICT and BFS when a thousand labelled samples are provided for fine-tuning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_65",
            "start": 498,
            "end": 701,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_66@0",
            "content": "Multi-hop Retrieval",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_66",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_67@0",
            "content": "While HLP aims to acquires the ability in matching document-wise concepts and facts, it raises our interest in its capability for multi-hop scenarios.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_67",
            "start": 0,
            "end": 149,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_67@1",
            "content": "We evaluate our methods on HotpotQA in a single-hop manner.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_67",
            "start": 151,
            "end": 209,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_67@2",
            "content": "Specifically, for each query, we randomly selects one golden passage from the two as a positive passage and one additional passage with high TF-IDF scores as a negative passage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_67",
            "start": 211,
            "end": 387,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_67@3",
            "content": "Our models are further fine-tuned on the HotpotQA training set and evaluated on the bridge and the comparison type questions from the development set, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_67",
            "start": 389,
            "end": 552,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_67@4",
            "content": "The results of our study are shown in Table 5 which reveals that HLP consistently outperforms others methods, with up to a 11-point improvement on top-5 retrieval accuracy of bridge questions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_67",
            "start": 554,
            "end": 745,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_67@5",
            "content": "Furthermore, WLP yields a 4-point advantages in average over ICT and BFS on bridge questions, showing that document-wise relevance contributes to better associative abilities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_67",
            "start": 747,
            "end": 921,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_67@6",
            "content": "We include a case study in Appendix F. Table 5: Retrieval accuracy on questions from Hot-potQA dev set, measured as the percentage of top-k retrieved passages which include both golds.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_67",
            "start": 923,
            "end": 1106,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_68@0",
            "content": "6 Analysis",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_68",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_69@0",
            "content": "Ablation Study",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_69",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_70@0",
            "content": "To better understand how different key factors affect the results, we conduct ablation experiments with results shown in Table 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_70",
            "start": 0,
            "end": 128,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_71@0",
            "content": "Our proposed dual-link (DL) and co-mention (CM) Q-P pairs, provide evidence induced by different hyperlinkbased topologies.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_71",
            "start": 0,
            "end": 122,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_71@1",
            "content": "To examine their respective effectiveness, we pre-train retrievers on Q-P pairs derived from each topology and their combinations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_71",
            "start": 124,
            "end": 253,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_71@2",
            "content": "We present zero-shot retrieval results in Table 3, which show that retrievers pre-trained on DL pairs has a distinct advantage over that on CM pairs, while combining both gives extra improvement.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_71",
            "start": 255,
            "end": 449,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_71@3",
            "content": "Negative Passage In practice, negative sampling is essential for learning a high-quality encoder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_71",
            "start": 451,
            "end": 547,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_71@4",
            "content": "Besides in-batch negative, our reported HLP employs one additional negative for each query.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_71",
            "start": 549,
            "end": 639,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_71@5",
            "content": "We further explore the impact of the additional negatives during pre-training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_71",
            "start": 641,
            "end": 718,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_71@6",
            "content": "In our ablation study, pre-training with additional negatives improves the results significantly, which may be attributed to using more in-batch pairs for text matching.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_71",
            "start": 720,
            "end": 888,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_71@7",
            "content": "More details on implementation and negative sampling strategies can be found in Appendix B.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_71",
            "start": 890,
            "end": 980,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_72@0",
            "content": "Analysis on Q-P Overlap",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_72",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_73@0",
            "content": "We carry out extensive analysis on the Q-P lexical overlap in the task of retrieval.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_73",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_73@1",
            "content": "Specifically, we tokenize q, p using the BERT tokenizer and measure the Q-P overlap as the proportion of the question tokens that appear in the corresponding passage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_73",
            "start": 85,
            "end": 250,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_73@2",
            "content": "Based on the degree of Q-P overlap, we divided the NQ dev set into five categories for further analysis.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_73",
            "start": 252,
            "end": 355,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_73@3",
            "content": "Distribution of Q-P Overlap Figure 3 shows both the and the retrieved pairs of HLP have a more similar overlap distribution with the downstream NQ dataset than the other methods, which implies the consistency between the relevance provided by HLP and that in real informationseeking scenario.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_73",
            "start": 357,
            "end": 648,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_73@4",
            "content": "Retrieval Performance vs. Q-P Overlap Figure 4 shows the top-20 retrieval accuracy on the samples with varying degrees of Q-P overlap.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_73",
            "start": 650,
            "end": 783,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_73@5",
            "content": "Both figures show that the retrievers are more likely to return answer-containing passages when there is higher Q-P overlap, suggesting that all these models can exploit lexical overlap for passage retrieval.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_73",
            "start": 785,
            "end": 992,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_73@6",
            "content": "Under the zero-shot setting, HLP outperforms all the methods except BM25 when r is larger than 0.8, which reflects the strong reasoning ability of HLP and the overlap-dependent nature of the termbased retrievers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_73",
            "start": 994,
            "end": 1205,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_73@7",
            "content": "After fine-tuning, models with additional pre-training perform better than the vanilla DPR while HLP outperforms all other methods in most of the cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_73",
            "start": 1207,
            "end": 1358,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_73@8",
            "content": "It is important to note that HLP is pre-trained on more high-overlap text pairs while it performs better than all the other methods when fewer overlaps are provided.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_73",
            "start": 1360,
            "end": 1524,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_73@9",
            "content": "We speculate that this is because the overlapping in HLP Q-P pairs mostly comes from the factual information, such as entity, which introduces fewer superficial cues, allowing for better adaptation to the downstream cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_73",
            "start": 1526,
            "end": 1747,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_74@0",
            "content": "Human Evaluation on Q-P pairs",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_74",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_75@0",
            "content": "We conduct human evaluation to investigate the proportion of Q-P pairs that convey the similar factlevel information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_75",
            "start": 0,
            "end": 116,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_75@1",
            "content": "Specially, we randomly selected one hundred examples from our constructed Q-P pairs and asked annotators to identify whether the query and the corresponding passage convey similar facts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_75",
            "start": 118,
            "end": 303,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_75@2",
            "content": "Each case is evaluated by three annotators and the result is determined by their votes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_75",
            "start": 305,
            "end": 391,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_75@3",
            "content": "Our results are shown in",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_75",
            "start": 393,
            "end": 416,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_76@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_76",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_77@0",
            "content": "This paper proposes Hyperlink-induced Pretraining (HLP), a pre-training method for OpenQA passage retrieval by leveraging the online textual relevance induced by hyperlink-based topology.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_77",
            "start": 0,
            "end": 186,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_77@1",
            "content": "Our experiments show that HLP gains significant improvements across multiple QA datasets under different scenarios, consistently outperforming other pre-training methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_77",
            "start": 188,
            "end": 357,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_77@2",
            "content": "Our method provides insights into OpenQA passage retrieval by analyzing the underlying bi-text relevance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_77",
            "start": 359,
            "end": 463,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_77@3",
            "content": "Future work involves addressing tasks like MS MARCO where the granularity of the information-seeking target is at the passage level.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_77",
            "start": 465,
            "end": 596,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_78@0",
            "content": "For the pre-training, all models we reproduced are trained with 20 million Q-P pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_78",
            "start": 0,
            "end": 84,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_78@1",
            "content": "Specifically, our reported HLP is trained on the combination of 10 million DL pairs and 10 million CM pairs while the HLP (DL) and HLP (CM) reported in",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_78",
            "start": 86,
            "end": 236,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_79@0",
            "content": "We discuss how we conduct data analysis to determine the hyperlink-based topology.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_79",
            "start": 0,
            "end": 81,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_79@1",
            "content": "Driven by a strong interest in what roles the Q-P overlapping spans play, we conduct exploratory data analysis on the widely-used NQ dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_79",
            "start": 83,
            "end": 223,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_79@2",
            "content": "Specifically, we extract all entities and mentions from the Q-P pairs using TagMe (Ferragina and Scaiella, 2010) for further investigation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_79",
            "start": 225,
            "end": 363,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_79@3",
            "content": "We observe about 55% queries q either explicitly mentions the titles of p or successfully links to the document via TagMe.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_79",
            "start": 365,
            "end": 486,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_79@4",
            "content": "This observation motivates us to construct the dual-link topology where the pseudo queries q mention p via a hypertext.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_79",
            "start": 488,
            "end": 606,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_79@5",
            "content": "Moreover, we observe about 45% queries q do not mention the titles of q but instead they share the same mentions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_79",
            "start": 608,
            "end": 720,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_79@6",
            "content": "This encourages us to adopt the co-mention topology where the pseudo q and p both mention a third-party document through hypertext.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_79",
            "start": 722,
            "end": 852,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_80@0",
            "content": "Algorithm 1: HLP Pairs Identification Notation: q, p \u2190 Wikipedia passages t Q \u2190 Topical entity of passage q M(q) \u2190 The set of entities mentioned in q d in (q) \u2190 in-degree of the Wikipedia entity t Q K \u2190 in-degree threshold for CM pairs Def IsDL(q, p):",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_80",
            "start": 0,
            "end": 250,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_81@0",
            "content": "if t P \u2208 M(q) & t Q \u2208 M(p) then return 1 else return 0 ; Def IsCM(q, p): foreach m \u2208 M(q) do if d in (m) < K & m \u2208 M (p) & t Q \u2208 M (p) then return 1 else return 0 E Fact-level Evidence Reduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_81",
            "start": 0,
            "end": 193,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_82@0",
            "content": "Intuitively, we assume any mentioned entity, let's say e Y mentioned in a Wikipedia document X, is used to describe the topical entity e X of this document.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_82",
            "start": 0,
            "end": 155,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_82@1",
            "content": "In other words, e Y is likely to attend in a topically relevant fact or event related to e X , which can be represented as a triple <e X , r XY , e Y > where r XY is a latent relation between e X and e Y .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_82",
            "start": 157,
            "end": 361,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_82@2",
            "content": "Given any passage pair (q, p) from Wikipedia, we consider q and p have fact-level evidence if they both entail a fact that can be represented as a triple, let's say <e X , r XY , e Y >.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_82",
            "start": 363,
            "end": 547,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_82@3",
            "content": "Further, if both passages q and p contain representative hypertext or topic of e X and e Y , we consider such fact-level evidence can be induced by hyperlink-based topology, namely hyperlink-induced fact.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_82",
            "start": 549,
            "end": 752,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_82@4",
            "content": "Below we show that any Q-P pair with hyperlink-induced fact while satisfying answer containing is within either DL or CM hyperlink-based topology.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_82",
            "start": 754,
            "end": 899,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_83@0",
            "content": "Following the example above, given q and p containing a factual triple <e X , r XY , e Y >, we have facts <e Q , r QX , e X >, <e Q , r QY , e Y > at q-side while <e P , r P X , e X >, <e P , r P Y , e Y > at p-side.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_83",
            "start": 0,
            "end": 215,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_83@1",
            "content": "Further, p entails <e P , r P Q , e Q > because of the answer containing property.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_83",
            "start": 217,
            "end": 298,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_84@0",
            "content": "Case1: e P = e X or e P = e Y .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_84",
            "start": 0,
            "end": 30,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_84@1",
            "content": "Then q entails facts <e Q , r QP , e P >.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_84",
            "start": 32,
            "end": 72,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_84@2",
            "content": "Note that r QP is likely but not necessarily to be identical to r P Q in p.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_84",
            "start": 74,
            "end": 148,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_84@3",
            "content": "In this case, (q, p) fits in the Dual-link topology in our definition.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_84",
            "start": 150,
            "end": 219,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_85@0",
            "content": "Case2: e P \u0338 = e X and e P \u0338 = e Y .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_85",
            "start": 0,
            "end": 35,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_85@1",
            "content": "Then given the facts <e Q , r QX , e X > at q-side, and <e P , r P X , e X > at p-side, (q, p) fits in the Co-mention topology.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_85",
            "start": 37,
            "end": 163,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_86@0",
            "content": "We evaluate HLP on multi-hop scenario where knowledge from different documents need to be associated.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_86",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_86@1",
            "content": "Besides significant improvements shown in Table 5, we conduct case study to investigate its capability on knowledge-intensive retrieval.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_86",
            "start": 102,
            "end": 237,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_86@2",
            "content": "In Table 8, a complex question is proposed, requiring the retriever firstly to retrieve the document \"Apple Remote\" and then \"Front Row (software)\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_86",
            "start": 239,
            "end": 386,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_86@3",
            "content": "HLP successfully retrieves both golds in the top-10 retrieved passages while the vanilla DPR fails.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_86",
            "start": 388,
            "end": 486,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_86@4",
            "content": "We find 6 items retrieved by HLP are related to the brand \"Apple\" while 4 by DPR, which indicates stronger comprehension and associative ability of HLP.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_86",
            "start": 488,
            "end": 639,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_87@0",
            "content": "We present case studies on the constructed HLP Q-P pairs in Table 9 and Table 10.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_87",
            "start": 0,
            "end": 80,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_87@1",
            "content": "As we can see,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_87",
            "start": 82,
            "end": 95,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_88@0",
            "content": "Jonathan Berant, Andrew Chou, Roy Frostig, Percy Liang, Semantic parsing on Freebase from question-answer pairs, 2013, Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_88",
            "start": 0,
            "end": 207,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_89@0",
            "content": "Alexey Borisov, Ilya Markov, Pavel Maarten De Rijke,  Serdyukov, A neural click model for web search, 2016-04-11, Proceedings of the 25th International Conference on World Wide Web, WWW 2016, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_89",
            "start": 0,
            "end": 192,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_90@0",
            "content": "Wei-Cheng Chang, Yu Felix, Yin-Wen Chang, Yiming Yang, Sanjiv Kumar, Pre-training tasks for embedding-based large-scale retrieval, 2019, International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_90",
            "start": 0,
            "end": 191,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_91@0",
            "content": "Danqi Chen, Adam Fisch, Jason Weston, Antoine Bordes, Reading Wikipedia to answer opendomain questions, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_91",
            "start": 0,
            "end": 240,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_92@0",
            "content": "Mostafa Dehghani, Hamed Zamani, Aliaksei Severyn, Jaap Kamps, W Croft, Neural ranking models with weak supervision, 2017-08-07, Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_92",
            "start": 0,
            "end": 241,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_93@0",
            "content": "Paolo Ferragina, Ugo Scaiella, Tagme: on-thefly annotation of short text fragments (by wikipedia entities), 2010, Proceedings of the 19th ACM international conference on Information and knowledge management, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_93",
            "start": 0,
            "end": 208,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_94@0",
            "content": "Ana Suchin Gururangan, Swabha Marasovi\u0107, Kyle Swayamdipta, Iz Lo, Doug Beltagy, Noah Downey,  Smith, 2020. Don't stop pretraining: Adapt language models to domains and tasks, , Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_94",
            "start": 0,
            "end": 315,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_95@0",
            "content": "Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Mingwei Chang. 2020. Retrieval augmented language model pre-training, , International Conference on Machine Learning, PMLR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_95",
            "start": 0,
            "end": 179,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_96@0",
            "content": "Mandar Joshi, Eunsol Choi, Daniel Weld, Luke Zettlemoyer, TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_96",
            "start": 0,
            "end": 284,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_97@0",
            "content": "Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, Wen-Tau Yih, Dense passage retrieval for opendomain question answering, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_97",
            "start": 0,
            "end": 320,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_98@0",
            "content": "UNKNOWN, None, 2014, Adam: A method for stochastic optimization, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_98",
            "start": 0,
            "end": 65,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_99@0",
            "content": "Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Natural questions: a benchmark for question answering research, 2019, Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_99",
            "start": 0,
            "end": 296,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_100@0",
            "content": "Kenton Lee, Ming-Wei Chang, Kristina Toutanova, Latent retrieval for weakly supervised open domain question answering, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_100",
            "start": 0,
            "end": 255,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_101@0",
            "content": "UNKNOWN, None, 2021, PAQ: 65 million probably-asked questions and what you can do with them, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_101",
            "start": 0,
            "end": 97,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_102@0",
            "content": "Ji Ma, Ivan Korotkov, Yinfei Yang, Keith Hall, Ryan Mcdonald, Zero-shot neural passage retrieval via domain-targeted synthetic question generation, 2021-04-19, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, EACL 2021, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_102",
            "start": 0,
            "end": 293,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_103@0",
            "content": "Mike Mintz, Steven Bills, Rion Snow, Dan Jurafsky, Distant supervision for relation extraction without labeled data, 2009, Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_103",
            "start": 0,
            "end": 285,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_104@0",
            "content": "Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, Li Deng, Ms marco: A human generated machine reading comprehension dataset, 2016, CoCo@ NIPS, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_104",
            "start": 0,
            "end": 178,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_105@0",
            "content": "UNKNOWN, None, 2021, Domain-matched pretraining tasks for dense retrieval, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_105",
            "start": 0,
            "end": 75,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_106@0",
            "content": "Yingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang Ren, Wayne Zhao, Daxiang Dong, Hua Wu, Haifeng Wang, RocketQA: An optimized training approach to dense passage retrieval for opendomain question answering, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_106",
            "start": 0,
            "end": 398,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_107@0",
            "content": "UNKNOWN, None, 2021, Towards robust neural retrieval models with synthetic pre-training, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_107",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_108@0",
            "content": "UNKNOWN, None, 2009, The probabilistic relevance framework: BM25 and beyond, Now Publishers Inc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_108",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_109@0",
            "content": "UNKNOWN, None, 2021, End-to-end training of neural retrievers for open-domain question answering, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_109",
            "start": 0,
            "end": 98,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_110@0",
            "content": "Kazutoshi Shinoda, Saku Sugawara, Akiko Aizawa, Can question generation debias question answering models? a case study on question-context lexical overlap, 2021, Proceedings of the 3rd Workshop on Machine Reading for Question Answering, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_110",
            "start": 0,
            "end": 237,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_111@0",
            "content": "George Tsatsaronis, Georgios Balikas, Prodromos Malakasiotis, Ioannis Partalas, Matthias Zschunke, Dirk Michael R Alvers, Anastasia Weissenborn, Sergios Krithara, Dimitris Petridis,  Polychronopoulos, An overview of the bioasq large-scale biomedical semantic indexing and question answering competition, 2015, BMC bioinformatics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_111",
            "start": 0,
            "end": 330,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_112@0",
            "content": "Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, Christopher Manning, HotpotQA: A dataset for diverse, explainable multi-hop question answering, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_112",
            "start": 0,
            "end": 280,
            "label": {}
        },
        {
            "ix": "202-ARR_v2_113@0",
            "content": "UNKNOWN, None, , Soujanya Poria, and Tat-Seng Chua. 2021. Retrieving and reading: A comprehensive survey on open-domain question answering, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v2_113",
            "start": 0,
            "end": 140,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "202-ARR_v2_0",
            "tgt_ix": "202-ARR_v2_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_0",
            "tgt_ix": "202-ARR_v2_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_1",
            "tgt_ix": "202-ARR_v2_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_1",
            "tgt_ix": "202-ARR_v2_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_0",
            "tgt_ix": "202-ARR_v2_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_2",
            "tgt_ix": "202-ARR_v2_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_3",
            "tgt_ix": "202-ARR_v2_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_3",
            "tgt_ix": "202-ARR_v2_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_5",
            "tgt_ix": "202-ARR_v2_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_6",
            "tgt_ix": "202-ARR_v2_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_3",
            "tgt_ix": "202-ARR_v2_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_3",
            "tgt_ix": "202-ARR_v2_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_3",
            "tgt_ix": "202-ARR_v2_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_4",
            "tgt_ix": "202-ARR_v2_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_3",
            "tgt_ix": "202-ARR_v2_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_7",
            "tgt_ix": "202-ARR_v2_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_3",
            "tgt_ix": "202-ARR_v2_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_8",
            "tgt_ix": "202-ARR_v2_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_3",
            "tgt_ix": "202-ARR_v2_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_9",
            "tgt_ix": "202-ARR_v2_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_11",
            "tgt_ix": "202-ARR_v2_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_12",
            "tgt_ix": "202-ARR_v2_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_3",
            "tgt_ix": "202-ARR_v2_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_3",
            "tgt_ix": "202-ARR_v2_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_3",
            "tgt_ix": "202-ARR_v2_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_10",
            "tgt_ix": "202-ARR_v2_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_3",
            "tgt_ix": "202-ARR_v2_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_13",
            "tgt_ix": "202-ARR_v2_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_15",
            "tgt_ix": "202-ARR_v2_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_16",
            "tgt_ix": "202-ARR_v2_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_3",
            "tgt_ix": "202-ARR_v2_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_3",
            "tgt_ix": "202-ARR_v2_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_3",
            "tgt_ix": "202-ARR_v2_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_14",
            "tgt_ix": "202-ARR_v2_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_0",
            "tgt_ix": "202-ARR_v2_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_17",
            "tgt_ix": "202-ARR_v2_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_19",
            "tgt_ix": "202-ARR_v2_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_18",
            "tgt_ix": "202-ARR_v2_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_18",
            "tgt_ix": "202-ARR_v2_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_18",
            "tgt_ix": "202-ARR_v2_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_0",
            "tgt_ix": "202-ARR_v2_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_20",
            "tgt_ix": "202-ARR_v2_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_22",
            "tgt_ix": "202-ARR_v2_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_23",
            "tgt_ix": "202-ARR_v2_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_24",
            "tgt_ix": "202-ARR_v2_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_25",
            "tgt_ix": "202-ARR_v2_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_26",
            "tgt_ix": "202-ARR_v2_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_27",
            "tgt_ix": "202-ARR_v2_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_21",
            "tgt_ix": "202-ARR_v2_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_21",
            "tgt_ix": "202-ARR_v2_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_21",
            "tgt_ix": "202-ARR_v2_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_21",
            "tgt_ix": "202-ARR_v2_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_21",
            "tgt_ix": "202-ARR_v2_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_21",
            "tgt_ix": "202-ARR_v2_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_21",
            "tgt_ix": "202-ARR_v2_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_21",
            "tgt_ix": "202-ARR_v2_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_0",
            "tgt_ix": "202-ARR_v2_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_28",
            "tgt_ix": "202-ARR_v2_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_30",
            "tgt_ix": "202-ARR_v2_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_31",
            "tgt_ix": "202-ARR_v2_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_32",
            "tgt_ix": "202-ARR_v2_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_33",
            "tgt_ix": "202-ARR_v2_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_34",
            "tgt_ix": "202-ARR_v2_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_35",
            "tgt_ix": "202-ARR_v2_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_36",
            "tgt_ix": "202-ARR_v2_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_37",
            "tgt_ix": "202-ARR_v2_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_38",
            "tgt_ix": "202-ARR_v2_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_39",
            "tgt_ix": "202-ARR_v2_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_29",
            "tgt_ix": "202-ARR_v2_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_29",
            "tgt_ix": "202-ARR_v2_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_29",
            "tgt_ix": "202-ARR_v2_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_29",
            "tgt_ix": "202-ARR_v2_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_29",
            "tgt_ix": "202-ARR_v2_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_29",
            "tgt_ix": "202-ARR_v2_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_29",
            "tgt_ix": "202-ARR_v2_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_29",
            "tgt_ix": "202-ARR_v2_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_29",
            "tgt_ix": "202-ARR_v2_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_29",
            "tgt_ix": "202-ARR_v2_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_29",
            "tgt_ix": "202-ARR_v2_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_29",
            "tgt_ix": "202-ARR_v2_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_0",
            "tgt_ix": "202-ARR_v2_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_40",
            "tgt_ix": "202-ARR_v2_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_42",
            "tgt_ix": "202-ARR_v2_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_43",
            "tgt_ix": "202-ARR_v2_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_44",
            "tgt_ix": "202-ARR_v2_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_45",
            "tgt_ix": "202-ARR_v2_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_41",
            "tgt_ix": "202-ARR_v2_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_41",
            "tgt_ix": "202-ARR_v2_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_41",
            "tgt_ix": "202-ARR_v2_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_41",
            "tgt_ix": "202-ARR_v2_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_41",
            "tgt_ix": "202-ARR_v2_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_41",
            "tgt_ix": "202-ARR_v2_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_0",
            "tgt_ix": "202-ARR_v2_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_46",
            "tgt_ix": "202-ARR_v2_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_47",
            "tgt_ix": "202-ARR_v2_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_47",
            "tgt_ix": "202-ARR_v2_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_47",
            "tgt_ix": "202-ARR_v2_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_48",
            "tgt_ix": "202-ARR_v2_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_49",
            "tgt_ix": "202-ARR_v2_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_49",
            "tgt_ix": "202-ARR_v2_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_47",
            "tgt_ix": "202-ARR_v2_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_50",
            "tgt_ix": "202-ARR_v2_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_51",
            "tgt_ix": "202-ARR_v2_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_51",
            "tgt_ix": "202-ARR_v2_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_47",
            "tgt_ix": "202-ARR_v2_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_52",
            "tgt_ix": "202-ARR_v2_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_54",
            "tgt_ix": "202-ARR_v2_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_55",
            "tgt_ix": "202-ARR_v2_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_53",
            "tgt_ix": "202-ARR_v2_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_53",
            "tgt_ix": "202-ARR_v2_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_53",
            "tgt_ix": "202-ARR_v2_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_53",
            "tgt_ix": "202-ARR_v2_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_47",
            "tgt_ix": "202-ARR_v2_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_56",
            "tgt_ix": "202-ARR_v2_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_57",
            "tgt_ix": "202-ARR_v2_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_57",
            "tgt_ix": "202-ARR_v2_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_0",
            "tgt_ix": "202-ARR_v2_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_58",
            "tgt_ix": "202-ARR_v2_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_59",
            "tgt_ix": "202-ARR_v2_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_59",
            "tgt_ix": "202-ARR_v2_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_61",
            "tgt_ix": "202-ARR_v2_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_62",
            "tgt_ix": "202-ARR_v2_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_60",
            "tgt_ix": "202-ARR_v2_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_60",
            "tgt_ix": "202-ARR_v2_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_60",
            "tgt_ix": "202-ARR_v2_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_60",
            "tgt_ix": "202-ARR_v2_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_59",
            "tgt_ix": "202-ARR_v2_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_63",
            "tgt_ix": "202-ARR_v2_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_64",
            "tgt_ix": "202-ARR_v2_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_64",
            "tgt_ix": "202-ARR_v2_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_59",
            "tgt_ix": "202-ARR_v2_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_65",
            "tgt_ix": "202-ARR_v2_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_67",
            "tgt_ix": "202-ARR_v2_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_66",
            "tgt_ix": "202-ARR_v2_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_66",
            "tgt_ix": "202-ARR_v2_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_66",
            "tgt_ix": "202-ARR_v2_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_0",
            "tgt_ix": "202-ARR_v2_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_68",
            "tgt_ix": "202-ARR_v2_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_69",
            "tgt_ix": "202-ARR_v2_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_69",
            "tgt_ix": "202-ARR_v2_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_69",
            "tgt_ix": "202-ARR_v2_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_70",
            "tgt_ix": "202-ARR_v2_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_0",
            "tgt_ix": "202-ARR_v2_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_71",
            "tgt_ix": "202-ARR_v2_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_72",
            "tgt_ix": "202-ARR_v2_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_72",
            "tgt_ix": "202-ARR_v2_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_0",
            "tgt_ix": "202-ARR_v2_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_73",
            "tgt_ix": "202-ARR_v2_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_74",
            "tgt_ix": "202-ARR_v2_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_74",
            "tgt_ix": "202-ARR_v2_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_0",
            "tgt_ix": "202-ARR_v2_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_75",
            "tgt_ix": "202-ARR_v2_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_76",
            "tgt_ix": "202-ARR_v2_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_76",
            "tgt_ix": "202-ARR_v2_77",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_76",
            "tgt_ix": "202-ARR_v2_78",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_77",
            "tgt_ix": "202-ARR_v2_78",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_76",
            "tgt_ix": "202-ARR_v2_79",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_78",
            "tgt_ix": "202-ARR_v2_79",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_80",
            "tgt_ix": "202-ARR_v2_81",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_81",
            "tgt_ix": "202-ARR_v2_82",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_82",
            "tgt_ix": "202-ARR_v2_83",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_83",
            "tgt_ix": "202-ARR_v2_84",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_84",
            "tgt_ix": "202-ARR_v2_85",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_76",
            "tgt_ix": "202-ARR_v2_80",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_76",
            "tgt_ix": "202-ARR_v2_81",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_76",
            "tgt_ix": "202-ARR_v2_82",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_76",
            "tgt_ix": "202-ARR_v2_83",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_76",
            "tgt_ix": "202-ARR_v2_84",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_76",
            "tgt_ix": "202-ARR_v2_85",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_79",
            "tgt_ix": "202-ARR_v2_80",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_76",
            "tgt_ix": "202-ARR_v2_86",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_85",
            "tgt_ix": "202-ARR_v2_86",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_76",
            "tgt_ix": "202-ARR_v2_87",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_86",
            "tgt_ix": "202-ARR_v2_87",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v2_0",
            "tgt_ix": "202-ARR_v2_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_1",
            "tgt_ix": "202-ARR_v2_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_2",
            "tgt_ix": "202-ARR_v2_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_2",
            "tgt_ix": "202-ARR_v2_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_2",
            "tgt_ix": "202-ARR_v2_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_2",
            "tgt_ix": "202-ARR_v2_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_2",
            "tgt_ix": "202-ARR_v2_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_2",
            "tgt_ix": "202-ARR_v2_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_2",
            "tgt_ix": "202-ARR_v2_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_3",
            "tgt_ix": "202-ARR_v2_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_4",
            "tgt_ix": "202-ARR_v2_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_4",
            "tgt_ix": "202-ARR_v2_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_4",
            "tgt_ix": "202-ARR_v2_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_4",
            "tgt_ix": "202-ARR_v2_4@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_5",
            "tgt_ix": "202-ARR_v2_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_6",
            "tgt_ix": "202-ARR_v2_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_7",
            "tgt_ix": "202-ARR_v2_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_8",
            "tgt_ix": "202-ARR_v2_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_9",
            "tgt_ix": "202-ARR_v2_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_10",
            "tgt_ix": "202-ARR_v2_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_11",
            "tgt_ix": "202-ARR_v2_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_11",
            "tgt_ix": "202-ARR_v2_11@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_11",
            "tgt_ix": "202-ARR_v2_11@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_11",
            "tgt_ix": "202-ARR_v2_11@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_11",
            "tgt_ix": "202-ARR_v2_11@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_11",
            "tgt_ix": "202-ARR_v2_11@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_12",
            "tgt_ix": "202-ARR_v2_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_12",
            "tgt_ix": "202-ARR_v2_12@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_12",
            "tgt_ix": "202-ARR_v2_12@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_12",
            "tgt_ix": "202-ARR_v2_12@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_13",
            "tgt_ix": "202-ARR_v2_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_13",
            "tgt_ix": "202-ARR_v2_13@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_14",
            "tgt_ix": "202-ARR_v2_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_15",
            "tgt_ix": "202-ARR_v2_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_16",
            "tgt_ix": "202-ARR_v2_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_16",
            "tgt_ix": "202-ARR_v2_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_16",
            "tgt_ix": "202-ARR_v2_16@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_16",
            "tgt_ix": "202-ARR_v2_16@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_16",
            "tgt_ix": "202-ARR_v2_16@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_16",
            "tgt_ix": "202-ARR_v2_16@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_16",
            "tgt_ix": "202-ARR_v2_16@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_17",
            "tgt_ix": "202-ARR_v2_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_17",
            "tgt_ix": "202-ARR_v2_17@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_17",
            "tgt_ix": "202-ARR_v2_17@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_17",
            "tgt_ix": "202-ARR_v2_17@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_18",
            "tgt_ix": "202-ARR_v2_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_19",
            "tgt_ix": "202-ARR_v2_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_19",
            "tgt_ix": "202-ARR_v2_19@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_19",
            "tgt_ix": "202-ARR_v2_19@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_19",
            "tgt_ix": "202-ARR_v2_19@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_19",
            "tgt_ix": "202-ARR_v2_19@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_19",
            "tgt_ix": "202-ARR_v2_19@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_19",
            "tgt_ix": "202-ARR_v2_19@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_19",
            "tgt_ix": "202-ARR_v2_19@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_19",
            "tgt_ix": "202-ARR_v2_19@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_20",
            "tgt_ix": "202-ARR_v2_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_21",
            "tgt_ix": "202-ARR_v2_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_22",
            "tgt_ix": "202-ARR_v2_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_22",
            "tgt_ix": "202-ARR_v2_22@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_23",
            "tgt_ix": "202-ARR_v2_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_23",
            "tgt_ix": "202-ARR_v2_23@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_23",
            "tgt_ix": "202-ARR_v2_23@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_24",
            "tgt_ix": "202-ARR_v2_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_25",
            "tgt_ix": "202-ARR_v2_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_26",
            "tgt_ix": "202-ARR_v2_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_26",
            "tgt_ix": "202-ARR_v2_26@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_26",
            "tgt_ix": "202-ARR_v2_26@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_27",
            "tgt_ix": "202-ARR_v2_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_28",
            "tgt_ix": "202-ARR_v2_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_28",
            "tgt_ix": "202-ARR_v2_28@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_29",
            "tgt_ix": "202-ARR_v2_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_30",
            "tgt_ix": "202-ARR_v2_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_30",
            "tgt_ix": "202-ARR_v2_30@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_30",
            "tgt_ix": "202-ARR_v2_30@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_30",
            "tgt_ix": "202-ARR_v2_30@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_30",
            "tgt_ix": "202-ARR_v2_30@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_30",
            "tgt_ix": "202-ARR_v2_30@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_31",
            "tgt_ix": "202-ARR_v2_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_32",
            "tgt_ix": "202-ARR_v2_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_33",
            "tgt_ix": "202-ARR_v2_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_34",
            "tgt_ix": "202-ARR_v2_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_34",
            "tgt_ix": "202-ARR_v2_34@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_34",
            "tgt_ix": "202-ARR_v2_34@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_34",
            "tgt_ix": "202-ARR_v2_34@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_35",
            "tgt_ix": "202-ARR_v2_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_36",
            "tgt_ix": "202-ARR_v2_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_37",
            "tgt_ix": "202-ARR_v2_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_38",
            "tgt_ix": "202-ARR_v2_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_39",
            "tgt_ix": "202-ARR_v2_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_39",
            "tgt_ix": "202-ARR_v2_39@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_39",
            "tgt_ix": "202-ARR_v2_39@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_39",
            "tgt_ix": "202-ARR_v2_39@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_40",
            "tgt_ix": "202-ARR_v2_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_41",
            "tgt_ix": "202-ARR_v2_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_42",
            "tgt_ix": "202-ARR_v2_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_42",
            "tgt_ix": "202-ARR_v2_42@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_43",
            "tgt_ix": "202-ARR_v2_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_44",
            "tgt_ix": "202-ARR_v2_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_44",
            "tgt_ix": "202-ARR_v2_44@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_44",
            "tgt_ix": "202-ARR_v2_44@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_44",
            "tgt_ix": "202-ARR_v2_44@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_45",
            "tgt_ix": "202-ARR_v2_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_46",
            "tgt_ix": "202-ARR_v2_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_47",
            "tgt_ix": "202-ARR_v2_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_48",
            "tgt_ix": "202-ARR_v2_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_49",
            "tgt_ix": "202-ARR_v2_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_50",
            "tgt_ix": "202-ARR_v2_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_50",
            "tgt_ix": "202-ARR_v2_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_50",
            "tgt_ix": "202-ARR_v2_50@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_51",
            "tgt_ix": "202-ARR_v2_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_52",
            "tgt_ix": "202-ARR_v2_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_53",
            "tgt_ix": "202-ARR_v2_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_54",
            "tgt_ix": "202-ARR_v2_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_54",
            "tgt_ix": "202-ARR_v2_54@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_55",
            "tgt_ix": "202-ARR_v2_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_56",
            "tgt_ix": "202-ARR_v2_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_56",
            "tgt_ix": "202-ARR_v2_56@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_56",
            "tgt_ix": "202-ARR_v2_56@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_56",
            "tgt_ix": "202-ARR_v2_56@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_57",
            "tgt_ix": "202-ARR_v2_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_58",
            "tgt_ix": "202-ARR_v2_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_58",
            "tgt_ix": "202-ARR_v2_58@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_58",
            "tgt_ix": "202-ARR_v2_58@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_58",
            "tgt_ix": "202-ARR_v2_58@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_58",
            "tgt_ix": "202-ARR_v2_58@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_58",
            "tgt_ix": "202-ARR_v2_58@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_59",
            "tgt_ix": "202-ARR_v2_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_60",
            "tgt_ix": "202-ARR_v2_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_61",
            "tgt_ix": "202-ARR_v2_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_62",
            "tgt_ix": "202-ARR_v2_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_62",
            "tgt_ix": "202-ARR_v2_62@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_62",
            "tgt_ix": "202-ARR_v2_62@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_63",
            "tgt_ix": "202-ARR_v2_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_63",
            "tgt_ix": "202-ARR_v2_63@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_63",
            "tgt_ix": "202-ARR_v2_63@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_63",
            "tgt_ix": "202-ARR_v2_63@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_63",
            "tgt_ix": "202-ARR_v2_63@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_64",
            "tgt_ix": "202-ARR_v2_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_65",
            "tgt_ix": "202-ARR_v2_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_65",
            "tgt_ix": "202-ARR_v2_65@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_65",
            "tgt_ix": "202-ARR_v2_65@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_65",
            "tgt_ix": "202-ARR_v2_65@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_66",
            "tgt_ix": "202-ARR_v2_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_67",
            "tgt_ix": "202-ARR_v2_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_67",
            "tgt_ix": "202-ARR_v2_67@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_67",
            "tgt_ix": "202-ARR_v2_67@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_67",
            "tgt_ix": "202-ARR_v2_67@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_67",
            "tgt_ix": "202-ARR_v2_67@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_67",
            "tgt_ix": "202-ARR_v2_67@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_67",
            "tgt_ix": "202-ARR_v2_67@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_68",
            "tgt_ix": "202-ARR_v2_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_69",
            "tgt_ix": "202-ARR_v2_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_70",
            "tgt_ix": "202-ARR_v2_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_71",
            "tgt_ix": "202-ARR_v2_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_71",
            "tgt_ix": "202-ARR_v2_71@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_71",
            "tgt_ix": "202-ARR_v2_71@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_71",
            "tgt_ix": "202-ARR_v2_71@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_71",
            "tgt_ix": "202-ARR_v2_71@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_71",
            "tgt_ix": "202-ARR_v2_71@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_71",
            "tgt_ix": "202-ARR_v2_71@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_71",
            "tgt_ix": "202-ARR_v2_71@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_72",
            "tgt_ix": "202-ARR_v2_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_73",
            "tgt_ix": "202-ARR_v2_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_73",
            "tgt_ix": "202-ARR_v2_73@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_73",
            "tgt_ix": "202-ARR_v2_73@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_73",
            "tgt_ix": "202-ARR_v2_73@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_73",
            "tgt_ix": "202-ARR_v2_73@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_73",
            "tgt_ix": "202-ARR_v2_73@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_73",
            "tgt_ix": "202-ARR_v2_73@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_73",
            "tgt_ix": "202-ARR_v2_73@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_73",
            "tgt_ix": "202-ARR_v2_73@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_73",
            "tgt_ix": "202-ARR_v2_73@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_74",
            "tgt_ix": "202-ARR_v2_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_75",
            "tgt_ix": "202-ARR_v2_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_75",
            "tgt_ix": "202-ARR_v2_75@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_75",
            "tgt_ix": "202-ARR_v2_75@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_75",
            "tgt_ix": "202-ARR_v2_75@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_76",
            "tgt_ix": "202-ARR_v2_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_77",
            "tgt_ix": "202-ARR_v2_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_77",
            "tgt_ix": "202-ARR_v2_77@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_77",
            "tgt_ix": "202-ARR_v2_77@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_77",
            "tgt_ix": "202-ARR_v2_77@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_78",
            "tgt_ix": "202-ARR_v2_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_78",
            "tgt_ix": "202-ARR_v2_78@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_79",
            "tgt_ix": "202-ARR_v2_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_79",
            "tgt_ix": "202-ARR_v2_79@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_79",
            "tgt_ix": "202-ARR_v2_79@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_79",
            "tgt_ix": "202-ARR_v2_79@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_79",
            "tgt_ix": "202-ARR_v2_79@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_79",
            "tgt_ix": "202-ARR_v2_79@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_79",
            "tgt_ix": "202-ARR_v2_79@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_80",
            "tgt_ix": "202-ARR_v2_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_81",
            "tgt_ix": "202-ARR_v2_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_82",
            "tgt_ix": "202-ARR_v2_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_82",
            "tgt_ix": "202-ARR_v2_82@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_82",
            "tgt_ix": "202-ARR_v2_82@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_82",
            "tgt_ix": "202-ARR_v2_82@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_82",
            "tgt_ix": "202-ARR_v2_82@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_83",
            "tgt_ix": "202-ARR_v2_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_83",
            "tgt_ix": "202-ARR_v2_83@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_84",
            "tgt_ix": "202-ARR_v2_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_84",
            "tgt_ix": "202-ARR_v2_84@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_84",
            "tgt_ix": "202-ARR_v2_84@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_84",
            "tgt_ix": "202-ARR_v2_84@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_85",
            "tgt_ix": "202-ARR_v2_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_85",
            "tgt_ix": "202-ARR_v2_85@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_86",
            "tgt_ix": "202-ARR_v2_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_86",
            "tgt_ix": "202-ARR_v2_86@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_86",
            "tgt_ix": "202-ARR_v2_86@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_86",
            "tgt_ix": "202-ARR_v2_86@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_86",
            "tgt_ix": "202-ARR_v2_86@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_87",
            "tgt_ix": "202-ARR_v2_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_87",
            "tgt_ix": "202-ARR_v2_87@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_88",
            "tgt_ix": "202-ARR_v2_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_89",
            "tgt_ix": "202-ARR_v2_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_90",
            "tgt_ix": "202-ARR_v2_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_91",
            "tgt_ix": "202-ARR_v2_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_92",
            "tgt_ix": "202-ARR_v2_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_93",
            "tgt_ix": "202-ARR_v2_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_94",
            "tgt_ix": "202-ARR_v2_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_95",
            "tgt_ix": "202-ARR_v2_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_96",
            "tgt_ix": "202-ARR_v2_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_97",
            "tgt_ix": "202-ARR_v2_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_98",
            "tgt_ix": "202-ARR_v2_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_99",
            "tgt_ix": "202-ARR_v2_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_100",
            "tgt_ix": "202-ARR_v2_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_101",
            "tgt_ix": "202-ARR_v2_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_102",
            "tgt_ix": "202-ARR_v2_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_103",
            "tgt_ix": "202-ARR_v2_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_104",
            "tgt_ix": "202-ARR_v2_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_105",
            "tgt_ix": "202-ARR_v2_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_106",
            "tgt_ix": "202-ARR_v2_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_107",
            "tgt_ix": "202-ARR_v2_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_108",
            "tgt_ix": "202-ARR_v2_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_109",
            "tgt_ix": "202-ARR_v2_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_110",
            "tgt_ix": "202-ARR_v2_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_111",
            "tgt_ix": "202-ARR_v2_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_112",
            "tgt_ix": "202-ARR_v2_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v2_113",
            "tgt_ix": "202-ARR_v2_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 744,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "doc_id": "202-ARR",
        "version": 2
    }
}