{
    "nodes": [
        {
            "ix": "202-ARR_v1_0",
            "content": "Hyperlink-induced Pre-training for Passage Retrieval of Open-domain Question Answering",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_2",
            "content": "To alleviate the data scarcity problem in training question answering systems, recent works propose additional intermediate pre-training for dense passage retrieval (DPR). However, there still remains a large discrepancy between the provided upstream signals and the downstream question-passage relevance, which leads to less improvement. To bridge this gap, we propose the HyperLink-induced Pre-training (HLP), a method to pre-train the dense retriever with the text relevance induced by hyperlink-based topology within Web documents. We demonstrate that the hyperlinkbased structures of dual-link and co-mention can provide effective relevance signals for large-scale pre-training that better facilitate downstream passage retrieval. We investigate the effectiveness of our approach across a wide range of open-domain QA datasets under zeroshot, few-shot, multi-hop, and out-of-domain scenarios. The experiments show our HLP outperforms the BM25 by up to 7 points as well as other pre-training methods by up to 30 points in terms of top-20 retrieval accuracy under the zero-shot scenario. Furthermore, HLP significantly outperforms other pre-training methods under the other scenarios.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "202-ARR_v1_4",
            "content": "Open-domain question answering (OpenQA) aims to answer factual open questions with a large external corpus of passages. Current approaches to OpenQA usually adopt a two-stage retriever-reader paradigm (Chen et al., 2017;Zhu et al., 2021) to fetch the final answer span. The performance of OpenQA systems is largely bounded by the retriever as it determines the evidential documents for the reader to examine. Traditional retrievers, such as TF-IDF and BM25 (Robertson and Zaragoza, 2009), are considered incapable of adapting to sce-We will soon release our source code and pre-training corpus on github.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_5",
            "content": "In 2011 he directed his first international feature film, romantic comedy \"Letters to Santa (Listy do M.)\" Who directs the romantic comedy \"Letters to Santa\"?",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_6",
            "content": "Letters to Santa (Polish: Listy do M.), alternatively known as Letters to St. Nicholas, is a 2011 Polish-language romantic comedy film, directed by the director Mitja Okorn. The action takes place during one single Christmas Eve, when a few adults find the loves of their lives.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_7",
            "content": "Letters to Santa (film)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_8",
            "content": "Human Query",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_9",
            "content": "Our HLP Query",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_10",
            "content": "The action takes place during one single Christmas Eve, when a few adults find the loves of their lives.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_11",
            "content": "ICT Query",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_12",
            "content": "The city area measures 517 km2 (200 sq mi) and comprises 18 boroughs.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_13",
            "content": "In-doc contextual Doc-wise contextual Figure 1: An example of different kinds of pseudo Q-P pairs. Underlined texts are hypertexts that linked to other Wikipedia pages. The ICT query is a random sentence originated from the passage and the WLP query is a sentence from the first section of an out-link document of the given passage. The text highlighted in green gives evidence to answer the human query, and our proposed HLP query can be a better surrogate of the human query. narios where deep semantic understanding is required. Recent works Karpukhin et al., 2020;Qu et al., 2021) show that by finetuning pre-trained language models on sufficient downstream data, dense retrievers can significantly outperform traditional term-based retrievers.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_14",
            "content": "Considering the data-hungry nature of the neural retrieval models, extensive efforts Sachan et al., 2021) have been made to design self-supervised tasks to pre-train the retriever. However, these pre-training tasks construct relevance signals largely depending on easily achieving sentence-level or document-level contextual relationships. For example, the relationship between a sentence and its originated context (shown by the ICT query in Figure 1) may not be sufficient enough to facilitate question-passage matching for the tasks of OpenQA. We also find that these pretrained retrievers still fall far behind BM25 in our pilot study on the zero-shot experiment.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_15",
            "content": "In order to address the shortcomings of the matching-oriented pre-training tasks as mentioned above, we propose a pre-training method with better surrogates of real natural question-passage (Q-P) pairs. We consider two conditions of relevance within Q-P pairs, which is similar to the process of distantly supervised retriever learning (Mintz et al., 2009;Chen et al., 2017).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_16",
            "content": "The evidence, such as entities and their corresponding relations, should exist across the query and the targeted passage as they both discuss similar facts or events related to the answer.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_17",
            "content": "should contain the answer of the query, which means that a text span within the passage can provide the information-seeking target of the query.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_18",
            "content": "In this paper, we propose HyperLink-induced Pre-training (HLP), a pre-training method to learn effective Q-P relevance induced by the hyperlink topology within naturally-occurring Web documents. Specifically, these Q-P pairs are automatically extracted from the online documents with relevance adequately designed via hyperlink-based topology to facilitate downstream retrieval for question answering. Figure 1 shows an example of comparison between the human-written query and different pseudo queries. By the guidance of hyperlinks, our HLP query hold the relevance of answer containing with the passage (query title occurs in the passage). Meanwhile, the HLP query can introduce far more effective relevance of evidence existence than other pseudo queries by deeply mining the hyperlink topology, e.g., the dual-link structure. In figure 1, both HLP query and the passage both contain information corresponding to the same fact of \"Mitja Okorn directed the film of Letters to Santa\". This makes our pseudo query low-cost and a good surrogate for the manually written query.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_19",
            "content": "Our contributions are two-fold. First, we present a hyperlink-induced relevance construction methodology that can better facilitate downstream passage retrieval for question answering, and specifically, we propose a pre-training method: Hyperlink-induced Pre-training (HLP). Second, we conduct evaluations on six popular QA datasets, investigating the effectiveness of our approach under zero-shot, few-shot, multi-hop, and out-of-domain (OOD) scenarios. The experiments show HLP outperforms BM25 in most of the cases under the zero-shot scenario and other pre-training methods under all scenarios.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_20",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "202-ARR_v1_21",
            "content": "Dense Retriever Pre-training Previous works have attempted to conduct additional pre-training for dense retrievers on various weakly supervised data. Borisov et al. (2016) and Dehghani et al. (2017) pre-trained ranking models on click-logs and BM25-induced signals respectively for web search. proposed the inverse cloze task (ICT) to pre-train a dense retrieval model, which randomly selects sentences as pseudo queries, and matched them to the passages that they originate from. Besides, proposed the pre-training task of wiki link prediction (WLP) and body first selection (BFS) tasks. Similar to our work, the WLP task also leveraged the hyperlinks within Wikipedia to construct relevant text pairs. However, as shown in figure 1, the WLP pseudo query can only ensure the weak doc-wise contextual relationship with the passage. Guu et al. (2020) 3 Hyperlink-induced Pre-training (HLP)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_22",
            "content": "In this section, we firstly discuss the background of OpenQA retrieval, then our methodology and training framework.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_23",
            "content": "Preliminaries",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "202-ARR_v1_24",
            "content": "Passage Retrieval Given a question q, passage retrieval aims to provide a set of relevant passages p from a large corpus D. Our work adopts Wikipedia as source corpus and each passage is a disjoint segment within a document from D. OpenQA Q-P Relevance For OpenQA, a passage p is considered relevant to the query q if p conveys similar facts and contains the answer to q. These two conditions of relevance, namely evidence existence and answer containing, are properly introduced into the HLP Q-P pairs under the guidance of desired hyperlink structure. We will discuss more in this section.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_25",
            "content": "To better formulate the relevance of pseudo Q-P pairs, we denote the sequence of passages within a document as A = [a 1 , a 2 , ..., a n A ] where A \u2208 D. The corresponding topical entity and the title of document A are denoted as e A and t A , respectively. We use m A to indicate a mention of entity e A , which is a hypertext span linking to document A. Note that the mention span m A is usually identical to the document title t A or a variant version of it. Further, we define F (p) as the entity-level factual information conveyed by the passage p, which is a set consists of the topical entity e P and the entities mentioned within passage p. Evidence Existence in HLP With appropriately designed hyperlink topologies, our HLP Q-P pairs guarantee the co-occurrence of entities which are presented as hypertext or topics in q and p. This is considered as evidence across the Q-P pairs:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_26",
            "content": "F (q) \u2229 F (p) = \u2205(1)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_27",
            "content": "Furthermore, we conjecture that HLP is more likely to achieve fact-level relevance than entitylevel overlap. We conduct human evaluation in Section 6.3 and case studies in Appendix G to support this conjecture. Moreover, we demonstrate that any Q-P pair containing hyperlink-induced factual evidence, which is represented as a triple that induced by hyperlinks, is included in our proposed topologies, which are included in Appendix D. Answer Containing in HLP We consider the document title t Q as the information-seeking target of q. Accordingly, the relevance of answer containing can be formulated as",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_28",
            "content": "t Q \u2286 p (2)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_29",
            "content": "The rationale behind this is that both the natural question and the Wikipedia document are intended to describe related facts and events regarding a targeted object, whereas the object is an answer for a question but a topic for a Wikipedia document. This similarity leads us to take the document title as the information-seeking target of its context.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_30",
            "content": "Hyperlink-induced Q-P Pairs",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "202-ARR_v1_31",
            "content": "Based on analysis of how queries match their evidential passages in the NQ (Kwiatkowski et al., 2019) dataset, we propose two kinds of hyperlink topology for relevance construction: Dual-link and Co-mention. We present our exploratory data analysis on NQ dataset in Appendix C. Here we discuss the desired hyperlink topologies and the corresponding relevance of the pseudo Q-P pairs. Dual-link (DL) Among all NQ training samples, 55% of questions mention the title of their corresponding golden passage. This observation motivates us to leverage the topology of dual-link (DL) for relevance construction. We consider a passage pair (a i , b j ) follows the dual-link topology if they link to each other. An example of a DL pair (a i , b j ) is shown in Figure 2, in which passage b j mentions the title of document A as m A , satisfying the condition of answer containing:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_32",
            "content": "t A \u2248 m A and m A \u2286 b j (3)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_33",
            "content": "Further, since the passages a i and b j both mention the topical entity of the other, the entities e A and e B appear in both passages as evidence:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_34",
            "content": "{e A , e B } \u2286 F (a i ) \u2229 F (b j )(4)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_35",
            "content": "Co-mention (CM) Among all NQ training samples, about 40% of questions fail to match the duallink condition but mention the same third-party entity as their corresponding golden passages. In light of this observation, we utilize another topology of Co-mention (CM). We consider that a passage pair (c k , d l ) follows the Co-mention topology if they both link to a third-party document E and d l links to c k . Figure 2 illustrates a CM pair (c l , d k )",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_36",
            "content": "where answer containing is ensured as the title of c k occurs in d l :",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_37",
            "content": "t C \u2248 m C and m C \u2286 d l(5)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_38",
            "content": "Since both c l and d k mention a third-party entity e E , and that e C is a topical entity in c l while a mentioned entity in d k , we have entity-level evidence across c l and d k as:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_39",
            "content": "{e C , e E } \u2286 F (c k ) \u2229 F (d l )(6)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_40",
            "content": "In practice, we use sentence-level queries which contain the corresponding evidential hypertext, and we do not prepend the title to the passage in order to reduce the superficial entity-level overlap. To improve the quality of CM pairs, we filter out those with a co-mentioned entity which has a top 10% highest-ranked in-degree among the Wikipedia entity. To illustrate how we construct our pseudo Q-P pairs, we present pseudo code in Appendix E. Furthermore, we highlight that HLP has the following advantages: 1) it introduces more semantic variants and paraphrasing for better text matching.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_41",
            "content": "2) The hypertext reflects potential interests or needs of users in relevant information, which is consistent to the downstream information-seeking propose.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_42",
            "content": "Bi-encoder Training",
            "ntype": "title",
            "meta": {
                "section": "3.3"
            }
        },
        {
            "ix": "202-ARR_v1_43",
            "content": "We adopt a BERT-based bi-encoder to encode queries and passages separately into d-dimension vectors. The output representation is derived from the last hidden state of the [CLS] token and the final matching score is measured by the inner product:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_44",
            "content": "h q = BERT Q (q)([CLS]) h p = BERT P (p)([CLS]) S(p, q) = h T q \u2022 h p Let B = { q i , p + i , p \u2212 i } n i=1",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_45",
            "content": "be a mini-batch with n instances. Each instance contains a question q i paired with a positive passage p + i and a negative passage p \u2212 i . With in-batch negative sampling, each question q i considers all the passages in B except its own gold p + i as negatives, resulting in 2n \u2212 1 negatives per question in total. We use the negative log likelihood of the positive passage as our loss for optimization:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_46",
            "content": "L(q i , p + i , p \u2212 i,1 , ..., p \u2212 i,2n\u22121 ) = \u2212 log e S(q i ,p + i )",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_47",
            "content": "e S(q i ,p + i ) + 2n\u22121 j=1 e S(q i ,p \u2212 i,j )",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_48",
            "content": "Experimental Setup",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "202-ARR_v1_49",
            "content": "In this session, we discuss the pre-training corpus preparation, downstream datasets, the hyperparameter and the basic setup for our experiments.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_50",
            "content": "Pre-training Corpus",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "202-ARR_v1_51",
            "content": "We adopt Wikipedia as our source corpus D for pretraining as it is the largest encyclopedia covering diverse topics with good content quality and linking structures. We choose the snapshot 03-01-2021 of an English Wikipedia dump, and process it with WikiExtractor 2 to obtain clean context. After filtering out documents with blank text or a title less than three letters, following previous work (Karpukhin et al., 2020), we split the remaining documents into disjoint chunks of 100 words as passages, resulting in over 22 million passages in the end.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_52",
            "content": "Downstream Datasets",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "202-ARR_v1_53",
            "content": "We",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_54",
            "content": "Implementation Details",
            "ntype": "title",
            "meta": {
                "section": "4.3"
            }
        },
        {
            "ix": "202-ARR_v1_55",
            "content": "During the pre-training, we train the bi-encoder for 5 epochs with parameters shared, using a batch size of 400 and an Adam optimizer (Kingma and Ba, 2014) with a learning rate 2 \u00d7 10 \u22125 , linear scheduling with 10% warm-up steps. Our HLP and all the reproduced baselines are trained on 20 million Q-P pairs with in-batch negative sampling, and the best checkpoints are selected based on the average rank of gold passages evaluated on the NQ dev set.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_56",
            "content": "The pre-training takes around 3 days using eight NVIDIA V100 32GB GPUs.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_57",
            "content": "For the downstream, we use the same hyperparameters for all experiments. Specifically, we fine-tune the pre-trained models for 40 epochs with a batch size of 256 and the same optimizer and learning rate settings to the pre-training. We conduct evaluation on respective dev sets to select best checkpoints, and we use the last checkpoint if there is no dev set or test set (e.g. HotpotQA). More details can be found in the Appendix A.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_58",
            "content": "Baselines",
            "ntype": "title",
            "meta": {
                "section": "4.4"
            }
        },
        {
            "ix": "202-ARR_v1_59",
            "content": "Most existing baselines have been implemented under different experimental settings, which have a substantial effect on the retrieval performance. To ensure fairness, we reproduce several pre-training methods (ICT, WLP, BFS, and their combination) under the same experimental setting, such as batch size, base model, amount of pre-training data, and so on. The only difference between our method and the re-implemented baselines is the self-supervision signal derived from the respective pre-training samples. Our reproduced BM25 baseline is better than that reported in Karpukhin et al. (2020), and the re-implemented pre-training methods also perform better than those reported by the recent work 3 . In addition, we include the work REALM (Guu et al., 2020) as a baseline which has recently been reproduced by Sachan et al. ( 2021) using 240 GPUs and is named masked salient spans (MSS). We note that most related works gain improvements from varying downstream setting or synthetic pre-training with access to the downstream data of respective domain, which is out of the scope of our interests.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_60",
            "content": "Experiments",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "202-ARR_v1_61",
            "content": "Main Results",
            "ntype": "title",
            "meta": {
                "section": "5.1"
            }
        },
        {
            "ix": "202-ARR_v1_62",
            "content": "Table 1 shows the retrieval accuracy of different models on three popular QA datasets under zeroshot and full-set fine-tuning settings.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_63",
            "content": "Under zero-shot setting, HLP consistently outperforms BM25 except for the top-5 retrieval accuracy of TriviaQA, while all other pre-training baselines are far behind. We attribute the minor improvement over BM25 on TriviaQA to a high overlap between questions and passages, which gives term-based retriever a clear advantage. We investigate the coverage of the question tokens that appear in the gold passage and find that the overlap is indeed higher in TriviaQA (62.8%) than NQ (60.7%) and WQ (57.5%).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_64",
            "content": "After fine-tuning, all models with intermediate pre-training give better results than the vanilla DPR while our HLP achieves the best in nearly all cases. Among ICT, WLP and BFS, we observe that WLP is the most competitive with or without fine-tuning, and additional improvements can be achieved by combining three of them. This observation indicates that pre-training with diverse relevance leads to better generalization to downstream tasks, while document-wise relevance is more adaptable for the OpenQA retrieval. The advantage of documentwise relevance may come from the fact that texts in different documents are likely written by different parties, providing less superficial cues for text matching, which is beneficial for the downstream retrieval. Our HLP learns both coarse-grained document-wise relationships as well as the finegrained entity-level evidence, which results in a significant improvement.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_65",
            "content": "Few-shot Learning",
            "ntype": "title",
            "meta": {
                "section": "5.2"
            }
        },
        {
            "ix": "202-ARR_v1_66",
            "content": "To investigate the retrieval effectiveness in a more realistic scenario, we conduct experiments for few-shot learning. Specifically, we fine-tune the pre-trained models on large datasets (NQ, Triv-iaQA) with m (m = {16, 256, 1024}) samples and present the few-shot retrieval results in Table 2. With only a few hundred labeled data for fine-tuning, all the models with intermediate pre-training perform better than that without, and HLP outperforms the other methods by a larger margin when m is smaller. Among three reimplemented baselines, WLP gains the largest improvement with increasing number of samples, outperforming ICT and BFS when a thousand labelled samples are provided for fine-tuning.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_67",
            "content": "Multi-hop Retrieval",
            "ntype": "title",
            "meta": {
                "section": "5.4"
            }
        },
        {
            "ix": "202-ARR_v1_68",
            "content": "While HLP aims to acquires the ability in matching document-wise concepts and facts, it raises our interest in its capability for multi-hop scenarios. We evaluate our methods on HotpotQA in a single-hop manner. Specifically, for each query, we randomly selects one golden passage from the two as a positive passage and one additional passage with high TF-IDF scores as a negative passage. Our models are further fine-tuned on the HotpotQA training set and evaluated on the bridge and the comparison type questions from the development set, respectively. The results of our study are shown in Table 5: Retrieval accuracy on questions from Hot-potQA dev set, measured as the percentage of top-k retrieved passages which include both golds.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_69",
            "content": "6 Analysis",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_70",
            "content": "Ablation Study",
            "ntype": "title",
            "meta": {
                "section": "6.1"
            }
        },
        {
            "ix": "202-ARR_v1_71",
            "content": "To better understand how different key factors affect the results, we conduct ablation experiments with results shown in Table 3.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_72",
            "content": "Our proposed dual-link (DL) and co-mention (CM) Q-P pairs, provide evidence induced by different hyperlinkbased topologies. To examine their respective effectiveness, we pre-train retrievers on Q-P pairs derived from each topology and their combinations. We present zero-shot retrieval results in Table 3, which show that retrievers pre-trained on DL pairs has a distinct advantage over that on CM pairs, while combining both gives extra improvement. Negative Passage In practice, negative sampling is essential for learning a high-quality encoder. Besides in-batch negative, our reported HLP employs one additional negative for each query. We further explore the impact of the additional negatives during pre-training. In our ablation study, pre-training with additional negatives improves the results significantly, which may be attributed to using more in-batch pairs for text matching. More details on implementation and negative sampling strategies can be found in Appendix B.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_73",
            "content": "Analysis on Q-P Overlap",
            "ntype": "title",
            "meta": {
                "section": "6.2"
            }
        },
        {
            "ix": "202-ARR_v1_74",
            "content": "We carry out extensive analysis on the Q-P lexical overlap in the task of retrieval. Specifically, we tokenize q, p using the BERT tokenizer and measure the Q-P overlap as the proportion of the question tokens that appear in the corresponding passage. Based on the degree of Q-P overlap, we divided the NQ dev set into five categories for further analysis. Distribution of Q-P Overlap Figure 3 shows both the pre-training and the retrieved pairs of HLP have a more similar overlap distribution with the downstream NQ dataset than the other methods, which implies the consistency between the relevance provided by HLP and that in real informationseeking scenario. Retrieval Performance vs. Q-P Overlap Figure 4 shows the top-20 retrieval accuracy on the samples with varying degrees of Q-P overlap. Both figures show that the retrievers are more likely to return answer-containing passages when there is higher Q-P overlap, suggesting that all these models can exploit lexical overlap for passage retrieval. Under the zero-shot setting, HLP outperforms all the methods except BM25 when r is larger than 0.8, which reflects the strong reasoning ability of HLP and the overlap-dependent nature of the termbased retrievers. After fine-tuning, models with additional pre-training perform better than the vanilla DPR while HLP outperforms all other methods in most of the cases. It is important to note that HLP is pre-trained on more high-overlap text pairs while it performs better than all the other methods when fewer overlaps are provided. We speculate that this is because the overlapping in HLP Q-P pairs mostly comes from the factual information, such as entity, which introduces fewer superficial cues, allowing for better adaptation to the downstream cases.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_75",
            "content": "Human Evaluation on Q-P pairs",
            "ntype": "title",
            "meta": {
                "section": "6.3"
            }
        },
        {
            "ix": "202-ARR_v1_76",
            "content": "We conduct human evaluation to investigate the proportion of Q-P pairs that convey the similar factlevel information. Specially, we randomly selected one hundred examples from our constructed Q-P pairs and asked annotators to identify whether the query and the corresponding passage convey similar facts. Each case is evaluated by three annotators and the result is determined by their votes. Our results are shown in",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_77",
            "content": "For the pre-training, all models including our reproduced baselines are trained with 20 million Q-P pairs with in-batch negative sampling. Specifically, our reported HLP is trained on the combination of 10 million DL pairs and 10 million CM pairs. The HLP (DL) and HLP (CM) reported in",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_78",
            "content": "In this part, we detailedly discuss how we conduct exploratory data analysis on NQ training set to determine the hyperlink-based topology. Driven by a strong interest in what kind of roles the overlapping spans play between the queries q and passages p, we conduct exploratory data analysis on the widelyused NQ dataset. Specifically, we recognize all entities and mentions from the queries and the passages using TagMe (Ferragina and Scaiella, 2010) for further investigation. As a result, we observe about 55% queries q either explicitly mentions the titles of p or the successfully links to the document where p originated via TagMe, which motivates us to construct the dual-link topology where the pseudo queries q mention p via a hypertext. Moreover, we observe about 45% queries do not mention title of q but share the same mentions with p which encourages us to adopt the co-mention topology where the pseudo q and p both mention a third-party document through hypertext.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_79",
            "content": "Intuitively, we assume the mentioned entity, let's say e Y mentioned in a Wikipedia document X, is used to describe the topical entity e X of this document. In other words, e Y is likely to attend in a topically relevant fact or event, which can be represented as a triple <e X , r XY , e Y > where r XY is a latent relation between e X and e Y .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_80",
            "content": "Given any passage pair (q, p) from Wikipedia, we call q and p have fact-level evidence if they both entail a fact that can be represented as a triple <e X , r XY , e Y > where e X , e Y are entities and r XY is their corresponding relations. Further, if both passages q and p contain representative hypertext or topic of e X and e Y , we say this fact-level evidence can be induced by hyperlink-based topology, namely hyperlink-induced fact. In this session, we prove that any Q-P pair with hyperlink-induced fact while satisfying answer containing is within either DL or CM hyperlink-based topology.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_81",
            "content": "Following the example above, both q and p contain a factual triple <e X , r XY , e Y >. Since mentioned entities are used to describe the topical entity, we have facts <e Q , r QX , e X >, <e Q , r QY , e Y > at q-side while <e P , r P X , e X >, <e P , r P Y , e Y > at p-side. Further, p contains <e P , r P Q , e Q > because of the answer containing condition.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_82",
            "content": "Case1: The entity e P = e X or e P = e Y . Then q provides facts <e Q , r QP , e P > where r QP is likely but not necessarily to be identical to r P Q in p. In this case, (q, p) fits in the Dual-link topology in our definition.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_83",
            "content": "Case2: The entity e P = e X and e P = e Y . Then given the facts <e Q , r QX , e X > at q-side, and <e P , r P X , e X >, <e P , r P Q , e Q > at p-side, (q, p) fits in the Co-mention topology.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_84",
            "content": "Algorithm 1: HLP Pairs Identification Notation: q, p \u2190 Wikipedia passages t Q \u2190 Topical entity of passage q M(q) \u2190 The set of entities mentioned in q d in (q) \u2190 in-degree of the Wikipedia entity t Q K \u2190 in-degree threshold for CM pairs Def IsDL(q, p):",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_85",
            "content": "if t P \u2208 M(q) & t Q \u2208 M(p)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_86",
            "content": "We evaluate HLP on multi-hop scenario where knowledge from different documents need to be associated for retrieval. Besides significant improvements shown in Table 5, we conduct case study to investigate its capability on knowledgeintensive retrieval. In Table 8, a complex question is proposed, requiring the retriever firstly to retrieve the document \"Apple Remote\" and then \"Front Row (software)\" to fetch the final answer.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_87",
            "content": "Our HLP successfully retrieves both golds in the top-10 retrieved passages while the vanilla DPR fails. We find 6 items retrieved by HIS are related to the brand \"Apple\" while 4 are by DPR, showing stronger comprehension and associative ability from HLP.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_88",
            "content": "Besides human evaluation, we present case studies on HLP Q-P pairs, which is shown in Table 9 and Table 10. As we can see in the tables, a few lexical variants of entities and fact-level paraphrasing are presented across questions and passages, which can be interpreted as factual evidence for OpenQA passage matching. For example, entity-level variants such as \"Robert and Richard Sherman\" vs. \"Sherman Brothers\", and fact-level paraphrases such as \"Abby Kelley and Stephen Symonds Foster ... working for abolitionism\" vs. \"... radical abolitionists, Abby Kelley Foster and her husband Stephen S.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_89",
            "content": "Foster\" can be found in our examples.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "202-ARR_v1_90",
            "content": "Jonathan Berant, Andrew Chou, Roy Frostig, Percy Liang, Semantic parsing on freebase from question-answer pairs, 2013, Proceedings of the 2013 conference on empirical methods in natural language processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "Jonathan Berant",
                    "Andrew Chou",
                    "Roy Frostig",
                    "Percy Liang"
                ],
                "title": "Semantic parsing on freebase from question-answer pairs",
                "pub_date": "2013",
                "pub_title": "Proceedings of the 2013 conference on empirical methods in natural language processing",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v1_91",
            "content": "Alexey Borisov, Ilya Markov, Pavel Maarten De Rijke,  Serdyukov, A neural click model for web search, 2016-04-11, Proceedings of the 25th International Conference on World Wide Web, WWW 2016, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Alexey Borisov",
                    "Ilya Markov",
                    "Pavel Maarten De Rijke",
                    " Serdyukov"
                ],
                "title": "A neural click model for web search",
                "pub_date": "2016-04-11",
                "pub_title": "Proceedings of the 25th International Conference on World Wide Web, WWW 2016",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v1_92",
            "content": "UNKNOWN, None, 2020, Pretraining tasks for embedding-based large-scale retrieval, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Pretraining tasks for embedding-based large-scale retrieval",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v1_93",
            "content": "Danqi Chen, Adam Fisch, Jason Weston, Antoine Bordes, Reading wikipedia to answer opendomain questions, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Danqi Chen",
                    "Adam Fisch",
                    "Jason Weston",
                    "Antoine Bordes"
                ],
                "title": "Reading wikipedia to answer opendomain questions",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "202-ARR_v1_94",
            "content": "Mostafa Dehghani, Hamed Zamani, Aliaksei Severyn, Jaap Kamps, W Croft, Neural ranking models with weak supervision, 2017-08-07, Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Mostafa Dehghani",
                    "Hamed Zamani",
                    "Aliaksei Severyn",
                    "Jaap Kamps",
                    "W Croft"
                ],
                "title": "Neural ranking models with weak supervision",
                "pub_date": "2017-08-07",
                "pub_title": "Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v1_95",
            "content": "Paolo Ferragina, Ugo Scaiella, Tagme: on-the-fly annotation of short text fragments (by wikipedia entities), 2010, Proceedings of the 19th ACM international conference on Information and knowledge management, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "Paolo Ferragina",
                    "Ugo Scaiella"
                ],
                "title": "Tagme: on-the-fly annotation of short text fragments (by wikipedia entities)",
                "pub_date": "2010",
                "pub_title": "Proceedings of the 19th ACM international conference on Information and knowledge management",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v1_96",
            "content": "UNKNOWN, None, , 2020. Don't stop pretraining: adapt language models to domains and tasks, .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "2020. Don't stop pretraining: adapt language models to domains and tasks",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v1_97",
            "content": "Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, Mingwei Chang, Retrieval augmented language model pre-training, 2020, International Conference on Machine Learning, PMLR.",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Kelvin Guu",
                    "Kenton Lee",
                    "Zora Tung",
                    "Panupong Pasupat",
                    "Mingwei Chang"
                ],
                "title": "Retrieval augmented language model pre-training",
                "pub_date": "2020",
                "pub_title": "International Conference on Machine Learning",
                "pub": "PMLR"
            }
        },
        {
            "ix": "202-ARR_v1_98",
            "content": "Mandar Joshi, Eunsol Choi, S Daniel, Luke Weld,  Zettlemoyer, Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Mandar Joshi",
                    "Eunsol Choi",
                    "S Daniel",
                    "Luke Weld",
                    " Zettlemoyer"
                ],
                "title": "Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v1_99",
            "content": "Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, Wen-Tau Yih, Dense passage retrieval for open-domain question answering, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Vladimir Karpukhin",
                    "Barlas Oguz",
                    "Sewon Min",
                    "Patrick Lewis",
                    "Ledell Wu",
                    "Sergey Edunov",
                    "Danqi Chen",
                    "Wen-Tau Yih"
                ],
                "title": "Dense passage retrieval for open-domain question answering",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v1_100",
            "content": "UNKNOWN, None, 2014, Adam: A method for stochastic optimization, .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": null,
                "title": null,
                "pub_date": "2014",
                "pub_title": "Adam: A method for stochastic optimization",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v1_101",
            "content": "Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Natural questions: a benchmark for question answering research, 2019, Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Tom Kwiatkowski",
                    "Jennimaria Palomaki",
                    "Olivia Redfield",
                    "Michael Collins",
                    "Ankur Parikh",
                    "Chris Alberti",
                    "Danielle Epstein",
                    "Illia Polosukhin",
                    "Jacob Devlin",
                    "Kenton Lee"
                ],
                "title": "Natural questions: a benchmark for question answering research",
                "pub_date": "2019",
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v1_102",
            "content": "Kenton Lee, Ming-Wei Chang, Kristina Toutanova, Latent retrieval for weakly supervised open domain question answering, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Kenton Lee",
                    "Ming-Wei Chang",
                    "Kristina Toutanova"
                ],
                "title": "Latent retrieval for weakly supervised open domain question answering",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v1_103",
            "content": "UNKNOWN, None, 2021, PAQ: 65 million probably-asked questions and what you can do with them, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "PAQ: 65 million probably-asked questions and what you can do with them",
                "pub": "CoRR"
            }
        },
        {
            "ix": "202-ARR_v1_104",
            "content": "Ji Ma, Ivan Korotkov, Yinfei Yang, Keith Hall, Ryan Mcdonald, Zero-shot neural passage retrieval via domain-targeted synthetic question generation, 2021-04-19, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, EACL 2021, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Ji Ma",
                    "Ivan Korotkov",
                    "Yinfei Yang",
                    "Keith Hall",
                    "Ryan Mcdonald"
                ],
                "title": "Zero-shot neural passage retrieval via domain-targeted synthetic question generation",
                "pub_date": "2021-04-19",
                "pub_title": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, EACL 2021",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v1_105",
            "content": "Mike Mintz, Steven Bills, Rion Snow, Dan Jurafsky, Distant supervision for relation extraction without labeled data, 2009, Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Mike Mintz",
                    "Steven Bills",
                    "Rion Snow",
                    "Dan Jurafsky"
                ],
                "title": "Distant supervision for relation extraction without labeled data",
                "pub_date": "2009",
                "pub_title": "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v1_106",
            "content": "Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, Li Deng, Ms marco: A human generated machine reading comprehension dataset, 2016, CoCo@ NIPS, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "Tri Nguyen",
                    "Mir Rosenberg",
                    "Xia Song",
                    "Jianfeng Gao",
                    "Saurabh Tiwary",
                    "Rangan Majumder",
                    "Li Deng"
                ],
                "title": "Ms marco: A human generated machine reading comprehension dataset",
                "pub_date": "2016",
                "pub_title": "CoCo@ NIPS",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v1_107",
            "content": "UNKNOWN, None, 2021, Domain-matched pretraining tasks for dense retrieval, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Domain-matched pretraining tasks for dense retrieval",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v1_108",
            "content": "Yingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang Ren, Wayne Zhao, Daxiang Dong, Hua Wu, Haifeng Wang, Rocketqa: An optimized training approach to dense passage retrieval for opendomain question answering, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Yingqi Qu",
                    "Yuchen Ding",
                    "Jing Liu",
                    "Kai Liu",
                    "Ruiyang Ren",
                    "Wayne Zhao",
                    "Daxiang Dong",
                    "Hua Wu",
                    "Haifeng Wang"
                ],
                "title": "Rocketqa: An optimized training approach to dense passage retrieval for opendomain question answering",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "202-ARR_v1_109",
            "content": "UNKNOWN, None, , Heng Ji, and Avirup Sil. 2021. Towards robust neural retrieval, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Heng Ji, and Avirup Sil. 2021. Towards robust neural retrieval",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "202-ARR_v1_0@0",
            "content": "Hyperlink-induced Pre-training for Passage Retrieval of Open-domain Question Answering",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_0",
            "start": 0,
            "end": 85,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_2@0",
            "content": "To alleviate the data scarcity problem in training question answering systems, recent works propose additional intermediate pre-training for dense passage retrieval (DPR).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_2",
            "start": 0,
            "end": 170,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_2@1",
            "content": "However, there still remains a large discrepancy between the provided upstream signals and the downstream question-passage relevance, which leads to less improvement.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_2",
            "start": 172,
            "end": 337,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_2@2",
            "content": "To bridge this gap, we propose the HyperLink-induced Pre-training (HLP), a method to pre-train the dense retriever with the text relevance induced by hyperlink-based topology within Web documents.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_2",
            "start": 339,
            "end": 534,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_2@3",
            "content": "We demonstrate that the hyperlinkbased structures of dual-link and co-mention can provide effective relevance signals for large-scale pre-training that better facilitate downstream passage retrieval.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_2",
            "start": 536,
            "end": 734,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_2@4",
            "content": "We investigate the effectiveness of our approach across a wide range of open-domain QA datasets under zeroshot, few-shot, multi-hop, and out-of-domain scenarios.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_2",
            "start": 736,
            "end": 896,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_2@5",
            "content": "The experiments show our HLP outperforms the BM25 by up to 7 points as well as other pre-training methods by up to 30 points in terms of top-20 retrieval accuracy under the zero-shot scenario.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_2",
            "start": 898,
            "end": 1089,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_2@6",
            "content": "Furthermore, HLP significantly outperforms other pre-training methods under the other scenarios.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_2",
            "start": 1091,
            "end": 1186,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_4@0",
            "content": "Open-domain question answering (OpenQA) aims to answer factual open questions with a large external corpus of passages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_4",
            "start": 0,
            "end": 118,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_4@1",
            "content": "Current approaches to OpenQA usually adopt a two-stage retriever-reader paradigm (Chen et al., 2017;Zhu et al., 2021) to fetch the final answer span.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_4",
            "start": 120,
            "end": 268,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_4@2",
            "content": "The performance of OpenQA systems is largely bounded by the retriever as it determines the evidential documents for the reader to examine.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_4",
            "start": 270,
            "end": 407,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_4@3",
            "content": "Traditional retrievers, such as TF-IDF and BM25 (Robertson and Zaragoza, 2009), are considered incapable of adapting to sce-We will soon release our source code and pre-training corpus on github.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_4",
            "start": 409,
            "end": 603,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_5@0",
            "content": "In 2011 he directed his first international feature film, romantic comedy \"Letters to Santa (Listy do M.)\" Who directs the romantic comedy \"Letters to Santa\"?",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_5",
            "start": 0,
            "end": 157,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_6@0",
            "content": "Letters to Santa (Polish: Listy do M.), alternatively known as Letters to St. Nicholas, is a 2011 Polish-language romantic comedy film, directed by the director Mitja Okorn.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_6",
            "start": 0,
            "end": 172,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_6@1",
            "content": "The action takes place during one single Christmas Eve, when a few adults find the loves of their lives.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_6",
            "start": 174,
            "end": 277,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_7@0",
            "content": "Letters to Santa (film)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_7",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_8@0",
            "content": "Human Query",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_8",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_9@0",
            "content": "Our HLP Query",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_9",
            "start": 0,
            "end": 12,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_10@0",
            "content": "The action takes place during one single Christmas Eve, when a few adults find the loves of their lives.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_10",
            "start": 0,
            "end": 103,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_11@0",
            "content": "ICT Query",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_11",
            "start": 0,
            "end": 8,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_12@0",
            "content": "The city area measures 517 km2 (200 sq mi) and comprises 18 boroughs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_12",
            "start": 0,
            "end": 68,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_13@0",
            "content": "In-doc contextual Doc-wise contextual Figure 1: An example of different kinds of pseudo Q-P pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_13",
            "start": 0,
            "end": 97,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_13@1",
            "content": "Underlined texts are hypertexts that linked to other Wikipedia pages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_13",
            "start": 99,
            "end": 167,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_13@2",
            "content": "The ICT query is a random sentence originated from the passage and the WLP query is a sentence from the first section of an out-link document of the given passage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_13",
            "start": 169,
            "end": 331,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_13@3",
            "content": "The text highlighted in green gives evidence to answer the human query, and our proposed HLP query can be a better surrogate of the human query.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_13",
            "start": 333,
            "end": 476,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_13@4",
            "content": "narios where deep semantic understanding is required.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_13",
            "start": 478,
            "end": 530,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_13@5",
            "content": "Recent works Karpukhin et al., 2020;Qu et al., 2021) show that by finetuning pre-trained language models on sufficient downstream data, dense retrievers can significantly outperform traditional term-based retrievers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_13",
            "start": 532,
            "end": 747,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_14@0",
            "content": "Considering the data-hungry nature of the neural retrieval models, extensive efforts Sachan et al., 2021) have been made to design self-supervised tasks to pre-train the retriever.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_14",
            "start": 0,
            "end": 179,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_14@1",
            "content": "However, these pre-training tasks construct relevance signals largely depending on easily achieving sentence-level or document-level contextual relationships.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_14",
            "start": 181,
            "end": 338,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_14@2",
            "content": "For example, the relationship between a sentence and its originated context (shown by the ICT query in Figure 1) may not be sufficient enough to facilitate question-passage matching for the tasks of OpenQA.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_14",
            "start": 340,
            "end": 545,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_14@3",
            "content": "We also find that these pretrained retrievers still fall far behind BM25 in our pilot study on the zero-shot experiment.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_14",
            "start": 547,
            "end": 666,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_15@0",
            "content": "In order to address the shortcomings of the matching-oriented pre-training tasks as mentioned above, we propose a pre-training method with better surrogates of real natural question-passage (Q-P) pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_15",
            "start": 0,
            "end": 201,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_15@1",
            "content": "We consider two conditions of relevance within Q-P pairs, which is similar to the process of distantly supervised retriever learning (Mintz et al., 2009;Chen et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_15",
            "start": 203,
            "end": 374,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_16@0",
            "content": "The evidence, such as entities and their corresponding relations, should exist across the query and the targeted passage as they both discuss similar facts or events related to the answer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_16",
            "start": 0,
            "end": 187,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_17@0",
            "content": "should contain the answer of the query, which means that a text span within the passage can provide the information-seeking target of the query.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_17",
            "start": 0,
            "end": 143,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_18@0",
            "content": "In this paper, we propose HyperLink-induced Pre-training (HLP), a pre-training method to learn effective Q-P relevance induced by the hyperlink topology within naturally-occurring Web documents.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_18",
            "start": 0,
            "end": 193,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_18@1",
            "content": "Specifically, these Q-P pairs are automatically extracted from the online documents with relevance adequately designed via hyperlink-based topology to facilitate downstream retrieval for question answering.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_18",
            "start": 195,
            "end": 400,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_18@2",
            "content": "Figure 1 shows an example of comparison between the human-written query and different pseudo queries.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_18",
            "start": 402,
            "end": 502,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_18@3",
            "content": "By the guidance of hyperlinks, our HLP query hold the relevance of answer containing with the passage (query title occurs in the passage).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_18",
            "start": 504,
            "end": 641,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_18@4",
            "content": "Meanwhile, the HLP query can introduce far more effective relevance of evidence existence than other pseudo queries by deeply mining the hyperlink topology, e.g., the dual-link structure.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_18",
            "start": 643,
            "end": 829,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_18@5",
            "content": "In figure 1, both HLP query and the passage both contain information corresponding to the same fact of \"Mitja Okorn directed the film of Letters to Santa\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_18",
            "start": 831,
            "end": 985,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_18@6",
            "content": "This makes our pseudo query low-cost and a good surrogate for the manually written query.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_18",
            "start": 987,
            "end": 1075,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_19@0",
            "content": "Our contributions are two-fold.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_19",
            "start": 0,
            "end": 30,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_19@1",
            "content": "First, we present a hyperlink-induced relevance construction methodology that can better facilitate downstream passage retrieval for question answering, and specifically, we propose a pre-training method: Hyperlink-induced Pre-training (HLP).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_19",
            "start": 32,
            "end": 273,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_19@2",
            "content": "Second, we conduct evaluations on six popular QA datasets, investigating the effectiveness of our approach under zero-shot, few-shot, multi-hop, and out-of-domain (OOD) scenarios.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_19",
            "start": 275,
            "end": 453,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_19@3",
            "content": "The experiments show HLP outperforms BM25 in most of the cases under the zero-shot scenario and other pre-training methods under all scenarios.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_19",
            "start": 455,
            "end": 597,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_20@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_20",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_21@0",
            "content": "Dense Retriever Pre-training Previous works have attempted to conduct additional pre-training for dense retrievers on various weakly supervised data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_21",
            "start": 0,
            "end": 148,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_21@1",
            "content": "Borisov et al. (2016) and Dehghani et al. (2017) pre-trained ranking models on click-logs and BM25-induced signals respectively for web search.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_21",
            "start": 150,
            "end": 292,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_21@2",
            "content": "proposed the inverse cloze task (ICT) to pre-train a dense retrieval model, which randomly selects sentences as pseudo queries, and matched them to the passages that they originate from.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_21",
            "start": 294,
            "end": 479,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_21@3",
            "content": "Besides, proposed the pre-training task of wiki link prediction (WLP) and body first selection (BFS) tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_21",
            "start": 481,
            "end": 587,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_21@4",
            "content": "Similar to our work, the WLP task also leveraged the hyperlinks within Wikipedia to construct relevant text pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_21",
            "start": 589,
            "end": 702,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_21@5",
            "content": "However, as shown in figure 1, the WLP pseudo query can only ensure the weak doc-wise contextual relationship with the passage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_21",
            "start": 704,
            "end": 830,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_21@6",
            "content": "Guu et al. (2020) 3 Hyperlink-induced Pre-training (HLP)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_21",
            "start": 832,
            "end": 887,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_22@0",
            "content": "In this section, we firstly discuss the background of OpenQA retrieval, then our methodology and training framework.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_22",
            "start": 0,
            "end": 115,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_23@0",
            "content": "Preliminaries",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_23",
            "start": 0,
            "end": 12,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_24@0",
            "content": "Passage Retrieval Given a question q, passage retrieval aims to provide a set of relevant passages p from a large corpus D. Our work adopts Wikipedia as source corpus and each passage is a disjoint segment within a document from D. OpenQA Q-P Relevance For OpenQA, a passage p is considered relevant to the query q if p conveys similar facts and contains the answer to q. These two conditions of relevance, namely evidence existence and answer containing, are properly introduced into the HLP Q-P pairs under the guidance of desired hyperlink structure.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_24",
            "start": 0,
            "end": 552,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_24@1",
            "content": "We will discuss more in this section.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_24",
            "start": 554,
            "end": 590,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_25@0",
            "content": "To better formulate the relevance of pseudo Q-P pairs, we denote the sequence of passages within a document as A = [a 1 , a 2 , ..., a n A ] where A \u2208 D. The corresponding topical entity and the title of document A are denoted as e A and t A , respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_25",
            "start": 0,
            "end": 256,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_25@1",
            "content": "We use m A to indicate a mention of entity e A , which is a hypertext span linking to document A. Note that the mention span m A is usually identical to the document title t A or a variant version of it.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_25",
            "start": 258,
            "end": 460,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_25@2",
            "content": "Further, we define F (p) as the entity-level factual information conveyed by the passage p, which is a set consists of the topical entity e P and the entities mentioned within passage p. Evidence Existence in HLP With appropriately designed hyperlink topologies, our HLP Q-P pairs guarantee the co-occurrence of entities which are presented as hypertext or topics in q and p. This is considered as evidence across the Q-P pairs:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_25",
            "start": 462,
            "end": 889,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_26@0",
            "content": "F (q) \u2229 F (p) = \u2205(1)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_26",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_27@0",
            "content": "Furthermore, we conjecture that HLP is more likely to achieve fact-level relevance than entitylevel overlap.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_27",
            "start": 0,
            "end": 107,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_27@1",
            "content": "We conduct human evaluation in Section 6.3 and case studies in Appendix G to support this conjecture.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_27",
            "start": 109,
            "end": 209,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_27@2",
            "content": "Moreover, we demonstrate that any Q-P pair containing hyperlink-induced factual evidence, which is represented as a triple that induced by hyperlinks, is included in our proposed topologies, which are included in Appendix D. Answer Containing in HLP We consider the document title t Q as the information-seeking target of q. Accordingly, the relevance of answer containing can be formulated as",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_27",
            "start": 211,
            "end": 603,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_28@0",
            "content": "t Q \u2286 p (2)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_28",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_29@0",
            "content": "The rationale behind this is that both the natural question and the Wikipedia document are intended to describe related facts and events regarding a targeted object, whereas the object is an answer for a question but a topic for a Wikipedia document.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_29",
            "start": 0,
            "end": 249,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_29@1",
            "content": "This similarity leads us to take the document title as the information-seeking target of its context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_29",
            "start": 251,
            "end": 351,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_30@0",
            "content": "Hyperlink-induced Q-P Pairs",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_30",
            "start": 0,
            "end": 26,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_31@0",
            "content": "Based on analysis of how queries match their evidential passages in the NQ (Kwiatkowski et al., 2019) dataset, we propose two kinds of hyperlink topology for relevance construction: Dual-link and Co-mention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_31",
            "start": 0,
            "end": 206,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_31@1",
            "content": "We present our exploratory data analysis on NQ dataset in Appendix C. Here we discuss the desired hyperlink topologies and the corresponding relevance of the pseudo Q-P pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_31",
            "start": 208,
            "end": 382,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_31@2",
            "content": "Dual-link (DL) Among all NQ training samples, 55% of questions mention the title of their corresponding golden passage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_31",
            "start": 384,
            "end": 502,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_31@3",
            "content": "This observation motivates us to leverage the topology of dual-link (DL) for relevance construction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_31",
            "start": 504,
            "end": 603,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_31@4",
            "content": "We consider a passage pair (a i , b j ) follows the dual-link topology if they link to each other.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_31",
            "start": 605,
            "end": 702,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_31@5",
            "content": "An example of a DL pair (a i , b j ) is shown in Figure 2, in which passage b j mentions the title of document A as m A , satisfying the condition of answer containing:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_31",
            "start": 704,
            "end": 871,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_32@0",
            "content": "t A \u2248 m A and m A \u2286 b j (3)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_32",
            "start": 0,
            "end": 26,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_33@0",
            "content": "Further, since the passages a i and b j both mention the topical entity of the other, the entities e A and e B appear in both passages as evidence:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_33",
            "start": 0,
            "end": 146,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_34@0",
            "content": "{e A , e B } \u2286 F (a i ) \u2229 F (b j )(4)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_34",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_35@0",
            "content": "Co-mention (CM) Among all NQ training samples, about 40% of questions fail to match the duallink condition but mention the same third-party entity as their corresponding golden passages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_35",
            "start": 0,
            "end": 185,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_35@1",
            "content": "In light of this observation, we utilize another topology of Co-mention (CM).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_35",
            "start": 187,
            "end": 263,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_35@2",
            "content": "We consider that a passage pair (c k , d l ) follows the Co-mention topology if they both link to a third-party document E and d l links to c k .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_35",
            "start": 265,
            "end": 409,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_35@3",
            "content": "Figure 2 illustrates a CM pair (c l , d k )",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_35",
            "start": 411,
            "end": 453,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_36@0",
            "content": "where answer containing is ensured as the title of c k occurs in d l :",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_36",
            "start": 0,
            "end": 69,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_37@0",
            "content": "t C \u2248 m C and m C \u2286 d l(5)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_37",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_38@0",
            "content": "Since both c l and d k mention a third-party entity e E , and that e C is a topical entity in c l while a mentioned entity in d k , we have entity-level evidence across c l and d k as:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_38",
            "start": 0,
            "end": 183,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_39@0",
            "content": "{e C , e E } \u2286 F (c k ) \u2229 F (d l )(6)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_39",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_40@0",
            "content": "In practice, we use sentence-level queries which contain the corresponding evidential hypertext, and we do not prepend the title to the passage in order to reduce the superficial entity-level overlap.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_40",
            "start": 0,
            "end": 199,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_40@1",
            "content": "To improve the quality of CM pairs, we filter out those with a co-mentioned entity which has a top 10% highest-ranked in-degree among the Wikipedia entity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_40",
            "start": 201,
            "end": 355,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_40@2",
            "content": "To illustrate how we construct our pseudo Q-P pairs, we present pseudo code in Appendix E. Furthermore, we highlight that HLP has the following advantages: 1) it introduces more semantic variants and paraphrasing for better text matching.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_40",
            "start": 357,
            "end": 594,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_41@0",
            "content": "2) The hypertext reflects potential interests or needs of users in relevant information, which is consistent to the downstream information-seeking propose.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_41",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_42@0",
            "content": "Bi-encoder Training",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_42",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_43@0",
            "content": "We adopt a BERT-based bi-encoder to encode queries and passages separately into d-dimension vectors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_43",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_43@1",
            "content": "The output representation is derived from the last hidden state of the [CLS] token and the final matching score is measured by the inner product:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_43",
            "start": 101,
            "end": 245,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_44@0",
            "content": "h q = BERT Q (q)([CLS]) h p = BERT P (p)([CLS]) S(p, q) = h T q \u2022 h p Let B = { q i , p + i , p \u2212 i } n i=1",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_44",
            "start": 0,
            "end": 106,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_45@0",
            "content": "be a mini-batch with n instances.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_45",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_45@1",
            "content": "Each instance contains a question q i paired with a positive passage p + i and a negative passage p \u2212 i .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_45",
            "start": 34,
            "end": 138,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_45@2",
            "content": "With in-batch negative sampling, each question q i considers all the passages in B except its own gold p + i as negatives, resulting in 2n \u2212 1 negatives per question in total.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_45",
            "start": 140,
            "end": 314,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_45@3",
            "content": "We use the negative log likelihood of the positive passage as our loss for optimization:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_45",
            "start": 316,
            "end": 403,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_46@0",
            "content": "L(q i , p + i , p \u2212 i,1 , ..., p \u2212 i,2n\u22121 ) = \u2212 log e S(q i ,p + i )",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_46",
            "start": 0,
            "end": 67,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_47@0",
            "content": "e S(q i ,p + i ) + 2n\u22121 j=1 e S(q i ,p \u2212 i,j )",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_47",
            "start": 0,
            "end": 45,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_48@0",
            "content": "Experimental Setup",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_48",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_49@0",
            "content": "In this session, we discuss the pre-training corpus preparation, downstream datasets, the hyperparameter and the basic setup for our experiments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_49",
            "start": 0,
            "end": 144,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_50@0",
            "content": "Pre-training Corpus",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_50",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_51@0",
            "content": "We adopt Wikipedia as our source corpus D for pretraining as it is the largest encyclopedia covering diverse topics with good content quality and linking structures.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_51",
            "start": 0,
            "end": 164,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_51@1",
            "content": "We choose the snapshot 03-01-2021 of an English Wikipedia dump, and process it with WikiExtractor 2 to obtain clean context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_51",
            "start": 166,
            "end": 289,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_51@2",
            "content": "After filtering out documents with blank text or a title less than three letters, following previous work (Karpukhin et al., 2020), we split the remaining documents into disjoint chunks of 100 words as passages, resulting in over 22 million passages in the end.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_51",
            "start": 291,
            "end": 551,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_52@0",
            "content": "Downstream Datasets",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_52",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_53@0",
            "content": "We",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_53",
            "start": 0,
            "end": 1,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_54@0",
            "content": "Implementation Details",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_54",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_55@0",
            "content": "During the pre-training, we train the bi-encoder for 5 epochs with parameters shared, using a batch size of 400 and an Adam optimizer (Kingma and Ba, 2014) with a learning rate 2 \u00d7 10 \u22125 , linear scheduling with 10% warm-up steps.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_55",
            "start": 0,
            "end": 229,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_55@1",
            "content": "Our HLP and all the reproduced baselines are trained on 20 million Q-P pairs with in-batch negative sampling, and the best checkpoints are selected based on the average rank of gold passages evaluated on the NQ dev set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_55",
            "start": 231,
            "end": 449,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_56@0",
            "content": "The pre-training takes around 3 days using eight NVIDIA V100 32GB GPUs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_56",
            "start": 0,
            "end": 70,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_57@0",
            "content": "For the downstream, we use the same hyperparameters for all experiments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_57",
            "start": 0,
            "end": 71,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_57@1",
            "content": "Specifically, we fine-tune the pre-trained models for 40 epochs with a batch size of 256 and the same optimizer and learning rate settings to the pre-training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_57",
            "start": 73,
            "end": 231,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_57@2",
            "content": "We conduct evaluation on respective dev sets to select best checkpoints, and we use the last checkpoint if there is no dev set or test set (e.g. HotpotQA).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_57",
            "start": 233,
            "end": 387,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_57@3",
            "content": "More details can be found in the Appendix A.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_57",
            "start": 389,
            "end": 432,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_58@0",
            "content": "Baselines",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_58",
            "start": 0,
            "end": 8,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_59@0",
            "content": "Most existing baselines have been implemented under different experimental settings, which have a substantial effect on the retrieval performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_59",
            "start": 0,
            "end": 145,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_59@1",
            "content": "To ensure fairness, we reproduce several pre-training methods (ICT, WLP, BFS, and their combination) under the same experimental setting, such as batch size, base model, amount of pre-training data, and so on.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_59",
            "start": 147,
            "end": 355,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_59@2",
            "content": "The only difference between our method and the re-implemented baselines is the self-supervision signal derived from the respective pre-training samples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_59",
            "start": 357,
            "end": 508,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_59@3",
            "content": "Our reproduced BM25 baseline is better than that reported in Karpukhin et al. (2020), and the re-implemented pre-training methods also perform better than those reported by the recent work 3 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_59",
            "start": 510,
            "end": 701,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_59@4",
            "content": "In addition, we include the work REALM (Guu et al., 2020) as a baseline which has recently been reproduced by Sachan et al. ( 2021) using 240 GPUs and is named masked salient spans (MSS).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_59",
            "start": 703,
            "end": 889,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_59@5",
            "content": "We note that most related works gain improvements from varying downstream setting or synthetic pre-training with access to the downstream data of respective domain, which is out of the scope of our interests.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_59",
            "start": 891,
            "end": 1098,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_60@0",
            "content": "Experiments",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_60",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_61@0",
            "content": "Main Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_61",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_62@0",
            "content": "Table 1 shows the retrieval accuracy of different models on three popular QA datasets under zeroshot and full-set fine-tuning settings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_62",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_63@0",
            "content": "Under zero-shot setting, HLP consistently outperforms BM25 except for the top-5 retrieval accuracy of TriviaQA, while all other pre-training baselines are far behind.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_63",
            "start": 0,
            "end": 165,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_63@1",
            "content": "We attribute the minor improvement over BM25 on TriviaQA to a high overlap between questions and passages, which gives term-based retriever a clear advantage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_63",
            "start": 167,
            "end": 324,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_63@2",
            "content": "We investigate the coverage of the question tokens that appear in the gold passage and find that the overlap is indeed higher in TriviaQA (62.8%) than NQ (60.7%) and WQ (57.5%).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_63",
            "start": 326,
            "end": 502,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_64@0",
            "content": "After fine-tuning, all models with intermediate pre-training give better results than the vanilla DPR while our HLP achieves the best in nearly all cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_64",
            "start": 0,
            "end": 153,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_64@1",
            "content": "Among ICT, WLP and BFS, we observe that WLP is the most competitive with or without fine-tuning, and additional improvements can be achieved by combining three of them.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_64",
            "start": 155,
            "end": 322,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_64@2",
            "content": "This observation indicates that pre-training with diverse relevance leads to better generalization to downstream tasks, while document-wise relevance is more adaptable for the OpenQA retrieval.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_64",
            "start": 324,
            "end": 516,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_64@3",
            "content": "The advantage of documentwise relevance may come from the fact that texts in different documents are likely written by different parties, providing less superficial cues for text matching, which is beneficial for the downstream retrieval.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_64",
            "start": 518,
            "end": 755,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_64@4",
            "content": "Our HLP learns both coarse-grained document-wise relationships as well as the finegrained entity-level evidence, which results in a significant improvement.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_64",
            "start": 757,
            "end": 912,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_65@0",
            "content": "Few-shot Learning",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_65",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_66@0",
            "content": "To investigate the retrieval effectiveness in a more realistic scenario, we conduct experiments for few-shot learning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_66",
            "start": 0,
            "end": 117,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_66@1",
            "content": "Specifically, we fine-tune the pre-trained models on large datasets (NQ, Triv-iaQA) with m (m = {16, 256, 1024}) samples and present the few-shot retrieval results in Table 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_66",
            "start": 119,
            "end": 293,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_66@2",
            "content": "With only a few hundred labeled data for fine-tuning, all the models with intermediate pre-training perform better than that without, and HLP outperforms the other methods by a larger margin when m is smaller.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_66",
            "start": 295,
            "end": 503,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_66@3",
            "content": "Among three reimplemented baselines, WLP gains the largest improvement with increasing number of samples, outperforming ICT and BFS when a thousand labelled samples are provided for fine-tuning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_66",
            "start": 505,
            "end": 698,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_67@0",
            "content": "Multi-hop Retrieval",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_67",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_68@0",
            "content": "While HLP aims to acquires the ability in matching document-wise concepts and facts, it raises our interest in its capability for multi-hop scenarios.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_68",
            "start": 0,
            "end": 149,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_68@1",
            "content": "We evaluate our methods on HotpotQA in a single-hop manner.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_68",
            "start": 151,
            "end": 209,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_68@2",
            "content": "Specifically, for each query, we randomly selects one golden passage from the two as a positive passage and one additional passage with high TF-IDF scores as a negative passage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_68",
            "start": 211,
            "end": 387,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_68@3",
            "content": "Our models are further fine-tuned on the HotpotQA training set and evaluated on the bridge and the comparison type questions from the development set, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_68",
            "start": 389,
            "end": 552,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_68@4",
            "content": "The results of our study are shown in Table 5: Retrieval accuracy on questions from Hot-potQA dev set, measured as the percentage of top-k retrieved passages which include both golds.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_68",
            "start": 554,
            "end": 736,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_69@0",
            "content": "6 Analysis",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_69",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_70@0",
            "content": "Ablation Study",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_70",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_71@0",
            "content": "To better understand how different key factors affect the results, we conduct ablation experiments with results shown in Table 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_71",
            "start": 0,
            "end": 128,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_72@0",
            "content": "Our proposed dual-link (DL) and co-mention (CM) Q-P pairs, provide evidence induced by different hyperlinkbased topologies.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_72",
            "start": 0,
            "end": 122,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_72@1",
            "content": "To examine their respective effectiveness, we pre-train retrievers on Q-P pairs derived from each topology and their combinations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_72",
            "start": 124,
            "end": 253,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_72@2",
            "content": "We present zero-shot retrieval results in Table 3, which show that retrievers pre-trained on DL pairs has a distinct advantage over that on CM pairs, while combining both gives extra improvement.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_72",
            "start": 255,
            "end": 449,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_72@3",
            "content": "Negative Passage In practice, negative sampling is essential for learning a high-quality encoder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_72",
            "start": 451,
            "end": 547,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_72@4",
            "content": "Besides in-batch negative, our reported HLP employs one additional negative for each query.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_72",
            "start": 549,
            "end": 639,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_72@5",
            "content": "We further explore the impact of the additional negatives during pre-training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_72",
            "start": 641,
            "end": 718,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_72@6",
            "content": "In our ablation study, pre-training with additional negatives improves the results significantly, which may be attributed to using more in-batch pairs for text matching.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_72",
            "start": 720,
            "end": 888,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_72@7",
            "content": "More details on implementation and negative sampling strategies can be found in Appendix B.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_72",
            "start": 890,
            "end": 980,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_73@0",
            "content": "Analysis on Q-P Overlap",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_73",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_74@0",
            "content": "We carry out extensive analysis on the Q-P lexical overlap in the task of retrieval.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_74",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_74@1",
            "content": "Specifically, we tokenize q, p using the BERT tokenizer and measure the Q-P overlap as the proportion of the question tokens that appear in the corresponding passage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_74",
            "start": 85,
            "end": 250,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_74@2",
            "content": "Based on the degree of Q-P overlap, we divided the NQ dev set into five categories for further analysis.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_74",
            "start": 252,
            "end": 355,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_74@3",
            "content": "Distribution of Q-P Overlap Figure 3 shows both the pre-training and the retrieved pairs of HLP have a more similar overlap distribution with the downstream NQ dataset than the other methods, which implies the consistency between the relevance provided by HLP and that in real informationseeking scenario.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_74",
            "start": 357,
            "end": 661,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_74@4",
            "content": "Retrieval Performance vs. Q-P Overlap Figure 4 shows the top-20 retrieval accuracy on the samples with varying degrees of Q-P overlap.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_74",
            "start": 663,
            "end": 796,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_74@5",
            "content": "Both figures show that the retrievers are more likely to return answer-containing passages when there is higher Q-P overlap, suggesting that all these models can exploit lexical overlap for passage retrieval.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_74",
            "start": 798,
            "end": 1005,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_74@6",
            "content": "Under the zero-shot setting, HLP outperforms all the methods except BM25 when r is larger than 0.8, which reflects the strong reasoning ability of HLP and the overlap-dependent nature of the termbased retrievers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_74",
            "start": 1007,
            "end": 1218,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_74@7",
            "content": "After fine-tuning, models with additional pre-training perform better than the vanilla DPR while HLP outperforms all other methods in most of the cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_74",
            "start": 1220,
            "end": 1371,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_74@8",
            "content": "It is important to note that HLP is pre-trained on more high-overlap text pairs while it performs better than all the other methods when fewer overlaps are provided.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_74",
            "start": 1373,
            "end": 1537,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_74@9",
            "content": "We speculate that this is because the overlapping in HLP Q-P pairs mostly comes from the factual information, such as entity, which introduces fewer superficial cues, allowing for better adaptation to the downstream cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_74",
            "start": 1539,
            "end": 1760,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_75@0",
            "content": "Human Evaluation on Q-P pairs",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_75",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_76@0",
            "content": "We conduct human evaluation to investigate the proportion of Q-P pairs that convey the similar factlevel information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_76",
            "start": 0,
            "end": 116,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_76@1",
            "content": "Specially, we randomly selected one hundred examples from our constructed Q-P pairs and asked annotators to identify whether the query and the corresponding passage convey similar facts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_76",
            "start": 118,
            "end": 303,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_76@2",
            "content": "Each case is evaluated by three annotators and the result is determined by their votes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_76",
            "start": 305,
            "end": 391,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_76@3",
            "content": "Our results are shown in",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_76",
            "start": 393,
            "end": 416,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_77@0",
            "content": "For the pre-training, all models including our reproduced baselines are trained with 20 million Q-P pairs with in-batch negative sampling.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_77",
            "start": 0,
            "end": 137,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_77@1",
            "content": "Specifically, our reported HLP is trained on the combination of 10 million DL pairs and 10 million CM pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_77",
            "start": 139,
            "end": 246,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_77@2",
            "content": "The HLP (DL) and HLP (CM) reported in",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_77",
            "start": 248,
            "end": 284,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_78@0",
            "content": "In this part, we detailedly discuss how we conduct exploratory data analysis on NQ training set to determine the hyperlink-based topology.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_78",
            "start": 0,
            "end": 137,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_78@1",
            "content": "Driven by a strong interest in what kind of roles the overlapping spans play between the queries q and passages p, we conduct exploratory data analysis on the widelyused NQ dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_78",
            "start": 139,
            "end": 319,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_78@2",
            "content": "Specifically, we recognize all entities and mentions from the queries and the passages using TagMe (Ferragina and Scaiella, 2010) for further investigation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_78",
            "start": 321,
            "end": 476,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_78@3",
            "content": "As a result, we observe about 55% queries q either explicitly mentions the titles of p or the successfully links to the document where p originated via TagMe, which motivates us to construct the dual-link topology where the pseudo queries q mention p via a hypertext.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_78",
            "start": 478,
            "end": 744,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_78@4",
            "content": "Moreover, we observe about 45% queries do not mention title of q but share the same mentions with p which encourages us to adopt the co-mention topology where the pseudo q and p both mention a third-party document through hypertext.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_78",
            "start": 746,
            "end": 977,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_79@0",
            "content": "Intuitively, we assume the mentioned entity, let's say e Y mentioned in a Wikipedia document X, is used to describe the topical entity e X of this document.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_79",
            "start": 0,
            "end": 155,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_79@1",
            "content": "In other words, e Y is likely to attend in a topically relevant fact or event, which can be represented as a triple <e X , r XY , e Y > where r XY is a latent relation between e X and e Y .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_79",
            "start": 157,
            "end": 345,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_80@0",
            "content": "Given any passage pair (q, p) from Wikipedia, we call q and p have fact-level evidence if they both entail a fact that can be represented as a triple <e X , r XY , e Y > where e X , e Y are entities and r XY is their corresponding relations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_80",
            "start": 0,
            "end": 240,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_80@1",
            "content": "Further, if both passages q and p contain representative hypertext or topic of e X and e Y , we say this fact-level evidence can be induced by hyperlink-based topology, namely hyperlink-induced fact.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_80",
            "start": 242,
            "end": 440,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_80@2",
            "content": "In this session, we prove that any Q-P pair with hyperlink-induced fact while satisfying answer containing is within either DL or CM hyperlink-based topology.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_80",
            "start": 442,
            "end": 599,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_81@0",
            "content": "Following the example above, both q and p contain a factual triple <e X , r XY , e Y >.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_81",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_81@1",
            "content": "Since mentioned entities are used to describe the topical entity, we have facts <e Q , r QX , e X >, <e Q , r QY , e Y > at q-side while <e P , r P X , e X >, <e P , r P Y , e Y > at p-side.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_81",
            "start": 88,
            "end": 277,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_81@2",
            "content": "Further, p contains <e P , r P Q , e Q > because of the answer containing condition.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_81",
            "start": 279,
            "end": 362,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_82@0",
            "content": "Case1: The entity e P = e X or e P = e Y .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_82",
            "start": 0,
            "end": 41,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_82@1",
            "content": "Then q provides facts <e Q , r QP , e P > where r QP is likely but not necessarily to be identical to r P Q in p. In this case, (q, p) fits in the Dual-link topology in our definition.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_82",
            "start": 43,
            "end": 226,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_83@0",
            "content": "Case2: The entity e P = e X and e P = e Y . Then given the facts <e Q , r QX , e X > at q-side, and <e P , r P X , e X >, <e P , r P Q , e Q > at p-side, (q, p) fits in the Co-mention topology.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_83",
            "start": 0,
            "end": 192,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_84@0",
            "content": "Algorithm 1: HLP Pairs Identification Notation: q, p \u2190 Wikipedia passages t Q \u2190 Topical entity of passage q M(q) \u2190 The set of entities mentioned in q d in (q) \u2190 in-degree of the Wikipedia entity t Q K \u2190 in-degree threshold for CM pairs Def IsDL(q, p):",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_84",
            "start": 0,
            "end": 250,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_85@0",
            "content": "if t P \u2208 M(q) & t Q \u2208 M(p)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_85",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_86@0",
            "content": "We evaluate HLP on multi-hop scenario where knowledge from different documents need to be associated for retrieval.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_86",
            "start": 0,
            "end": 114,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_86@1",
            "content": "Besides significant improvements shown in Table 5, we conduct case study to investigate its capability on knowledgeintensive retrieval.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_86",
            "start": 116,
            "end": 250,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_86@2",
            "content": "In Table 8, a complex question is proposed, requiring the retriever firstly to retrieve the document \"Apple Remote\" and then \"Front Row (software)\" to fetch the final answer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_86",
            "start": 252,
            "end": 425,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_87@0",
            "content": "Our HLP successfully retrieves both golds in the top-10 retrieved passages while the vanilla DPR fails.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_87",
            "start": 0,
            "end": 102,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_87@1",
            "content": "We find 6 items retrieved by HIS are related to the brand \"Apple\" while 4 are by DPR, showing stronger comprehension and associative ability from HLP.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_87",
            "start": 104,
            "end": 253,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_88@0",
            "content": "Besides human evaluation, we present case studies on HLP Q-P pairs, which is shown in Table 9 and Table 10.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_88",
            "start": 0,
            "end": 106,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_88@1",
            "content": "As we can see in the tables, a few lexical variants of entities and fact-level paraphrasing are presented across questions and passages, which can be interpreted as factual evidence for OpenQA passage matching.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_88",
            "start": 108,
            "end": 317,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_88@2",
            "content": "For example, entity-level variants such as \"Robert and Richard Sherman\" vs. \"Sherman Brothers\", and fact-level paraphrases such as \"Abby Kelley and Stephen Symonds Foster ... working for abolitionism\" vs. \"... radical abolitionists, Abby Kelley Foster and her husband Stephen S.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_88",
            "start": 319,
            "end": 596,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_89@0",
            "content": "Foster\" can be found in our examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_89",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_90@0",
            "content": "Jonathan Berant, Andrew Chou, Roy Frostig, Percy Liang, Semantic parsing on freebase from question-answer pairs, 2013, Proceedings of the 2013 conference on empirical methods in natural language processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_90",
            "start": 0,
            "end": 207,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_91@0",
            "content": "Alexey Borisov, Ilya Markov, Pavel Maarten De Rijke,  Serdyukov, A neural click model for web search, 2016-04-11, Proceedings of the 25th International Conference on World Wide Web, WWW 2016, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_91",
            "start": 0,
            "end": 192,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_92@0",
            "content": "UNKNOWN, None, 2020, Pretraining tasks for embedding-based large-scale retrieval, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_92",
            "start": 0,
            "end": 82,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_93@0",
            "content": "Danqi Chen, Adam Fisch, Jason Weston, Antoine Bordes, Reading wikipedia to answer opendomain questions, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_93",
            "start": 0,
            "end": 210,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_94@0",
            "content": "Mostafa Dehghani, Hamed Zamani, Aliaksei Severyn, Jaap Kamps, W Croft, Neural ranking models with weak supervision, 2017-08-07, Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_94",
            "start": 0,
            "end": 241,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_95@0",
            "content": "Paolo Ferragina, Ugo Scaiella, Tagme: on-the-fly annotation of short text fragments (by wikipedia entities), 2010, Proceedings of the 19th ACM international conference on Information and knowledge management, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_95",
            "start": 0,
            "end": 209,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_96@0",
            "content": "UNKNOWN, None, , 2020. Don't stop pretraining: adapt language models to domains and tasks, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_96",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_97@0",
            "content": "Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, Mingwei Chang, Retrieval augmented language model pre-training, 2020, International Conference on Machine Learning, PMLR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_97",
            "start": 0,
            "end": 173,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_98@0",
            "content": "Mandar Joshi, Eunsol Choi, S Daniel, Luke Weld,  Zettlemoyer, Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_98",
            "start": 0,
            "end": 247,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_99@0",
            "content": "Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, Wen-Tau Yih, Dense passage retrieval for open-domain question answering, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_99",
            "start": 0,
            "end": 272,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_100@0",
            "content": "UNKNOWN, None, 2014, Adam: A method for stochastic optimization, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_100",
            "start": 0,
            "end": 65,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_101@0",
            "content": "Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Natural questions: a benchmark for question answering research, 2019, Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_101",
            "start": 0,
            "end": 296,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_102@0",
            "content": "Kenton Lee, Ming-Wei Chang, Kristina Toutanova, Latent retrieval for weakly supervised open domain question answering, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_102",
            "start": 0,
            "end": 214,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_103@0",
            "content": "UNKNOWN, None, 2021, PAQ: 65 million probably-asked questions and what you can do with them, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_103",
            "start": 0,
            "end": 97,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_104@0",
            "content": "Ji Ma, Ivan Korotkov, Yinfei Yang, Keith Hall, Ryan Mcdonald, Zero-shot neural passage retrieval via domain-targeted synthetic question generation, 2021-04-19, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, EACL 2021, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_104",
            "start": 0,
            "end": 293,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_105@0",
            "content": "Mike Mintz, Steven Bills, Rion Snow, Dan Jurafsky, Distant supervision for relation extraction without labeled data, 2009, Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_105",
            "start": 0,
            "end": 285,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_106@0",
            "content": "Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, Li Deng, Ms marco: A human generated machine reading comprehension dataset, 2016, CoCo@ NIPS, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_106",
            "start": 0,
            "end": 178,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_107@0",
            "content": "UNKNOWN, None, 2021, Domain-matched pretraining tasks for dense retrieval, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_107",
            "start": 0,
            "end": 75,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_108@0",
            "content": "Yingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang Ren, Wayne Zhao, Daxiang Dong, Hua Wu, Haifeng Wang, Rocketqa: An optimized training approach to dense passage retrieval for opendomain question answering, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_108",
            "start": 0,
            "end": 357,
            "label": {}
        },
        {
            "ix": "202-ARR_v1_109@0",
            "content": "UNKNOWN, None, , Heng Ji, and Avirup Sil. 2021. Towards robust neural retrieval, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "202-ARR_v1_109",
            "start": 0,
            "end": 81,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "202-ARR_v1_0",
            "tgt_ix": "202-ARR_v1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_0",
            "tgt_ix": "202-ARR_v1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_1",
            "tgt_ix": "202-ARR_v1_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_1",
            "tgt_ix": "202-ARR_v1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_0",
            "tgt_ix": "202-ARR_v1_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_2",
            "tgt_ix": "202-ARR_v1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_4",
            "tgt_ix": "202-ARR_v1_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_5",
            "tgt_ix": "202-ARR_v1_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_3",
            "tgt_ix": "202-ARR_v1_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_3",
            "tgt_ix": "202-ARR_v1_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_3",
            "tgt_ix": "202-ARR_v1_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_3",
            "tgt_ix": "202-ARR_v1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_7",
            "tgt_ix": "202-ARR_v1_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_8",
            "tgt_ix": "202-ARR_v1_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_3",
            "tgt_ix": "202-ARR_v1_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_3",
            "tgt_ix": "202-ARR_v1_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_3",
            "tgt_ix": "202-ARR_v1_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_6",
            "tgt_ix": "202-ARR_v1_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_3",
            "tgt_ix": "202-ARR_v1_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_9",
            "tgt_ix": "202-ARR_v1_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_3",
            "tgt_ix": "202-ARR_v1_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_10",
            "tgt_ix": "202-ARR_v1_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_3",
            "tgt_ix": "202-ARR_v1_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_11",
            "tgt_ix": "202-ARR_v1_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_13",
            "tgt_ix": "202-ARR_v1_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_14",
            "tgt_ix": "202-ARR_v1_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_3",
            "tgt_ix": "202-ARR_v1_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_3",
            "tgt_ix": "202-ARR_v1_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_3",
            "tgt_ix": "202-ARR_v1_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_12",
            "tgt_ix": "202-ARR_v1_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_3",
            "tgt_ix": "202-ARR_v1_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_15",
            "tgt_ix": "202-ARR_v1_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_17",
            "tgt_ix": "202-ARR_v1_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_18",
            "tgt_ix": "202-ARR_v1_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_3",
            "tgt_ix": "202-ARR_v1_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_3",
            "tgt_ix": "202-ARR_v1_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_3",
            "tgt_ix": "202-ARR_v1_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_16",
            "tgt_ix": "202-ARR_v1_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_0",
            "tgt_ix": "202-ARR_v1_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_19",
            "tgt_ix": "202-ARR_v1_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_21",
            "tgt_ix": "202-ARR_v1_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_20",
            "tgt_ix": "202-ARR_v1_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_20",
            "tgt_ix": "202-ARR_v1_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_20",
            "tgt_ix": "202-ARR_v1_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_0",
            "tgt_ix": "202-ARR_v1_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_22",
            "tgt_ix": "202-ARR_v1_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_24",
            "tgt_ix": "202-ARR_v1_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_25",
            "tgt_ix": "202-ARR_v1_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_26",
            "tgt_ix": "202-ARR_v1_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_27",
            "tgt_ix": "202-ARR_v1_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_28",
            "tgt_ix": "202-ARR_v1_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_23",
            "tgt_ix": "202-ARR_v1_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_23",
            "tgt_ix": "202-ARR_v1_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_23",
            "tgt_ix": "202-ARR_v1_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_23",
            "tgt_ix": "202-ARR_v1_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_23",
            "tgt_ix": "202-ARR_v1_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_23",
            "tgt_ix": "202-ARR_v1_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_23",
            "tgt_ix": "202-ARR_v1_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_0",
            "tgt_ix": "202-ARR_v1_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_29",
            "tgt_ix": "202-ARR_v1_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_31",
            "tgt_ix": "202-ARR_v1_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_32",
            "tgt_ix": "202-ARR_v1_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_33",
            "tgt_ix": "202-ARR_v1_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_34",
            "tgt_ix": "202-ARR_v1_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_35",
            "tgt_ix": "202-ARR_v1_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_36",
            "tgt_ix": "202-ARR_v1_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_37",
            "tgt_ix": "202-ARR_v1_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_38",
            "tgt_ix": "202-ARR_v1_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_39",
            "tgt_ix": "202-ARR_v1_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_40",
            "tgt_ix": "202-ARR_v1_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_30",
            "tgt_ix": "202-ARR_v1_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_30",
            "tgt_ix": "202-ARR_v1_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_30",
            "tgt_ix": "202-ARR_v1_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_30",
            "tgt_ix": "202-ARR_v1_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_30",
            "tgt_ix": "202-ARR_v1_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_30",
            "tgt_ix": "202-ARR_v1_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_30",
            "tgt_ix": "202-ARR_v1_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_30",
            "tgt_ix": "202-ARR_v1_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_30",
            "tgt_ix": "202-ARR_v1_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_30",
            "tgt_ix": "202-ARR_v1_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_30",
            "tgt_ix": "202-ARR_v1_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_30",
            "tgt_ix": "202-ARR_v1_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_0",
            "tgt_ix": "202-ARR_v1_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_41",
            "tgt_ix": "202-ARR_v1_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_43",
            "tgt_ix": "202-ARR_v1_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_44",
            "tgt_ix": "202-ARR_v1_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_45",
            "tgt_ix": "202-ARR_v1_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_46",
            "tgt_ix": "202-ARR_v1_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_42",
            "tgt_ix": "202-ARR_v1_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_42",
            "tgt_ix": "202-ARR_v1_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_42",
            "tgt_ix": "202-ARR_v1_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_42",
            "tgt_ix": "202-ARR_v1_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_42",
            "tgt_ix": "202-ARR_v1_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_42",
            "tgt_ix": "202-ARR_v1_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_0",
            "tgt_ix": "202-ARR_v1_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_47",
            "tgt_ix": "202-ARR_v1_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_48",
            "tgt_ix": "202-ARR_v1_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_48",
            "tgt_ix": "202-ARR_v1_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_48",
            "tgt_ix": "202-ARR_v1_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_49",
            "tgt_ix": "202-ARR_v1_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_50",
            "tgt_ix": "202-ARR_v1_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_50",
            "tgt_ix": "202-ARR_v1_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_48",
            "tgt_ix": "202-ARR_v1_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_51",
            "tgt_ix": "202-ARR_v1_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_52",
            "tgt_ix": "202-ARR_v1_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_52",
            "tgt_ix": "202-ARR_v1_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_48",
            "tgt_ix": "202-ARR_v1_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_53",
            "tgt_ix": "202-ARR_v1_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_55",
            "tgt_ix": "202-ARR_v1_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_56",
            "tgt_ix": "202-ARR_v1_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_54",
            "tgt_ix": "202-ARR_v1_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_54",
            "tgt_ix": "202-ARR_v1_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_54",
            "tgt_ix": "202-ARR_v1_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_54",
            "tgt_ix": "202-ARR_v1_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_48",
            "tgt_ix": "202-ARR_v1_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_57",
            "tgt_ix": "202-ARR_v1_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_58",
            "tgt_ix": "202-ARR_v1_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_58",
            "tgt_ix": "202-ARR_v1_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_0",
            "tgt_ix": "202-ARR_v1_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_59",
            "tgt_ix": "202-ARR_v1_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_60",
            "tgt_ix": "202-ARR_v1_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_60",
            "tgt_ix": "202-ARR_v1_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_62",
            "tgt_ix": "202-ARR_v1_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_63",
            "tgt_ix": "202-ARR_v1_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_61",
            "tgt_ix": "202-ARR_v1_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_61",
            "tgt_ix": "202-ARR_v1_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_61",
            "tgt_ix": "202-ARR_v1_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_61",
            "tgt_ix": "202-ARR_v1_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_60",
            "tgt_ix": "202-ARR_v1_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_64",
            "tgt_ix": "202-ARR_v1_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_65",
            "tgt_ix": "202-ARR_v1_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_65",
            "tgt_ix": "202-ARR_v1_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_60",
            "tgt_ix": "202-ARR_v1_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_66",
            "tgt_ix": "202-ARR_v1_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_68",
            "tgt_ix": "202-ARR_v1_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_67",
            "tgt_ix": "202-ARR_v1_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_67",
            "tgt_ix": "202-ARR_v1_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_67",
            "tgt_ix": "202-ARR_v1_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_0",
            "tgt_ix": "202-ARR_v1_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_69",
            "tgt_ix": "202-ARR_v1_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_70",
            "tgt_ix": "202-ARR_v1_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_70",
            "tgt_ix": "202-ARR_v1_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_70",
            "tgt_ix": "202-ARR_v1_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_71",
            "tgt_ix": "202-ARR_v1_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_0",
            "tgt_ix": "202-ARR_v1_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_72",
            "tgt_ix": "202-ARR_v1_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_73",
            "tgt_ix": "202-ARR_v1_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_73",
            "tgt_ix": "202-ARR_v1_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_0",
            "tgt_ix": "202-ARR_v1_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_74",
            "tgt_ix": "202-ARR_v1_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_75",
            "tgt_ix": "202-ARR_v1_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_75",
            "tgt_ix": "202-ARR_v1_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_75",
            "tgt_ix": "202-ARR_v1_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_76",
            "tgt_ix": "202-ARR_v1_77",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_75",
            "tgt_ix": "202-ARR_v1_78",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_77",
            "tgt_ix": "202-ARR_v1_78",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_79",
            "tgt_ix": "202-ARR_v1_80",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_80",
            "tgt_ix": "202-ARR_v1_81",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_81",
            "tgt_ix": "202-ARR_v1_82",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_82",
            "tgt_ix": "202-ARR_v1_83",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_75",
            "tgt_ix": "202-ARR_v1_79",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_75",
            "tgt_ix": "202-ARR_v1_80",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_75",
            "tgt_ix": "202-ARR_v1_81",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_75",
            "tgt_ix": "202-ARR_v1_82",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_75",
            "tgt_ix": "202-ARR_v1_83",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_78",
            "tgt_ix": "202-ARR_v1_79",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_84",
            "tgt_ix": "202-ARR_v1_85",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_75",
            "tgt_ix": "202-ARR_v1_84",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_75",
            "tgt_ix": "202-ARR_v1_85",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_83",
            "tgt_ix": "202-ARR_v1_84",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_86",
            "tgt_ix": "202-ARR_v1_87",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_75",
            "tgt_ix": "202-ARR_v1_86",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_75",
            "tgt_ix": "202-ARR_v1_87",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_85",
            "tgt_ix": "202-ARR_v1_86",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_88",
            "tgt_ix": "202-ARR_v1_89",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_75",
            "tgt_ix": "202-ARR_v1_88",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_75",
            "tgt_ix": "202-ARR_v1_89",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_87",
            "tgt_ix": "202-ARR_v1_88",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "202-ARR_v1_0",
            "tgt_ix": "202-ARR_v1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_1",
            "tgt_ix": "202-ARR_v1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_2",
            "tgt_ix": "202-ARR_v1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_2",
            "tgt_ix": "202-ARR_v1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_2",
            "tgt_ix": "202-ARR_v1_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_2",
            "tgt_ix": "202-ARR_v1_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_2",
            "tgt_ix": "202-ARR_v1_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_2",
            "tgt_ix": "202-ARR_v1_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_2",
            "tgt_ix": "202-ARR_v1_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_3",
            "tgt_ix": "202-ARR_v1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_4",
            "tgt_ix": "202-ARR_v1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_4",
            "tgt_ix": "202-ARR_v1_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_4",
            "tgt_ix": "202-ARR_v1_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_4",
            "tgt_ix": "202-ARR_v1_4@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_5",
            "tgt_ix": "202-ARR_v1_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_6",
            "tgt_ix": "202-ARR_v1_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_6",
            "tgt_ix": "202-ARR_v1_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_7",
            "tgt_ix": "202-ARR_v1_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_8",
            "tgt_ix": "202-ARR_v1_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_9",
            "tgt_ix": "202-ARR_v1_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_10",
            "tgt_ix": "202-ARR_v1_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_11",
            "tgt_ix": "202-ARR_v1_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_12",
            "tgt_ix": "202-ARR_v1_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_13",
            "tgt_ix": "202-ARR_v1_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_13",
            "tgt_ix": "202-ARR_v1_13@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_13",
            "tgt_ix": "202-ARR_v1_13@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_13",
            "tgt_ix": "202-ARR_v1_13@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_13",
            "tgt_ix": "202-ARR_v1_13@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_13",
            "tgt_ix": "202-ARR_v1_13@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_14",
            "tgt_ix": "202-ARR_v1_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_14",
            "tgt_ix": "202-ARR_v1_14@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_14",
            "tgt_ix": "202-ARR_v1_14@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_14",
            "tgt_ix": "202-ARR_v1_14@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_15",
            "tgt_ix": "202-ARR_v1_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_15",
            "tgt_ix": "202-ARR_v1_15@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_16",
            "tgt_ix": "202-ARR_v1_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_17",
            "tgt_ix": "202-ARR_v1_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_18",
            "tgt_ix": "202-ARR_v1_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_18",
            "tgt_ix": "202-ARR_v1_18@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_18",
            "tgt_ix": "202-ARR_v1_18@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_18",
            "tgt_ix": "202-ARR_v1_18@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_18",
            "tgt_ix": "202-ARR_v1_18@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_18",
            "tgt_ix": "202-ARR_v1_18@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_18",
            "tgt_ix": "202-ARR_v1_18@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_19",
            "tgt_ix": "202-ARR_v1_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_19",
            "tgt_ix": "202-ARR_v1_19@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_19",
            "tgt_ix": "202-ARR_v1_19@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_19",
            "tgt_ix": "202-ARR_v1_19@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_20",
            "tgt_ix": "202-ARR_v1_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_21",
            "tgt_ix": "202-ARR_v1_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_21",
            "tgt_ix": "202-ARR_v1_21@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_21",
            "tgt_ix": "202-ARR_v1_21@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_21",
            "tgt_ix": "202-ARR_v1_21@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_21",
            "tgt_ix": "202-ARR_v1_21@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_21",
            "tgt_ix": "202-ARR_v1_21@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_21",
            "tgt_ix": "202-ARR_v1_21@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_22",
            "tgt_ix": "202-ARR_v1_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_23",
            "tgt_ix": "202-ARR_v1_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_24",
            "tgt_ix": "202-ARR_v1_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_24",
            "tgt_ix": "202-ARR_v1_24@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_25",
            "tgt_ix": "202-ARR_v1_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_25",
            "tgt_ix": "202-ARR_v1_25@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_25",
            "tgt_ix": "202-ARR_v1_25@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_26",
            "tgt_ix": "202-ARR_v1_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_27",
            "tgt_ix": "202-ARR_v1_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_27",
            "tgt_ix": "202-ARR_v1_27@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_27",
            "tgt_ix": "202-ARR_v1_27@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_28",
            "tgt_ix": "202-ARR_v1_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_29",
            "tgt_ix": "202-ARR_v1_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_29",
            "tgt_ix": "202-ARR_v1_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_30",
            "tgt_ix": "202-ARR_v1_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_31",
            "tgt_ix": "202-ARR_v1_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_31",
            "tgt_ix": "202-ARR_v1_31@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_31",
            "tgt_ix": "202-ARR_v1_31@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_31",
            "tgt_ix": "202-ARR_v1_31@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_31",
            "tgt_ix": "202-ARR_v1_31@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_31",
            "tgt_ix": "202-ARR_v1_31@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_32",
            "tgt_ix": "202-ARR_v1_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_33",
            "tgt_ix": "202-ARR_v1_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_34",
            "tgt_ix": "202-ARR_v1_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_35",
            "tgt_ix": "202-ARR_v1_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_35",
            "tgt_ix": "202-ARR_v1_35@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_35",
            "tgt_ix": "202-ARR_v1_35@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_35",
            "tgt_ix": "202-ARR_v1_35@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_36",
            "tgt_ix": "202-ARR_v1_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_37",
            "tgt_ix": "202-ARR_v1_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_38",
            "tgt_ix": "202-ARR_v1_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_39",
            "tgt_ix": "202-ARR_v1_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_40",
            "tgt_ix": "202-ARR_v1_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_40",
            "tgt_ix": "202-ARR_v1_40@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_40",
            "tgt_ix": "202-ARR_v1_40@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_41",
            "tgt_ix": "202-ARR_v1_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_42",
            "tgt_ix": "202-ARR_v1_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_43",
            "tgt_ix": "202-ARR_v1_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_43",
            "tgt_ix": "202-ARR_v1_43@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_44",
            "tgt_ix": "202-ARR_v1_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_45",
            "tgt_ix": "202-ARR_v1_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_45",
            "tgt_ix": "202-ARR_v1_45@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_45",
            "tgt_ix": "202-ARR_v1_45@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_45",
            "tgt_ix": "202-ARR_v1_45@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_46",
            "tgt_ix": "202-ARR_v1_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_47",
            "tgt_ix": "202-ARR_v1_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_48",
            "tgt_ix": "202-ARR_v1_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_49",
            "tgt_ix": "202-ARR_v1_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_50",
            "tgt_ix": "202-ARR_v1_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_51",
            "tgt_ix": "202-ARR_v1_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_51",
            "tgt_ix": "202-ARR_v1_51@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_51",
            "tgt_ix": "202-ARR_v1_51@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_52",
            "tgt_ix": "202-ARR_v1_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_53",
            "tgt_ix": "202-ARR_v1_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_54",
            "tgt_ix": "202-ARR_v1_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_55",
            "tgt_ix": "202-ARR_v1_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_55",
            "tgt_ix": "202-ARR_v1_55@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_56",
            "tgt_ix": "202-ARR_v1_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_57",
            "tgt_ix": "202-ARR_v1_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_57",
            "tgt_ix": "202-ARR_v1_57@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_57",
            "tgt_ix": "202-ARR_v1_57@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_57",
            "tgt_ix": "202-ARR_v1_57@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_58",
            "tgt_ix": "202-ARR_v1_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_59",
            "tgt_ix": "202-ARR_v1_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_59",
            "tgt_ix": "202-ARR_v1_59@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_59",
            "tgt_ix": "202-ARR_v1_59@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_59",
            "tgt_ix": "202-ARR_v1_59@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_59",
            "tgt_ix": "202-ARR_v1_59@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_59",
            "tgt_ix": "202-ARR_v1_59@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_60",
            "tgt_ix": "202-ARR_v1_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_61",
            "tgt_ix": "202-ARR_v1_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_62",
            "tgt_ix": "202-ARR_v1_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_63",
            "tgt_ix": "202-ARR_v1_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_63",
            "tgt_ix": "202-ARR_v1_63@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_63",
            "tgt_ix": "202-ARR_v1_63@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_64",
            "tgt_ix": "202-ARR_v1_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_64",
            "tgt_ix": "202-ARR_v1_64@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_64",
            "tgt_ix": "202-ARR_v1_64@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_64",
            "tgt_ix": "202-ARR_v1_64@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_64",
            "tgt_ix": "202-ARR_v1_64@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_65",
            "tgt_ix": "202-ARR_v1_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_66",
            "tgt_ix": "202-ARR_v1_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_66",
            "tgt_ix": "202-ARR_v1_66@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_66",
            "tgt_ix": "202-ARR_v1_66@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_66",
            "tgt_ix": "202-ARR_v1_66@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_67",
            "tgt_ix": "202-ARR_v1_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_68",
            "tgt_ix": "202-ARR_v1_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_68",
            "tgt_ix": "202-ARR_v1_68@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_68",
            "tgt_ix": "202-ARR_v1_68@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_68",
            "tgt_ix": "202-ARR_v1_68@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_68",
            "tgt_ix": "202-ARR_v1_68@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_69",
            "tgt_ix": "202-ARR_v1_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_70",
            "tgt_ix": "202-ARR_v1_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_71",
            "tgt_ix": "202-ARR_v1_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_72",
            "tgt_ix": "202-ARR_v1_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_72",
            "tgt_ix": "202-ARR_v1_72@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_72",
            "tgt_ix": "202-ARR_v1_72@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_72",
            "tgt_ix": "202-ARR_v1_72@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_72",
            "tgt_ix": "202-ARR_v1_72@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_72",
            "tgt_ix": "202-ARR_v1_72@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_72",
            "tgt_ix": "202-ARR_v1_72@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_72",
            "tgt_ix": "202-ARR_v1_72@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_73",
            "tgt_ix": "202-ARR_v1_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_74",
            "tgt_ix": "202-ARR_v1_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_74",
            "tgt_ix": "202-ARR_v1_74@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_74",
            "tgt_ix": "202-ARR_v1_74@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_74",
            "tgt_ix": "202-ARR_v1_74@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_74",
            "tgt_ix": "202-ARR_v1_74@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_74",
            "tgt_ix": "202-ARR_v1_74@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_74",
            "tgt_ix": "202-ARR_v1_74@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_74",
            "tgt_ix": "202-ARR_v1_74@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_74",
            "tgt_ix": "202-ARR_v1_74@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_74",
            "tgt_ix": "202-ARR_v1_74@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_75",
            "tgt_ix": "202-ARR_v1_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_76",
            "tgt_ix": "202-ARR_v1_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_76",
            "tgt_ix": "202-ARR_v1_76@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_76",
            "tgt_ix": "202-ARR_v1_76@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_76",
            "tgt_ix": "202-ARR_v1_76@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_77",
            "tgt_ix": "202-ARR_v1_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_77",
            "tgt_ix": "202-ARR_v1_77@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_77",
            "tgt_ix": "202-ARR_v1_77@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_78",
            "tgt_ix": "202-ARR_v1_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_78",
            "tgt_ix": "202-ARR_v1_78@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_78",
            "tgt_ix": "202-ARR_v1_78@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_78",
            "tgt_ix": "202-ARR_v1_78@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_78",
            "tgt_ix": "202-ARR_v1_78@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_79",
            "tgt_ix": "202-ARR_v1_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_79",
            "tgt_ix": "202-ARR_v1_79@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_80",
            "tgt_ix": "202-ARR_v1_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_80",
            "tgt_ix": "202-ARR_v1_80@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_80",
            "tgt_ix": "202-ARR_v1_80@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_81",
            "tgt_ix": "202-ARR_v1_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_81",
            "tgt_ix": "202-ARR_v1_81@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_81",
            "tgt_ix": "202-ARR_v1_81@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_82",
            "tgt_ix": "202-ARR_v1_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_82",
            "tgt_ix": "202-ARR_v1_82@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_83",
            "tgt_ix": "202-ARR_v1_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_84",
            "tgt_ix": "202-ARR_v1_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_85",
            "tgt_ix": "202-ARR_v1_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_86",
            "tgt_ix": "202-ARR_v1_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_86",
            "tgt_ix": "202-ARR_v1_86@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_86",
            "tgt_ix": "202-ARR_v1_86@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_87",
            "tgt_ix": "202-ARR_v1_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_87",
            "tgt_ix": "202-ARR_v1_87@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_88",
            "tgt_ix": "202-ARR_v1_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_88",
            "tgt_ix": "202-ARR_v1_88@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_88",
            "tgt_ix": "202-ARR_v1_88@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_89",
            "tgt_ix": "202-ARR_v1_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_90",
            "tgt_ix": "202-ARR_v1_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_91",
            "tgt_ix": "202-ARR_v1_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_92",
            "tgt_ix": "202-ARR_v1_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_93",
            "tgt_ix": "202-ARR_v1_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_94",
            "tgt_ix": "202-ARR_v1_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_95",
            "tgt_ix": "202-ARR_v1_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_96",
            "tgt_ix": "202-ARR_v1_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_97",
            "tgt_ix": "202-ARR_v1_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_98",
            "tgt_ix": "202-ARR_v1_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_99",
            "tgt_ix": "202-ARR_v1_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_100",
            "tgt_ix": "202-ARR_v1_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_101",
            "tgt_ix": "202-ARR_v1_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_102",
            "tgt_ix": "202-ARR_v1_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_103",
            "tgt_ix": "202-ARR_v1_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_104",
            "tgt_ix": "202-ARR_v1_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_105",
            "tgt_ix": "202-ARR_v1_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_106",
            "tgt_ix": "202-ARR_v1_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_107",
            "tgt_ix": "202-ARR_v1_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_108",
            "tgt_ix": "202-ARR_v1_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "202-ARR_v1_109",
            "tgt_ix": "202-ARR_v1_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 992,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "position_tag_type": "from_draft",
        "doc_id": "202-ARR",
        "version": 1
    }
}