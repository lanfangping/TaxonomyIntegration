{
    "nodes": [
        {
            "ix": "308-ARR_v1_0",
            "content": "Residue-Based Natural Language Adversarial Attack Detection",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_2",
            "content": "Deep learning based systems are susceptible to adversarial attacks, where a small, imperceptible change at the input alters the model prediction. However, to date the majority of the approaches to detect these attacks have been designed for image processing systems. Many popular image adversarial detection approaches are able to identify adversarial examples from embedding feature spaces, whilst in the NLP domain existing state of the art detection approaches solely focus on input text features, without consideration of model embedding spaces. This work examines what differences result when porting these image designed strategies to Natural Language Processing (NLP) tasks -these detectors are found to not port over well. This is expected as NLP systems have a very different form of input: discrete and sequential in nature, rather than the continuous and fixed size inputs for images. As an equivalent model-focused NLP detection approach, this work proposes a simple sentenceembedding \"residue\" based detector to identify adversarial examples. On many tasks, it outperforms ported image domain detectors and recent state of the art NLP specific detectors 1 .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "308-ARR_v1_4",
            "content": "In the last decade deep learning based models have demonstrated success in a wide range of application areas, including Natural Language Processing (NLP) (Vaswani et al., 2017) and object recognition (He et al., 2015). These systems may be deployed in mission critical situations, where there is the requirement for a high level of robustness. However, (Szegedy et al., 2014) demonstrated that deep models have an inherent weakness: small perturbations in the input can yield significant, undesired, changes in the output from the model. These input perturbations were termed adversarial examples and their generation adversarial attacks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_5",
            "content": "Adversarial attacks have been developed for systems operating in various domains: image systems (Serban et al., 2020;Biggio and Roli, 2017;Bhambri et al., 2019) and NLP systems (Lin et al., 2014;Samanta and Mehta, 2017;Rosenberg et al., 2017). The characteristics of the input can be very different between these application domains. Broadly, the nature of inputs can be described using two key attributes: static (fixed length) vs sequential and continuous vs discrete. Under this categorisation, image inputs are continuous and static, whilst NLP inputs are discrete and sequential. This work argues that due to the fundamental differences in the input and resulting adversarial perturbations in the different domains, adversarial attack behaviour can vary significantly from one domain to another. Hence, the extensive research on exploring and understanding adversarial perturbation behaviour in the continuous, static world of image systems does not necessarily transfer well to the NLP tasks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_6",
            "content": "For adversarial attack generation, a number of specific NLP attacks have been proposed that are designed for NLP task inputs (Lin et al., 2014;Samanta and Mehta, 2017;Rosenberg et al., 2017;Grosse et al., 2016;Sun et al., 2018;Cheng et al., 2018;Blohm et al., 2018;DBL, 2018;Neekhara et al., 2018;Raina et al., 2020;Jia and Liang, 2017;Minervini and Riedel, 2018;Niu and Bansal, 2018;Ribeiro et al., 2018;Iyyer et al., 2018;Zhao et al., 2017). However, there has been less research on developing defence schemes. These defence strategies can be split into two main groups: model modification, where the model or data is altered at training time (e.g. adversarial training (Yoo and Qi, 2021)) and detection, where external systems or algorithms are applied to trained models to identify adversarial attacks. As model modification approaches demand re-training of models, detection approaches are usually considered easier for implementation on deployed systems and thus are often preferred. Hence, this work investigates the portability of popular detection approaches designed for image systems to NLP systems. Furthermore, this work introduces a specific NLP detection approach that exploits the discrete nature of the inputs for NLP systems. This approach out-performs standard schemes designed for image adversarial attack detection, as well as other NLP detection schemes.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_7",
            "content": "The proposed NLP specific detection approach will be referred to as residue detection, as it is shown that adversarial attacks in the discrete, word sequence, space result in easily detectable residual components in the sentence embedding space. This residue can be easily detected using a simple linear classifier operating in the encoder embedding space. In addition, this work shows that even when an adversary has knowledge of the linear residual detector, they can only construct attacks at a fraction of the original strength. Hence this work argues that realistic (word level, semantically similar) adversarial perturbations at the natural language input of NLP systems leave behind easily detectable residue in the sentence embedding. Interestingly, the residue detection approach is shown to perform poorly when used to detect attacks in the image domain, supporting the hypothesis that the nature of the input has an important influence on the design of effective defence strategies.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_8",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "308-ARR_v1_9",
            "content": "Previous work in the image domain has analysed the output of specific layers in an attempt to identify adversarial examples or adversarial subspaces. First, (Feinman et al., 2017) proposed that adversarial subspaces have a lower probability density, motivating the use of the Kernel Density (KD) metric to detect the adversarial examples. Nevertheless, (Ma et al., 2018) found Local Intrinsic Dimensionality (LID) was a better metric in defining the subspace for more complex data. In contrast to the local subspace focused approaches of KD and LID, (Carrara et al., 2019b) showed that trajectories of hidden layer features can be used to train a LSTM network to accurately discriminate between authentic and adversarial examples. Out performing all previous methods, ( introduced an effective detection framework using Mahalanobis Distance Analysis (MDA), where the distance is calculated between a test sample and the closest class-conditional Gaussian distribution in the space defined by the output of the final layer of the classifier (logit space). (Li and Li, 2016) also explored using the output of convolutional layers for image classification systems to identify statistics that distinguish adversarial samples from original samples. They find that by performing a PCA decomposition the statistical variation in the least principal directions is the most significant and can be used to separate original and adversarial samples. However, they argue this is ineffective as an adversary can easily suppress the tail distribution. Hence, (Li and Li, 2016) extract statistics from the convolutional layer output to train a cascade classifier to separate the original and adversarial samples. Most recently, (Mao et al., 2019) avoid the use of artificially designed metrics and combine the adversarial subspace identification stage and the detecting adversaries stage into a single framework, where a parametric model adaptively learns the deep features for detecting adversaries.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_10",
            "content": "In contrast to the embedding space detection approaches, (Cohen et al., 2019) shows that influence functions combined with Nearest Neighbour distances perform comparably or better than the above standard detection approaches. Other detection approaches have explored the use of uncertainty: (Smith and Gal, 2018) argues that adversarial examples are out of distribution and do not lie on the manifold of real data. Hence, a discriminative Bayesian model's epistemic (model) uncertainty should be high. Therefore, calculations of the model uncertainty are thought to be useful in detecting adversarial examples, independent of the domain. However, Bayesian approaches aren't always practical in implementation and thus many different approaches to approximate this uncertainty have been suggested in literature (Leibig et al., 2017;Gal, 2016;Gal and Ghahramani, 2016).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_11",
            "content": "There are a number of existing NLP specific detection approaches. For character level attacks, detection approaches have exploited the grammatical (Sakaguchi et al., 2017) and spelling (Mays et al., 1991;Islam and Inkpen, 2009) inconsistencies to identify and detect the adversarial samples. However, these character level attacks are unlikely to be employed in practice due to the simplicity with which they can be detected. Therefore, detection approaches for the more difficult semantically similar attack samples are of greater interest, where the meaning of the textual input is maintained without compromising the spelling or grammatical integrity. To tackle such word-level, semantically similar examples, designed a discriminator to classify each token representation as part of an adversarial perturbation or not, which is then used to 'correct' the perturbation. Other detection approaches (Raina et al., 2020;Han et al., 2020;Minervini and Riedel, 2018) have shown some success in using perplexity to identify adversarial textual examples. Most recently, (Mozes et al., 2020) achieved state of the art performance with the Frequency Guided Word Substitution (FGWS) detector, where a change in model prediction after substituting out low frequency words is revealing of adversarial samples.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_12",
            "content": "Adversarial Attacks",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "308-ARR_v1_13",
            "content": "An adversarial attack is defined as an imperceptible change to the input that causes an undesired change in the output of a system. Often, an attack is found for a specific data point, x. Consider a classifier F \u03b8, with parameters \u03b8, that predicts a class label for an input data point, x, sampled from the input distribution X . A successful adversarial attack is where a perturbation \u03b4 at the input causes the system to miss-classify,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_14",
            "content": "F \u03b8(x + \u03b4) \u0338 = F \u03b8(x).",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_15",
            "content": "(1)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_16",
            "content": "When defining adversarial attacks, it is important consider the interpretation of an imperceptible change. Adversarial perturbations are not considered effective if they are easy to detect. Hence, the size of the perturbation must be constrained:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_17",
            "content": "G(x, x + \u03b4) \u2264 \u03f5,(2)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_18",
            "content": "where the function G() describes the form of constraint and \u03f5 is a selected threshold of imperceptibility. Typically, when considering continuous space inputs (such as images), a popular form of the constraint of Equation 2, is to limit the perturbation in the l p norm, with p \u2208 [1, \u221e), e.g. ||\u03b4|| p \u2264 \u03f5.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_19",
            "content": "For whitebox attacks in the image domain, the dominant attack approach has proven to be Projected Gradient Descent (PGD) (Kurakin et al., 2016). The PGD approach, iteratively updates the adversarial perturbation, \u03b4, initialised as \u03b4 0 = 0. Each iterative step moves the perturbation in the direction that maximises the loss function, L, used in the training of the model,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_20",
            "content": "\u03b4 i+1 = clip \u03f5 (\u03b4 i + \u03b1\u2207 \u03b4 i L(x + \u03b4 i ; \u03b8)), (3)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_21",
            "content": "where \u03b1 is an arbitrary step-size parameter and the clipping function, clip \u03f5 , ensures the imperceptibility constraint of Equation 2 is satisfied.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_22",
            "content": "When considering the NLP domain, a sequential, discrete input of L words, can be explicitly represented as,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_23",
            "content": "x = w 1:L = w 1 , w 2 , . . . , w L\u22121 , w L ,(4)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_24",
            "content": "where, the discrete word tokens, w 1:L , are often mapped to a continuous, sequential word embedding (Devlin et al., 2019) space,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_25",
            "content": "h 1:L = h 1 , h 2 , . . . , h L\u22121 , h L . (5",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_26",
            "content": ")",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_27",
            "content": "Attacks must take place in the discrete text space,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_28",
            "content": "x + \u03b4 = w \u2032 1:L \u2032 = w \u2032 1 , w \u2032 2 , . . . , w \u2032 L \u2032 \u22121 , w L \u2032 ,(6)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_29",
            "content": "This requires a change in the interpretation of the perturbation \u03b4. It is not simple to define an appropriate function G() in Equation 2for word sequences. Perturbations can be measured at a character or word level. Alternatively, the perturbation could be measured in the vectorized embedding space (Equation 5), using for example l p -norm based (Goodfellow et al., 2015) metrics or cosine similarity (Carrara et al., 2019a), which have been used in the image domain. However, constraints in the embedding space do not necessarily achieve imperceptibility in the original word sequence space.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_30",
            "content": "The simplest approach is to use a variant of an editbased measurement , L e (), which counts the number of changes between the original sequence, w 1:L and the adversarial sequence w \u2032 1:L \u2032 , where a change is a swap/addition/deletion, and ensures it is smaller than a maximum number of changes, N ,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_31",
            "content": "L e (w 1:L , w \u2032 1:L \u2032 ) \u2264 N.(7)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_32",
            "content": "For the NLP adversarial attacks this work only examines word-level attacks, as these are considered more difficult to detect than character-level attacks. As an example, for an input sequence of L words, a N -word substitution adversarial attack, w \u2032 1:N , applied at word positions n 1 , n 2 , . . . , n N gives the adversarial output, w \u2032",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_33",
            "content": "1:L \u2032 w \u2032 1:L \u2032 = w 1 , . . . , w n 1 \u22121 , w \u2032 1 , w n 1 +1 , . . . , w n N \u22121 , w \u2032 N , w n N +1 , . . . , w L . (8",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_34",
            "content": ")",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_35",
            "content": "The challenge is to select which words to replace, and what to replace them with. A simple yet effective substitution attack approach that ensures a small change in the semantic content of a sentence is to use saliency to rank the word positions, and to use word synonyms for the substitutions (Ren et al., 2019). This attack is termed Probability Weight Word Saliency (PWWS). The highest ranking word word can be swapped for a synonym from a preselected list of given synonyms. The next most highly ranked word is substituted in the same manner and the process is repeated till the required N words have been substituted. The above approach is limited to attacking specific word sequences and so cannot easily be generalised to universal attacks (Moosavi-Dezfooli et al., 2016), where the same perturbation is used for all inputs. For this situation, a simple solution is concatenation (Wang and Bansal, 2018;Blohm et al., 2018), where for example, the same N -length sequence of words is appended to each input sequence of words, as described in (Raina et al., 2020). Here,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_36",
            "content": "w \u2032 1:L \u2032 = w 1 , . . . , w L , w \u2032 1 , . . . , w \u2032 N .(9)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_37",
            "content": "In both the substitution attack (Equation 8) and the concatenation attack (Equation 9), the size of the attack can be measured using the number of edits, L e (w 1:L , w \u2032 1:L \u2032 ) = N .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_38",
            "content": "Adversarial Attack Detection",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "308-ARR_v1_39",
            "content": "For a deployed system, the easiest approach to defend against adversarial attacks is to use a detection process to identify adversarial examples without having to modify the existing system. For the image domain Section 2 discusses many of the standard detection approaches. In this work, we select two distinct approaches that have been generally successful: uncertainty (Smith and Gal, 2018), where adversarial samples are thought to result in greater epistemic uncertainty and Mahalanobis Distance , where the Mahalanobis distance in the logit space is indicative of how out of distribution a sample is (adversarial samples are considered more out of distribution). In the NLP domain, when excluding trivial grammar and spelling based detectors, perplexity based detectors can be used (Raina et al., 2020). Many other NLP specific detectors Han et al., 2020;Minervini and Riedel, 2018) have been proposed, but (Mozes et al., 2020)'s FGWS detector is considered the state of art and is thus selected for comparison. Here low frequency words in an input are substituted for higher frequency words and the change in model prediction is measured -adversarial samples are found to generally have a greater change. This work introduces a further NLP specific detector: residue detection, described in detail in Section 4.1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_40",
            "content": "When considering any chosen detection measure F d , a threshold \u03b2 can be selected to decide whether an input, w 1:L , is adversarial or not, where F d (w 1:L ) > \u03b2, implies that w 1:L is an adversarial sample. To assess the success of the adversarial attack detection processes, precision-recall curves are used. For the binary classification task of identifying an input as adversarially attacked or not, at a given threshold \u03b2, the precision and recall values can be computed as prec = TP/TP + FP and rec = TP/TP + FN, where TP, FP and FN are the standard true-positive, false-positive and falsenegative definitions. A single point summary of precision recall-curves is given with the F 1 score.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_41",
            "content": "Residue Detection",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "308-ARR_v1_42",
            "content": "In this work we introduce a new NLP detection approach, residue detection, that aims to exploit the nature of the NLP input space, discrete and sequential. Here we make two hypotheses:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_43",
            "content": "1. Adversarial samples in an encoder embedding space result in larger components (residue) in central PCA eigenvector components than original examples.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_44",
            "content": "2. The residue is only significant (detectable) for systems operating on discrete data (e.g. NLP systems).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_45",
            "content": "The rationale behind these hypotheses is discussed next.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_46",
            "content": "Deep learning models typically consist of many layers of non-linear activation functions. For example, in the NLP domain systems are usually based on layers of the Transformer architecture (Vaswani et al., 2017). The complete end-to-end model F \u03b8() can be treated as a two stage process, with an initial set of layers forming the encoding stage, F en () and the remaining layers forming the output stage,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_47",
            "content": "F cl (), i.e. F \u03b8(x) = F cl (F en (x)).",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_48",
            "content": "If the encoding stage of the end-to-end classifier is sufficiently powerful, then the embedding space F en (x) will have compressed the useful information into very few dimensions, allowing the output stage to easily separate the data points into classes (for classification) or map the data points to a continuous value (for regression). A simple Principal Component Analysis (PCA) decomposition of this embedding space can be used to visualize the level of compression of the useful information. The PCA directions can be found using the eigenvectors of the covariance matrix, C, of the data in the encoder embedding space. If {q i } d i=1 , where d is the dimension of the encoder embedding space, represent the eigenvectors of C ordered in descending order by the associated eigenvalue in magnitude, then it is expected that almost all useful information is contained within the first few principal directions, {q i } p i=1 , where p \u226a d. Hence, the output stage, F cl () will implicitly use only these useful components. The impact of a successful adversarial perturbation, F en (x + \u03b4), is the significant change in the components in the principal eigenvector directions {q i } p i=1 , to allow fooling of the output stage. Due to the complex nature of the encoding stage and the out of distribution nature of the adversarial perturbations, there are likely to be residual components in the non-principal {q i } d i=p+1 eigenvector directions. These perturbations in the non-principal directions are likely to be more significant for the central eigenvectors, as the encoding stage is likely to almost entirely compress out components in the least principal eigenvector directions, {q i } d i=d \u2032 +1 , where d \u2032 \u2248 d. Hence, {q i } d \u2032 i=p+1 can be viewed as a subspace containing adversarial attack residue that can be used to identify adversarial examples.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_49",
            "content": "The existence of adversarial attack residue in the central PCA eigenvector directions, {q i } d \u2032 i=p+1 , suggests that in the encoder embedding space, F en (x), adversarial and original examples are linearly separable. This motivates the use of a simple linear classifier as an adversarial attack detector,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_50",
            "content": "P (adv|x) = \u03c3(WF en (x) + b),(10)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_51",
            "content": "where W and b are the parameters of the linear classifier to be learnt and \u03c3 is the sigmoid function.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_52",
            "content": "The above argument cannot predict how significant the residue in the central eigenvector space is likely to be. For the discrete space NLP attacks, the input perturbations are semantically small, whilst for continuous space image attacks the perturbations are explicitly small using a standard l p -norm. Hence, it is hypothesised that NLP perturbations cause larger errors to propagate through the system, resulting in more significant residue in the encoder embedding space than that for image attacks. Thus, the residue technique is only likely to be a feasible detection approach for discrete text attacks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_53",
            "content": "The hypotheses made in this section are analysed and empirically verified in Section 5.3.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_54",
            "content": "Experiments",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "308-ARR_v1_55",
            "content": "Experimental Setup",
            "ntype": "title",
            "meta": {
                "section": "5.1"
            }
        },
        {
            "ix": "308-ARR_v1_56",
            "content": "Table 1 describes four NLP classification datasets: IMDB (Maas et al., 2011); Twitter (Saravia et al., 2018); AG News and DBpedia . Further, a regression dataset, Linguaskill-Business (L-Bus) (Chambers and Ingham, 2011) All NLP task models were based on the Transformer encoder architecture (Vaswani et al., 2017). Table 2 indicates the specific architecture used for each task and also summarises the classification and regression performance for the different tasks. For classification tasks, the performance is measured by top 1 accuracy, whilst for the regression task (L-Bus), the performance is measured using Pearson Correlation Coefficient (PCC). (Devlin et al., 2018), ELECTRA (Clark et al., 2020)).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_57",
            "content": "Table 3 shows the impact of realistic adversarial attacks on the tasks: substitution (sub) attack (Equation 8), which replaces the N most salient tokens with a synonym defined by WordNet 2 , as dictated by the PWWS attack algorithm described in Section 3; or a targeted universal concatenation (con) attack (Equation 9), used for the regression task on the L-Bus dataset, seeking to maximise the average score output from the system by appending the same N words to the end of each input. For classification tasks, the impact of the adversarial attack is measured using the fooling rate, the fraction of originally correctly classified points, misclassified after the attack, whilst for the regression task, the impact is measured as the average increase in the output score.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_58",
            "content": "Results",
            "ntype": "title",
            "meta": {
                "section": "5.2"
            }
        },
        {
            "ix": "308-ARR_v1_59",
            "content": "Section 4.1 predicts that adversarial attacks in the discrete text space leave residue in a system's encoder embedding space that can be detected using a simple linear classifier. Hence, using the 12layer Transformer encoder's output CLS token embedding as the encoder embedding space for each dataset's trained system (Table 2), a simple linear classifier, as given in Equation 10, was trained 3 to detect adversarial examples from the adversarial attacks given for each dataset in Table 3. The training of the detection linear classifier was performed on the training data (Table 1) augmented with an equivalent adversarial example for each original input sample in the dataset. Using the test data samples augmented with adversarial examples (as defined by Table 3), Table 4 compares the efficacy of the linear residue detector to other popular detection strategies 4 (from Section 4) using the best F 1 score. It is evident from the high F-scores, that for most NLP tasks the linear detection approach is better than other state of the art NLP specific and ported image detection approaches. However, an adversary may have knowledge of the detection approach and may attempt to design an attack that directly avoids detection. Hence, for each dataset, the attack approaches were repeated with the added constraint that any attack words that resulted in detection were rejected. The impact of attacks that suppress detection have been presented in Table 5. Generally, it is shown across all NLP tasks that an adversary that attempts to avoid detection of its residue by a previously trained linear classifier, can only generate a significantly less powerful adversarial attack.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_60",
            "content": "Analysis",
            "ntype": "title",
            "meta": {
                "section": "5.3"
            }
        },
        {
            "ix": "308-ARR_v1_61",
            "content": "The aim of this section is verify that the success of the residue detector can be explained by the two main hypotheses made in Section 4.1. The claim that residue is left by adversarial samples in the central PCA eigenvector components is explored first. For each NLP task a PCA projection matrix is learnt in the encoder embedding space using the original training data samples (Table 1). Using the test data, the residue in the embedding space can be visualized through a plot of the average (across the data) component, \u03c1 i = 1 J J j=1 \u03c1 i,j in each eigenvector direction, q i of the original and attacked data, where",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_62",
            "content": "\u03c1 i,j = F en (x j ) T q i ,(11)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_63",
            "content": "with x j being the jth data point. Figure 1 shows an example plot for the Twitter dataset, where \u03c1 i is plotted against the eigenvalue rank, i for the original and attacked data examples. Residue plots for other datasets are included in Appendix A. Next, it is necessary to verify that the residue detector specifically uses the residue in the central eigenvector components to distinguish between original and adversarial samples. To establish this, each encoder embedding, F en (x)'s components not within a target subspace of PCA eigenvector directions {q i } p+w i=p , are removed, i.e. we have a projected embedding, x (p) = F en (x)\u2212 i / \u2208[p,p+w) q T i F en (x)q i , where w is a window size to choose. Now, using F cl (x (p) ) and a residue detector trained using the modified embeddings, x (p) , the classifier's (F cl (x (p) )) accuracy and detector performance (measured using F1 score) can be found. Figure 2 shows the performance of the classifier (F cl (x (p) )) and the detector for different start components p, with the window size, w = 5. It is clear that the principal components hold the most important information for classifier accuracy, but, as hypothesised in Section 4.1, it is the more central eigenvector components that hold the most information useful for the residue detector, i.e. the subspace defined by {q i } 10 i=5 holds the most detectable residue from adversarial examples. The second hypothesis in Section 4.1 claims that the existence of residue in the central eigenvector components is due to the discrete nature of NLP adversarial attacks. Hence, to analyze the impact of the discrete aspect of the attack, an artificial continuous space attack was constructed for the Twitter NLP system, where the continuous input embedding layer space (Equation 5) of the system is the space in which the attack is performed. Using the Twitter emotion classifier, a PGD (Equation 3) attack was performed on the input embeddings for each token, where the perturbation size was limited to be \u03f5 = 0.1 in the l \u221e norm, achieving a fooling rate of 0.73. Note that this form of attack is artificial, as a real adversary can only modify the discrete word sequence (Equation 4). To compare the influence of discrete and continuous attacks on the same system, the average (across dataset) l 2 and l \u221e norms of the perturbations in the input layer embedding space were found. Further, a single value summary, N \u03c3 , of the residue plot (e.g. Figure 1), was calculated for each attack. N \u03c3 is the average difference in standard deviations between the original component mean, \u03c1 To explicitly observe the impact of the nature of data on detectors, adversarial attacks are considered in four domains: the discrete, sequential NLP input space (NLP-disc); the artificial continuous, sequential embedding space of an NLP model (NLP-cont); the continuous, static image input space (Img-cont) and a forced discretised, static image input space (Img-disc). For the NLP-disc and NLP-cont the same attacks as in Table 6 are used. For the continuous image domain (Img-cont), a VGG-16 architecture image classifier trained on CIFAR-100 (Krizhevsky et al.) image data (achieving a top-5 accuracy of 90.1%) and attacked using a standard l \u221e PGD approach (Equation 3) is used. For the discrete image domain (Img-disc), the CIFAR-100 images, X \u2208 Z R\u00d7R 256 were discretised using function",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_64",
            "content": "Q q : Z R\u00d7R 256 \u2192 Z R\u00d7R q",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_65",
            "content": ", where Z q = {0, 1 256 q\u22121 , 2 255 q\u22121 , . . . , 255}. In this work 2bit quantization was used, i.e. q = 4. With this quantization, a VGG-16 architecture was trained to achieve 78.2% top-5 accuracy. To perform a discrete space attack, a variant of the PWWS synonym substitution attack (Section 3) was implemented, where synonyms were interpreted as closest permitted quantisation values and N pixel values were substituted 6 . For these different domains, Table 7 compares applicable detection approaches (certain NLP detection approaches are not valid outside the word sequence space) using the best F 1 score, where different attack perturbation sizes are considered (N substitutions for discrete attacks and for continuous attacks |\u03b4| \u2264 \u03f5 for perturbation \u03b4). In the discrete domains, the residue detection approach is better than all the other approaches. However, in the continuous data type domains, the Mahalanobis Distance dominates as the detection approach, with the residue detection approach performing the worst. As predicted by the second hypothesis of Section 4.1, the lack of success of the residue detection approach is expected here -6 Code for Image Experiments: link after anonymity period.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_66",
            "content": "the residue detection approach is only successful for discrete space attacks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_67",
            "content": "To verify that the residue detection approach is agnostic to the type of attack, the residue detector trained on substitution attack examples was evaluated on concatenation attack examples. Using the Twitter dataset, a N = 3 concatenation attack was applied, achieving a fooling rate of 0.59. In this setting, the residue detector (trained on the N = 6 substitution adversarial examples) achieved a F 1 score of 0.81, which is comparable to the original score of 0.84 (from Table 4). This shows that even with different attack approaches similar forms of residue are produced, meaning a residue detector can be used even without knowledge of the type of adversarial attack.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_68",
            "content": "Conclusions",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "308-ARR_v1_69",
            "content": "In recent years, deep learning systems have been deployed for a large number of tasks, ranging from the image to the natural language domain. However, small, imperceptible adversarial perturbations at the input, have been found to easily fool these systems, compromising their validity in high-stakes applications. Defence strategies for deep learning systems has been extensively researched, but this work has been predominantly carried out for systems operating in the image domain. As a result, the adversarial detection strategies developed, are inherently tuned to attacks on the continuous space of images. This work shows that these detection strategies do not necessarily transfer well to attacks on natural language processing systems. Hence, an adversarial attack detection approach is proposed that specifically exploits the discrete nature of perturbations for attacks on discrete sequential inputs.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_70",
            "content": "The proposed approach, termed residue detection, demonstrates that imperceptible attack perturbations on natural language inputs tend to result in large perturbations in word embedding spaces, which result in distinctive residual components. These residual components can be identified using a simple linear classifier. This residue detection approach was found to out-perform both detection approaches ported from the image domain and other state of the art NLP specific detectors.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_71",
            "content": "The key finding in this work is that the nature of the data (e.g. discrete or continuous) strongly influences the success of detection systems and hence it is important to consider the domain when designing defence strategies. 8, whilst the regression dataset, L-Bus, was subject to a N -word concatenation attack as in Equation 9. For the classification tasks the impact of the adversarial attacks was measured using fooling rate, whilst for the L-Bus dataset task, the average output score from the system is given. Figure A.2 gives the encoder embedding space PCA residue plots for all the datasets not included in the main text.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_72",
            "content": "In the main text, two main forms of text adversarial attacks are considered: PWWS substitution attack (Ren et al., 2019) and a simple universal concatenation attack (con) (Raina et al., 2020). For completeness, Table A.2 presents the success of the adversarial attack detection approaches from the main text on two other popular adversarial attack approaches:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_73",
            "content": "\u2022 Textfooler (Jin et al., 2019) -A blackbox substitution attack where words with highest importance ranking are replaced. \u2022 BERT-based Adversarial Examples (BAE) (Garg and Ramakrishnan, 2020) -A BERT language model is used to replace and insert tokens to construct the adversarial sequence. This variant is termed BAE-R/I. These adversarial attack approaches were implemented using the TextAttack (Morris et al., 2020) Python library with no change made to the default configurations. Note that this means the perturbation sizes are measured using a Universal Sentence Encoder's cosine similarity (Cer et al., 2018).",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_74",
            "content": "Table A.3 compares the impact on error sizes (using l 2 and l \u221e norms) and the residue plot metric, N \u03c3 for the original text space discrete attacks and an artificial input embedding space continuous attack. The purpose of this table is to present the results for the datasets not included in the main text in Table 6.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_75",
            "content": "A limitation of the residue approach proposed in this work is that it requires training on adversarial examples, which is not necessary for other NLP detectors. This means there is a greater computational cost associated with this detector. Moreover, associated with this limitation is a small risk, where in process of generating creative adversarial examples to build a robust residue detector, the attack generation scheme may be so strong that it can more easily evade detection from other existing detectors already deployed in industry. There are no further ethical concerns related to this detector.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "308-ARR_v1_76",
            "content": "UNKNOWN, None, , Adversarial texts with gradient methods, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Adversarial texts with gradient methods",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_77",
            "content": "UNKNOWN, None, 1667, A study of black box adversarial attacks in computer vision, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": null,
                "title": null,
                "pub_date": "1667",
                "pub_title": "A study of black box adversarial attacks in computer vision",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_78",
            "content": "UNKNOWN, None, 2017, Wild patterns: Ten years after the rise of adversarial machine learning, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": "Wild patterns: Ten years after the rise of adversarial machine learning",
                "pub": "CoRR"
            }
        },
        {
            "ix": "308-ARR_v1_79",
            "content": "UNKNOWN, None, 2018, Comparing attentionbased convolutional and recurrent neural networks: Success and limitations in machine reading comprehension, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Comparing attentionbased convolutional and recurrent neural networks: Success and limitations in machine reading comprehension",
                "pub": "CoRR"
            }
        },
        {
            "ix": "308-ARR_v1_80",
            "content": "Fabio Carrara, Rudy Becarelli, Roberto Caldelli, Fabrizio Falchi, Giuseppe Amato, Adversarial examples detection in features distance spaces, 2019, Computer Vision -ECCV 2018 Workshops, Springer International Publishing.",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Fabio Carrara",
                    "Rudy Becarelli",
                    "Roberto Caldelli",
                    "Fabrizio Falchi",
                    "Giuseppe Amato"
                ],
                "title": "Adversarial examples detection in features distance spaces",
                "pub_date": "2019",
                "pub_title": "Computer Vision -ECCV 2018 Workshops",
                "pub": "Springer International Publishing"
            }
        },
        {
            "ix": "308-ARR_v1_81",
            "content": "UNKNOWN, None, 2019, Adversarial Examples Detection in Features Distance Spaces: Subvolume B, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Adversarial Examples Detection in Features Distance Spaces: Subvolume B",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_82",
            "content": "UNKNOWN, None, 2018, Chris Tar, Yun-Hsuan Sung, Brian Strope, and Ray Kurzweil, .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Chris Tar, Yun-Hsuan Sung, Brian Strope, and Ray Kurzweil",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_83",
            "content": "Lucy Chambers, Kate Ingham, The BULATS online speaking test, 2011, Research Notes, .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Lucy Chambers",
                    "Kate Ingham"
                ],
                "title": "The BULATS online speaking test",
                "pub_date": "2011",
                "pub_title": "Research Notes",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_84",
            "content": "X Chen, X Liu, Y Qian, M Gales, P Woodland, Cued-rnnlm -an open-source toolkit for efficient training and evaluation of recurrent neural network language models, 2016, 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "X Chen",
                    "X Liu",
                    "Y Qian",
                    "M Gales",
                    "P Woodland"
                ],
                "title": "Cued-rnnlm -an open-source toolkit for efficient training and evaluation of recurrent neural network language models",
                "pub_date": "2016",
                "pub_title": "2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_85",
            "content": "UNKNOWN, None, 2018, Seq2sick: Evaluating the robustness of sequence-to-sequence models with adversarial examples, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Seq2sick: Evaluating the robustness of sequence-to-sequence models with adversarial examples",
                "pub": "CoRR"
            }
        },
        {
            "ix": "308-ARR_v1_86",
            "content": "UNKNOWN, None, 2003, ELECTRA: pretraining text encoders as discriminators rather than generators. CoRR, abs, .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": null,
                "title": null,
                "pub_date": "2003",
                "pub_title": "ELECTRA: pretraining text encoders as discriminators rather than generators. CoRR, abs",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_87",
            "content": "UNKNOWN, None, 2019, Detecting adversarial samples using influence functions and nearest neighbors, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Detecting adversarial samples using influence functions and nearest neighbors",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_88",
            "content": ", Common European Framework of Reference for Languages: Learning, Teaching, 2001, Assessment, Cambridge University Press.",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [],
                "title": "Common European Framework of Reference for Languages: Learning, Teaching",
                "pub_date": "2001",
                "pub_title": "Assessment",
                "pub": "Cambridge University Press"
            }
        },
        {
            "ix": "308-ARR_v1_89",
            "content": "UNKNOWN, None, 2018, BERT: pre-training of deep bidirectional transformers for language understanding, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "BERT: pre-training of deep bidirectional transformers for language understanding",
                "pub": "CoRR"
            }
        },
        {
            "ix": "308-ARR_v1_90",
            "content": "UNKNOWN, None, 2019, Bert: Pre-training of deep bidirectional transformers for language understanding, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_91",
            "content": "UNKNOWN, None, 2017, Detecting adversarial samples from artifacts, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": "Detecting adversarial samples from artifacts",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_92",
            "content": "UNKNOWN, None, 2016, Uncertainty in deep learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": null,
                "title": null,
                "pub_date": "2016",
                "pub_title": "Uncertainty in deep learning",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_93",
            "content": "UNKNOWN, None, 2016, Dropout as a bayesian approximation: Representing model uncertainty in deep learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": null,
                "title": null,
                "pub_date": "2016",
                "pub_title": "Dropout as a bayesian approximation: Representing model uncertainty in deep learning",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_94",
            "content": "UNKNOWN, None, 1970, BAE: bert-based adversarial examples for text classification. CoRR, abs, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": null,
                "title": null,
                "pub_date": "1970",
                "pub_title": "BAE: bert-based adversarial examples for text classification. CoRR, abs",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_95",
            "content": "Ian Goodfellow, Jonathon Shlens, Christian Szegedy, Explaining and harnessing adversarial examples, 2015, International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "Ian Goodfellow",
                    "Jonathon Shlens",
                    "Christian Szegedy"
                ],
                "title": "Explaining and harnessing adversarial examples",
                "pub_date": "2015",
                "pub_title": "International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_96",
            "content": "UNKNOWN, None, 2016, Adversarial perturbations against deep neural networks for malware classification, .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": null,
                "title": null,
                "pub_date": "2016",
                "pub_title": "Adversarial perturbations against deep neural networks for malware classification",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_97",
            "content": "UNKNOWN, None, 2020, Adversarial attack and defense of structured prediction models, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Adversarial attack and defense of structured prediction models",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_98",
            "content": "UNKNOWN, None, 2015, Deep residual learning for image recognition, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": null,
                "title": null,
                "pub_date": "2015",
                "pub_title": "Deep residual learning for image recognition",
                "pub": "CoRR"
            }
        },
        {
            "ix": "308-ARR_v1_99",
            "content": "UNKNOWN, None, 2018, Adversarial deep learning for robust detection of binary encoded malware, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Adversarial deep learning for robust detection of binary encoded malware",
                "pub": "CoRR"
            }
        },
        {
            "ix": "308-ARR_v1_100",
            "content": "Aminul Islam, Diana Inkpen, Real-word spelling correction using google web it 3-grams, 2009, Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Aminul Islam",
                    "Diana Inkpen"
                ],
                "title": "Real-word spelling correction using google web it 3-grams",
                "pub_date": "2009",
                "pub_title": "Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "308-ARR_v1_101",
            "content": "Mohit Iyyer, John Wieting, Kevin Gimpel, Luke Zettlemoyer, Adversarial example generation with syntactically controlled paraphrase networks, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Mohit Iyyer",
                    "John Wieting",
                    "Kevin Gimpel",
                    "Luke Zettlemoyer"
                ],
                "title": "Adversarial example generation with syntactically controlled paraphrase networks",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "308-ARR_v1_102",
            "content": "UNKNOWN, None, 2017, Adversarial examples for evaluating reading comprehension systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": "Adversarial examples for evaluating reading comprehension systems",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_103",
            "content": "UNKNOWN, None, 1907, Is BERT really robust? natural language attack on text classification and entailment. CoRR, abs, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": null,
                "title": null,
                "pub_date": "1907",
                "pub_title": "Is BERT really robust? natural language attack on text classification and entailment. CoRR, abs",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_104",
            "content": "UNKNOWN, None, , Cifar-100 (canadian institute for advanced research), .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Cifar-100 (canadian institute for advanced research)",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_105",
            "content": "UNKNOWN, None, 2016, Adversarial machine learning at scale. CoRR, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": null,
                "title": null,
                "pub_date": "2016",
                "pub_title": "Adversarial machine learning at scale. CoRR",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_106",
            "content": "UNKNOWN, None, 2018, A simple unified framework for detecting outof-distribution samples and adversarial attacks, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "A simple unified framework for detecting outof-distribution samples and adversarial attacks",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_107",
            "content": "Christian Leibig, M Vaneeda Allken, Philipp Ayhan, S Berens,  Wahl, Leveraging uncertainty information from deep neural networks for disease detection, 2017, Scientific Reports, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": [
                    "Christian Leibig",
                    "M Vaneeda Allken",
                    "Philipp Ayhan",
                    "S Berens",
                    " Wahl"
                ],
                "title": "Leveraging uncertainty information from deep neural networks for disease detection",
                "pub_date": "2017",
                "pub_title": "Scientific Reports",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_108",
            "content": "UNKNOWN, None, 2018, Textbugger: Generating adversarial text against real-world applications, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Textbugger: Generating adversarial text against real-world applications",
                "pub": "CoRR"
            }
        },
        {
            "ix": "308-ARR_v1_109",
            "content": "UNKNOWN, None, 2016, Adversarial examples detection in deep networks with convolutional filter statistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": null,
                "title": null,
                "pub_date": "2016",
                "pub_title": "Adversarial examples detection in deep networks with convolutional filter statistics",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_110",
            "content": "UNKNOWN, None, 2014, , .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": null,
                "title": null,
                "pub_date": "2014",
                "pub_title": null,
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_111",
            "content": "UNKNOWN, None, 2018, Characterizing adversarial subspaces using local intrinsic dimensionality, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Characterizing adversarial subspaces using local intrinsic dimensionality",
                "pub": "CoRR"
            }
        },
        {
            "ix": "308-ARR_v1_112",
            "content": "Andrew Maas, Raymond Daly, Peter Pham, Dan Huang, Andrew Ng, Christopher Potts, Learning word vectors for sentiment analysis, 2011, Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "Andrew Maas",
                    "Raymond Daly",
                    "Peter Pham",
                    "Dan Huang",
                    "Andrew Ng",
                    "Christopher Potts"
                ],
                "title": "Learning word vectors for sentiment analysis",
                "pub_date": "2011",
                "pub_title": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_113",
            "content": "UNKNOWN, None, 2019, Learning to characterize adversarial subspaces, .",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Learning to characterize adversarial subspaces",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_114",
            "content": "Eric Mays, Fred Damerau, Robert Mercer, Context based spelling correction, 1991, Information Processing Management, .",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": [
                    "Eric Mays",
                    "Fred Damerau",
                    "Robert Mercer"
                ],
                "title": "Context based spelling correction",
                "pub_date": "1991",
                "pub_title": "Information Processing Management",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_115",
            "content": "UNKNOWN, None, 2018, Adversarially regularising neural NLI models to integrate logical background knowledge, .",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Adversarially regularising neural NLI models to integrate logical background knowledge",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_116",
            "content": "UNKNOWN, None, 2016, , .",
            "ntype": "ref",
            "meta": {
                "xid": "b40",
                "authors": null,
                "title": null,
                "pub_date": "2016",
                "pub_title": null,
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_117",
            "content": "John Morris, Eli Lifland, Jin Yoo, Jake Grigsby, Di Jin, Yanjun Qi, TextAttack: A framework for adversarial attacks, data augmentation, and adversarial training in NLP, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b41",
                "authors": [
                    "John Morris",
                    "Eli Lifland",
                    "Jin Yoo",
                    "Jake Grigsby",
                    "Di Jin",
                    "Yanjun Qi"
                ],
                "title": "TextAttack: A framework for adversarial attacks, data augmentation, and adversarial training in NLP",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_118",
            "content": "UNKNOWN, None, 2004, Frequency-guided word substitutions for detecting textual adversarial examples. CoRR, abs, .",
            "ntype": "ref",
            "meta": {
                "xid": "b42",
                "authors": null,
                "title": null,
                "pub_date": "2004",
                "pub_title": "Frequency-guided word substitutions for detecting textual adversarial examples. CoRR, abs",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_119",
            "content": "UNKNOWN, None, 2018, Adversarial reprogramming of sequence classification neural networks, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b43",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Adversarial reprogramming of sequence classification neural networks",
                "pub": "CoRR"
            }
        },
        {
            "ix": "308-ARR_v1_120",
            "content": "UNKNOWN, None, 2018, Adversarial oversensitivity and over-stability strategies for dialogue models, .",
            "ntype": "ref",
            "meta": {
                "xid": "b44",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Adversarial oversensitivity and over-stability strategies for dialogue models",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_121",
            "content": "UNKNOWN, None, 2016, Crafting adversarial input sequences for recurrent neural networks, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b45",
                "authors": null,
                "title": null,
                "pub_date": "2016",
                "pub_title": "Crafting adversarial input sequences for recurrent neural networks",
                "pub": "CoRR"
            }
        },
        {
            "ix": "308-ARR_v1_122",
            "content": "Vyas Raina, J Mark, Kate Gales,  Knill, Universal Adversarial Attacks on Spoken Language Assessment Systems, 2020, Proc. Interspeech 2020, .",
            "ntype": "ref",
            "meta": {
                "xid": "b46",
                "authors": [
                    " Vyas Raina",
                    "J Mark",
                    "Kate Gales",
                    " Knill"
                ],
                "title": "Universal Adversarial Attacks on Spoken Language Assessment Systems",
                "pub_date": "2020",
                "pub_title": "Proc. Interspeech 2020",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_123",
            "content": "Yihe Shuhuai Ren, Kun Deng, Wanxiang He,  Che, Generating natural language adversarial examples through probability weighted word saliency, 2019, ACL (1), .",
            "ntype": "ref",
            "meta": {
                "xid": "b47",
                "authors": [
                    "Yihe Shuhuai Ren",
                    "Kun Deng",
                    "Wanxiang He",
                    " Che"
                ],
                "title": "Generating natural language adversarial examples through probability weighted word saliency",
                "pub_date": "2019",
                "pub_title": "ACL (1)",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_124",
            "content": "Sameer Marco Tulio Ribeiro, Carlos Singh,  Guestrin, Semantically equivalent adversarial rules for debugging NLP models, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b48",
                "authors": [
                    "Sameer Marco Tulio Ribeiro",
                    "Carlos Singh",
                    " Guestrin"
                ],
                "title": "Semantically equivalent adversarial rules for debugging NLP models",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "308-ARR_v1_125",
            "content": "UNKNOWN, None, 2017, Generic black-box end-to-end attack against rnns and other API calls based malware classifiers, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b49",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": "Generic black-box end-to-end attack against rnns and other API calls based malware classifiers",
                "pub": "CoRR"
            }
        },
        {
            "ix": "308-ARR_v1_126",
            "content": "UNKNOWN, None, 2017, Grammatical error correction with neural reinforcement learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b50",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": "Grammatical error correction with neural reinforcement learning",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_127",
            "content": "UNKNOWN, None, 2017, Towards crafting text adversarial samples, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b51",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": "Towards crafting text adversarial samples",
                "pub": "CoRR"
            }
        },
        {
            "ix": "308-ARR_v1_128",
            "content": "Elvis Saravia, Hsien-Chi Toby Liu, Yen-Hao Huang, Junlin Wu, Yi-Shin Chen, CARER: Contextualized affect representations for emotion recognition, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b52",
                "authors": [
                    "Elvis Saravia",
                    "Hsien-Chi Toby Liu",
                    "Yen-Hao Huang",
                    "Junlin Wu",
                    "Yi-Shin Chen"
                ],
                "title": "CARER: Contextualized affect representations for emotion recognition",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "308-ARR_v1_129",
            "content": "UNKNOWN, None, 2008, Adversarial examples on object recognition: A comprehensive survey. CoRR, abs, .",
            "ntype": "ref",
            "meta": {
                "xid": "b53",
                "authors": null,
                "title": null,
                "pub_date": "2008",
                "pub_title": "Adversarial examples on object recognition: A comprehensive survey. CoRR, abs",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_130",
            "content": "UNKNOWN, None, 2018, Understanding measures of uncertainty for adversarial example detection, .",
            "ntype": "ref",
            "meta": {
                "xid": "b54",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Understanding measures of uncertainty for adversarial example detection",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_131",
            "content": "Mengying Sun, Fengyi Tang, Jinfeng Yi, Fei Wang, Jiayu Zhou, Identify susceptible locations in medical records via adversarial attacks on deep predictive models, 2018, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery amp; Data Mining, KDD '18, .",
            "ntype": "ref",
            "meta": {
                "xid": "b55",
                "authors": [
                    "Mengying Sun",
                    "Fengyi Tang",
                    "Jinfeng Yi",
                    "Fei Wang",
                    "Jiayu Zhou"
                ],
                "title": "Identify susceptible locations in medical records via adversarial attacks on deep predictive models",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery amp; Data Mining, KDD '18",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_132",
            "content": "Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, Rob Fergus, Intriguing properties of neural networks, 2014, International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b56",
                "authors": [
                    "Christian Szegedy",
                    "Wojciech Zaremba",
                    "Ilya Sutskever",
                    "Joan Bruna",
                    "Dumitru Erhan",
                    "Ian Goodfellow",
                    "Rob Fergus"
                ],
                "title": "Intriguing properties of neural networks",
                "pub_date": "2014",
                "pub_title": "International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_133",
            "content": "UNKNOWN, None, 2017, , .",
            "ntype": "ref",
            "meta": {
                "xid": "b57",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": null,
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_134",
            "content": "UNKNOWN, None, 2018, Robust machine comprehension models via adversarial training, .",
            "ntype": "ref",
            "meta": {
                "xid": "b58",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Robust machine comprehension models via adversarial training",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_135",
            "content": "UNKNOWN, None, 2021, Towards improving adversarial training of nlp models, .",
            "ntype": "ref",
            "meta": {
                "xid": "b59",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Towards improving adversarial training of nlp models",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_136",
            "content": "Xiang Zhang, Junbo Zhao, Yann Lecun, Character-level convolutional networks for text classification, 2015, Advances in Neural Information Processing Systems, Curran Associates, Inc.",
            "ntype": "ref",
            "meta": {
                "xid": "b60",
                "authors": [
                    "Xiang Zhang",
                    "Junbo Zhao",
                    "Yann Lecun"
                ],
                "title": "Character-level convolutional networks for text classification",
                "pub_date": "2015",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": "Curran Associates, Inc"
            }
        },
        {
            "ix": "308-ARR_v1_137",
            "content": "UNKNOWN, None, 2017, Generating natural adversarial examples, .",
            "ntype": "ref",
            "meta": {
                "xid": "b61",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": "Generating natural adversarial examples",
                "pub": null
            }
        },
        {
            "ix": "308-ARR_v1_138",
            "content": "UNKNOWN, None, 2019, Learning to discriminate perturbations for blocking adversarial attacks in text classification, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b62",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Learning to discriminate perturbations for blocking adversarial attacks in text classification",
                "pub": "CoRR"
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "308-ARR_v1_0@0",
            "content": "Residue-Based Natural Language Adversarial Attack Detection",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_0",
            "start": 0,
            "end": 58,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_2@0",
            "content": "Deep learning based systems are susceptible to adversarial attacks, where a small, imperceptible change at the input alters the model prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_2",
            "start": 0,
            "end": 144,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_2@1",
            "content": "However, to date the majority of the approaches to detect these attacks have been designed for image processing systems.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_2",
            "start": 146,
            "end": 265,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_2@2",
            "content": "Many popular image adversarial detection approaches are able to identify adversarial examples from embedding feature spaces, whilst in the NLP domain existing state of the art detection approaches solely focus on input text features, without consideration of model embedding spaces.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_2",
            "start": 267,
            "end": 548,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_2@3",
            "content": "This work examines what differences result when porting these image designed strategies to Natural Language Processing (NLP) tasks -these detectors are found to not port over well.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_2",
            "start": 550,
            "end": 729,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_2@4",
            "content": "This is expected as NLP systems have a very different form of input: discrete and sequential in nature, rather than the continuous and fixed size inputs for images.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_2",
            "start": 731,
            "end": 894,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_2@5",
            "content": "As an equivalent model-focused NLP detection approach, this work proposes a simple sentenceembedding \"residue\" based detector to identify adversarial examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_2",
            "start": 896,
            "end": 1054,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_2@6",
            "content": "On many tasks, it outperforms ported image domain detectors and recent state of the art NLP specific detectors 1 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_2",
            "start": 1056,
            "end": 1169,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_4@0",
            "content": "In the last decade deep learning based models have demonstrated success in a wide range of application areas, including Natural Language Processing (NLP) (Vaswani et al., 2017) and object recognition (He et al., 2015).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_4",
            "start": 0,
            "end": 217,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_4@1",
            "content": "These systems may be deployed in mission critical situations, where there is the requirement for a high level of robustness.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_4",
            "start": 219,
            "end": 342,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_4@2",
            "content": "However, (Szegedy et al., 2014) demonstrated that deep models have an inherent weakness: small perturbations in the input can yield significant, undesired, changes in the output from the model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_4",
            "start": 344,
            "end": 536,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_4@3",
            "content": "These input perturbations were termed adversarial examples and their generation adversarial attacks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_4",
            "start": 538,
            "end": 637,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_5@0",
            "content": "Adversarial attacks have been developed for systems operating in various domains: image systems (Serban et al., 2020;Biggio and Roli, 2017;Bhambri et al., 2019) and NLP systems (Lin et al., 2014;Samanta and Mehta, 2017;Rosenberg et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_5",
            "start": 0,
            "end": 242,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_5@1",
            "content": "The characteristics of the input can be very different between these application domains.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_5",
            "start": 244,
            "end": 332,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_5@2",
            "content": "Broadly, the nature of inputs can be described using two key attributes: static (fixed length) vs sequential and continuous vs discrete.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_5",
            "start": 334,
            "end": 469,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_5@3",
            "content": "Under this categorisation, image inputs are continuous and static, whilst NLP inputs are discrete and sequential.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_5",
            "start": 471,
            "end": 583,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_5@4",
            "content": "This work argues that due to the fundamental differences in the input and resulting adversarial perturbations in the different domains, adversarial attack behaviour can vary significantly from one domain to another.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_5",
            "start": 585,
            "end": 799,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_5@5",
            "content": "Hence, the extensive research on exploring and understanding adversarial perturbation behaviour in the continuous, static world of image systems does not necessarily transfer well to the NLP tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_5",
            "start": 801,
            "end": 997,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_6@0",
            "content": "For adversarial attack generation, a number of specific NLP attacks have been proposed that are designed for NLP task inputs (Lin et al., 2014;Samanta and Mehta, 2017;Rosenberg et al., 2017;Grosse et al., 2016;Sun et al., 2018;Cheng et al., 2018;Blohm et al., 2018;DBL, 2018;Neekhara et al., 2018;Raina et al., 2020;Jia and Liang, 2017;Minervini and Riedel, 2018;Niu and Bansal, 2018;Ribeiro et al., 2018;Iyyer et al., 2018;Zhao et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_6",
            "start": 0,
            "end": 442,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_6@1",
            "content": "However, there has been less research on developing defence schemes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_6",
            "start": 444,
            "end": 511,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_6@2",
            "content": "These defence strategies can be split into two main groups: model modification, where the model or data is altered at training time (e.g. adversarial training (Yoo and Qi, 2021)) and detection, where external systems or algorithms are applied to trained models to identify adversarial attacks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_6",
            "start": 513,
            "end": 805,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_6@3",
            "content": "As model modification approaches demand re-training of models, detection approaches are usually considered easier for implementation on deployed systems and thus are often preferred.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_6",
            "start": 807,
            "end": 988,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_6@4",
            "content": "Hence, this work investigates the portability of popular detection approaches designed for image systems to NLP systems.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_6",
            "start": 990,
            "end": 1109,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_6@5",
            "content": "Furthermore, this work introduces a specific NLP detection approach that exploits the discrete nature of the inputs for NLP systems.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_6",
            "start": 1111,
            "end": 1242,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_6@6",
            "content": "This approach out-performs standard schemes designed for image adversarial attack detection, as well as other NLP detection schemes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_6",
            "start": 1244,
            "end": 1375,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_7@0",
            "content": "The proposed NLP specific detection approach will be referred to as residue detection, as it is shown that adversarial attacks in the discrete, word sequence, space result in easily detectable residual components in the sentence embedding space.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_7",
            "start": 0,
            "end": 244,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_7@1",
            "content": "This residue can be easily detected using a simple linear classifier operating in the encoder embedding space.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_7",
            "start": 246,
            "end": 355,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_7@2",
            "content": "In addition, this work shows that even when an adversary has knowledge of the linear residual detector, they can only construct attacks at a fraction of the original strength.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_7",
            "start": 357,
            "end": 531,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_7@3",
            "content": "Hence this work argues that realistic (word level, semantically similar) adversarial perturbations at the natural language input of NLP systems leave behind easily detectable residue in the sentence embedding.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_7",
            "start": 533,
            "end": 741,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_7@4",
            "content": "Interestingly, the residue detection approach is shown to perform poorly when used to detect attacks in the image domain, supporting the hypothesis that the nature of the input has an important influence on the design of effective defence strategies.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_7",
            "start": 743,
            "end": 992,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_8@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_8",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_9@0",
            "content": "Previous work in the image domain has analysed the output of specific layers in an attempt to identify adversarial examples or adversarial subspaces.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_9",
            "start": 0,
            "end": 148,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_9@1",
            "content": "First, (Feinman et al., 2017) proposed that adversarial subspaces have a lower probability density, motivating the use of the Kernel Density (KD) metric to detect the adversarial examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_9",
            "start": 150,
            "end": 337,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_9@2",
            "content": "Nevertheless, (Ma et al., 2018) found Local Intrinsic Dimensionality (LID) was a better metric in defining the subspace for more complex data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_9",
            "start": 339,
            "end": 480,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_9@3",
            "content": "In contrast to the local subspace focused approaches of KD and LID, (Carrara et al., 2019b) showed that trajectories of hidden layer features can be used to train a LSTM network to accurately discriminate between authentic and adversarial examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_9",
            "start": 482,
            "end": 729,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_9@4",
            "content": "Out performing all previous methods, ( introduced an effective detection framework using Mahalanobis Distance Analysis (MDA), where the distance is calculated between a test sample and the closest class-conditional Gaussian distribution in the space defined by the output of the final layer of the classifier (logit space).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_9",
            "start": 731,
            "end": 1053,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_9@5",
            "content": "(Li and Li, 2016) also explored using the output of convolutional layers for image classification systems to identify statistics that distinguish adversarial samples from original samples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_9",
            "start": 1055,
            "end": 1242,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_9@6",
            "content": "They find that by performing a PCA decomposition the statistical variation in the least principal directions is the most significant and can be used to separate original and adversarial samples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_9",
            "start": 1244,
            "end": 1437,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_9@7",
            "content": "However, they argue this is ineffective as an adversary can easily suppress the tail distribution.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_9",
            "start": 1439,
            "end": 1536,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_9@8",
            "content": "Hence, (Li and Li, 2016) extract statistics from the convolutional layer output to train a cascade classifier to separate the original and adversarial samples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_9",
            "start": 1538,
            "end": 1696,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_9@9",
            "content": "Most recently, (Mao et al., 2019) avoid the use of artificially designed metrics and combine the adversarial subspace identification stage and the detecting adversaries stage into a single framework, where a parametric model adaptively learns the deep features for detecting adversaries.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_9",
            "start": 1698,
            "end": 1984,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_10@0",
            "content": "In contrast to the embedding space detection approaches, (Cohen et al., 2019) shows that influence functions combined with Nearest Neighbour distances perform comparably or better than the above standard detection approaches.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_10",
            "start": 0,
            "end": 224,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_10@1",
            "content": "Other detection approaches have explored the use of uncertainty: (Smith and Gal, 2018) argues that adversarial examples are out of distribution and do not lie on the manifold of real data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_10",
            "start": 226,
            "end": 413,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_10@2",
            "content": "Hence, a discriminative Bayesian model's epistemic (model) uncertainty should be high.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_10",
            "start": 415,
            "end": 500,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_10@3",
            "content": "Therefore, calculations of the model uncertainty are thought to be useful in detecting adversarial examples, independent of the domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_10",
            "start": 502,
            "end": 636,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_10@4",
            "content": "However, Bayesian approaches aren't always practical in implementation and thus many different approaches to approximate this uncertainty have been suggested in literature (Leibig et al., 2017;Gal, 2016;Gal and Ghahramani, 2016).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_10",
            "start": 638,
            "end": 866,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_11@0",
            "content": "There are a number of existing NLP specific detection approaches.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_11",
            "start": 0,
            "end": 64,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_11@1",
            "content": "For character level attacks, detection approaches have exploited the grammatical (Sakaguchi et al., 2017) and spelling (Mays et al., 1991;Islam and Inkpen, 2009) inconsistencies to identify and detect the adversarial samples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_11",
            "start": 66,
            "end": 290,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_11@2",
            "content": "However, these character level attacks are unlikely to be employed in practice due to the simplicity with which they can be detected.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_11",
            "start": 292,
            "end": 424,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_11@3",
            "content": "Therefore, detection approaches for the more difficult semantically similar attack samples are of greater interest, where the meaning of the textual input is maintained without compromising the spelling or grammatical integrity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_11",
            "start": 426,
            "end": 653,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_11@4",
            "content": "To tackle such word-level, semantically similar examples, designed a discriminator to classify each token representation as part of an adversarial perturbation or not, which is then used to 'correct' the perturbation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_11",
            "start": 655,
            "end": 871,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_11@5",
            "content": "Other detection approaches (Raina et al., 2020;Han et al., 2020;Minervini and Riedel, 2018) have shown some success in using perplexity to identify adversarial textual examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_11",
            "start": 873,
            "end": 1049,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_11@6",
            "content": "Most recently, (Mozes et al., 2020) achieved state of the art performance with the Frequency Guided Word Substitution (FGWS) detector, where a change in model prediction after substituting out low frequency words is revealing of adversarial samples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_11",
            "start": 1051,
            "end": 1299,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_12@0",
            "content": "Adversarial Attacks",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_12",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_13@0",
            "content": "An adversarial attack is defined as an imperceptible change to the input that causes an undesired change in the output of a system.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_13",
            "start": 0,
            "end": 130,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_13@1",
            "content": "Often, an attack is found for a specific data point, x. Consider a classifier F \u03b8, with parameters \u03b8, that predicts a class label for an input data point, x, sampled from the input distribution X .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_13",
            "start": 132,
            "end": 328,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_13@2",
            "content": "A successful adversarial attack is where a perturbation \u03b4 at the input causes the system to miss-classify,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_13",
            "start": 330,
            "end": 435,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_14@0",
            "content": "F \u03b8(x + \u03b4) \u0338 = F \u03b8(x).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_14",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_15@0",
            "content": "(1)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_15",
            "start": 0,
            "end": 2,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_16@0",
            "content": "When defining adversarial attacks, it is important consider the interpretation of an imperceptible change.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_16",
            "start": 0,
            "end": 105,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_16@1",
            "content": "Adversarial perturbations are not considered effective if they are easy to detect.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_16",
            "start": 107,
            "end": 188,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_16@2",
            "content": "Hence, the size of the perturbation must be constrained:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_16",
            "start": 190,
            "end": 245,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_17@0",
            "content": "G(x, x + \u03b4) \u2264 \u03f5,(2)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_17",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_18@0",
            "content": "where the function G() describes the form of constraint and \u03f5 is a selected threshold of imperceptibility.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_18",
            "start": 0,
            "end": 105,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_18@1",
            "content": "Typically, when considering continuous space inputs (such as images), a popular form of the constraint of Equation 2, is to limit the perturbation in the l p norm, with p \u2208 [1, \u221e), e.g. ||\u03b4|| p \u2264 \u03f5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_18",
            "start": 107,
            "end": 304,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_19@0",
            "content": "For whitebox attacks in the image domain, the dominant attack approach has proven to be Projected Gradient Descent (PGD) (Kurakin et al., 2016).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_19",
            "start": 0,
            "end": 143,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_19@1",
            "content": "The PGD approach, iteratively updates the adversarial perturbation, \u03b4, initialised as \u03b4 0 = 0.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_19",
            "start": 145,
            "end": 238,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_19@2",
            "content": "Each iterative step moves the perturbation in the direction that maximises the loss function, L, used in the training of the model,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_19",
            "start": 240,
            "end": 370,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_20@0",
            "content": "\u03b4 i+1 = clip \u03f5 (\u03b4 i + \u03b1\u2207 \u03b4 i L(x + \u03b4 i ; \u03b8)), (3)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_20",
            "start": 0,
            "end": 48,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_21@0",
            "content": "where \u03b1 is an arbitrary step-size parameter and the clipping function, clip \u03f5 , ensures the imperceptibility constraint of Equation 2 is satisfied.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_21",
            "start": 0,
            "end": 146,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_22@0",
            "content": "When considering the NLP domain, a sequential, discrete input of L words, can be explicitly represented as,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_22",
            "start": 0,
            "end": 106,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_23@0",
            "content": "x = w 1:L = w 1 , w 2 , . . . , w L\u22121 , w L ,(4)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_23",
            "start": 0,
            "end": 47,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_24@0",
            "content": "where, the discrete word tokens, w 1:L , are often mapped to a continuous, sequential word embedding (Devlin et al., 2019) space,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_24",
            "start": 0,
            "end": 128,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_25@0",
            "content": "h 1:L = h 1 , h 2 , . . . , h L\u22121 , h L . (5",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_25",
            "start": 0,
            "end": 43,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_26@0",
            "content": ")",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_26",
            "start": 0,
            "end": 0,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_27@0",
            "content": "Attacks must take place in the discrete text space,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_27",
            "start": 0,
            "end": 50,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_28@0",
            "content": "x + \u03b4 = w \u2032 1:L \u2032 = w \u2032 1 , w \u2032 2 , . . . , w \u2032 L \u2032 \u22121 , w L \u2032 ,(6)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_28",
            "start": 0,
            "end": 66,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_29@0",
            "content": "This requires a change in the interpretation of the perturbation \u03b4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_29",
            "start": 0,
            "end": 66,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_29@1",
            "content": "It is not simple to define an appropriate function G() in Equation 2for word sequences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_29",
            "start": 68,
            "end": 154,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_29@2",
            "content": "Perturbations can be measured at a character or word level.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_29",
            "start": 156,
            "end": 214,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_29@3",
            "content": "Alternatively, the perturbation could be measured in the vectorized embedding space (Equation 5), using for example l p -norm based (Goodfellow et al., 2015) metrics or cosine similarity (Carrara et al., 2019a), which have been used in the image domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_29",
            "start": 216,
            "end": 468,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_29@4",
            "content": "However, constraints in the embedding space do not necessarily achieve imperceptibility in the original word sequence space.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_29",
            "start": 470,
            "end": 593,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_30@0",
            "content": "The simplest approach is to use a variant of an editbased measurement , L e (), which counts the number of changes between the original sequence, w 1:L and the adversarial sequence w \u2032 1:L \u2032 , where a change is a swap/addition/deletion, and ensures it is smaller than a maximum number of changes, N ,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_30",
            "start": 0,
            "end": 299,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_31@0",
            "content": "L e (w 1:L , w \u2032 1:L \u2032 ) \u2264 N.(7)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_31",
            "start": 0,
            "end": 31,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_32@0",
            "content": "For the NLP adversarial attacks this work only examines word-level attacks, as these are considered more difficult to detect than character-level attacks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_32",
            "start": 0,
            "end": 153,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_32@1",
            "content": "As an example, for an input sequence of L words, a N -word substitution adversarial attack, w \u2032 1:N , applied at word positions n 1 , n 2 , . . . , n N gives the adversarial output, w \u2032",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_32",
            "start": 155,
            "end": 339,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_33@0",
            "content": "1:L \u2032 w \u2032 1:L \u2032 = w 1 , . . . , w n 1 \u22121 , w \u2032 1 , w n 1 +1 , . . . , w n N \u22121 , w \u2032 N , w n N +1 , . . . , w L . (8",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_33",
            "start": 0,
            "end": 115,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_34@0",
            "content": ")",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_34",
            "start": 0,
            "end": 0,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_35@0",
            "content": "The challenge is to select which words to replace, and what to replace them with.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_35",
            "start": 0,
            "end": 80,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_35@1",
            "content": "A simple yet effective substitution attack approach that ensures a small change in the semantic content of a sentence is to use saliency to rank the word positions, and to use word synonyms for the substitutions (Ren et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_35",
            "start": 82,
            "end": 312,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_35@2",
            "content": "This attack is termed Probability Weight Word Saliency (PWWS).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_35",
            "start": 314,
            "end": 375,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_35@3",
            "content": "The highest ranking word word can be swapped for a synonym from a preselected list of given synonyms.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_35",
            "start": 377,
            "end": 477,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_35@4",
            "content": "The next most highly ranked word is substituted in the same manner and the process is repeated till the required N words have been substituted.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_35",
            "start": 479,
            "end": 621,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_35@5",
            "content": "The above approach is limited to attacking specific word sequences and so cannot easily be generalised to universal attacks (Moosavi-Dezfooli et al., 2016), where the same perturbation is used for all inputs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_35",
            "start": 623,
            "end": 830,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_35@6",
            "content": "For this situation, a simple solution is concatenation (Wang and Bansal, 2018;Blohm et al., 2018), where for example, the same N -length sequence of words is appended to each input sequence of words, as described in (Raina et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_35",
            "start": 832,
            "end": 1068,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_35@7",
            "content": "Here,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_35",
            "start": 1070,
            "end": 1074,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_36@0",
            "content": "w \u2032 1:L \u2032 = w 1 , . . . , w L , w \u2032 1 , . . . , w \u2032 N .(9)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_36",
            "start": 0,
            "end": 57,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_37@0",
            "content": "In both the substitution attack (Equation 8) and the concatenation attack (Equation 9), the size of the attack can be measured using the number of edits, L e (w 1:L , w \u2032 1:L \u2032 ) = N .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_37",
            "start": 0,
            "end": 183,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_38@0",
            "content": "Adversarial Attack Detection",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_38",
            "start": 0,
            "end": 27,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_39@0",
            "content": "For a deployed system, the easiest approach to defend against adversarial attacks is to use a detection process to identify adversarial examples without having to modify the existing system.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_39",
            "start": 0,
            "end": 189,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_39@1",
            "content": "For the image domain Section 2 discusses many of the standard detection approaches.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_39",
            "start": 191,
            "end": 273,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_39@2",
            "content": "In this work, we select two distinct approaches that have been generally successful: uncertainty (Smith and Gal, 2018), where adversarial samples are thought to result in greater epistemic uncertainty and Mahalanobis Distance , where the Mahalanobis distance in the logit space is indicative of how out of distribution a sample is (adversarial samples are considered more out of distribution).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_39",
            "start": 275,
            "end": 667,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_39@3",
            "content": "In the NLP domain, when excluding trivial grammar and spelling based detectors, perplexity based detectors can be used (Raina et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_39",
            "start": 669,
            "end": 808,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_39@4",
            "content": "Many other NLP specific detectors Han et al., 2020;Minervini and Riedel, 2018) have been proposed, but (Mozes et al., 2020)'s FGWS detector is considered the state of art and is thus selected for comparison.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_39",
            "start": 810,
            "end": 1016,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_39@5",
            "content": "Here low frequency words in an input are substituted for higher frequency words and the change in model prediction is measured -adversarial samples are found to generally have a greater change.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_39",
            "start": 1018,
            "end": 1210,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_39@6",
            "content": "This work introduces a further NLP specific detector: residue detection, described in detail in Section 4.1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_39",
            "start": 1212,
            "end": 1319,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_40@0",
            "content": "When considering any chosen detection measure F d , a threshold \u03b2 can be selected to decide whether an input, w 1:L , is adversarial or not, where F d (w 1:L ) > \u03b2, implies that w 1:L is an adversarial sample.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_40",
            "start": 0,
            "end": 208,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_40@1",
            "content": "To assess the success of the adversarial attack detection processes, precision-recall curves are used.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_40",
            "start": 210,
            "end": 311,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_40@2",
            "content": "For the binary classification task of identifying an input as adversarially attacked or not, at a given threshold \u03b2, the precision and recall values can be computed as prec = TP/TP + FP and rec = TP/TP + FN, where TP, FP and FN are the standard true-positive, false-positive and falsenegative definitions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_40",
            "start": 313,
            "end": 617,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_40@3",
            "content": "A single point summary of precision recall-curves is given with the F 1 score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_40",
            "start": 619,
            "end": 696,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_41@0",
            "content": "Residue Detection",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_41",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_42@0",
            "content": "In this work we introduce a new NLP detection approach, residue detection, that aims to exploit the nature of the NLP input space, discrete and sequential.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_42",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_42@1",
            "content": "Here we make two hypotheses:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_42",
            "start": 156,
            "end": 183,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_43@0",
            "content": "1. Adversarial samples in an encoder embedding space result in larger components (residue) in central PCA eigenvector components than original examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_43",
            "start": 0,
            "end": 151,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_44@0",
            "content": "2. The residue is only significant (detectable) for systems operating on discrete data (e.g. NLP systems).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_44",
            "start": 0,
            "end": 105,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_45@0",
            "content": "The rationale behind these hypotheses is discussed next.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_45",
            "start": 0,
            "end": 55,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_46@0",
            "content": "Deep learning models typically consist of many layers of non-linear activation functions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_46",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_46@1",
            "content": "For example, in the NLP domain systems are usually based on layers of the Transformer architecture (Vaswani et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_46",
            "start": 90,
            "end": 211,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_46@2",
            "content": "The complete end-to-end model F \u03b8() can be treated as a two stage process, with an initial set of layers forming the encoding stage, F en () and the remaining layers forming the output stage,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_46",
            "start": 213,
            "end": 403,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_47@0",
            "content": "F cl (), i.e. F \u03b8(x) = F cl (F en (x)).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_47",
            "start": 0,
            "end": 38,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_48@0",
            "content": "If the encoding stage of the end-to-end classifier is sufficiently powerful, then the embedding space F en (x) will have compressed the useful information into very few dimensions, allowing the output stage to easily separate the data points into classes (for classification) or map the data points to a continuous value (for regression).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_48",
            "start": 0,
            "end": 337,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_48@1",
            "content": "A simple Principal Component Analysis (PCA) decomposition of this embedding space can be used to visualize the level of compression of the useful information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_48",
            "start": 339,
            "end": 496,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_48@2",
            "content": "The PCA directions can be found using the eigenvectors of the covariance matrix, C, of the data in the encoder embedding space.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_48",
            "start": 498,
            "end": 624,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_48@3",
            "content": "If {q i } d i=1 , where d is the dimension of the encoder embedding space, represent the eigenvectors of C ordered in descending order by the associated eigenvalue in magnitude, then it is expected that almost all useful information is contained within the first few principal directions, {q i } p i=1 , where p \u226a d. Hence, the output stage, F cl () will implicitly use only these useful components.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_48",
            "start": 626,
            "end": 1024,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_48@4",
            "content": "The impact of a successful adversarial perturbation, F en (x + \u03b4), is the significant change in the components in the principal eigenvector directions {q i } p i=1 , to allow fooling of the output stage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_48",
            "start": 1026,
            "end": 1228,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_48@5",
            "content": "Due to the complex nature of the encoding stage and the out of distribution nature of the adversarial perturbations, there are likely to be residual components in the non-principal {q i } d i=p+1 eigenvector directions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_48",
            "start": 1230,
            "end": 1448,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_48@6",
            "content": "These perturbations in the non-principal directions are likely to be more significant for the central eigenvectors, as the encoding stage is likely to almost entirely compress out components in the least principal eigenvector directions, {q i } d i=d \u2032 +1 , where d \u2032 \u2248 d. Hence, {q i } d \u2032 i=p+1 can be viewed as a subspace containing adversarial attack residue that can be used to identify adversarial examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_48",
            "start": 1450,
            "end": 1862,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_49@0",
            "content": "The existence of adversarial attack residue in the central PCA eigenvector directions, {q i } d \u2032 i=p+1 , suggests that in the encoder embedding space, F en (x), adversarial and original examples are linearly separable.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_49",
            "start": 0,
            "end": 218,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_49@1",
            "content": "This motivates the use of a simple linear classifier as an adversarial attack detector,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_49",
            "start": 220,
            "end": 306,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_50@0",
            "content": "P (adv|x) = \u03c3(WF en (x) + b),(10)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_50",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_51@0",
            "content": "where W and b are the parameters of the linear classifier to be learnt and \u03c3 is the sigmoid function.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_51",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_52@0",
            "content": "The above argument cannot predict how significant the residue in the central eigenvector space is likely to be.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_52",
            "start": 0,
            "end": 110,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_52@1",
            "content": "For the discrete space NLP attacks, the input perturbations are semantically small, whilst for continuous space image attacks the perturbations are explicitly small using a standard l p -norm.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_52",
            "start": 112,
            "end": 303,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_52@2",
            "content": "Hence, it is hypothesised that NLP perturbations cause larger errors to propagate through the system, resulting in more significant residue in the encoder embedding space than that for image attacks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_52",
            "start": 305,
            "end": 503,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_52@3",
            "content": "Thus, the residue technique is only likely to be a feasible detection approach for discrete text attacks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_52",
            "start": 505,
            "end": 609,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_53@0",
            "content": "The hypotheses made in this section are analysed and empirically verified in Section 5.3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_53",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_54@0",
            "content": "Experiments",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_54",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_55@0",
            "content": "Experimental Setup",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_55",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_56@0",
            "content": "Table 1 describes four NLP classification datasets: IMDB (Maas et al., 2011); Twitter (Saravia et al., 2018); AG News and DBpedia .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_56",
            "start": 0,
            "end": 130,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_56@1",
            "content": "Further, a regression dataset, Linguaskill-Business (L-Bus) (Chambers and Ingham, 2011) All NLP task models were based on the Transformer encoder architecture (Vaswani et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_56",
            "start": 132,
            "end": 313,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_56@2",
            "content": "Table 2 indicates the specific architecture used for each task and also summarises the classification and regression performance for the different tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_56",
            "start": 315,
            "end": 467,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_56@3",
            "content": "For classification tasks, the performance is measured by top 1 accuracy, whilst for the regression task (L-Bus), the performance is measured using Pearson Correlation Coefficient (PCC).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_56",
            "start": 469,
            "end": 653,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_56@4",
            "content": "(Devlin et al., 2018), ELECTRA (Clark et al., 2020)).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_56",
            "start": 655,
            "end": 707,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_57@0",
            "content": "Table 3 shows the impact of realistic adversarial attacks on the tasks: substitution (sub) attack (Equation 8), which replaces the N most salient tokens with a synonym defined by WordNet 2 , as dictated by the PWWS attack algorithm described in Section 3; or a targeted universal concatenation (con) attack (Equation 9), used for the regression task on the L-Bus dataset, seeking to maximise the average score output from the system by appending the same N words to the end of each input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_57",
            "start": 0,
            "end": 487,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_57@1",
            "content": "For classification tasks, the impact of the adversarial attack is measured using the fooling rate, the fraction of originally correctly classified points, misclassified after the attack, whilst for the regression task, the impact is measured as the average increase in the output score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_57",
            "start": 489,
            "end": 774,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_58@0",
            "content": "Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_58",
            "start": 0,
            "end": 6,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_59@0",
            "content": "Section 4.1 predicts that adversarial attacks in the discrete text space leave residue in a system's encoder embedding space that can be detected using a simple linear classifier.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_59",
            "start": 0,
            "end": 178,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_59@1",
            "content": "Hence, using the 12layer Transformer encoder's output CLS token embedding as the encoder embedding space for each dataset's trained system (Table 2), a simple linear classifier, as given in Equation 10, was trained 3 to detect adversarial examples from the adversarial attacks given for each dataset in Table 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_59",
            "start": 180,
            "end": 490,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_59@2",
            "content": "The training of the detection linear classifier was performed on the training data (Table 1) augmented with an equivalent adversarial example for each original input sample in the dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_59",
            "start": 492,
            "end": 679,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_59@3",
            "content": "Using the test data samples augmented with adversarial examples (as defined by Table 3), Table 4 compares the efficacy of the linear residue detector to other popular detection strategies 4 (from Section 4) using the best F 1 score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_59",
            "start": 681,
            "end": 912,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_59@4",
            "content": "It is evident from the high F-scores, that for most NLP tasks the linear detection approach is better than other state of the art NLP specific and ported image detection approaches.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_59",
            "start": 914,
            "end": 1094,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_59@5",
            "content": "However, an adversary may have knowledge of the detection approach and may attempt to design an attack that directly avoids detection.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_59",
            "start": 1096,
            "end": 1229,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_59@6",
            "content": "Hence, for each dataset, the attack approaches were repeated with the added constraint that any attack words that resulted in detection were rejected.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_59",
            "start": 1231,
            "end": 1380,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_59@7",
            "content": "The impact of attacks that suppress detection have been presented in Table 5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_59",
            "start": 1382,
            "end": 1458,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_59@8",
            "content": "Generally, it is shown across all NLP tasks that an adversary that attempts to avoid detection of its residue by a previously trained linear classifier, can only generate a significantly less powerful adversarial attack.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_59",
            "start": 1460,
            "end": 1679,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_60@0",
            "content": "Analysis",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_60",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_61@0",
            "content": "The aim of this section is verify that the success of the residue detector can be explained by the two main hypotheses made in Section 4.1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_61",
            "start": 0,
            "end": 138,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_61@1",
            "content": "The claim that residue is left by adversarial samples in the central PCA eigenvector components is explored first.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_61",
            "start": 140,
            "end": 253,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_61@2",
            "content": "For each NLP task a PCA projection matrix is learnt in the encoder embedding space using the original training data samples (Table 1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_61",
            "start": 255,
            "end": 388,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_61@3",
            "content": "Using the test data, the residue in the embedding space can be visualized through a plot of the average (across the data) component, \u03c1 i = 1 J J j=1 \u03c1 i,j in each eigenvector direction, q i of the original and attacked data, where",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_61",
            "start": 390,
            "end": 619,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_62@0",
            "content": "\u03c1 i,j = F en (x j ) T q i ,(11)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_62",
            "start": 0,
            "end": 30,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_63@0",
            "content": "with x j being the jth data point.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_63",
            "start": 0,
            "end": 33,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_63@1",
            "content": "Figure 1 shows an example plot for the Twitter dataset, where \u03c1 i is plotted against the eigenvalue rank, i for the original and attacked data examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_63",
            "start": 35,
            "end": 186,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_63@2",
            "content": "Residue plots for other datasets are included in Appendix A. Next, it is necessary to verify that the residue detector specifically uses the residue in the central eigenvector components to distinguish between original and adversarial samples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_63",
            "start": 188,
            "end": 430,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_63@3",
            "content": "To establish this, each encoder embedding, F en (x)'s components not within a target subspace of PCA eigenvector directions {q i } p+w i=p , are removed, i.e. we have a projected embedding, x (p) = F en (x)\u2212 i / \u2208[p,p+w) q T i F en (x)q i , where w is a window size to choose.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_63",
            "start": 432,
            "end": 707,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_63@4",
            "content": "Now, using F cl (x (p) ) and a residue detector trained using the modified embeddings, x (p) , the classifier's (F cl (x (p) )) accuracy and detector performance (measured using F1 score) can be found.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_63",
            "start": 709,
            "end": 909,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_63@5",
            "content": "Figure 2 shows the performance of the classifier (F cl (x (p) )) and the detector for different start components p, with the window size, w = 5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_63",
            "start": 911,
            "end": 1054,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_63@6",
            "content": "It is clear that the principal components hold the most important information for classifier accuracy, but, as hypothesised in Section 4.1, it is the more central eigenvector components that hold the most information useful for the residue detector, i.e. the subspace defined by {q i } 10 i=5 holds the most detectable residue from adversarial examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_63",
            "start": 1056,
            "end": 1408,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_63@7",
            "content": "The second hypothesis in Section 4.1 claims that the existence of residue in the central eigenvector components is due to the discrete nature of NLP adversarial attacks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_63",
            "start": 1410,
            "end": 1578,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_63@8",
            "content": "Hence, to analyze the impact of the discrete aspect of the attack, an artificial continuous space attack was constructed for the Twitter NLP system, where the continuous input embedding layer space (Equation 5) of the system is the space in which the attack is performed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_63",
            "start": 1580,
            "end": 1850,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_63@9",
            "content": "Using the Twitter emotion classifier, a PGD (Equation 3) attack was performed on the input embeddings for each token, where the perturbation size was limited to be \u03f5 = 0.1 in the l \u221e norm, achieving a fooling rate of 0.73.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_63",
            "start": 1852,
            "end": 2073,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_63@10",
            "content": "Note that this form of attack is artificial, as a real adversary can only modify the discrete word sequence (Equation 4).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_63",
            "start": 2075,
            "end": 2195,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_63@11",
            "content": "To compare the influence of discrete and continuous attacks on the same system, the average (across dataset) l 2 and l \u221e norms of the perturbations in the input layer embedding space were found.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_63",
            "start": 2197,
            "end": 2390,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_63@12",
            "content": "Further, a single value summary, N \u03c3 , of the residue plot (e.g. Figure 1), was calculated for each attack.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_63",
            "start": 2392,
            "end": 2498,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_63@13",
            "content": "N \u03c3 is the average difference in standard deviations between the original component mean, \u03c1 To explicitly observe the impact of the nature of data on detectors, adversarial attacks are considered in four domains: the discrete, sequential NLP input space (NLP-disc); the artificial continuous, sequential embedding space of an NLP model (NLP-cont); the continuous, static image input space (Img-cont) and a forced discretised, static image input space (Img-disc).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_63",
            "start": 2500,
            "end": 2961,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_63@14",
            "content": "For the NLP-disc and NLP-cont the same attacks as in Table 6 are used.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_63",
            "start": 2963,
            "end": 3032,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_63@15",
            "content": "For the continuous image domain (Img-cont), a VGG-16 architecture image classifier trained on CIFAR-100 (Krizhevsky et al.) image data (achieving a top-5 accuracy of 90.1%) and attacked using a standard l \u221e PGD approach (Equation 3) is used.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_63",
            "start": 3034,
            "end": 3274,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_63@16",
            "content": "For the discrete image domain (Img-disc), the CIFAR-100 images, X \u2208 Z R\u00d7R 256 were discretised using function",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_63",
            "start": 3276,
            "end": 3384,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_64@0",
            "content": "Q q : Z R\u00d7R 256 \u2192 Z R\u00d7R q",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_64",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_65@0",
            "content": ", where Z q = {0, 1 256 q\u22121 , 2 255 q\u22121 , . . . , 255}. In this work 2bit quantization was used, i.e. q = 4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_65",
            "start": 0,
            "end": 107,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_65@1",
            "content": "With this quantization, a VGG-16 architecture was trained to achieve 78.2% top-5 accuracy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_65",
            "start": 109,
            "end": 198,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_65@2",
            "content": "To perform a discrete space attack, a variant of the PWWS synonym substitution attack (Section 3) was implemented, where synonyms were interpreted as closest permitted quantisation values and N pixel values were substituted 6 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_65",
            "start": 200,
            "end": 426,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_65@3",
            "content": "For these different domains, Table 7 compares applicable detection approaches (certain NLP detection approaches are not valid outside the word sequence space) using the best F 1 score, where different attack perturbation sizes are considered (N substitutions for discrete attacks and for continuous attacks |\u03b4| \u2264 \u03f5 for perturbation \u03b4).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_65",
            "start": 428,
            "end": 762,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_65@4",
            "content": "In the discrete domains, the residue detection approach is better than all the other approaches.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_65",
            "start": 764,
            "end": 859,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_65@5",
            "content": "However, in the continuous data type domains, the Mahalanobis Distance dominates as the detection approach, with the residue detection approach performing the worst.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_65",
            "start": 861,
            "end": 1025,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_65@6",
            "content": "As predicted by the second hypothesis of Section 4.1, the lack of success of the residue detection approach is expected here -6 Code for Image Experiments: link after anonymity period.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_65",
            "start": 1027,
            "end": 1210,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_66@0",
            "content": "the residue detection approach is only successful for discrete space attacks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_66",
            "start": 0,
            "end": 76,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_67@0",
            "content": "To verify that the residue detection approach is agnostic to the type of attack, the residue detector trained on substitution attack examples was evaluated on concatenation attack examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_67",
            "start": 0,
            "end": 188,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_67@1",
            "content": "Using the Twitter dataset, a N = 3 concatenation attack was applied, achieving a fooling rate of 0.59.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_67",
            "start": 190,
            "end": 291,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_67@2",
            "content": "In this setting, the residue detector (trained on the N = 6 substitution adversarial examples) achieved a F 1 score of 0.81, which is comparable to the original score of 0.84 (from Table 4).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_67",
            "start": 293,
            "end": 482,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_67@3",
            "content": "This shows that even with different attack approaches similar forms of residue are produced, meaning a residue detector can be used even without knowledge of the type of adversarial attack.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_67",
            "start": 484,
            "end": 672,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_68@0",
            "content": "Conclusions",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_68",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_69@0",
            "content": "In recent years, deep learning systems have been deployed for a large number of tasks, ranging from the image to the natural language domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_69",
            "start": 0,
            "end": 140,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_69@1",
            "content": "However, small, imperceptible adversarial perturbations at the input, have been found to easily fool these systems, compromising their validity in high-stakes applications.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_69",
            "start": 142,
            "end": 313,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_69@2",
            "content": "Defence strategies for deep learning systems has been extensively researched, but this work has been predominantly carried out for systems operating in the image domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_69",
            "start": 315,
            "end": 483,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_69@3",
            "content": "As a result, the adversarial detection strategies developed, are inherently tuned to attacks on the continuous space of images.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_69",
            "start": 485,
            "end": 611,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_69@4",
            "content": "This work shows that these detection strategies do not necessarily transfer well to attacks on natural language processing systems.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_69",
            "start": 613,
            "end": 743,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_69@5",
            "content": "Hence, an adversarial attack detection approach is proposed that specifically exploits the discrete nature of perturbations for attacks on discrete sequential inputs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_69",
            "start": 745,
            "end": 910,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_70@0",
            "content": "The proposed approach, termed residue detection, demonstrates that imperceptible attack perturbations on natural language inputs tend to result in large perturbations in word embedding spaces, which result in distinctive residual components.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_70",
            "start": 0,
            "end": 240,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_70@1",
            "content": "These residual components can be identified using a simple linear classifier.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_70",
            "start": 242,
            "end": 318,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_70@2",
            "content": "This residue detection approach was found to out-perform both detection approaches ported from the image domain and other state of the art NLP specific detectors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_70",
            "start": 320,
            "end": 481,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_71@0",
            "content": "The key finding in this work is that the nature of the data (e.g. discrete or continuous) strongly influences the success of detection systems and hence it is important to consider the domain when designing defence strategies.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_71",
            "start": 0,
            "end": 225,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_71@1",
            "content": "8, whilst the regression dataset, L-Bus, was subject to a N -word concatenation attack as in Equation 9.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_71",
            "start": 227,
            "end": 330,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_71@2",
            "content": "For the classification tasks the impact of the adversarial attacks was measured using fooling rate, whilst for the L-Bus dataset task, the average output score from the system is given.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_71",
            "start": 332,
            "end": 516,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_71@3",
            "content": "Figure A.2 gives the encoder embedding space PCA residue plots for all the datasets not included in the main text.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_71",
            "start": 518,
            "end": 631,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_72@0",
            "content": "In the main text, two main forms of text adversarial attacks are considered: PWWS substitution attack (Ren et al., 2019) and a simple universal concatenation attack (con) (Raina et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_72",
            "start": 0,
            "end": 191,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_72@1",
            "content": "For completeness, Table A.2 presents the success of the adversarial attack detection approaches from the main text on two other popular adversarial attack approaches:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_72",
            "start": 193,
            "end": 358,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_73@0",
            "content": "\u2022 Textfooler (Jin et al., 2019) -A blackbox substitution attack where words with highest importance ranking are replaced. \u2022 BERT-based Adversarial Examples (BAE) (Garg and Ramakrishnan, 2020) -A BERT language model is used to replace and insert tokens to construct the adversarial sequence. This variant is termed BAE-R/I. These adversarial attack approaches were implemented using the TextAttack (Morris et al., 2020) Python library with no change made to the default configurations. Note that this means the perturbation sizes are measured using a Universal Sentence Encoder's cosine similarity (Cer et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_73",
            "start": 0,
            "end": 615,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_74@0",
            "content": "Table A.3 compares the impact on error sizes (using l 2 and l \u221e norms) and the residue plot metric, N \u03c3 for the original text space discrete attacks and an artificial input embedding space continuous attack.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_74",
            "start": 0,
            "end": 206,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_74@1",
            "content": "The purpose of this table is to present the results for the datasets not included in the main text in Table 6.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_74",
            "start": 208,
            "end": 317,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_75@0",
            "content": "A limitation of the residue approach proposed in this work is that it requires training on adversarial examples, which is not necessary for other NLP detectors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_75",
            "start": 0,
            "end": 159,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_75@1",
            "content": "This means there is a greater computational cost associated with this detector.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_75",
            "start": 161,
            "end": 239,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_75@2",
            "content": "Moreover, associated with this limitation is a small risk, where in process of generating creative adversarial examples to build a robust residue detector, the attack generation scheme may be so strong that it can more easily evade detection from other existing detectors already deployed in industry.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_75",
            "start": 241,
            "end": 541,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_75@3",
            "content": "There are no further ethical concerns related to this detector.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_75",
            "start": 543,
            "end": 605,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_76@0",
            "content": "UNKNOWN, None, , Adversarial texts with gradient methods, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_76",
            "start": 0,
            "end": 58,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_77@0",
            "content": "UNKNOWN, None, 1667, A study of black box adversarial attacks in computer vision, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_77",
            "start": 0,
            "end": 82,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_78@0",
            "content": "UNKNOWN, None, 2017, Wild patterns: Ten years after the rise of adversarial machine learning, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_78",
            "start": 0,
            "end": 98,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_79@0",
            "content": "UNKNOWN, None, 2018, Comparing attentionbased convolutional and recurrent neural networks: Success and limitations in machine reading comprehension, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_79",
            "start": 0,
            "end": 153,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_80@0",
            "content": "Fabio Carrara, Rudy Becarelli, Roberto Caldelli, Fabrizio Falchi, Giuseppe Amato, Adversarial examples detection in features distance spaces, 2019, Computer Vision -ECCV 2018 Workshops, Springer International Publishing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_80",
            "start": 0,
            "end": 219,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_81@0",
            "content": "UNKNOWN, None, 2019, Adversarial Examples Detection in Features Distance Spaces: Subvolume B, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_81",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_82@0",
            "content": "UNKNOWN, None, 2018, Chris Tar, Yun-Hsuan Sung, Brian Strope, and Ray Kurzweil, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_82",
            "start": 0,
            "end": 80,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_83@0",
            "content": "Lucy Chambers, Kate Ingham, The BULATS online speaking test, 2011, Research Notes, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_83",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_84@0",
            "content": "X Chen, X Liu, Y Qian, M Gales, P Woodland, Cued-rnnlm -an open-source toolkit for efficient training and evaluation of recurrent neural network language models, 2016, 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_84",
            "start": 0,
            "end": 256,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_85@0",
            "content": "UNKNOWN, None, 2018, Seq2sick: Evaluating the robustness of sequence-to-sequence models with adversarial examples, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_85",
            "start": 0,
            "end": 119,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_86@0",
            "content": "UNKNOWN, None, 2003, ELECTRA: pretraining text encoders as discriminators rather than generators. CoRR, abs, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_86",
            "start": 0,
            "end": 109,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_87@0",
            "content": "UNKNOWN, None, 2019, Detecting adversarial samples using influence functions and nearest neighbors, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_87",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_88@0",
            "content": ", Common European Framework of Reference for Languages: Learning, Teaching, 2001, Assessment, Cambridge University Press.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_88",
            "start": 0,
            "end": 120,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_89@0",
            "content": "UNKNOWN, None, 2018, BERT: pre-training of deep bidirectional transformers for language understanding, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_89",
            "start": 0,
            "end": 107,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_90@0",
            "content": "UNKNOWN, None, 2019, Bert: Pre-training of deep bidirectional transformers for language understanding, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_90",
            "start": 0,
            "end": 103,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_91@0",
            "content": "UNKNOWN, None, 2017, Detecting adversarial samples from artifacts, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_91",
            "start": 0,
            "end": 67,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_92@0",
            "content": "UNKNOWN, None, 2016, Uncertainty in deep learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_92",
            "start": 0,
            "end": 51,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_93@0",
            "content": "UNKNOWN, None, 2016, Dropout as a bayesian approximation: Representing model uncertainty in deep learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_93",
            "start": 0,
            "end": 107,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_94@0",
            "content": "UNKNOWN, None, 1970, BAE: bert-based adversarial examples for text classification. CoRR, abs, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_94",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_95@0",
            "content": "Ian Goodfellow, Jonathon Shlens, Christian Szegedy, Explaining and harnessing adversarial examples, 2015, International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_95",
            "start": 0,
            "end": 160,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_96@0",
            "content": "UNKNOWN, None, 2016, Adversarial perturbations against deep neural networks for malware classification, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_96",
            "start": 0,
            "end": 104,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_97@0",
            "content": "UNKNOWN, None, 2020, Adversarial attack and defense of structured prediction models, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_97",
            "start": 0,
            "end": 85,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_98@0",
            "content": "UNKNOWN, None, 2015, Deep residual learning for image recognition, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_98",
            "start": 0,
            "end": 71,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_99@0",
            "content": "UNKNOWN, None, 2018, Adversarial deep learning for robust detection of binary encoded malware, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_99",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_100@0",
            "content": "Aminul Islam, Diana Inkpen, Real-word spelling correction using google web it 3-grams, 2009, Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_100",
            "start": 0,
            "end": 222,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_101@0",
            "content": "Mohit Iyyer, John Wieting, Kevin Gimpel, Luke Zettlemoyer, Adversarial example generation with syntactically controlled paraphrase networks, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_101",
            "start": 0,
            "end": 302,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_102@0",
            "content": "UNKNOWN, None, 2017, Adversarial examples for evaluating reading comprehension systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_102",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_103@0",
            "content": "UNKNOWN, None, 1907, Is BERT really robust? natural language attack on text classification and entailment. CoRR, abs, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_103",
            "start": 0,
            "end": 118,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_104@0",
            "content": "UNKNOWN, None, , Cifar-100 (canadian institute for advanced research), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_104",
            "start": 0,
            "end": 71,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_105@0",
            "content": "UNKNOWN, None, 2016, Adversarial machine learning at scale. CoRR, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_105",
            "start": 0,
            "end": 66,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_106@0",
            "content": "UNKNOWN, None, 2018, A simple unified framework for detecting outof-distribution samples and adversarial attacks, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_106",
            "start": 0,
            "end": 114,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_107@0",
            "content": "Christian Leibig, M Vaneeda Allken, Philipp Ayhan, S Berens,  Wahl, Leveraging uncertainty information from deep neural networks for disease detection, 2017, Scientific Reports, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_107",
            "start": 0,
            "end": 178,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_108@0",
            "content": "UNKNOWN, None, 2018, Textbugger: Generating adversarial text against real-world applications, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_108",
            "start": 0,
            "end": 98,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_109@0",
            "content": "UNKNOWN, None, 2016, Adversarial examples detection in deep networks with convolutional filter statistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_109",
            "start": 0,
            "end": 107,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_110@0",
            "content": "UNKNOWN, None, 2014, , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_110",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_111@0",
            "content": "UNKNOWN, None, 2018, Characterizing adversarial subspaces using local intrinsic dimensionality, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_111",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_112@0",
            "content": "Andrew Maas, Raymond Daly, Peter Pham, Dan Huang, Andrew Ng, Christopher Potts, Learning word vectors for sentiment analysis, 2011, Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_112",
            "start": 0,
            "end": 250,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_113@0",
            "content": "UNKNOWN, None, 2019, Learning to characterize adversarial subspaces, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_113",
            "start": 0,
            "end": 69,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_114@0",
            "content": "Eric Mays, Fred Damerau, Robert Mercer, Context based spelling correction, 1991, Information Processing Management, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_114",
            "start": 0,
            "end": 116,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_115@0",
            "content": "UNKNOWN, None, 2018, Adversarially regularising neural NLI models to integrate logical background knowledge, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_115",
            "start": 0,
            "end": 109,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_116@0",
            "content": "UNKNOWN, None, 2016, , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_116",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_117@0",
            "content": "John Morris, Eli Lifland, Jin Yoo, Jake Grigsby, Di Jin, Yanjun Qi, TextAttack: A framework for adversarial attacks, data augmentation, and adversarial training in NLP, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_117",
            "start": 0,
            "end": 286,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_118@0",
            "content": "UNKNOWN, None, 2004, Frequency-guided word substitutions for detecting textual adversarial examples. CoRR, abs, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_118",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_119@0",
            "content": "UNKNOWN, None, 2018, Adversarial reprogramming of sequence classification neural networks, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_119",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_120@0",
            "content": "UNKNOWN, None, 2018, Adversarial oversensitivity and over-stability strategies for dialogue models, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_120",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_121@0",
            "content": "UNKNOWN, None, 2016, Crafting adversarial input sequences for recurrent neural networks, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_121",
            "start": 0,
            "end": 93,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_122@0",
            "content": "Vyas Raina, J Mark, Kate Gales,  Knill, Universal Adversarial Attacks on Spoken Language Assessment Systems, 2020, Proc. Interspeech 2020, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_122",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_123@0",
            "content": "Yihe Shuhuai Ren, Kun Deng, Wanxiang He,  Che, Generating natural language adversarial examples through probability weighted word saliency, 2019, ACL (1), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_123",
            "start": 0,
            "end": 155,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_124@0",
            "content": "Sameer Marco Tulio Ribeiro, Carlos Singh,  Guestrin, Semantically equivalent adversarial rules for debugging NLP models, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_124",
            "start": 0,
            "end": 257,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_125@0",
            "content": "UNKNOWN, None, 2017, Generic black-box end-to-end attack against rnns and other API calls based malware classifiers, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_125",
            "start": 0,
            "end": 121,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_126@0",
            "content": "UNKNOWN, None, 2017, Grammatical error correction with neural reinforcement learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_126",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_127@0",
            "content": "UNKNOWN, None, 2017, Towards crafting text adversarial samples, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_127",
            "start": 0,
            "end": 68,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_128@0",
            "content": "Elvis Saravia, Hsien-Chi Toby Liu, Yen-Hao Huang, Junlin Wu, Yi-Shin Chen, CARER: Contextualized affect representations for emotion recognition, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_128",
            "start": 0,
            "end": 280,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_129@0",
            "content": "UNKNOWN, None, 2008, Adversarial examples on object recognition: A comprehensive survey. CoRR, abs, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_129",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_130@0",
            "content": "UNKNOWN, None, 2018, Understanding measures of uncertainty for adversarial example detection, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_130",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_131@0",
            "content": "Mengying Sun, Fengyi Tang, Jinfeng Yi, Fei Wang, Jiayu Zhou, Identify susceptible locations in medical records via adversarial attacks on deep predictive models, 2018, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery amp; Data Mining, KDD '18, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_131",
            "start": 0,
            "end": 278,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_132@0",
            "content": "Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, Rob Fergus, Intriguing properties of neural networks, 2014, International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_132",
            "start": 0,
            "end": 210,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_133@0",
            "content": "UNKNOWN, None, 2017, , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_133",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_134@0",
            "content": "UNKNOWN, None, 2018, Robust machine comprehension models via adversarial training, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_134",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_135@0",
            "content": "UNKNOWN, None, 2021, Towards improving adversarial training of nlp models, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_135",
            "start": 0,
            "end": 75,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_136@0",
            "content": "Xiang Zhang, Junbo Zhao, Yann Lecun, Character-level convolutional networks for text classification, 2015, Advances in Neural Information Processing Systems, Curran Associates, Inc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_136",
            "start": 0,
            "end": 180,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_137@0",
            "content": "UNKNOWN, None, 2017, Generating natural adversarial examples, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_137",
            "start": 0,
            "end": 62,
            "label": {}
        },
        {
            "ix": "308-ARR_v1_138@0",
            "content": "UNKNOWN, None, 2019, Learning to discriminate perturbations for blocking adversarial attacks in text classification, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "308-ARR_v1_138",
            "start": 0,
            "end": 121,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "308-ARR_v1_0",
            "tgt_ix": "308-ARR_v1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_0",
            "tgt_ix": "308-ARR_v1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_1",
            "tgt_ix": "308-ARR_v1_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_1",
            "tgt_ix": "308-ARR_v1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_0",
            "tgt_ix": "308-ARR_v1_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_2",
            "tgt_ix": "308-ARR_v1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_4",
            "tgt_ix": "308-ARR_v1_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_5",
            "tgt_ix": "308-ARR_v1_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_6",
            "tgt_ix": "308-ARR_v1_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_3",
            "tgt_ix": "308-ARR_v1_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_3",
            "tgt_ix": "308-ARR_v1_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_3",
            "tgt_ix": "308-ARR_v1_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_3",
            "tgt_ix": "308-ARR_v1_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_3",
            "tgt_ix": "308-ARR_v1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_0",
            "tgt_ix": "308-ARR_v1_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_7",
            "tgt_ix": "308-ARR_v1_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_9",
            "tgt_ix": "308-ARR_v1_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_10",
            "tgt_ix": "308-ARR_v1_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_8",
            "tgt_ix": "308-ARR_v1_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_8",
            "tgt_ix": "308-ARR_v1_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_8",
            "tgt_ix": "308-ARR_v1_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_8",
            "tgt_ix": "308-ARR_v1_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_0",
            "tgt_ix": "308-ARR_v1_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_11",
            "tgt_ix": "308-ARR_v1_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_13",
            "tgt_ix": "308-ARR_v1_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_14",
            "tgt_ix": "308-ARR_v1_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_15",
            "tgt_ix": "308-ARR_v1_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_16",
            "tgt_ix": "308-ARR_v1_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_17",
            "tgt_ix": "308-ARR_v1_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_18",
            "tgt_ix": "308-ARR_v1_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_19",
            "tgt_ix": "308-ARR_v1_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_20",
            "tgt_ix": "308-ARR_v1_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_21",
            "tgt_ix": "308-ARR_v1_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_22",
            "tgt_ix": "308-ARR_v1_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_23",
            "tgt_ix": "308-ARR_v1_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_24",
            "tgt_ix": "308-ARR_v1_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_25",
            "tgt_ix": "308-ARR_v1_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_26",
            "tgt_ix": "308-ARR_v1_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_27",
            "tgt_ix": "308-ARR_v1_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_28",
            "tgt_ix": "308-ARR_v1_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_29",
            "tgt_ix": "308-ARR_v1_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_30",
            "tgt_ix": "308-ARR_v1_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_31",
            "tgt_ix": "308-ARR_v1_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_32",
            "tgt_ix": "308-ARR_v1_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_33",
            "tgt_ix": "308-ARR_v1_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_34",
            "tgt_ix": "308-ARR_v1_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_35",
            "tgt_ix": "308-ARR_v1_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_36",
            "tgt_ix": "308-ARR_v1_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_0",
            "tgt_ix": "308-ARR_v1_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_37",
            "tgt_ix": "308-ARR_v1_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_39",
            "tgt_ix": "308-ARR_v1_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_38",
            "tgt_ix": "308-ARR_v1_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_38",
            "tgt_ix": "308-ARR_v1_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_38",
            "tgt_ix": "308-ARR_v1_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_38",
            "tgt_ix": "308-ARR_v1_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_40",
            "tgt_ix": "308-ARR_v1_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_42",
            "tgt_ix": "308-ARR_v1_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_43",
            "tgt_ix": "308-ARR_v1_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_44",
            "tgt_ix": "308-ARR_v1_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_45",
            "tgt_ix": "308-ARR_v1_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_46",
            "tgt_ix": "308-ARR_v1_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_47",
            "tgt_ix": "308-ARR_v1_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_48",
            "tgt_ix": "308-ARR_v1_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_49",
            "tgt_ix": "308-ARR_v1_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_50",
            "tgt_ix": "308-ARR_v1_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_51",
            "tgt_ix": "308-ARR_v1_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_52",
            "tgt_ix": "308-ARR_v1_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_41",
            "tgt_ix": "308-ARR_v1_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_41",
            "tgt_ix": "308-ARR_v1_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_41",
            "tgt_ix": "308-ARR_v1_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_41",
            "tgt_ix": "308-ARR_v1_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_41",
            "tgt_ix": "308-ARR_v1_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_41",
            "tgt_ix": "308-ARR_v1_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_41",
            "tgt_ix": "308-ARR_v1_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_41",
            "tgt_ix": "308-ARR_v1_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_41",
            "tgt_ix": "308-ARR_v1_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_41",
            "tgt_ix": "308-ARR_v1_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_41",
            "tgt_ix": "308-ARR_v1_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_41",
            "tgt_ix": "308-ARR_v1_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_41",
            "tgt_ix": "308-ARR_v1_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_0",
            "tgt_ix": "308-ARR_v1_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_53",
            "tgt_ix": "308-ARR_v1_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_54",
            "tgt_ix": "308-ARR_v1_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_54",
            "tgt_ix": "308-ARR_v1_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_56",
            "tgt_ix": "308-ARR_v1_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_55",
            "tgt_ix": "308-ARR_v1_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_55",
            "tgt_ix": "308-ARR_v1_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_55",
            "tgt_ix": "308-ARR_v1_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_54",
            "tgt_ix": "308-ARR_v1_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_57",
            "tgt_ix": "308-ARR_v1_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_58",
            "tgt_ix": "308-ARR_v1_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_58",
            "tgt_ix": "308-ARR_v1_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_54",
            "tgt_ix": "308-ARR_v1_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_59",
            "tgt_ix": "308-ARR_v1_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_61",
            "tgt_ix": "308-ARR_v1_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_62",
            "tgt_ix": "308-ARR_v1_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_63",
            "tgt_ix": "308-ARR_v1_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_64",
            "tgt_ix": "308-ARR_v1_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_65",
            "tgt_ix": "308-ARR_v1_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_66",
            "tgt_ix": "308-ARR_v1_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_60",
            "tgt_ix": "308-ARR_v1_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_60",
            "tgt_ix": "308-ARR_v1_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_60",
            "tgt_ix": "308-ARR_v1_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_60",
            "tgt_ix": "308-ARR_v1_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_60",
            "tgt_ix": "308-ARR_v1_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_60",
            "tgt_ix": "308-ARR_v1_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_60",
            "tgt_ix": "308-ARR_v1_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_60",
            "tgt_ix": "308-ARR_v1_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_0",
            "tgt_ix": "308-ARR_v1_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_67",
            "tgt_ix": "308-ARR_v1_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_69",
            "tgt_ix": "308-ARR_v1_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_70",
            "tgt_ix": "308-ARR_v1_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_71",
            "tgt_ix": "308-ARR_v1_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_72",
            "tgt_ix": "308-ARR_v1_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_68",
            "tgt_ix": "308-ARR_v1_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_68",
            "tgt_ix": "308-ARR_v1_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_68",
            "tgt_ix": "308-ARR_v1_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_68",
            "tgt_ix": "308-ARR_v1_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_68",
            "tgt_ix": "308-ARR_v1_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_68",
            "tgt_ix": "308-ARR_v1_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_68",
            "tgt_ix": "308-ARR_v1_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_68",
            "tgt_ix": "308-ARR_v1_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_74",
            "tgt_ix": "308-ARR_v1_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "308-ARR_v1_0",
            "tgt_ix": "308-ARR_v1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_1",
            "tgt_ix": "308-ARR_v1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_2",
            "tgt_ix": "308-ARR_v1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_2",
            "tgt_ix": "308-ARR_v1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_2",
            "tgt_ix": "308-ARR_v1_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_2",
            "tgt_ix": "308-ARR_v1_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_2",
            "tgt_ix": "308-ARR_v1_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_2",
            "tgt_ix": "308-ARR_v1_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_2",
            "tgt_ix": "308-ARR_v1_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_3",
            "tgt_ix": "308-ARR_v1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_4",
            "tgt_ix": "308-ARR_v1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_4",
            "tgt_ix": "308-ARR_v1_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_4",
            "tgt_ix": "308-ARR_v1_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_4",
            "tgt_ix": "308-ARR_v1_4@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_5",
            "tgt_ix": "308-ARR_v1_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_5",
            "tgt_ix": "308-ARR_v1_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_5",
            "tgt_ix": "308-ARR_v1_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_5",
            "tgt_ix": "308-ARR_v1_5@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_5",
            "tgt_ix": "308-ARR_v1_5@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_5",
            "tgt_ix": "308-ARR_v1_5@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_6",
            "tgt_ix": "308-ARR_v1_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_6",
            "tgt_ix": "308-ARR_v1_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_6",
            "tgt_ix": "308-ARR_v1_6@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_6",
            "tgt_ix": "308-ARR_v1_6@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_6",
            "tgt_ix": "308-ARR_v1_6@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_6",
            "tgt_ix": "308-ARR_v1_6@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_6",
            "tgt_ix": "308-ARR_v1_6@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_7",
            "tgt_ix": "308-ARR_v1_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_7",
            "tgt_ix": "308-ARR_v1_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_7",
            "tgt_ix": "308-ARR_v1_7@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_7",
            "tgt_ix": "308-ARR_v1_7@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_7",
            "tgt_ix": "308-ARR_v1_7@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_8",
            "tgt_ix": "308-ARR_v1_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_9",
            "tgt_ix": "308-ARR_v1_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_9",
            "tgt_ix": "308-ARR_v1_9@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_9",
            "tgt_ix": "308-ARR_v1_9@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_9",
            "tgt_ix": "308-ARR_v1_9@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_9",
            "tgt_ix": "308-ARR_v1_9@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_9",
            "tgt_ix": "308-ARR_v1_9@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_9",
            "tgt_ix": "308-ARR_v1_9@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_9",
            "tgt_ix": "308-ARR_v1_9@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_9",
            "tgt_ix": "308-ARR_v1_9@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_9",
            "tgt_ix": "308-ARR_v1_9@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_10",
            "tgt_ix": "308-ARR_v1_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_10",
            "tgt_ix": "308-ARR_v1_10@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_10",
            "tgt_ix": "308-ARR_v1_10@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_10",
            "tgt_ix": "308-ARR_v1_10@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_10",
            "tgt_ix": "308-ARR_v1_10@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_11",
            "tgt_ix": "308-ARR_v1_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_11",
            "tgt_ix": "308-ARR_v1_11@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_11",
            "tgt_ix": "308-ARR_v1_11@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_11",
            "tgt_ix": "308-ARR_v1_11@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_11",
            "tgt_ix": "308-ARR_v1_11@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_11",
            "tgt_ix": "308-ARR_v1_11@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_11",
            "tgt_ix": "308-ARR_v1_11@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_12",
            "tgt_ix": "308-ARR_v1_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_13",
            "tgt_ix": "308-ARR_v1_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_13",
            "tgt_ix": "308-ARR_v1_13@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_13",
            "tgt_ix": "308-ARR_v1_13@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_14",
            "tgt_ix": "308-ARR_v1_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_15",
            "tgt_ix": "308-ARR_v1_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_16",
            "tgt_ix": "308-ARR_v1_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_16",
            "tgt_ix": "308-ARR_v1_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_16",
            "tgt_ix": "308-ARR_v1_16@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_17",
            "tgt_ix": "308-ARR_v1_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_18",
            "tgt_ix": "308-ARR_v1_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_18",
            "tgt_ix": "308-ARR_v1_18@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_19",
            "tgt_ix": "308-ARR_v1_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_19",
            "tgt_ix": "308-ARR_v1_19@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_19",
            "tgt_ix": "308-ARR_v1_19@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_20",
            "tgt_ix": "308-ARR_v1_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_21",
            "tgt_ix": "308-ARR_v1_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_22",
            "tgt_ix": "308-ARR_v1_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_23",
            "tgt_ix": "308-ARR_v1_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_24",
            "tgt_ix": "308-ARR_v1_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_25",
            "tgt_ix": "308-ARR_v1_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_26",
            "tgt_ix": "308-ARR_v1_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_27",
            "tgt_ix": "308-ARR_v1_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_28",
            "tgt_ix": "308-ARR_v1_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_29",
            "tgt_ix": "308-ARR_v1_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_29",
            "tgt_ix": "308-ARR_v1_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_29",
            "tgt_ix": "308-ARR_v1_29@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_29",
            "tgt_ix": "308-ARR_v1_29@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_29",
            "tgt_ix": "308-ARR_v1_29@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_30",
            "tgt_ix": "308-ARR_v1_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_31",
            "tgt_ix": "308-ARR_v1_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_32",
            "tgt_ix": "308-ARR_v1_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_32",
            "tgt_ix": "308-ARR_v1_32@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_33",
            "tgt_ix": "308-ARR_v1_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_34",
            "tgt_ix": "308-ARR_v1_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_35",
            "tgt_ix": "308-ARR_v1_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_35",
            "tgt_ix": "308-ARR_v1_35@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_35",
            "tgt_ix": "308-ARR_v1_35@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_35",
            "tgt_ix": "308-ARR_v1_35@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_35",
            "tgt_ix": "308-ARR_v1_35@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_35",
            "tgt_ix": "308-ARR_v1_35@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_35",
            "tgt_ix": "308-ARR_v1_35@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_35",
            "tgt_ix": "308-ARR_v1_35@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_36",
            "tgt_ix": "308-ARR_v1_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_37",
            "tgt_ix": "308-ARR_v1_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_38",
            "tgt_ix": "308-ARR_v1_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_39",
            "tgt_ix": "308-ARR_v1_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_39",
            "tgt_ix": "308-ARR_v1_39@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_39",
            "tgt_ix": "308-ARR_v1_39@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_39",
            "tgt_ix": "308-ARR_v1_39@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_39",
            "tgt_ix": "308-ARR_v1_39@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_39",
            "tgt_ix": "308-ARR_v1_39@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_39",
            "tgt_ix": "308-ARR_v1_39@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_40",
            "tgt_ix": "308-ARR_v1_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_40",
            "tgt_ix": "308-ARR_v1_40@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_40",
            "tgt_ix": "308-ARR_v1_40@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_40",
            "tgt_ix": "308-ARR_v1_40@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_41",
            "tgt_ix": "308-ARR_v1_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_42",
            "tgt_ix": "308-ARR_v1_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_42",
            "tgt_ix": "308-ARR_v1_42@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_43",
            "tgt_ix": "308-ARR_v1_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_44",
            "tgt_ix": "308-ARR_v1_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_45",
            "tgt_ix": "308-ARR_v1_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_46",
            "tgt_ix": "308-ARR_v1_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_46",
            "tgt_ix": "308-ARR_v1_46@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_46",
            "tgt_ix": "308-ARR_v1_46@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_47",
            "tgt_ix": "308-ARR_v1_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_48",
            "tgt_ix": "308-ARR_v1_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_48",
            "tgt_ix": "308-ARR_v1_48@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_48",
            "tgt_ix": "308-ARR_v1_48@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_48",
            "tgt_ix": "308-ARR_v1_48@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_48",
            "tgt_ix": "308-ARR_v1_48@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_48",
            "tgt_ix": "308-ARR_v1_48@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_48",
            "tgt_ix": "308-ARR_v1_48@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_49",
            "tgt_ix": "308-ARR_v1_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_49",
            "tgt_ix": "308-ARR_v1_49@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_50",
            "tgt_ix": "308-ARR_v1_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_51",
            "tgt_ix": "308-ARR_v1_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_52",
            "tgt_ix": "308-ARR_v1_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_52",
            "tgt_ix": "308-ARR_v1_52@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_52",
            "tgt_ix": "308-ARR_v1_52@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_52",
            "tgt_ix": "308-ARR_v1_52@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_53",
            "tgt_ix": "308-ARR_v1_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_54",
            "tgt_ix": "308-ARR_v1_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_55",
            "tgt_ix": "308-ARR_v1_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_56",
            "tgt_ix": "308-ARR_v1_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_56",
            "tgt_ix": "308-ARR_v1_56@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_56",
            "tgt_ix": "308-ARR_v1_56@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_56",
            "tgt_ix": "308-ARR_v1_56@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_56",
            "tgt_ix": "308-ARR_v1_56@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_57",
            "tgt_ix": "308-ARR_v1_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_57",
            "tgt_ix": "308-ARR_v1_57@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_58",
            "tgt_ix": "308-ARR_v1_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_59",
            "tgt_ix": "308-ARR_v1_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_59",
            "tgt_ix": "308-ARR_v1_59@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_59",
            "tgt_ix": "308-ARR_v1_59@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_59",
            "tgt_ix": "308-ARR_v1_59@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_59",
            "tgt_ix": "308-ARR_v1_59@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_59",
            "tgt_ix": "308-ARR_v1_59@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_59",
            "tgt_ix": "308-ARR_v1_59@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_59",
            "tgt_ix": "308-ARR_v1_59@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_59",
            "tgt_ix": "308-ARR_v1_59@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_60",
            "tgt_ix": "308-ARR_v1_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_61",
            "tgt_ix": "308-ARR_v1_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_61",
            "tgt_ix": "308-ARR_v1_61@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_61",
            "tgt_ix": "308-ARR_v1_61@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_61",
            "tgt_ix": "308-ARR_v1_61@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_62",
            "tgt_ix": "308-ARR_v1_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_63",
            "tgt_ix": "308-ARR_v1_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_63",
            "tgt_ix": "308-ARR_v1_63@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_63",
            "tgt_ix": "308-ARR_v1_63@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_63",
            "tgt_ix": "308-ARR_v1_63@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_63",
            "tgt_ix": "308-ARR_v1_63@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_63",
            "tgt_ix": "308-ARR_v1_63@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_63",
            "tgt_ix": "308-ARR_v1_63@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_63",
            "tgt_ix": "308-ARR_v1_63@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_63",
            "tgt_ix": "308-ARR_v1_63@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_63",
            "tgt_ix": "308-ARR_v1_63@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_63",
            "tgt_ix": "308-ARR_v1_63@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_63",
            "tgt_ix": "308-ARR_v1_63@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_63",
            "tgt_ix": "308-ARR_v1_63@12",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_63",
            "tgt_ix": "308-ARR_v1_63@13",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_63",
            "tgt_ix": "308-ARR_v1_63@14",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_63",
            "tgt_ix": "308-ARR_v1_63@15",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_63",
            "tgt_ix": "308-ARR_v1_63@16",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_64",
            "tgt_ix": "308-ARR_v1_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_65",
            "tgt_ix": "308-ARR_v1_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_65",
            "tgt_ix": "308-ARR_v1_65@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_65",
            "tgt_ix": "308-ARR_v1_65@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_65",
            "tgt_ix": "308-ARR_v1_65@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_65",
            "tgt_ix": "308-ARR_v1_65@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_65",
            "tgt_ix": "308-ARR_v1_65@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_65",
            "tgt_ix": "308-ARR_v1_65@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_66",
            "tgt_ix": "308-ARR_v1_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_67",
            "tgt_ix": "308-ARR_v1_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_67",
            "tgt_ix": "308-ARR_v1_67@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_67",
            "tgt_ix": "308-ARR_v1_67@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_67",
            "tgt_ix": "308-ARR_v1_67@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_68",
            "tgt_ix": "308-ARR_v1_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_69",
            "tgt_ix": "308-ARR_v1_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_69",
            "tgt_ix": "308-ARR_v1_69@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_69",
            "tgt_ix": "308-ARR_v1_69@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_69",
            "tgt_ix": "308-ARR_v1_69@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_69",
            "tgt_ix": "308-ARR_v1_69@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_69",
            "tgt_ix": "308-ARR_v1_69@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_70",
            "tgt_ix": "308-ARR_v1_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_70",
            "tgt_ix": "308-ARR_v1_70@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_70",
            "tgt_ix": "308-ARR_v1_70@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_71",
            "tgt_ix": "308-ARR_v1_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_71",
            "tgt_ix": "308-ARR_v1_71@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_71",
            "tgt_ix": "308-ARR_v1_71@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_71",
            "tgt_ix": "308-ARR_v1_71@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_72",
            "tgt_ix": "308-ARR_v1_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_72",
            "tgt_ix": "308-ARR_v1_72@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_73",
            "tgt_ix": "308-ARR_v1_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_74",
            "tgt_ix": "308-ARR_v1_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_74",
            "tgt_ix": "308-ARR_v1_74@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_75",
            "tgt_ix": "308-ARR_v1_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_75",
            "tgt_ix": "308-ARR_v1_75@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_75",
            "tgt_ix": "308-ARR_v1_75@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_75",
            "tgt_ix": "308-ARR_v1_75@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_76",
            "tgt_ix": "308-ARR_v1_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_77",
            "tgt_ix": "308-ARR_v1_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_78",
            "tgt_ix": "308-ARR_v1_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_79",
            "tgt_ix": "308-ARR_v1_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_80",
            "tgt_ix": "308-ARR_v1_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_81",
            "tgt_ix": "308-ARR_v1_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_82",
            "tgt_ix": "308-ARR_v1_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_83",
            "tgt_ix": "308-ARR_v1_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_84",
            "tgt_ix": "308-ARR_v1_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_85",
            "tgt_ix": "308-ARR_v1_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_86",
            "tgt_ix": "308-ARR_v1_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_87",
            "tgt_ix": "308-ARR_v1_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_88",
            "tgt_ix": "308-ARR_v1_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_89",
            "tgt_ix": "308-ARR_v1_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_90",
            "tgt_ix": "308-ARR_v1_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_91",
            "tgt_ix": "308-ARR_v1_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_92",
            "tgt_ix": "308-ARR_v1_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_93",
            "tgt_ix": "308-ARR_v1_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_94",
            "tgt_ix": "308-ARR_v1_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_95",
            "tgt_ix": "308-ARR_v1_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_96",
            "tgt_ix": "308-ARR_v1_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_97",
            "tgt_ix": "308-ARR_v1_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_98",
            "tgt_ix": "308-ARR_v1_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_99",
            "tgt_ix": "308-ARR_v1_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_100",
            "tgt_ix": "308-ARR_v1_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_101",
            "tgt_ix": "308-ARR_v1_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_102",
            "tgt_ix": "308-ARR_v1_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_103",
            "tgt_ix": "308-ARR_v1_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_104",
            "tgt_ix": "308-ARR_v1_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_105",
            "tgt_ix": "308-ARR_v1_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_106",
            "tgt_ix": "308-ARR_v1_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_107",
            "tgt_ix": "308-ARR_v1_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_108",
            "tgt_ix": "308-ARR_v1_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_109",
            "tgt_ix": "308-ARR_v1_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_110",
            "tgt_ix": "308-ARR_v1_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_111",
            "tgt_ix": "308-ARR_v1_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_112",
            "tgt_ix": "308-ARR_v1_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_113",
            "tgt_ix": "308-ARR_v1_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_114",
            "tgt_ix": "308-ARR_v1_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_115",
            "tgt_ix": "308-ARR_v1_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_116",
            "tgt_ix": "308-ARR_v1_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_117",
            "tgt_ix": "308-ARR_v1_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_118",
            "tgt_ix": "308-ARR_v1_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_119",
            "tgt_ix": "308-ARR_v1_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_120",
            "tgt_ix": "308-ARR_v1_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_121",
            "tgt_ix": "308-ARR_v1_121@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_122",
            "tgt_ix": "308-ARR_v1_122@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_123",
            "tgt_ix": "308-ARR_v1_123@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_124",
            "tgt_ix": "308-ARR_v1_124@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_125",
            "tgt_ix": "308-ARR_v1_125@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_126",
            "tgt_ix": "308-ARR_v1_126@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_127",
            "tgt_ix": "308-ARR_v1_127@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_128",
            "tgt_ix": "308-ARR_v1_128@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_129",
            "tgt_ix": "308-ARR_v1_129@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_130",
            "tgt_ix": "308-ARR_v1_130@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_131",
            "tgt_ix": "308-ARR_v1_131@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_132",
            "tgt_ix": "308-ARR_v1_132@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_133",
            "tgt_ix": "308-ARR_v1_133@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_134",
            "tgt_ix": "308-ARR_v1_134@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_135",
            "tgt_ix": "308-ARR_v1_135@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_136",
            "tgt_ix": "308-ARR_v1_136@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_137",
            "tgt_ix": "308-ARR_v1_137@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "308-ARR_v1_138",
            "tgt_ix": "308-ARR_v1_138@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 1417,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "position_tag_type": "from_draft",
        "doc_id": "308-ARR",
        "version": 1
    }
}