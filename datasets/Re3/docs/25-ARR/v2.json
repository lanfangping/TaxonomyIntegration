{
    "nodes": [
        {
            "ix": "25-ARR_v2_0",
            "content": "Achieving Reliable Human Assessment of Open-Domain Dialogue Systems",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_2",
            "content": "Evaluation of open-domain dialogue systems is highly challenging and development of better techniques is highlighted time and again as desperately needed. Despite substantial efforts to carry out reliable live evaluation of systems in recent competitions, annotations have been abandoned and reported as too unreliable to yield sensible results. This is a serious problem since automatic metrics are not known to provide a good indication of what may or may not be a high-quality conversation. Answering the distress call of competitions that have emphasized the urgent need for better evaluation techniques in dialogue, we present the successful development of human evaluation that is highly reliable while still remaining feasible and low cost. Self-replication experiments reveal almost perfectly repeatable results with a correlation of r = 0.969. Furthermore, due to the lack of appropriate methods of statistical significance testing, the likelihood of potential improvements to systems occurring due to chance is rarely taken into account in dialogue evaluation, and the evaluation we propose facilitates application of standard tests. Since we have developed a highly reliable evaluation method, new insights into system performance can be revealed. We therefore include a comparison of state-of-the-art models (i) with and without personas, to measure the contribution of personas to conversation quality, as well as (ii) prescribed versus freely chosen topics. Interestingly with respect to personas, results indicate that personas do not positively contribute to conversation quality as expected.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "25-ARR_v2_4",
            "content": "Evaluation of open-domain dialogue is particularly challenging and has been cited in high-profile competitions as a known open problem (Dinan et al., 2019). Challenges arise primarily from the fact that in real-world conversations there exists such a vast number of possible appropriate responses.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_5",
            "content": "Subsequently, dialogue evaluation that relies on comparison with pre-created reference dialogues incur substantial false-negative rates as many appropriate responses are unfairly penalized simply for not corresponding closely with references. In addition, evaluation faces further challenges with respect to the ability to fully take into account dialogue history. 1 In this paper, we present a new method of opendomain dialogue evaluation based on human assessment of live conversations with models that avoids the need for pre-created reference dialogues and ensures full familiarity with dialogue history, ticking two important boxes in terms of validity. Although live human evaluation of models has the advantage of being highly valid, reliability unfortunately cannot be assumed and developing methods of evaluation for language tasks that achieve high rater consistency has been challenging, often resulting in low levels of agreement between annotators (Finch and Choi, 2020;Callison-Burch et al., 2011, 2012Bojar et al., 2013Bojar et al., , 2014Mehri and Eskenazi, 2020b). Despite challenges in this respect, our proposed method provides highly reliable evaluation, achieving a correlation of r = 0.969 in selfreplication experiments. Additionally, the evaluation can be carried out cheaply and on a large scale through strict quality controlled crowd-sourcing, as well as including score standardization for fairer ranking of competing models. We make the data and code publicly available to aid future research. 2",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_6",
            "content": "Problems in Past Evaluations",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "25-ARR_v2_7",
            "content": "A common issue occurs that can potentially impact the validity of results is filtering the set of systems to be evaluated via automatic metric scores. Since metric scores are known to be a poor substitute for human assessment, this only results in the possibility that the best system according to human judges is inadvertently filtered out at this stage. For example, ConvAI2 (Dinan et al., 2019) ranked models firstly using automatic metrics before top models according to metric scores were assessed by crowd-sourced workers on Mechanical Turk, while similarly in the sixth Dialog System Technology Challenge (DSTC6) systems were filtered according to metric scores prior to human evaluation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_8",
            "content": "In terms of the live evaluation, competitions such as ConvAI2 report such evaluations as highly challenging, with many of the resulting dialogues reported to be senseless, offensive, or simply not in line with instructions and ultimately live evaluation results have been discarded.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_9",
            "content": "Despite challenges, competitions that operate in the public domain, making data and evaluation techniques available to researchers (such as ourselves) should be applauded for such efforts.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_10",
            "content": "On the other hand, competitions that (for one reason or another) do not release data and evaluation techniques into the public domain have reported relative success in terms of human evaluation. However until such methods can be accessed and independently verified through replication studies, they will unfortunately have little impact . The first Amazon Alexa Socialbot Grand Challenge required human assessors to score how coherent and engaging conversations were on a 1-5 rating scale by two distinct groups: volunteer Amazon employees (experts), and general Alexa users (crowds) (Ram et al., 2018), are reported to achieve a correlation of overall scores for the two types of human assessors at 0.93. The absolute average rating across all chatbots was reported to be 20% lower for experts compared to general users. In an additional effort to evaluate models, conversational user experience, coherence, engagement, domain coverage, topical diversity, and conversational depth were assessed (1-5 scale), with combined scores reported to correlate with those of general users at r = 0.66. In addition to methods and data not being publicly available, correlations are difficult to interpret since no detail is provided about the number of judgments on which the correlation is calculated for example.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_11",
            "content": "In addition to competitions that generally aim to include human evaluation of systems, automatic metrics are often proposed for dialogue evaluation, themselves requiring a human evaluation data set on which to evaluate the proposed metric. However, inappropriate statistics are often applied. For example, Pang et al. (2020) propose a holistic metric to automatically evaluate four distinct aspects of dialogue, and a human evaluation experiment is deployed on Mechanical Turk using a 1-5 rating scale. The mean correlation between human assessors is reported as r = 0.61. However, mean correlations are unfortunately difficult to interpret, since correlation coefficients are not additive , averages calculated in the usual way cannot be assumed to reflect central tendency, and unfortunately, the distribution of correlations is not reported (Alexander, 1990). Mehri and Eskenazi (2020b) propose USR (Un-Supervised and Reference-free), an unsupervised model that predicts the quality of dialog for a range of criteria using various rating scales: understandable (0-1 rating scale), natural (1-3), maintains context (1-3), interesting (1-3), uses knowledge (0-1); overall quality (1-5). Despite human evaluation being carried out by experts inter-annotator agreement levels varied depending on criteria being measured, ranging from as low as 0.298. Additionally, although correlations between human assessments are reported as significant at p < 0.01, despite such statistics often being reported for correlations, they are unfortunately not very meaningful in terms of their impact on correlation interpretation and can be somewhat misleading. Contrary to common expectations, even small effect sizes (low r) can produce very low p-values (strong significance) in such tests. Aiming to achieve a significant correlation is an extremely low bar to reach in terms of consistency, since a low p-value in this case simply rejects the null hypothesis that the correlation is zero.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_12",
            "content": "In addition to the above issues, human evaluation of dialogue systems rarely take into account the fact that differences in performance can occur simply by chance. The method of human evaluation we propose provides a means of applying standard tests for statistical significance to avoid concluding differences that are highly likely to have occurred simply by chance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_13",
            "content": "Crowd-sourcing Reliable Human",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "25-ARR_v2_14",
            "content": "Assessment of Open-Domain Dialogue",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_15",
            "content": "Crowd-sourcing with highly accurate quality control provides a potential mechanism to ensure the three most important criteria that makes an evaluation meaningful while still remaining feasible: validity, reliability and scalability. Subsequently, we ask crowd-workers to carry out live text-based chat with models prior to that same worker also rating the quality of the immediately preceding conversation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_16",
            "content": "Human Ratings of Dialogue Quality",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "25-ARR_v2_17",
            "content": "A continuous (0-100) rating scale is employed with three main motivation points (Graham et al., 2013;Novikova et al., 2018;Li et al., 2019;Santhanam and Shaikh, 2019;Barrault et al., 2020;Howcroft et al., 2020). Firstly, continuous scales reduce potential bias when comparing the performance of competing models by enabling score standardization. The score distribution of each human assessor is standardized according to overall mean and standard deviation of all ratings provided by that assessor, thus removing any adverse effects of those employing overly harsh (or indeed lenient) scoring strategies.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_18",
            "content": "Secondly, the 0-100 rating scale allows standard significance tests to score distributions of models to help determine which models significantly outperform others. Thirdly, and possibly most importantly, a continuous rating scale facilitates highly accurate quality control of crowd-sourced workers so that the evaluation can scale while still maintaining validity at a low cost. Each human assessor is firstly asked to carry out a live conversation with a randomly selected model, comprised of a minimum of 10 conversational inputs, before rating the quality of the conversation that just took place under a number of criteria shown in Figure 1. Note that the measurement criteria we employed are not immutable and we encourage to extend or adjust the criteria for future studies as necessary.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_19",
            "content": "A continuous rating scale is advantageous for several reasons but employment of such a scale raises the question of how it should be labeled. In evaluation of language tasks, adjectival scale labels, such as poor, low, medium, high, perfect/ okay, good, excellent, and so on, are often employed despite their likely contribution to annotator inconsistency (Loukina et al., 2020;Sorodoc et al., 2017). This is despite evidence of adjectival scale labels being problematic in terms of bias resulting from positively and negatively worded items not being true opposites of one another, and items intended to have neutral intensity in fact proving to have Robotic: It was obvious that I was talking to a chatbot as opposed to another human user. Interesting: The conversation with the chatbot was interesting. Fun: The conversation with the chatbot was fun/enjoyable. Consistent: The chatbot was consistent throughout the conversation. Fluent: The chatbot's English was fluent and natural throughout the conversation. Repetitive: I felt that the chatbot kept being repetitive during the conversation. Topic: The chatbot stays on topic. specific conceptual meanings. Alexandrov (2010) provides a summary of issues associated with adjectival labels.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_20",
            "content": "To avoid any such causes of inconsistency, we structure each rating as a simple Likert declarative statement and ask human assessors to rate the degree to which they agree with each of these statement, making it possible to keep the rating scale constant while only changing the statement for each measurement criteria. We ask judges to rate each conversation under the seven aforementioned measurement criteria (Figure 1) along with a continuous rating scale labeled only at each extreme with strongly disagree (left); strongly agree (right).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_21",
            "content": "Quality Controlling the Crowd for",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "25-ARR_v2_22",
            "content": "Open-Domain Dialogue",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_23",
            "content": "We structure Human Intelligence Tasks (HITs) so that a sufficiently rich score distribution is collected from each individual worker who participated, asking each to hold six conversations, comprised of a shuffled arrangement of five dialogue models and a single quality control model. Many approaches to quality controlling the crowd employ gold-standard items as quality checks (Liu et al., 2013;Lasecki et al., 2014). This approach is however highly likely to allow low quality data to pollute the resulting evaluation, since any worker willing to assign high scores to all items will undeservedly pass this check. 3 The approach also runs in contrast to our aim of the same individual who took part in a live conversation to also assess its quality, as it relies on the use of pre-created gold standard conversations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_24",
            "content": "Our quality control approach overcomes these challenges by deploying models in live conversations that have known distinct performance levels instead of asking workers to assess the quality of pre-existing known high quality conversations. Within a HIT, the five models m can produce some quality level of conversation and the model l produces known lower quality dialogues (lower than the five models). For a single worker who takes part in conversations with m and l, we then check how consistently the worker rated the conversations of l lower than m. This results in a quality control mechanism that does not ask workers to be consistent with other workers or to correctly rate gold standard dialogues but only assesses worker consistency by how consistently they distinguish between known distinct performance models and only with respect to their own conversation ratings.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_25",
            "content": "From a practical standpoint, creating a low performance model, l, is additionally far less challenging and costly than pre-creating a known set of high quality dialogues, and degraded models operate fully automatically. Low quality models produce outputs via generation of random responses with meaning distortion also applied.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_26",
            "content": "For random response degradation: Low quality responses are generated by random sampling responses from training set dialogues with the intention of disregarding any previous input from the user, so responses from the model are likely to be perceived as low quality since they have low relevance. To reduce the quality of conversations further, we apply meaning distortion: each response, r, is altered to distort its meaning by randomly selecting a sequence of words within that response and replacing it with a sequence of words sampled from a distinct training set dialogue, with the length of the replaced word sequence being determined by the number of words in r. The specific details are provided in Appendix A.1, and Figure 4 in Appendix A.4 gives a typical example.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_27",
            "content": "Hits subsequently consist of a total of six dialogues comprised of five genuine models and a single quality control model that generates meaning distorted and random responses. Crowd-sourced workers converse with each model before rating conversation quality (model order is shuffled and blind). Statistical significance tests are then applied to score distributions of workers for the ratings they attributed to ordinary models, m, relative to the low quality model, l. The resulting p-value is then employed as a means of rating worker consistency, and any worker with p >= 0.05 shows no significant difference between low and ordinary model quality and is filtered out.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_28",
            "content": "Calculating System-Level Scores",
            "ntype": "title",
            "meta": {
                "section": "3.3"
            }
        },
        {
            "ix": "25-ARR_v2_29",
            "content": "Scores are collected from workers who rate models on a 0-100 rating scale, and we refer to these scores as raw scores. Scores for negative attributes, i.e. robotic and repetitive, are then reversed for ease of further comparison, 100 \u2212 the original rating. A distribution of scores is extracted for each worker and raw scores are standardized according to each worker's mean and standard deviation, in order to iron out any differences in worker scoring strategy.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_30",
            "content": "Average standardized scores for each criteria are calculated, and an overall score is calculated as the average of all measurement criteria.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_31",
            "content": "Meta-Evaluation",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "25-ARR_v2_32",
            "content": "In order to assess the reliability of the proposed method of human evaluation, we carry out a metaevaluation in which we firstly examine individual human assessor consistency, before conducting a self-replication experiment. A number of models are required to function as a sample set of test systems, and for this purpose we employ available pre-trained models from ParlAI: 4 Poly-Encoder Transformer (Humeau et al., 2019), Bi-Encoder Transformer (Dinan et al., 2018), Sequence to Sequence (Sutskever et al., 2014), Key-Value Memory Networks (Miller et al., 2016), and a LSTMbased Model (Hochreiter and Schmidhuber, 1997). Within the evaluation setting of ConvAI2, each model is with a persona consisting of approximately five textual statements to emulate a personality. However, to increase the number of models and to provide an interesting comparison, we additionally include a version of each of the above models without any persona, resulting in 10 competing models.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_33",
            "content": "Hits were posted on the crowd-sourcing platform Amazon Mechanical Turk. 5 Firstly, and in order to evaluate the open-domain models in as realistic a setting as possible, we allow workers to choose the topic of conversation and input their chosen topic in a text field. The open nature of conversations should be noted however as something that influences the difficulty of producing consistent results Table 1: Numbers of workers who took part in human evaluation of models, average time taken per dialogue in minutes (min), and total number of dialogues assessed before and after quality control in which workers freely chose the topic (Free run 1); precisely the same experiment set-up was repeated (Free run 2); where the topic was prescribed via an ice-breaker statement (Ice-breaker) selected directly from the persona of the model.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_34",
            "content": "in our self-replication experiment. The fact that we allow human assessors to freely choose the topic of conversation means that differences in ratings could result from legitimate differences in performance when different topics are chosen by human assessors. We nonetheless test our evaluation allowing the user to choose the topic as this is part of our core aim for developing evaluation of dialogue truly in the open domain.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_35",
            "content": "Besides choosing a topic, we additionally asked workers to input their opinion of the topic they chose to discuss with models, categorizing the topic as either liked, ambivalent about it, or disliked. For example, if the topic they chose to discuss was dogs, we were curious to know if this was motivated by the fact that the worker liked or disliked dogs or indeed that they had chosen to discuss something they had no particular feeling about. Table 2 shows subsequent proportions (%) of workers, and the detailed instructions are introduced in Figure 5 in Appendix A.4. Perhaps unsurprisingly, the vast majority of workers chose to discuss something they liked (84% for workers who passed quality control). Nonetheless 7% of good workers were ambivalent about the topic they chose and 9% chose a topic they reported as disliking.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_36",
            "content": "Free Table 1 shows the number of workers who participated in the initial data collection run who freely chose the topic of conversation with models (Free run 1), amounting to 1,525 dialogues \u00d7 7 criteria = 10,675 human ratings. The details of payment to each worker and the total experiment cost are provided in Appendix A.2. Table 1 also shows the proportion of workers who passed quality checks, numbers of dialogues assessed in total before and after quality filtering, as well as the average time taken for workers to complete a hit and average time taken to assess dialogues. As mentioned previously, we carry out a second data collection run with precisely the same settings (Free run 2) to measure the reliability of results and Table 1 shows equivalent statistics with respect to Free run 2 in which a total of 1,480 dialogues \u00d7 7 ratings = 10,360 human ratings were collected in total.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_37",
            "content": "Human Assessor Consistency",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "25-ARR_v2_38",
            "content": "Although the overall aim of our evaluation is to produce reliable results at the system level, which we test later in Section 4.2, we firstly examine ratings of workers at the level of individual dialogue ratings. Technically speaking, the most meaningful reliability measures for continuous ratings scales test consistency of aggregate (system-level) results because although a high level of random error is expected in individual continuous rating scale scores, when aggregates are calculated for large samples of ratings, positive and negative error that is truly random effectively cancels itself out, and does not negatively impact consistency. In other words, the rating scale we employ does not rely on consistency on the level of individual ratings. We nonetheless examine individual rater consistency, since it is the standard approach, but keep in mind that results in this part of our meta-evaluation are not crucial when testing reliability for an evaluation carried out via a continuous rating scale where consistency in overall system-level results are more important.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_39",
            "content": "The distribution of Pearson correlation coefficients for pairs of workers who assessed the same hit is depicted in Figure 2.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_40",
            "content": "As can be seen from Figure 2, the likelihood of agreement between pairs of workers who failed quality control is close to random as the distribution is approaching uniformity across almost the range of possible coefficients. In contrast, for pairs of workers who pass quality control, the peak of agreement is between an r of 0.6 and 0.7, showing high agreement in general between such annotator pairs. Some of the observed disagreement is likely to be the result of legitimate differences between scores of two workers who chose distinct topics to discuss with the same model however, an unavoidable source of inconsistency when testing models with respect to the open domain. Interestingly, in 5% of dialogues, worker pairs assigned the same hit happened to both freely choose an identical topic to discuss with the same model. Furthermore, remaining disagreement at the level of individual ratings might not be problematic at the level of overall scores in relation to aggregation of ratings collected on a continuous rating scale.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_41",
            "content": "System-level Consistency",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "25-ARR_v2_42",
            "content": "Table 3 shows results of the system-level evaluation resulting from the initial data collection run on Mechanical Turk (Free run 1), where competing models are ordered by overall highest average zscore. 6 Table 3 4: Average standardized scores for models in human evaluation where workers were prescribed an ice-breaker topic of conversation sampled from the persona of the model; the correlation (r) between these scores and Free run 1 in Table 3; models are consistent with Table 3; n is number of ratings; models without p did not have a persona (ice-breaker statement was subsequently unknown to these models). , where a colored cell indicates that the system in that row significantly outperformed the system in that column. Models are consistent with Table 3.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_43",
            "content": "A B A p C C p B p D D p E p E A B A p C C p B p D D p E p E 0.00 0.05 0.10",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_44",
            "content": "the board, consistency is very high, exceeding a correlation of 0.94 in almost all cases with the exception of robotic which nonetheless achieved a correlation of over 0.7. Besides individual criteria, of crucial importance is the consistency of overall results, as this is the means by which models would ordinarily be ranked in terms of overall performance. As can be observed from Table 3, the correlation reached in terms of overall scores for systems is 0.969, which is very close to a perfect correlation, showing extremely high levels of reliability for the evaluation, evidence that the approach overcomes substantial challenges with respect to annotator consistency and expected difficulties with respect to evaluating models in the open domain, where assessors are legitimately free to choose distinct topics of conversation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_45",
            "content": "In any empirical evaluation, statistical significance tests should be applied to take into account the fact that small differences in scores between systems can occur simply by chance. We provide pairwise significance test results in Figure 3, where we apply standard significance test, Wilcoxon ranksum to rating distributions for each pair of competing models for each data collection run, and corresponding results for run 2 in Figure 6 in Appendix A.4. Results showed a very high proportion of identical conclusions, 84%, drawn from pairwise significance tests applied to data from the two data collection runs at p < 0.1. Results for p < 0.05, additionally showed high correspondence between pairwise significance test conclusions, only marginally lower with 82% of the same conclusions being drawn for pairs of models in the two data collection runs. We additionally provide correlations between measurement criteria and overall scores in Table 8 of Appendix A.4.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_46",
            "content": "Persona Contribution to System Performance",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "25-ARR_v2_47",
            "content": "Since we have verified the reliability of the human evaluation, we take a closer look at the results and investigate dialogue quality when models employ a persona. Results in Table 3 reveal that perhaps unexpectedly in general are either rated more favorably by human assessors when they carry out dialogues without a persona or a tie occurs between models with and without a persona.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_48",
            "content": "Evaluating with Prescribed Topics",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "25-ARR_v2_49",
            "content": "In contrast to the initial experiment in which workers were permitted to choose the topic of conversation, we further investigate the performance of models in a slightly easier setting where the topic under discussion is known to the model, by selecting a statement from its persona, which we refer to as an ice-breaker topic statement. An ice-breaker topic statement is then provided to human assessors at the beginning of each conversation, and the assessor is instructed to talk about this topic with the model. We therefore provide the topic of conversation to workers in the form of an ice-breaker topic statement, corresponding to a randomly selected persona statement belonging to the agent. Again, we run this experiment on MTurk, this time contrasting results for our initial data collection run where workers freely chose a topic with one in which workers were instructed to talk about the ice-breaker statement with models. Numbers of workers who participated in the Icebreaker run are provided in Table 1, while a breakdown of results for each model and overall average scores are shown in Table 4 as well as the correlation between scores for systems when a topic is freely chosen. Interestingly, in terms of absolute differences in raw scores, the best performing model achieves higher fluency, consistency and is deemed less repetitive when evaluated in icebreaker conversations compared those with freely chosen topics. Raw average scores for models in the Ice-breaker run are additionally provided in Table 11 in Appendix A.4. Relatively speaking, in terms of system rankings, no meaningful difference in relative performance is observed when models are tested in a scenario where the worker chooses a topic and when one is prescribed with an ice-breaker statement, as can be seen from the strong correlation between scores for models in Free run 1 and Ice-breaker evaluation as shown in In this experiment, we employed four prevailing word-overlap-based metrics as described in the following, whose scores are computed on the Con-vAI2 test set.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_50",
            "content": "BLEU BLEU (Bilingual Evaluation Understudy) evaluate the quality of a system output by computing the n-gram precision according to humangenerated references (Papineni et al., 2002). It also uses the brevity penalty to penalize short outputs.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_51",
            "content": "ROUGE-L ROUGE (Recall-Oriented Understudy for Gisting Evaluation) is a recall-adaptation of BLEU, whose wildly-applied variant is ROUGE-L (Lin and Hovy, 2003). It computes the precision and recall using longest common subsequence (LSC) instead of n-gram, and the F1 score of precision and recall is reported as the final score.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_52",
            "content": "METEOR METEOR (Metric for Evaluation of Translation with Explicit ORdering) was firstly proposed to overcome flaws of BLEU, like no usage of recall (Denkowski and Lavie, 2011). It computes the unigram precision and recall, and have a different mechanism of choosing the brevity penalty.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_53",
            "content": "GLEU GLEU (Google-BLEU) is a variety of BLEU (Wu et al., 2016) which computes the ngram precision and recall instead of the standalone precision. The minimum of precision and recall is reported as the final GLEU score.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_54",
            "content": "Metric r",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_55",
            "content": "BLEU-4 \u22120.883 BLEU-1 \u22120.707 ROUGE-L \u22120.799 METEOR \u22120.321 GLEU \u22120.816",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_56",
            "content": "Reference-free Metrics",
            "ntype": "title",
            "meta": {
                "section": "7.2"
            }
        },
        {
            "ix": "25-ARR_v2_57",
            "content": "The following introduces two reference-free automatic metrics we employed: FED and USR. Their scores are computed using the conversations collected in our experiment.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_58",
            "content": "FED FED (Fine-grained Evaluation of Dialog) is a pre-trained-model based metric to evaluate a textual conversation history (Mehri and Eskenazi, 2020a). Given a conversation c, a pre-trained model m, two predefined responses r p and r n (p = positive and n = negative), the FED score is L m (r p |c) \u2212 L m (r n |c) where L m (r|c) computes the likelihood that the model m will generate a response r to a conversation c. We employed medium and large DialoGPT (Zhang et al., 2020) as FED scorers, where the full list of predefined positive and negative responses are available in Table 7 in Appendix.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_59",
            "content": "USR USR (an UnSupervised Reference-free metric) uses the pre-trained model RoBERTa (Liu et al., 2019) to assess the quality of a conversation (Mehri and Eskenazi, 2020b). It consists of three sub-metrics: USR-MLM is to evaluate the understandability and naturalness, USR-DR(c) and USR-DR(f) are to evaluate the interestingness and consistency. The sub-metric scores then produce an overall score through a regression model.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_60",
            "content": "Correlation between Automatic Metrics and Human Evaluation",
            "ntype": "title",
            "meta": {
                "section": "7.3"
            }
        },
        {
            "ix": "25-ARR_v2_61",
            "content": "We compute the correlation between commonly applied automatic metrics and our human evaluation methods, including word-overlap-based metrics and reference-free metrics, as shown in Tables 5 and 6 respectively. As can be seen from Table 5, unfortunately no word-overlap metric achieves a strong positive correlation with human assessment, confirming once again that the invalidity of system rankings currently produced by automatic metric scores.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_62",
            "content": "In terms of reference-free metrics, results correspond better and are more encouraging. FED has the ability of distinguishing \"repetitive\" models, but for other criteria, it correlates weakly or even negatively with human. Meanwhile, despite USR only correlating marginally with human in terms of consistency and topic loyalty, USR-DR(f) correlates closest to human among the three sub-metrics, while it performs best on evaluating consistency and topic loyalty.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_63",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "8"
            }
        },
        {
            "ix": "25-ARR_v2_64",
            "content": "Development of reliable evaluation of open-domain dialogue has been highlighted as a known openproblem. We overcome previous challenges and provide a new human evaluation methodology shown as highly consistent, with results for models correlating at r = 0.969 in two separate data collection runs. Our evaluation has the advantage of highly accurate quality control of crowd-sourcing, differences in scoring strategies to be ironed out via score standardization, applicability of standard significance testing while increasing the reliability of results.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "25-ARR_v2_65",
            "content": "Alexander Ralph, A note on averaging correlations, 1990, Bulletin of the Psychonomic Society, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "Alexander Ralph"
                ],
                "title": "A note on averaging correlations",
                "pub_date": "1990",
                "pub_title": "Bulletin of the Psychonomic Society",
                "pub": null
            }
        },
        {
            "ix": "25-ARR_v2_66",
            "content": "Aliosha Alexandrov, Characteristics of singleitem measures in likert scale format, 2010, The Electronic Journal of Business Research Methods, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Aliosha Alexandrov"
                ],
                "title": "Characteristics of singleitem measures in likert scale format",
                "pub_date": "2010",
                "pub_title": "The Electronic Journal of Business Research Methods",
                "pub": null
            }
        },
        {
            "ix": "25-ARR_v2_67",
            "content": "UNKNOWN, None, , Santanu Pal, Matt Post, and Marcos Zampieri. 2020. Findings of the 2020 conference on machine translation (wmt20). In Proceedings of the Fifth Conference on Machine Translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Santanu Pal, Matt Post, and Marcos Zampieri. 2020. Findings of the 2020 conference on machine translation (wmt20). In Proceedings of the Fifth Conference on Machine Translation",
                "pub": null
            }
        },
        {
            "ix": "25-ARR_v2_68",
            "content": "Ondrej Bojar, Christian Buck, Christian Federmann, Barry Haddow, Philipp Koehn, Johannes Leveling, Christof Monz, Pavel Pecina, Matt Post, Herve Saint-Amand, Radu Soricut, Lucia Specia, Ale\u0161 Tamchyna, Findings of the 2014 workshop on statistical machine translation, 2014, Proceedings of the Ninth Workshop on Statistical Machine Translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Ondrej Bojar",
                    "Christian Buck",
                    "Christian Federmann",
                    "Barry Haddow",
                    "Philipp Koehn",
                    "Johannes Leveling",
                    "Christof Monz",
                    "Pavel Pecina",
                    "Matt Post",
                    "Herve Saint-Amand",
                    "Radu Soricut",
                    "Lucia Specia",
                    "Ale\u0161 Tamchyna"
                ],
                "title": "Findings of the 2014 workshop on statistical machine translation",
                "pub_date": "2014",
                "pub_title": "Proceedings of the Ninth Workshop on Statistical Machine Translation",
                "pub": null
            }
        },
        {
            "ix": "25-ARR_v2_69",
            "content": "Ond\u0159ej Bojar, Christian Buck, Chris Callison-Burch, Christian Federmann, Barry Haddow, Philipp Koehn, Christof Monz, Matt Post, Radu Soricut, Lucia Specia, Findings of the 2013 Workshop on Statistical Machine Translation, 2013, Proceedings of the Eighth Workshop on Statistical Machine Translation, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Ond\u0159ej Bojar",
                    "Christian Buck",
                    "Chris Callison-Burch",
                    "Christian Federmann",
                    "Barry Haddow",
                    "Philipp Koehn",
                    "Christof Monz",
                    "Matt Post",
                    "Radu Soricut",
                    "Lucia Specia"
                ],
                "title": "Findings of the 2013 Workshop on Statistical Machine Translation",
                "pub_date": "2013",
                "pub_title": "Proceedings of the Eighth Workshop on Statistical Machine Translation",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "25-ARR_v2_70",
            "content": "Chris Callison-Burch, Philipp Koehn, Christof Monz, Matt Post, Radu Soricut, Lucia Specia, Findings of the 2012 workshop on statistical machine translation, 2012, Proceedings of the Seventh Workshop on Statistical Machine Translation, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "Chris Callison-Burch",
                    "Philipp Koehn",
                    "Christof Monz",
                    "Matt Post",
                    "Radu Soricut",
                    "Lucia Specia"
                ],
                "title": "Findings of the 2012 workshop on statistical machine translation",
                "pub_date": "2012",
                "pub_title": "Proceedings of the Seventh Workshop on Statistical Machine Translation",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "25-ARR_v2_71",
            "content": "Chris Callison-Burch, Philipp Koehn, Christof Monz, Omar Zaidan, Findings of the 2011 workshop on statistical machine translation, 2011, Proceedings of the Sixth Workshop on Statistical Machine Translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "Chris Callison-Burch",
                    "Philipp Koehn",
                    "Christof Monz",
                    "Omar Zaidan"
                ],
                "title": "Findings of the 2011 workshop on statistical machine translation",
                "pub_date": "2011",
                "pub_title": "Proceedings of the Sixth Workshop on Statistical Machine Translation",
                "pub": null
            }
        },
        {
            "ix": "25-ARR_v2_72",
            "content": "M Denkowski, A Lavie, Meteor 1.3: Automatic metric for reliable optimization and evaluation of machine translation systems, 2011, Proceedings of the Sixth Workshop on Statistical Machine Translation, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "M Denkowski",
                    "A Lavie"
                ],
                "title": "Meteor 1.3: Automatic metric for reliable optimization and evaluation of machine translation systems",
                "pub_date": "2011",
                "pub_title": "Proceedings of the Sixth Workshop on Statistical Machine Translation",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "25-ARR_v2_73",
            "content": "UNKNOWN, None, 2019, , .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": null,
                "pub": null
            }
        },
        {
            "ix": "25-ARR_v2_74",
            "content": "UNKNOWN, None, , , .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": null,
                "pub": null
            }
        },
        {
            "ix": "25-ARR_v2_75",
            "content": "UNKNOWN, None, 2018, Wizard of wikipedia: Knowledge-powered conversational agents, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Wizard of wikipedia: Knowledge-powered conversational agents",
                "pub": "CoRR"
            }
        },
        {
            "ix": "25-ARR_v2_76",
            "content": "Sarah Finch, Jinho Choi, Towards unified dialogue system evaluation: A comprehensive analysis of current evaluation protocols, 2020, Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Sarah Finch",
                    "Jinho Choi"
                ],
                "title": "Towards unified dialogue system evaluation: A comprehensive analysis of current evaluation protocols",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue",
                "pub": null
            }
        },
        {
            "ix": "25-ARR_v2_77",
            "content": "Yvette Graham, Timothy Baldwin, Alistair Moffat, Justin Zobel, Crowd-sourcing of human judgments of machine translation fluency, 2013, Proceedings of the Australasian Language Technology Association Workshop 2013 (ALTA 2013), .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Yvette Graham",
                    "Timothy Baldwin",
                    "Alistair Moffat",
                    "Justin Zobel"
                ],
                "title": "Crowd-sourcing of human judgments of machine translation fluency",
                "pub_date": "2013",
                "pub_title": "Proceedings of the Australasian Language Technology Association Workshop 2013 (ALTA 2013)",
                "pub": null
            }
        },
        {
            "ix": "25-ARR_v2_78",
            "content": "Sepp Hochreiter, J\u00fcrgen Schmidhuber, Long short-term memory, 1997, Neural Comput, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    "Sepp Hochreiter",
                    "J\u00fcrgen Schmidhuber"
                ],
                "title": "Long short-term memory",
                "pub_date": "1997",
                "pub_title": "Neural Comput",
                "pub": null
            }
        },
        {
            "ix": "25-ARR_v2_79",
            "content": "David Howcroft, Anya Belz, Miruna-Adriana Clinciu, Dimitra Gkatzia, A Sadid, Saad Hasan, Simon Mahamood,  Mille, Sashank Emiel Van Miltenburg, Verena Santhanam,  Rieser, Twenty years of confusion in human evaluation: NLG needs evaluation sheets and standardised definitions, 2020, Proceedings of the 13th International Conference on Natural Language Generation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "David Howcroft",
                    "Anya Belz",
                    "Miruna-Adriana Clinciu",
                    "Dimitra Gkatzia",
                    "A Sadid",
                    "Saad Hasan",
                    "Simon Mahamood",
                    " Mille",
                    "Sashank Emiel Van Miltenburg",
                    "Verena Santhanam",
                    " Rieser"
                ],
                "title": "Twenty years of confusion in human evaluation: NLG needs evaluation sheets and standardised definitions",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 13th International Conference on Natural Language Generation",
                "pub": null
            }
        },
        {
            "ix": "25-ARR_v2_80",
            "content": "UNKNOWN, None, 1905, Poly-encoders: Transformer architectures and pre-training strategies for fast and accurate multi-sentence scoring, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": null,
                "title": null,
                "pub_date": "1905",
                "pub_title": "Poly-encoders: Transformer architectures and pre-training strategies for fast and accurate multi-sentence scoring",
                "pub": null
            }
        },
        {
            "ix": "25-ARR_v2_81",
            "content": "Walter Lasecki, Jaime Teevan, Ece Kamar, Information extraction and manipulation threats in crowd-powered systems, 2014, Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work & Social Computing, CSCW '14, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "Walter Lasecki",
                    "Jaime Teevan",
                    "Ece Kamar"
                ],
                "title": "Information extraction and manipulation threats in crowd-powered systems",
                "pub_date": "2014",
                "pub_title": "Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work & Social Computing, CSCW '14",
                "pub": null
            }
        },
        {
            "ix": "25-ARR_v2_82",
            "content": "UNKNOWN, None, 2019, Acute-eval: Improved dialogue evaluation with optimized questions and multi-turn comparisons, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Acute-eval: Improved dialogue evaluation with optimized questions and multi-turn comparisons",
                "pub": null
            }
        },
        {
            "ix": "25-ARR_v2_83",
            "content": "Chin-Yew Lin, Eduard Hovy, Automatic evaluation of summaries using n-gram co-occurrence statistics, 2003, Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Chin-Yew Lin",
                    "Eduard Hovy"
                ],
                "title": "Automatic evaluation of summaries using n-gram co-occurrence statistics",
                "pub_date": "2003",
                "pub_title": "Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "25-ARR_v2_84",
            "content": "Qiang Liu, Alexander Ihler, Mark Steyvers, Scoring workers in crowdsourcing: How many control questions are enough?, 2013, Advances in Neural Information Processing Systems, Curran Associates, Inc.",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "Qiang Liu",
                    "Alexander Ihler",
                    "Mark Steyvers"
                ],
                "title": "Scoring workers in crowdsourcing: How many control questions are enough?",
                "pub_date": "2013",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": "Curran Associates, Inc"
            }
        },
        {
            "ix": "25-ARR_v2_85",
            "content": "UNKNOWN, None, 1907, Roberta: A robustly optimized BERT pretraining approach, .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": null,
                "title": null,
                "pub_date": "1907",
                "pub_title": "Roberta: A robustly optimized BERT pretraining approach",
                "pub": null
            }
        },
        {
            "ix": "25-ARR_v2_86",
            "content": "Anastassia Loukina, Nitin Madnani, Aoife Cahill, Lili Yao, Matthew Johnson, Brian Riordan, Daniel Mccaffrey, Using PRMSE to evaluate automated scoring systems in the presence of label noise, 2020, Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "Anastassia Loukina",
                    "Nitin Madnani",
                    "Aoife Cahill",
                    "Lili Yao",
                    "Matthew Johnson",
                    "Brian Riordan",
                    "Daniel Mccaffrey"
                ],
                "title": "Using PRMSE to evaluate automated scoring systems in the presence of label noise",
                "pub_date": "2020",
                "pub_title": "Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "25-ARR_v2_87",
            "content": "Shikib Mehri, Maxine Eskenazi, Unsupervised evaluation of interactive dialog with DialoGPT, 2020, Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Shikib Mehri",
                    "Maxine Eskenazi"
                ],
                "title": "Unsupervised evaluation of interactive dialog with DialoGPT",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "25-ARR_v2_88",
            "content": "Shikib Mehri, Maxine Eskenazi, USR: An unsupervised and reference free evaluation metric for dialog generation, 2020, Proceedings of the 58th, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Shikib Mehri",
                    "Maxine Eskenazi"
                ],
                "title": "USR: An unsupervised and reference free evaluation metric for dialog generation",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th",
                "pub": null
            }
        },
        {
            "ix": "25-ARR_v2_89",
            "content": "UNKNOWN, None, , Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Annual Meeting of the Association for Computational Linguistics",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "25-ARR_v2_90",
            "content": "Simon Mille, Anya Belz, Bernd Bohnet, Thiago Castro Ferreira, Yvette Graham, Leo Wanner, The third multilingual surface realisation shared task (SR'20): Overview and evaluation results, 2020, Proceedings of the Third Workshop on Multilingual Surface Realisation, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Simon Mille",
                    "Anya Belz",
                    "Bernd Bohnet",
                    "Thiago Castro Ferreira",
                    "Yvette Graham",
                    "Leo Wanner"
                ],
                "title": "The third multilingual surface realisation shared task (SR'20): Overview and evaluation results",
                "pub_date": "2020",
                "pub_title": "Proceedings of the Third Workshop on Multilingual Surface Realisation",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "25-ARR_v2_91",
            "content": "UNKNOWN, None, 2016, Key-value memory networks for directly reading documents, .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": null,
                "title": null,
                "pub_date": "2016",
                "pub_title": "Key-value memory networks for directly reading documents",
                "pub": null
            }
        },
        {
            "ix": "25-ARR_v2_92",
            "content": "Jekaterina Novikova, Ond\u0159ej Du\u0161ek, Verena Rieser, RankME: Reliable human ratings for natural language generation, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": [
                    "Jekaterina Novikova",
                    "Ond\u0159ej Du\u0161ek",
                    "Verena Rieser"
                ],
                "title": "RankME: Reliable human ratings for natural language generation",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "25-ARR_v2_93",
            "content": "Bo Pang, Erik Nijkamp, Wenjuan Han, Linqi Zhou, Yixian Liu, Kewei Tu, Towards holistic and automatic evaluation of open-domain dialogue generation, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Bo Pang",
                    "Erik Nijkamp",
                    "Wenjuan Han",
                    "Linqi Zhou",
                    "Yixian Liu",
                    "Kewei Tu"
                ],
                "title": "Towards holistic and automatic evaluation of open-domain dialogue generation",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "25-ARR_v2_94",
            "content": "Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, Bleu: A method for automatic evaluation of machine translation, 2002, Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL '02, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "Kishore Papineni",
                    "Salim Roukos",
                    "Todd Ward",
                    "Wei-Jing Zhu"
                ],
                "title": "Bleu: A method for automatic evaluation of machine translation",
                "pub_date": "2002",
                "pub_title": "Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL '02",
                "pub": null
            }
        },
        {
            "ix": "25-ARR_v2_95",
            "content": "UNKNOWN, None, 2018, Gene Hwang, and Art Pettigrue, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Gene Hwang, and Art Pettigrue",
                "pub": null
            }
        },
        {
            "ix": "25-ARR_v2_96",
            "content": "Sashank Santhanam, Alireza Karduni, Samira Shaikh, Studying the effects of cognitive biases in evaluation of conversational agents, 2020, Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": [
                    "Sashank Santhanam",
                    "Alireza Karduni",
                    "Samira Shaikh"
                ],
                "title": "Studying the effects of cognitive biases in evaluation of conversational agents",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems",
                "pub": null
            }
        },
        {
            "ix": "25-ARR_v2_97",
            "content": "Sashank Santhanam, Samira Shaikh, Towards best experiment design for evaluating dialogue system output, 2019, Proceedings of the 12th International Conference on Natural Language Generation, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": [
                    "Sashank Santhanam",
                    "Samira Shaikh"
                ],
                "title": "Towards best experiment design for evaluating dialogue system output",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 12th International Conference on Natural Language Generation",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "25-ARR_v2_98",
            "content": "Ionut Sorodoc, Jey Lau, Nikolaos Aletras, Timothy Baldwin, Multimodal topic labelling, 2017, Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics, Short Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": [
                    "Ionut Sorodoc",
                    "Jey Lau",
                    "Nikolaos Aletras",
                    "Timothy Baldwin"
                ],
                "title": "Multimodal topic labelling",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics",
                "pub": "Short Papers"
            }
        },
        {
            "ix": "25-ARR_v2_99",
            "content": "Ilya Sutskever, Oriol Vinyals, V Quoc,  Le, Sequence to sequence learning with neural networks, 2014, Proceedings of the 27th International Conference on Neural Information Processing Systems, MIT Press.",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": [
                    "Ilya Sutskever",
                    "Oriol Vinyals",
                    "V Quoc",
                    " Le"
                ],
                "title": "Sequence to sequence learning with neural networks",
                "pub_date": "2014",
                "pub_title": "Proceedings of the 27th International Conference on Neural Information Processing Systems",
                "pub": "MIT Press"
            }
        },
        {
            "ix": "25-ARR_v2_100",
            "content": "Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, Jeff Klingner, Apurva Shah, Melvin Johnson, Xiaobing Liu, Lukasz Kaiser, Stephan Gouws, Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens, George Kurian, Nishant Patil, Wei Wang, Google's neural machine translation system: Bridging the gap between human and machine translation, 2016, Oriol Vinyals, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": [
                    "Yonghui Wu",
                    "Mike Schuster",
                    "Zhifeng Chen",
                    "Quoc Le",
                    "Mohammad Norouzi",
                    "Wolfgang Macherey",
                    "Maxim Krikun",
                    "Yuan Cao",
                    "Qin Gao",
                    "Klaus Macherey",
                    "Jeff Klingner",
                    "Apurva Shah",
                    "Melvin Johnson",
                    "Xiaobing Liu",
                    "Lukasz Kaiser",
                    "Stephan Gouws",
                    "Yoshikiyo Kato",
                    "Taku Kudo",
                    "Hideto Kazawa",
                    "Keith Stevens",
                    "George Kurian",
                    "Nishant Patil",
                    "Wei Wang"
                ],
                "title": "Google's neural machine translation system: Bridging the gap between human and machine translation",
                "pub_date": "2016",
                "pub_title": "Oriol Vinyals",
                "pub": "CoRR"
            }
        },
        {
            "ix": "25-ARR_v2_101",
            "content": "UNKNOWN, None, , , .",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": null,
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "25-ARR_v2_0@0",
            "content": "Achieving Reliable Human Assessment of Open-Domain Dialogue Systems",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_0",
            "start": 0,
            "end": 66,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_2@0",
            "content": "Evaluation of open-domain dialogue systems is highly challenging and development of better techniques is highlighted time and again as desperately needed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_2",
            "start": 0,
            "end": 153,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_2@1",
            "content": "Despite substantial efforts to carry out reliable live evaluation of systems in recent competitions, annotations have been abandoned and reported as too unreliable to yield sensible results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_2",
            "start": 155,
            "end": 344,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_2@2",
            "content": "This is a serious problem since automatic metrics are not known to provide a good indication of what may or may not be a high-quality conversation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_2",
            "start": 346,
            "end": 492,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_2@3",
            "content": "Answering the distress call of competitions that have emphasized the urgent need for better evaluation techniques in dialogue, we present the successful development of human evaluation that is highly reliable while still remaining feasible and low cost.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_2",
            "start": 494,
            "end": 746,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_2@4",
            "content": "Self-replication experiments reveal almost perfectly repeatable results with a correlation of r = 0.969.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_2",
            "start": 748,
            "end": 851,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_2@5",
            "content": "Furthermore, due to the lack of appropriate methods of statistical significance testing, the likelihood of potential improvements to systems occurring due to chance is rarely taken into account in dialogue evaluation, and the evaluation we propose facilitates application of standard tests.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_2",
            "start": 853,
            "end": 1142,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_2@6",
            "content": "Since we have developed a highly reliable evaluation method, new insights into system performance can be revealed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_2",
            "start": 1144,
            "end": 1257,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_2@7",
            "content": "We therefore include a comparison of state-of-the-art models (i) with and without personas, to measure the contribution of personas to conversation quality, as well as (ii) prescribed versus freely chosen topics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_2",
            "start": 1259,
            "end": 1470,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_2@8",
            "content": "Interestingly with respect to personas, results indicate that personas do not positively contribute to conversation quality as expected.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_2",
            "start": 1472,
            "end": 1607,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_4@0",
            "content": "Evaluation of open-domain dialogue is particularly challenging and has been cited in high-profile competitions as a known open problem (Dinan et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_4",
            "start": 0,
            "end": 155,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_4@1",
            "content": "Challenges arise primarily from the fact that in real-world conversations there exists such a vast number of possible appropriate responses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_4",
            "start": 157,
            "end": 296,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_5@0",
            "content": "Subsequently, dialogue evaluation that relies on comparison with pre-created reference dialogues incur substantial false-negative rates as many appropriate responses are unfairly penalized simply for not corresponding closely with references.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_5",
            "start": 0,
            "end": 241,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_5@1",
            "content": "In addition, evaluation faces further challenges with respect to the ability to fully take into account dialogue history.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_5",
            "start": 243,
            "end": 363,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_5@2",
            "content": "1 In this paper, we present a new method of opendomain dialogue evaluation based on human assessment of live conversations with models that avoids the need for pre-created reference dialogues and ensures full familiarity with dialogue history, ticking two important boxes in terms of validity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_5",
            "start": 365,
            "end": 657,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_5@3",
            "content": "Although live human evaluation of models has the advantage of being highly valid, reliability unfortunately cannot be assumed and developing methods of evaluation for language tasks that achieve high rater consistency has been challenging, often resulting in low levels of agreement between annotators (Finch and Choi, 2020;Callison-Burch et al., 2011, 2012Bojar et al., 2013Bojar et al., , 2014Mehri and Eskenazi, 2020b).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_5",
            "start": 659,
            "end": 1080,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_5@4",
            "content": "Despite challenges in this respect, our proposed method provides highly reliable evaluation, achieving a correlation of r = 0.969 in selfreplication experiments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_5",
            "start": 1082,
            "end": 1242,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_5@5",
            "content": "Additionally, the evaluation can be carried out cheaply and on a large scale through strict quality controlled crowd-sourcing, as well as including score standardization for fairer ranking of competing models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_5",
            "start": 1244,
            "end": 1452,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_5@6",
            "content": "We make the data and code publicly available to aid future research.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_5",
            "start": 1454,
            "end": 1521,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_5@7",
            "content": "2",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_5",
            "start": 1523,
            "end": 1523,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_6@0",
            "content": "Problems in Past Evaluations",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_6",
            "start": 0,
            "end": 27,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_7@0",
            "content": "A common issue occurs that can potentially impact the validity of results is filtering the set of systems to be evaluated via automatic metric scores.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_7",
            "start": 0,
            "end": 149,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_7@1",
            "content": "Since metric scores are known to be a poor substitute for human assessment, this only results in the possibility that the best system according to human judges is inadvertently filtered out at this stage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_7",
            "start": 151,
            "end": 354,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_7@2",
            "content": "For example, ConvAI2 (Dinan et al., 2019) ranked models firstly using automatic metrics before top models according to metric scores were assessed by crowd-sourced workers on Mechanical Turk, while similarly in the sixth Dialog System Technology Challenge (DSTC6) systems were filtered according to metric scores prior to human evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_7",
            "start": 356,
            "end": 694,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_8@0",
            "content": "In terms of the live evaluation, competitions such as ConvAI2 report such evaluations as highly challenging, with many of the resulting dialogues reported to be senseless, offensive, or simply not in line with instructions and ultimately live evaluation results have been discarded.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_8",
            "start": 0,
            "end": 281,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_9@0",
            "content": "Despite challenges, competitions that operate in the public domain, making data and evaluation techniques available to researchers (such as ourselves) should be applauded for such efforts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_9",
            "start": 0,
            "end": 187,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_10@0",
            "content": "On the other hand, competitions that (for one reason or another) do not release data and evaluation techniques into the public domain have reported relative success in terms of human evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_10",
            "start": 0,
            "end": 193,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_10@1",
            "content": "However until such methods can be accessed and independently verified through replication studies, they will unfortunately have little impact .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_10",
            "start": 195,
            "end": 337,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_10@2",
            "content": "The first Amazon Alexa Socialbot Grand Challenge required human assessors to score how coherent and engaging conversations were on a 1-5 rating scale by two distinct groups: volunteer Amazon employees (experts), and general Alexa users (crowds) (Ram et al., 2018), are reported to achieve a correlation of overall scores for the two types of human assessors at 0.93.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_10",
            "start": 339,
            "end": 704,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_10@3",
            "content": "The absolute average rating across all chatbots was reported to be 20% lower for experts compared to general users.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_10",
            "start": 706,
            "end": 820,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_10@4",
            "content": "In an additional effort to evaluate models, conversational user experience, coherence, engagement, domain coverage, topical diversity, and conversational depth were assessed (1-5 scale), with combined scores reported to correlate with those of general users at r = 0.66.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_10",
            "start": 822,
            "end": 1091,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_10@5",
            "content": "In addition to methods and data not being publicly available, correlations are difficult to interpret since no detail is provided about the number of judgments on which the correlation is calculated for example.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_10",
            "start": 1093,
            "end": 1303,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_11@0",
            "content": "In addition to competitions that generally aim to include human evaluation of systems, automatic metrics are often proposed for dialogue evaluation, themselves requiring a human evaluation data set on which to evaluate the proposed metric.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_11",
            "start": 0,
            "end": 238,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_11@1",
            "content": "However, inappropriate statistics are often applied.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_11",
            "start": 240,
            "end": 291,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_11@2",
            "content": "For example, Pang et al. (2020) propose a holistic metric to automatically evaluate four distinct aspects of dialogue, and a human evaluation experiment is deployed on Mechanical Turk using a 1-5 rating scale.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_11",
            "start": 293,
            "end": 501,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_11@3",
            "content": "The mean correlation between human assessors is reported as r = 0.61.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_11",
            "start": 503,
            "end": 571,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_11@4",
            "content": "However, mean correlations are unfortunately difficult to interpret, since correlation coefficients are not additive , averages calculated in the usual way cannot be assumed to reflect central tendency, and unfortunately, the distribution of correlations is not reported (Alexander, 1990).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_11",
            "start": 573,
            "end": 861,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_11@5",
            "content": "Mehri and Eskenazi (2020b) propose USR (Un-Supervised and Reference-free), an unsupervised model that predicts the quality of dialog for a range of criteria using various rating scales: understandable (0-1 rating scale), natural (1-3), maintains context (1-3), interesting (1-3), uses knowledge (0-1); overall quality (1-5).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_11",
            "start": 863,
            "end": 1186,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_11@6",
            "content": "Despite human evaluation being carried out by experts inter-annotator agreement levels varied depending on criteria being measured, ranging from as low as 0.298.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_11",
            "start": 1188,
            "end": 1348,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_11@7",
            "content": "Additionally, although correlations between human assessments are reported as significant at p < 0.01, despite such statistics often being reported for correlations, they are unfortunately not very meaningful in terms of their impact on correlation interpretation and can be somewhat misleading.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_11",
            "start": 1350,
            "end": 1644,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_11@8",
            "content": "Contrary to common expectations, even small effect sizes (low r) can produce very low p-values (strong significance) in such tests.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_11",
            "start": 1646,
            "end": 1776,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_11@9",
            "content": "Aiming to achieve a significant correlation is an extremely low bar to reach in terms of consistency, since a low p-value in this case simply rejects the null hypothesis that the correlation is zero.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_11",
            "start": 1778,
            "end": 1976,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_12@0",
            "content": "In addition to the above issues, human evaluation of dialogue systems rarely take into account the fact that differences in performance can occur simply by chance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_12",
            "start": 0,
            "end": 162,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_12@1",
            "content": "The method of human evaluation we propose provides a means of applying standard tests for statistical significance to avoid concluding differences that are highly likely to have occurred simply by chance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_12",
            "start": 164,
            "end": 367,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_13@0",
            "content": "Crowd-sourcing Reliable Human",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_13",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_14@0",
            "content": "Assessment of Open-Domain Dialogue",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_14",
            "start": 0,
            "end": 33,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_15@0",
            "content": "Crowd-sourcing with highly accurate quality control provides a potential mechanism to ensure the three most important criteria that makes an evaluation meaningful while still remaining feasible: validity, reliability and scalability.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_15",
            "start": 0,
            "end": 232,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_15@1",
            "content": "Subsequently, we ask crowd-workers to carry out live text-based chat with models prior to that same worker also rating the quality of the immediately preceding conversation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_15",
            "start": 234,
            "end": 406,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_16@0",
            "content": "Human Ratings of Dialogue Quality",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_16",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_17@0",
            "content": "A continuous (0-100) rating scale is employed with three main motivation points (Graham et al., 2013;Novikova et al., 2018;Li et al., 2019;Santhanam and Shaikh, 2019;Barrault et al., 2020;Howcroft et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_17",
            "start": 0,
            "end": 210,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_17@1",
            "content": "Firstly, continuous scales reduce potential bias when comparing the performance of competing models by enabling score standardization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_17",
            "start": 212,
            "end": 345,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_17@2",
            "content": "The score distribution of each human assessor is standardized according to overall mean and standard deviation of all ratings provided by that assessor, thus removing any adverse effects of those employing overly harsh (or indeed lenient) scoring strategies.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_17",
            "start": 347,
            "end": 604,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_18@0",
            "content": "Secondly, the 0-100 rating scale allows standard significance tests to score distributions of models to help determine which models significantly outperform others.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_18",
            "start": 0,
            "end": 163,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_18@1",
            "content": "Thirdly, and possibly most importantly, a continuous rating scale facilitates highly accurate quality control of crowd-sourced workers so that the evaluation can scale while still maintaining validity at a low cost.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_18",
            "start": 165,
            "end": 379,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_18@2",
            "content": "Each human assessor is firstly asked to carry out a live conversation with a randomly selected model, comprised of a minimum of 10 conversational inputs, before rating the quality of the conversation that just took place under a number of criteria shown in Figure 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_18",
            "start": 381,
            "end": 646,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_18@3",
            "content": "Note that the measurement criteria we employed are not immutable and we encourage to extend or adjust the criteria for future studies as necessary.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_18",
            "start": 648,
            "end": 794,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_19@0",
            "content": "A continuous rating scale is advantageous for several reasons but employment of such a scale raises the question of how it should be labeled.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_19",
            "start": 0,
            "end": 140,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_19@1",
            "content": "In evaluation of language tasks, adjectival scale labels, such as poor, low, medium, high, perfect/ okay, good, excellent, and so on, are often employed despite their likely contribution to annotator inconsistency (Loukina et al., 2020;Sorodoc et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_19",
            "start": 142,
            "end": 399,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_19@2",
            "content": "This is despite evidence of adjectival scale labels being problematic in terms of bias resulting from positively and negatively worded items not being true opposites of one another, and items intended to have neutral intensity in fact proving to have Robotic: It was obvious that I was talking to a chatbot as opposed to another human user.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_19",
            "start": 401,
            "end": 740,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_19@3",
            "content": "Interesting: The conversation with the chatbot was interesting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_19",
            "start": 742,
            "end": 804,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_19@4",
            "content": "Fun: The conversation with the chatbot was fun/enjoyable.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_19",
            "start": 806,
            "end": 862,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_19@5",
            "content": "Consistent: The chatbot was consistent throughout the conversation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_19",
            "start": 864,
            "end": 930,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_19@6",
            "content": "Fluent: The chatbot's English was fluent and natural throughout the conversation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_19",
            "start": 932,
            "end": 1012,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_19@7",
            "content": "Repetitive: I felt that the chatbot kept being repetitive during the conversation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_19",
            "start": 1014,
            "end": 1095,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_19@8",
            "content": "Topic: The chatbot stays on topic.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_19",
            "start": 1097,
            "end": 1130,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_19@9",
            "content": "specific conceptual meanings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_19",
            "start": 1132,
            "end": 1160,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_19@10",
            "content": "Alexandrov (2010) provides a summary of issues associated with adjectival labels.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_19",
            "start": 1162,
            "end": 1242,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_20@0",
            "content": "To avoid any such causes of inconsistency, we structure each rating as a simple Likert declarative statement and ask human assessors to rate the degree to which they agree with each of these statement, making it possible to keep the rating scale constant while only changing the statement for each measurement criteria.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_20",
            "start": 0,
            "end": 318,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_20@1",
            "content": "We ask judges to rate each conversation under the seven aforementioned measurement criteria (Figure 1) along with a continuous rating scale labeled only at each extreme with strongly disagree (left); strongly agree (right).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_20",
            "start": 320,
            "end": 542,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_21@0",
            "content": "Quality Controlling the Crowd for",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_21",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_22@0",
            "content": "Open-Domain Dialogue",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_22",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_23@0",
            "content": "We structure Human Intelligence Tasks (HITs) so that a sufficiently rich score distribution is collected from each individual worker who participated, asking each to hold six conversations, comprised of a shuffled arrangement of five dialogue models and a single quality control model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_23",
            "start": 0,
            "end": 284,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_23@1",
            "content": "Many approaches to quality controlling the crowd employ gold-standard items as quality checks (Liu et al., 2013;Lasecki et al., 2014).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_23",
            "start": 286,
            "end": 419,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_23@2",
            "content": "This approach is however highly likely to allow low quality data to pollute the resulting evaluation, since any worker willing to assign high scores to all items will undeservedly pass this check.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_23",
            "start": 421,
            "end": 616,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_23@3",
            "content": "3 The approach also runs in contrast to our aim of the same individual who took part in a live conversation to also assess its quality, as it relies on the use of pre-created gold standard conversations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_23",
            "start": 618,
            "end": 820,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_24@0",
            "content": "Our quality control approach overcomes these challenges by deploying models in live conversations that have known distinct performance levels instead of asking workers to assess the quality of pre-existing known high quality conversations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_24",
            "start": 0,
            "end": 238,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_24@1",
            "content": "Within a HIT, the five models m can produce some quality level of conversation and the model l produces known lower quality dialogues (lower than the five models).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_24",
            "start": 240,
            "end": 402,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_24@2",
            "content": "For a single worker who takes part in conversations with m and l, we then check how consistently the worker rated the conversations of l lower than m. This results in a quality control mechanism that does not ask workers to be consistent with other workers or to correctly rate gold standard dialogues but only assesses worker consistency by how consistently they distinguish between known distinct performance models and only with respect to their own conversation ratings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_24",
            "start": 404,
            "end": 877,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_25@0",
            "content": "From a practical standpoint, creating a low performance model, l, is additionally far less challenging and costly than pre-creating a known set of high quality dialogues, and degraded models operate fully automatically.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_25",
            "start": 0,
            "end": 218,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_25@1",
            "content": "Low quality models produce outputs via generation of random responses with meaning distortion also applied.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_25",
            "start": 220,
            "end": 326,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_26@0",
            "content": "For random response degradation: Low quality responses are generated by random sampling responses from training set dialogues with the intention of disregarding any previous input from the user, so responses from the model are likely to be perceived as low quality since they have low relevance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_26",
            "start": 0,
            "end": 294,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_26@1",
            "content": "To reduce the quality of conversations further, we apply meaning distortion: each response, r, is altered to distort its meaning by randomly selecting a sequence of words within that response and replacing it with a sequence of words sampled from a distinct training set dialogue, with the length of the replaced word sequence being determined by the number of words in r. The specific details are provided in Appendix A.1, and Figure 4 in Appendix A.4 gives a typical example.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_26",
            "start": 296,
            "end": 772,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_27@0",
            "content": "Hits subsequently consist of a total of six dialogues comprised of five genuine models and a single quality control model that generates meaning distorted and random responses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_27",
            "start": 0,
            "end": 175,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_27@1",
            "content": "Crowd-sourced workers converse with each model before rating conversation quality (model order is shuffled and blind).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_27",
            "start": 177,
            "end": 294,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_27@2",
            "content": "Statistical significance tests are then applied to score distributions of workers for the ratings they attributed to ordinary models, m, relative to the low quality model, l.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_27",
            "start": 296,
            "end": 469,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_27@3",
            "content": "The resulting p-value is then employed as a means of rating worker consistency, and any worker with p >= 0.05 shows no significant difference between low and ordinary model quality and is filtered out.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_27",
            "start": 471,
            "end": 671,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_28@0",
            "content": "Calculating System-Level Scores",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_28",
            "start": 0,
            "end": 30,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_29@0",
            "content": "Scores are collected from workers who rate models on a 0-100 rating scale, and we refer to these scores as raw scores.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_29",
            "start": 0,
            "end": 117,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_29@1",
            "content": "Scores for negative attributes, i.e. robotic and repetitive, are then reversed for ease of further comparison, 100 \u2212 the original rating.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_29",
            "start": 119,
            "end": 255,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_29@2",
            "content": "A distribution of scores is extracted for each worker and raw scores are standardized according to each worker's mean and standard deviation, in order to iron out any differences in worker scoring strategy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_29",
            "start": 257,
            "end": 462,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_30@0",
            "content": "Average standardized scores for each criteria are calculated, and an overall score is calculated as the average of all measurement criteria.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_30",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_31@0",
            "content": "Meta-Evaluation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_31",
            "start": 0,
            "end": 14,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_32@0",
            "content": "In order to assess the reliability of the proposed method of human evaluation, we carry out a metaevaluation in which we firstly examine individual human assessor consistency, before conducting a self-replication experiment.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_32",
            "start": 0,
            "end": 223,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_32@1",
            "content": "A number of models are required to function as a sample set of test systems, and for this purpose we employ available pre-trained models from ParlAI: 4 Poly-Encoder Transformer (Humeau et al., 2019), Bi-Encoder Transformer (Dinan et al., 2018), Sequence to Sequence (Sutskever et al., 2014), Key-Value Memory Networks (Miller et al., 2016), and a LSTMbased Model (Hochreiter and Schmidhuber, 1997).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_32",
            "start": 225,
            "end": 622,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_32@2",
            "content": "Within the evaluation setting of ConvAI2, each model is with a persona consisting of approximately five textual statements to emulate a personality.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_32",
            "start": 624,
            "end": 771,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_32@3",
            "content": "However, to increase the number of models and to provide an interesting comparison, we additionally include a version of each of the above models without any persona, resulting in 10 competing models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_32",
            "start": 773,
            "end": 972,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_33@0",
            "content": "Hits were posted on the crowd-sourcing platform Amazon Mechanical Turk. 5 Firstly, and in order to evaluate the open-domain models in as realistic a setting as possible, we allow workers to choose the topic of conversation and input their chosen topic in a text field.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_33",
            "start": 0,
            "end": 267,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_33@1",
            "content": "The open nature of conversations should be noted however as something that influences the difficulty of producing consistent results Table 1: Numbers of workers who took part in human evaluation of models, average time taken per dialogue in minutes (min), and total number of dialogues assessed before and after quality control in which workers freely chose the topic (Free run 1); precisely the same experiment set-up was repeated (Free run 2); where the topic was prescribed via an ice-breaker statement (Ice-breaker) selected directly from the persona of the model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_33",
            "start": 269,
            "end": 836,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_34@0",
            "content": "in our self-replication experiment.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_34",
            "start": 0,
            "end": 34,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_34@1",
            "content": "The fact that we allow human assessors to freely choose the topic of conversation means that differences in ratings could result from legitimate differences in performance when different topics are chosen by human assessors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_34",
            "start": 36,
            "end": 259,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_34@2",
            "content": "We nonetheless test our evaluation allowing the user to choose the topic as this is part of our core aim for developing evaluation of dialogue truly in the open domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_34",
            "start": 261,
            "end": 428,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_35@0",
            "content": "Besides choosing a topic, we additionally asked workers to input their opinion of the topic they chose to discuss with models, categorizing the topic as either liked, ambivalent about it, or disliked.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_35",
            "start": 0,
            "end": 199,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_35@1",
            "content": "For example, if the topic they chose to discuss was dogs, we were curious to know if this was motivated by the fact that the worker liked or disliked dogs or indeed that they had chosen to discuss something they had no particular feeling about.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_35",
            "start": 201,
            "end": 444,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_35@2",
            "content": "Table 2 shows subsequent proportions (%) of workers, and the detailed instructions are introduced in Figure 5 in Appendix A.4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_35",
            "start": 446,
            "end": 571,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_35@3",
            "content": "Perhaps unsurprisingly, the vast majority of workers chose to discuss something they liked (84% for workers who passed quality control).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_35",
            "start": 573,
            "end": 708,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_35@4",
            "content": "Nonetheless 7% of good workers were ambivalent about the topic they chose and 9% chose a topic they reported as disliking.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_35",
            "start": 710,
            "end": 831,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_36@0",
            "content": "Free Table 1 shows the number of workers who participated in the initial data collection run who freely chose the topic of conversation with models (Free run 1), amounting to 1,525 dialogues \u00d7 7 criteria = 10,675 human ratings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_36",
            "start": 0,
            "end": 226,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_36@1",
            "content": "The details of payment to each worker and the total experiment cost are provided in Appendix A.2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_36",
            "start": 228,
            "end": 324,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_36@2",
            "content": "Table 1 also shows the proportion of workers who passed quality checks, numbers of dialogues assessed in total before and after quality filtering, as well as the average time taken for workers to complete a hit and average time taken to assess dialogues.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_36",
            "start": 326,
            "end": 579,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_36@3",
            "content": "As mentioned previously, we carry out a second data collection run with precisely the same settings (Free run 2) to measure the reliability of results and Table 1 shows equivalent statistics with respect to Free run 2 in which a total of 1,480 dialogues \u00d7 7 ratings = 10,360 human ratings were collected in total.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_36",
            "start": 581,
            "end": 893,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_37@0",
            "content": "Human Assessor Consistency",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_37",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_38@0",
            "content": "Although the overall aim of our evaluation is to produce reliable results at the system level, which we test later in Section 4.2, we firstly examine ratings of workers at the level of individual dialogue ratings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_38",
            "start": 0,
            "end": 212,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_38@1",
            "content": "Technically speaking, the most meaningful reliability measures for continuous ratings scales test consistency of aggregate (system-level) results because although a high level of random error is expected in individual continuous rating scale scores, when aggregates are calculated for large samples of ratings, positive and negative error that is truly random effectively cancels itself out, and does not negatively impact consistency.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_38",
            "start": 214,
            "end": 648,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_38@2",
            "content": "In other words, the rating scale we employ does not rely on consistency on the level of individual ratings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_38",
            "start": 650,
            "end": 756,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_38@3",
            "content": "We nonetheless examine individual rater consistency, since it is the standard approach, but keep in mind that results in this part of our meta-evaluation are not crucial when testing reliability for an evaluation carried out via a continuous rating scale where consistency in overall system-level results are more important.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_38",
            "start": 758,
            "end": 1081,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_39@0",
            "content": "The distribution of Pearson correlation coefficients for pairs of workers who assessed the same hit is depicted in Figure 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_39",
            "start": 0,
            "end": 123,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_40@0",
            "content": "As can be seen from Figure 2, the likelihood of agreement between pairs of workers who failed quality control is close to random as the distribution is approaching uniformity across almost the range of possible coefficients.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_40",
            "start": 0,
            "end": 223,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_40@1",
            "content": "In contrast, for pairs of workers who pass quality control, the peak of agreement is between an r of 0.6 and 0.7, showing high agreement in general between such annotator pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_40",
            "start": 225,
            "end": 401,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_40@2",
            "content": "Some of the observed disagreement is likely to be the result of legitimate differences between scores of two workers who chose distinct topics to discuss with the same model however, an unavoidable source of inconsistency when testing models with respect to the open domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_40",
            "start": 403,
            "end": 676,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_40@3",
            "content": "Interestingly, in 5% of dialogues, worker pairs assigned the same hit happened to both freely choose an identical topic to discuss with the same model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_40",
            "start": 678,
            "end": 828,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_40@4",
            "content": "Furthermore, remaining disagreement at the level of individual ratings might not be problematic at the level of overall scores in relation to aggregation of ratings collected on a continuous rating scale.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_40",
            "start": 830,
            "end": 1033,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_41@0",
            "content": "System-level Consistency",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_41",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_42@0",
            "content": "Table 3 shows results of the system-level evaluation resulting from the initial data collection run on Mechanical Turk (Free run 1), where competing models are ordered by overall highest average zscore.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_42",
            "start": 0,
            "end": 201,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_42@1",
            "content": "6 Table 3 4: Average standardized scores for models in human evaluation where workers were prescribed an ice-breaker topic of conversation sampled from the persona of the model; the correlation (r) between these scores and Free run 1 in Table 3; models are consistent with Table 3; n is number of ratings; models without p did not have a persona (ice-breaker statement was subsequently unknown to these models). , where a colored cell indicates that the system in that row significantly outperformed the system in that column.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_42",
            "start": 203,
            "end": 728,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_42@2",
            "content": "Models are consistent with Table 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_42",
            "start": 730,
            "end": 764,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_43@0",
            "content": "A B A p C C p B p D D p E p E A B A p C C p B p D D p E p E 0.00 0.05 0.10",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_43",
            "start": 0,
            "end": 73,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_44@0",
            "content": "the board, consistency is very high, exceeding a correlation of 0.94 in almost all cases with the exception of robotic which nonetheless achieved a correlation of over 0.7.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_44",
            "start": 0,
            "end": 171,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_44@1",
            "content": "Besides individual criteria, of crucial importance is the consistency of overall results, as this is the means by which models would ordinarily be ranked in terms of overall performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_44",
            "start": 173,
            "end": 358,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_44@2",
            "content": "As can be observed from Table 3, the correlation reached in terms of overall scores for systems is 0.969, which is very close to a perfect correlation, showing extremely high levels of reliability for the evaluation, evidence that the approach overcomes substantial challenges with respect to annotator consistency and expected difficulties with respect to evaluating models in the open domain, where assessors are legitimately free to choose distinct topics of conversation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_44",
            "start": 360,
            "end": 834,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_45@0",
            "content": "In any empirical evaluation, statistical significance tests should be applied to take into account the fact that small differences in scores between systems can occur simply by chance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_45",
            "start": 0,
            "end": 183,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_45@1",
            "content": "We provide pairwise significance test results in Figure 3, where we apply standard significance test, Wilcoxon ranksum to rating distributions for each pair of competing models for each data collection run, and corresponding results for run 2 in Figure 6 in Appendix A.4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_45",
            "start": 185,
            "end": 455,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_45@2",
            "content": "Results showed a very high proportion of identical conclusions, 84%, drawn from pairwise significance tests applied to data from the two data collection runs at p < 0.1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_45",
            "start": 457,
            "end": 625,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_45@3",
            "content": "Results for p < 0.05, additionally showed high correspondence between pairwise significance test conclusions, only marginally lower with 82% of the same conclusions being drawn for pairs of models in the two data collection runs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_45",
            "start": 627,
            "end": 855,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_45@4",
            "content": "We additionally provide correlations between measurement criteria and overall scores in Table 8 of Appendix A.4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_45",
            "start": 857,
            "end": 968,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_46@0",
            "content": "Persona Contribution to System Performance",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_46",
            "start": 0,
            "end": 41,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_47@0",
            "content": "Since we have verified the reliability of the human evaluation, we take a closer look at the results and investigate dialogue quality when models employ a persona.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_47",
            "start": 0,
            "end": 162,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_47@1",
            "content": "Results in Table 3 reveal that perhaps unexpectedly in general are either rated more favorably by human assessors when they carry out dialogues without a persona or a tie occurs between models with and without a persona.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_47",
            "start": 164,
            "end": 383,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_48@0",
            "content": "Evaluating with Prescribed Topics",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_48",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_49@0",
            "content": "In contrast to the initial experiment in which workers were permitted to choose the topic of conversation, we further investigate the performance of models in a slightly easier setting where the topic under discussion is known to the model, by selecting a statement from its persona, which we refer to as an ice-breaker topic statement.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_49",
            "start": 0,
            "end": 335,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_49@1",
            "content": "An ice-breaker topic statement is then provided to human assessors at the beginning of each conversation, and the assessor is instructed to talk about this topic with the model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_49",
            "start": 337,
            "end": 513,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_49@2",
            "content": "We therefore provide the topic of conversation to workers in the form of an ice-breaker topic statement, corresponding to a randomly selected persona statement belonging to the agent.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_49",
            "start": 515,
            "end": 697,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_49@3",
            "content": "Again, we run this experiment on MTurk, this time contrasting results for our initial data collection run where workers freely chose a topic with one in which workers were instructed to talk about the ice-breaker statement with models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_49",
            "start": 699,
            "end": 933,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_49@4",
            "content": "Numbers of workers who participated in the Icebreaker run are provided in Table 1, while a breakdown of results for each model and overall average scores are shown in Table 4 as well as the correlation between scores for systems when a topic is freely chosen.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_49",
            "start": 935,
            "end": 1193,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_49@5",
            "content": "Interestingly, in terms of absolute differences in raw scores, the best performing model achieves higher fluency, consistency and is deemed less repetitive when evaluated in icebreaker conversations compared those with freely chosen topics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_49",
            "start": 1195,
            "end": 1434,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_49@6",
            "content": "Raw average scores for models in the Ice-breaker run are additionally provided in Table 11 in Appendix A.4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_49",
            "start": 1436,
            "end": 1542,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_49@7",
            "content": "Relatively speaking, in terms of system rankings, no meaningful difference in relative performance is observed when models are tested in a scenario where the worker chooses a topic and when one is prescribed with an ice-breaker statement, as can be seen from the strong correlation between scores for models in Free run 1 and Ice-breaker evaluation as shown in In this experiment, we employed four prevailing word-overlap-based metrics as described in the following, whose scores are computed on the Con-vAI2 test set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_49",
            "start": 1544,
            "end": 2061,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_50@0",
            "content": "BLEU BLEU (Bilingual Evaluation Understudy) evaluate the quality of a system output by computing the n-gram precision according to humangenerated references (Papineni et al., 2002).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_50",
            "start": 0,
            "end": 180,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_50@1",
            "content": "It also uses the brevity penalty to penalize short outputs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_50",
            "start": 182,
            "end": 240,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_51@0",
            "content": "ROUGE-L ROUGE (Recall-Oriented Understudy for Gisting Evaluation) is a recall-adaptation of BLEU, whose wildly-applied variant is ROUGE-L (Lin and Hovy, 2003).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_51",
            "start": 0,
            "end": 158,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_51@1",
            "content": "It computes the precision and recall using longest common subsequence (LSC) instead of n-gram, and the F1 score of precision and recall is reported as the final score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_51",
            "start": 160,
            "end": 326,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_52@0",
            "content": "METEOR METEOR (Metric for Evaluation of Translation with Explicit ORdering) was firstly proposed to overcome flaws of BLEU, like no usage of recall (Denkowski and Lavie, 2011).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_52",
            "start": 0,
            "end": 175,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_52@1",
            "content": "It computes the unigram precision and recall, and have a different mechanism of choosing the brevity penalty.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_52",
            "start": 177,
            "end": 285,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_53@0",
            "content": "GLEU GLEU (Google-BLEU) is a variety of BLEU (Wu et al., 2016) which computes the ngram precision and recall instead of the standalone precision.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_53",
            "start": 0,
            "end": 144,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_53@1",
            "content": "The minimum of precision and recall is reported as the final GLEU score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_53",
            "start": 146,
            "end": 217,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_54@0",
            "content": "Metric r",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_54",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_55@0",
            "content": "BLEU-4 \u22120.883 BLEU-1 \u22120.707 ROUGE-L \u22120.799 METEOR \u22120.321 GLEU \u22120.816",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_55",
            "start": 0,
            "end": 67,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_56@0",
            "content": "Reference-free Metrics",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_56",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_57@0",
            "content": "The following introduces two reference-free automatic metrics we employed: FED and USR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_57",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_57@1",
            "content": "Their scores are computed using the conversations collected in our experiment.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_57",
            "start": 88,
            "end": 165,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_58@0",
            "content": "FED FED (Fine-grained Evaluation of Dialog) is a pre-trained-model based metric to evaluate a textual conversation history (Mehri and Eskenazi, 2020a).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_58",
            "start": 0,
            "end": 150,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_58@1",
            "content": "Given a conversation c, a pre-trained model m, two predefined responses r p and r n (p = positive and n = negative), the FED score is L m (r p |c) \u2212 L m (r n |c) where L m (r|c) computes the likelihood that the model m will generate a response r to a conversation c. We employed medium and large DialoGPT (Zhang et al., 2020) as FED scorers, where the full list of predefined positive and negative responses are available in Table 7 in Appendix.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_58",
            "start": 152,
            "end": 596,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_59@0",
            "content": "USR USR (an UnSupervised Reference-free metric) uses the pre-trained model RoBERTa (Liu et al., 2019) to assess the quality of a conversation (Mehri and Eskenazi, 2020b).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_59",
            "start": 0,
            "end": 169,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_59@1",
            "content": "It consists of three sub-metrics: USR-MLM is to evaluate the understandability and naturalness, USR-DR(c) and USR-DR(f) are to evaluate the interestingness and consistency.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_59",
            "start": 171,
            "end": 342,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_59@2",
            "content": "The sub-metric scores then produce an overall score through a regression model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_59",
            "start": 344,
            "end": 422,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_60@0",
            "content": "Correlation between Automatic Metrics and Human Evaluation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_60",
            "start": 0,
            "end": 57,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_61@0",
            "content": "We compute the correlation between commonly applied automatic metrics and our human evaluation methods, including word-overlap-based metrics and reference-free metrics, as shown in Tables 5 and 6 respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_61",
            "start": 0,
            "end": 208,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_61@1",
            "content": "As can be seen from Table 5, unfortunately no word-overlap metric achieves a strong positive correlation with human assessment, confirming once again that the invalidity of system rankings currently produced by automatic metric scores.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_61",
            "start": 210,
            "end": 444,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_62@0",
            "content": "In terms of reference-free metrics, results correspond better and are more encouraging.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_62",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_62@1",
            "content": "FED has the ability of distinguishing \"repetitive\" models, but for other criteria, it correlates weakly or even negatively with human.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_62",
            "start": 88,
            "end": 221,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_62@2",
            "content": "Meanwhile, despite USR only correlating marginally with human in terms of consistency and topic loyalty, USR-DR(f) correlates closest to human among the three sub-metrics, while it performs best on evaluating consistency and topic loyalty.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_62",
            "start": 223,
            "end": 461,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_63@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_63",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_64@0",
            "content": "Development of reliable evaluation of open-domain dialogue has been highlighted as a known openproblem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_64",
            "start": 0,
            "end": 102,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_64@1",
            "content": "We overcome previous challenges and provide a new human evaluation methodology shown as highly consistent, with results for models correlating at r = 0.969 in two separate data collection runs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_64",
            "start": 104,
            "end": 296,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_64@2",
            "content": "Our evaluation has the advantage of highly accurate quality control of crowd-sourcing, differences in scoring strategies to be ironed out via score standardization, applicability of standard significance testing while increasing the reliability of results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_64",
            "start": 298,
            "end": 553,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_65@0",
            "content": "Alexander Ralph, A note on averaging correlations, 1990, Bulletin of the Psychonomic Society, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_65",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_66@0",
            "content": "Aliosha Alexandrov, Characteristics of singleitem measures in likert scale format, 2010, The Electronic Journal of Business Research Methods, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_66",
            "start": 0,
            "end": 142,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_67@0",
            "content": "UNKNOWN, None, , Santanu Pal, Matt Post, and Marcos Zampieri. 2020. Findings of the 2020 conference on machine translation (wmt20). In Proceedings of the Fifth Conference on Machine Translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_67",
            "start": 0,
            "end": 195,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_68@0",
            "content": "Ondrej Bojar, Christian Buck, Christian Federmann, Barry Haddow, Philipp Koehn, Johannes Leveling, Christof Monz, Pavel Pecina, Matt Post, Herve Saint-Amand, Radu Soricut, Lucia Specia, Ale\u0161 Tamchyna, Findings of the 2014 workshop on statistical machine translation, 2014, Proceedings of the Ninth Workshop on Statistical Machine Translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_68",
            "start": 0,
            "end": 343,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_69@0",
            "content": "Ond\u0159ej Bojar, Christian Buck, Chris Callison-Burch, Christian Federmann, Barry Haddow, Philipp Koehn, Christof Monz, Matt Post, Radu Soricut, Lucia Specia, Findings of the 2013 Workshop on Statistical Machine Translation, 2013, Proceedings of the Eighth Workshop on Statistical Machine Translation, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_69",
            "start": 0,
            "end": 340,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_70@0",
            "content": "Chris Callison-Burch, Philipp Koehn, Christof Monz, Matt Post, Radu Soricut, Lucia Specia, Findings of the 2012 workshop on statistical machine translation, 2012, Proceedings of the Seventh Workshop on Statistical Machine Translation, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_70",
            "start": 0,
            "end": 276,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_71@0",
            "content": "Chris Callison-Burch, Philipp Koehn, Christof Monz, Omar Zaidan, Findings of the 2011 workshop on statistical machine translation, 2011, Proceedings of the Sixth Workshop on Statistical Machine Translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_71",
            "start": 0,
            "end": 207,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_72@0",
            "content": "M Denkowski, A Lavie, Meteor 1.3: Automatic metric for reliable optimization and evaluation of machine translation systems, 2011, Proceedings of the Sixth Workshop on Statistical Machine Translation, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_72",
            "start": 0,
            "end": 241,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_73@0",
            "content": "UNKNOWN, None, 2019, , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_73",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_74@0",
            "content": "UNKNOWN, None, , , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_74",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_75@0",
            "content": "UNKNOWN, None, 2018, Wizard of wikipedia: Knowledge-powered conversational agents, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_75",
            "start": 0,
            "end": 87,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_76@0",
            "content": "Sarah Finch, Jinho Choi, Towards unified dialogue system evaluation: A comprehensive analysis of current evaluation protocols, 2020, Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_76",
            "start": 0,
            "end": 229,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_77@0",
            "content": "Yvette Graham, Timothy Baldwin, Alistair Moffat, Justin Zobel, Crowd-sourcing of human judgments of machine translation fluency, 2013, Proceedings of the Australasian Language Technology Association Workshop 2013 (ALTA 2013), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_77",
            "start": 0,
            "end": 226,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_78@0",
            "content": "Sepp Hochreiter, J\u00fcrgen Schmidhuber, Long short-term memory, 1997, Neural Comput, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_78",
            "start": 0,
            "end": 82,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_79@0",
            "content": "David Howcroft, Anya Belz, Miruna-Adriana Clinciu, Dimitra Gkatzia, A Sadid, Saad Hasan, Simon Mahamood,  Mille, Sashank Emiel Van Miltenburg, Verena Santhanam,  Rieser, Twenty years of confusion in human evaluation: NLG needs evaluation sheets and standardised definitions, 2020, Proceedings of the 13th International Conference on Natural Language Generation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_79",
            "start": 0,
            "end": 362,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_80@0",
            "content": "UNKNOWN, None, 1905, Poly-encoders: Transformer architectures and pre-training strategies for fast and accurate multi-sentence scoring, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_80",
            "start": 0,
            "end": 136,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_81@0",
            "content": "Walter Lasecki, Jaime Teevan, Ece Kamar, Information extraction and manipulation threats in crowd-powered systems, 2014, Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work & Social Computing, CSCW '14, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_81",
            "start": 0,
            "end": 229,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_82@0",
            "content": "UNKNOWN, None, 2019, Acute-eval: Improved dialogue evaluation with optimized questions and multi-turn comparisons, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_82",
            "start": 0,
            "end": 115,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_83@0",
            "content": "Chin-Yew Lin, Eduard Hovy, Automatic evaluation of summaries using n-gram co-occurrence statistics, 2003, Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_83",
            "start": 0,
            "end": 291,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_84@0",
            "content": "Qiang Liu, Alexander Ihler, Mark Steyvers, Scoring workers in crowdsourcing: How many control questions are enough?, 2013, Advances in Neural Information Processing Systems, Curran Associates, Inc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_84",
            "start": 0,
            "end": 196,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_85@0",
            "content": "UNKNOWN, None, 1907, Roberta: A robustly optimized BERT pretraining approach, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_85",
            "start": 0,
            "end": 78,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_86@0",
            "content": "Anastassia Loukina, Nitin Madnani, Aoife Cahill, Lili Yao, Matthew Johnson, Brian Riordan, Daniel Mccaffrey, Using PRMSE to evaluate automated scoring systems in the presence of label noise, 2020, Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_86",
            "start": 0,
            "end": 340,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_87@0",
            "content": "Shikib Mehri, Maxine Eskenazi, Unsupervised evaluation of interactive dialog with DialoGPT, 2020, Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_87",
            "start": 0,
            "end": 235,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_88@0",
            "content": "Shikib Mehri, Maxine Eskenazi, USR: An unsupervised and reference free evaluation metric for dialog generation, 2020, Proceedings of the 58th, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_88",
            "start": 0,
            "end": 143,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_89@0",
            "content": "UNKNOWN, None, , Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_89",
            "start": 0,
            "end": 131,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_90@0",
            "content": "Simon Mille, Anya Belz, Bernd Bohnet, Thiago Castro Ferreira, Yvette Graham, Leo Wanner, The third multilingual surface realisation shared task (SR'20): Overview and evaluation results, 2020, Proceedings of the Third Workshop on Multilingual Surface Realisation, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_90",
            "start": 0,
            "end": 304,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_91@0",
            "content": "UNKNOWN, None, 2016, Key-value memory networks for directly reading documents, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_91",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_92@0",
            "content": "Jekaterina Novikova, Ond\u0159ej Du\u0161ek, Verena Rieser, RankME: Reliable human ratings for natural language generation, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_92",
            "start": 0,
            "end": 305,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_93@0",
            "content": "Bo Pang, Erik Nijkamp, Wenjuan Han, Linqi Zhou, Yixian Liu, Kewei Tu, Towards holistic and automatic evaluation of open-domain dialogue generation, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_93",
            "start": 0,
            "end": 292,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_94@0",
            "content": "Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, Bleu: A method for automatic evaluation of machine translation, 2002, Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL '02, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_94",
            "start": 0,
            "end": 221,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_95@0",
            "content": "UNKNOWN, None, 2018, Gene Hwang, and Art Pettigrue, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_95",
            "start": 0,
            "end": 52,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_96@0",
            "content": "Sashank Santhanam, Alireza Karduni, Samira Shaikh, Studying the effects of cognitive biases in evaluation of conversational agents, 2020, Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_96",
            "start": 0,
            "end": 216,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_97@0",
            "content": "Sashank Santhanam, Samira Shaikh, Towards best experiment design for evaluating dialogue system output, 2019, Proceedings of the 12th International Conference on Natural Language Generation, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_97",
            "start": 0,
            "end": 232,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_98@0",
            "content": "Ionut Sorodoc, Jey Lau, Nikolaos Aletras, Timothy Baldwin, Multimodal topic labelling, 2017, Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics, Short Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_98",
            "start": 0,
            "end": 214,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_99@0",
            "content": "Ilya Sutskever, Oriol Vinyals, V Quoc,  Le, Sequence to sequence learning with neural networks, 2014, Proceedings of the 27th International Conference on Neural Information Processing Systems, MIT Press.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_99",
            "start": 0,
            "end": 202,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_100@0",
            "content": "Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, Jeff Klingner, Apurva Shah, Melvin Johnson, Xiaobing Liu, Lukasz Kaiser, Stephan Gouws, Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens, George Kurian, Nishant Patil, Wei Wang, Google's neural machine translation system: Bridging the gap between human and machine translation, 2016, Oriol Vinyals, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_100",
            "start": 0,
            "end": 446,
            "label": {}
        },
        {
            "ix": "25-ARR_v2_101@0",
            "content": "UNKNOWN, None, , , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "25-ARR_v2_101",
            "start": 0,
            "end": 19,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "25-ARR_v2_0",
            "tgt_ix": "25-ARR_v2_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_0",
            "tgt_ix": "25-ARR_v2_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_1",
            "tgt_ix": "25-ARR_v2_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_1",
            "tgt_ix": "25-ARR_v2_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_0",
            "tgt_ix": "25-ARR_v2_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_2",
            "tgt_ix": "25-ARR_v2_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_4",
            "tgt_ix": "25-ARR_v2_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_3",
            "tgt_ix": "25-ARR_v2_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_3",
            "tgt_ix": "25-ARR_v2_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_3",
            "tgt_ix": "25-ARR_v2_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_0",
            "tgt_ix": "25-ARR_v2_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_5",
            "tgt_ix": "25-ARR_v2_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_7",
            "tgt_ix": "25-ARR_v2_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_8",
            "tgt_ix": "25-ARR_v2_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_9",
            "tgt_ix": "25-ARR_v2_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_10",
            "tgt_ix": "25-ARR_v2_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_11",
            "tgt_ix": "25-ARR_v2_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_6",
            "tgt_ix": "25-ARR_v2_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_6",
            "tgt_ix": "25-ARR_v2_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_6",
            "tgt_ix": "25-ARR_v2_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_6",
            "tgt_ix": "25-ARR_v2_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_6",
            "tgt_ix": "25-ARR_v2_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_6",
            "tgt_ix": "25-ARR_v2_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_6",
            "tgt_ix": "25-ARR_v2_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_0",
            "tgt_ix": "25-ARR_v2_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_12",
            "tgt_ix": "25-ARR_v2_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_14",
            "tgt_ix": "25-ARR_v2_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_13",
            "tgt_ix": "25-ARR_v2_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_13",
            "tgt_ix": "25-ARR_v2_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_13",
            "tgt_ix": "25-ARR_v2_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_13",
            "tgt_ix": "25-ARR_v2_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_15",
            "tgt_ix": "25-ARR_v2_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_17",
            "tgt_ix": "25-ARR_v2_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_18",
            "tgt_ix": "25-ARR_v2_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_19",
            "tgt_ix": "25-ARR_v2_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_16",
            "tgt_ix": "25-ARR_v2_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_16",
            "tgt_ix": "25-ARR_v2_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_16",
            "tgt_ix": "25-ARR_v2_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_16",
            "tgt_ix": "25-ARR_v2_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_16",
            "tgt_ix": "25-ARR_v2_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_13",
            "tgt_ix": "25-ARR_v2_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_20",
            "tgt_ix": "25-ARR_v2_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_22",
            "tgt_ix": "25-ARR_v2_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_23",
            "tgt_ix": "25-ARR_v2_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_24",
            "tgt_ix": "25-ARR_v2_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_25",
            "tgt_ix": "25-ARR_v2_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_26",
            "tgt_ix": "25-ARR_v2_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_21",
            "tgt_ix": "25-ARR_v2_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_21",
            "tgt_ix": "25-ARR_v2_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_21",
            "tgt_ix": "25-ARR_v2_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_21",
            "tgt_ix": "25-ARR_v2_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_21",
            "tgt_ix": "25-ARR_v2_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_21",
            "tgt_ix": "25-ARR_v2_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_21",
            "tgt_ix": "25-ARR_v2_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_13",
            "tgt_ix": "25-ARR_v2_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_27",
            "tgt_ix": "25-ARR_v2_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_29",
            "tgt_ix": "25-ARR_v2_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_28",
            "tgt_ix": "25-ARR_v2_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_28",
            "tgt_ix": "25-ARR_v2_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_28",
            "tgt_ix": "25-ARR_v2_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_0",
            "tgt_ix": "25-ARR_v2_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_30",
            "tgt_ix": "25-ARR_v2_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_32",
            "tgt_ix": "25-ARR_v2_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_33",
            "tgt_ix": "25-ARR_v2_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_34",
            "tgt_ix": "25-ARR_v2_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_31",
            "tgt_ix": "25-ARR_v2_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_31",
            "tgt_ix": "25-ARR_v2_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_31",
            "tgt_ix": "25-ARR_v2_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_31",
            "tgt_ix": "25-ARR_v2_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_31",
            "tgt_ix": "25-ARR_v2_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_31",
            "tgt_ix": "25-ARR_v2_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_35",
            "tgt_ix": "25-ARR_v2_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_31",
            "tgt_ix": "25-ARR_v2_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_36",
            "tgt_ix": "25-ARR_v2_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_38",
            "tgt_ix": "25-ARR_v2_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_39",
            "tgt_ix": "25-ARR_v2_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_37",
            "tgt_ix": "25-ARR_v2_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_37",
            "tgt_ix": "25-ARR_v2_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_37",
            "tgt_ix": "25-ARR_v2_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_37",
            "tgt_ix": "25-ARR_v2_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_31",
            "tgt_ix": "25-ARR_v2_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_40",
            "tgt_ix": "25-ARR_v2_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_42",
            "tgt_ix": "25-ARR_v2_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_43",
            "tgt_ix": "25-ARR_v2_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_44",
            "tgt_ix": "25-ARR_v2_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_41",
            "tgt_ix": "25-ARR_v2_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_41",
            "tgt_ix": "25-ARR_v2_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_41",
            "tgt_ix": "25-ARR_v2_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_41",
            "tgt_ix": "25-ARR_v2_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_41",
            "tgt_ix": "25-ARR_v2_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_0",
            "tgt_ix": "25-ARR_v2_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_45",
            "tgt_ix": "25-ARR_v2_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_46",
            "tgt_ix": "25-ARR_v2_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_46",
            "tgt_ix": "25-ARR_v2_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_0",
            "tgt_ix": "25-ARR_v2_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_47",
            "tgt_ix": "25-ARR_v2_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_49",
            "tgt_ix": "25-ARR_v2_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_50",
            "tgt_ix": "25-ARR_v2_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_51",
            "tgt_ix": "25-ARR_v2_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_52",
            "tgt_ix": "25-ARR_v2_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_53",
            "tgt_ix": "25-ARR_v2_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_54",
            "tgt_ix": "25-ARR_v2_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_48",
            "tgt_ix": "25-ARR_v2_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_48",
            "tgt_ix": "25-ARR_v2_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_48",
            "tgt_ix": "25-ARR_v2_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_48",
            "tgt_ix": "25-ARR_v2_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_48",
            "tgt_ix": "25-ARR_v2_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_48",
            "tgt_ix": "25-ARR_v2_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_48",
            "tgt_ix": "25-ARR_v2_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_48",
            "tgt_ix": "25-ARR_v2_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_0",
            "tgt_ix": "25-ARR_v2_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_55",
            "tgt_ix": "25-ARR_v2_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_57",
            "tgt_ix": "25-ARR_v2_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_58",
            "tgt_ix": "25-ARR_v2_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_56",
            "tgt_ix": "25-ARR_v2_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_56",
            "tgt_ix": "25-ARR_v2_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_56",
            "tgt_ix": "25-ARR_v2_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_56",
            "tgt_ix": "25-ARR_v2_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_0",
            "tgt_ix": "25-ARR_v2_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_59",
            "tgt_ix": "25-ARR_v2_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_61",
            "tgt_ix": "25-ARR_v2_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_60",
            "tgt_ix": "25-ARR_v2_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_60",
            "tgt_ix": "25-ARR_v2_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_60",
            "tgt_ix": "25-ARR_v2_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_0",
            "tgt_ix": "25-ARR_v2_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_62",
            "tgt_ix": "25-ARR_v2_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_63",
            "tgt_ix": "25-ARR_v2_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_63",
            "tgt_ix": "25-ARR_v2_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "25-ARR_v2_0",
            "tgt_ix": "25-ARR_v2_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_1",
            "tgt_ix": "25-ARR_v2_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_2",
            "tgt_ix": "25-ARR_v2_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_2",
            "tgt_ix": "25-ARR_v2_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_2",
            "tgt_ix": "25-ARR_v2_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_2",
            "tgt_ix": "25-ARR_v2_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_2",
            "tgt_ix": "25-ARR_v2_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_2",
            "tgt_ix": "25-ARR_v2_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_2",
            "tgt_ix": "25-ARR_v2_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_2",
            "tgt_ix": "25-ARR_v2_2@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_2",
            "tgt_ix": "25-ARR_v2_2@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_3",
            "tgt_ix": "25-ARR_v2_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_4",
            "tgt_ix": "25-ARR_v2_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_4",
            "tgt_ix": "25-ARR_v2_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_5",
            "tgt_ix": "25-ARR_v2_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_5",
            "tgt_ix": "25-ARR_v2_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_5",
            "tgt_ix": "25-ARR_v2_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_5",
            "tgt_ix": "25-ARR_v2_5@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_5",
            "tgt_ix": "25-ARR_v2_5@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_5",
            "tgt_ix": "25-ARR_v2_5@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_5",
            "tgt_ix": "25-ARR_v2_5@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_5",
            "tgt_ix": "25-ARR_v2_5@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_6",
            "tgt_ix": "25-ARR_v2_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_7",
            "tgt_ix": "25-ARR_v2_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_7",
            "tgt_ix": "25-ARR_v2_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_7",
            "tgt_ix": "25-ARR_v2_7@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_8",
            "tgt_ix": "25-ARR_v2_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_9",
            "tgt_ix": "25-ARR_v2_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_10",
            "tgt_ix": "25-ARR_v2_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_10",
            "tgt_ix": "25-ARR_v2_10@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_10",
            "tgt_ix": "25-ARR_v2_10@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_10",
            "tgt_ix": "25-ARR_v2_10@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_10",
            "tgt_ix": "25-ARR_v2_10@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_10",
            "tgt_ix": "25-ARR_v2_10@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_11",
            "tgt_ix": "25-ARR_v2_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_11",
            "tgt_ix": "25-ARR_v2_11@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_11",
            "tgt_ix": "25-ARR_v2_11@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_11",
            "tgt_ix": "25-ARR_v2_11@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_11",
            "tgt_ix": "25-ARR_v2_11@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_11",
            "tgt_ix": "25-ARR_v2_11@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_11",
            "tgt_ix": "25-ARR_v2_11@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_11",
            "tgt_ix": "25-ARR_v2_11@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_11",
            "tgt_ix": "25-ARR_v2_11@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_11",
            "tgt_ix": "25-ARR_v2_11@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_12",
            "tgt_ix": "25-ARR_v2_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_12",
            "tgt_ix": "25-ARR_v2_12@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_13",
            "tgt_ix": "25-ARR_v2_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_14",
            "tgt_ix": "25-ARR_v2_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_15",
            "tgt_ix": "25-ARR_v2_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_15",
            "tgt_ix": "25-ARR_v2_15@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_16",
            "tgt_ix": "25-ARR_v2_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_17",
            "tgt_ix": "25-ARR_v2_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_17",
            "tgt_ix": "25-ARR_v2_17@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_17",
            "tgt_ix": "25-ARR_v2_17@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_18",
            "tgt_ix": "25-ARR_v2_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_18",
            "tgt_ix": "25-ARR_v2_18@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_18",
            "tgt_ix": "25-ARR_v2_18@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_18",
            "tgt_ix": "25-ARR_v2_18@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_19",
            "tgt_ix": "25-ARR_v2_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_19",
            "tgt_ix": "25-ARR_v2_19@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_19",
            "tgt_ix": "25-ARR_v2_19@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_19",
            "tgt_ix": "25-ARR_v2_19@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_19",
            "tgt_ix": "25-ARR_v2_19@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_19",
            "tgt_ix": "25-ARR_v2_19@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_19",
            "tgt_ix": "25-ARR_v2_19@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_19",
            "tgt_ix": "25-ARR_v2_19@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_19",
            "tgt_ix": "25-ARR_v2_19@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_19",
            "tgt_ix": "25-ARR_v2_19@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_19",
            "tgt_ix": "25-ARR_v2_19@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_20",
            "tgt_ix": "25-ARR_v2_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_20",
            "tgt_ix": "25-ARR_v2_20@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_21",
            "tgt_ix": "25-ARR_v2_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_22",
            "tgt_ix": "25-ARR_v2_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_23",
            "tgt_ix": "25-ARR_v2_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_23",
            "tgt_ix": "25-ARR_v2_23@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_23",
            "tgt_ix": "25-ARR_v2_23@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_23",
            "tgt_ix": "25-ARR_v2_23@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_24",
            "tgt_ix": "25-ARR_v2_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_24",
            "tgt_ix": "25-ARR_v2_24@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_24",
            "tgt_ix": "25-ARR_v2_24@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_25",
            "tgt_ix": "25-ARR_v2_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_25",
            "tgt_ix": "25-ARR_v2_25@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_26",
            "tgt_ix": "25-ARR_v2_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_26",
            "tgt_ix": "25-ARR_v2_26@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_27",
            "tgt_ix": "25-ARR_v2_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_27",
            "tgt_ix": "25-ARR_v2_27@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_27",
            "tgt_ix": "25-ARR_v2_27@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_27",
            "tgt_ix": "25-ARR_v2_27@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_28",
            "tgt_ix": "25-ARR_v2_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_29",
            "tgt_ix": "25-ARR_v2_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_29",
            "tgt_ix": "25-ARR_v2_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_29",
            "tgt_ix": "25-ARR_v2_29@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_30",
            "tgt_ix": "25-ARR_v2_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_31",
            "tgt_ix": "25-ARR_v2_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_32",
            "tgt_ix": "25-ARR_v2_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_32",
            "tgt_ix": "25-ARR_v2_32@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_32",
            "tgt_ix": "25-ARR_v2_32@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_32",
            "tgt_ix": "25-ARR_v2_32@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_33",
            "tgt_ix": "25-ARR_v2_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_33",
            "tgt_ix": "25-ARR_v2_33@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_34",
            "tgt_ix": "25-ARR_v2_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_34",
            "tgt_ix": "25-ARR_v2_34@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_34",
            "tgt_ix": "25-ARR_v2_34@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_35",
            "tgt_ix": "25-ARR_v2_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_35",
            "tgt_ix": "25-ARR_v2_35@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_35",
            "tgt_ix": "25-ARR_v2_35@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_35",
            "tgt_ix": "25-ARR_v2_35@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_35",
            "tgt_ix": "25-ARR_v2_35@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_36",
            "tgt_ix": "25-ARR_v2_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_36",
            "tgt_ix": "25-ARR_v2_36@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_36",
            "tgt_ix": "25-ARR_v2_36@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_36",
            "tgt_ix": "25-ARR_v2_36@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_37",
            "tgt_ix": "25-ARR_v2_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_38",
            "tgt_ix": "25-ARR_v2_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_38",
            "tgt_ix": "25-ARR_v2_38@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_38",
            "tgt_ix": "25-ARR_v2_38@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_38",
            "tgt_ix": "25-ARR_v2_38@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_39",
            "tgt_ix": "25-ARR_v2_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_40",
            "tgt_ix": "25-ARR_v2_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_40",
            "tgt_ix": "25-ARR_v2_40@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_40",
            "tgt_ix": "25-ARR_v2_40@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_40",
            "tgt_ix": "25-ARR_v2_40@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_40",
            "tgt_ix": "25-ARR_v2_40@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_41",
            "tgt_ix": "25-ARR_v2_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_42",
            "tgt_ix": "25-ARR_v2_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_42",
            "tgt_ix": "25-ARR_v2_42@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_42",
            "tgt_ix": "25-ARR_v2_42@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_43",
            "tgt_ix": "25-ARR_v2_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_44",
            "tgt_ix": "25-ARR_v2_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_44",
            "tgt_ix": "25-ARR_v2_44@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_44",
            "tgt_ix": "25-ARR_v2_44@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_45",
            "tgt_ix": "25-ARR_v2_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_45",
            "tgt_ix": "25-ARR_v2_45@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_45",
            "tgt_ix": "25-ARR_v2_45@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_45",
            "tgt_ix": "25-ARR_v2_45@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_45",
            "tgt_ix": "25-ARR_v2_45@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_46",
            "tgt_ix": "25-ARR_v2_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_47",
            "tgt_ix": "25-ARR_v2_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_47",
            "tgt_ix": "25-ARR_v2_47@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_48",
            "tgt_ix": "25-ARR_v2_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_49",
            "tgt_ix": "25-ARR_v2_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_49",
            "tgt_ix": "25-ARR_v2_49@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_49",
            "tgt_ix": "25-ARR_v2_49@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_49",
            "tgt_ix": "25-ARR_v2_49@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_49",
            "tgt_ix": "25-ARR_v2_49@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_49",
            "tgt_ix": "25-ARR_v2_49@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_49",
            "tgt_ix": "25-ARR_v2_49@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_49",
            "tgt_ix": "25-ARR_v2_49@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_50",
            "tgt_ix": "25-ARR_v2_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_50",
            "tgt_ix": "25-ARR_v2_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_51",
            "tgt_ix": "25-ARR_v2_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_51",
            "tgt_ix": "25-ARR_v2_51@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_52",
            "tgt_ix": "25-ARR_v2_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_52",
            "tgt_ix": "25-ARR_v2_52@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_53",
            "tgt_ix": "25-ARR_v2_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_53",
            "tgt_ix": "25-ARR_v2_53@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_54",
            "tgt_ix": "25-ARR_v2_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_55",
            "tgt_ix": "25-ARR_v2_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_56",
            "tgt_ix": "25-ARR_v2_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_57",
            "tgt_ix": "25-ARR_v2_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_57",
            "tgt_ix": "25-ARR_v2_57@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_58",
            "tgt_ix": "25-ARR_v2_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_58",
            "tgt_ix": "25-ARR_v2_58@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_59",
            "tgt_ix": "25-ARR_v2_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_59",
            "tgt_ix": "25-ARR_v2_59@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_59",
            "tgt_ix": "25-ARR_v2_59@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_60",
            "tgt_ix": "25-ARR_v2_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_61",
            "tgt_ix": "25-ARR_v2_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_61",
            "tgt_ix": "25-ARR_v2_61@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_62",
            "tgt_ix": "25-ARR_v2_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_62",
            "tgt_ix": "25-ARR_v2_62@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_62",
            "tgt_ix": "25-ARR_v2_62@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_63",
            "tgt_ix": "25-ARR_v2_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_64",
            "tgt_ix": "25-ARR_v2_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_64",
            "tgt_ix": "25-ARR_v2_64@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_64",
            "tgt_ix": "25-ARR_v2_64@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_65",
            "tgt_ix": "25-ARR_v2_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_66",
            "tgt_ix": "25-ARR_v2_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_67",
            "tgt_ix": "25-ARR_v2_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_68",
            "tgt_ix": "25-ARR_v2_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_69",
            "tgt_ix": "25-ARR_v2_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_70",
            "tgt_ix": "25-ARR_v2_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_71",
            "tgt_ix": "25-ARR_v2_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_72",
            "tgt_ix": "25-ARR_v2_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_73",
            "tgt_ix": "25-ARR_v2_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_74",
            "tgt_ix": "25-ARR_v2_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_75",
            "tgt_ix": "25-ARR_v2_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_76",
            "tgt_ix": "25-ARR_v2_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_77",
            "tgt_ix": "25-ARR_v2_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_78",
            "tgt_ix": "25-ARR_v2_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_79",
            "tgt_ix": "25-ARR_v2_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_80",
            "tgt_ix": "25-ARR_v2_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_81",
            "tgt_ix": "25-ARR_v2_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_82",
            "tgt_ix": "25-ARR_v2_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_83",
            "tgt_ix": "25-ARR_v2_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_84",
            "tgt_ix": "25-ARR_v2_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_85",
            "tgt_ix": "25-ARR_v2_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_86",
            "tgt_ix": "25-ARR_v2_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_87",
            "tgt_ix": "25-ARR_v2_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_88",
            "tgt_ix": "25-ARR_v2_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_89",
            "tgt_ix": "25-ARR_v2_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_90",
            "tgt_ix": "25-ARR_v2_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_91",
            "tgt_ix": "25-ARR_v2_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_92",
            "tgt_ix": "25-ARR_v2_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_93",
            "tgt_ix": "25-ARR_v2_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_94",
            "tgt_ix": "25-ARR_v2_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_95",
            "tgt_ix": "25-ARR_v2_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_96",
            "tgt_ix": "25-ARR_v2_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_97",
            "tgt_ix": "25-ARR_v2_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_98",
            "tgt_ix": "25-ARR_v2_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_99",
            "tgt_ix": "25-ARR_v2_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_100",
            "tgt_ix": "25-ARR_v2_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "25-ARR_v2_101",
            "tgt_ix": "25-ARR_v2_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 703,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "doc_id": "25-ARR",
        "version": 2
    }
}