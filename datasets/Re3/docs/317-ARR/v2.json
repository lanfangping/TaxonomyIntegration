{
    "nodes": [
        {
            "ix": "317-ARR_v2_0",
            "content": "Neural reality of argument structure constructions",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_2",
            "content": "In lexicalist linguistic theories, argument structure is assumed to be predictable from the meaning of verbs. As a result, the verb is the primary determinant of the meaning of a clause. In contrast, construction grammarians propose that argument structure is encoded in constructions (or form-meaning pairs) that are distinct from verbs. Decades of psycholinguistic research have produced substantial empirical evidence in favor of the construction view. Here we adapt several psycholinguistic studies to probe for the existence of argument structure constructions (ASCs) in Transformerbased language models (LMs). First, using a sentence sorting experiment, we find that sentences sharing the same construction are closer in embedding space than sentences sharing the same verb. Furthermore, LMs increasingly prefer grouping by construction with more input data, mirroring the behaviour of non-native language learners. Second, in a \"Jabberwocky\" priming-based experiment, we find that LMs associate ASCs with meaning, even in semantically nonsensical sentences. Our work offers the first evidence for ASCs in LMs and highlights the potential to devise novel probing methods grounded in psycholinguistic research.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "317-ARR_v2_4",
            "content": "Pretrained Transformer-based language models (LMs) such as BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019b) have recently achieved impressive results on many natural language tasks, spawning a new interdisciplinary field of aligning LMs with linguistic theory and probing the linguistic capabilities of LMs (Linzen and Baroni, 2021). Most probing work so far has investigated the linguistic knowledge of LMs on phenomena such as agreement, binding, licensing, and movement (Warstadt et al., 2020a;Hu et al., 2020)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_5",
            "content": "Bob with a particular focus on determining whether a sentence is linguistically acceptable (Sch\u00fctze, 1996). Relatively little work has attempted to determine whether the linguistic knowledge induced by LMs is more similar to a formal grammar of the sort postulated by mainstream generative linguistics (Chomsky, 1965(Chomsky, , 1981(Chomsky, , 1995, or to a network of form-meaning pairs as advocated by construction grammar (Goldberg, 1995(Goldberg, , 2006.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_6",
            "content": "One area where construction grammar disagrees with many generative theories of language is in the analysis of the argument structure of verbs, that is, the specification of the number of arguments that a verb takes, their semantic relation to the verb, and their syntactic form (Levin and Rappaport Hovav, 2005). Lexicalist theories were long dominant in generative grammar (Chomsky, 1981;Kaplan and Bresnan, 1982;Pollard and Sag, 1987). In lexicalist theories, argument structure is assumed to be encoded in the lexical entry of the verb: for example, the verb visit is lexically specified as being transitive and as requiring a noun phrase object (Chomsky, 1986). In contrast, construction grammar suggests that argument structure is encoded in form-meaning pairs known as argument structure constructions (ASCs, Figure 1), which are distinct from verbs. The argument structure of a verb is determined by pairing it with an ASC (Goldberg, 1995). To date, a substantial body of psycholinguistic work has provided evidence for the psychological reality of ASCs in sentence sorting (Bencini and Goldberg, 2000;Gries and Wulff, 2005), priming (Ziegler et al., 2019), and novel verb experiments (Kaschak and Glenberg, 2000;Johnson and Goldberg, 2013).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_7",
            "content": "Here we connect basic research in ASCs with neural probing by adapting several psycholinguistic studies to Transformer-based LMs and show evidence for the neural reality of ASCs. Our first case study is based on sentence sorting (Bencini and Goldberg, 2000); we discover that in English, German, Italian, and Spanish, LMs consider sentences that share the same construction to be more semantically similar than sentences sharing the main verb. Furthermore, this preference for constructional meaning only manifests in larger LMs (trained with more data), whereas smaller LMs rely on the main verb, an easily accessible surface feature. Human experiments with non-native speakers found a similarly increased preference for constructional meaning in more proficient speakers (Liang, 2002;Baicchi and Della Putta, 2019), suggesting commonalities in language acquisition between LMs and humans.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_8",
            "content": "Our second case study is based on nonsense \"Jabberwocky\" sentences that nevertheless convey meaning when they are arranged in constructional templates (Johnson and Goldberg, 2013). We adapt the original priming experiment to LMs and show that RoBERTa is able to derive meaning from ASCs, even without any lexical cues. This finding offers counter-evidence to earlier claims that LMs are relatively insensitive to word order when constructing sentence meaning (Yu and Ettinger, 2020;Sinha et al., 2021). Our source code and data are available at: https://github.com/SPOClab-ca/ neural-reality-constructions.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_9",
            "content": "Psycholinguistic background",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "317-ARR_v2_10",
            "content": "Construction grammar and ASCs",
            "ntype": "title",
            "meta": {
                "section": "2.1"
            }
        },
        {
            "ix": "317-ARR_v2_11",
            "content": "Construction grammar is a family of linguistic theories proposing that all linguistic knowledge consists of constructions: pairings between form and meaning where some aspects of form or meaning are not predictable from their parts (Fillmore et al., 1988;Kay and Fillmore, 1999;Goldberg, 1995Goldberg, , 2006. Common examples include idiomatic expressions such as under the weather (meaning \"to feel unwell\"), but many linguistic patterns are constructions, including morphemes (e.g., -ify), words (e.g., apple), and abstract patterns like the ditransitive and passive. In contrast to lexicalist theories of argument structure, construction grammar rejects the dichotomy between syntax and lexicon. In contrast to transformational grammar, it rejects any distinction between surface and underlying structure.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_12",
            "content": "We focus on a specific family of constructions for which there is an ample body of psycholinguistic evidence: argument structure constructions (ASCs). ASCs are constructions that specify the argument structure of a verb (Goldberg, 1995). In the lexicalist, verb-centered view, argument structure is a lexical property of the verb, and the main verb of a sentence determines the form and meaning of the sentence (Chomsky, 1981;Kaplan and Bresnan, 1982;Pollard and Sag, 1987;Levin and Rappaport Hovav, 1995). For example, sneeze is intransitive (allowing no direct object) and hit is transitive (requiring one direct object). However, lexicalist theories encounter difficulties with sentences like \"he sneezed the napkin off the table\" since intransitive verbs are not permitted to have object arguments.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_13",
            "content": "Rather than assuming multiple implausible senses for the verb \"sneeze\" with different argument structures, Goldberg (1995) proposed that ASCs operate on an arbitrary verb, altering its argument structure while at the same time modifying its meaning. For example, the caused-motion ASC adds a direct object and a path argument to the verb sneeze, with the semantics of causing the object to move along the path. Other ASCs include the transitive, ditransitive, and resultative (Figure 1), which specify the argument structure of a verb and interact with its meaning in different ways.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_14",
            "content": "Psycholinguistic evidence for ASCs",
            "ntype": "title",
            "meta": {
                "section": "2.2"
            }
        },
        {
            "ix": "317-ARR_v2_15",
            "content": "Sentence sorting. Several psycholinguistic studies have found evidence for argument structure con-",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_16",
            "content": "Caused-motion Resultative Throw Anita threw the hammer. Chris threw Linda the pencil.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_17",
            "content": "Pat threw the keys onto the roof.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_18",
            "content": "Lyn threw the box apart.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_19",
            "content": "Michelle got the book.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_20",
            "content": "Beth got Liz an invitation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_21",
            "content": "Laura got the ball into the net.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_22",
            "content": "Dana got the mattress inflated.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_23",
            "content": "Barbara sliced the bread. Jennifer sliced Terry an apple.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_24",
            "content": "Meg sliced the ham onto the plate.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_25",
            "content": "Nancy sliced the tire open.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_26",
            "content": "Audrey took the watch. Paula took Sue a message.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_27",
            "content": "Kim took the rose into the house.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_28",
            "content": "Rachel took the wall down.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_29",
            "content": "Table 1: Stimuli from Bencini and Goldberg (2000), consisting of a 4x4 design, with 4 different verbs and 4 different argument structure constructions.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_30",
            "content": "structions using experimental methods. Among these, Bencini and Goldberg (2000) used a sentence sorting task to determine whether the verb or construction in a sentence was the main determinant of sentence meaning. 17 participants were given 16 index cards with sentences containing 4 verbs (throw, get, slice, and take) and 4 constructions (transitive, ditransitive, caused-motion, and resultative) and were instructed to sort them into 4 piles by overall sentence meaning (Table 1). The experimenters measured the deviation to a purely verb-based or construction-based sort, and found that on average, the piles were closer to a construction sort.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_31",
            "content": "Non-native sentence sorting. The same set of experimental stimuli was used with L2 (non-native) English speakers. Gries and Wulff (2005) ran the experiment with 22 German native speakers, who preferred the construction-based sort over the verbbased sort, showing that constructional knowledge is not limited to native speakers. Liang (2002) ran the experiment on Chinese native speakers of 3 different English levels (46 beginner, 31 intermediate, and 33 advanced), and found that beginners preferred a verb-based sort, while advanced learners produced construction-based sorts similar to native speakers (Figure 2). Likewise, Baicchi and Della Putta (2019) found the same result in Italian native speakers with B1 and B2 English proficiency levels. Overall, these studies show evidence for ASCs in the mental representations of native and L2 English speakers alike, and furthermore, preference for constructional over verb sorting increases with increasing English proficiency.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_32",
            "content": "Multilingual sentence sorting. Similar sentence sorting experiments have been conducted in other languages, with varying results. Kirsch (2019) ran a sentence sorting experiment in German with 40 participants and found that they mainly sorted by verb but rarely by construction. Baicchi and Della Putta (2019) ran an experiment with non-native learners of Italian (15 participants of B1 level and 10 participants of B2 level): both groups preferred the constructional sort, and similar to Liang (2002), the B2 learners sorted more by construction than the B1 learners. V\u00e1zquez ( 2004) ran an experiment in Spanish with 16 participants, and found approximately equal proportions of constructions and verb sort. In Italian and Spanish, some different constructions were substituted as not all of the English constructions had an equivalent in these languages; see the appendix for the complete set of stimuli in each language.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_33",
            "content": "Priming. Another line of psycholinguistic evidence comes from priming studies. Priming refers to the condition where exposure to a (prior) stimulus influences the response to a later stimulus (Pickering and Ferreira, 2008). Bock and Loebell (1990) found that participants were more likely to produce sentences of a given syntactic structure when primed with a sentence of the same structure; Ziegler et al. (2019) argued that Bock and Loebell (1990) did not adequately control for lexical overlap, and instead, they showed that the construction must be shared for the priming effect to occur, not just shared abstract syntax.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_34",
            "content": "Novel verbs. Even with unfamiliar words, there is evidence that constructions are associated with meaning. Kaschak and Glenberg (2000) constructed sentences with novel denominal verbs and found that participants were more likely to interpret a transfer event when the denominal verb was used in a ditransitive sentence (Tom crutched Lyn an apple) than a transitive one (Tom crutched an apple).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_35",
            "content": "Johnson and Goldberg (2013) used a \"Jabberwocky\" priming task to show that abstract constructional templates are associated with meaning. Participants were primed with a nonsense sentence of a given construction (e.g., He daxed her the norp for the ditransitive construction), followed by a lexical decision task of quickly deciding if a string of characters was a real English word or a non-word. The word in the decision task was semantically congruent with the construction (gave) or incongruent (made); furthermore, they experimented with target words that were high-frequency (gave), lowfrequency (handed), or semantically related but not associated with the construction (transferred). They found priming effects (faster lexical decision times) in all three conditions, with the strongest effect for the high-frequency condition, followed by the low-frequency and the semantically nonassociate conditions.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_36",
            "content": "We adapt several of these psycholinguistic studies to LMs: the sentence sorting experiments in Case study 1, and the Jabberwocky priming experiment in Case study 2. We choose these studies because their designs allow for thousands of stimuli sentences to be generated automatically using templates, avoiding issues caused by small sample sizes from manually constructed sentences.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_37",
            "content": "3 Related work in NLP",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_38",
            "content": "Linguistic probing of LMs",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "317-ARR_v2_39",
            "content": "Many studies have probed for various aspects of syntax in LSTMs and Transformer-based LMs. Linzen et al. (2016) tested LSTMs on their ability to capture subject-verb agreement, using templates to generate test data. This idea was extended by BLiMP (Warstadt et al., 2020a), a suite encompassing 67 linguistic phenomena, including fillergap effects, NPI licensing, and ellipsis; Hu et al. (2020) released a similar test suite. Template generation is a convenient method to construct stimuli exhibiting specific linguistic properties, but alternative approaches include CoLA (Warstadt et al., 2019), which compiled an acceptability benchmark of sentences drawn from linguistic publications, and Gulordava et al. (2018), who perturbed natural sentences to study LMs' knowledge of agreement on nonsense sentences. We refer to Linzen and Baroni (2021) for a comprehensive review of the linguistic probing literature.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_40",
            "content": "So far, relatively few papers approached LM probing from a construction grammar perspective. Madabushi et al. (2020) probed for BERT's knowledge of constructions via a sentence pair classification task of predicting whether two sentences share the same construction. Their probe was based on data from Dunn (2017), who used an unsupervised algorithm to extract plausible constructions from corpora based on association strength. How-ever, the linguistic validity of these automatically induced constructions is uncertain, and there is currently no human-labelled wide-coverage construction grammar dataset in any language suitable for probing. Other computational work focused on a few specific constructions, such as identifying caused-motion constructions in corpora (Hwang and Palmer, 2015) and annotating constructions related to causal language (Dunietz et al., 2015). Lebani and Lenci (2016) is the most similar to our work: they probed distributional vector space models for ASCs based on the Jabberwocky priming experiment by Johnson and Goldberg (2013).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_41",
            "content": "Psycholinguistic treatment of LMs",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "317-ARR_v2_42",
            "content": "Some recent probing studies adapted methods and data from psycholinguistic research, treating LMs as psycholinguistic participants. Using a cloze completion task, Ettinger (2020) found that BERT was less sensitive than humans at commonsense inferences and detecting role reversals, and fails completely at understanding negation. Michaelov and Bergen (2020) compared LM surprisals with the N400 (a measure of human language processing difficulty) across a wide range of conditions; used psycholinguistic stimuli and found that LMs exhibit different layerwise surprisal patterns for morphosyntactic, semantic, and commonsense anomalies. Wilcox et al. (2021) compared LM and human sensitivities to syntactic violations using a maze task to collect human reaction times. Prasad et al. (2019); Misra et al. (2020) investigated whether LMs are sensitive to priming effects like humans. The advantage of psycholinguistic data is that they are carefully constructed by expert linguists to test theories of language processing in humans; however, their small sample size makes it challenging to make statistically meaningful conclusions when the (oft-sparse) experimental stimuli are used to probe a language model.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_43",
            "content": "Case study 1: Sentence sorting",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "317-ARR_v2_44",
            "content": "This section describes our adaptation of the sentence sorting experiments to Transformer LMs.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_45",
            "content": "Methodology",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "317-ARR_v2_46",
            "content": "Models. To simulate varying non-native English proficiency levels, we use MiniBERTa models (Warstadt et al., 2020b) 100M, and 1B tokens. We also use the base RoBERTa model (Liu et al., 2019b), trained with 30B tokens. In other languages, there are no available pretrained checkpoints with varying amounts of pretraining data, so we use the mBERT model (Devlin et al., 2019) and a monolingual Transformer LM in each language. 2 We obtain sentence embeddings for our models by taking the average of their contextual token embeddings at the secondto-last layer (i.e., layer 11 for base RoBERTa). We use the second-to-last because the last layer is more specialized for the LM pretraining objective and less suitable for sentence embeddings (Liu et al., 2019a). Template generation. We use templates to generate stimuli similar to the 4x4 design in the Bencini and Goldberg (2000) experiment. To ensure an adequate sample size, we run multiple empirical trials. In each trial, we sample 4 random distinct verbs from a pool of 10 verbs that are compatible with all 4 constructions (cut, hit, get, kick, pull, punch, push, slice, tear, throw). We then randomly fill in the slots for proper names, objects, and complements for each sentence according to its verb, such that the sentence is semantically coherent, and there is no lexical overlap among the sentences of any construction. Table 3 in the ap-2 We use monolingual German and Italian models from https://github.com/dbmdz/berts, and the monolingual Spanish model from Ca\u00f1ete et al. (2020). pendix shows a set of template-generated sentences. In English, we generate 1000 sets of stimuli using this procedure; for other languages, we use the original stimuli from their respective publications.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_47",
            "content": "Evaluation. Similar to the human experiments, we group the sentence embeddings into 4 clusters (not necessarily of the same size) using agglomerative clustering by Euclidean distance (Pedregosa et al., 2011). We then compute the deviation to a pure construction and pure verb sort using the Hungarian algorithm for optimal bipartite matching. This measures the minimal number of cluster assignment changes necessary to reach a pure construction or verb sort, ranging from 0 to 12. Thus, lower construction deviation indicates that constructional information is more salient in the LM's embeddings.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_48",
            "content": "Results and interpretation",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "317-ARR_v2_49",
            "content": "Figure 2 shows the LM sentence sorting results for English. All differences are statistically significant (p < .001). The smallest 1M MiniBERTa model is the only LM to prefer verb over construction sorting, and as the amount of pretraining data grows, the LMs increasingly prefer sorting by construction instead of by verb. This closely mirrors the trend observed in the human experiments.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_50",
            "content": "The results for multilingual sorting are shown in Figure 3. Both mBERT and the monolingual LMs consistently prefer constructional sorting over verb (Kirsch, 2019), Italian (Baicchi and Della Putta, 2019), and Spanish (V\u00e1zquez, 2004). LM results are obtained using the same stimuli; we use both mBERT and a monolingual LM for each language.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_51",
            "content": "sorting in all three languages, whereas the results from the human experiments are less consistent.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_52",
            "content": "Our results show that RoBERTa can generalize meaning from abstract constructions without lexical overlap. Only larger LMs and English speakers of more advanced proficiency are able to make this generalization, while smaller LMs and less proficient speakers derive meaning more from surface features like lexical content. This finding agrees with Warstadt et al. (2020b), who found that larger LMs have an inductive bias towards linguistic generalizations, while smaller LMs have an inductive bias towards surface generalizations; this may explain the success of large LMs on downstream tasks. A small quantity of data (10M tokens) is sufficient for LMs to prefer the constructional sort, indicating that ASCs are relatively easy to learn: roughly on par with other types of linguistic knowledge, and requiring less data than commonsense knowledge (Zhang et al., 2021;Liu et al., 2021).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_53",
            "content": "We note some limitations in these results, and reasons to avoid drawing unreasonably strong conclusions from them. Human sentence sorting experiments can be influenced by minor differences in the experimental setup: Bencini and Goldberg (2000) obtained significantly different results in two runs that only differed on the precise wording of instructions. In the German experiment (Kirsch, 2019), the author hypothesized that the participants were influenced by a different experiment that they had completed before the sentence sorting one. Given this experimental variation, we cannot attribute differences across languages to differences in their linguistic typology. Although LMs do not suffer from the same experimental variation, we cannot conclude statistical significance from the multilingual experiments, where only one set of stimuli is available in each language.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_54",
            "content": "Case study 2: Jabberwocky constructions",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "317-ARR_v2_55",
            "content": "We next adapt the \"Jabberwocky\" priming experiment from Johnson and Goldberg (2013) to LMs, and make several changes to the original setup to better assess the capabilities of LMs. Priming is a standard experimental paradigm in psycholinguistic research, but it is not directly applicable to LMs: existing methods simulate priming either by applying additional fine-tuning (Prasad et al., 2019), or by concatenating sentences that typically do not co-occur in natural text (Misra et al., 2020). Therefore, we instead propose a method to probe LMs for the same linguistic information using only distance measurements on their contextual embeddings.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_56",
            "content": "Methodology",
            "ntype": "title",
            "meta": {
                "section": "5.1"
            }
        },
        {
            "ix": "317-ARR_v2_57",
            "content": "Template generation. We generate sentences for the four constructions randomly using the templates in Table 2. Instead of filling nonce words like norp into the templates as in the original study, we take an approach similar to Gulordava et al. (2018) and generate 5000 sentences for each construction She traded her the epicenter gave made put took",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_58",
            "content": "Ditransitive S/he V-ed him/her the N. She traded her the epicenter. He flew her the donut.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_59",
            "content": "Resultative S/he V-ed it Adj.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_60",
            "content": "He cut it seasonal. She surged it civil.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_61",
            "content": "Caused-motion S/he V-ed it on the N. He registered it on the diamond. She awarded it on the corn.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_62",
            "content": "S/he V-ed it from him/her. He declined it from her. She drove it from him. by randomly filling real words of the appropriate part-of-speech into construction templates (Table 2). This gives nonsense sentences like \"She traded her the epicenter\"; we refer to these random words as Jabberwocky words. By using real words, we avoid any potential instability from feeding tokens into the model that it has never seen during pretraining. We obtain a set of singular nouns, past tense verbs, and adjectives from the Penn Treebank (Marcus et al., 1993), excluding words with fewer than 10 occurrences. Verb embeddings. Our probing strategy is based on the assumption that the contextual embedding for a verb captures its meaning in context. Therefore, if LMs associate ASCs with meaning, we should expect the contextual embedding for the Jabberwocky verb to contain the meaning of the construction. Specifically, we measure the Euclidean distance to a prototype verb for each construction (Figure 4). These are verbs that Johnson and Goldberg (2013) selected whose meaning closely resembles the construction's meaning: gave, made, put, and took for the ditransitive, resultative, caused-motion, and removal constructions, respectively. 3 We also run the same setup using lower frequency prototype verbs from the same study: handed, turned, placed, and removed. 4 As a control, we measure the Euclidean distance to the prototype verbs of the other three unrelated constructions.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_63",
            "content": "The prototype verb embeddings are generated by taking the average across their contextual embeddings across a 4M-word subset of the British National Corpus (BNC; Leech (1992)). We use the second-to-last layer of RoBERTa-base, and in cases where a verb is split into multiple subwords, we take the embedding of the first subword token as the verb embedding.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_64",
            "content": "Results and interpretation",
            "ntype": "title",
            "meta": {
                "section": "5.2"
            }
        },
        {
            "ix": "317-ARR_v2_65",
            "content": "We find that the Euclidean distance between the prototype and Jabberwocky verb embeddings is significantly lower (p < .001) when the verb is congruent with the construction than when they are incongruent, and this is observed for both high and low-frequency prototype verbs (Figure 5). Examining the individual constructions and verbs (Figure 6), we note that in the high-frequency scenario, the lowest distance prototype verb is always the congruent one, for all four constructions. In the low-frequency scenario, the result is less consis-11.899 12.295 12.567 12.328 11.924 11.701 11.868 11.864 11.691 11.593 11.395 11.599 11.740 11.954 11.936 tent: the congruent verb is not always the lowest distance one, although it is always still at most the second-lowest distance out of the four.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_66",
            "content": "The main result holds for both high and lowfrequency scenarios, but the correct prototype verb is associated more consistently in the highfrequency case. This agrees with Wei et al. (2021), who found that LMs have greater difficulty learning the linguistic properties of less frequent words. We also note that the Euclidean distances are higher overall in the low-frequency scenario, which is consistent with previous work that found lower frequency words to occupy a peripheral region of the embedding space .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_67",
            "content": "Potential confounds",
            "ntype": "title",
            "meta": {
                "section": "5.3"
            }
        },
        {
            "ix": "317-ARR_v2_68",
            "content": "In any experiment, one must be careful to ensure that the observed patterns are due to the phenomenon under investigation rather than confounding factors. We discuss potential confounds arising from lexical overlap, anisotropy of contextual embeddings, and neighboring words.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_69",
            "content": "Lexical overlap. The randomized experiment design ensures that the Jabberwocky words cannot be lexically biased towards any construction, since each verb is equally likely to occur in every construction. Technically, the lexical content in the four constructions are not identical: i.e., words such as \"from\" (occurring only in the removal construction) or \"on\" (in the caused-motion construction) may provide hints to the sentence meaning. However, the ditransitive and resultative constructions do not contain any such informative words, yet RoBERTa still associates the correct prototype verb for these constructions, so we consider it unlikely to be relying solely on lexical overlap. There is substantial evidence that RoBERTa is able to associate abstract constructional templates with their meaning without lexical cues. This result is perhaps surprising, given that previous work found that LMs are relatively insensitive to word order in compositional phrases (Yu and Ettinger, 2020) and downstream inference tasks (Sinha et al., 2021;Pham et al., 2021), where their performance can be largely attributed to lexical overlap.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_70",
            "content": "Anisotropy. Recent probing work have found that contextual embeddings suffer from anisotropy, where embeddings lie in a narrow cone and have much higher cosine similarity than expected if they were directionally uniform (Ethayarajh, 2019). Furthermore, a small number of dimensions dominate geometric measures such as Euclidean and cosine distance, resulting in a degradation of representation quality (Kovaleva et al., 2021;Timkey and van Schijndel, 2021). Since our experiments rely heavily on Euclidean distance, anisotropy is a significant concern. Following Timkey and van Schijndel (2021), we perform standardization by subtracting the mean vector and dividing each dimension by its standard deviation, where the mean and standard deviation for each dimension is computed from a sample of the BNC. We observe little difference after standardization: in both the high and low frequency scenarios, the Euclidean distances are lower for the congruent than the incongruent conditions, by a similar margin compared to the original experiment without standardization. We also run standardization on the first case study, and find that the results remain essentially unchanged: smaller LMs still prefer verb sorting while larger LMs prefer construction sorting. Thus, neither of our experiments appear to be affected by anisotropy.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_71",
            "content": "Neighboring words. A final confounding factor is our assumption that RoBERTa's contextual embeddings represent word meaning, when in reality, they contain a mixture of syntactic and semantic information. Contextual embeddings are known to contain syntax trees (Hewitt and Manning, 2019) and linguistic information about neighboring words in a sentence (Klafka and Ettinger, 2020); although previous work did not consider ASCs, it is plausible that our verb embeddings leak information about the sentence's construction in a similar manner. If this were the case, the prototype verb embedding for gave would contain not only the semantics of transfer that we intended, but also information about its usual syntactic form 5 of \"S gave NP1 NP2\", and both would be captured by our Euclidean distance measurement. Controlling for this syntactic confound is difficult -one could alternatively probe for transfer semantics without syntactic confounds using a natural language inference setup (e.g., whether the sentence entails the statement \"NP1 received NP2\"), but we leave further exploration of this idea to future work.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_72",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "317-ARR_v2_73",
            "content": "We find evidence for argument structure constructions in Transformer language models from two separate angles: sentence sorting and Jabberwocky construction experiments. Our work extends the existing body of literature on LM probing by taking a constructionist instead of generative approach to linguistic probing. Our sentence sorting experiments identified a striking resemblance between humans' and LMs' internal language representations as LMs are exposed to increasing quantities of data, despite the differences between neural language models and the human brain. Our two studies suggest that LMs are able to derive meaning from abstract constructional templates with minimal lexical overlap. Both sets of experiments were inspired by psycholinguistic studies, which we adapted to fit the capabilities of LMs -this illustrates the potential for future work on grounding LM probing methodologies in psycholinguistic research.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_74",
            "content": "We use principal components analysis (PCA) to visualize the sentence sorting experiment for the MiniBERTa models (trained with 1M and 100M tokens) and RoBERTa-base (trained with 30B tokens). In RoBERTa, there is strong evidence of clustering based on constructions; the effect is unclear in the 100M model and nonexistent in the 1M model (Figure 7). This visually confirms our quantitative evaluation based on the construction and verb deviation metrics (Figure 2).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_75",
            "content": "Table 3 shows an example set of templategenerated stimuli for sentence sorting: we generate 1000 similar sets of 16 sentences to increase the sample size. We also present the sentence sorting stimuli for German (Table 4), Italian (Table 5), and Spanish (Table 6). German uses the same four constructions as English. Italian does not have the ditransitive construction but instead uses the prepositional dative construction to express transfer semantics. Spanish has no equivalents for the causedmotion and resultative constructions, so the authors in that experiment instead used the unplanned reflexive (expressing accidental or unplanned events), and the middle construction (expressing states pertaining to the subject).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "317-ARR_v2_76",
            "content": "UNKNOWN, None, 2019, Constructions at work in foreign language learners' mind: A comparison between two sentence-sorting experiments with English and Italian learners. Review of Cognitive Linguistics. Published under the auspices of the Spanish Cognitive Linguistics Association, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Constructions at work in foreign language learners' mind: A comparison between two sentence-sorting experiments with English and Italian learners. Review of Cognitive Linguistics. Published under the auspices of the Spanish Cognitive Linguistics Association",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_77",
            "content": "M Giulia, Adele Bencini,  Goldberg, The contribution of argument structure constructions to sentence meaning, 2000, Journal of Memory and Language, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "M Giulia",
                    "Adele Bencini",
                    " Goldberg"
                ],
                "title": "The contribution of argument structure constructions to sentence meaning",
                "pub_date": "2000",
                "pub_title": "Journal of Memory and Language",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_78",
            "content": "Kathryn Bock, Helga Loebell, Framing sentences, 1990, Cognition, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "Kathryn Bock",
                    "Helga Loebell"
                ],
                "title": "Framing sentences",
                "pub_date": "1990",
                "pub_title": "Cognition",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_79",
            "content": "UNKNOWN, None, 2003, The gradience of the dative alternation. Unpublished manuscript, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": null,
                "title": null,
                "pub_date": "2003",
                "pub_title": "The gradience of the dative alternation. Unpublished manuscript",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_80",
            "content": "UNKNOWN, None, 2020, Spanish pre-trained BERT model and evaluation data, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Spanish pre-trained BERT model and evaluation data",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_81",
            "content": "UNKNOWN, None, 1965, Aspects of the Theory of Syntax, MIT Press.",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": null,
                "title": null,
                "pub_date": "1965",
                "pub_title": "Aspects of the Theory of Syntax",
                "pub": "MIT Press"
            }
        },
        {
            "ix": "317-ARR_v2_82",
            "content": "UNKNOWN, None, 1981, Lectures on Government and Binding, Foris Publications.",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": null,
                "title": null,
                "pub_date": "1981",
                "pub_title": "Lectures on Government and Binding",
                "pub": "Foris Publications"
            }
        },
        {
            "ix": "317-ARR_v2_83",
            "content": "UNKNOWN, None, 1986, Knowledge of Language, Praeger.",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": null,
                "title": null,
                "pub_date": "1986",
                "pub_title": "Knowledge of Language",
                "pub": "Praeger"
            }
        },
        {
            "ix": "317-ARR_v2_84",
            "content": "UNKNOWN, None, 1995, The Minimalist Program, The MIT Press.",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": null,
                "title": null,
                "pub_date": "1995",
                "pub_title": "The Minimalist Program",
                "pub": "The MIT Press"
            }
        },
        {
            "ix": "317-ARR_v2_85",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Jacob Devlin",
                    "Ming-Wei Chang",
                    "Kenton Lee",
                    "Kristina Toutanova"
                ],
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_86",
            "content": "Jesse Dunietz, Lori Levin, Jaime Carbonell, Annotating causal language using corpus lexicography of constructions, 2015, Proceedings of The 9th Linguistic Annotation Workshop, .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Jesse Dunietz",
                    "Lori Levin",
                    "Jaime Carbonell"
                ],
                "title": "Annotating causal language using corpus lexicography of constructions",
                "pub_date": "2015",
                "pub_title": "Proceedings of The 9th Linguistic Annotation Workshop",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_87",
            "content": "Jonathan Dunn, Computational learning of construction grammars, 2017, Language and Cognition, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Jonathan Dunn"
                ],
                "title": "Computational learning of construction grammars",
                "pub_date": "2017",
                "pub_title": "Language and Cognition",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_88",
            "content": "Kawin Ethayarajh, How contextual are contextualized word representations? comparing the geometry of BERT, ELMo, and GPT-2 embeddings, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Kawin Ethayarajh"
                ],
                "title": "How contextual are contextualized word representations? comparing the geometry of BERT, ELMo, and GPT-2 embeddings",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_89",
            "content": "Allyson Ettinger, What BERT is not: Lessons from a new suite of psycholinguistic diagnostics for language models, 2020, Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    "Allyson Ettinger"
                ],
                "title": "What BERT is not: Lessons from a new suite of psycholinguistic diagnostics for language models",
                "pub_date": "2020",
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_90",
            "content": "Charles Fillmore, Paul Kay, Mary Catherine, O' Connor, Regularity and idiomaticity in grammatical constructions: The case of let alone, 1988, Language, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Charles Fillmore",
                    "Paul Kay",
                    "Mary Catherine",
                    "O' Connor"
                ],
                "title": "Regularity and idiomaticity in grammatical constructions: The case of let alone",
                "pub_date": "1988",
                "pub_title": "Language",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_91",
            "content": "UNKNOWN, None, 1995, Constructions: A construction grammar approach to argument structure, University of Chicago Press.",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": null,
                "title": null,
                "pub_date": "1995",
                "pub_title": "Constructions: A construction grammar approach to argument structure",
                "pub": "University of Chicago Press"
            }
        },
        {
            "ix": "317-ARR_v2_92",
            "content": "UNKNOWN, None, 2006, Constructions at Work: The Nature of Generalization in Language, Oxford University Press.",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": null,
                "title": null,
                "pub_date": "2006",
                "pub_title": "Constructions at Work: The Nature of Generalization in Language",
                "pub": "Oxford University Press"
            }
        },
        {
            "ix": "317-ARR_v2_93",
            "content": "Stefan Th Gries, Stefanie Wulff, Do foreign language learners also have constructions?, 2005, Annual Review of Cognitive Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Stefan Th Gries",
                    "Stefanie Wulff"
                ],
                "title": "Do foreign language learners also have constructions?",
                "pub_date": "2005",
                "pub_title": "Annual Review of Cognitive Linguistics",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_94",
            "content": "Kristina Gulordava, Piotr Bojanowski, \u00c9douard Grave, Tal Linzen, Marco Baroni, Colorless green recurrent networks dream hierarchically, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Kristina Gulordava",
                    "Piotr Bojanowski",
                    "\u00c9douard Grave",
                    "Tal Linzen",
                    "Marco Baroni"
                ],
                "title": "Colorless green recurrent networks dream hierarchically",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "317-ARR_v2_95",
            "content": "John Hewitt, D Christopher,  Manning, A structural probe for finding syntax in word representations, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "John Hewitt",
                    "D Christopher",
                    " Manning"
                ],
                "title": "A structural probe for finding syntax in word representations",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_96",
            "content": "Jennifer Hu, Jon Gauthier, Peng Qian, Ethan Wilcox, Roger Levy, A systematic assessment of syntactic generalization in neural language models, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Jennifer Hu",
                    "Jon Gauthier",
                    "Peng Qian",
                    "Ethan Wilcox",
                    "Roger Levy"
                ],
                "title": "A systematic assessment of syntactic generalization in neural language models",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_97",
            "content": "D Jena, Martha Hwang,  Palmer, Identification of caused motion construction, 2015, Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "D Jena",
                    "Martha Hwang",
                    " Palmer"
                ],
                "title": "Identification of caused motion construction",
                "pub_date": "2015",
                "pub_title": "Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_98",
            "content": "A Matt, Adele Johnson,  Goldberg, Evidence for automatic accessing of constructional meaning: Jabberwocky sentences prime associated verbs, 2013, Language and Cognitive Processes, .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "A Matt",
                    "Adele Johnson",
                    " Goldberg"
                ],
                "title": "Evidence for automatic accessing of constructional meaning: Jabberwocky sentences prime associated verbs",
                "pub_date": "2013",
                "pub_title": "Language and Cognitive Processes",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_99",
            "content": "UNKNOWN, None, 1982, Lexical functional grammar: A formal system for grammatical representation, MIT Press.",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": null,
                "title": null,
                "pub_date": "1982",
                "pub_title": "Lexical functional grammar: A formal system for grammatical representation",
                "pub": "MIT Press"
            }
        },
        {
            "ix": "317-ARR_v2_100",
            "content": "P Michael, Arthur Kaschak,  Glenberg, Constructing meaning: The role of affordances and grammatical constructions in sentence comprehension, 2000, Journal of memory and language, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "P Michael",
                    "Arthur Kaschak",
                    " Glenberg"
                ],
                "title": "Constructing meaning: The role of affordances and grammatical constructions in sentence comprehension",
                "pub_date": "2000",
                "pub_title": "Journal of memory and language",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_101",
            "content": "UNKNOWN, None, 1999, Grammatical constructions and linguistic generalizations: The What's X Doing Y? construction. Language, .",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": null,
                "title": null,
                "pub_date": "1999",
                "pub_title": "Grammatical constructions and linguistic generalizations: The What's X Doing Y? construction. Language",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_102",
            "content": "UNKNOWN, None, 2019, The psychological reality of argument structure constructions: A visual world eye tracking study, .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "The psychological reality of argument structure constructions: A visual world eye tracking study",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_103",
            "content": "Josef Klafka, Allyson Ettinger, Spying on your neighbors: Fine-grained probing of contextual embeddings for information about surrounding words, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": [
                    "Josef Klafka",
                    "Allyson Ettinger"
                ],
                "title": "Spying on your neighbors: Fine-grained probing of contextual embeddings for information about surrounding words",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_104",
            "content": "Olga Kovaleva, Saurabh Kulshreshtha, Anna Rogers, Anna Rumshisky, BERT busters: Outlier dimensions that disrupt Transformers, 2021, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Olga Kovaleva",
                    "Saurabh Kulshreshtha",
                    "Anna Rogers",
                    "Anna Rumshisky"
                ],
                "title": "BERT busters: Outlier dimensions that disrupt Transformers",
                "pub_date": "2021",
                "pub_title": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_105",
            "content": "E Gianluca, Alessandro Lebani,  Lenci, beware the Jabberwock, dear reader!\" Testing the distributional reality of construction semantics, 2016, Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex-V), .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "E Gianluca",
                    "Alessandro Lebani",
                    " Lenci"
                ],
                "title": "beware the Jabberwock, dear reader!\" Testing the distributional reality of construction semantics",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex-V)",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_106",
            "content": "UNKNOWN, None, , million words of English: the British National Corpus (BNC). Language Research, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "million words of English: the British National Corpus (BNC). Language Research",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_107",
            "content": "UNKNOWN, None, 1995, Unaccusativity in the Syntax-Lexical Semantics Interface, MIT Press.",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": null,
                "title": null,
                "pub_date": "1995",
                "pub_title": "Unaccusativity in the Syntax-Lexical Semantics Interface",
                "pub": "MIT Press"
            }
        },
        {
            "ix": "317-ARR_v2_108",
            "content": "UNKNOWN, None, 2005, Argument Realization, Cambridge University Press.",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": null,
                "title": null,
                "pub_date": "2005",
                "pub_title": "Argument Realization",
                "pub": "Cambridge University Press"
            }
        },
        {
            "ix": "317-ARR_v2_109",
            "content": "Bai Li, Zining Zhu, Guillaume Thomas, Yang Xu, Frank Rudzicz, How is BERT surprised? Layerwise detection of linguistic anomalies, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": [
                    "Bai Li",
                    "Zining Zhu",
                    "Guillaume Thomas",
                    "Yang Xu",
                    "Frank Rudzicz"
                ],
                "title": "How is BERT surprised? Layerwise detection of linguistic anomalies",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "317-ARR_v2_110",
            "content": "UNKNOWN, None, 2002, Sentence comprehension by Chinese learners of English: Verb-centered or construction-based?, .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": null,
                "title": null,
                "pub_date": "2002",
                "pub_title": "Sentence comprehension by Chinese learners of English: Verb-centered or construction-based?",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_111",
            "content": "Tal Linzen, Marco Baroni, Syntactic structure from deep learning, 2021, Annual Review of Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": [
                    "Tal Linzen",
                    "Marco Baroni"
                ],
                "title": "Syntactic structure from deep learning",
                "pub_date": "2021",
                "pub_title": "Annual Review of Linguistics",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_112",
            "content": "Tal Linzen, Emmanuel Dupoux, Yoav Goldberg, Assessing the ability of LSTMs to learn syntax-sensitive dependencies, 2016, Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "Tal Linzen",
                    "Emmanuel Dupoux",
                    "Yoav Goldberg"
                ],
                "title": "Assessing the ability of LSTMs to learn syntax-sensitive dependencies",
                "pub_date": "2016",
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_113",
            "content": "Z Leo, Yizhong Liu, Jungo Wang, Hannaneh Kasai, Noah A Hajishirzi,  Smith, Probing across time: What does RoBERTa know and when?, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: Findings, .",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": [
                    "Z Leo",
                    "Yizhong Liu",
                    "Jungo Wang",
                    "Hannaneh Kasai",
                    "Noah A Hajishirzi",
                    " Smith"
                ],
                "title": "Probing across time: What does RoBERTa know and when?",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: Findings",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_114",
            "content": "F Nelson, Matt Liu, Yonatan Gardner,  Belinkov, E Matthew, Noah A Peters,  Smith, Linguistic knowledge and transferability of contextual representations, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": [
                    "F Nelson",
                    "Matt Liu",
                    "Yonatan Gardner",
                    " Belinkov",
                    "E Matthew",
                    "Noah A Peters",
                    " Smith"
                ],
                "title": "Linguistic knowledge and transferability of contextual representations",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_115",
            "content": "UNKNOWN, None, 2019, RoBERTa: A robustly optimized BERT pretraining approach, .",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "RoBERTa: A robustly optimized BERT pretraining approach",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_116",
            "content": "Laurence Harish Tayyar Madabushi, Dagmar Romain, Petar Divjak,  Milin, CxGBERT: BERT meets construction grammar, 2020, Proceedings of the 28th International Conference on Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b40",
                "authors": [
                    "Laurence Harish Tayyar Madabushi",
                    "Dagmar Romain",
                    "Petar Divjak",
                    " Milin"
                ],
                "title": "CxGBERT: BERT meets construction grammar",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 28th International Conference on Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_117",
            "content": "UNKNOWN, None, 1993, Building a large annotated corpus of English: The Penn Treebank, .",
            "ntype": "ref",
            "meta": {
                "xid": "b41",
                "authors": null,
                "title": null,
                "pub_date": "1993",
                "pub_title": "Building a large annotated corpus of English: The Penn Treebank",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_118",
            "content": "James Michaelov, Benjamin Bergen, How well does surprisal explain N400 amplitude under different experimental conditions?, 2020, Proceedings of the 24th Conference on Computational Natural Language Learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b42",
                "authors": [
                    "James Michaelov",
                    "Benjamin Bergen"
                ],
                "title": "How well does surprisal explain N400 amplitude under different experimental conditions?",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 24th Conference on Computational Natural Language Learning",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_119",
            "content": "Kanishka Misra, Allyson Ettinger, Julia Rayz, Exploring BERT's sensitivity to lexical cues using tests from semantic priming, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings, .",
            "ntype": "ref",
            "meta": {
                "xid": "b43",
                "authors": [
                    "Kanishka Misra",
                    "Allyson Ettinger",
                    "Julia Rayz"
                ],
                "title": "Exploring BERT's sensitivity to lexical cues using tests from semantic priming",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_120",
            "content": "Fabian Pedregosa, Ga\u00ebl Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, Scikit-learn: Machine learning in Python, 2011, Journal of machine Learning research, .",
            "ntype": "ref",
            "meta": {
                "xid": "b44",
                "authors": [
                    "Fabian Pedregosa",
                    "Ga\u00ebl Varoquaux",
                    "Alexandre Gramfort",
                    "Vincent Michel",
                    "Bertrand Thirion",
                    "Olivier Grisel",
                    "Mathieu Blondel",
                    "Peter Prettenhofer",
                    "Ron Weiss",
                    "Vincent Dubourg"
                ],
                "title": "Scikit-learn: Machine learning in Python",
                "pub_date": "2011",
                "pub_title": "Journal of machine Learning research",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_121",
            "content": "Thang Pham, Trung Bui, Long Mai, Anh Nguyen, Out of order: How important is the sequential order of words in a sentence in natural language understanding tasks?, 2021, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, .",
            "ntype": "ref",
            "meta": {
                "xid": "b45",
                "authors": [
                    "Thang Pham",
                    "Trung Bui",
                    "Long Mai",
                    "Anh Nguyen"
                ],
                "title": "Out of order: How important is the sequential order of words in a sentence in natural language understanding tasks?",
                "pub_date": "2021",
                "pub_title": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_122",
            "content": "J Martin,  Pickering, S Victor,  Ferreira, Structural priming: a critical review, 2008, Psychological bulletin, .",
            "ntype": "ref",
            "meta": {
                "xid": "b46",
                "authors": [
                    "J Martin",
                    " Pickering",
                    "S Victor",
                    " Ferreira"
                ],
                "title": "Structural priming: a critical review",
                "pub_date": "2008",
                "pub_title": "Psychological bulletin",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_123",
            "content": "UNKNOWN, None, 1987, Information-Based Syntax and Semantics, CSLI.",
            "ntype": "ref",
            "meta": {
                "xid": "b47",
                "authors": null,
                "title": null,
                "pub_date": "1987",
                "pub_title": "Information-Based Syntax and Semantics",
                "pub": "CSLI"
            }
        },
        {
            "ix": "317-ARR_v2_124",
            "content": "Grusha Prasad, Marten Van Schijndel, Tal Linzen, Using priming to uncover the organization of syntactic representations in neural language models, 2019, Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL), .",
            "ntype": "ref",
            "meta": {
                "xid": "b48",
                "authors": [
                    "Grusha Prasad",
                    "Marten Van Schijndel",
                    "Tal Linzen"
                ],
                "title": "Using priming to uncover the organization of syntactic representations in neural language models",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_125",
            "content": "UNKNOWN, None, 1996, The Empirical Base of Linguistics: Grammaticality Judgments and Linguistic Methodology, University of Chicago Press.",
            "ntype": "ref",
            "meta": {
                "xid": "b49",
                "authors": null,
                "title": null,
                "pub_date": "1996",
                "pub_title": "The Empirical Base of Linguistics: Grammaticality Judgments and Linguistic Methodology",
                "pub": "University of Chicago Press"
            }
        },
        {
            "ix": "317-ARR_v2_126",
            "content": "Koustuv Sinha, Prasanna Parthasarathi, Joelle Pineau, Adina Williams, UnNatural Language Inference, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b50",
                "authors": [
                    "Koustuv Sinha",
                    "Prasanna Parthasarathi",
                    "Joelle Pineau",
                    "Adina Williams"
                ],
                "title": "UnNatural Language Inference",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "317-ARR_v2_127",
            "content": "William Timkey, Marten Van Schijndel, All bark and no bite: Rogue dimensions in transformer language models obscure representational quality, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b51",
                "authors": [
                    "William Timkey",
                    "Marten Van Schijndel"
                ],
                "title": "All bark and no bite: Rogue dimensions in transformer language models obscure representational quality",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_128",
            "content": "Montserrat Mart\u00ednez,  V\u00e1zquez, Learning argument structure generalizations in a foreign language, 2004, Vigo International Journal of Applied Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b52",
                "authors": [
                    " Montserrat Mart\u00ednez",
                    " V\u00e1zquez"
                ],
                "title": "Learning argument structure generalizations in a foreign language",
                "pub_date": "2004",
                "pub_title": "Vigo International Journal of Applied Linguistics",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_129",
            "content": "Alex Warstadt, Alicia Parrish, Haokun Liu, Anhad Mohananey, Wei Peng, Sheng-Fu Wang, Samuel R Bowman, BLiMP: The benchmark of linguistic minimal pairs for English, 2020, Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b53",
                "authors": [
                    "Alex Warstadt",
                    "Alicia Parrish",
                    "Haokun Liu",
                    "Anhad Mohananey",
                    "Wei Peng",
                    "Sheng-Fu Wang",
                    "Samuel R Bowman"
                ],
                "title": "BLiMP: The benchmark of linguistic minimal pairs for English",
                "pub_date": "2020",
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_130",
            "content": "Alex Warstadt, Amanpreet Singh, Samuel R Bowman, Neural network acceptability judgments, 2019, Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b54",
                "authors": [
                    "Alex Warstadt",
                    "Amanpreet Singh",
                    "Samuel R Bowman"
                ],
                "title": "Neural network acceptability judgments",
                "pub_date": "2019",
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_131",
            "content": "Alex Warstadt, Yian Zhang, Xiaocheng Li, Haokun Liu, Samuel R Bowman, Learning which features matter: RoBERTa acquires a preference for linguistic generalizations (eventually), 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP.",
            "ntype": "ref",
            "meta": {
                "xid": "b55",
                "authors": [
                    "Alex Warstadt",
                    "Yian Zhang",
                    "Xiaocheng Li",
                    "Haokun Liu",
                    "Samuel R Bowman"
                ],
                "title": "Learning which features matter: RoBERTa acquires a preference for linguistic generalizations (eventually)",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
                "pub": "EMNLP"
            }
        },
        {
            "ix": "317-ARR_v2_132",
            "content": "Jason Wei, Dan Garrette, Tal Linzen, Ellie Pavlick, Frequency effects on syntactic rule learning in transformers, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP.",
            "ntype": "ref",
            "meta": {
                "xid": "b56",
                "authors": [
                    "Jason Wei",
                    "Dan Garrette",
                    "Tal Linzen",
                    "Ellie Pavlick"
                ],
                "title": "Frequency effects on syntactic rule learning in transformers",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
                "pub": "EMNLP"
            }
        },
        {
            "ix": "317-ARR_v2_133",
            "content": "Ethan Wilcox, Pranali Vani, Roger Levy, A targeted assessment of incremental processing in neural language models and humans, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b57",
                "authors": [
                    "Ethan Wilcox",
                    "Pranali Vani",
                    "Roger Levy"
                ],
                "title": "A targeted assessment of incremental processing in neural language models and humans",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "317-ARR_v2_134",
            "content": "Lang Yu, Allyson Ettinger, Assessing phrasal representation and composition in transformers, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b58",
                "authors": [
                    "Lang Yu",
                    "Allyson Ettinger"
                ],
                "title": "Assessing phrasal representation and composition in transformers",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_135",
            "content": "Yian Zhang, Alex Warstadt, Haau-Sing Li, Samuel R Bowman, When do you need billions of words of pretraining data?, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b59",
                "authors": [
                    "Yian Zhang",
                    "Alex Warstadt",
                    "Haau-Sing Li",
                    "Samuel R Bowman"
                ],
                "title": "When do you need billions of words of pretraining data?",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "317-ARR_v2_136",
            "content": "Jayden Ziegler, Giulia Bencini, Adele Goldberg, Jesse Snedeker, How abstract is syntax? Evidence from structural priming, 2019, Cognition, .",
            "ntype": "ref",
            "meta": {
                "xid": "b60",
                "authors": [
                    "Jayden Ziegler",
                    "Giulia Bencini",
                    "Adele Goldberg",
                    "Jesse Snedeker"
                ],
                "title": "How abstract is syntax? Evidence from structural priming",
                "pub_date": "2019",
                "pub_title": "Cognition",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "317-ARR_v2_0@0",
            "content": "Neural reality of argument structure constructions",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_0",
            "start": 0,
            "end": 49,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_2@0",
            "content": "In lexicalist linguistic theories, argument structure is assumed to be predictable from the meaning of verbs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_2",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_2@1",
            "content": "As a result, the verb is the primary determinant of the meaning of a clause.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_2",
            "start": 110,
            "end": 185,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_2@2",
            "content": "In contrast, construction grammarians propose that argument structure is encoded in constructions (or form-meaning pairs) that are distinct from verbs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_2",
            "start": 187,
            "end": 337,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_2@3",
            "content": "Decades of psycholinguistic research have produced substantial empirical evidence in favor of the construction view.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_2",
            "start": 339,
            "end": 454,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_2@4",
            "content": "Here we adapt several psycholinguistic studies to probe for the existence of argument structure constructions (ASCs) in Transformerbased language models (LMs).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_2",
            "start": 456,
            "end": 614,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_2@5",
            "content": "First, using a sentence sorting experiment, we find that sentences sharing the same construction are closer in embedding space than sentences sharing the same verb.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_2",
            "start": 616,
            "end": 779,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_2@6",
            "content": "Furthermore, LMs increasingly prefer grouping by construction with more input data, mirroring the behaviour of non-native language learners.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_2",
            "start": 781,
            "end": 920,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_2@7",
            "content": "Second, in a \"Jabberwocky\" priming-based experiment, we find that LMs associate ASCs with meaning, even in semantically nonsensical sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_2",
            "start": 922,
            "end": 1063,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_2@8",
            "content": "Our work offers the first evidence for ASCs in LMs and highlights the potential to devise novel probing methods grounded in psycholinguistic research.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_2",
            "start": 1065,
            "end": 1214,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_4@0",
            "content": "Pretrained Transformer-based language models (LMs) such as BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019b) have recently achieved impressive results on many natural language tasks, spawning a new interdisciplinary field of aligning LMs with linguistic theory and probing the linguistic capabilities of LMs (Linzen and Baroni, 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_4",
            "start": 0,
            "end": 342,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_4@1",
            "content": "Most probing work so far has investigated the linguistic knowledge of LMs on phenomena such as agreement, binding, licensing, and movement (Warstadt et al., 2020a;Hu et al., 2020)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_4",
            "start": 344,
            "end": 522,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_5@0",
            "content": "Bob with a particular focus on determining whether a sentence is linguistically acceptable (Sch\u00fctze, 1996).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_5",
            "start": 0,
            "end": 106,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_5@1",
            "content": "Relatively little work has attempted to determine whether the linguistic knowledge induced by LMs is more similar to a formal grammar of the sort postulated by mainstream generative linguistics (Chomsky, 1965(Chomsky, , 1981(Chomsky, , 1995, or to a network of form-meaning pairs as advocated by construction grammar (Goldberg, 1995(Goldberg, , 2006.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_5",
            "start": 108,
            "end": 457,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_6@0",
            "content": "One area where construction grammar disagrees with many generative theories of language is in the analysis of the argument structure of verbs, that is, the specification of the number of arguments that a verb takes, their semantic relation to the verb, and their syntactic form (Levin and Rappaport Hovav, 2005).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_6",
            "start": 0,
            "end": 311,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_6@1",
            "content": "Lexicalist theories were long dominant in generative grammar (Chomsky, 1981;Kaplan and Bresnan, 1982;Pollard and Sag, 1987).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_6",
            "start": 313,
            "end": 436,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_6@2",
            "content": "In lexicalist theories, argument structure is assumed to be encoded in the lexical entry of the verb: for example, the verb visit is lexically specified as being transitive and as requiring a noun phrase object (Chomsky, 1986).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_6",
            "start": 438,
            "end": 664,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_6@3",
            "content": "In contrast, construction grammar suggests that argument structure is encoded in form-meaning pairs known as argument structure constructions (ASCs, Figure 1), which are distinct from verbs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_6",
            "start": 666,
            "end": 855,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_6@4",
            "content": "The argument structure of a verb is determined by pairing it with an ASC (Goldberg, 1995).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_6",
            "start": 857,
            "end": 946,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_6@5",
            "content": "To date, a substantial body of psycholinguistic work has provided evidence for the psychological reality of ASCs in sentence sorting (Bencini and Goldberg, 2000;Gries and Wulff, 2005), priming (Ziegler et al., 2019), and novel verb experiments (Kaschak and Glenberg, 2000;Johnson and Goldberg, 2013).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_6",
            "start": 948,
            "end": 1247,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_7@0",
            "content": "Here we connect basic research in ASCs with neural probing by adapting several psycholinguistic studies to Transformer-based LMs and show evidence for the neural reality of ASCs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_7",
            "start": 0,
            "end": 177,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_7@1",
            "content": "Our first case study is based on sentence sorting (Bencini and Goldberg, 2000); we discover that in English, German, Italian, and Spanish, LMs consider sentences that share the same construction to be more semantically similar than sentences sharing the main verb.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_7",
            "start": 179,
            "end": 442,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_7@2",
            "content": "Furthermore, this preference for constructional meaning only manifests in larger LMs (trained with more data), whereas smaller LMs rely on the main verb, an easily accessible surface feature.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_7",
            "start": 444,
            "end": 634,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_7@3",
            "content": "Human experiments with non-native speakers found a similarly increased preference for constructional meaning in more proficient speakers (Liang, 2002;Baicchi and Della Putta, 2019), suggesting commonalities in language acquisition between LMs and humans.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_7",
            "start": 636,
            "end": 889,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_8@0",
            "content": "Our second case study is based on nonsense \"Jabberwocky\" sentences that nevertheless convey meaning when they are arranged in constructional templates (Johnson and Goldberg, 2013).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_8",
            "start": 0,
            "end": 179,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_8@1",
            "content": "We adapt the original priming experiment to LMs and show that RoBERTa is able to derive meaning from ASCs, even without any lexical cues.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_8",
            "start": 181,
            "end": 317,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_8@2",
            "content": "This finding offers counter-evidence to earlier claims that LMs are relatively insensitive to word order when constructing sentence meaning (Yu and Ettinger, 2020;Sinha et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_8",
            "start": 319,
            "end": 501,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_8@3",
            "content": "Our source code and data are available at: https://github.com/SPOClab-ca/ neural-reality-constructions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_8",
            "start": 503,
            "end": 605,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_9@0",
            "content": "Psycholinguistic background",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_9",
            "start": 0,
            "end": 26,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_10@0",
            "content": "Construction grammar and ASCs",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_10",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_11@0",
            "content": "Construction grammar is a family of linguistic theories proposing that all linguistic knowledge consists of constructions: pairings between form and meaning where some aspects of form or meaning are not predictable from their parts (Fillmore et al., 1988;Kay and Fillmore, 1999;Goldberg, 1995Goldberg, , 2006.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_11",
            "start": 0,
            "end": 308,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_11@1",
            "content": "Common examples include idiomatic expressions such as under the weather (meaning \"to feel unwell\"), but many linguistic patterns are constructions, including morphemes (e.g., -ify), words (e.g., apple), and abstract patterns like the ditransitive and passive.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_11",
            "start": 310,
            "end": 568,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_11@2",
            "content": "In contrast to lexicalist theories of argument structure, construction grammar rejects the dichotomy between syntax and lexicon.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_11",
            "start": 570,
            "end": 697,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_11@3",
            "content": "In contrast to transformational grammar, it rejects any distinction between surface and underlying structure.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_11",
            "start": 699,
            "end": 807,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_12@0",
            "content": "We focus on a specific family of constructions for which there is an ample body of psycholinguistic evidence: argument structure constructions (ASCs).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_12",
            "start": 0,
            "end": 149,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_12@1",
            "content": "ASCs are constructions that specify the argument structure of a verb (Goldberg, 1995).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_12",
            "start": 151,
            "end": 236,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_12@2",
            "content": "In the lexicalist, verb-centered view, argument structure is a lexical property of the verb, and the main verb of a sentence determines the form and meaning of the sentence (Chomsky, 1981;Kaplan and Bresnan, 1982;Pollard and Sag, 1987;Levin and Rappaport Hovav, 1995).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_12",
            "start": 238,
            "end": 505,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_12@3",
            "content": "For example, sneeze is intransitive (allowing no direct object) and hit is transitive (requiring one direct object).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_12",
            "start": 507,
            "end": 622,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_12@4",
            "content": "However, lexicalist theories encounter difficulties with sentences like \"he sneezed the napkin off the table\" since intransitive verbs are not permitted to have object arguments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_12",
            "start": 624,
            "end": 801,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_13@0",
            "content": "Rather than assuming multiple implausible senses for the verb \"sneeze\" with different argument structures, Goldberg (1995) proposed that ASCs operate on an arbitrary verb, altering its argument structure while at the same time modifying its meaning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_13",
            "start": 0,
            "end": 248,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_13@1",
            "content": "For example, the caused-motion ASC adds a direct object and a path argument to the verb sneeze, with the semantics of causing the object to move along the path.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_13",
            "start": 250,
            "end": 409,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_13@2",
            "content": "Other ASCs include the transitive, ditransitive, and resultative (Figure 1), which specify the argument structure of a verb and interact with its meaning in different ways.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_13",
            "start": 411,
            "end": 582,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_14@0",
            "content": "Psycholinguistic evidence for ASCs",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_14",
            "start": 0,
            "end": 33,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_15@0",
            "content": "Sentence sorting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_15",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_15@1",
            "content": "Several psycholinguistic studies have found evidence for argument structure con-",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_15",
            "start": 18,
            "end": 97,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_16@0",
            "content": "Caused-motion Resultative Throw Anita threw the hammer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_16",
            "start": 0,
            "end": 54,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_16@1",
            "content": "Chris threw Linda the pencil.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_16",
            "start": 56,
            "end": 84,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_17@0",
            "content": "Pat threw the keys onto the roof.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_17",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_18@0",
            "content": "Lyn threw the box apart.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_18",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_19@0",
            "content": "Michelle got the book.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_19",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_20@0",
            "content": "Beth got Liz an invitation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_20",
            "start": 0,
            "end": 26,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_21@0",
            "content": "Laura got the ball into the net.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_21",
            "start": 0,
            "end": 31,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_22@0",
            "content": "Dana got the mattress inflated.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_22",
            "start": 0,
            "end": 30,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_23@0",
            "content": "Barbara sliced the bread.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_23",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_23@1",
            "content": "Jennifer sliced Terry an apple.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_23",
            "start": 26,
            "end": 56,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_24@0",
            "content": "Meg sliced the ham onto the plate.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_24",
            "start": 0,
            "end": 33,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_25@0",
            "content": "Nancy sliced the tire open.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_25",
            "start": 0,
            "end": 26,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_26@0",
            "content": "Audrey took the watch.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_26",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_26@1",
            "content": "Paula took Sue a message.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_26",
            "start": 23,
            "end": 47,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_27@0",
            "content": "Kim took the rose into the house.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_27",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_28@0",
            "content": "Rachel took the wall down.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_28",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_29@0",
            "content": "Table 1: Stimuli from Bencini and Goldberg (2000), consisting of a 4x4 design, with 4 different verbs and 4 different argument structure constructions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_29",
            "start": 0,
            "end": 150,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_30@0",
            "content": "structions using experimental methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_30",
            "start": 0,
            "end": 37,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_30@1",
            "content": "Among these, Bencini and Goldberg (2000) used a sentence sorting task to determine whether the verb or construction in a sentence was the main determinant of sentence meaning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_30",
            "start": 39,
            "end": 213,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_30@2",
            "content": "17 participants were given 16 index cards with sentences containing 4 verbs (throw, get, slice, and take) and 4 constructions (transitive, ditransitive, caused-motion, and resultative) and were instructed to sort them into 4 piles by overall sentence meaning (Table 1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_30",
            "start": 215,
            "end": 483,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_30@3",
            "content": "The experimenters measured the deviation to a purely verb-based or construction-based sort, and found that on average, the piles were closer to a construction sort.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_30",
            "start": 485,
            "end": 648,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_31@0",
            "content": "Non-native sentence sorting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_31",
            "start": 0,
            "end": 27,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_31@1",
            "content": "The same set of experimental stimuli was used with L2 (non-native) English speakers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_31",
            "start": 29,
            "end": 112,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_31@2",
            "content": "Gries and Wulff (2005) ran the experiment with 22 German native speakers, who preferred the construction-based sort over the verbbased sort, showing that constructional knowledge is not limited to native speakers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_31",
            "start": 114,
            "end": 326,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_31@3",
            "content": "Liang (2002) ran the experiment on Chinese native speakers of 3 different English levels (46 beginner, 31 intermediate, and 33 advanced), and found that beginners preferred a verb-based sort, while advanced learners produced construction-based sorts similar to native speakers (Figure 2).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_31",
            "start": 328,
            "end": 615,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_31@4",
            "content": "Likewise, Baicchi and Della Putta (2019) found the same result in Italian native speakers with B1 and B2 English proficiency levels.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_31",
            "start": 617,
            "end": 748,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_31@5",
            "content": "Overall, these studies show evidence for ASCs in the mental representations of native and L2 English speakers alike, and furthermore, preference for constructional over verb sorting increases with increasing English proficiency.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_31",
            "start": 750,
            "end": 977,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_32@0",
            "content": "Multilingual sentence sorting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_32",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_32@1",
            "content": "Similar sentence sorting experiments have been conducted in other languages, with varying results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_32",
            "start": 31,
            "end": 128,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_32@2",
            "content": "Kirsch (2019) ran a sentence sorting experiment in German with 40 participants and found that they mainly sorted by verb but rarely by construction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_32",
            "start": 130,
            "end": 277,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_32@3",
            "content": "Baicchi and Della Putta (2019) ran an experiment with non-native learners of Italian (15 participants of B1 level and 10 participants of B2 level): both groups preferred the constructional sort, and similar to Liang (2002), the B2 learners sorted more by construction than the B1 learners.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_32",
            "start": 279,
            "end": 567,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_32@4",
            "content": "V\u00e1zquez ( 2004) ran an experiment in Spanish with 16 participants, and found approximately equal proportions of constructions and verb sort.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_32",
            "start": 569,
            "end": 708,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_32@5",
            "content": "In Italian and Spanish, some different constructions were substituted as not all of the English constructions had an equivalent in these languages; see the appendix for the complete set of stimuli in each language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_32",
            "start": 710,
            "end": 923,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_33@0",
            "content": "Priming.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_33",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_33@1",
            "content": "Another line of psycholinguistic evidence comes from priming studies.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_33",
            "start": 9,
            "end": 77,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_33@2",
            "content": "Priming refers to the condition where exposure to a (prior) stimulus influences the response to a later stimulus (Pickering and Ferreira, 2008).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_33",
            "start": 79,
            "end": 222,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_33@3",
            "content": "Bock and Loebell (1990) found that participants were more likely to produce sentences of a given syntactic structure when primed with a sentence of the same structure; Ziegler et al. (2019) argued that Bock and Loebell (1990) did not adequately control for lexical overlap, and instead, they showed that the construction must be shared for the priming effect to occur, not just shared abstract syntax.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_33",
            "start": 224,
            "end": 624,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_34@0",
            "content": "Novel verbs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_34",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_34@1",
            "content": "Even with unfamiliar words, there is evidence that constructions are associated with meaning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_34",
            "start": 13,
            "end": 105,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_34@2",
            "content": "Kaschak and Glenberg (2000) constructed sentences with novel denominal verbs and found that participants were more likely to interpret a transfer event when the denominal verb was used in a ditransitive sentence (Tom crutched Lyn an apple) than a transitive one (Tom crutched an apple).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_34",
            "start": 107,
            "end": 392,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_35@0",
            "content": "Johnson and Goldberg (2013) used a \"Jabberwocky\" priming task to show that abstract constructional templates are associated with meaning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_35",
            "start": 0,
            "end": 136,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_35@1",
            "content": "Participants were primed with a nonsense sentence of a given construction (e.g., He daxed her the norp for the ditransitive construction), followed by a lexical decision task of quickly deciding if a string of characters was a real English word or a non-word.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_35",
            "start": 138,
            "end": 396,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_35@2",
            "content": "The word in the decision task was semantically congruent with the construction (gave) or incongruent (made); furthermore, they experimented with target words that were high-frequency (gave), lowfrequency (handed), or semantically related but not associated with the construction (transferred).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_35",
            "start": 398,
            "end": 690,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_35@3",
            "content": "They found priming effects (faster lexical decision times) in all three conditions, with the strongest effect for the high-frequency condition, followed by the low-frequency and the semantically nonassociate conditions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_35",
            "start": 692,
            "end": 910,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_36@0",
            "content": "We adapt several of these psycholinguistic studies to LMs: the sentence sorting experiments in Case study 1, and the Jabberwocky priming experiment in Case study 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_36",
            "start": 0,
            "end": 163,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_36@1",
            "content": "We choose these studies because their designs allow for thousands of stimuli sentences to be generated automatically using templates, avoiding issues caused by small sample sizes from manually constructed sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_36",
            "start": 165,
            "end": 379,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_37@0",
            "content": "3 Related work in NLP",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_37",
            "start": 0,
            "end": 20,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_38@0",
            "content": "Linguistic probing of LMs",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_38",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_39@0",
            "content": "Many studies have probed for various aspects of syntax in LSTMs and Transformer-based LMs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_39",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_39@1",
            "content": "Linzen et al. (2016) tested LSTMs on their ability to capture subject-verb agreement, using templates to generate test data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_39",
            "start": 91,
            "end": 214,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_39@2",
            "content": "This idea was extended by BLiMP (Warstadt et al., 2020a), a suite encompassing 67 linguistic phenomena, including fillergap effects, NPI licensing, and ellipsis; Hu et al. (2020) released a similar test suite.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_39",
            "start": 216,
            "end": 424,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_39@3",
            "content": "Template generation is a convenient method to construct stimuli exhibiting specific linguistic properties, but alternative approaches include CoLA (Warstadt et al., 2019), which compiled an acceptability benchmark of sentences drawn from linguistic publications, and Gulordava et al. (2018), who perturbed natural sentences to study LMs' knowledge of agreement on nonsense sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_39",
            "start": 426,
            "end": 808,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_39@4",
            "content": "We refer to Linzen and Baroni (2021) for a comprehensive review of the linguistic probing literature.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_39",
            "start": 810,
            "end": 910,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_40@0",
            "content": "So far, relatively few papers approached LM probing from a construction grammar perspective.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_40",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_40@1",
            "content": "Madabushi et al. (2020) probed for BERT's knowledge of constructions via a sentence pair classification task of predicting whether two sentences share the same construction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_40",
            "start": 93,
            "end": 265,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_40@2",
            "content": "Their probe was based on data from Dunn (2017), who used an unsupervised algorithm to extract plausible constructions from corpora based on association strength.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_40",
            "start": 267,
            "end": 427,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_40@3",
            "content": "How-ever, the linguistic validity of these automatically induced constructions is uncertain, and there is currently no human-labelled wide-coverage construction grammar dataset in any language suitable for probing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_40",
            "start": 429,
            "end": 642,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_40@4",
            "content": "Other computational work focused on a few specific constructions, such as identifying caused-motion constructions in corpora (Hwang and Palmer, 2015) and annotating constructions related to causal language (Dunietz et al., 2015).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_40",
            "start": 644,
            "end": 872,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_40@5",
            "content": "Lebani and Lenci (2016) is the most similar to our work: they probed distributional vector space models for ASCs based on the Jabberwocky priming experiment by Johnson and Goldberg (2013).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_40",
            "start": 874,
            "end": 1061,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_41@0",
            "content": "Psycholinguistic treatment of LMs",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_41",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_42@0",
            "content": "Some recent probing studies adapted methods and data from psycholinguistic research, treating LMs as psycholinguistic participants.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_42",
            "start": 0,
            "end": 130,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_42@1",
            "content": "Using a cloze completion task, Ettinger (2020) found that BERT was less sensitive than humans at commonsense inferences and detecting role reversals, and fails completely at understanding negation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_42",
            "start": 132,
            "end": 328,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_42@2",
            "content": "Michaelov and Bergen (2020) compared LM surprisals with the N400 (a measure of human language processing difficulty) across a wide range of conditions; used psycholinguistic stimuli and found that LMs exhibit different layerwise surprisal patterns for morphosyntactic, semantic, and commonsense anomalies.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_42",
            "start": 330,
            "end": 634,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_42@3",
            "content": "Wilcox et al. (2021) compared LM and human sensitivities to syntactic violations using a maze task to collect human reaction times.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_42",
            "start": 636,
            "end": 766,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_42@4",
            "content": "Prasad et al. (2019); Misra et al. (2020) investigated whether LMs are sensitive to priming effects like humans.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_42",
            "start": 768,
            "end": 879,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_42@5",
            "content": "The advantage of psycholinguistic data is that they are carefully constructed by expert linguists to test theories of language processing in humans; however, their small sample size makes it challenging to make statistically meaningful conclusions when the (oft-sparse) experimental stimuli are used to probe a language model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_42",
            "start": 881,
            "end": 1206,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_43@0",
            "content": "Case study 1: Sentence sorting",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_43",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_44@0",
            "content": "This section describes our adaptation of the sentence sorting experiments to Transformer LMs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_44",
            "start": 0,
            "end": 92,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_45@0",
            "content": "Methodology",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_45",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_46@0",
            "content": "Models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_46",
            "start": 0,
            "end": 6,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_46@1",
            "content": "To simulate varying non-native English proficiency levels, we use MiniBERTa models (Warstadt et al., 2020b) 100M, and 1B tokens.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_46",
            "start": 8,
            "end": 135,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_46@2",
            "content": "We also use the base RoBERTa model (Liu et al., 2019b), trained with 30B tokens.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_46",
            "start": 137,
            "end": 216,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_46@3",
            "content": "In other languages, there are no available pretrained checkpoints with varying amounts of pretraining data, so we use the mBERT model (Devlin et al., 2019) and a monolingual Transformer LM in each language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_46",
            "start": 218,
            "end": 423,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_46@4",
            "content": "2 We obtain sentence embeddings for our models by taking the average of their contextual token embeddings at the secondto-last layer (i.e., layer 11 for base RoBERTa).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_46",
            "start": 425,
            "end": 591,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_46@5",
            "content": "We use the second-to-last because the last layer is more specialized for the LM pretraining objective and less suitable for sentence embeddings (Liu et al., 2019a).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_46",
            "start": 593,
            "end": 756,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_46@6",
            "content": "Template generation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_46",
            "start": 758,
            "end": 777,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_46@7",
            "content": "We use templates to generate stimuli similar to the 4x4 design in the Bencini and Goldberg (2000) experiment.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_46",
            "start": 779,
            "end": 887,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_46@8",
            "content": "To ensure an adequate sample size, we run multiple empirical trials.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_46",
            "start": 889,
            "end": 956,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_46@9",
            "content": "In each trial, we sample 4 random distinct verbs from a pool of 10 verbs that are compatible with all 4 constructions (cut, hit, get, kick, pull, punch, push, slice, tear, throw).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_46",
            "start": 958,
            "end": 1136,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_46@10",
            "content": "We then randomly fill in the slots for proper names, objects, and complements for each sentence according to its verb, such that the sentence is semantically coherent, and there is no lexical overlap among the sentences of any construction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_46",
            "start": 1138,
            "end": 1377,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_46@11",
            "content": "Table 3 in the ap-2 We use monolingual German and Italian models from https://github.com/dbmdz/berts, and the monolingual Spanish model from Ca\u00f1ete et al. (2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_46",
            "start": 1379,
            "end": 1540,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_46@12",
            "content": "pendix shows a set of template-generated sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_46",
            "start": 1542,
            "end": 1592,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_46@13",
            "content": "In English, we generate 1000 sets of stimuli using this procedure; for other languages, we use the original stimuli from their respective publications.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_46",
            "start": 1594,
            "end": 1744,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_47@0",
            "content": "Evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_47",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_47@1",
            "content": "Similar to the human experiments, we group the sentence embeddings into 4 clusters (not necessarily of the same size) using agglomerative clustering by Euclidean distance (Pedregosa et al., 2011).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_47",
            "start": 12,
            "end": 207,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_47@2",
            "content": "We then compute the deviation to a pure construction and pure verb sort using the Hungarian algorithm for optimal bipartite matching.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_47",
            "start": 209,
            "end": 341,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_47@3",
            "content": "This measures the minimal number of cluster assignment changes necessary to reach a pure construction or verb sort, ranging from 0 to 12.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_47",
            "start": 343,
            "end": 479,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_47@4",
            "content": "Thus, lower construction deviation indicates that constructional information is more salient in the LM's embeddings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_47",
            "start": 481,
            "end": 596,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_48@0",
            "content": "Results and interpretation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_48",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_49@0",
            "content": "Figure 2 shows the LM sentence sorting results for English.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_49",
            "start": 0,
            "end": 58,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_49@1",
            "content": "All differences are statistically significant (p < .001).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_49",
            "start": 60,
            "end": 116,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_49@2",
            "content": "The smallest 1M MiniBERTa model is the only LM to prefer verb over construction sorting, and as the amount of pretraining data grows, the LMs increasingly prefer sorting by construction instead of by verb.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_49",
            "start": 118,
            "end": 322,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_49@3",
            "content": "This closely mirrors the trend observed in the human experiments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_49",
            "start": 324,
            "end": 388,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_50@0",
            "content": "The results for multilingual sorting are shown in Figure 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_50",
            "start": 0,
            "end": 58,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_50@1",
            "content": "Both mBERT and the monolingual LMs consistently prefer constructional sorting over verb (Kirsch, 2019), Italian (Baicchi and Della Putta, 2019), and Spanish (V\u00e1zquez, 2004).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_50",
            "start": 60,
            "end": 232,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_50@2",
            "content": "LM results are obtained using the same stimuli; we use both mBERT and a monolingual LM for each language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_50",
            "start": 234,
            "end": 338,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_51@0",
            "content": "sorting in all three languages, whereas the results from the human experiments are less consistent.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_51",
            "start": 0,
            "end": 98,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_52@0",
            "content": "Our results show that RoBERTa can generalize meaning from abstract constructions without lexical overlap.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_52",
            "start": 0,
            "end": 104,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_52@1",
            "content": "Only larger LMs and English speakers of more advanced proficiency are able to make this generalization, while smaller LMs and less proficient speakers derive meaning more from surface features like lexical content.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_52",
            "start": 106,
            "end": 319,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_52@2",
            "content": "This finding agrees with Warstadt et al. (2020b), who found that larger LMs have an inductive bias towards linguistic generalizations, while smaller LMs have an inductive bias towards surface generalizations; this may explain the success of large LMs on downstream tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_52",
            "start": 321,
            "end": 591,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_52@3",
            "content": "A small quantity of data (10M tokens) is sufficient for LMs to prefer the constructional sort, indicating that ASCs are relatively easy to learn: roughly on par with other types of linguistic knowledge, and requiring less data than commonsense knowledge (Zhang et al., 2021;Liu et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_52",
            "start": 593,
            "end": 884,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_53@0",
            "content": "We note some limitations in these results, and reasons to avoid drawing unreasonably strong conclusions from them.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_53",
            "start": 0,
            "end": 113,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_53@1",
            "content": "Human sentence sorting experiments can be influenced by minor differences in the experimental setup: Bencini and Goldberg (2000) obtained significantly different results in two runs that only differed on the precise wording of instructions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_53",
            "start": 115,
            "end": 354,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_53@2",
            "content": "In the German experiment (Kirsch, 2019), the author hypothesized that the participants were influenced by a different experiment that they had completed before the sentence sorting one.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_53",
            "start": 356,
            "end": 540,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_53@3",
            "content": "Given this experimental variation, we cannot attribute differences across languages to differences in their linguistic typology.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_53",
            "start": 542,
            "end": 669,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_53@4",
            "content": "Although LMs do not suffer from the same experimental variation, we cannot conclude statistical significance from the multilingual experiments, where only one set of stimuli is available in each language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_53",
            "start": 671,
            "end": 874,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_54@0",
            "content": "Case study 2: Jabberwocky constructions",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_54",
            "start": 0,
            "end": 38,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_55@0",
            "content": "We next adapt the \"Jabberwocky\" priming experiment from Johnson and Goldberg (2013) to LMs, and make several changes to the original setup to better assess the capabilities of LMs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_55",
            "start": 0,
            "end": 179,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_55@1",
            "content": "Priming is a standard experimental paradigm in psycholinguistic research, but it is not directly applicable to LMs: existing methods simulate priming either by applying additional fine-tuning (Prasad et al., 2019), or by concatenating sentences that typically do not co-occur in natural text (Misra et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_55",
            "start": 181,
            "end": 493,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_55@2",
            "content": "Therefore, we instead propose a method to probe LMs for the same linguistic information using only distance measurements on their contextual embeddings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_55",
            "start": 495,
            "end": 646,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_56@0",
            "content": "Methodology",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_56",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_57@0",
            "content": "Template generation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_57",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_57@1",
            "content": "We generate sentences for the four constructions randomly using the templates in Table 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_57",
            "start": 21,
            "end": 109,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_57@2",
            "content": "Instead of filling nonce words like norp into the templates as in the original study, we take an approach similar to Gulordava et al. (2018) and generate 5000 sentences for each construction She traded her the epicenter gave made put took",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_57",
            "start": 111,
            "end": 348,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_58@0",
            "content": "Ditransitive S/he V-ed him/her the N. She traded her the epicenter.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_58",
            "start": 0,
            "end": 66,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_58@1",
            "content": "He flew her the donut.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_58",
            "start": 68,
            "end": 89,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_59@0",
            "content": "Resultative S/he V-ed it Adj.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_59",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_60@0",
            "content": "He cut it seasonal. She surged it civil.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_60",
            "start": 0,
            "end": 39,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_61@0",
            "content": "Caused-motion S/he V-ed it on the N. He registered it on the diamond.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_61",
            "start": 0,
            "end": 68,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_61@1",
            "content": "She awarded it on the corn.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_61",
            "start": 70,
            "end": 96,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_62@0",
            "content": "S/he V-ed it from him/her.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_62",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_62@1",
            "content": "He declined it from her.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_62",
            "start": 27,
            "end": 50,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_62@2",
            "content": "She drove it from him.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_62",
            "start": 52,
            "end": 73,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_62@3",
            "content": "by randomly filling real words of the appropriate part-of-speech into construction templates (Table 2).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_62",
            "start": 75,
            "end": 177,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_62@4",
            "content": "This gives nonsense sentences like \"She traded her the epicenter\"; we refer to these random words as Jabberwocky words.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_62",
            "start": 179,
            "end": 297,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_62@5",
            "content": "By using real words, we avoid any potential instability from feeding tokens into the model that it has never seen during pretraining.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_62",
            "start": 299,
            "end": 431,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_62@6",
            "content": "We obtain a set of singular nouns, past tense verbs, and adjectives from the Penn Treebank (Marcus et al., 1993), excluding words with fewer than 10 occurrences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_62",
            "start": 433,
            "end": 593,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_62@7",
            "content": "Verb embeddings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_62",
            "start": 595,
            "end": 610,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_62@8",
            "content": "Our probing strategy is based on the assumption that the contextual embedding for a verb captures its meaning in context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_62",
            "start": 612,
            "end": 732,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_62@9",
            "content": "Therefore, if LMs associate ASCs with meaning, we should expect the contextual embedding for the Jabberwocky verb to contain the meaning of the construction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_62",
            "start": 734,
            "end": 890,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_62@10",
            "content": "Specifically, we measure the Euclidean distance to a prototype verb for each construction (Figure 4).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_62",
            "start": 892,
            "end": 992,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_62@11",
            "content": "These are verbs that Johnson and Goldberg (2013) selected whose meaning closely resembles the construction's meaning: gave, made, put, and took for the ditransitive, resultative, caused-motion, and removal constructions, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_62",
            "start": 994,
            "end": 1227,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_62@12",
            "content": "3 We also run the same setup using lower frequency prototype verbs from the same study: handed, turned, placed, and removed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_62",
            "start": 1229,
            "end": 1352,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_62@13",
            "content": "4 As a control, we measure the Euclidean distance to the prototype verbs of the other three unrelated constructions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_62",
            "start": 1354,
            "end": 1469,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_63@0",
            "content": "The prototype verb embeddings are generated by taking the average across their contextual embeddings across a 4M-word subset of the British National Corpus (BNC; Leech (1992)).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_63",
            "start": 0,
            "end": 175,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_63@1",
            "content": "We use the second-to-last layer of RoBERTa-base, and in cases where a verb is split into multiple subwords, we take the embedding of the first subword token as the verb embedding.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_63",
            "start": 177,
            "end": 355,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_64@0",
            "content": "Results and interpretation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_64",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_65@0",
            "content": "We find that the Euclidean distance between the prototype and Jabberwocky verb embeddings is significantly lower (p < .001) when the verb is congruent with the construction than when they are incongruent, and this is observed for both high and low-frequency prototype verbs (Figure 5).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_65",
            "start": 0,
            "end": 284,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_65@1",
            "content": "Examining the individual constructions and verbs (Figure 6), we note that in the high-frequency scenario, the lowest distance prototype verb is always the congruent one, for all four constructions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_65",
            "start": 286,
            "end": 482,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_65@2",
            "content": "In the low-frequency scenario, the result is less consis-11.899 12.295 12.567 12.328 11.924 11.701 11.868 11.864 11.691 11.593 11.395 11.599 11.740 11.954 11.936 tent: the congruent verb is not always the lowest distance one, although it is always still at most the second-lowest distance out of the four.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_65",
            "start": 484,
            "end": 788,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_66@0",
            "content": "The main result holds for both high and lowfrequency scenarios, but the correct prototype verb is associated more consistently in the highfrequency case.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_66",
            "start": 0,
            "end": 152,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_66@1",
            "content": "This agrees with Wei et al. (2021), who found that LMs have greater difficulty learning the linguistic properties of less frequent words.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_66",
            "start": 154,
            "end": 290,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_66@2",
            "content": "We also note that the Euclidean distances are higher overall in the low-frequency scenario, which is consistent with previous work that found lower frequency words to occupy a peripheral region of the embedding space .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_66",
            "start": 292,
            "end": 509,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_67@0",
            "content": "Potential confounds",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_67",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_68@0",
            "content": "In any experiment, one must be careful to ensure that the observed patterns are due to the phenomenon under investigation rather than confounding factors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_68",
            "start": 0,
            "end": 153,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_68@1",
            "content": "We discuss potential confounds arising from lexical overlap, anisotropy of contextual embeddings, and neighboring words.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_68",
            "start": 155,
            "end": 274,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_69@0",
            "content": "Lexical overlap.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_69",
            "start": 0,
            "end": 15,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_69@1",
            "content": "The randomized experiment design ensures that the Jabberwocky words cannot be lexically biased towards any construction, since each verb is equally likely to occur in every construction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_69",
            "start": 17,
            "end": 202,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_69@2",
            "content": "Technically, the lexical content in the four constructions are not identical: i.e., words such as \"from\" (occurring only in the removal construction) or \"on\" (in the caused-motion construction) may provide hints to the sentence meaning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_69",
            "start": 204,
            "end": 439,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_69@3",
            "content": "However, the ditransitive and resultative constructions do not contain any such informative words, yet RoBERTa still associates the correct prototype verb for these constructions, so we consider it unlikely to be relying solely on lexical overlap.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_69",
            "start": 441,
            "end": 687,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_69@4",
            "content": "There is substantial evidence that RoBERTa is able to associate abstract constructional templates with their meaning without lexical cues.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_69",
            "start": 689,
            "end": 826,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_69@5",
            "content": "This result is perhaps surprising, given that previous work found that LMs are relatively insensitive to word order in compositional phrases (Yu and Ettinger, 2020) and downstream inference tasks (Sinha et al., 2021;Pham et al., 2021), where their performance can be largely attributed to lexical overlap.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_69",
            "start": 828,
            "end": 1132,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_70@0",
            "content": "Anisotropy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_70",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_70@1",
            "content": "Recent probing work have found that contextual embeddings suffer from anisotropy, where embeddings lie in a narrow cone and have much higher cosine similarity than expected if they were directionally uniform (Ethayarajh, 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_70",
            "start": 12,
            "end": 238,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_70@2",
            "content": "Furthermore, a small number of dimensions dominate geometric measures such as Euclidean and cosine distance, resulting in a degradation of representation quality (Kovaleva et al., 2021;Timkey and van Schijndel, 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_70",
            "start": 240,
            "end": 456,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_70@3",
            "content": "Since our experiments rely heavily on Euclidean distance, anisotropy is a significant concern.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_70",
            "start": 458,
            "end": 551,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_70@4",
            "content": "Following Timkey and van Schijndel (2021), we perform standardization by subtracting the mean vector and dividing each dimension by its standard deviation, where the mean and standard deviation for each dimension is computed from a sample of the BNC.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_70",
            "start": 553,
            "end": 802,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_70@5",
            "content": "We observe little difference after standardization: in both the high and low frequency scenarios, the Euclidean distances are lower for the congruent than the incongruent conditions, by a similar margin compared to the original experiment without standardization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_70",
            "start": 804,
            "end": 1066,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_70@6",
            "content": "We also run standardization on the first case study, and find that the results remain essentially unchanged: smaller LMs still prefer verb sorting while larger LMs prefer construction sorting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_70",
            "start": 1068,
            "end": 1259,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_70@7",
            "content": "Thus, neither of our experiments appear to be affected by anisotropy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_70",
            "start": 1261,
            "end": 1329,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_71@0",
            "content": "Neighboring words.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_71",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_71@1",
            "content": "A final confounding factor is our assumption that RoBERTa's contextual embeddings represent word meaning, when in reality, they contain a mixture of syntactic and semantic information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_71",
            "start": 19,
            "end": 202,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_71@2",
            "content": "Contextual embeddings are known to contain syntax trees (Hewitt and Manning, 2019) and linguistic information about neighboring words in a sentence (Klafka and Ettinger, 2020); although previous work did not consider ASCs, it is plausible that our verb embeddings leak information about the sentence's construction in a similar manner.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_71",
            "start": 204,
            "end": 538,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_71@3",
            "content": "If this were the case, the prototype verb embedding for gave would contain not only the semantics of transfer that we intended, but also information about its usual syntactic form 5 of \"S gave NP1 NP2\", and both would be captured by our Euclidean distance measurement.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_71",
            "start": 540,
            "end": 807,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_71@4",
            "content": "Controlling for this syntactic confound is difficult -one could alternatively probe for transfer semantics without syntactic confounds using a natural language inference setup (e.g., whether the sentence entails the statement \"NP1 received NP2\"), but we leave further exploration of this idea to future work.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_71",
            "start": 809,
            "end": 1116,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_72@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_72",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_73@0",
            "content": "We find evidence for argument structure constructions in Transformer language models from two separate angles: sentence sorting and Jabberwocky construction experiments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_73",
            "start": 0,
            "end": 168,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_73@1",
            "content": "Our work extends the existing body of literature on LM probing by taking a constructionist instead of generative approach to linguistic probing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_73",
            "start": 170,
            "end": 313,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_73@2",
            "content": "Our sentence sorting experiments identified a striking resemblance between humans' and LMs' internal language representations as LMs are exposed to increasing quantities of data, despite the differences between neural language models and the human brain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_73",
            "start": 315,
            "end": 568,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_73@3",
            "content": "Our two studies suggest that LMs are able to derive meaning from abstract constructional templates with minimal lexical overlap.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_73",
            "start": 570,
            "end": 697,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_73@4",
            "content": "Both sets of experiments were inspired by psycholinguistic studies, which we adapted to fit the capabilities of LMs -this illustrates the potential for future work on grounding LM probing methodologies in psycholinguistic research.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_73",
            "start": 699,
            "end": 929,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_74@0",
            "content": "We use principal components analysis (PCA) to visualize the sentence sorting experiment for the MiniBERTa models (trained with 1M and 100M tokens) and RoBERTa-base (trained with 30B tokens).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_74",
            "start": 0,
            "end": 189,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_74@1",
            "content": "In RoBERTa, there is strong evidence of clustering based on constructions; the effect is unclear in the 100M model and nonexistent in the 1M model (Figure 7).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_74",
            "start": 191,
            "end": 348,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_74@2",
            "content": "This visually confirms our quantitative evaluation based on the construction and verb deviation metrics (Figure 2).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_74",
            "start": 350,
            "end": 464,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_75@0",
            "content": "Table 3 shows an example set of templategenerated stimuli for sentence sorting: we generate 1000 similar sets of 16 sentences to increase the sample size.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_75",
            "start": 0,
            "end": 153,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_75@1",
            "content": "We also present the sentence sorting stimuli for German (Table 4), Italian (Table 5), and Spanish (Table 6).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_75",
            "start": 155,
            "end": 262,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_75@2",
            "content": "German uses the same four constructions as English.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_75",
            "start": 264,
            "end": 314,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_75@3",
            "content": "Italian does not have the ditransitive construction but instead uses the prepositional dative construction to express transfer semantics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_75",
            "start": 316,
            "end": 452,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_75@4",
            "content": "Spanish has no equivalents for the causedmotion and resultative constructions, so the authors in that experiment instead used the unplanned reflexive (expressing accidental or unplanned events), and the middle construction (expressing states pertaining to the subject).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_75",
            "start": 454,
            "end": 722,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_76@0",
            "content": "UNKNOWN, None, 2019, Constructions at work in foreign language learners' mind: A comparison between two sentence-sorting experiments with English and Italian learners. Review of Cognitive Linguistics. Published under the auspices of the Spanish Cognitive Linguistics Association, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_76",
            "start": 0,
            "end": 280,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_77@0",
            "content": "M Giulia, Adele Bencini,  Goldberg, The contribution of argument structure constructions to sentence meaning, 2000, Journal of Memory and Language, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_77",
            "start": 0,
            "end": 148,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_78@0",
            "content": "Kathryn Bock, Helga Loebell, Framing sentences, 1990, Cognition, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_78",
            "start": 0,
            "end": 65,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_79@0",
            "content": "UNKNOWN, None, 2003, The gradience of the dative alternation. Unpublished manuscript, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_79",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_80@0",
            "content": "UNKNOWN, None, 2020, Spanish pre-trained BERT model and evaluation data, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_80",
            "start": 0,
            "end": 73,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_81@0",
            "content": "UNKNOWN, None, 1965, Aspects of the Theory of Syntax, MIT Press.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_81",
            "start": 0,
            "end": 63,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_82@0",
            "content": "UNKNOWN, None, 1981, Lectures on Government and Binding, Foris Publications.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_82",
            "start": 0,
            "end": 75,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_83@0",
            "content": "UNKNOWN, None, 1986, Knowledge of Language, Praeger.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_83",
            "start": 0,
            "end": 51,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_84@0",
            "content": "UNKNOWN, None, 1995, The Minimalist Program, The MIT Press.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_84",
            "start": 0,
            "end": 58,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_85@0",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_85",
            "start": 0,
            "end": 294,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_86@0",
            "content": "Jesse Dunietz, Lori Levin, Jaime Carbonell, Annotating causal language using corpus lexicography of constructions, 2015, Proceedings of The 9th Linguistic Annotation Workshop, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_86",
            "start": 0,
            "end": 176,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_87@0",
            "content": "Jonathan Dunn, Computational learning of construction grammars, 2017, Language and Cognition, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_87",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_88@0",
            "content": "Kawin Ethayarajh, How contextual are contextualized word representations? comparing the geometry of BERT, ELMo, and GPT-2 embeddings, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_88",
            "start": 0,
            "end": 317,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_89@0",
            "content": "Allyson Ettinger, What BERT is not: Lessons from a new suite of psycholinguistic diagnostics for language models, 2020, Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_89",
            "start": 0,
            "end": 183,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_90@0",
            "content": "Charles Fillmore, Paul Kay, Mary Catherine, O' Connor, Regularity and idiomaticity in grammatical constructions: The case of let alone, 1988, Language, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_90",
            "start": 0,
            "end": 152,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_91@0",
            "content": "UNKNOWN, None, 1995, Constructions: A construction grammar approach to argument structure, University of Chicago Press.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_91",
            "start": 0,
            "end": 118,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_92@0",
            "content": "UNKNOWN, None, 2006, Constructions at Work: The Nature of Generalization in Language, Oxford University Press.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_92",
            "start": 0,
            "end": 109,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_93@0",
            "content": "Stefan Th Gries, Stefanie Wulff, Do foreign language learners also have constructions?, 2005, Annual Review of Cognitive Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_93",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_94@0",
            "content": "Kristina Gulordava, Piotr Bojanowski, \u00c9douard Grave, Tal Linzen, Marco Baroni, Colorless green recurrent networks dream hierarchically, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_94",
            "start": 0,
            "end": 297,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_95@0",
            "content": "John Hewitt, D Christopher,  Manning, A structural probe for finding syntax in word representations, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_95",
            "start": 0,
            "end": 251,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_96@0",
            "content": "Jennifer Hu, Jon Gauthier, Peng Qian, Ethan Wilcox, Roger Levy, A systematic assessment of syntactic generalization in neural language models, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_96",
            "start": 0,
            "end": 238,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_97@0",
            "content": "D Jena, Martha Hwang,  Palmer, Identification of caused motion construction, 2015, Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_97",
            "start": 0,
            "end": 166,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_98@0",
            "content": "A Matt, Adele Johnson,  Goldberg, Evidence for automatic accessing of constructional meaning: Jabberwocky sentences prime associated verbs, 2013, Language and Cognitive Processes, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_98",
            "start": 0,
            "end": 180,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_99@0",
            "content": "UNKNOWN, None, 1982, Lexical functional grammar: A formal system for grammatical representation, MIT Press.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_99",
            "start": 0,
            "end": 106,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_100@0",
            "content": "P Michael, Arthur Kaschak,  Glenberg, Constructing meaning: The role of affordances and grammatical constructions in sentence comprehension, 2000, Journal of memory and language, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_100",
            "start": 0,
            "end": 179,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_101@0",
            "content": "UNKNOWN, None, 1999, Grammatical constructions and linguistic generalizations: The What's X Doing Y? construction. Language, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_101",
            "start": 0,
            "end": 125,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_102@0",
            "content": "UNKNOWN, None, 2019, The psychological reality of argument structure constructions: A visual world eye tracking study, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_102",
            "start": 0,
            "end": 119,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_103@0",
            "content": "Josef Klafka, Allyson Ettinger, Spying on your neighbors: Fine-grained probing of contextual embeddings for information about surrounding words, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_103",
            "start": 0,
            "end": 240,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_104@0",
            "content": "Olga Kovaleva, Saurabh Kulshreshtha, Anna Rogers, Anna Rumshisky, BERT busters: Outlier dimensions that disrupt Transformers, 2021, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_104",
            "start": 0,
            "end": 208,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_105@0",
            "content": "E Gianluca, Alessandro Lebani,  Lenci, beware the Jabberwock, dear reader!\" Testing the distributional reality of construction semantics, 2016, Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex-V), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_105",
            "start": 0,
            "end": 225,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_106@0",
            "content": "UNKNOWN, None, , million words of English: the British National Corpus (BNC). Language Research, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_106",
            "start": 0,
            "end": 97,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_107@0",
            "content": "UNKNOWN, None, 1995, Unaccusativity in the Syntax-Lexical Semantics Interface, MIT Press.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_107",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_108@0",
            "content": "UNKNOWN, None, 2005, Argument Realization, Cambridge University Press.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_108",
            "start": 0,
            "end": 69,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_109@0",
            "content": "Bai Li, Zining Zhu, Guillaume Thomas, Yang Xu, Frank Rudzicz, How is BERT surprised? Layerwise detection of linguistic anomalies, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_109",
            "start": 0,
            "end": 311,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_110@0",
            "content": "UNKNOWN, None, 2002, Sentence comprehension by Chinese learners of English: Verb-centered or construction-based?, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_110",
            "start": 0,
            "end": 114,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_111@0",
            "content": "Tal Linzen, Marco Baroni, Syntactic structure from deep learning, 2021, Annual Review of Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_111",
            "start": 0,
            "end": 102,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_112@0",
            "content": "Tal Linzen, Emmanuel Dupoux, Yoav Goldberg, Assessing the ability of LSTMs to learn syntax-sensitive dependencies, 2016, Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_112",
            "start": 0,
            "end": 184,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_113@0",
            "content": "Z Leo, Yizhong Liu, Jungo Wang, Hannaneh Kasai, Noah A Hajishirzi,  Smith, Probing across time: What does RoBERTa know and when?, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: Findings, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_113",
            "start": 0,
            "end": 234,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_114@0",
            "content": "F Nelson, Matt Liu, Yonatan Gardner,  Belinkov, E Matthew, Noah A Peters,  Smith, Linguistic knowledge and transferability of contextual representations, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_114",
            "start": 0,
            "end": 304,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_115@0",
            "content": "UNKNOWN, None, 2019, RoBERTa: A robustly optimized BERT pretraining approach, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_115",
            "start": 0,
            "end": 78,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_116@0",
            "content": "Laurence Harish Tayyar Madabushi, Dagmar Romain, Petar Divjak,  Milin, CxGBERT: BERT meets construction grammar, 2020, Proceedings of the 28th International Conference on Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_116",
            "start": 0,
            "end": 198,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_117@0",
            "content": "UNKNOWN, None, 1993, Building a large annotated corpus of English: The Penn Treebank, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_117",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_118@0",
            "content": "James Michaelov, Benjamin Bergen, How well does surprisal explain N400 amplitude under different experimental conditions?, 2020, Proceedings of the 24th Conference on Computational Natural Language Learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_118",
            "start": 0,
            "end": 208,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_119@0",
            "content": "Kanishka Misra, Allyson Ettinger, Julia Rayz, Exploring BERT's sensitivity to lexical cues using tests from semantic priming, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_119",
            "start": 0,
            "end": 230,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_120@0",
            "content": "Fabian Pedregosa, Ga\u00ebl Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, Scikit-learn: Machine learning in Python, 2011, Journal of machine Learning research, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_120",
            "start": 0,
            "end": 255,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_121@0",
            "content": "Thang Pham, Trung Bui, Long Mai, Anh Nguyen, Out of order: How important is the sequential order of words in a sentence in natural language understanding tasks?, 2021, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_121",
            "start": 0,
            "end": 244,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_122@0",
            "content": "J Martin,  Pickering, S Victor,  Ferreira, Structural priming: a critical review, 2008, Psychological bulletin, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_122",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_123@0",
            "content": "UNKNOWN, None, 1987, Information-Based Syntax and Semantics, CSLI.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_123",
            "start": 0,
            "end": 65,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_124@0",
            "content": "Grusha Prasad, Marten Van Schijndel, Tal Linzen, Using priming to uncover the organization of syntactic representations in neural language models, 2019, Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_124",
            "start": 0,
            "end": 240,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_125@0",
            "content": "UNKNOWN, None, 1996, The Empirical Base of Linguistics: Grammaticality Judgments and Linguistic Methodology, University of Chicago Press.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_125",
            "start": 0,
            "end": 136,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_126@0",
            "content": "Koustuv Sinha, Prasanna Parthasarathi, Joelle Pineau, Adina Williams, UnNatural Language Inference, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_126",
            "start": 0,
            "end": 281,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_127@0",
            "content": "William Timkey, Marten Van Schijndel, All bark and no bite: Rogue dimensions in transformer language models obscure representational quality, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_127",
            "start": 0,
            "end": 236,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_128@0",
            "content": "Montserrat Mart\u00ednez,  V\u00e1zquez, Learning argument structure generalizations in a foreign language, 2004, Vigo International Journal of Applied Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_128",
            "start": 0,
            "end": 155,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_129@0",
            "content": "Alex Warstadt, Alicia Parrish, Haokun Liu, Anhad Mohananey, Wei Peng, Sheng-Fu Wang, Samuel R Bowman, BLiMP: The benchmark of linguistic minimal pairs for English, 2020, Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_129",
            "start": 0,
            "end": 233,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_130@0",
            "content": "Alex Warstadt, Amanpreet Singh, Samuel R Bowman, Neural network acceptability judgments, 2019, Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_130",
            "start": 0,
            "end": 158,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_131@0",
            "content": "Alex Warstadt, Yian Zhang, Xiaocheng Li, Haokun Liu, Samuel R Bowman, Learning which features matter: RoBERTa acquires a preference for linguistic generalizations (eventually), 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_131",
            "start": 0,
            "end": 276,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_132@0",
            "content": "Jason Wei, Dan Garrette, Tal Linzen, Ellie Pavlick, Frequency effects on syntactic rule learning in transformers, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_132",
            "start": 0,
            "end": 213,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_133@0",
            "content": "Ethan Wilcox, Pranali Vani, Roger Levy, A targeted assessment of incremental processing in neural language models and humans, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_133",
            "start": 0,
            "end": 307,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_134@0",
            "content": "Lang Yu, Allyson Ettinger, Assessing phrasal representation and composition in transformers, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_134",
            "start": 0,
            "end": 195,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_135@0",
            "content": "Yian Zhang, Alex Warstadt, Haau-Sing Li, Samuel R Bowman, When do you need billions of words of pretraining data?, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_135",
            "start": 0,
            "end": 210,
            "label": {}
        },
        {
            "ix": "317-ARR_v2_136@0",
            "content": "Jayden Ziegler, Giulia Bencini, Adele Goldberg, Jesse Snedeker, How abstract is syntax? Evidence from structural priming, 2019, Cognition, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "317-ARR_v2_136",
            "start": 0,
            "end": 139,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "317-ARR_v2_0",
            "tgt_ix": "317-ARR_v2_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_0",
            "tgt_ix": "317-ARR_v2_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_1",
            "tgt_ix": "317-ARR_v2_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_1",
            "tgt_ix": "317-ARR_v2_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_0",
            "tgt_ix": "317-ARR_v2_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_2",
            "tgt_ix": "317-ARR_v2_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_3",
            "tgt_ix": "317-ARR_v2_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_3",
            "tgt_ix": "317-ARR_v2_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_5",
            "tgt_ix": "317-ARR_v2_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_6",
            "tgt_ix": "317-ARR_v2_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_7",
            "tgt_ix": "317-ARR_v2_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_3",
            "tgt_ix": "317-ARR_v2_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_3",
            "tgt_ix": "317-ARR_v2_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_3",
            "tgt_ix": "317-ARR_v2_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_3",
            "tgt_ix": "317-ARR_v2_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_4",
            "tgt_ix": "317-ARR_v2_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_0",
            "tgt_ix": "317-ARR_v2_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_8",
            "tgt_ix": "317-ARR_v2_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_9",
            "tgt_ix": "317-ARR_v2_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_9",
            "tgt_ix": "317-ARR_v2_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_11",
            "tgt_ix": "317-ARR_v2_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_12",
            "tgt_ix": "317-ARR_v2_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_10",
            "tgt_ix": "317-ARR_v2_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_10",
            "tgt_ix": "317-ARR_v2_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_10",
            "tgt_ix": "317-ARR_v2_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_10",
            "tgt_ix": "317-ARR_v2_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_9",
            "tgt_ix": "317-ARR_v2_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_13",
            "tgt_ix": "317-ARR_v2_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_14",
            "tgt_ix": "317-ARR_v2_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_14",
            "tgt_ix": "317-ARR_v2_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_16",
            "tgt_ix": "317-ARR_v2_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_17",
            "tgt_ix": "317-ARR_v2_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_14",
            "tgt_ix": "317-ARR_v2_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_14",
            "tgt_ix": "317-ARR_v2_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_14",
            "tgt_ix": "317-ARR_v2_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_15",
            "tgt_ix": "317-ARR_v2_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_19",
            "tgt_ix": "317-ARR_v2_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_20",
            "tgt_ix": "317-ARR_v2_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_21",
            "tgt_ix": "317-ARR_v2_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_14",
            "tgt_ix": "317-ARR_v2_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_14",
            "tgt_ix": "317-ARR_v2_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_14",
            "tgt_ix": "317-ARR_v2_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_14",
            "tgt_ix": "317-ARR_v2_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_18",
            "tgt_ix": "317-ARR_v2_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_23",
            "tgt_ix": "317-ARR_v2_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_24",
            "tgt_ix": "317-ARR_v2_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_14",
            "tgt_ix": "317-ARR_v2_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_14",
            "tgt_ix": "317-ARR_v2_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_14",
            "tgt_ix": "317-ARR_v2_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_22",
            "tgt_ix": "317-ARR_v2_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_26",
            "tgt_ix": "317-ARR_v2_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_27",
            "tgt_ix": "317-ARR_v2_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_28",
            "tgt_ix": "317-ARR_v2_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_29",
            "tgt_ix": "317-ARR_v2_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_30",
            "tgt_ix": "317-ARR_v2_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_31",
            "tgt_ix": "317-ARR_v2_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_32",
            "tgt_ix": "317-ARR_v2_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_33",
            "tgt_ix": "317-ARR_v2_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_34",
            "tgt_ix": "317-ARR_v2_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_35",
            "tgt_ix": "317-ARR_v2_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_36",
            "tgt_ix": "317-ARR_v2_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_14",
            "tgt_ix": "317-ARR_v2_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_14",
            "tgt_ix": "317-ARR_v2_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_14",
            "tgt_ix": "317-ARR_v2_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_14",
            "tgt_ix": "317-ARR_v2_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_14",
            "tgt_ix": "317-ARR_v2_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_14",
            "tgt_ix": "317-ARR_v2_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_14",
            "tgt_ix": "317-ARR_v2_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_14",
            "tgt_ix": "317-ARR_v2_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_14",
            "tgt_ix": "317-ARR_v2_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_14",
            "tgt_ix": "317-ARR_v2_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_14",
            "tgt_ix": "317-ARR_v2_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_14",
            "tgt_ix": "317-ARR_v2_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_25",
            "tgt_ix": "317-ARR_v2_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_0",
            "tgt_ix": "317-ARR_v2_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_37",
            "tgt_ix": "317-ARR_v2_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_39",
            "tgt_ix": "317-ARR_v2_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_38",
            "tgt_ix": "317-ARR_v2_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_38",
            "tgt_ix": "317-ARR_v2_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_38",
            "tgt_ix": "317-ARR_v2_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_0",
            "tgt_ix": "317-ARR_v2_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_40",
            "tgt_ix": "317-ARR_v2_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_41",
            "tgt_ix": "317-ARR_v2_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_41",
            "tgt_ix": "317-ARR_v2_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_0",
            "tgt_ix": "317-ARR_v2_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_42",
            "tgt_ix": "317-ARR_v2_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_43",
            "tgt_ix": "317-ARR_v2_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_43",
            "tgt_ix": "317-ARR_v2_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_43",
            "tgt_ix": "317-ARR_v2_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_44",
            "tgt_ix": "317-ARR_v2_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_46",
            "tgt_ix": "317-ARR_v2_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_45",
            "tgt_ix": "317-ARR_v2_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_45",
            "tgt_ix": "317-ARR_v2_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_45",
            "tgt_ix": "317-ARR_v2_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_43",
            "tgt_ix": "317-ARR_v2_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_47",
            "tgt_ix": "317-ARR_v2_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_49",
            "tgt_ix": "317-ARR_v2_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_50",
            "tgt_ix": "317-ARR_v2_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_51",
            "tgt_ix": "317-ARR_v2_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_52",
            "tgt_ix": "317-ARR_v2_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_48",
            "tgt_ix": "317-ARR_v2_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_48",
            "tgt_ix": "317-ARR_v2_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_48",
            "tgt_ix": "317-ARR_v2_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_48",
            "tgt_ix": "317-ARR_v2_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_48",
            "tgt_ix": "317-ARR_v2_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_48",
            "tgt_ix": "317-ARR_v2_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_0",
            "tgt_ix": "317-ARR_v2_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_53",
            "tgt_ix": "317-ARR_v2_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_54",
            "tgt_ix": "317-ARR_v2_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_54",
            "tgt_ix": "317-ARR_v2_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_54",
            "tgt_ix": "317-ARR_v2_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_55",
            "tgt_ix": "317-ARR_v2_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_56",
            "tgt_ix": "317-ARR_v2_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_56",
            "tgt_ix": "317-ARR_v2_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_58",
            "tgt_ix": "317-ARR_v2_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_59",
            "tgt_ix": "317-ARR_v2_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_60",
            "tgt_ix": "317-ARR_v2_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_56",
            "tgt_ix": "317-ARR_v2_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_56",
            "tgt_ix": "317-ARR_v2_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_56",
            "tgt_ix": "317-ARR_v2_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_56",
            "tgt_ix": "317-ARR_v2_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_57",
            "tgt_ix": "317-ARR_v2_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_62",
            "tgt_ix": "317-ARR_v2_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_56",
            "tgt_ix": "317-ARR_v2_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_56",
            "tgt_ix": "317-ARR_v2_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_61",
            "tgt_ix": "317-ARR_v2_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_54",
            "tgt_ix": "317-ARR_v2_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_63",
            "tgt_ix": "317-ARR_v2_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_65",
            "tgt_ix": "317-ARR_v2_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_64",
            "tgt_ix": "317-ARR_v2_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_64",
            "tgt_ix": "317-ARR_v2_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_64",
            "tgt_ix": "317-ARR_v2_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_54",
            "tgt_ix": "317-ARR_v2_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_66",
            "tgt_ix": "317-ARR_v2_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_68",
            "tgt_ix": "317-ARR_v2_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_69",
            "tgt_ix": "317-ARR_v2_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_70",
            "tgt_ix": "317-ARR_v2_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_67",
            "tgt_ix": "317-ARR_v2_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_67",
            "tgt_ix": "317-ARR_v2_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_67",
            "tgt_ix": "317-ARR_v2_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_67",
            "tgt_ix": "317-ARR_v2_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_67",
            "tgt_ix": "317-ARR_v2_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_0",
            "tgt_ix": "317-ARR_v2_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_71",
            "tgt_ix": "317-ARR_v2_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_72",
            "tgt_ix": "317-ARR_v2_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_72",
            "tgt_ix": "317-ARR_v2_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_72",
            "tgt_ix": "317-ARR_v2_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_73",
            "tgt_ix": "317-ARR_v2_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_72",
            "tgt_ix": "317-ARR_v2_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_74",
            "tgt_ix": "317-ARR_v2_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "317-ARR_v2_0",
            "tgt_ix": "317-ARR_v2_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_1",
            "tgt_ix": "317-ARR_v2_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_2",
            "tgt_ix": "317-ARR_v2_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_2",
            "tgt_ix": "317-ARR_v2_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_2",
            "tgt_ix": "317-ARR_v2_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_2",
            "tgt_ix": "317-ARR_v2_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_2",
            "tgt_ix": "317-ARR_v2_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_2",
            "tgt_ix": "317-ARR_v2_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_2",
            "tgt_ix": "317-ARR_v2_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_2",
            "tgt_ix": "317-ARR_v2_2@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_2",
            "tgt_ix": "317-ARR_v2_2@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_3",
            "tgt_ix": "317-ARR_v2_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_4",
            "tgt_ix": "317-ARR_v2_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_4",
            "tgt_ix": "317-ARR_v2_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_5",
            "tgt_ix": "317-ARR_v2_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_5",
            "tgt_ix": "317-ARR_v2_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_6",
            "tgt_ix": "317-ARR_v2_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_6",
            "tgt_ix": "317-ARR_v2_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_6",
            "tgt_ix": "317-ARR_v2_6@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_6",
            "tgt_ix": "317-ARR_v2_6@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_6",
            "tgt_ix": "317-ARR_v2_6@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_6",
            "tgt_ix": "317-ARR_v2_6@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_7",
            "tgt_ix": "317-ARR_v2_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_7",
            "tgt_ix": "317-ARR_v2_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_7",
            "tgt_ix": "317-ARR_v2_7@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_7",
            "tgt_ix": "317-ARR_v2_7@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_8",
            "tgt_ix": "317-ARR_v2_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_8",
            "tgt_ix": "317-ARR_v2_8@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_8",
            "tgt_ix": "317-ARR_v2_8@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_8",
            "tgt_ix": "317-ARR_v2_8@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_9",
            "tgt_ix": "317-ARR_v2_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_10",
            "tgt_ix": "317-ARR_v2_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_11",
            "tgt_ix": "317-ARR_v2_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_11",
            "tgt_ix": "317-ARR_v2_11@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_11",
            "tgt_ix": "317-ARR_v2_11@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_11",
            "tgt_ix": "317-ARR_v2_11@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_12",
            "tgt_ix": "317-ARR_v2_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_12",
            "tgt_ix": "317-ARR_v2_12@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_12",
            "tgt_ix": "317-ARR_v2_12@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_12",
            "tgt_ix": "317-ARR_v2_12@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_12",
            "tgt_ix": "317-ARR_v2_12@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_13",
            "tgt_ix": "317-ARR_v2_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_13",
            "tgt_ix": "317-ARR_v2_13@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_13",
            "tgt_ix": "317-ARR_v2_13@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_14",
            "tgt_ix": "317-ARR_v2_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_15",
            "tgt_ix": "317-ARR_v2_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_15",
            "tgt_ix": "317-ARR_v2_15@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_16",
            "tgt_ix": "317-ARR_v2_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_16",
            "tgt_ix": "317-ARR_v2_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_17",
            "tgt_ix": "317-ARR_v2_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_18",
            "tgt_ix": "317-ARR_v2_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_19",
            "tgt_ix": "317-ARR_v2_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_20",
            "tgt_ix": "317-ARR_v2_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_21",
            "tgt_ix": "317-ARR_v2_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_22",
            "tgt_ix": "317-ARR_v2_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_23",
            "tgt_ix": "317-ARR_v2_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_23",
            "tgt_ix": "317-ARR_v2_23@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_24",
            "tgt_ix": "317-ARR_v2_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_25",
            "tgt_ix": "317-ARR_v2_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_26",
            "tgt_ix": "317-ARR_v2_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_26",
            "tgt_ix": "317-ARR_v2_26@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_27",
            "tgt_ix": "317-ARR_v2_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_28",
            "tgt_ix": "317-ARR_v2_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_29",
            "tgt_ix": "317-ARR_v2_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_30",
            "tgt_ix": "317-ARR_v2_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_30",
            "tgt_ix": "317-ARR_v2_30@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_30",
            "tgt_ix": "317-ARR_v2_30@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_30",
            "tgt_ix": "317-ARR_v2_30@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_31",
            "tgt_ix": "317-ARR_v2_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_31",
            "tgt_ix": "317-ARR_v2_31@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_31",
            "tgt_ix": "317-ARR_v2_31@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_31",
            "tgt_ix": "317-ARR_v2_31@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_31",
            "tgt_ix": "317-ARR_v2_31@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_31",
            "tgt_ix": "317-ARR_v2_31@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_32",
            "tgt_ix": "317-ARR_v2_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_32",
            "tgt_ix": "317-ARR_v2_32@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_32",
            "tgt_ix": "317-ARR_v2_32@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_32",
            "tgt_ix": "317-ARR_v2_32@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_32",
            "tgt_ix": "317-ARR_v2_32@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_32",
            "tgt_ix": "317-ARR_v2_32@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_33",
            "tgt_ix": "317-ARR_v2_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_33",
            "tgt_ix": "317-ARR_v2_33@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_33",
            "tgt_ix": "317-ARR_v2_33@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_33",
            "tgt_ix": "317-ARR_v2_33@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_34",
            "tgt_ix": "317-ARR_v2_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_34",
            "tgt_ix": "317-ARR_v2_34@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_34",
            "tgt_ix": "317-ARR_v2_34@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_35",
            "tgt_ix": "317-ARR_v2_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_35",
            "tgt_ix": "317-ARR_v2_35@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_35",
            "tgt_ix": "317-ARR_v2_35@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_35",
            "tgt_ix": "317-ARR_v2_35@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_36",
            "tgt_ix": "317-ARR_v2_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_36",
            "tgt_ix": "317-ARR_v2_36@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_37",
            "tgt_ix": "317-ARR_v2_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_38",
            "tgt_ix": "317-ARR_v2_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_39",
            "tgt_ix": "317-ARR_v2_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_39",
            "tgt_ix": "317-ARR_v2_39@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_39",
            "tgt_ix": "317-ARR_v2_39@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_39",
            "tgt_ix": "317-ARR_v2_39@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_39",
            "tgt_ix": "317-ARR_v2_39@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_40",
            "tgt_ix": "317-ARR_v2_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_40",
            "tgt_ix": "317-ARR_v2_40@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_40",
            "tgt_ix": "317-ARR_v2_40@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_40",
            "tgt_ix": "317-ARR_v2_40@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_40",
            "tgt_ix": "317-ARR_v2_40@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_40",
            "tgt_ix": "317-ARR_v2_40@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_41",
            "tgt_ix": "317-ARR_v2_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_42",
            "tgt_ix": "317-ARR_v2_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_42",
            "tgt_ix": "317-ARR_v2_42@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_42",
            "tgt_ix": "317-ARR_v2_42@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_42",
            "tgt_ix": "317-ARR_v2_42@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_42",
            "tgt_ix": "317-ARR_v2_42@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_42",
            "tgt_ix": "317-ARR_v2_42@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_43",
            "tgt_ix": "317-ARR_v2_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_44",
            "tgt_ix": "317-ARR_v2_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_45",
            "tgt_ix": "317-ARR_v2_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_46",
            "tgt_ix": "317-ARR_v2_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_46",
            "tgt_ix": "317-ARR_v2_46@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_46",
            "tgt_ix": "317-ARR_v2_46@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_46",
            "tgt_ix": "317-ARR_v2_46@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_46",
            "tgt_ix": "317-ARR_v2_46@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_46",
            "tgt_ix": "317-ARR_v2_46@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_46",
            "tgt_ix": "317-ARR_v2_46@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_46",
            "tgt_ix": "317-ARR_v2_46@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_46",
            "tgt_ix": "317-ARR_v2_46@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_46",
            "tgt_ix": "317-ARR_v2_46@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_46",
            "tgt_ix": "317-ARR_v2_46@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_46",
            "tgt_ix": "317-ARR_v2_46@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_46",
            "tgt_ix": "317-ARR_v2_46@12",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_46",
            "tgt_ix": "317-ARR_v2_46@13",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_47",
            "tgt_ix": "317-ARR_v2_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_47",
            "tgt_ix": "317-ARR_v2_47@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_47",
            "tgt_ix": "317-ARR_v2_47@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_47",
            "tgt_ix": "317-ARR_v2_47@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_47",
            "tgt_ix": "317-ARR_v2_47@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_48",
            "tgt_ix": "317-ARR_v2_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_49",
            "tgt_ix": "317-ARR_v2_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_49",
            "tgt_ix": "317-ARR_v2_49@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_49",
            "tgt_ix": "317-ARR_v2_49@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_49",
            "tgt_ix": "317-ARR_v2_49@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_50",
            "tgt_ix": "317-ARR_v2_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_50",
            "tgt_ix": "317-ARR_v2_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_50",
            "tgt_ix": "317-ARR_v2_50@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_51",
            "tgt_ix": "317-ARR_v2_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_52",
            "tgt_ix": "317-ARR_v2_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_52",
            "tgt_ix": "317-ARR_v2_52@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_52",
            "tgt_ix": "317-ARR_v2_52@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_52",
            "tgt_ix": "317-ARR_v2_52@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_53",
            "tgt_ix": "317-ARR_v2_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_53",
            "tgt_ix": "317-ARR_v2_53@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_53",
            "tgt_ix": "317-ARR_v2_53@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_53",
            "tgt_ix": "317-ARR_v2_53@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_53",
            "tgt_ix": "317-ARR_v2_53@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_54",
            "tgt_ix": "317-ARR_v2_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_55",
            "tgt_ix": "317-ARR_v2_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_55",
            "tgt_ix": "317-ARR_v2_55@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_55",
            "tgt_ix": "317-ARR_v2_55@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_56",
            "tgt_ix": "317-ARR_v2_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_57",
            "tgt_ix": "317-ARR_v2_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_57",
            "tgt_ix": "317-ARR_v2_57@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_57",
            "tgt_ix": "317-ARR_v2_57@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_58",
            "tgt_ix": "317-ARR_v2_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_58",
            "tgt_ix": "317-ARR_v2_58@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_59",
            "tgt_ix": "317-ARR_v2_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_60",
            "tgt_ix": "317-ARR_v2_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_61",
            "tgt_ix": "317-ARR_v2_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_61",
            "tgt_ix": "317-ARR_v2_61@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_62",
            "tgt_ix": "317-ARR_v2_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_62",
            "tgt_ix": "317-ARR_v2_62@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_62",
            "tgt_ix": "317-ARR_v2_62@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_62",
            "tgt_ix": "317-ARR_v2_62@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_62",
            "tgt_ix": "317-ARR_v2_62@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_62",
            "tgt_ix": "317-ARR_v2_62@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_62",
            "tgt_ix": "317-ARR_v2_62@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_62",
            "tgt_ix": "317-ARR_v2_62@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_62",
            "tgt_ix": "317-ARR_v2_62@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_62",
            "tgt_ix": "317-ARR_v2_62@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_62",
            "tgt_ix": "317-ARR_v2_62@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_62",
            "tgt_ix": "317-ARR_v2_62@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_62",
            "tgt_ix": "317-ARR_v2_62@12",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_62",
            "tgt_ix": "317-ARR_v2_62@13",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_63",
            "tgt_ix": "317-ARR_v2_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_63",
            "tgt_ix": "317-ARR_v2_63@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_64",
            "tgt_ix": "317-ARR_v2_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_65",
            "tgt_ix": "317-ARR_v2_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_65",
            "tgt_ix": "317-ARR_v2_65@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_65",
            "tgt_ix": "317-ARR_v2_65@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_66",
            "tgt_ix": "317-ARR_v2_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_66",
            "tgt_ix": "317-ARR_v2_66@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_66",
            "tgt_ix": "317-ARR_v2_66@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_67",
            "tgt_ix": "317-ARR_v2_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_68",
            "tgt_ix": "317-ARR_v2_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_68",
            "tgt_ix": "317-ARR_v2_68@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_69",
            "tgt_ix": "317-ARR_v2_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_69",
            "tgt_ix": "317-ARR_v2_69@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_69",
            "tgt_ix": "317-ARR_v2_69@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_69",
            "tgt_ix": "317-ARR_v2_69@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_69",
            "tgt_ix": "317-ARR_v2_69@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_69",
            "tgt_ix": "317-ARR_v2_69@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_70",
            "tgt_ix": "317-ARR_v2_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_70",
            "tgt_ix": "317-ARR_v2_70@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_70",
            "tgt_ix": "317-ARR_v2_70@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_70",
            "tgt_ix": "317-ARR_v2_70@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_70",
            "tgt_ix": "317-ARR_v2_70@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_70",
            "tgt_ix": "317-ARR_v2_70@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_70",
            "tgt_ix": "317-ARR_v2_70@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_70",
            "tgt_ix": "317-ARR_v2_70@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_71",
            "tgt_ix": "317-ARR_v2_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_71",
            "tgt_ix": "317-ARR_v2_71@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_71",
            "tgt_ix": "317-ARR_v2_71@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_71",
            "tgt_ix": "317-ARR_v2_71@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_71",
            "tgt_ix": "317-ARR_v2_71@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_72",
            "tgt_ix": "317-ARR_v2_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_73",
            "tgt_ix": "317-ARR_v2_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_73",
            "tgt_ix": "317-ARR_v2_73@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_73",
            "tgt_ix": "317-ARR_v2_73@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_73",
            "tgt_ix": "317-ARR_v2_73@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_73",
            "tgt_ix": "317-ARR_v2_73@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_74",
            "tgt_ix": "317-ARR_v2_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_74",
            "tgt_ix": "317-ARR_v2_74@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_74",
            "tgt_ix": "317-ARR_v2_74@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_75",
            "tgt_ix": "317-ARR_v2_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_75",
            "tgt_ix": "317-ARR_v2_75@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_75",
            "tgt_ix": "317-ARR_v2_75@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_75",
            "tgt_ix": "317-ARR_v2_75@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_75",
            "tgt_ix": "317-ARR_v2_75@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_76",
            "tgt_ix": "317-ARR_v2_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_77",
            "tgt_ix": "317-ARR_v2_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_78",
            "tgt_ix": "317-ARR_v2_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_79",
            "tgt_ix": "317-ARR_v2_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_80",
            "tgt_ix": "317-ARR_v2_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_81",
            "tgt_ix": "317-ARR_v2_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_82",
            "tgt_ix": "317-ARR_v2_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_83",
            "tgt_ix": "317-ARR_v2_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_84",
            "tgt_ix": "317-ARR_v2_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_85",
            "tgt_ix": "317-ARR_v2_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_86",
            "tgt_ix": "317-ARR_v2_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_87",
            "tgt_ix": "317-ARR_v2_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_88",
            "tgt_ix": "317-ARR_v2_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_89",
            "tgt_ix": "317-ARR_v2_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_90",
            "tgt_ix": "317-ARR_v2_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_91",
            "tgt_ix": "317-ARR_v2_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_92",
            "tgt_ix": "317-ARR_v2_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_93",
            "tgt_ix": "317-ARR_v2_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_94",
            "tgt_ix": "317-ARR_v2_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_95",
            "tgt_ix": "317-ARR_v2_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_96",
            "tgt_ix": "317-ARR_v2_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_97",
            "tgt_ix": "317-ARR_v2_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_98",
            "tgt_ix": "317-ARR_v2_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_99",
            "tgt_ix": "317-ARR_v2_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_100",
            "tgt_ix": "317-ARR_v2_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_101",
            "tgt_ix": "317-ARR_v2_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_102",
            "tgt_ix": "317-ARR_v2_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_103",
            "tgt_ix": "317-ARR_v2_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_104",
            "tgt_ix": "317-ARR_v2_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_105",
            "tgt_ix": "317-ARR_v2_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_106",
            "tgt_ix": "317-ARR_v2_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_107",
            "tgt_ix": "317-ARR_v2_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_108",
            "tgt_ix": "317-ARR_v2_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_109",
            "tgt_ix": "317-ARR_v2_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_110",
            "tgt_ix": "317-ARR_v2_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_111",
            "tgt_ix": "317-ARR_v2_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_112",
            "tgt_ix": "317-ARR_v2_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_113",
            "tgt_ix": "317-ARR_v2_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_114",
            "tgt_ix": "317-ARR_v2_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_115",
            "tgt_ix": "317-ARR_v2_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_116",
            "tgt_ix": "317-ARR_v2_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_117",
            "tgt_ix": "317-ARR_v2_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_118",
            "tgt_ix": "317-ARR_v2_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_119",
            "tgt_ix": "317-ARR_v2_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_120",
            "tgt_ix": "317-ARR_v2_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_121",
            "tgt_ix": "317-ARR_v2_121@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_122",
            "tgt_ix": "317-ARR_v2_122@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_123",
            "tgt_ix": "317-ARR_v2_123@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_124",
            "tgt_ix": "317-ARR_v2_124@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_125",
            "tgt_ix": "317-ARR_v2_125@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_126",
            "tgt_ix": "317-ARR_v2_126@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_127",
            "tgt_ix": "317-ARR_v2_127@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_128",
            "tgt_ix": "317-ARR_v2_128@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_129",
            "tgt_ix": "317-ARR_v2_129@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_130",
            "tgt_ix": "317-ARR_v2_130@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_131",
            "tgt_ix": "317-ARR_v2_131@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_132",
            "tgt_ix": "317-ARR_v2_132@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_133",
            "tgt_ix": "317-ARR_v2_133@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_134",
            "tgt_ix": "317-ARR_v2_134@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_135",
            "tgt_ix": "317-ARR_v2_135@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "317-ARR_v2_136",
            "tgt_ix": "317-ARR_v2_136@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 930,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "doc_id": "317-ARR",
        "version": 2
    }
}