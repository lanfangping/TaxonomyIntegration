{
    "nodes": [
        {
            "ix": "177-ARR_v1_0",
            "content": "FairLex: A Multilingual Benchmark for Evaluating Fairness in Legal Text Processing",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_2",
            "content": "We present a benchmark suite of four datasets for evaluating the fairness of pre-trained legal language models and the techniques used to fine-tune them for downstream tasks. Our benchmarks cover four jurisdictions (European Council, USA, Swiss, and Chinese), five languages (English, German, French, Italian and Chinese) and fairness across five attributes (gender, age, nationality/region, language, and legal area). In our experiments, we evaluate pre-trained language models using several group-robust fine-tuning techniques and show that none of these combinations guarantee fairness, nor consistently mitigate group disparities. Furthermore, we analyze what causes performance differences across groups, and how group-robust fine-tuning techniques fail to mitigate group disparities under both representation inequality and temporal distribution swift.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "177-ARR_v1_4",
            "content": "The sector of law produces massive volumes of textual data (Katz et al., 2020), and as a result, legal research for settling personal injury claims, for example, can take several years, potentially discouraging clients. Legal systems around the world, e.g., in India, 1 Brazil, 2 or the US 3 , experience yearlong backlogs of pending cases. Natural Language Processing (NLP) for law (Chalkidis and Kampas, 2019;Aletras et al., 2019;Zhong et al., 2020) receives increasing attention. Assistive technologies can speed up legal research or discovery significantly assisting lawyers, judges and clerks. They can also help legal scholars to study case law (Katz, 2012), improve access of law to laypersons, help sociologists and research ethicists to expose biases in the justice system (Angwin et al., 2016;Dressel and Farid, 2018), and even scrutinize decision-making itself (Bell et al., 2021). In the context of law, non-discrimination (i.e. equality) is of paramount importance, e.g., EU nondiscrimination law (Council of European Union, 2000Union, , 2006 prohibits both direct and indirect discrimination. Discrimination occurs when one person is treated less favourably than others would be treated in comparable situations on grounds of sex, racial or ethnic origin, disability, sexual orientation, religion or belief and age. 4 Given the gravity that legal outcomes have for individuals, assistive technologies cannot be adopted to speed up legal research at the expense of fairness (Wachter et al., 2021), potentially also decreasing the trust in our legal systems (Barfield, 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_5",
            "content": "In recent years, the NLP and machine learning literature has introduced fairness objectives, typically derived from the Rawlsian notion of equal opportunities (Rawls, 1971), to evaluate the extent to which models discriminate across protected attributes. Some of these rely on notions of resource allocation, i.e., reflecting the idea that groups are treated fairly if they are equally represented in the training data used to induce our models, or if the same number of training iterations is performed per group. This is sometimes referred to as the resource allocation perspective on fairness (Lundgard, 2020). Contrary, there is also a capability-centered approach to fairness (Anderson, 1999;Robeyns, 2009), in which the goal is reserve enough resources per group to achieve similar performance levels, which is ultimately what is important for how individuals are treated in legal processes. We adopt a capability-centered approach to fairness and define fairness in terms of performance parity (Hashimoto et al., 2018) or equal risk (Donini et al., 2018). 5 Performance disparity (Hashimoto et al., 2018) refers to the phenomenon of high overall performance, but low performance on minority groups, as a result of minimizing risk across samples (not groups), Since some groups benefit more than others from models and technologies that exhibit performance disparity, this likely widens gaps between those groups. Performance disparity works against the ideal of fair and equal opportunities for all groups in our societies. We therefore define a fair classifier as one that has similar performance (equal risk) across all groups (Donini et al., 2018).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_6",
            "content": "In sum, we adopt the view that (approximate) equality under the law in a modern world requires that our NLP technologies exhibit (approximately) equal risk across sensitive attributes. For everyone to be treated equally under the law, regardless of race, gender, nationality, or other characteristics, NLP technologies need to be (approximately) insensitive to these attributes. In a supervised learning setting, models are trained on historical data that not always represent all groups in our societies equally. Moreover, historical legal data tends to reflect social biases in our societies and legal institutions. For example, criminal justice is already often strongly influenced by racial bias, with people of colour being more likely to be arrested and receive higher punishments than others, both in the US 6 and in the UK. 7 When models are deployed in production, they may reinforce these biases. We consider three types of attributes in this work:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_7",
            "content": "\u2022 Demographics: The first category includes demographic information of the involved parties, e.g., the gender, sexual orientation, nationality, age, or race of the plaintiff/defendant in a case. In this case, we aim to mitigate biases against specific groups, e.g., a model performs worse for female defendants or is biased against black defendants. \u2022 Regional: The second category includes regional information of the courts in charge of a case. In this case, we aim to mitigate disparity in-between different regions in a given jurisdiction, e.g., a model performs better in specific cases originated or ruled in courts of specific regions.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_8",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "177-ARR_v1_9",
            "content": "Fair machine learning The literature on inducing approximately fair models from biased data is rapidly growing. See Mehrabi et al. (2021) for a recent survey. We rely on this literature in how we define fairness, and for the algorithms that we compare in our experiments below. As already discussed, we adopt a capability-centered approach to fairness and define fairness in terms of performance parity (Hashimoto et al., 2018) or equal risk (Donini et al., 2018). The fairness-promoting learning algorithms we evaluate are discussed in detail in \u00a74. Some of these -Group Distributionally Robust Optimization (Sagawa et al., 2020) and Invariant Risk Minimization (Arjovsky et al., 2020) -have previously been evaluated for fairness in the context of hate speech (Koh et al., 2021). has a limited history. In a classic study, Angwin et al. (2016) analyzed the performance of the Correctional Offender Management Profiling for Alternative Sanctions (COMPAS) system, which was used for parole risk assessment (recidivism prediction) in the US. The system relied on 137 features from questionnaires and criminal records. Angwin et al. (2016) found that blacks were almost twice as likely as whites to be mislabeled as high risk (of re-offending), revealing a severe racial bias in the system. The system was later compared to crowdworkers in Dressel and Farid (2018).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_10",
            "content": "These studies relied on tabular data and did not involve text processing. More recently, Wang et al. (2021b) studied legal judgment consistency using a dataset of Chinese criminal cases. They evaluated the consistency of LSTM-based models across region and gender and reported severe fairness gaps across gender. They also found that the fairness gap was particular severe for more serious crimes.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_11",
            "content": "Previous work has focused on the analysis of specific cases, languages or algorithms, but Fair-Lex aims at easing the development and testing of bias-mitigation models or algorithms within the legal domain. FairLex allows researchers to explore fairness across four datasets covering four jurisdictions (Council of Europe, United States of America, Swiss Confederation and People's Republic of China), five languages (English, German, French, Italian and Chinese) and various sensitive attributes (gender, age, region, etc.). Furthermore, we provide competitive baselines including stateof-the-art transformer-based models, adapted to the examined datasets, and an in-dept examination of performance of four group robust algorithms described in detail in Section 4.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_12",
            "content": "Benchmark Datasets",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "177-ARR_v1_13",
            "content": "ECtHR The European Court of Human Rights (ECtHR) hears allegations that a state has breached human rights provisions of the European Convention of Human Rights (ECHR). We use the dataset of Chalkidis et al. (2021), which contains 11K cases from ECtHR's public database. Each case is mapped to articles of the ECHR that were violated (if any). This is a multi-label text classification task. Given the facts of a case, the goal is to predict the ECHR articles that were violated, if any, as decided (ruled) by the court. The cases are chronologically split into training (9k, 2001-16), development (1k, 2016-17), and test (1k, 2017-19) sets.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_14",
            "content": "To facilitate the study of fairness of text classifiers, we record for each case the following attributes: (a) The defendant states, which are the European states that allegedly violated the ECHR. The defendant states for each case is a subset of the 47 Member States of the Council of Europe; 8 To have statistical support, we group defendant states in two: Central-Eastern European states, on one hand, and all other states, as classified by the Eu-roVoc thesaurus. 9 (b) The applicant's age at the time of the decision. We extract the birth year of the applicant from the case facts, if possible, and classify its case in an age group (\u226435, \u226464, or older) ; and (c) the applicant's gender, extracted from the facts, if possible based on pronouns, classified in two categories (male, female).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_15",
            "content": "The US Supreme Court (SCOTUS) is the highest federal court in the United States of America and generally hears only the most controversial or otherwise complex cases which have not been sufficiently well solved by lower courts. We combine information from SCOTUS opinions with the Supreme Court DataBase (SCDB) 10 (Spaeth et al., 2020). SCDB provides metadata (e.g., date of publication, decisions, issues, decision directions and many more) for all cases. We consider the available 14 thematic issue areas (e.g, Criminal Procedure, Civil Rights, Economic Activity, etc.). This is a single-label multi-class document classification task. Given the court opinion, the goal is to predict the issue area whose focus is on the subject matter of the controversy (dispute). SCOTUS contains a total of 9,262 cases that we split chronologically into 80% for training (7.4k, 1946-1982), 10% for development (914,(1982)(1983)(1984)(1985)(1986)(1987)(1988)(1989)(1990)(1991) and 10% for testing (931,.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_16",
            "content": "From SCDB, we also use the following attributes to study fairness: (a) the type of respondent, which is a manual categorization of respondents (defendants) in five categories (person, public entity, organization, facility and other); and (c) the direction of the decision, i.e., whether the decision is liberal, or conservative, provided by SCDB.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_17",
            "content": "FSCS The Federal Supreme Court of Switzerland (FSCS) is the last level of appeal in Switzerland and similarly to SCOTUS, the court generally hears only the most controversial or otherwise complex cases which have not been sufficiently well solved by lower courts. The court often focus only on small parts of previous decision, where they discuss possible wrong reasoning by the lower court. The Swiss-Judgment-Predict dataset (Niklaus et al., 2021) contains more than 85K decisions from the FSCS written in one of three languages (50K German, 31K French, 4K Italian) from the years 2000 to 2020. The dataset provides labels for a simplified binary (approval, dismissal) classification task. Given the facts of the case, the goal is to predict if the plaintiff's request is valid or partially valid. The cases are also chronologically split into training (59.7k, 2000-2014), development (8.2k, 2015-2016), and test (17.4k, 2017-2020) sets.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_18",
            "content": "The dataset provides three additional attributes: (a) the language of the FSCS written decision, in either German, French, or Italian; (b) the legal area of the case (public, penal, social, civil, or insurance law) derived from the chambers where the decisions were heard; and (c) the region that denotes in which federal region was the case originated.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_19",
            "content": "SPC The Supreme People's Court of China (SPC) is the last level of appeal in China and considers cases that originated from the high people's courts concerning matters of national importance. The Chinese AI and Law challenge (CAIL) dataset (Xiao et al., 2018) is a Chinese legal NLP dataset for judgment prediction and contains more 1m criminal cases. The dataset provides labels for relevant article of criminal code prediction, charge (type of crime) prediction, imprisonment term (period) prediction, and monetary penalty prediction.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_20",
            "content": "Recently, Wang et al. (2021b) re-annotated a subset of approx. 100k cases with demographic attributes. Specifically the new dataset has been annotated with: (a) the applicant's gender, classified in two categories (male, female); and (b) the region of the court that denotes in which out of the 7 provincial-level administrative regions was the case judged. We re-split the dataset chronologically into training (80k, 2013-2017), development (12k, 2017-2018), and test (12k, 2018) sets. In our study, we examine a crime severity prediction task, a single-label multi-class classification task, where given the facts of a case, the goal is to predict how severe was the committed crime with respect to the imprisonment term. We approximate crime severity by the length of imprisonment term, split in 6 clusters (0, \u226412, \u226436, \u226460, \u2264120, >120 months).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_21",
            "content": "Fine-tuning Algorithms",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "177-ARR_v1_22",
            "content": "Across experiments, our main goal is to find a hypothesis for which the risk R(h) is minimal:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_23",
            "content": "h * = arg min h\u2208H R(h) (1) R(h) = E(L(h(x), y))(2)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_24",
            "content": "where y are the targets (ground truth) and h(x) = \u0177 is the system hypothesis (model's predictions).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_25",
            "content": "Similar to previous studies, R(h) is an expectation of the selected loss function (L). In this work, we study multi-label text classification (Section 3), thus we aim to minimize the binary cross-entropy loss across L classes:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_26",
            "content": "L = \u2212y log \u0177 \u2212 (1 \u2212 y) log(1 \u2212 \u0177) (3)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_27",
            "content": "ERM (Vapnik, 1992), which stands for Empirical Risk Minimization, is the most standard and widely used optimization technique to train neural methods. The loss is calculated as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_28",
            "content": "L ERM = N i=1 L i N (4",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_29",
            "content": ")",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_30",
            "content": "where N is the number of instances (training examples) in a batch, and L i is the loss per instance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_31",
            "content": "Besides ERM, we also consider a representative selection of group-robust fine-tuning algorithms which aims at mitigating performance disparities with respect to a given attribute (A), e.g., the gender of the applicant or the region of the court. Each attribute is split into G groups, i.e., male/female for gender. All algorithms rely on a balanced group sampler, i.e., an equal number of instances (samples) per group (N G ) are included in each batch. Most of the algorithms are built upon group-wise losses (L g ), computed as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_32",
            "content": "L(g i ) = 1 N g i N g i j=1 L(x j ) (5)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_33",
            "content": "Group DRO (Sagawa et al., 2020), stands for Group Distributionally Robust Optimization (DRO). Group DRO is an extension of the Group Uniform algorithm, where the group-wise losses are weighted inversely proportional to the group training performance. The total loss is:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_34",
            "content": "L DRO = G i=1 w g i * L(g i ), where(6)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_35",
            "content": "w g i = 1 W ( \u0175g i * e L(g i ) ) and W = G i=1 w g i (7)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_36",
            "content": "where G is the number of groups (labels), L g are the averaged group-wise (label-wise) losses, w g are the group (label) weights, \u0175g are the group (label) weights as computed in the previous update step. Initially the weight mass in equally distributed across groups.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_37",
            "content": "REx (Krueger et al., 2020), which stands for Risk Extrapolation, is yet another proposed group-robust optimization algorithm. Krueger et al. (2020) hypothesize that variation across training groups is representative of the variation later encountered at test time, so they also consider the variance across the group-wise losses. In V-REx the total loss is calculated as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_38",
            "content": "L REX = L ERM + \u03bb * Var([L g 1 , . . . , L g G ]) (8)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_39",
            "content": "where Var is the variance among the group-wise losses and \u03bb, a weighting hyper-parameter scalar.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_40",
            "content": "IRM (Arjovsky et al., 2020), which stands for Invariant Risk Minimization, mainly aims to penalize variance across multiple training dummy estimators across groups, i.e., performance cannot vary in samples that correspond to the same group. The total loss is computed as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_41",
            "content": "L IRM = 1 G \uf8eb \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ed G i=1 L(g i ) + \u03bb * P(g i ) \uf8f6 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f8(9)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_42",
            "content": "Please refer to Arjovsky et al. (2020) for the definition of the group penalty terms (P g ).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_43",
            "content": "Adversarial Removal (Elazar and Goldberg, 2018) algorithm mitigates group disparities by means of an additional adversarial classifier (Goodfellow et al., 2014). The adversarial classifier share the encoder with the main network and is trained to predict the protected attribute (A) of an instance. The total loss factors in the adversarial one, thus penalizing the model when it is able to discriminate groups. Formally, the total loss is calculated as:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_44",
            "content": "L AR = L ERM \u2212 \u03bb * L ADV (10",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_45",
            "content": ")",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_46",
            "content": "L ADV = L(\u011d i , g i ) (11",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_47",
            "content": ")",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_48",
            "content": "where \u011di is the adversarial classifier's prediction for the examined attribute A (in which group (g i ) of A, does the example belong to) given the input (x).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_49",
            "content": "Experimental SetUp",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "177-ARR_v1_50",
            "content": "Models Since we are interested in classifying long documents (up to 6000 tokens per document, see Figure 2 in Appendix C.1), we developed a hierarchical BERT-based model similar to that of Chalkidis et al. (2021), so as to avoid using only the first 512 tokens of a text. Our hierarchical model, first, encodes the text through a pre-trained Transformer-based architecture, thus representing each paragraph independently with the [CLS] token. Then, the paragraph representations are fed into a two-layers transformer encoder with the exact same specifications of the first one (e.g., hidden units, number of attention heads), so as to contextualize them, i.e., it makes paragraphs representations aware of the surrounding paragraphs. Finally, the model max-pools the context-aware paragraph representations computing the document-level representation and feed it to a classification layer.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_51",
            "content": "For the purpose of this work, we release four domain-specific BERT models with continued pretraining on the corpora of the examined datasets (ECtHR, SCOTUS, FSCS, SPC). 11 We train minisized BERT models with 6 Transformer blocks, 384 hidden units, and 12 attention heads. We warmstart all models from the public MiniLMv2 models checkpoints (Wang et al., 2021a) Table 2: Test results for all examined group-robust algorithms per dataset attribute. We report the average performance across groups (mF1), the group disparity among groups (GD), and the worst-group performance (mF1 W ). \u2191 denotes that higher scores are better, while \u2193 denotes that lower scores are better.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_52",
            "content": "\u2191 mF1 \u2193 GD \u2191 mF1 W \u2191 mF1 \u2193 GD \u2191 mF1 W \u2191 mF1 \u2193 GD \u2191 mF1 W \u2191 mF1 \u2193 GD \u2191 mF1 W \u2191 mF1 \u2193 GD \u2191 mF1 W Bag-of-",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_53",
            "content": "\u2191 mF1 \u2193 GD \u2191 mF1 W \u2191 mF1 \u2193 GD \u2191 mF1 W \u2191 mF1 \u2193 GD \u2191 mF1 W \u2191 mF1 \u2193 GD \u2191 mF1 W \u2191 mF1 \u2193 GD \u2191 mF1 W Bag-of-",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_54",
            "content": "version of RoBERTa (Liu et al., 2019) for the English datasets (ECtHR, SCOTUS) and the one distilled from XLM-R (Conneau et al., 2020) for the rest (trilingual FSCS, and Chinese SPC). Given the limited size of these models, we can effectively use up to 4096 tokens in ECtHR and SCOTUS and up to 2048 tokens in FSCS and SPC for up to 16 samples per batch in a 24gb nvidia gpu card. 12 For completeness, we also consider linear Bagof Words (BoW) classifiers using TF-IDF scores of the most frequent n-grams (where n = 1, 2, 3) in the training corpus of each dataset.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_55",
            "content": "We release a unified version of the benchmark on Hugging Face Datasets (Lhoest et al., 2021). 13 In our experiments, we use and extend the WILDs (Koh et al., 2021) library. For reproducibility and further exploration with new group-robust methods, we release our code on Github. 12 Evaluation Details Across experiments we compute the macro-F1 score per group (mF1 i ), excluding the group of unidentified instances, if any. 14 We report macro-F1 to avoid bias toward majority classes because of class imbalance and skewed label distributions across train, development, and test 12 This is particularly important for group-robust algorithms that consider group-wise losses.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_56",
            "content": "13 Both links will be revealed upon acceptance. 14 The group of unidentified instances includes the instances, where the value of the examined attribute is unidentifiable (unknown). See details in Appendix C.2. subsets. We report the average macro-F1 across groups (mF1) and the group disparity (GD) among groups measured as the group-wise std dev.:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_57",
            "content": "GD = 1 G G i=1 (mF1 i \u2212 mF1) 2 (12)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_58",
            "content": "We also report the worst-group performance (mF1 W = min([mF1 1 , mF1 2 , . . . mF1 G )).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_59",
            "content": "Baseline Results",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "177-ARR_v1_60",
            "content": "In Table 2, we report the results of all our baselines on the four datasets introduced in this paper. We first observe that the results of linear classifiers trained with the ERM algorithm (top row per dataset) are consistently worse (lower average and worst-case performance, higher group disparity) compared to transformed-based models in the same setting. In other words linear classifier have lower overall performance, while being less fair with respect to the applied definition of fairness (i.e. equal performance across groups).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_61",
            "content": "As one can see, transformer-based models trained with the ERM algorithm, i.e., without taking into account information about groups and their distribution, perform either better on in the same ballpark than models trained with methods specialized to mitigate biases (Section 4), with an average loss of 0.17 only in terms of mF1 and of 0.78 in terms of mF1 W . While, these algorithms improve worst case performance in the literature, when applied in a controlled experimental environment, they fail in a real-world setting, where both groups across attributes and labels are imbalanced, while also both group and label distribution change over time. Furthermore, we cannot identify one algorithm that performs better across datasets and group with respect to the others, indeed results are quite mixed without any recognizable pattern.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_62",
            "content": "Group Disparity Analysis We identify three general (attribute agnostic) factors that could potentially lead to performance disparity across groups:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_63",
            "content": "\u2022 Representation Inequality: Not all groups are equally represented in the training set. To examine this aspect, we report the number of training cases per group. \u2022 Temporal Concept Drift: The label distribution for a given group changes over time, i.e., inbetween training and test subsets. To examine this aspect, we report per group, the KL divergence in-between the training and test label distribution. \u2022 Worst Class Influence: The performance is not equal across labels (classes), which may disproportionally affect the macro-averaged performance across groups. To examine this aspect, we report the Worst Class Influence (WCI) score per group, which is computed as follows:",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_64",
            "content": "WCI(i) = #test-cases (worst-class) #test-cases(13)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_65",
            "content": "In Table 3, we present the results across all attributes. We observe that only in 4 out of 10 cases (attributes), the less represented groups are those with the worst performance compared to the rest. It is generally not the case that high KL divergence (drift) correlates with low performance. In other words, group disparities does not seem to be driven by temporal concept drift. Finally, the influence of the worst class is relatively uniform across groups in most cases, but in the cases where groups differ in this regard, worst class influence correlates with error in 2 out of 3 cases. 15 In ECtHR, considering performance across defendant state, we see that all the three factors correlate internally, i.e., the worst performing group is 15 For ECtHR performance across defendant states and SCO-TUS across directions, but not for ECtHR performance across applicant age. Table 3: Statistics for the three general (attribute agnostic) cross-examined factors (representation inequality, temporal concept drift, and worst-class influence), as introduced in Section 6. We highlight the worst and best performing group per attribute. In boldface, we highlight the best (less harmful) value per factor across groups. Performance (mF1) reported for ERM.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_66",
            "content": "less represented, has higher temporal drift and has more cases in the worst performing class. This is not the case considering performance across other attributes. It is also not the case for SCOTUS. In FSCS, considering the attributes of language and region, representation inequality seems to be an important factor that leads to group disparity. This is not the case for legal area, where the best represented group is the worst performing group. In other words, there are other reasons that lead to performance disparity in this case; for example, inconsistencies in rules and gathering of evidence in criminal cases potentially affects the predictability of rulings (Macula, 2019). In sum, we do not see any of these factors fully explain the performance disparities across groups.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_67",
            "content": "We have evaluated fairness across attributes that are not necessarily independent of each other. We therefore evaluate the extent to which performance disparities along different attributes correlate, i.e., how attributes interact, and whether performance differences for attribute A 1 can potentially explain performance differences for another attribute A 2 . We examine this for the two attributes with the highest group disparity: the defendant state in ECtHR, and the legal area in FSCS. For the bins induced by these two attributes (A 1 ), we compute mF1 scores across other attributes (A 2 ). In ECtHR, approx. 83% and 81% of male and women applicants are involved in cases against E.C. European states (best-performing group). Similarly, in case of age groups, we observe that ratio of cases against E.C. European states is: 87% and 86% for \u226465 and \u226435, the best-and worst-performing groups respectively.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_68",
            "content": "In FSCS, the ratio of cases relevant to penal law is: approx. 29%, and 41% written in written in French (best-performing group) and Italian (worstperforming group). Similarly, approx. 27% originated in E. Switzerland (best-performing group) and 42% in Federation (worst performing group) are relevant to penal law. In both attributes, there is a 15% increase of cases relevant to penal law for the worst performing groups. In other words, the group disparity in one attribute A2 (language, region) could be also explained by the influence of another attribute A1 (legal area).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_69",
            "content": "In Table 4, we report the performance in the aforementioned cross-attribute (A1, A2) pairings. cross-examination in ECtHR, we observe that group disparities in attribute A2 (Table 3) are consistent across groups of the plausible influencer (i.e. attribute A1). Hence, cross-attribute influence does not explain the observed group disparities.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_70",
            "content": "We believe that such an in-depth analysis of the results is fundamental to understand the influence of different factors in the outcomes. This analysis wouldn't be possible, if we had \"counterfeited\" an ideal scenario, where all groups and labels where equally represented. While a controlled experimental environment is frequently used to examine specific factors, it could hide, or partially alleviate such phenomena, hence producing misleading results on fairness of the examined models.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_71",
            "content": "Conclusions",
            "ntype": "title",
            "meta": {
                "section": "7"
            }
        },
        {
            "ix": "177-ARR_v1_72",
            "content": "We introduced FairLex, a multi-lingual benchmark for the development and testing of bias-mitigation models or algorithms within the legal domain, based on four datasets covering four jurisdictions, five languages and various sensitive attributes. Furthermore, we provided competitive baselines including state-of-the-art transformer-based models adapted to the examined datasets, and an in-dept examination of performance of four group robust algorithms (Adversarial Removal, IRM, Group DRO, and REx). While, these algorithms improve worst case performance in the literature, when applied in a controlled experimental environment, they fail in a real-world setting, where both groups across attributes, and labels are imbalanced, while also both group and label distributions change over time. Furthermore, we cannot identify a single algorithm that performs better across datasets and groups compared to the rest.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_73",
            "content": "The legal notion of discrimination has a different scope and semantics in comparison to the notions of fairness and bias used in the context of machine learning (Gerards and Xenedis, 2020), where the aim usually is to achieve equal odds, e.g. that a court shall rule the same decision for both men and woman based on similar facts, or to have 50/50 favourable decisions for both man and woman, but equal opportunities (Rawls, 1971).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_74",
            "content": "In particular, EU non-discrimination law (Council of European Union, 2000Union, , 2006 prohibits both direct and indirect discrimination. Direct discrimination occurs when one person is treated \"less favourably than another is, has been or would be treated in a comparable situation\" on grounds of sex, racial or ethnic origin, disability, sexual orientation, religion or belief and age in the context of a protected sector (e.g. the workplace and provision of goods and services) (Wachter et al., 2021). Prohibiting direct discrimination allows to provide people with equal access to opportunities (i.e. formal equality). This however does not suffice, nor guarantee to create equality of opportunity (i.e. substantive equality), which can instead be achieved only by accounting for protected attributes and for social and historical realities and by taking positive measures to level the playing field (Fredman, 2016). The notion of indirect discrimination is grounded on achieving substantive equality in practice. Indirect discrimination refers to situations in which an apparently neutral provision, criterion or practice would put persons with a protected characteristic at disadvantage in comparison to other persons, unless 'that provision, criterion or practice is \"justified by a legitimate aim and the means of achieving that aim are appropriate and necessary\".",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_75",
            "content": "Nevertheless, the current EU non-discrimination law framework suffers from limitations, both as regards its personal (i.e. it only protects six characteristics) and material scope (i.e. the prohibition on discrimination is limited only to certain fields) (Gerards and Xenedis, 2020). These limitations pose problems in connection to algorithmic discrimination. For example, as algorithmic bias often creates seemingly neutral distinctions which however often correlate to a protected group (i.e. proxy discrimination), the limited list of protected grounds renders difficult to tackle the effects of algorithmic bias through the concept of direct discrimination (Prince and Schwarcz, 2019). Indirect discrimination can help address those cases. but its application in this context poses several challenges.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_76",
            "content": "In April 2021 the European Commission presented a proposal for a Regulation laying down harmonized rules on artificial intelligence (AI Act / AIA) (Council of European Union, 2021). The proposal aims at avoiding \"significant risks to the health and safety or fundamental rights of persons\" and would, once adopted, complement the currently applicable legal framework for tackling algorithmic discrimination, thereby overcoming some of its existing limitations. The envisaged implementation of the proposed AI Act highlights the importance that the legislator poses in preventing and mitigating discrimination and biases arising from the development and use of AI systems in several areas of application, including in the legal sector (Schwemer et al., 2021). AI systems used for the administration of justice and democratic processes are proposed to be deemed high-risk in order \"to address the risks of potential biases, errors, and opacity\" (recital 40 AIA). The consequence is that such systems would be subject to a variety of design and development requirements, e.g. related to the training, validation and testing data sets which would have to be examined inter alia in relation to possible biases (art. 10(2) lit. f AIA) or related to human oversight of such AI system with a view to remain aware of automation bias (art. 14(4) lit. b AIA).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_77",
            "content": "The topic deserves great attention because AI systems learning from historical data pose the risk of transporting biases previously encumbered in the data in future decision-making, thereby exponentially increasing their effect. For example, criminal justice is already often strongly influenced by racial bias, with people of colour being more likely to be arrested and receive higher punishments than others, both in both in the USA 16 and in the UK. 17",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_78",
            "content": "We fine-tune all models using the AdamW (Loshchilov and Hutter, 2019) optimizer with a learning rate of 3e-5. We use a batch size of 16 and train models for up to 20 epochs using early stopping on validation performance. 18 Across datasets and attributes, we run five repetitions with different random seeds and report averaged scores.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_79",
            "content": "In Figure 2 we report the distribution of sequence (document) length across FairLex datasets (ECtHR, SCOTUS, FSCS). We observe that the documents are extremely long (3,000-6,000+ words) across datasets.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_80",
            "content": "In Tables 5 and 6 we report the group distribution per examined attribute under consideration. In some cases, the extraction of the specific attribute, e.g., gender or age in ECtHR, was not possible, i.e., the applied rules would no suffice, possibly because the information is intentionally missing. During training, the groups of unidentified samples is included, but we report test scores excluding those, i.e., mF1 and GD do not take into account the F1 of these groups.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_81",
            "content": "In Tables 7, 8, 9, and 10, we report the Jensen-Shannon divergences between train-test, train-dev and test-test distribution of labels separately for each protrected attribute values and for each dataset in our framework.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "177-ARR_v1_82",
            "content": "UNKNOWN, None, , 2019. Proceedings of the 1st Natural Legal Language Processing Workshop at NAACL 2019. Minneapolis, Minnesota, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "2019. Proceedings of the 1st Natural Legal Language Processing Workshop at NAACL 2019. Minneapolis, Minnesota",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_83",
            "content": "Elizabeth Anderson, What is the point of equality?, 1999, Ethics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Elizabeth Anderson"
                ],
                "title": "What is the point of equality?",
                "pub_date": "1999",
                "pub_title": "Ethics",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_84",
            "content": "UNKNOWN, None, 2016, Machine bias: There's software used across the country to predict future criminals. and it's biased against blacks, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": null,
                "title": null,
                "pub_date": "2016",
                "pub_title": "Machine bias: There's software used across the country to predict future criminals. and it's biased against blacks",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_85",
            "content": "UNKNOWN, None, 2020, Invariant Risk Minimization, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Invariant Risk Minimization",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_86",
            "content": "UNKNOWN, None, 2020, The Cambridge Handbook of the Law of Algorithms. Cambridge Law Handbooks, Cambridge University Press.",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "The Cambridge Handbook of the Law of Algorithms. Cambridge Law Handbooks",
                "pub": "Cambridge University Press"
            }
        },
        {
            "ix": "177-ARR_v1_87",
            "content": "Kristen Bell, Jenny Hong, Nick Mckeown, Catalin Voss, The Recon Approach: A New Direction for Machine Learning in Criminal Law, 2021, Berkeley Technology Law Journal, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "Kristen Bell",
                    "Jenny Hong",
                    "Nick Mckeown",
                    "Catalin Voss"
                ],
                "title": "The Recon Approach: A New Direction for Machine Learning in Criminal Law",
                "pub_date": "2021",
                "pub_title": "Berkeley Technology Law Journal",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_88",
            "content": ", Paragraph-level rationale extraction through regularization: A case study on European court of human rights cases, , Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [],
                "title": "Paragraph-level rationale extraction through regularization: A case study on European court of human rights cases",
                "pub_date": null,
                "pub_title": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_89",
            "content": "UNKNOWN, None, 2019, Deep learning in law: Early adaptation and legal word embeddings trained on large corpora. Artificial Intelligence and Law, .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Deep learning in law: Early adaptation and legal word embeddings trained on large corpora. Artificial Intelligence and Law",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_90",
            "content": "Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettlemoyer, Veselin Stoyanov, Unsupervised cross-lingual representation learning at scale, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Alexis Conneau",
                    "Kartikay Khandelwal",
                    "Naman Goyal",
                    "Vishrav Chaudhary",
                    "Guillaume Wenzek",
                    "Francisco Guzm\u00e1n",
                    "Edouard Grave",
                    "Myle Ott",
                    "Luke Zettlemoyer",
                    "Veselin Stoyanov"
                ],
                "title": "Unsupervised cross-lingual representation learning at scale",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_91",
            "content": "UNKNOWN, None, 2000-06, implementing the principle of equal treatment between persons irrespective of racial or ethnic origin, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": null,
                "title": null,
                "pub_date": "2000-06",
                "pub_title": "implementing the principle of equal treatment between persons irrespective of racial or ethnic origin",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_92",
            "content": "UNKNOWN, None, 2006-07, on the implementation of the principle of equal opportunities and equal treatment of men and women in matters of employment and occupation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": null,
                "title": null,
                "pub_date": "2006-07",
                "pub_title": "on the implementation of the principle of equal opportunities and equal treatment of men and women in matters of employment and occupation",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_93",
            "content": "UNKNOWN, None, 2021, Proposal for a Regulation laying down harmonised rules on Artificial Intelligence (Artificial Intelligence Act) and amending certain Union legislative acts, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Proposal for a Regulation laying down harmonised rules on Artificial Intelligence (Artificial Intelligence Act) and amending certain Union legislative acts",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_94",
            "content": "Michele Donini, Luca Oneto, Shai Ben-David, John Shawe-Taylor, Massimiliano Pontil, Empirical risk minimization under fairness constraints, 2018, Advances in Neural Information Processing Systems, Curran Associates, Inc.",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Michele Donini",
                    "Luca Oneto",
                    "Shai Ben-David",
                    "John Shawe-Taylor",
                    "Massimiliano Pontil"
                ],
                "title": "Empirical risk minimization under fairness constraints",
                "pub_date": "2018",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": "Curran Associates, Inc"
            }
        },
        {
            "ix": "177-ARR_v1_95",
            "content": "Julia Dressel, Hany Farid, The accuracy, fairness, and limits of predicting recidivism, 2018, Science Advances, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    "Julia Dressel",
                    "Hany Farid"
                ],
                "title": "The accuracy, fairness, and limits of predicting recidivism",
                "pub_date": "2018",
                "pub_title": "Science Advances",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_96",
            "content": "Yanai Elazar, Yoav Goldberg, Adversarial removal of demographic attributes from text data, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Yanai Elazar",
                    "Yoav Goldberg"
                ],
                "title": "Adversarial removal of demographic attributes from text data",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_97",
            "content": "UNKNOWN, None, 2016, Substantive equality revisited. I-CON Oxford Legal Studies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": null,
                "title": null,
                "pub_date": "2016",
                "pub_title": "Substantive equality revisited. I-CON Oxford Legal Studies",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_98",
            "content": "UNKNOWN, None, 2020, Algorithmic discrimination in europe: challenges and opportunities for gender equality and nondiscrimination law, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Algorithmic discrimination in europe: challenges and opportunities for gender equality and nondiscrimination law",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_99",
            "content": "Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio, Generative adversarial networks, 2014, Advances in Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Ian Goodfellow",
                    "Jean Pouget-Abadie",
                    "Mehdi Mirza",
                    "Bing Xu",
                    "David Warde-Farley",
                    "Sherjil Ozair",
                    "Aaron Courville",
                    "Yoshua Bengio"
                ],
                "title": "Generative adversarial networks",
                "pub_date": "2014",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_100",
            "content": "Tatsunori Hashimoto, Megha Srivastava, Hongseok Namkoong, Percy Liang, Fairness without demographics in repeated loss minimization, 2018, Proceedings of the 35th International Conference on Machine Learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Tatsunori Hashimoto",
                    "Megha Srivastava",
                    "Hongseok Namkoong",
                    "Percy Liang"
                ],
                "title": "Fairness without demographics in repeated loss minimization",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 35th International Conference on Machine Learning",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_101",
            "content": "Daniel Martin Katz, Quantitative legal prediction-or-how I learned to stop worrying and start preparing for the data-driven future of the legal services industry, 2012, Emory Law Journal, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    " Daniel Martin Katz"
                ],
                "title": "Quantitative legal prediction-or-how I learned to stop worrying and start preparing for the data-driven future of the legal services industry",
                "pub_date": "2012",
                "pub_title": "Emory Law Journal",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_102",
            "content": "Corinna Daniel Martin Katz,  Coupette, Janis Beckedorf, and Dirk Hartung. 2020. Complex societies and the growth of the law, , Scientific Reports, .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Corinna Daniel Martin Katz",
                    " Coupette"
                ],
                "title": "Janis Beckedorf, and Dirk Hartung. 2020. Complex societies and the growth of the law",
                "pub_date": null,
                "pub_title": "Scientific Reports",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_103",
            "content": "Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Xie, Marvin Zhang, Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard Phillips, Irena Gao, Tony Lee, Etienne David, Ian Stavness, Wei Guo, A Berton, Imran Earnshaw, Sara Haque, Jure Beery, Anshul Leskovec, Emma Kundaje, Sergey Pierson, Chelsea Levine, Percy Finn,  Liang, WILDS: A benchmark of in-the-wild distribution shifts, 2021, International Conference on Machine Learning (ICML), .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "Pang Wei Koh",
                    "Shiori Sagawa",
                    "Henrik Marklund",
                    "Sang Xie",
                    "Marvin Zhang",
                    "Akshay Balsubramani",
                    "Weihua Hu",
                    "Michihiro Yasunaga",
                    "Richard Phillips",
                    "Irena Gao",
                    "Tony Lee",
                    "Etienne David",
                    "Ian Stavness",
                    "Wei Guo",
                    "A Berton",
                    "Imran Earnshaw",
                    "Sara Haque",
                    "Jure Beery",
                    "Anshul Leskovec",
                    "Emma Kundaje",
                    "Sergey Pierson",
                    "Chelsea Levine",
                    "Percy Finn",
                    " Liang"
                ],
                "title": "WILDS: A benchmark of in-the-wild distribution shifts",
                "pub_date": "2021",
                "pub_title": "International Conference on Machine Learning (ICML)",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_104",
            "content": "UNKNOWN, None, , Out-of-Distribution Generalization via Risk Extrapolation (REx), CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Out-of-Distribution Generalization via Risk Extrapolation (REx)",
                "pub": "CoRR"
            }
        },
        {
            "ix": "177-ARR_v1_105",
            "content": "UNKNOWN, None, , Lysandre Debut, Stas Bekman, Pierric Cistac, Thibault Goehringer, Victor Mustar, Fran\u00e7ois Lagunas, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Lysandre Debut, Stas Bekman, Pierric Cistac, Thibault Goehringer, Victor Mustar, Fran\u00e7ois Lagunas",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_106",
            "content": "UNKNOWN, None, 1907, Roberta: A robustly optimized BERT pretraining approach, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": null,
                "title": null,
                "pub_date": "1907",
                "pub_title": "Roberta: A robustly optimized BERT pretraining approach",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_107",
            "content": "Ilya Loshchilov, Frank Hutter, Decoupled weight decay regularization, 2019, International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Ilya Loshchilov",
                    "Frank Hutter"
                ],
                "title": "Decoupled weight decay regularization",
                "pub_date": "2019",
                "pub_title": "International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_108",
            "content": "Alan Lundgard, Measuring justice in machine learning, 2020, Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, FAT* '20, Association for Computing Machinery.",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": [
                    "Alan Lundgard"
                ],
                "title": "Measuring justice in machine learning",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, FAT* '20",
                "pub": "Association for Computing Machinery"
            }
        },
        {
            "ix": "177-ARR_v1_109",
            "content": "UNKNOWN, None, 2019, The Potential to Secure a Fair Trial Through Evidence Exclusion: A Swiss Perspective, Springer International Publishing.",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "The Potential to Secure a Fair Trial Through Evidence Exclusion: A Swiss Perspective",
                "pub": "Springer International Publishing"
            }
        },
        {
            "ix": "177-ARR_v1_110",
            "content": "Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, Aram Galstyan, A survey on bias and fairness in machine learning, 2021, ACM Comput. Surv, .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Ninareh Mehrabi",
                    "Fred Morstatter",
                    "Nripsuta Saxena",
                    "Kristina Lerman",
                    "Aram Galstyan"
                ],
                "title": "A survey on bias and fairness in machine learning",
                "pub_date": "2021",
                "pub_title": "ACM Comput. Surv",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_111",
            "content": "Joel Niklaus, Ilias Chalkidis, Matthias St\u00fcrmer, Swiss-Court-Predict: A Multilingual Legal Judgment Prediction Benchmark, 2021, Proceedings of the 2022 NLLP Workshop, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "Joel Niklaus",
                    "Ilias Chalkidis",
                    "Matthias St\u00fcrmer"
                ],
                "title": "Swiss-Court-Predict: A Multilingual Legal Judgment Prediction Benchmark",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2022 NLLP Workshop",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_112",
            "content": "Anya Prince, Daniel Schwarcz, Proxy discrimination in the age of artificial intelligence and big data, 2019, Iowa Law Review, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": [
                    "Anya Prince",
                    "Daniel Schwarcz"
                ],
                "title": "Proxy discrimination in the age of artificial intelligence and big data",
                "pub_date": "2019",
                "pub_title": "Iowa Law Review",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_113",
            "content": "UNKNOWN, None, 1971, Theory of Justice, Belknap Press of Harvard University Press.",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": null,
                "title": null,
                "pub_date": "1971",
                "pub_title": "Theory of Justice",
                "pub": "Belknap Press of Harvard University Press"
            }
        },
        {
            "ix": "177-ARR_v1_114",
            "content": "UNKNOWN, None, 2009, Justice as fairness and the capability approach. Arguments for a Better World. Essays for Amartya Sen's, .",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": null,
                "title": null,
                "pub_date": "2009",
                "pub_title": "Justice as fairness and the capability approach. Arguments for a Better World. Essays for Amartya Sen's",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_115",
            "content": "Shiori Sagawa, Pang Wei Koh, Tatsunori Hashimoto, Percy Liang, Distributionally Robust Neural Networks, 2020, International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": [
                    "Shiori Sagawa",
                    "Pang Wei Koh",
                    "Tatsunori Hashimoto",
                    "Percy Liang"
                ],
                "title": "Distributionally Robust Neural Networks",
                "pub_date": "2020",
                "pub_title": "International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_116",
            "content": "Letizia Sebastian Felix Schwemer, Tommaso Tomada,  Pasini, Legal ai systems in the eu's proposed artificial intelligence act, 2021, Joint Proceedings of the Workshops on Automated Semantic Analysis of Information in Legal Text (ASAIL 2021) and AI and Intelligent Assistance for Legal Professionals in the Digital, Workplace, .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": [
                    "Letizia Sebastian Felix Schwemer",
                    "Tommaso Tomada",
                    " Pasini"
                ],
                "title": "Legal ai systems in the eu's proposed artificial intelligence act",
                "pub_date": "2021",
                "pub_title": "Joint Proceedings of the Workshops on Automated Semantic Analysis of Information in Legal Text (ASAIL 2021) and AI and Intelligent Assistance for Legal Professionals in the Digital, Workplace",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_117",
            "content": "UNKNOWN, None, 2020, Supreme Court Database, Version 2020 Release 01, .",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Supreme Court Database, Version 2020 Release 01",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_118",
            "content": "Dimitrios Tsarapatsanis, Nikolaos Aletras, On the ethical limits of natural language processing on legal text, 2021, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "Dimitrios Tsarapatsanis",
                    "Nikolaos Aletras"
                ],
                "title": "On the ethical limits of natural language processing on legal text",
                "pub_date": "2021",
                "pub_title": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "177-ARR_v1_119",
            "content": "V Vapnik, Principles of risk minimization for learning theory, 1992, Advances in Neural Information Processing Systems, Morgan-Kaufmann.",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": [
                    "V Vapnik"
                ],
                "title": "Principles of risk minimization for learning theory",
                "pub_date": "1992",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": "Morgan-Kaufmann"
            }
        },
        {
            "ix": "177-ARR_v1_120",
            "content": "Sandra Wachter, Brent Mittelstadt, Chris Russell, Bias preservation in machine learning: The legality of fairness metrics under eu nondiscrimination law, 2021, West Virginia Law Review, .",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": [
                    "Sandra Wachter",
                    "Brent Mittelstadt",
                    "Chris Russell"
                ],
                "title": "Bias preservation in machine learning: The legality of fairness metrics under eu nondiscrimination law",
                "pub_date": "2021",
                "pub_title": "West Virginia Law Review",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_121",
            "content": "Wenhui Wang, Hangbo Bao, Shaohan Huang, Li Dong, Furu Wei, MiniLMv2: Multi-head selfattention relation distillation for compressing pretrained transformers, 2021, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, .",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": [
                    "Wenhui Wang",
                    "Hangbo Bao",
                    "Shaohan Huang",
                    "Li Dong",
                    "Furu Wei"
                ],
                "title": "MiniLMv2: Multi-head selfattention relation distillation for compressing pretrained transformers",
                "pub_date": "2021",
                "pub_title": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_122",
            "content": "Yuzhong Wang, Chaojun Xiao, Shirong Ma, Haoxi Zhong, Cunchao Tu, Tianyang Zhang, Zhiyuan Liu, Maosong Sun, Equality before the law: Legal judgment consistency analysis for fairness, 2021, Science China -Information Sciences, .",
            "ntype": "ref",
            "meta": {
                "xid": "b40",
                "authors": [
                    "Yuzhong Wang",
                    "Chaojun Xiao",
                    "Shirong Ma",
                    "Haoxi Zhong",
                    "Cunchao Tu",
                    "Tianyang Zhang",
                    "Zhiyuan Liu",
                    "Maosong Sun"
                ],
                "title": "Equality before the law: Legal judgment consistency analysis for fairness",
                "pub_date": "2021",
                "pub_title": "Science China -Information Sciences",
                "pub": null
            }
        },
        {
            "ix": "177-ARR_v1_123",
            "content": "UNKNOWN, None, 2018, CAIL2018: A large-scale legal dataset for judgment prediction, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b41",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "CAIL2018: A large-scale legal dataset for judgment prediction",
                "pub": "CoRR"
            }
        },
        {
            "ix": "177-ARR_v1_124",
            "content": "Haoxi Zhong, Chaojun Xiao, Cunchao Tu, Tianyang Zhang, Zhiyuan Liu, Maosong Sun, How does NLP benefit legal system: A summary of legal artificial intelligence, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b42",
                "authors": [
                    "Haoxi Zhong",
                    "Chaojun Xiao",
                    "Cunchao Tu",
                    "Tianyang Zhang",
                    "Zhiyuan Liu",
                    "Maosong Sun"
                ],
                "title": "How does NLP benefit legal system: A summary of legal artificial intelligence",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Online. Association for Computational Linguistics"
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "177-ARR_v1_0@0",
            "content": "FairLex: A Multilingual Benchmark for Evaluating Fairness in Legal Text Processing",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_0",
            "start": 0,
            "end": 81,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_2@0",
            "content": "We present a benchmark suite of four datasets for evaluating the fairness of pre-trained legal language models and the techniques used to fine-tune them for downstream tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_2",
            "start": 0,
            "end": 173,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_2@1",
            "content": "Our benchmarks cover four jurisdictions (European Council, USA, Swiss, and Chinese), five languages (English, German, French, Italian and Chinese) and fairness across five attributes (gender, age, nationality/region, language, and legal area).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_2",
            "start": 175,
            "end": 417,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_2@2",
            "content": "In our experiments, we evaluate pre-trained language models using several group-robust fine-tuning techniques and show that none of these combinations guarantee fairness, nor consistently mitigate group disparities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_2",
            "start": 419,
            "end": 633,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_2@3",
            "content": "Furthermore, we analyze what causes performance differences across groups, and how group-robust fine-tuning techniques fail to mitigate group disparities under both representation inequality and temporal distribution swift.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_2",
            "start": 635,
            "end": 857,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_4@0",
            "content": "The sector of law produces massive volumes of textual data (Katz et al., 2020), and as a result, legal research for settling personal injury claims, for example, can take several years, potentially discouraging clients.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_4",
            "start": 0,
            "end": 218,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_4@1",
            "content": "Legal systems around the world, e.g., in India, 1 Brazil, 2 or the US 3 , experience yearlong backlogs of pending cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_4",
            "start": 220,
            "end": 339,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_4@2",
            "content": "Natural Language Processing (NLP) for law (Chalkidis and Kampas, 2019;Aletras et al., 2019;Zhong et al., 2020) receives increasing attention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_4",
            "start": 341,
            "end": 481,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_4@3",
            "content": "Assistive technologies can speed up legal research or discovery significantly assisting lawyers, judges and clerks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_4",
            "start": 483,
            "end": 597,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_4@4",
            "content": "They can also help legal scholars to study case law (Katz, 2012), improve access of law to laypersons, help sociologists and research ethicists to expose biases in the justice system (Angwin et al., 2016;Dressel and Farid, 2018), and even scrutinize decision-making itself (Bell et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_4",
            "start": 599,
            "end": 891,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_4@5",
            "content": "In the context of law, non-discrimination (i.e. equality) is of paramount importance, e.g., EU nondiscrimination law (Council of European Union, 2000Union, , 2006 prohibits both direct and indirect discrimination.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_4",
            "start": 893,
            "end": 1105,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_4@6",
            "content": "Discrimination occurs when one person is treated less favourably than others would be treated in comparable situations on grounds of sex, racial or ethnic origin, disability, sexual orientation, religion or belief and age.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_4",
            "start": 1107,
            "end": 1328,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_4@7",
            "content": "4 Given the gravity that legal outcomes have for individuals, assistive technologies cannot be adopted to speed up legal research at the expense of fairness (Wachter et al., 2021), potentially also decreasing the trust in our legal systems (Barfield, 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_4",
            "start": 1330,
            "end": 1586,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_5@0",
            "content": "In recent years, the NLP and machine learning literature has introduced fairness objectives, typically derived from the Rawlsian notion of equal opportunities (Rawls, 1971), to evaluate the extent to which models discriminate across protected attributes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_5",
            "start": 0,
            "end": 253,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_5@1",
            "content": "Some of these rely on notions of resource allocation, i.e., reflecting the idea that groups are treated fairly if they are equally represented in the training data used to induce our models, or if the same number of training iterations is performed per group.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_5",
            "start": 255,
            "end": 513,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_5@2",
            "content": "This is sometimes referred to as the resource allocation perspective on fairness (Lundgard, 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_5",
            "start": 515,
            "end": 612,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_5@3",
            "content": "Contrary, there is also a capability-centered approach to fairness (Anderson, 1999;Robeyns, 2009), in which the goal is reserve enough resources per group to achieve similar performance levels, which is ultimately what is important for how individuals are treated in legal processes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_5",
            "start": 614,
            "end": 896,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_5@4",
            "content": "We adopt a capability-centered approach to fairness and define fairness in terms of performance parity (Hashimoto et al., 2018) or equal risk (Donini et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_5",
            "start": 898,
            "end": 1061,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_5@5",
            "content": "5 Performance disparity (Hashimoto et al., 2018) refers to the phenomenon of high overall performance, but low performance on minority groups, as a result of minimizing risk across samples (not groups), Since some groups benefit more than others from models and technologies that exhibit performance disparity, this likely widens gaps between those groups.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_5",
            "start": 1063,
            "end": 1418,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_5@6",
            "content": "Performance disparity works against the ideal of fair and equal opportunities for all groups in our societies.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_5",
            "start": 1420,
            "end": 1529,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_5@7",
            "content": "We therefore define a fair classifier as one that has similar performance (equal risk) across all groups (Donini et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_5",
            "start": 1531,
            "end": 1657,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_6@0",
            "content": "In sum, we adopt the view that (approximate) equality under the law in a modern world requires that our NLP technologies exhibit (approximately) equal risk across sensitive attributes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_6",
            "start": 0,
            "end": 183,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_6@1",
            "content": "For everyone to be treated equally under the law, regardless of race, gender, nationality, or other characteristics, NLP technologies need to be (approximately) insensitive to these attributes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_6",
            "start": 185,
            "end": 377,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_6@2",
            "content": "In a supervised learning setting, models are trained on historical data that not always represent all groups in our societies equally.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_6",
            "start": 379,
            "end": 512,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_6@3",
            "content": "Moreover, historical legal data tends to reflect social biases in our societies and legal institutions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_6",
            "start": 514,
            "end": 616,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_6@4",
            "content": "For example, criminal justice is already often strongly influenced by racial bias, with people of colour being more likely to be arrested and receive higher punishments than others, both in the US 6 and in the UK.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_6",
            "start": 618,
            "end": 830,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_6@5",
            "content": "7 When models are deployed in production, they may reinforce these biases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_6",
            "start": 832,
            "end": 905,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_6@6",
            "content": "We consider three types of attributes in this work:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_6",
            "start": 907,
            "end": 957,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_7@0",
            "content": "\u2022 Demographics: The first category includes demographic information of the involved parties, e.g., the gender, sexual orientation, nationality, age, or race of the plaintiff/defendant in a case. In this case, we aim to mitigate biases against specific groups, e.g., a model performs worse for female defendants or is biased against black defendants. \u2022 Regional: The second category includes regional information of the courts in charge of a case. In this case, we aim to mitigate disparity in-between different regions in a given jurisdiction, e.g., a model performs better in specific cases originated or ruled in courts of specific regions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_7",
            "start": 0,
            "end": 641,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_8@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_8",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_9@0",
            "content": "Fair machine learning The literature on inducing approximately fair models from biased data is rapidly growing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_9",
            "start": 0,
            "end": 110,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_9@1",
            "content": "See Mehrabi et al. (2021) for a recent survey.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_9",
            "start": 112,
            "end": 157,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_9@2",
            "content": "We rely on this literature in how we define fairness, and for the algorithms that we compare in our experiments below.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_9",
            "start": 159,
            "end": 276,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_9@3",
            "content": "As already discussed, we adopt a capability-centered approach to fairness and define fairness in terms of performance parity (Hashimoto et al., 2018) or equal risk (Donini et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_9",
            "start": 278,
            "end": 463,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_9@4",
            "content": "The fairness-promoting learning algorithms we evaluate are discussed in detail in \u00a74.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_9",
            "start": 465,
            "end": 549,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_9@5",
            "content": "Some of these -Group Distributionally Robust Optimization (Sagawa et al., 2020) and Invariant Risk Minimization (Arjovsky et al., 2020) -have previously been evaluated for fairness in the context of hate speech (Koh et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_9",
            "start": 551,
            "end": 780,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_9@6",
            "content": "has a limited history.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_9",
            "start": 782,
            "end": 803,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_9@7",
            "content": "In a classic study, Angwin et al. (2016) analyzed the performance of the Correctional Offender Management Profiling for Alternative Sanctions (COMPAS) system, which was used for parole risk assessment (recidivism prediction) in the US.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_9",
            "start": 805,
            "end": 1039,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_9@8",
            "content": "The system relied on 137 features from questionnaires and criminal records.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_9",
            "start": 1041,
            "end": 1115,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_9@9",
            "content": "Angwin et al. (2016) found that blacks were almost twice as likely as whites to be mislabeled as high risk (of re-offending), revealing a severe racial bias in the system.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_9",
            "start": 1117,
            "end": 1287,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_9@10",
            "content": "The system was later compared to crowdworkers in Dressel and Farid (2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_9",
            "start": 1289,
            "end": 1362,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_10@0",
            "content": "These studies relied on tabular data and did not involve text processing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_10",
            "start": 0,
            "end": 72,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_10@1",
            "content": "More recently, Wang et al. (2021b) studied legal judgment consistency using a dataset of Chinese criminal cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_10",
            "start": 74,
            "end": 185,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_10@2",
            "content": "They evaluated the consistency of LSTM-based models across region and gender and reported severe fairness gaps across gender.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_10",
            "start": 187,
            "end": 311,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_10@3",
            "content": "They also found that the fairness gap was particular severe for more serious crimes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_10",
            "start": 313,
            "end": 396,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_11@0",
            "content": "Previous work has focused on the analysis of specific cases, languages or algorithms, but Fair-Lex aims at easing the development and testing of bias-mitigation models or algorithms within the legal domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_11",
            "start": 0,
            "end": 205,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_11@1",
            "content": "FairLex allows researchers to explore fairness across four datasets covering four jurisdictions (Council of Europe, United States of America, Swiss Confederation and People's Republic of China), five languages (English, German, French, Italian and Chinese) and various sensitive attributes (gender, age, region, etc.).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_11",
            "start": 207,
            "end": 524,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_11@2",
            "content": "Furthermore, we provide competitive baselines including stateof-the-art transformer-based models, adapted to the examined datasets, and an in-dept examination of performance of four group robust algorithms described in detail in Section 4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_11",
            "start": 526,
            "end": 764,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_12@0",
            "content": "Benchmark Datasets",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_12",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_13@0",
            "content": "ECtHR The European Court of Human Rights (ECtHR) hears allegations that a state has breached human rights provisions of the European Convention of Human Rights (ECHR).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_13",
            "start": 0,
            "end": 166,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_13@1",
            "content": "We use the dataset of Chalkidis et al. (2021), which contains 11K cases from ECtHR's public database.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_13",
            "start": 168,
            "end": 268,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_13@2",
            "content": "Each case is mapped to articles of the ECHR that were violated (if any).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_13",
            "start": 270,
            "end": 341,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_13@3",
            "content": "This is a multi-label text classification task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_13",
            "start": 343,
            "end": 389,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_13@4",
            "content": "Given the facts of a case, the goal is to predict the ECHR articles that were violated, if any, as decided (ruled) by the court.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_13",
            "start": 391,
            "end": 518,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_13@5",
            "content": "The cases are chronologically split into training (9k, 2001-16), development (1k, 2016-17), and test (1k, 2017-19) sets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_13",
            "start": 520,
            "end": 639,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_14@0",
            "content": "To facilitate the study of fairness of text classifiers, we record for each case the following attributes: (a) The defendant states, which are the European states that allegedly violated the ECHR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_14",
            "start": 0,
            "end": 195,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_14@1",
            "content": "The defendant states for each case is a subset of the 47 Member States of the Council of Europe; 8 To have statistical support, we group defendant states in two: Central-Eastern European states, on one hand, and all other states, as classified by the Eu-roVoc thesaurus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_14",
            "start": 197,
            "end": 466,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_14@2",
            "content": "9 (b) The applicant's age at the time of the decision.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_14",
            "start": 468,
            "end": 521,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_14@3",
            "content": "We extract the birth year of the applicant from the case facts, if possible, and classify its case in an age group (\u226435, \u226464, or older) ; and (c) the applicant's gender, extracted from the facts, if possible based on pronouns, classified in two categories (male, female).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_14",
            "start": 523,
            "end": 793,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_15@0",
            "content": "The US Supreme Court (SCOTUS) is the highest federal court in the United States of America and generally hears only the most controversial or otherwise complex cases which have not been sufficiently well solved by lower courts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_15",
            "start": 0,
            "end": 226,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_15@1",
            "content": "We combine information from SCOTUS opinions with the Supreme Court DataBase (SCDB) 10 (Spaeth et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_15",
            "start": 228,
            "end": 335,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_15@2",
            "content": "SCDB provides metadata (e.g., date of publication, decisions, issues, decision directions and many more) for all cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_15",
            "start": 337,
            "end": 455,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_15@3",
            "content": "We consider the available 14 thematic issue areas (e.g, Criminal Procedure, Civil Rights, Economic Activity, etc.).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_15",
            "start": 457,
            "end": 571,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_15@4",
            "content": "This is a single-label multi-class document classification task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_15",
            "start": 573,
            "end": 636,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_15@5",
            "content": "Given the court opinion, the goal is to predict the issue area whose focus is on the subject matter of the controversy (dispute).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_15",
            "start": 638,
            "end": 766,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_15@6",
            "content": "SCOTUS contains a total of 9,262 cases that we split chronologically into 80% for training (7.4k, 1946-1982), 10% for development (914,(1982)(1983)(1984)(1985)(1986)(1987)(1988)(1989)(1990)(1991) and 10% for testing (931,.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_15",
            "start": 768,
            "end": 989,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_16@0",
            "content": "From SCDB, we also use the following attributes to study fairness: (a) the type of respondent, which is a manual categorization of respondents (defendants) in five categories (person, public entity, organization, facility and other); and (c) the direction of the decision, i.e., whether the decision is liberal, or conservative, provided by SCDB.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_16",
            "start": 0,
            "end": 345,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_17@0",
            "content": "FSCS The Federal Supreme Court of Switzerland (FSCS) is the last level of appeal in Switzerland and similarly to SCOTUS, the court generally hears only the most controversial or otherwise complex cases which have not been sufficiently well solved by lower courts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_17",
            "start": 0,
            "end": 262,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_17@1",
            "content": "The court often focus only on small parts of previous decision, where they discuss possible wrong reasoning by the lower court.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_17",
            "start": 264,
            "end": 390,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_17@2",
            "content": "The Swiss-Judgment-Predict dataset (Niklaus et al., 2021) contains more than 85K decisions from the FSCS written in one of three languages (50K German, 31K French, 4K Italian) from the years 2000 to 2020.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_17",
            "start": 392,
            "end": 595,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_17@3",
            "content": "The dataset provides labels for a simplified binary (approval, dismissal) classification task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_17",
            "start": 597,
            "end": 690,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_17@4",
            "content": "Given the facts of the case, the goal is to predict if the plaintiff's request is valid or partially valid.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_17",
            "start": 692,
            "end": 798,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_17@5",
            "content": "The cases are also chronologically split into training (59.7k, 2000-2014), development (8.2k, 2015-2016), and test (17.4k, 2017-2020) sets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_17",
            "start": 800,
            "end": 938,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_18@0",
            "content": "The dataset provides three additional attributes: (a) the language of the FSCS written decision, in either German, French, or Italian; (b) the legal area of the case (public, penal, social, civil, or insurance law) derived from the chambers where the decisions were heard; and (c) the region that denotes in which federal region was the case originated.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_18",
            "start": 0,
            "end": 352,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_19@0",
            "content": "SPC The Supreme People's Court of China (SPC) is the last level of appeal in China and considers cases that originated from the high people's courts concerning matters of national importance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_19",
            "start": 0,
            "end": 190,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_19@1",
            "content": "The Chinese AI and Law challenge (CAIL) dataset (Xiao et al., 2018) is a Chinese legal NLP dataset for judgment prediction and contains more 1m criminal cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_19",
            "start": 192,
            "end": 350,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_19@2",
            "content": "The dataset provides labels for relevant article of criminal code prediction, charge (type of crime) prediction, imprisonment term (period) prediction, and monetary penalty prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_19",
            "start": 352,
            "end": 535,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_20@0",
            "content": "Recently, Wang et al. (2021b) re-annotated a subset of approx.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_20",
            "start": 0,
            "end": 61,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_20@1",
            "content": "100k cases with demographic attributes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_20",
            "start": 63,
            "end": 101,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_20@2",
            "content": "Specifically the new dataset has been annotated with: (a) the applicant's gender, classified in two categories (male, female); and (b) the region of the court that denotes in which out of the 7 provincial-level administrative regions was the case judged.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_20",
            "start": 103,
            "end": 356,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_20@3",
            "content": "We re-split the dataset chronologically into training (80k, 2013-2017), development (12k, 2017-2018), and test (12k, 2018) sets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_20",
            "start": 358,
            "end": 485,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_20@4",
            "content": "In our study, we examine a crime severity prediction task, a single-label multi-class classification task, where given the facts of a case, the goal is to predict how severe was the committed crime with respect to the imprisonment term.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_20",
            "start": 487,
            "end": 722,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_20@5",
            "content": "We approximate crime severity by the length of imprisonment term, split in 6 clusters (0, \u226412, \u226436, \u226460, \u2264120, >120 months).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_20",
            "start": 724,
            "end": 847,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_21@0",
            "content": "Fine-tuning Algorithms",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_21",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_22@0",
            "content": "Across experiments, our main goal is to find a hypothesis for which the risk R(h) is minimal:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_22",
            "start": 0,
            "end": 92,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_23@0",
            "content": "h * = arg min h\u2208H R(h) (1) R(h) = E(L(h(x), y))(2)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_23",
            "start": 0,
            "end": 49,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_24@0",
            "content": "where y are the targets (ground truth) and h(x) = \u0177 is the system hypothesis (model's predictions).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_24",
            "start": 0,
            "end": 98,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_25@0",
            "content": "Similar to previous studies, R(h) is an expectation of the selected loss function (L).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_25",
            "start": 0,
            "end": 85,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_25@1",
            "content": "In this work, we study multi-label text classification (Section 3), thus we aim to minimize the binary cross-entropy loss across L classes:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_25",
            "start": 87,
            "end": 225,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_26@0",
            "content": "L = \u2212y log \u0177 \u2212 (1 \u2212 y) log(1 \u2212 \u0177) (3)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_26",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_27@0",
            "content": "ERM (Vapnik, 1992), which stands for Empirical Risk Minimization, is the most standard and widely used optimization technique to train neural methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_27",
            "start": 0,
            "end": 149,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_27@1",
            "content": "The loss is calculated as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_27",
            "start": 151,
            "end": 184,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_28@0",
            "content": "L ERM = N i=1 L i N (4",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_28",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_29@0",
            "content": ")",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_29",
            "start": 0,
            "end": 0,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_30@0",
            "content": "where N is the number of instances (training examples) in a batch, and L i is the loss per instance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_30",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_31@0",
            "content": "Besides ERM, we also consider a representative selection of group-robust fine-tuning algorithms which aims at mitigating performance disparities with respect to a given attribute (A), e.g., the gender of the applicant or the region of the court.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_31",
            "start": 0,
            "end": 244,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_31@1",
            "content": "Each attribute is split into G groups, i.e., male/female for gender.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_31",
            "start": 246,
            "end": 313,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_31@2",
            "content": "All algorithms rely on a balanced group sampler, i.e., an equal number of instances (samples) per group (N G ) are included in each batch.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_31",
            "start": 315,
            "end": 452,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_31@3",
            "content": "Most of the algorithms are built upon group-wise losses (L g ), computed as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_31",
            "start": 454,
            "end": 537,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_32@0",
            "content": "L(g i ) = 1 N g i N g i j=1 L(x j ) (5)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_32",
            "start": 0,
            "end": 38,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_33@0",
            "content": "Group DRO (Sagawa et al., 2020), stands for Group Distributionally Robust Optimization (DRO).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_33",
            "start": 0,
            "end": 92,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_33@1",
            "content": "Group DRO is an extension of the Group Uniform algorithm, where the group-wise losses are weighted inversely proportional to the group training performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_33",
            "start": 94,
            "end": 249,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_33@2",
            "content": "The total loss is:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_33",
            "start": 251,
            "end": 268,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_34@0",
            "content": "L DRO = G i=1 w g i * L(g i ), where(6)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_34",
            "start": 0,
            "end": 38,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_35@0",
            "content": "w g i = 1 W ( \u0175g i * e L(g i ) ) and W = G i=1 w g i (7)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_35",
            "start": 0,
            "end": 55,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_36@0",
            "content": "where G is the number of groups (labels), L g are the averaged group-wise (label-wise) losses, w g are the group (label) weights, \u0175g are the group (label) weights as computed in the previous update step.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_36",
            "start": 0,
            "end": 202,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_36@1",
            "content": "Initially the weight mass in equally distributed across groups.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_36",
            "start": 204,
            "end": 266,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_37@0",
            "content": "REx (Krueger et al., 2020), which stands for Risk Extrapolation, is yet another proposed group-robust optimization algorithm.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_37",
            "start": 0,
            "end": 124,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_37@1",
            "content": "Krueger et al. (2020) hypothesize that variation across training groups is representative of the variation later encountered at test time, so they also consider the variance across the group-wise losses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_37",
            "start": 126,
            "end": 328,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_37@2",
            "content": "In V-REx the total loss is calculated as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_37",
            "start": 330,
            "end": 378,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_38@0",
            "content": "L REX = L ERM + \u03bb * Var([L g 1 , . . . , L g G ]) (8)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_38",
            "start": 0,
            "end": 52,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_39@0",
            "content": "where Var is the variance among the group-wise losses and \u03bb, a weighting hyper-parameter scalar.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_39",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_40@0",
            "content": "IRM (Arjovsky et al., 2020), which stands for Invariant Risk Minimization, mainly aims to penalize variance across multiple training dummy estimators across groups, i.e., performance cannot vary in samples that correspond to the same group.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_40",
            "start": 0,
            "end": 239,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_40@1",
            "content": "The total loss is computed as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_40",
            "start": 241,
            "end": 278,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_41@0",
            "content": "L IRM = 1 G \uf8eb \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ed G i=1 L(g i ) + \u03bb * P(g i ) \uf8f6 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f8(9)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_41",
            "start": 0,
            "end": 73,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_42@0",
            "content": "Please refer to Arjovsky et al. (2020) for the definition of the group penalty terms (P g ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_42",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_43@0",
            "content": "Adversarial Removal (Elazar and Goldberg, 2018) algorithm mitigates group disparities by means of an additional adversarial classifier (Goodfellow et al., 2014).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_43",
            "start": 0,
            "end": 160,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_43@1",
            "content": "The adversarial classifier share the encoder with the main network and is trained to predict the protected attribute (A) of an instance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_43",
            "start": 162,
            "end": 297,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_43@2",
            "content": "The total loss factors in the adversarial one, thus penalizing the model when it is able to discriminate groups.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_43",
            "start": 299,
            "end": 410,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_43@3",
            "content": "Formally, the total loss is calculated as:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_43",
            "start": 412,
            "end": 453,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_44@0",
            "content": "L AR = L ERM \u2212 \u03bb * L ADV (10",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_44",
            "start": 0,
            "end": 27,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_45@0",
            "content": ")",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_45",
            "start": 0,
            "end": 0,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_46@0",
            "content": "L ADV = L(\u011d i , g i ) (11",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_46",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_47@0",
            "content": ")",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_47",
            "start": 0,
            "end": 0,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_48@0",
            "content": "where \u011di is the adversarial classifier's prediction for the examined attribute A (in which group (g i ) of A, does the example belong to) given the input (x).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_48",
            "start": 0,
            "end": 157,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_49@0",
            "content": "Experimental SetUp",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_49",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_50@0",
            "content": "Models Since we are interested in classifying long documents (up to 6000 tokens per document, see Figure 2 in Appendix C.1), we developed a hierarchical BERT-based model similar to that of Chalkidis et al. (2021), so as to avoid using only the first 512 tokens of a text.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_50",
            "start": 0,
            "end": 270,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_50@1",
            "content": "Our hierarchical model, first, encodes the text through a pre-trained Transformer-based architecture, thus representing each paragraph independently with the [CLS] token.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_50",
            "start": 272,
            "end": 441,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_50@2",
            "content": "Then, the paragraph representations are fed into a two-layers transformer encoder with the exact same specifications of the first one (e.g., hidden units, number of attention heads), so as to contextualize them, i.e., it makes paragraphs representations aware of the surrounding paragraphs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_50",
            "start": 443,
            "end": 732,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_50@3",
            "content": "Finally, the model max-pools the context-aware paragraph representations computing the document-level representation and feed it to a classification layer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_50",
            "start": 734,
            "end": 888,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_51@0",
            "content": "For the purpose of this work, we release four domain-specific BERT models with continued pretraining on the corpora of the examined datasets (ECtHR, SCOTUS, FSCS, SPC).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_51",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_51@1",
            "content": "11 We train minisized BERT models with 6 Transformer blocks, 384 hidden units, and 12 attention heads.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_51",
            "start": 169,
            "end": 270,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_51@2",
            "content": "We warmstart all models from the public MiniLMv2 models checkpoints (Wang et al., 2021a) Table 2: Test results for all examined group-robust algorithms per dataset attribute.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_51",
            "start": 272,
            "end": 445,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_51@3",
            "content": "We report the average performance across groups (mF1), the group disparity among groups (GD), and the worst-group performance (mF1 W ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_51",
            "start": 447,
            "end": 581,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_51@4",
            "content": "\u2191 denotes that higher scores are better, while \u2193 denotes that lower scores are better.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_51",
            "start": 583,
            "end": 668,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_52@0",
            "content": "\u2191 mF1 \u2193 GD \u2191 mF1 W \u2191 mF1 \u2193 GD \u2191 mF1 W \u2191 mF1 \u2193 GD \u2191 mF1 W \u2191 mF1 \u2193 GD \u2191 mF1 W \u2191 mF1 \u2193 GD \u2191 mF1 W Bag-of-",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_52",
            "start": 0,
            "end": 101,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_53@0",
            "content": "\u2191 mF1 \u2193 GD \u2191 mF1 W \u2191 mF1 \u2193 GD \u2191 mF1 W \u2191 mF1 \u2193 GD \u2191 mF1 W \u2191 mF1 \u2193 GD \u2191 mF1 W \u2191 mF1 \u2193 GD \u2191 mF1 W Bag-of-",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_53",
            "start": 0,
            "end": 101,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_54@0",
            "content": "version of RoBERTa (Liu et al., 2019) for the English datasets (ECtHR, SCOTUS) and the one distilled from XLM-R (Conneau et al., 2020) for the rest (trilingual FSCS, and Chinese SPC).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_54",
            "start": 0,
            "end": 182,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_54@1",
            "content": "Given the limited size of these models, we can effectively use up to 4096 tokens in ECtHR and SCOTUS and up to 2048 tokens in FSCS and SPC for up to 16 samples per batch in a 24gb nvidia gpu card.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_54",
            "start": 184,
            "end": 379,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_54@2",
            "content": "12 For completeness, we also consider linear Bagof Words (BoW) classifiers using TF-IDF scores of the most frequent n-grams (where n = 1, 2, 3) in the training corpus of each dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_54",
            "start": 381,
            "end": 563,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_55@0",
            "content": "We release a unified version of the benchmark on Hugging Face Datasets (Lhoest et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_55",
            "start": 0,
            "end": 92,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_55@1",
            "content": "13 In our experiments, we use and extend the WILDs (Koh et al., 2021) library.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_55",
            "start": 94,
            "end": 171,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_55@2",
            "content": "For reproducibility and further exploration with new group-robust methods, we release our code on Github.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_55",
            "start": 173,
            "end": 277,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_55@3",
            "content": "12 Evaluation Details Across experiments we compute the macro-F1 score per group (mF1 i ), excluding the group of unidentified instances, if any.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_55",
            "start": 279,
            "end": 423,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_55@4",
            "content": "14 We report macro-F1 to avoid bias toward majority classes because of class imbalance and skewed label distributions across train, development, and test 12 This is particularly important for group-robust algorithms that consider group-wise losses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_55",
            "start": 425,
            "end": 672,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_56@0",
            "content": "13 Both links will be revealed upon acceptance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_56",
            "start": 0,
            "end": 46,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_56@1",
            "content": "14 The group of unidentified instances includes the instances, where the value of the examined attribute is unidentifiable (unknown).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_56",
            "start": 48,
            "end": 180,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_56@2",
            "content": "See details in Appendix C.2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_56",
            "start": 182,
            "end": 209,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_56@3",
            "content": "subsets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_56",
            "start": 211,
            "end": 218,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_56@4",
            "content": "We report the average macro-F1 across groups (mF1) and the group disparity (GD) among groups measured as the group-wise std dev.:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_56",
            "start": 220,
            "end": 348,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_57@0",
            "content": "GD = 1 G G i=1 (mF1 i \u2212 mF1) 2 (12)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_57",
            "start": 0,
            "end": 34,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_58@0",
            "content": "We also report the worst-group performance (mF1 W = min([mF1 1 , mF1 2 , . . . mF1 G )).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_58",
            "start": 0,
            "end": 87,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_59@0",
            "content": "Baseline Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_59",
            "start": 0,
            "end": 15,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_60@0",
            "content": "In Table 2, we report the results of all our baselines on the four datasets introduced in this paper.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_60",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_60@1",
            "content": "We first observe that the results of linear classifiers trained with the ERM algorithm (top row per dataset) are consistently worse (lower average and worst-case performance, higher group disparity) compared to transformed-based models in the same setting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_60",
            "start": 102,
            "end": 357,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_60@2",
            "content": "In other words linear classifier have lower overall performance, while being less fair with respect to the applied definition of fairness (i.e. equal performance across groups).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_60",
            "start": 359,
            "end": 535,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_61@0",
            "content": "As one can see, transformer-based models trained with the ERM algorithm, i.e., without taking into account information about groups and their distribution, perform either better on in the same ballpark than models trained with methods specialized to mitigate biases (Section 4), with an average loss of 0.17 only in terms of mF1 and of 0.78 in terms of mF1 W .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_61",
            "start": 0,
            "end": 359,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_61@1",
            "content": "While, these algorithms improve worst case performance in the literature, when applied in a controlled experimental environment, they fail in a real-world setting, where both groups across attributes and labels are imbalanced, while also both group and label distribution change over time.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_61",
            "start": 361,
            "end": 649,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_61@2",
            "content": "Furthermore, we cannot identify one algorithm that performs better across datasets and group with respect to the others, indeed results are quite mixed without any recognizable pattern.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_61",
            "start": 651,
            "end": 835,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_62@0",
            "content": "Group Disparity Analysis We identify three general (attribute agnostic) factors that could potentially lead to performance disparity across groups:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_62",
            "start": 0,
            "end": 146,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_63@0",
            "content": "\u2022 Representation Inequality: Not all groups are equally represented in the training set. To examine this aspect, we report the number of training cases per group. \u2022 Temporal Concept Drift: The label distribution for a given group changes over time, i.e., inbetween training and test subsets. To examine this aspect, we report per group, the KL divergence in-between the training and test label distribution. \u2022 Worst Class Influence: The performance is not equal across labels (classes), which may disproportionally affect the macro-averaged performance across groups. To examine this aspect, we report the Worst Class Influence (WCI) score per group, which is computed as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_63",
            "start": 0,
            "end": 679,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_64@0",
            "content": "WCI(i) = #test-cases (worst-class) #test-cases(13)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_64",
            "start": 0,
            "end": 49,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_65@0",
            "content": "In Table 3, we present the results across all attributes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_65",
            "start": 0,
            "end": 56,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_65@1",
            "content": "We observe that only in 4 out of 10 cases (attributes), the less represented groups are those with the worst performance compared to the rest.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_65",
            "start": 58,
            "end": 199,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_65@2",
            "content": "It is generally not the case that high KL divergence (drift) correlates with low performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_65",
            "start": 201,
            "end": 293,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_65@3",
            "content": "In other words, group disparities does not seem to be driven by temporal concept drift.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_65",
            "start": 295,
            "end": 381,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_65@4",
            "content": "Finally, the influence of the worst class is relatively uniform across groups in most cases, but in the cases where groups differ in this regard, worst class influence correlates with error in 2 out of 3 cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_65",
            "start": 383,
            "end": 592,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_65@5",
            "content": "15 In ECtHR, considering performance across defendant state, we see that all the three factors correlate internally, i.e., the worst performing group is 15 For ECtHR performance across defendant states and SCO-TUS across directions, but not for ECtHR performance across applicant age.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_65",
            "start": 594,
            "end": 877,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_65@6",
            "content": "Table 3: Statistics for the three general (attribute agnostic) cross-examined factors (representation inequality, temporal concept drift, and worst-class influence), as introduced in Section 6.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_65",
            "start": 879,
            "end": 1071,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_65@7",
            "content": "We highlight the worst and best performing group per attribute.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_65",
            "start": 1073,
            "end": 1135,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_65@8",
            "content": "In boldface, we highlight the best (less harmful) value per factor across groups.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_65",
            "start": 1137,
            "end": 1217,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_65@9",
            "content": "Performance (mF1) reported for ERM.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_65",
            "start": 1219,
            "end": 1253,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_66@0",
            "content": "less represented, has higher temporal drift and has more cases in the worst performing class.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_66",
            "start": 0,
            "end": 92,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_66@1",
            "content": "This is not the case considering performance across other attributes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_66",
            "start": 94,
            "end": 162,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_66@2",
            "content": "It is also not the case for SCOTUS.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_66",
            "start": 164,
            "end": 198,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_66@3",
            "content": "In FSCS, considering the attributes of language and region, representation inequality seems to be an important factor that leads to group disparity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_66",
            "start": 200,
            "end": 347,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_66@4",
            "content": "This is not the case for legal area, where the best represented group is the worst performing group.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_66",
            "start": 349,
            "end": 448,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_66@5",
            "content": "In other words, there are other reasons that lead to performance disparity in this case; for example, inconsistencies in rules and gathering of evidence in criminal cases potentially affects the predictability of rulings (Macula, 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_66",
            "start": 450,
            "end": 685,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_66@6",
            "content": "In sum, we do not see any of these factors fully explain the performance disparities across groups.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_66",
            "start": 687,
            "end": 785,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_67@0",
            "content": "We have evaluated fairness across attributes that are not necessarily independent of each other.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_67",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_67@1",
            "content": "We therefore evaluate the extent to which performance disparities along different attributes correlate, i.e., how attributes interact, and whether performance differences for attribute A 1 can potentially explain performance differences for another attribute A 2 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_67",
            "start": 97,
            "end": 360,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_67@2",
            "content": "We examine this for the two attributes with the highest group disparity: the defendant state in ECtHR, and the legal area in FSCS.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_67",
            "start": 362,
            "end": 491,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_67@3",
            "content": "For the bins induced by these two attributes (A 1 ), we compute mF1 scores across other attributes (A 2 ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_67",
            "start": 493,
            "end": 598,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_67@4",
            "content": "In ECtHR, approx.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_67",
            "start": 600,
            "end": 616,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_67@5",
            "content": "83% and 81% of male and women applicants are involved in cases against E.C. European states (best-performing group).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_67",
            "start": 618,
            "end": 733,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_67@6",
            "content": "Similarly, in case of age groups, we observe that ratio of cases against E.C. European states is: 87% and 86% for \u226465 and \u226435, the best-and worst-performing groups respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_67",
            "start": 735,
            "end": 911,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_68@0",
            "content": "In FSCS, the ratio of cases relevant to penal law is: approx.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_68",
            "start": 0,
            "end": 60,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_68@1",
            "content": "29%, and 41% written in written in French (best-performing group) and Italian (worstperforming group).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_68",
            "start": 62,
            "end": 163,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_68@2",
            "content": "Similarly, approx.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_68",
            "start": 165,
            "end": 182,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_68@3",
            "content": "27% originated in E. Switzerland (best-performing group) and 42% in Federation (worst performing group) are relevant to penal law.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_68",
            "start": 184,
            "end": 313,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_68@4",
            "content": "In both attributes, there is a 15% increase of cases relevant to penal law for the worst performing groups.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_68",
            "start": 315,
            "end": 421,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_68@5",
            "content": "In other words, the group disparity in one attribute A2 (language, region) could be also explained by the influence of another attribute A1 (legal area).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_68",
            "start": 423,
            "end": 575,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_69@0",
            "content": "In Table 4, we report the performance in the aforementioned cross-attribute (A1, A2) pairings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_69",
            "start": 0,
            "end": 93,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_69@1",
            "content": "cross-examination in ECtHR, we observe that group disparities in attribute A2 (Table 3) are consistent across groups of the plausible influencer (i.e. attribute A1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_69",
            "start": 95,
            "end": 259,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_69@2",
            "content": "Hence, cross-attribute influence does not explain the observed group disparities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_69",
            "start": 261,
            "end": 341,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_70@0",
            "content": "We believe that such an in-depth analysis of the results is fundamental to understand the influence of different factors in the outcomes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_70",
            "start": 0,
            "end": 136,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_70@1",
            "content": "This analysis wouldn't be possible, if we had \"counterfeited\" an ideal scenario, where all groups and labels where equally represented.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_70",
            "start": 138,
            "end": 272,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_70@2",
            "content": "While a controlled experimental environment is frequently used to examine specific factors, it could hide, or partially alleviate such phenomena, hence producing misleading results on fairness of the examined models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_70",
            "start": 274,
            "end": 489,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_71@0",
            "content": "Conclusions",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_71",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_72@0",
            "content": "We introduced FairLex, a multi-lingual benchmark for the development and testing of bias-mitigation models or algorithms within the legal domain, based on four datasets covering four jurisdictions, five languages and various sensitive attributes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_72",
            "start": 0,
            "end": 245,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_72@1",
            "content": "Furthermore, we provided competitive baselines including state-of-the-art transformer-based models adapted to the examined datasets, and an in-dept examination of performance of four group robust algorithms (Adversarial Removal, IRM, Group DRO, and REx).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_72",
            "start": 247,
            "end": 500,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_72@2",
            "content": "While, these algorithms improve worst case performance in the literature, when applied in a controlled experimental environment, they fail in a real-world setting, where both groups across attributes, and labels are imbalanced, while also both group and label distributions change over time.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_72",
            "start": 502,
            "end": 792,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_72@3",
            "content": "Furthermore, we cannot identify a single algorithm that performs better across datasets and groups compared to the rest.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_72",
            "start": 794,
            "end": 913,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_73@0",
            "content": "The legal notion of discrimination has a different scope and semantics in comparison to the notions of fairness and bias used in the context of machine learning (Gerards and Xenedis, 2020), where the aim usually is to achieve equal odds, e.g. that a court shall rule the same decision for both men and woman based on similar facts, or to have 50/50 favourable decisions for both man and woman, but equal opportunities (Rawls, 1971).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_73",
            "start": 0,
            "end": 431,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_74@0",
            "content": "In particular, EU non-discrimination law (Council of European Union, 2000Union, , 2006 prohibits both direct and indirect discrimination.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_74",
            "start": 0,
            "end": 136,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_74@1",
            "content": "Direct discrimination occurs when one person is treated \"less favourably than another is, has been or would be treated in a comparable situation\" on grounds of sex, racial or ethnic origin, disability, sexual orientation, religion or belief and age in the context of a protected sector (e.g. the workplace and provision of goods and services) (Wachter et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_74",
            "start": 138,
            "end": 503,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_74@2",
            "content": "Prohibiting direct discrimination allows to provide people with equal access to opportunities (i.e. formal equality).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_74",
            "start": 505,
            "end": 621,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_74@3",
            "content": "This however does not suffice, nor guarantee to create equality of opportunity (i.e. substantive equality), which can instead be achieved only by accounting for protected attributes and for social and historical realities and by taking positive measures to level the playing field (Fredman, 2016).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_74",
            "start": 623,
            "end": 919,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_74@4",
            "content": "The notion of indirect discrimination is grounded on achieving substantive equality in practice.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_74",
            "start": 921,
            "end": 1016,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_74@5",
            "content": "Indirect discrimination refers to situations in which an apparently neutral provision, criterion or practice would put persons with a protected characteristic at disadvantage in comparison to other persons, unless 'that provision, criterion or practice is \"justified by a legitimate aim and the means of achieving that aim are appropriate and necessary\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_74",
            "start": 1018,
            "end": 1371,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_75@0",
            "content": "Nevertheless, the current EU non-discrimination law framework suffers from limitations, both as regards its personal (i.e. it only protects six characteristics) and material scope (i.e. the prohibition on discrimination is limited only to certain fields) (Gerards and Xenedis, 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_75",
            "start": 0,
            "end": 282,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_75@1",
            "content": "These limitations pose problems in connection to algorithmic discrimination.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_75",
            "start": 284,
            "end": 359,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_75@2",
            "content": "For example, as algorithmic bias often creates seemingly neutral distinctions which however often correlate to a protected group (i.e. proxy discrimination), the limited list of protected grounds renders difficult to tackle the effects of algorithmic bias through the concept of direct discrimination (Prince and Schwarcz, 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_75",
            "start": 361,
            "end": 689,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_75@3",
            "content": "Indirect discrimination can help address those cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_75",
            "start": 691,
            "end": 743,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_75@4",
            "content": "but its application in this context poses several challenges.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_75",
            "start": 745,
            "end": 805,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_76@0",
            "content": "In April 2021 the European Commission presented a proposal for a Regulation laying down harmonized rules on artificial intelligence (AI Act / AIA) (Council of European Union, 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_76",
            "start": 0,
            "end": 180,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_76@1",
            "content": "The proposal aims at avoiding \"significant risks to the health and safety or fundamental rights of persons\" and would, once adopted, complement the currently applicable legal framework for tackling algorithmic discrimination, thereby overcoming some of its existing limitations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_76",
            "start": 182,
            "end": 459,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_76@2",
            "content": "The envisaged implementation of the proposed AI Act highlights the importance that the legislator poses in preventing and mitigating discrimination and biases arising from the development and use of AI systems in several areas of application, including in the legal sector (Schwemer et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_76",
            "start": 461,
            "end": 757,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_76@3",
            "content": "AI systems used for the administration of justice and democratic processes are proposed to be deemed high-risk in order \"to address the risks of potential biases, errors, and opacity\" (recital 40 AIA).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_76",
            "start": 759,
            "end": 959,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_76@4",
            "content": "The consequence is that such systems would be subject to a variety of design and development requirements, e.g. related to the training, validation and testing data sets which would have to be examined inter alia in relation to possible biases (art.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_76",
            "start": 961,
            "end": 1209,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_76@5",
            "content": "10(2) lit.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_76",
            "start": 1211,
            "end": 1220,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_76@6",
            "content": "f AIA) or related to human oversight of such AI system with a view to remain aware of automation bias (art.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_76",
            "start": 1222,
            "end": 1328,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_76@7",
            "content": "14(4) lit.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_76",
            "start": 1330,
            "end": 1339,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_76@8",
            "content": "b AIA).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_76",
            "start": 1341,
            "end": 1347,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_77@0",
            "content": "The topic deserves great attention because AI systems learning from historical data pose the risk of transporting biases previously encumbered in the data in future decision-making, thereby exponentially increasing their effect.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_77",
            "start": 0,
            "end": 227,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_77@1",
            "content": "For example, criminal justice is already often strongly influenced by racial bias, with people of colour being more likely to be arrested and receive higher punishments than others, both in both in the USA 16 and in the UK.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_77",
            "start": 229,
            "end": 451,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_77@2",
            "content": "17",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_77",
            "start": 453,
            "end": 454,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_78@0",
            "content": "We fine-tune all models using the AdamW (Loshchilov and Hutter, 2019) optimizer with a learning rate of 3e-5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_78",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_78@1",
            "content": "We use a batch size of 16 and train models for up to 20 epochs using early stopping on validation performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_78",
            "start": 110,
            "end": 219,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_78@2",
            "content": "18 Across datasets and attributes, we run five repetitions with different random seeds and report averaged scores.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_78",
            "start": 221,
            "end": 334,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_79@0",
            "content": "In Figure 2 we report the distribution of sequence (document) length across FairLex datasets (ECtHR, SCOTUS, FSCS).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_79",
            "start": 0,
            "end": 114,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_79@1",
            "content": "We observe that the documents are extremely long (3,000-6,000+ words) across datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_79",
            "start": 116,
            "end": 201,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_80@0",
            "content": "In Tables 5 and 6 we report the group distribution per examined attribute under consideration.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_80",
            "start": 0,
            "end": 93,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_80@1",
            "content": "In some cases, the extraction of the specific attribute, e.g., gender or age in ECtHR, was not possible, i.e., the applied rules would no suffice, possibly because the information is intentionally missing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_80",
            "start": 95,
            "end": 299,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_80@2",
            "content": "During training, the groups of unidentified samples is included, but we report test scores excluding those, i.e., mF1 and GD do not take into account the F1 of these groups.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_80",
            "start": 301,
            "end": 473,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_81@0",
            "content": "In Tables 7, 8, 9, and 10, we report the Jensen-Shannon divergences between train-test, train-dev and test-test distribution of labels separately for each protrected attribute values and for each dataset in our framework.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_81",
            "start": 0,
            "end": 220,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_82@0",
            "content": "UNKNOWN, None, , 2019. Proceedings of the 1st Natural Legal Language Processing Workshop at NAACL 2019. Minneapolis, Minnesota, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_82",
            "start": 0,
            "end": 128,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_83@0",
            "content": "Elizabeth Anderson, What is the point of equality?, 1999, Ethics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_83",
            "start": 0,
            "end": 66,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_84@0",
            "content": "UNKNOWN, None, 2016, Machine bias: There's software used across the country to predict future criminals. and it's biased against blacks, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_84",
            "start": 0,
            "end": 137,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_85@0",
            "content": "UNKNOWN, None, 2020, Invariant Risk Minimization, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_85",
            "start": 0,
            "end": 50,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_86@0",
            "content": "UNKNOWN, None, 2020, The Cambridge Handbook of the Law of Algorithms. Cambridge Law Handbooks, Cambridge University Press.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_86",
            "start": 0,
            "end": 121,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_87@0",
            "content": "Kristen Bell, Jenny Hong, Nick Mckeown, Catalin Voss, The Recon Approach: A New Direction for Machine Learning in Criminal Law, 2021, Berkeley Technology Law Journal, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_87",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_88@0",
            "content": ", Paragraph-level rationale extraction through regularization: A case study on European court of human rights cases, , Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_88",
            "start": 0,
            "end": 263,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_89@0",
            "content": "UNKNOWN, None, 2019, Deep learning in law: Early adaptation and legal word embeddings trained on large corpora. Artificial Intelligence and Law, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_89",
            "start": 0,
            "end": 145,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_90@0",
            "content": "Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettlemoyer, Veselin Stoyanov, Unsupervised cross-lingual representation learning at scale, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_90",
            "start": 0,
            "end": 322,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_91@0",
            "content": "UNKNOWN, None, 2000-06, implementing the principle of equal treatment between persons irrespective of racial or ethnic origin, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_91",
            "start": 0,
            "end": 127,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_92@0",
            "content": "UNKNOWN, None, 2006-07, on the implementation of the principle of equal opportunities and equal treatment of men and women in matters of employment and occupation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_92",
            "start": 0,
            "end": 164,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_93@0",
            "content": "UNKNOWN, None, 2021, Proposal for a Regulation laying down harmonised rules on Artificial Intelligence (Artificial Intelligence Act) and amending certain Union legislative acts, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_93",
            "start": 0,
            "end": 178,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_94@0",
            "content": "Michele Donini, Luca Oneto, Shai Ben-David, John Shawe-Taylor, Massimiliano Pontil, Empirical risk minimization under fairness constraints, 2018, Advances in Neural Information Processing Systems, Curran Associates, Inc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_94",
            "start": 0,
            "end": 219,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_95@0",
            "content": "Julia Dressel, Hany Farid, The accuracy, fairness, and limits of predicting recidivism, 2018, Science Advances, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_95",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_96@0",
            "content": "Yanai Elazar, Yoav Goldberg, Adversarial removal of demographic attributes from text data, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_96",
            "start": 0,
            "end": 185,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_97@0",
            "content": "UNKNOWN, None, 2016, Substantive equality revisited. I-CON Oxford Legal Studies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_97",
            "start": 0,
            "end": 81,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_98@0",
            "content": "UNKNOWN, None, 2020, Algorithmic discrimination in europe: challenges and opportunities for gender equality and nondiscrimination law, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_98",
            "start": 0,
            "end": 135,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_99@0",
            "content": "Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio, Generative adversarial networks, 2014, Advances in Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_99",
            "start": 0,
            "end": 215,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_100@0",
            "content": "Tatsunori Hashimoto, Megha Srivastava, Hongseok Namkoong, Percy Liang, Fairness without demographics in repeated loss minimization, 2018, Proceedings of the 35th International Conference on Machine Learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_100",
            "start": 0,
            "end": 208,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_101@0",
            "content": "Daniel Martin Katz, Quantitative legal prediction-or-how I learned to stop worrying and start preparing for the data-driven future of the legal services industry, 2012, Emory Law Journal, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_101",
            "start": 0,
            "end": 188,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_102@0",
            "content": "Corinna Daniel Martin Katz,  Coupette, Janis Beckedorf, and Dirk Hartung. 2020. Complex societies and the growth of the law, , Scientific Reports, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_102",
            "start": 0,
            "end": 147,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_103@0",
            "content": "Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Xie, Marvin Zhang, Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard Phillips, Irena Gao, Tony Lee, Etienne David, Ian Stavness, Wei Guo, A Berton, Imran Earnshaw, Sara Haque, Jure Beery, Anshul Leskovec, Emma Kundaje, Sergey Pierson, Chelsea Levine, Percy Finn,  Liang, WILDS: A benchmark of in-the-wild distribution shifts, 2021, International Conference on Machine Learning (ICML), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_103",
            "start": 0,
            "end": 446,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_104@0",
            "content": "UNKNOWN, None, , Out-of-Distribution Generalization via Risk Extrapolation (REx), CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_104",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_105@0",
            "content": "UNKNOWN, None, , Lysandre Debut, Stas Bekman, Pierric Cistac, Thibault Goehringer, Victor Mustar, Fran\u00e7ois Lagunas, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_105",
            "start": 0,
            "end": 116,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_106@0",
            "content": "UNKNOWN, None, 1907, Roberta: A robustly optimized BERT pretraining approach, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_106",
            "start": 0,
            "end": 78,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_107@0",
            "content": "Ilya Loshchilov, Frank Hutter, Decoupled weight decay regularization, 2019, International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_107",
            "start": 0,
            "end": 130,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_108@0",
            "content": "Alan Lundgard, Measuring justice in machine learning, 2020, Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, FAT* '20, Association for Computing Machinery.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_108",
            "start": 0,
            "end": 187,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_109@0",
            "content": "UNKNOWN, None, 2019, The Potential to Secure a Fair Trial Through Evidence Exclusion: A Swiss Perspective, Springer International Publishing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_109",
            "start": 0,
            "end": 140,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_110@0",
            "content": "Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, Aram Galstyan, A survey on bias and fairness in machine learning, 2021, ACM Comput. Surv, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_110",
            "start": 0,
            "end": 158,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_111@0",
            "content": "Joel Niklaus, Ilias Chalkidis, Matthias St\u00fcrmer, Swiss-Court-Predict: A Multilingual Legal Judgment Prediction Benchmark, 2021, Proceedings of the 2022 NLLP Workshop, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_111",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_112@0",
            "content": "Anya Prince, Daniel Schwarcz, Proxy discrimination in the age of artificial intelligence and big data, 2019, Iowa Law Review, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_112",
            "start": 0,
            "end": 126,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_113@0",
            "content": "UNKNOWN, None, 1971, Theory of Justice, Belknap Press of Harvard University Press.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_113",
            "start": 0,
            "end": 81,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_114@0",
            "content": "UNKNOWN, None, 2009, Justice as fairness and the capability approach. Arguments for a Better World. Essays for Amartya Sen's, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_114",
            "start": 0,
            "end": 126,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_115@0",
            "content": "Shiori Sagawa, Pang Wei Koh, Tatsunori Hashimoto, Percy Liang, Distributionally Robust Neural Networks, 2020, International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_115",
            "start": 0,
            "end": 164,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_116@0",
            "content": "Letizia Sebastian Felix Schwemer, Tommaso Tomada,  Pasini, Legal ai systems in the eu's proposed artificial intelligence act, 2021, Joint Proceedings of the Workshops on Automated Semantic Analysis of Information in Legal Text (ASAIL 2021) and AI and Intelligent Assistance for Legal Professionals in the Digital, Workplace, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_116",
            "start": 0,
            "end": 325,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_117@0",
            "content": "UNKNOWN, None, 2020, Supreme Court Database, Version 2020 Release 01, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_117",
            "start": 0,
            "end": 70,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_118@0",
            "content": "Dimitrios Tsarapatsanis, Nikolaos Aletras, On the ethical limits of natural language processing on legal text, 2021, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_118",
            "start": 0,
            "end": 242,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_119@0",
            "content": "V Vapnik, Principles of risk minimization for learning theory, 1992, Advances in Neural Information Processing Systems, Morgan-Kaufmann.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_119",
            "start": 0,
            "end": 135,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_120@0",
            "content": "Sandra Wachter, Brent Mittelstadt, Chris Russell, Bias preservation in machine learning: The legality of fairness metrics under eu nondiscrimination law, 2021, West Virginia Law Review, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_120",
            "start": 0,
            "end": 186,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_121@0",
            "content": "Wenhui Wang, Hangbo Bao, Shaohan Huang, Li Dong, Furu Wei, MiniLMv2: Multi-head selfattention relation distillation for compressing pretrained transformers, 2021, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_121",
            "start": 0,
            "end": 239,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_122@0",
            "content": "Yuzhong Wang, Chaojun Xiao, Shirong Ma, Haoxi Zhong, Cunchao Tu, Tianyang Zhang, Zhiyuan Liu, Maosong Sun, Equality before the law: Legal judgment consistency analysis for fairness, 2021, Science China -Information Sciences, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_122",
            "start": 0,
            "end": 225,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_123@0",
            "content": "UNKNOWN, None, 2018, CAIL2018: A large-scale legal dataset for judgment prediction, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_123",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "177-ARR_v1_124@0",
            "content": "Haoxi Zhong, Chaojun Xiao, Cunchao Tu, Tianyang Zhang, Zhiyuan Liu, Maosong Sun, How does NLP benefit legal system: A summary of legal artificial intelligence, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "177-ARR_v1_124",
            "start": 0,
            "end": 304,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "177-ARR_v1_0",
            "tgt_ix": "177-ARR_v1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_0",
            "tgt_ix": "177-ARR_v1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_1",
            "tgt_ix": "177-ARR_v1_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_1",
            "tgt_ix": "177-ARR_v1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_0",
            "tgt_ix": "177-ARR_v1_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_2",
            "tgt_ix": "177-ARR_v1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_4",
            "tgt_ix": "177-ARR_v1_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_5",
            "tgt_ix": "177-ARR_v1_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_6",
            "tgt_ix": "177-ARR_v1_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_3",
            "tgt_ix": "177-ARR_v1_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_3",
            "tgt_ix": "177-ARR_v1_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_3",
            "tgt_ix": "177-ARR_v1_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_3",
            "tgt_ix": "177-ARR_v1_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_3",
            "tgt_ix": "177-ARR_v1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_0",
            "tgt_ix": "177-ARR_v1_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_8",
            "tgt_ix": "177-ARR_v1_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_8",
            "tgt_ix": "177-ARR_v1_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_10",
            "tgt_ix": "177-ARR_v1_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_8",
            "tgt_ix": "177-ARR_v1_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_8",
            "tgt_ix": "177-ARR_v1_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_9",
            "tgt_ix": "177-ARR_v1_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_0",
            "tgt_ix": "177-ARR_v1_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_11",
            "tgt_ix": "177-ARR_v1_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_13",
            "tgt_ix": "177-ARR_v1_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_12",
            "tgt_ix": "177-ARR_v1_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_12",
            "tgt_ix": "177-ARR_v1_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_12",
            "tgt_ix": "177-ARR_v1_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_15",
            "tgt_ix": "177-ARR_v1_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_16",
            "tgt_ix": "177-ARR_v1_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_17",
            "tgt_ix": "177-ARR_v1_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_18",
            "tgt_ix": "177-ARR_v1_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_19",
            "tgt_ix": "177-ARR_v1_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_12",
            "tgt_ix": "177-ARR_v1_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_12",
            "tgt_ix": "177-ARR_v1_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_12",
            "tgt_ix": "177-ARR_v1_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_12",
            "tgt_ix": "177-ARR_v1_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_12",
            "tgt_ix": "177-ARR_v1_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_12",
            "tgt_ix": "177-ARR_v1_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_14",
            "tgt_ix": "177-ARR_v1_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_0",
            "tgt_ix": "177-ARR_v1_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_20",
            "tgt_ix": "177-ARR_v1_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_22",
            "tgt_ix": "177-ARR_v1_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_23",
            "tgt_ix": "177-ARR_v1_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_24",
            "tgt_ix": "177-ARR_v1_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_25",
            "tgt_ix": "177-ARR_v1_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_26",
            "tgt_ix": "177-ARR_v1_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_27",
            "tgt_ix": "177-ARR_v1_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_28",
            "tgt_ix": "177-ARR_v1_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_29",
            "tgt_ix": "177-ARR_v1_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_30",
            "tgt_ix": "177-ARR_v1_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_31",
            "tgt_ix": "177-ARR_v1_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_32",
            "tgt_ix": "177-ARR_v1_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_33",
            "tgt_ix": "177-ARR_v1_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_34",
            "tgt_ix": "177-ARR_v1_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_35",
            "tgt_ix": "177-ARR_v1_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_36",
            "tgt_ix": "177-ARR_v1_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_37",
            "tgt_ix": "177-ARR_v1_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_38",
            "tgt_ix": "177-ARR_v1_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_39",
            "tgt_ix": "177-ARR_v1_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_40",
            "tgt_ix": "177-ARR_v1_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_41",
            "tgt_ix": "177-ARR_v1_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_42",
            "tgt_ix": "177-ARR_v1_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_43",
            "tgt_ix": "177-ARR_v1_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_44",
            "tgt_ix": "177-ARR_v1_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_45",
            "tgt_ix": "177-ARR_v1_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_46",
            "tgt_ix": "177-ARR_v1_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_47",
            "tgt_ix": "177-ARR_v1_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_0",
            "tgt_ix": "177-ARR_v1_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_48",
            "tgt_ix": "177-ARR_v1_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_50",
            "tgt_ix": "177-ARR_v1_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_51",
            "tgt_ix": "177-ARR_v1_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_52",
            "tgt_ix": "177-ARR_v1_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_53",
            "tgt_ix": "177-ARR_v1_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_49",
            "tgt_ix": "177-ARR_v1_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_49",
            "tgt_ix": "177-ARR_v1_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_49",
            "tgt_ix": "177-ARR_v1_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_49",
            "tgt_ix": "177-ARR_v1_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_49",
            "tgt_ix": "177-ARR_v1_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_49",
            "tgt_ix": "177-ARR_v1_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_55",
            "tgt_ix": "177-ARR_v1_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_56",
            "tgt_ix": "177-ARR_v1_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_57",
            "tgt_ix": "177-ARR_v1_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_49",
            "tgt_ix": "177-ARR_v1_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_49",
            "tgt_ix": "177-ARR_v1_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_49",
            "tgt_ix": "177-ARR_v1_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_49",
            "tgt_ix": "177-ARR_v1_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_54",
            "tgt_ix": "177-ARR_v1_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_0",
            "tgt_ix": "177-ARR_v1_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_58",
            "tgt_ix": "177-ARR_v1_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_60",
            "tgt_ix": "177-ARR_v1_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_61",
            "tgt_ix": "177-ARR_v1_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_62",
            "tgt_ix": "177-ARR_v1_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_64",
            "tgt_ix": "177-ARR_v1_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_65",
            "tgt_ix": "177-ARR_v1_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_59",
            "tgt_ix": "177-ARR_v1_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_59",
            "tgt_ix": "177-ARR_v1_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_59",
            "tgt_ix": "177-ARR_v1_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_59",
            "tgt_ix": "177-ARR_v1_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_59",
            "tgt_ix": "177-ARR_v1_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_59",
            "tgt_ix": "177-ARR_v1_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_59",
            "tgt_ix": "177-ARR_v1_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_59",
            "tgt_ix": "177-ARR_v1_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_67",
            "tgt_ix": "177-ARR_v1_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_68",
            "tgt_ix": "177-ARR_v1_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_69",
            "tgt_ix": "177-ARR_v1_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_59",
            "tgt_ix": "177-ARR_v1_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_59",
            "tgt_ix": "177-ARR_v1_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_59",
            "tgt_ix": "177-ARR_v1_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_59",
            "tgt_ix": "177-ARR_v1_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_66",
            "tgt_ix": "177-ARR_v1_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_0",
            "tgt_ix": "177-ARR_v1_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_70",
            "tgt_ix": "177-ARR_v1_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_71",
            "tgt_ix": "177-ARR_v1_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_71",
            "tgt_ix": "177-ARR_v1_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_73",
            "tgt_ix": "177-ARR_v1_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_74",
            "tgt_ix": "177-ARR_v1_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_75",
            "tgt_ix": "177-ARR_v1_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_76",
            "tgt_ix": "177-ARR_v1_77",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_71",
            "tgt_ix": "177-ARR_v1_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_71",
            "tgt_ix": "177-ARR_v1_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_71",
            "tgt_ix": "177-ARR_v1_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_71",
            "tgt_ix": "177-ARR_v1_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_71",
            "tgt_ix": "177-ARR_v1_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_72",
            "tgt_ix": "177-ARR_v1_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_71",
            "tgt_ix": "177-ARR_v1_78",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_77",
            "tgt_ix": "177-ARR_v1_78",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_71",
            "tgt_ix": "177-ARR_v1_79",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_78",
            "tgt_ix": "177-ARR_v1_79",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_71",
            "tgt_ix": "177-ARR_v1_80",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_79",
            "tgt_ix": "177-ARR_v1_80",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_71",
            "tgt_ix": "177-ARR_v1_81",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_80",
            "tgt_ix": "177-ARR_v1_81",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "177-ARR_v1_0",
            "tgt_ix": "177-ARR_v1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_1",
            "tgt_ix": "177-ARR_v1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_2",
            "tgt_ix": "177-ARR_v1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_2",
            "tgt_ix": "177-ARR_v1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_2",
            "tgt_ix": "177-ARR_v1_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_2",
            "tgt_ix": "177-ARR_v1_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_3",
            "tgt_ix": "177-ARR_v1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_4",
            "tgt_ix": "177-ARR_v1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_4",
            "tgt_ix": "177-ARR_v1_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_4",
            "tgt_ix": "177-ARR_v1_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_4",
            "tgt_ix": "177-ARR_v1_4@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_4",
            "tgt_ix": "177-ARR_v1_4@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_4",
            "tgt_ix": "177-ARR_v1_4@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_4",
            "tgt_ix": "177-ARR_v1_4@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_4",
            "tgt_ix": "177-ARR_v1_4@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_5",
            "tgt_ix": "177-ARR_v1_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_5",
            "tgt_ix": "177-ARR_v1_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_5",
            "tgt_ix": "177-ARR_v1_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_5",
            "tgt_ix": "177-ARR_v1_5@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_5",
            "tgt_ix": "177-ARR_v1_5@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_5",
            "tgt_ix": "177-ARR_v1_5@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_5",
            "tgt_ix": "177-ARR_v1_5@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_5",
            "tgt_ix": "177-ARR_v1_5@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_6",
            "tgt_ix": "177-ARR_v1_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_6",
            "tgt_ix": "177-ARR_v1_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_6",
            "tgt_ix": "177-ARR_v1_6@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_6",
            "tgt_ix": "177-ARR_v1_6@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_6",
            "tgt_ix": "177-ARR_v1_6@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_6",
            "tgt_ix": "177-ARR_v1_6@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_6",
            "tgt_ix": "177-ARR_v1_6@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_7",
            "tgt_ix": "177-ARR_v1_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_8",
            "tgt_ix": "177-ARR_v1_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_9",
            "tgt_ix": "177-ARR_v1_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_9",
            "tgt_ix": "177-ARR_v1_9@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_9",
            "tgt_ix": "177-ARR_v1_9@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_9",
            "tgt_ix": "177-ARR_v1_9@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_9",
            "tgt_ix": "177-ARR_v1_9@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_9",
            "tgt_ix": "177-ARR_v1_9@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_9",
            "tgt_ix": "177-ARR_v1_9@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_9",
            "tgt_ix": "177-ARR_v1_9@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_9",
            "tgt_ix": "177-ARR_v1_9@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_9",
            "tgt_ix": "177-ARR_v1_9@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_9",
            "tgt_ix": "177-ARR_v1_9@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_10",
            "tgt_ix": "177-ARR_v1_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_10",
            "tgt_ix": "177-ARR_v1_10@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_10",
            "tgt_ix": "177-ARR_v1_10@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_10",
            "tgt_ix": "177-ARR_v1_10@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_11",
            "tgt_ix": "177-ARR_v1_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_11",
            "tgt_ix": "177-ARR_v1_11@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_11",
            "tgt_ix": "177-ARR_v1_11@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_12",
            "tgt_ix": "177-ARR_v1_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_13",
            "tgt_ix": "177-ARR_v1_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_13",
            "tgt_ix": "177-ARR_v1_13@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_13",
            "tgt_ix": "177-ARR_v1_13@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_13",
            "tgt_ix": "177-ARR_v1_13@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_13",
            "tgt_ix": "177-ARR_v1_13@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_13",
            "tgt_ix": "177-ARR_v1_13@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_14",
            "tgt_ix": "177-ARR_v1_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_14",
            "tgt_ix": "177-ARR_v1_14@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_14",
            "tgt_ix": "177-ARR_v1_14@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_14",
            "tgt_ix": "177-ARR_v1_14@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_15",
            "tgt_ix": "177-ARR_v1_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_15",
            "tgt_ix": "177-ARR_v1_15@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_15",
            "tgt_ix": "177-ARR_v1_15@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_15",
            "tgt_ix": "177-ARR_v1_15@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_15",
            "tgt_ix": "177-ARR_v1_15@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_15",
            "tgt_ix": "177-ARR_v1_15@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_15",
            "tgt_ix": "177-ARR_v1_15@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_16",
            "tgt_ix": "177-ARR_v1_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_17",
            "tgt_ix": "177-ARR_v1_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_17",
            "tgt_ix": "177-ARR_v1_17@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_17",
            "tgt_ix": "177-ARR_v1_17@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_17",
            "tgt_ix": "177-ARR_v1_17@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_17",
            "tgt_ix": "177-ARR_v1_17@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_17",
            "tgt_ix": "177-ARR_v1_17@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_18",
            "tgt_ix": "177-ARR_v1_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_19",
            "tgt_ix": "177-ARR_v1_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_19",
            "tgt_ix": "177-ARR_v1_19@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_19",
            "tgt_ix": "177-ARR_v1_19@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_20",
            "tgt_ix": "177-ARR_v1_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_20",
            "tgt_ix": "177-ARR_v1_20@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_20",
            "tgt_ix": "177-ARR_v1_20@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_20",
            "tgt_ix": "177-ARR_v1_20@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_20",
            "tgt_ix": "177-ARR_v1_20@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_20",
            "tgt_ix": "177-ARR_v1_20@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_21",
            "tgt_ix": "177-ARR_v1_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_22",
            "tgt_ix": "177-ARR_v1_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_23",
            "tgt_ix": "177-ARR_v1_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_24",
            "tgt_ix": "177-ARR_v1_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_25",
            "tgt_ix": "177-ARR_v1_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_25",
            "tgt_ix": "177-ARR_v1_25@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_26",
            "tgt_ix": "177-ARR_v1_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_27",
            "tgt_ix": "177-ARR_v1_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_27",
            "tgt_ix": "177-ARR_v1_27@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_28",
            "tgt_ix": "177-ARR_v1_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_29",
            "tgt_ix": "177-ARR_v1_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_30",
            "tgt_ix": "177-ARR_v1_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_31",
            "tgt_ix": "177-ARR_v1_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_31",
            "tgt_ix": "177-ARR_v1_31@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_31",
            "tgt_ix": "177-ARR_v1_31@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_31",
            "tgt_ix": "177-ARR_v1_31@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_32",
            "tgt_ix": "177-ARR_v1_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_33",
            "tgt_ix": "177-ARR_v1_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_33",
            "tgt_ix": "177-ARR_v1_33@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_33",
            "tgt_ix": "177-ARR_v1_33@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_34",
            "tgt_ix": "177-ARR_v1_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_35",
            "tgt_ix": "177-ARR_v1_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_36",
            "tgt_ix": "177-ARR_v1_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_36",
            "tgt_ix": "177-ARR_v1_36@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_37",
            "tgt_ix": "177-ARR_v1_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_37",
            "tgt_ix": "177-ARR_v1_37@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_37",
            "tgt_ix": "177-ARR_v1_37@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_38",
            "tgt_ix": "177-ARR_v1_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_39",
            "tgt_ix": "177-ARR_v1_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_40",
            "tgt_ix": "177-ARR_v1_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_40",
            "tgt_ix": "177-ARR_v1_40@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_41",
            "tgt_ix": "177-ARR_v1_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_42",
            "tgt_ix": "177-ARR_v1_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_43",
            "tgt_ix": "177-ARR_v1_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_43",
            "tgt_ix": "177-ARR_v1_43@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_43",
            "tgt_ix": "177-ARR_v1_43@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_43",
            "tgt_ix": "177-ARR_v1_43@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_44",
            "tgt_ix": "177-ARR_v1_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_45",
            "tgt_ix": "177-ARR_v1_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_46",
            "tgt_ix": "177-ARR_v1_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_47",
            "tgt_ix": "177-ARR_v1_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_48",
            "tgt_ix": "177-ARR_v1_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_49",
            "tgt_ix": "177-ARR_v1_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_50",
            "tgt_ix": "177-ARR_v1_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_50",
            "tgt_ix": "177-ARR_v1_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_50",
            "tgt_ix": "177-ARR_v1_50@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_50",
            "tgt_ix": "177-ARR_v1_50@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_51",
            "tgt_ix": "177-ARR_v1_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_51",
            "tgt_ix": "177-ARR_v1_51@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_51",
            "tgt_ix": "177-ARR_v1_51@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_51",
            "tgt_ix": "177-ARR_v1_51@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_51",
            "tgt_ix": "177-ARR_v1_51@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_52",
            "tgt_ix": "177-ARR_v1_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_53",
            "tgt_ix": "177-ARR_v1_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_54",
            "tgt_ix": "177-ARR_v1_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_54",
            "tgt_ix": "177-ARR_v1_54@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_54",
            "tgt_ix": "177-ARR_v1_54@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_55",
            "tgt_ix": "177-ARR_v1_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_55",
            "tgt_ix": "177-ARR_v1_55@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_55",
            "tgt_ix": "177-ARR_v1_55@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_55",
            "tgt_ix": "177-ARR_v1_55@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_55",
            "tgt_ix": "177-ARR_v1_55@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_56",
            "tgt_ix": "177-ARR_v1_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_56",
            "tgt_ix": "177-ARR_v1_56@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_56",
            "tgt_ix": "177-ARR_v1_56@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_56",
            "tgt_ix": "177-ARR_v1_56@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_56",
            "tgt_ix": "177-ARR_v1_56@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_57",
            "tgt_ix": "177-ARR_v1_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_58",
            "tgt_ix": "177-ARR_v1_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_59",
            "tgt_ix": "177-ARR_v1_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_60",
            "tgt_ix": "177-ARR_v1_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_60",
            "tgt_ix": "177-ARR_v1_60@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_60",
            "tgt_ix": "177-ARR_v1_60@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_61",
            "tgt_ix": "177-ARR_v1_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_61",
            "tgt_ix": "177-ARR_v1_61@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_61",
            "tgt_ix": "177-ARR_v1_61@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_62",
            "tgt_ix": "177-ARR_v1_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_63",
            "tgt_ix": "177-ARR_v1_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_64",
            "tgt_ix": "177-ARR_v1_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_65",
            "tgt_ix": "177-ARR_v1_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_65",
            "tgt_ix": "177-ARR_v1_65@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_65",
            "tgt_ix": "177-ARR_v1_65@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_65",
            "tgt_ix": "177-ARR_v1_65@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_65",
            "tgt_ix": "177-ARR_v1_65@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_65",
            "tgt_ix": "177-ARR_v1_65@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_65",
            "tgt_ix": "177-ARR_v1_65@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_65",
            "tgt_ix": "177-ARR_v1_65@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_65",
            "tgt_ix": "177-ARR_v1_65@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_65",
            "tgt_ix": "177-ARR_v1_65@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_66",
            "tgt_ix": "177-ARR_v1_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_66",
            "tgt_ix": "177-ARR_v1_66@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_66",
            "tgt_ix": "177-ARR_v1_66@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_66",
            "tgt_ix": "177-ARR_v1_66@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_66",
            "tgt_ix": "177-ARR_v1_66@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_66",
            "tgt_ix": "177-ARR_v1_66@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_66",
            "tgt_ix": "177-ARR_v1_66@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_67",
            "tgt_ix": "177-ARR_v1_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_67",
            "tgt_ix": "177-ARR_v1_67@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_67",
            "tgt_ix": "177-ARR_v1_67@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_67",
            "tgt_ix": "177-ARR_v1_67@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_67",
            "tgt_ix": "177-ARR_v1_67@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_67",
            "tgt_ix": "177-ARR_v1_67@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_67",
            "tgt_ix": "177-ARR_v1_67@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_68",
            "tgt_ix": "177-ARR_v1_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_68",
            "tgt_ix": "177-ARR_v1_68@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_68",
            "tgt_ix": "177-ARR_v1_68@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_68",
            "tgt_ix": "177-ARR_v1_68@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_68",
            "tgt_ix": "177-ARR_v1_68@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_68",
            "tgt_ix": "177-ARR_v1_68@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_69",
            "tgt_ix": "177-ARR_v1_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_69",
            "tgt_ix": "177-ARR_v1_69@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_69",
            "tgt_ix": "177-ARR_v1_69@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_70",
            "tgt_ix": "177-ARR_v1_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_70",
            "tgt_ix": "177-ARR_v1_70@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_70",
            "tgt_ix": "177-ARR_v1_70@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_71",
            "tgt_ix": "177-ARR_v1_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_72",
            "tgt_ix": "177-ARR_v1_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_72",
            "tgt_ix": "177-ARR_v1_72@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_72",
            "tgt_ix": "177-ARR_v1_72@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_72",
            "tgt_ix": "177-ARR_v1_72@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_73",
            "tgt_ix": "177-ARR_v1_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_74",
            "tgt_ix": "177-ARR_v1_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_74",
            "tgt_ix": "177-ARR_v1_74@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_74",
            "tgt_ix": "177-ARR_v1_74@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_74",
            "tgt_ix": "177-ARR_v1_74@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_74",
            "tgt_ix": "177-ARR_v1_74@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_74",
            "tgt_ix": "177-ARR_v1_74@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_75",
            "tgt_ix": "177-ARR_v1_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_75",
            "tgt_ix": "177-ARR_v1_75@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_75",
            "tgt_ix": "177-ARR_v1_75@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_75",
            "tgt_ix": "177-ARR_v1_75@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_75",
            "tgt_ix": "177-ARR_v1_75@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_76",
            "tgt_ix": "177-ARR_v1_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_76",
            "tgt_ix": "177-ARR_v1_76@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_76",
            "tgt_ix": "177-ARR_v1_76@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_76",
            "tgt_ix": "177-ARR_v1_76@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_76",
            "tgt_ix": "177-ARR_v1_76@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_76",
            "tgt_ix": "177-ARR_v1_76@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_76",
            "tgt_ix": "177-ARR_v1_76@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_76",
            "tgt_ix": "177-ARR_v1_76@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_76",
            "tgt_ix": "177-ARR_v1_76@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_77",
            "tgt_ix": "177-ARR_v1_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_77",
            "tgt_ix": "177-ARR_v1_77@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_77",
            "tgt_ix": "177-ARR_v1_77@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_78",
            "tgt_ix": "177-ARR_v1_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_78",
            "tgt_ix": "177-ARR_v1_78@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_78",
            "tgt_ix": "177-ARR_v1_78@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_79",
            "tgt_ix": "177-ARR_v1_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_79",
            "tgt_ix": "177-ARR_v1_79@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_80",
            "tgt_ix": "177-ARR_v1_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_80",
            "tgt_ix": "177-ARR_v1_80@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_80",
            "tgt_ix": "177-ARR_v1_80@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_81",
            "tgt_ix": "177-ARR_v1_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_82",
            "tgt_ix": "177-ARR_v1_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_83",
            "tgt_ix": "177-ARR_v1_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_84",
            "tgt_ix": "177-ARR_v1_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_85",
            "tgt_ix": "177-ARR_v1_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_86",
            "tgt_ix": "177-ARR_v1_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_87",
            "tgt_ix": "177-ARR_v1_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_88",
            "tgt_ix": "177-ARR_v1_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_89",
            "tgt_ix": "177-ARR_v1_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_90",
            "tgt_ix": "177-ARR_v1_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_91",
            "tgt_ix": "177-ARR_v1_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_92",
            "tgt_ix": "177-ARR_v1_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_93",
            "tgt_ix": "177-ARR_v1_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_94",
            "tgt_ix": "177-ARR_v1_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_95",
            "tgt_ix": "177-ARR_v1_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_96",
            "tgt_ix": "177-ARR_v1_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_97",
            "tgt_ix": "177-ARR_v1_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_98",
            "tgt_ix": "177-ARR_v1_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_99",
            "tgt_ix": "177-ARR_v1_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_100",
            "tgt_ix": "177-ARR_v1_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_101",
            "tgt_ix": "177-ARR_v1_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_102",
            "tgt_ix": "177-ARR_v1_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_103",
            "tgt_ix": "177-ARR_v1_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_104",
            "tgt_ix": "177-ARR_v1_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_105",
            "tgt_ix": "177-ARR_v1_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_106",
            "tgt_ix": "177-ARR_v1_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_107",
            "tgt_ix": "177-ARR_v1_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_108",
            "tgt_ix": "177-ARR_v1_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_109",
            "tgt_ix": "177-ARR_v1_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_110",
            "tgt_ix": "177-ARR_v1_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_111",
            "tgt_ix": "177-ARR_v1_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_112",
            "tgt_ix": "177-ARR_v1_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_113",
            "tgt_ix": "177-ARR_v1_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_114",
            "tgt_ix": "177-ARR_v1_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_115",
            "tgt_ix": "177-ARR_v1_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_116",
            "tgt_ix": "177-ARR_v1_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_117",
            "tgt_ix": "177-ARR_v1_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_118",
            "tgt_ix": "177-ARR_v1_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_119",
            "tgt_ix": "177-ARR_v1_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_120",
            "tgt_ix": "177-ARR_v1_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_121",
            "tgt_ix": "177-ARR_v1_121@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_122",
            "tgt_ix": "177-ARR_v1_122@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_123",
            "tgt_ix": "177-ARR_v1_123@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "177-ARR_v1_124",
            "tgt_ix": "177-ARR_v1_124@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 1331,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "position_tag_type": "from_draft",
        "doc_id": "177-ARR",
        "version": 1
    }
}