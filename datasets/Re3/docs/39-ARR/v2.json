{
    "nodes": [
        {
            "ix": "39-ARR_v2_0",
            "content": "Cross-Lingual Event Detection via Optimized Adversarial Training",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_2",
            "content": "In this work, we focus on Cross-Lingual Event Detection where a model is trained on data from a source language but its performance is evaluated on data from a second, target, language. Most recent works in this area have harnessed the language-invariant qualities displayed by pre-trained Multi-lingual Language Models. Their performance, however, reveals there is room for improvement as the crosslingual setting entails particular challenges. We employ Adversarial Language Adaptation to train a Language Discriminator to discern between the source and target languages using unlabeled data. The discriminator is trained in an adversarial manner so that the encoder learns to produce refined, language-invariant representations that lead to improved performance. More importantly, we optimize the adversarial training process by only presenting the discriminator with the most informative samples. We base our intuition about what makes a sample informative on two disparate metrics: sample similarity and event presence. Thus, we propose leveraging Optimal Transport as a solution to naturally combine these two distinct information sources into the selection process. Extensive experiments on 8 different language pairs, using 4 languages from unrelated families, show the flexibility and effectiveness of our model that achieves state-of-the-art results.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "39-ARR_v2_4",
            "content": "Event Detection (ED) is an important sub-task within the broader Information Extraction (IE) task. Event detection consists of being able to identify the words, commonly referred to as triggers, that denote the occurrence of events in a sentence, and classify them into a discrete set of event types. For example, in the sentence \"Jamie bought a car yesterday.\", bought is considered the trigger of a TRANSACTION:TRANSFER-OWNERSHIP 1 1 Event type taken from the ACE05 dataset. event type. It is a very well studied task in which there have been lots of previous research efforts that have recently been primarily deep learningbased (Nguyen and Grishman, 2015;Chen et al., 2015;Nguyen et al., 2016a,b;Sha et al., 2018;Wadden et al., 2019;Zhang et al., 2019a;Yang et al., 2019;Nguyen and Nguyen, 2019;Zhang et al., 2020;Liu et al., 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_5",
            "content": "Nonetheless, ED remains quite a challenging task as the context in which a trigger occurs can change its corresponding type completely. Furthermore, the same event might also be expressed by entirely different words/phrases. Additionally, the vast majority of the aforementioned efforts are limited to a monolingual setting -performing ED on text belonging to a single language.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_6",
            "content": "Alternatively, Cross-Lingual ED (CLED) proposes the scenario of creating models that effectively perform ED on data belonging to more than one language, which brings about additional challenges. For instance, trigger words present in one language might not exist in another one. An frequent example of this phenomenon are verb conjugations where some tenses only exist in some languages. Accurate verb handling is of particular importance for the ED task as event triggers are usually related to the verbs in a sentence. Some recent work (Majewska et al., 2021) has attempted to address this issue by injecting external verb knowledge into the training process. Another similar problematic issue for CLED are triggers with different meanings that are each distinct words in different languages. For instance, the word \"juicio\" in Spanish can either mean \"judgement\" or \"trial\" in English, depending on the context.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_7",
            "content": "A compelling approach to creating a crosslingual model is to use transfer learning which carries the performance of a model trained on a source language over onto a second target language. The general idea is leveraging the existing high-quality annotated data available for a high-resource language to train a model in a way that allows it to learn the language-invariant characteristics of the task at hand, ED in this case, so that it also performs effectively on text from a second language. Prior works on transfer learning for CLED have relied on pre-trained Multilingual Language Models (MLMs), such as multilingual BERT (mBERT) (Devlin et al., 2019), to take advantage of their innate language-invariant qualities. Yet, their performance still shows room for improvement as they sometimes struggle to handle the difficult instances, unique to cross-lingual settings, mentioned earlier. We identify a significant shortcoming of previous CLED efforts in that they do not exploit the abundant supply of unlabeled data: even though MLMs are trained on immense amounts of it, unlabeled data is not used when fine-tuning for the ED task. It is our intuition that by integrating unlabeled target-language data into the training process, the model is exposed to more language context which should help deal with issues such as verb variation and multiple connotations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_8",
            "content": "As such, we propose making use of Adversarial Language Adaptation (ALA) (Joty et al., 2017;Chen et al., 2018) to train a CLED model. The key idea is to generate language-invariant representations that are not indicative of language but remain informative for the ED task. Unlabeled data from both the source and target languages is used to train a Language Discriminator (LD) network that learns to discern between the two. The adversarial part comes from the fact that the encoder and discriminator are trained with opposing objectives: as the LD becomes better at distinguishing between languages, the encoder learns to generate more language-invariant representations in an attempt to fool the LD. To the best of our knowledge, our work is the first one proposing the use of ALA for the CLED task.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_9",
            "content": "Nonetheless, contrary to past uses of ALA where the same importance is given to all unlabeled samples, we recognize that such course of action is suboptimal as certain samples are bound to be more informative for the discriminator than others. For example, we would like to present the LD with the samples that allow it to learn the fine-grained distinctions between the source and target languages, instead of relying on syntactic differences. Moreover, in the context of ED, we suggest it would be beneficial for the LD to be trained with examples containing events, instead of non-event samples, as the presence of an event can then be incorporated into the generated representations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_10",
            "content": "Hence, we propose refining the adversarial training process by only keeping the most informative examples while disregarding less useful ones. Our intuition as to what makes samples more informative for CLED is two-fold: First, we presume that presenting the LD with examples that are too different makes the discrimination task too simple. As mentioned previously, we would like the LD to learn a fine-grained distinction between the source and target languages which, in turn, improves the language-invariance of the encoder's representations. Thus, we suggest presenting the LD with examples that have similar contextual semantics, i.e., similar contextualized representations. Second, we consider that sentences containing events should provide an ED system with additional task-relevant information when compared against non-event samples. Accordingly, we argue that event-containing sentences should have a larger probability of being selected for ALA training.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_11",
            "content": "With these intuitions in mind, we propose Optimal Transport (OT) (Villani, 2008) as a natural solution to simultaneously incorporate both the similarity between sample representations and the likelihood of the samples containing an event into a single framework. Therefore, we cast sample selection as an OT problem in which we attempt to find the best alignment between the samples from the source and target languages.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_12",
            "content": "For our experiments, we focus on the widely used ACE05 (Walker et al., 2006) and ERE (Song et al., 2015) datasets which, in conjuction, contain event-annotations in 4 different languages: English, Spanish, Chinese, and Arabic. We work on 8 different language pairs by selecting different languages as the source and target. Our proposed model obtains new state-of-the-art results with considerable performance improvements (+ 2-3% in F1 scores) over competitive baselines and previously published results (M'hamdi et al., 2019). We believe these results demonstrate our model's efficacy and applicability at creating CLED systems.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_13",
            "content": "The rest of this paper is organized as follows: section 2 provides an thorough description of our proposed model, section 3 presents and analyses the results from our experiments, section 4 provides a brief review of related work, and section 5 includes our conclusions.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_14",
            "content": "Model",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "39-ARR_v2_15",
            "content": "Problem Definition",
            "ntype": "title",
            "meta": {
                "section": "2.1"
            }
        },
        {
            "ix": "39-ARR_v2_16",
            "content": "Following prior works (M'hamdi et al., 2019;Majewska et al., 2021), we treat ED as a sequence labeling problem. Given a set D of word sequences w i = {w i1 , w i2 , ..., w in\u22121 , w in } and their corresponding label sequences y i = {y i1 , y i2 , ..., y in\u22121 , y in }, we use an encoder network E to obtain a contextualized vector representation of the words in the input sequence",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_17",
            "content": "h i = E(w i ) = {h i1 , h i2 , ..., h in\u22121 , h in }.",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_18",
            "content": "Using such representations as input, a prediction network P computes a distribution over the set of possible labels and is trained in a supervised manner using the negative log-likelihood function L P :",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_19",
            "content": "L P = \u2212 |D| i=1 n j=1 logP (y ij |h ij )(1)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_20",
            "content": "In the cross-lingual transfer-learning setting, the data used to train the model and the data on which the model is tested come from different languages known as the source and target, respectively. As such, we deal with two datasets D src and D tgt . We assume that we do not have access to the gold labels of the target language y tgt , other than to evaluate our CLED model at testing time.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_21",
            "content": "Our goal is to define a model able to generate language-invariant word representations that are refined enough so that cross-lingual issues, such as the ones described in section 1, are properly handled.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_22",
            "content": "Baseline Model",
            "ntype": "title",
            "meta": {
                "section": "2.2"
            }
        },
        {
            "ix": "39-ARR_v2_23",
            "content": "Here, we briefly describe the BERT-CRF model proposed by M'hamdi et al. ( 2019) which was the previous state-of-the-art and serves as our main baseline. Using multilingual BERT (mBERT, (Devlin et al., 2019)) as its encoder, BERT-CRF generates robust, contextualized representations for words from different languages. For words that are split into multiple word-pieces, the average of the representation vectors for all comprising sub-pieces is used as the representation of the full word.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_24",
            "content": "For classification purposes, instead of assigning the labels of each token independently, BERT-CRF uses a Conditional Random Field (CRF) (Lafferty et al., 2001) layer on top of the prediction network to better capture the interactions between the label sequences. In summary, the contextualized representation vectors h i generated by the mBERT encoder from the words in the sequence are then fed to a CRF layer which finds the optimal label sequence.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_25",
            "content": "Adversarial Language Adaptation",
            "ntype": "title",
            "meta": {
                "section": "2.3"
            }
        },
        {
            "ix": "39-ARR_v2_26",
            "content": "The pre-trained versions of MLMs like mBERT or XLM-RoBERTa (Conneau et al., 2019) generate contextualized representations with a certain degree of language-invariance. This can be confirmed by their successful application in cross-lingual settings (M'hamdi et al., 2019;Majewska et al., 2021). However, a lingering issue is the difficulty of learning the nuances of the target language such as verb variations that do not exist in the source language used to train them. Majewska et al. (2021), for instance, propose to address this issue by injecting external verb knowledge into the encoder via taskspecific adapter modules (Pfeiffer et al., 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_27",
            "content": "It is our intuition, however, that these issues can be mitigated by achieving a more refined level of language-invariance in the word representations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_28",
            "content": "As such, we propose using Adversarial Language Adaptation (ALA) (Joty et al., 2017), a technique used to create language-invariant models. The ALA framework consists in including a Language Discriminator (LD) whose purpose is to learn language-dependent features and be able to differentiate between the samples from either the source or the target languages.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_29",
            "content": "A fundamental characteristic of the ALA approach is its lack of requirements for annotated data in the target language. As such, we can use data from both D src and D tgt . An auxiliary dataset D aux = {(w 1 , l 1 ), . . . , (w 2m , l 2m )} is created where w i is a text sequence from either D src or D tgt , and l i is a language label. The cardinality of D aux is |D aux | = 2m, where m is equal to the batch size. Text samples w 1 . . . w m \u2208 D src , and samples w m+1 . . . w 2m \u2208 D tgt . As described earlier, the encoder E receives the text sequences and produces a sequence of contextualized representations E(w i ) = h i = {h i0 , h i1 , h i2 , . . . , h in } where h i0 is the representation of the [CLS] token added at the beginning of every input sequence.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_30",
            "content": "In our work, the LD is a a simple Multi-Layer Perceptron(MLP) network that takes h i0 as input and produces a single sigmoid output. It's trained with the usual binary cross-entropy loss function objective: LD loss = arg min LD L(LD(h i0 ), l i ).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_31",
            "content": "As the LD learns to distinguish between the source and target languages, we concurrently train the encoder to \"fool\" the discriminator. In other words, the encoder must learn to generate representations that are language-invariant enough that the LD is unable to classify them while still remaining predictive for event-trigger classification. We optimize the following loss:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_32",
            "content": "arg min E,C n j=1 (L(C(h ij ), y ij )) \u2212 \u03bbL(LD(h i0 , l i )) (2)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_33",
            "content": "Where C refers to the CRF-based classifier network and \u03bb is a hyperparameter.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_34",
            "content": "Equation 2 is implemented by using a Gradient-Reversal Layer (GRL) (Ganin and Lempitsky, 2015) which acts as the identity during the forward pass, but reverses the direction of the gradients during the backward pass. The first term in Equation 2can, of course, only be applied for annotated data from the source language.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_35",
            "content": "The GRL is applied to the input vectors, h i0 , of the LD. This way, the LD is being trained to differentiate between the two languages while the encoder is trained in the opposite direction, i.e. to generate sequence representations that are harder to discriminate.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_36",
            "content": "Adversarial Training Optimization",
            "ntype": "title",
            "meta": {
                "section": "2.4"
            }
        },
        {
            "ix": "39-ARR_v2_37",
            "content": "ALA has already been shown to be effective at generating language-invariant models (Joty et al., 2017;Chen et al., 2018). However, in regular ALA training, all samples in a batch, from both the source and target domains, are treated equally. That is, all samples are used as examples for the discriminator to learn how to better discern between the two domains. We propose that ALA effectiveness can be further improved by carefully selecting the samples with which to train the discriminator. We argue that some samples might be more informative than others and that, by only using such informative samples during training, better adaptation results can be achieved.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_38",
            "content": "We base our notion as to what makes a sample more informative on two factors. First, we argue that presenting the LD with examples from the source and target language that are too dissimilar makes its task easier which, in turn, leads to the LD not learning the fine-grained distinctions between the languages. Instead, we propose using samples whose vector representations h i0 are close to each other in the embedding space. The intuition for this being that, as representations capture the contextual semantics of the samples, closer representations correspond to more similar examples. Second, we suggest that presenting the LD with samples containing events should make the encoder incorporate task-specific information into its representations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_39",
            "content": "Optimal Transport",
            "ntype": "title",
            "meta": {
                "section": "2.4.1"
            }
        },
        {
            "ix": "39-ARR_v2_40",
            "content": "One challenge of using the two mentioned criteria for the ALA sample selection process is that they come with two different measures which are hard to combine. To address this, we propose using Optimal Transport (OT) (Villani, 2008) as a natural way to combine these two metrics into a single framework for sample selection. Optimal transport is, in broad terms, the problem of finding out the cheapest transformation between two discrete probability distributions. It requires a cost function to determine the cost of transforming a data point in one distribution into a data point in the second distribution. When the cost function is based on a valid distance function, the minimum cost is known as the Wasserstein distance. Formally, it solves the following optimization problem:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_41",
            "content": "\u03c0 * (s, t) = min \u03c0\u2208 (s,t) s\u2208S t\u2208T \u03c0(s, t) C(s, t) ds dt (3) s.t. s \u223c p(s) and t \u223c q(t)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_42",
            "content": "where S and T are the two domains to be transformed; p(s) and q(t) are the probability distributions of S and T , respectively; C is a cost function for mapping S to T , C(s, t) : S \u00d7 T \u2212\u2192 R + ; and finally, \u03c0 * (s, t) is the optimal joint distribution over the set of all joint distributions (s, t). The problem described by Equation 3 is, of course, intractable. Therefore, we use instead the Sinkhorn algorithm (Cuturi, 2013) which is an entropy-based relaxation of the discrete OT problem.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_43",
            "content": "Problem Formulation",
            "ntype": "title",
            "meta": {
                "section": "2.4.2"
            }
        },
        {
            "ix": "39-ARR_v2_44",
            "content": "We formulate the OT problem as follows: the domains S and T are defined as the representation vectors of the text samples in either the source h s i0 or the target h t j0 languages. We use the L2 distance between these representations as the cost function:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_45",
            "content": "C(h s i0 , h t j0 ) = ||h s i0 \u2212 h t j0 || 2",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_46",
            "content": "To define the marginal probability distributions p(s) and q(t) for the S and T domains, we propose including an Event-Presence (EP) prediction module and use its normalized likelihood scores as the probability distributions for S and T . Thus, the auxiliary dataset D aux is augmented to include an event-presence label e i for each sample. Of course, this can only be done for samples in the source language as the labels for the target-language data are unavailable:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_47",
            "content": "D aux = {(w 1 , l 1 , e 1 ), . . . , (w m , l m , e m ), (w m+1 , l m+1 ), . . . , (w 2m , l 2m )}",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_48",
            "content": "The EP module is then trained to optimize the following loss:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_49",
            "content": "EP loss = arg min EP L(EP (h i0 ), e i )(5)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_50",
            "content": "where i <= m, i.e., only using samples from the source language. The probability distributions p(s) and p(t) are the computed as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_51",
            "content": "p(s) = Sof tmax(EP (h s i0 ) | l i == s)(6)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_52",
            "content": "p(t) = Sof tmax(EP (h t i0 ) | l i == t)(7)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_53",
            "content": "Sample Selection",
            "ntype": "title",
            "meta": {
                "section": "2.4.3"
            }
        },
        {
            "ix": "39-ARR_v2_54",
            "content": "We use the OT solution matrix \u03c0 * , where an entry \u03c0 * (s, t) represents the optimal cost of transforming data point s \u2208 S into t \u2208 T , to compute an the overall similarity score v i of a sample h i0 \u2208 S to the samples in the target domain T by using the average distance:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_55",
            "content": "v i = m j \u03c0 * (h s i0 , h t j0 ) m(8)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_56",
            "content": "Correspondingly, we compute an overall similarity score v j of each sample h j0 \u2208 T to the samples in the source domain S:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_57",
            "content": "v j = m i \u03c0 * (h s i0 , h t j0 ) m (9)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_58",
            "content": "Lastly, we select a fraction, hyperparameter \u03b3, of samples with the best similarity scores from both the source and target languages, and only use these selected samples during ALA training.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_59",
            "content": "OACLED Model",
            "ntype": "title",
            "meta": {
                "section": "2.5"
            }
        },
        {
            "ix": "39-ARR_v2_60",
            "content": "We train our Optimized Adversarial Cross-Lingual Event Detection (OACLED) model end-to-end with the following loss objective: L f ull = CRF loss + \u03b1LD loss + \u03b2EP loss (10) where \u03b1 and \u03b2 are trade-off hyperparameters.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_61",
            "content": "Experiments",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "39-ARR_v2_62",
            "content": "Datasets",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "39-ARR_v2_63",
            "content": "We evaluate our model on the ACE05 (Walker et al., 2006) dataset which includes annotated eventtrigger data in 3 languages: English, Chinese and Arabic. To include an additional language in our experiments, we also evaluate on the ERE dataset which has annotated data in English and Spanish. Note that the ACE05 and ERE datasets do not share the same label set: ACE05 involves 33 distinct event types while ERE involves 38 event types. We follow the same data pre-processing and splits as in previous work (M'hamdi et al., 2019)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_64",
            "content": "Hyper-parameters",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "39-ARR_v2_65",
            "content": "We fine-tune the hyper-parameters for our OA-CLED model using the development data. We apply the following values based on the fine-tuning process:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_66",
            "content": "\u2022 AdamW as the optimizer. \u2022 5 warm up epochs. \u2022 A learning rate of 1e \u22125 for the transformer parameters and of 1e \u22124 for the rest of the parameters. \u2022 A batch size of 16. \u2022 300 for the dimensionality of the layers in feed-forwards networks. \u2022 A \u03b3 = 0.5 for the percentage of samples used in adversarial training. \u2022 A \u03bb = 0.001 as the scaling factor of the GRL layer. \u2022 An \u03b1 = 1 and \u03b2 = 0.001 as the trade-off parameters of the LD loss and ED loss, respectively. \u2022 A dropout of 10% for added regularization during training.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_67",
            "content": "Main Results",
            "ntype": "title",
            "meta": {
                "section": "3.3"
            }
        },
        {
            "ix": "39-ARR_v2_68",
            "content": "In our experiments, we work with 8 distinct language pairs by selecting each of the available languages as either the source or target language: English-Chinese, Chinese-English, English-Arabic, Arabic-English, Chinese-Arabic, Arabic-Chinese, English-Spanish, and Spanish-English.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_69",
            "content": "The Chinese-Spanish, Spanish-Chinese, Arabic-Spanish, and Spanish-Arabic language combinations are unavailable due the previously mentioned incompatibility between the event type sets in ACE05 and ERE.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_70",
            "content": "We compare our OACLED model against 3 relevant baselines. First, the previous state-of-the-art CLED model BERT-CRF (M'hamdi et al., 2019) as described in section 2.2. Second, the mBERT-2TA model (Majewska et al., 2021) which aims at improving cross-lingual performance by incorporating language-independent verb knowledge via task-specific adapters. And third, XLM-R-CRF which is equivalent in all regards to BERT-CRF except that it uses XLM-RoBERTa (Conneau et al., 2019) as the encoder.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_71",
            "content": "Table 2 and Table 3 show the results of our experiments on the ACE05 and ERE datasets, respectively. In all our experiments, we use the base transformer versions bert-base-cased and xlm-robertabase as the encoders, parameters are tuned on the development data of the source language, and all entries are the average of five runs.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_72",
            "content": "From Tables 2 and 3, it should be noted that there is a substantial performance increase by performing the trivial change of replacing mBERT with XLM-RoBERTa as the encoder. Furthermore, our OACLED model clearly and consistently outperforms the baselines for all language pairings, with the exception of the Chinese-Arabic pair. We attribute this to the impaired performance of XLM-RoBERTa as the encoder for that specific pair as can be confirmed by the poor performance of the XLM-R-CRF baseline on the same configuration. Most importantly, OACLED's improvement over the XLM-R-CRF baseline is present in every configuration, which validates the effectiveness of our optimized approach to ALA training.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_73",
            "content": "Ablation Study",
            "ntype": "title",
            "meta": {
                "section": "3.4"
            }
        },
        {
            "ix": "39-ARR_v2_74",
            "content": "We identify 2 main components in our approach: using ALA to create refined language-invariant representations, and optimizing the adversarial training process by selecting a subset of samples chosen with OT to incorporate our measures of informativeness into the sample selection process. Of course, removing ALA training entirely restores the model to the baseline. However, adversarial training optimization via OT has various aspects to it. In order to understand the contribution of these aspects, we explore four different models: OACLED-OT presents the effects of removing sample selection entirely and using all available samples to train the LD; OACLED-L2 uses a constant distance between the unlabeled samples instead the standard L2 distance used in the Sinkhorn algorithm; OACLED-EP completely removes the EP module and a uniform distribution is used as the probability distributions for both languages; finally, OACLED-ED-Loss keeps the EP module, but removes its EP loss term from Equation 10. The performance results of these models is presented in Table 4. In this and the following sections (3.5, 3.6.2), we present the results of experiments using English as the sole source language as it is the source language most ubiquitously used. We, however, found consistency in the displayed effects for different source/target language configurations. As expected, removing the sample selection through OT leads to the worst performance drop. This highlights the importance of selecting informative examples for the LD. Furthermore, removing the cost function also hurts performance greatly, which shows that a proper distance function is needed for the OT algorithm to work effectively. While the effects of removing the EP module and its corresponding loss term are not of the same magnitude, they are still significant. These results support our claim for the need and utility of all the components in our approach, showing that their inclusion is crucial in achieving state-of-the-art performance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_75",
            "content": "Language Model Finetuning",
            "ntype": "title",
            "meta": {
                "section": "3.5"
            }
        },
        {
            "ix": "39-ARR_v2_76",
            "content": "The key contribution of our approach is to exploit unlabeled data in the target language, which is usually abundant, by introducing it into the training process to improve our model's language-invariant qualities.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_77",
            "content": "To confirm the utility of our approach, Table 5 contrasts our model's performance against a baseline whose encoder has been finetuned with the same unlabeled data using the standard masked language model objective. It can be observed that our model outperforms the finetuned baseline in two out of the three target languages. Additionally, the difference in performance in those two instances is considerably larger (3.58% and 1.15%), than the setting in which the baseline performs better (0.13%).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_78",
            "content": "Analysis",
            "ntype": "title",
            "meta": {
                "section": "3.6"
            }
        },
        {
            "ix": "39-ARR_v2_79",
            "content": "Learned Representation Distances",
            "ntype": "title",
            "meta": {
                "section": "3.6.1"
            }
        },
        {
            "ix": "39-ARR_v2_80",
            "content": "First, we look at the distance between the sentencelevel representations h i0 generated by the encoder for different source/target language pairs. Figure 1 shows a plot of such distances using cosine distance as the distance function. When computing the correlation with the performance results in Table 2, we obtain a score R = \u22120.6616, meaning there is moderate negative correlation between the distance of the representations and model performance, i.e. closer representations lead to better performance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_81",
            "content": "Similarly, Table 6 shows a comparison of the distances between the representations generated by OACLED and those obtained by the XLM-R-CRF baseline.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_82",
            "content": "Baseline OACLED English/Chinese 3.64e-3 3.93e-6 English/Arabic 7.71e-2 2.08e-5 English/Spanish 5.4e-3 5.3e-6 Chinese/English 3.62e-3 3.87e-6 Arabic/English 4.16e-2 1.02e-5 Spanish/English 6.87e-3 1.49e-5",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_83",
            "content": "Table 6: Comparison of representation-vector distances for language pairs between our model and the baseline.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_84",
            "content": "We observe that OACLED representations are closer, by several orders of magnitude, than those obtained by the baseline. This supports our claim that our model's encoder generates more refined language-invariant representations than those obtained by the default version of XLM-RoBERTa.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_85",
            "content": "Access to Labeled Target Data",
            "ntype": "title",
            "meta": {
                "section": "3.6.2"
            }
        },
        {
            "ix": "39-ARR_v2_86",
            "content": "Previously, we discussed how a key feature of our approach is that it does not require annotated data in the target language and, instead, leverages the use of unlabeled data which is readily available. Nonetheless, we also explore the performance of our model in the event that there exists a small amount of annotated target data available. Figure 2 shows the results of our experiments when using different amounts of labeled target data during training. It can be observed that OACLED consistently outperforms the baseline even when there is some availability of annotated data. Additionally, performance steadily increases as more and more data is used. This conforms to expectations, and confirms that having labeled data in the target language available for training is ultimately beneficial to the model's performance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_87",
            "content": "Case Study",
            "ntype": "title",
            "meta": {
                "section": "3.6.3"
            }
        },
        {
            "ix": "39-ARR_v2_88",
            "content": "Next, we look into our model's predictions and analyse instances where it outperforms the baseline to exemplify the advantages of dealing with optimized language-invariant representations. We identify two important patterns.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_89",
            "content": "First, our model seems to better classify events in the target language that involve trigger words that have distinct connotations that depend on context. Specially those that are two distinct words in the source language. For example, the Spanish word \"juicio\" can have two distinct meanings that are different words in English: \"trial\" and \"judgement\". Our model correctly classifies it as a JUSTICE:TRIAL-HEARING trigger in the sentence \"Dos llamados a juicio fueron hechos por un jurado federal investigador\". Meanwhile, the baseline fails to even recognize it as a trigger. Another example is the word \"detenido\", an adjective that can mean both \"detained\", in a criminal context, and \"stopped\", as in halted. Our model correctly classifies it in the sentence \"Padilla no deber\u00eda permanecer detenido durante meses alejado de otros reos\" as a JUSTICE:ARREST-JAIL trigger while the baseline fails to detect the event. We manually identified 23 of these polysemous triggers in the Spanish 2 test set and found that 19 (82.6%) were correctly classified by our OACLED model versus 14 (60.8%) by the baseline (27.8% improvement).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_90",
            "content": "Additionally, we found our model correctly classifies verb conjugation variants that do not exist in the source language. For instance, our model correctly recognizes the words \"venderlos\", \"vender\", \"vendes\", and \"vendedor\" (variants of the verb \"to buy\") as TRANSACTION:TRANSFER-OWNERSHIP triggers whereas the baseline incorrectly classifies them as being of the TRANSACTION:TRANSFER-MONEY type. As previously mentioned, Majewska et al. (2021) propose injecting external verb-knowledge into the training to help with verb interpretation for event extraction. Our empirical results, however, outperform their reports which appears to imply that, at least for CLED, holistically learning the language-invariant features shared between the target and source languages works better than injecting language-specific verb knowledge.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_91",
            "content": "We believe these findings illustrate how, by introducing additional context in the form of unlabeled data, the model is able to learn fine-grained word representations that better capture the semantics of the words in the target language, and successfully deal with difficult cross-lingual issues.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_92",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "39-ARR_v2_93",
            "content": "Research efforts on monolingual ED are extensive and varied. Hand-crafted, feature-based, languagespecific methods were the basis of early ED approaches (Ahn, 2006;Ji and Grishman, 2008;Patwardhan and Riloff, 2009;Liao and Grishman, 2010a,b;Hong et al., 2011;McClosky et al., 2011;Li et al., 2013;Miwa et al., 2014;Yang and Mitchell, 2016). More recent efforts have primarily made use of deep learning techniques such as convolutional neural networks (Nguyen and Grishman, 2015;Chen et al., 2015;Nguyen et al., 2016b), recurrent neural networks (Nguyen et al., 2016a;Sha et al., 2018;Lai et al., 2020), graph convolutional networks (Nguyen and Grishman, 2018;Yan et al., 2019;Nguyen et al., 2021a), adversarial networks (Hong et al., 2018;Zhang et al., 2019b), and pre-trained language models (Wadden et al., 2019;Zhang et al., 2019a;Yang et al., 2019;Zhang et al., 2020;Liu et al., 2020;Pouran Ben Veyseh et al., 2021b,a).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_94",
            "content": "Works on cross-lingual ED are not as prevalent and generally make use of cross-lingual resources employed to address the differences between languages such as bilingual dictionaries or parallel corpora (Muis et al., 2018;Liu et al., 2019) and, more recently, pre-trained multilingual language models (M'hamdi et al., 2019;Hambardzumyan et al., 2020;Majewska et al., 2021). Unlike these previous efforts, our method leverages unlabeled data to further refine the language-invariant qualities of the language models. Adversarial Language Adaptation, inspired by models in domain adaptation research (Ganin and Lempitsky, 2015;Naik and Rose, 2020;Ngo Trung et al., 2021), has been successfuly applied at generating language-invariant models (Joty et al., 2017;Chen et al., 2018;Nguyen et al., 2021b). Our method improves upon these approaches optimizing the adversarial training process by selecting the most informative examples from the unlabeled data.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_95",
            "content": "Additional examples of downstream applications of cross-lingual learning are document classification (Holger and Xian, 2018), named entity recognition (Xie et al., 2018) and part-of-speech tagging (Cohen et al., 2011). For a thorough review on cross-lingual learning, we refer the reader to Pikuliak et al. (2021).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_96",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "39-ARR_v2_97",
            "content": "We present OACLED, a new model for crosslingual event detection that learns fine-grained language-invariant representations by optimizing the standard ALA training through optimaltransport-based sample selection. Our model achieves new state-of-the-art performance in our experiments on 8 different language pairs which demonstrate its robustness and effectiveness at generating refined language-invariant representations that allow for better event detection results. Our analysis of its intermediate outputs and predictions confirm that OACLED's representations are indeed closer to each other and that this proximity translates into better handling of difficult cross-lingual instances. We also note that, while this work focuses on the event detection task, our proposed optimization of the adversarial training process is task independent and can be generalized to other related IE tasks when leveraging ALA is deemed beneficial.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "39-ARR_v2_98",
            "content": "David Ahn, The stages of event extraction, 2006, Proceedings of the Workshop on Annotating and Reasoning about Time and Events, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "David Ahn"
                ],
                "title": "The stages of event extraction",
                "pub_date": "2006",
                "pub_title": "Proceedings of the Workshop on Annotating and Reasoning about Time and Events",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_99",
            "content": "Xilun Chen, Yu Sun, Ben Athiwaratkun, Claire Cardie, Kilian Weinberger, Adversarial Deep Averaging Networks for Cross-Lingual Sentiment Classification, 2018, Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Xilun Chen",
                    "Yu Sun",
                    "Ben Athiwaratkun",
                    "Claire Cardie",
                    "Kilian Weinberger"
                ],
                "title": "Adversarial Deep Averaging Networks for Cross-Lingual Sentiment Classification",
                "pub_date": "2018",
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_100",
            "content": "Yubo Chen, Liheng Xu, Kang Liu, Daojian Zeng, Jun Zhao, Event extraction via dynamic multipooling convolutional neural networks, 2015, Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "Yubo Chen",
                    "Liheng Xu",
                    "Kang Liu",
                    "Daojian Zeng",
                    "Jun Zhao"
                ],
                "title": "Event extraction via dynamic multipooling convolutional neural networks",
                "pub_date": "2015",
                "pub_title": "Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_101",
            "content": "B Shay, Dipanjan Cohen, Noah Das,  Smith, Unsupervised structure prediction with nonparallel multilingual guidance, 2011, Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP.",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "B Shay",
                    "Dipanjan Cohen",
                    "Noah Das",
                    " Smith"
                ],
                "title": "Unsupervised structure prediction with nonparallel multilingual guidance",
                "pub_date": "2011",
                "pub_title": "Proceedings of the Conference on Empirical Methods in Natural Language Processing",
                "pub": "EMNLP"
            }
        },
        {
            "ix": "39-ARR_v2_102",
            "content": "Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettlemoyer, Veselin Stoyanov, Unsupervised cross-lingual representation learning at scale, 2019, CoRR, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Alexis Conneau",
                    "Kartikay Khandelwal",
                    "Naman Goyal",
                    "Vishrav Chaudhary",
                    "Guillaume Wenzek",
                    "Francisco Guzm\u00e1n",
                    "Edouard Grave",
                    "Myle Ott",
                    "Luke Zettlemoyer",
                    "Veselin Stoyanov"
                ],
                "title": "Unsupervised cross-lingual representation learning at scale",
                "pub_date": "2019",
                "pub_title": "CoRR",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_103",
            "content": "Marco Cuturi, Sinkhorn distances: Lightspeed computation of optimal transport, 2013, Proceedings of the 26th International Conference on Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "Marco Cuturi"
                ],
                "title": "Sinkhorn distances: Lightspeed computation of optimal transport",
                "pub_date": "2013",
                "pub_title": "Proceedings of the 26th International Conference on Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_104",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, Bert: Pre-training of deep bidirectional transformers for language understanding, 2019, NAACL-HLT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "Jacob Devlin",
                    "Ming-Wei Chang",
                    "Kenton Lee",
                    "Kristina Toutanova"
                ],
                "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
                "pub_date": "2019",
                "pub_title": "NAACL-HLT",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_105",
            "content": "Yaroslav Ganin, Victor Lempitsky, Unsupervised domain adaptation by backpropagation, 2015, Proceedings of the 32nd International Conference on Machine Learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Yaroslav Ganin",
                    "Victor Lempitsky"
                ],
                "title": "Unsupervised domain adaptation by backpropagation",
                "pub_date": "2015",
                "pub_title": "Proceedings of the 32nd International Conference on Machine Learning",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_106",
            "content": "Karen Hambardzumyan, Hrant Khachatrian, Jonathan , The role of alignment of multilingual contextualized embeddings in zero-shot crosslingual transfer for event extraction, 2020-05, Collaborative Technologies and Data Science in Artificial Intelligence Applications, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Karen Hambardzumyan",
                    "Hrant Khachatrian",
                    "Jonathan "
                ],
                "title": "The role of alignment of multilingual contextualized embeddings in zero-shot crosslingual transfer for event extraction",
                "pub_date": "2020-05",
                "pub_title": "Collaborative Technologies and Data Science in Artificial Intelligence Applications",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_107",
            "content": "Schwenk Holger, Li Xian, A corpus for multiligual document classification in eight languages, 2018, Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC), .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Schwenk Holger",
                    "Li Xian"
                ],
                "title": "A corpus for multiligual document classification in eight languages",
                "pub_date": "2018",
                "pub_title": "Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC)",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_108",
            "content": "Yu Hong, Jianfeng Zhang, Bin Ma, Jianmin Yao, Guodong Zhou, Qiaoming Zhu, Using cross-entity inference to improve event extraction, 2011, Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Yu Hong",
                    "Jianfeng Zhang",
                    "Bin Ma",
                    "Jianmin Yao",
                    "Guodong Zhou",
                    "Qiaoming Zhu"
                ],
                "title": "Using cross-entity inference to improve event extraction",
                "pub_date": "2011",
                "pub_title": "Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_109",
            "content": "Yu Hong, Wenxuan Zhou, Jingli Zhang, Guodong Zhou, Qiaoming Zhu, Self-regulation: Employing a generative adversarial network to improve event detection, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Yu Hong",
                    "Wenxuan Zhou",
                    "Jingli Zhang",
                    "Guodong Zhou",
                    "Qiaoming Zhu"
                ],
                "title": "Self-regulation: Employing a generative adversarial network to improve event detection",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "39-ARR_v2_110",
            "content": "Heng Ji, Ralph Grishman, Refining event extraction through cross-document inference, 2008, Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Heng Ji",
                    "Ralph Grishman"
                ],
                "title": "Refining event extraction through cross-document inference",
                "pub_date": "2008",
                "pub_title": "Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_111",
            "content": "Shafiq Joty, Preslav Nakov, Llu\u00eds M\u00e0rquez, Israa Jaradat, Cross-language learning with adversarial neural networks, 2017, Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL), .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    "Shafiq Joty",
                    "Preslav Nakov",
                    "Llu\u00eds M\u00e0rquez",
                    "Israa Jaradat"
                ],
                "title": "Cross-language learning with adversarial neural networks",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL)",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_112",
            "content": "John Lafferty, Andrew Mccallum, Fernando Pereira, Conditional random fields: Probabilistic models for segmenting and labeling sequence data, 2001, Proceedings of the Eighteenth International Conference on Machine Learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "John Lafferty",
                    "Andrew Mccallum",
                    "Fernando Pereira"
                ],
                "title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data",
                "pub_date": "2001",
                "pub_title": "Proceedings of the Eighteenth International Conference on Machine Learning",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_113",
            "content": "Tuan Viet Dac Lai, Thien Huu Ngo Nguyen,  Nguyen, Event detection: Gate diversity and syntactic importance scores for graph convolution neural networks, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Tuan Viet Dac Lai",
                    "Thien Huu Ngo Nguyen",
                    " Nguyen"
                ],
                "title": "Event detection: Gate diversity and syntactic importance scores for graph convolution neural networks",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_114",
            "content": "Qi Li, Ji Heng, Liang Huang, Joint event extraction via structured prediction with global features, 2013, Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "Qi Li",
                    "Ji Heng",
                    "Liang Huang"
                ],
                "title": "Joint event extraction via structured prediction with global features",
                "pub_date": "2013",
                "pub_title": "Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_115",
            "content": "Shasha Liao, Ralph Grishman, Filtered ranking for bootstrapping in event extraction, 2010, Proceedings of the International Conference on Computational Linguistics (COLING), .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Shasha Liao",
                    "Ralph Grishman"
                ],
                "title": "Filtered ranking for bootstrapping in event extraction",
                "pub_date": "2010",
                "pub_title": "Proceedings of the International Conference on Computational Linguistics (COLING)",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_116",
            "content": "Shasha Liao, Ralph Grishman, Using document level cross-event inference to improve event extraction, 2010, Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Shasha Liao",
                    "Ralph Grishman"
                ],
                "title": "Using document level cross-event inference to improve event extraction",
                "pub_date": "2010",
                "pub_title": "Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_117",
            "content": "Jian Liu, Yubo Chen, Kang Liu, Wei Bi, Xiaojiang Liu, Event extraction as machine reading comprehension, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "Jian Liu",
                    "Yubo Chen",
                    "Kang Liu",
                    "Wei Bi",
                    "Xiaojiang Liu"
                ],
                "title": "Event extraction as machine reading comprehension",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_118",
            "content": "Jian Liu, Yubo Chen, Kang Liu, Neural cross-lingual event detection with minimal parallel resources, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Jian Liu",
                    "Yubo Chen",
                    "Kang Liu"
                ],
                "title": "Neural cross-lingual event detection with minimal parallel resources",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_119",
            "content": "UNKNOWN, None, , Edoardo Maria Ponti, and Anna Korhonen. 2021. Verb knowledge injection for multilingual, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Edoardo Maria Ponti, and Anna Korhonen. 2021. Verb knowledge injection for multilingual",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_120",
            "content": "Minh Trung, Thien Nguyen,  Huu Nguyen, One for all: Neural joint modeling of entities and events, 2019, Association for the Advancement of Artificial Inteligence (AAAI), .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Minh Trung",
                    "Thien Nguyen",
                    " Huu Nguyen"
                ],
                "title": "One for all: Neural joint modeling of entities and events",
                "pub_date": "2019",
                "pub_title": "Association for the Advancement of Artificial Inteligence (AAAI)",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_121",
            "content": "Siddharth Patwardhan, Ellen Riloff, A unified model of phrasal and sentential evidence for information extraction, 2009, Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Siddharth Patwardhan",
                    "Ellen Riloff"
                ],
                "title": "A unified model of phrasal and sentential evidence for information extraction",
                "pub_date": "2009",
                "pub_title": "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_122",
            "content": "Jonas Pfeiffer, Andreas R\u00fcckl\u00e9, Clifton Poth, Aishwarya Kamath, Ivan Vuli\u0107, Sebastian Ruder, Kyunghyun Cho, Iryna Gurevych, AdapterHub: A framework for adapting transformers, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Jonas Pfeiffer",
                    "Andreas R\u00fcckl\u00e9",
                    "Clifton Poth",
                    "Aishwarya Kamath",
                    "Ivan Vuli\u0107",
                    "Sebastian Ruder",
                    "Kyunghyun Cho",
                    "Iryna Gurevych"
                ],
                "title": "AdapterHub: A framework for adapting transformers",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "39-ARR_v2_123",
            "content": "Mat\u00fa\u0161 Pikuliak, Mari\u00e1n \u0160imko, M\u00e1ria Bielikov\u00e1, Cross-lingual learning for text processing: A survey, 2021, Expert Systems with Applications, .",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Mat\u00fa\u0161 Pikuliak",
                    "Mari\u00e1n \u0160imko",
                    "M\u00e1ria Bielikov\u00e1"
                ],
                "title": "Cross-lingual learning for text processing: A survey",
                "pub_date": "2021",
                "pub_title": "Expert Systems with Applications",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_124",
            "content": ", Unleash GPT-2 power for event detection, , Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": [],
                "title": "Unleash GPT-2 power for event detection",
                "pub_date": null,
                "pub_title": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_125",
            "content": "Ben Amir Pouran, Minh Veyseh, Nghia Van Nguyen, Bonan Ngo Trung, Thien Huu Min,  Nguyen, Modeling document-level context for event detection via important context selection, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": [
                    "Ben Amir Pouran",
                    "Minh Veyseh",
                    "Nghia Van Nguyen",
                    "Bonan Ngo Trung",
                    "Thien Huu Min",
                    " Nguyen"
                ],
                "title": "Modeling document-level context for event detection via important context selection",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_126",
            "content": "Lei Sha, Feng Qian, Baobao Chang, Zhifang Sui, Jointly extracting event triggers and arguments by dependency-bridge rnn and tensor-based argument interaction, 2018, Proceedings of the Association for the Advancement of Artificial Intelligence (AAAI), .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Lei Sha",
                    "Feng Qian",
                    "Baobao Chang",
                    "Zhifang Sui"
                ],
                "title": "Jointly extracting event triggers and arguments by dependency-bridge rnn and tensor-based argument interaction",
                "pub_date": "2018",
                "pub_title": "Proceedings of the Association for the Advancement of Artificial Intelligence (AAAI)",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_127",
            "content": "UNKNOWN, None, , , .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": null,
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_128",
            "content": "Neville Ryant, Xiaoyi Ma, From light to rich ERE: Annotation of entities, relations, and events, 2015, Proceedings of the The 3rd Workshop on EVENTS: Definition, Detection, Coreference, and Representation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": [
                    "Neville Ryant",
                    "Xiaoyi Ma"
                ],
                "title": "From light to rich ERE: Annotation of entities, relations, and events",
                "pub_date": "2015",
                "pub_title": "Proceedings of the The 3rd Workshop on EVENTS: Definition, Detection, Coreference, and Representation",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_129",
            "content": "UNKNOWN, None, 2008, Optimal Transport: Old and New. Grundlehren der mathematischen Wissenschaften, Springer.",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": null,
                "title": null,
                "pub_date": "2008",
                "pub_title": "Optimal Transport: Old and New. Grundlehren der mathematischen Wissenschaften",
                "pub": "Springer"
            }
        },
        {
            "ix": "39-ARR_v2_130",
            "content": "David Wadden, Ulme Wennberg, Yi Luan, Hannaneh Hajishirzi, Entity, relation, and event extraction with contextualized span representations, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP.",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": [
                    "David Wadden",
                    "Ulme Wennberg",
                    "Yi Luan",
                    "Hannaneh Hajishirzi"
                ],
                "title": "Entity, relation, and event extraction with contextualized span representations",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing",
                "pub": "EMNLP-IJCNLP"
            }
        },
        {
            "ix": "39-ARR_v2_131",
            "content": "Christopher Walker, Stephanie Strassel, Julie Medero, Kazuaki Maeda, Ace 2005 multilingual training corpus, 2006, Technical report, Linguistic Data Consortium, .",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": [
                    "Christopher Walker",
                    "Stephanie Strassel",
                    "Julie Medero",
                    "Kazuaki Maeda"
                ],
                "title": "Ace 2005 multilingual training corpus",
                "pub_date": "2006",
                "pub_title": "Technical report, Linguistic Data Consortium",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_132",
            "content": "Jiateng Xie, Zhilin Yang, Graham Neubig, Noah Smith, Jaime Carbonell, Neural crosslingual named entity recognition with minimal resources, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP.",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": [
                    "Jiateng Xie",
                    "Zhilin Yang",
                    "Graham Neubig",
                    "Noah Smith",
                    "Jaime Carbonell"
                ],
                "title": "Neural crosslingual named entity recognition with minimal resources",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "pub": "EMNLP"
            }
        },
        {
            "ix": "39-ARR_v2_133",
            "content": "Haoran Yan, Xiaolong Jin, Xiangbin Meng, Jiafeng Guo, Xueqi Cheng, Event detection with multiorder graph convolution and aggregated attention, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": [
                    "Haoran Yan",
                    "Xiaolong Jin",
                    "Xiangbin Meng",
                    "Jiafeng Guo",
                    "Xueqi Cheng"
                ],
                "title": "Event detection with multiorder graph convolution and aggregated attention",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_134",
            "content": "Bishan Yang, Tom Mitchell, Joint extraction of events and entities within a document context, 2016, Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), .",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "Bishan Yang",
                    "Tom Mitchell"
                ],
                "title": "Joint extraction of events and entities within a document context",
                "pub_date": "2016",
                "pub_title": "Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_135",
            "content": "Sen Yang, Dawei Feng, Linbo Qiao, Zhigang Kan, Dongsheng Li, Exploring pre-trained language models for event extraction and generation, 2019, Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), .",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": [
                    "Sen Yang",
                    "Dawei Feng",
                    "Linbo Qiao",
                    "Zhigang Kan",
                    "Dongsheng Li"
                ],
                "title": "Exploring pre-trained language models for event extraction and generation",
                "pub_date": "2019",
                "pub_title": "Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_136",
            "content": "UNKNOWN, None, 2019, Extracting entities and events as a single task using a transition-based neural model, .",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Extracting entities and events as a single task using a transition-based neural model",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_137",
            "content": "Tongtao Zhang, Ji Heng, Avirup Sil, Joint Entity and Event Extraction with Generative Adversarial Imitation Learning, 2019, Data Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": [
                    "Tongtao Zhang",
                    "Ji Heng",
                    "Avirup Sil"
                ],
                "title": "Joint Entity and Event Extraction with Generative Adversarial Imitation Learning",
                "pub_date": "2019",
                "pub_title": "Data Intelligence",
                "pub": null
            }
        },
        {
            "ix": "39-ARR_v2_138",
            "content": "Yunyan Zhang, Guangluan Xu, Yang Wang, Daoyu Lin, Feng Li, Chenglong Wu, Jingyuan Zhang, Tinglei Huang, A question answering-based framework for one-step event argument extraction, 2020, IEEE Access, .",
            "ntype": "ref",
            "meta": {
                "xid": "b40",
                "authors": [
                    "Yunyan Zhang",
                    "Guangluan Xu",
                    "Yang Wang",
                    "Daoyu Lin",
                    "Feng Li",
                    "Chenglong Wu",
                    "Jingyuan Zhang",
                    "Tinglei Huang"
                ],
                "title": "A question answering-based framework for one-step event argument extraction",
                "pub_date": "2020",
                "pub_title": "IEEE Access",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "39-ARR_v2_0@0",
            "content": "Cross-Lingual Event Detection via Optimized Adversarial Training",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_0",
            "start": 0,
            "end": 63,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_2@0",
            "content": "In this work, we focus on Cross-Lingual Event Detection where a model is trained on data from a source language but its performance is evaluated on data from a second, target, language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_2",
            "start": 0,
            "end": 184,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_2@1",
            "content": "Most recent works in this area have harnessed the language-invariant qualities displayed by pre-trained Multi-lingual Language Models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_2",
            "start": 186,
            "end": 319,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_2@2",
            "content": "Their performance, however, reveals there is room for improvement as the crosslingual setting entails particular challenges.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_2",
            "start": 321,
            "end": 444,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_2@3",
            "content": "We employ Adversarial Language Adaptation to train a Language Discriminator to discern between the source and target languages using unlabeled data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_2",
            "start": 446,
            "end": 593,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_2@4",
            "content": "The discriminator is trained in an adversarial manner so that the encoder learns to produce refined, language-invariant representations that lead to improved performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_2",
            "start": 595,
            "end": 764,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_2@5",
            "content": "More importantly, we optimize the adversarial training process by only presenting the discriminator with the most informative samples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_2",
            "start": 766,
            "end": 899,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_2@6",
            "content": "We base our intuition about what makes a sample informative on two disparate metrics: sample similarity and event presence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_2",
            "start": 901,
            "end": 1023,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_2@7",
            "content": "Thus, we propose leveraging Optimal Transport as a solution to naturally combine these two distinct information sources into the selection process.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_2",
            "start": 1025,
            "end": 1171,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_2@8",
            "content": "Extensive experiments on 8 different language pairs, using 4 languages from unrelated families, show the flexibility and effectiveness of our model that achieves state-of-the-art results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_2",
            "start": 1173,
            "end": 1359,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_4@0",
            "content": "Event Detection (ED) is an important sub-task within the broader Information Extraction (IE) task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_4",
            "start": 0,
            "end": 97,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_4@1",
            "content": "Event detection consists of being able to identify the words, commonly referred to as triggers, that denote the occurrence of events in a sentence, and classify them into a discrete set of event types.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_4",
            "start": 99,
            "end": 299,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_4@2",
            "content": "For example, in the sentence \"Jamie bought a car yesterday.\", bought is considered the trigger of a TRANSACTION:TRANSFER-OWNERSHIP 1 1 Event type taken from the ACE05 dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_4",
            "start": 301,
            "end": 475,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_4@3",
            "content": "event type.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_4",
            "start": 477,
            "end": 487,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_4@4",
            "content": "It is a very well studied task in which there have been lots of previous research efforts that have recently been primarily deep learningbased (Nguyen and Grishman, 2015;Chen et al., 2015;Nguyen et al., 2016a,b;Sha et al., 2018;Wadden et al., 2019;Zhang et al., 2019a;Yang et al., 2019;Nguyen and Nguyen, 2019;Zhang et al., 2020;Liu et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_4",
            "start": 489,
            "end": 835,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_5@0",
            "content": "Nonetheless, ED remains quite a challenging task as the context in which a trigger occurs can change its corresponding type completely.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_5",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_5@1",
            "content": "Furthermore, the same event might also be expressed by entirely different words/phrases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_5",
            "start": 136,
            "end": 223,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_5@2",
            "content": "Additionally, the vast majority of the aforementioned efforts are limited to a monolingual setting -performing ED on text belonging to a single language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_5",
            "start": 225,
            "end": 377,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_6@0",
            "content": "Alternatively, Cross-Lingual ED (CLED) proposes the scenario of creating models that effectively perform ED on data belonging to more than one language, which brings about additional challenges.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_6",
            "start": 0,
            "end": 193,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_6@1",
            "content": "For instance, trigger words present in one language might not exist in another one.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_6",
            "start": 195,
            "end": 277,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_6@2",
            "content": "An frequent example of this phenomenon are verb conjugations where some tenses only exist in some languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_6",
            "start": 279,
            "end": 386,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_6@3",
            "content": "Accurate verb handling is of particular importance for the ED task as event triggers are usually related to the verbs in a sentence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_6",
            "start": 388,
            "end": 519,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_6@4",
            "content": "Some recent work (Majewska et al., 2021) has attempted to address this issue by injecting external verb knowledge into the training process.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_6",
            "start": 521,
            "end": 660,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_6@5",
            "content": "Another similar problematic issue for CLED are triggers with different meanings that are each distinct words in different languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_6",
            "start": 662,
            "end": 793,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_6@6",
            "content": "For instance, the word \"juicio\" in Spanish can either mean \"judgement\" or \"trial\" in English, depending on the context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_6",
            "start": 795,
            "end": 913,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_7@0",
            "content": "A compelling approach to creating a crosslingual model is to use transfer learning which carries the performance of a model trained on a source language over onto a second target language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_7",
            "start": 0,
            "end": 187,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_7@1",
            "content": "The general idea is leveraging the existing high-quality annotated data available for a high-resource language to train a model in a way that allows it to learn the language-invariant characteristics of the task at hand, ED in this case, so that it also performs effectively on text from a second language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_7",
            "start": 189,
            "end": 494,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_7@2",
            "content": "Prior works on transfer learning for CLED have relied on pre-trained Multilingual Language Models (MLMs), such as multilingual BERT (mBERT) (Devlin et al., 2019), to take advantage of their innate language-invariant qualities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_7",
            "start": 496,
            "end": 721,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_7@3",
            "content": "Yet, their performance still shows room for improvement as they sometimes struggle to handle the difficult instances, unique to cross-lingual settings, mentioned earlier.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_7",
            "start": 723,
            "end": 892,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_7@4",
            "content": "We identify a significant shortcoming of previous CLED efforts in that they do not exploit the abundant supply of unlabeled data: even though MLMs are trained on immense amounts of it, unlabeled data is not used when fine-tuning for the ED task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_7",
            "start": 894,
            "end": 1138,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_7@5",
            "content": "It is our intuition that by integrating unlabeled target-language data into the training process, the model is exposed to more language context which should help deal with issues such as verb variation and multiple connotations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_7",
            "start": 1140,
            "end": 1367,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_8@0",
            "content": "As such, we propose making use of Adversarial Language Adaptation (ALA) (Joty et al., 2017;Chen et al., 2018) to train a CLED model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_8",
            "start": 0,
            "end": 131,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_8@1",
            "content": "The key idea is to generate language-invariant representations that are not indicative of language but remain informative for the ED task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_8",
            "start": 133,
            "end": 270,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_8@2",
            "content": "Unlabeled data from both the source and target languages is used to train a Language Discriminator (LD) network that learns to discern between the two.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_8",
            "start": 272,
            "end": 422,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_8@3",
            "content": "The adversarial part comes from the fact that the encoder and discriminator are trained with opposing objectives: as the LD becomes better at distinguishing between languages, the encoder learns to generate more language-invariant representations in an attempt to fool the LD.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_8",
            "start": 424,
            "end": 699,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_8@4",
            "content": "To the best of our knowledge, our work is the first one proposing the use of ALA for the CLED task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_8",
            "start": 701,
            "end": 799,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_9@0",
            "content": "Nonetheless, contrary to past uses of ALA where the same importance is given to all unlabeled samples, we recognize that such course of action is suboptimal as certain samples are bound to be more informative for the discriminator than others.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_9",
            "start": 0,
            "end": 242,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_9@1",
            "content": "For example, we would like to present the LD with the samples that allow it to learn the fine-grained distinctions between the source and target languages, instead of relying on syntactic differences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_9",
            "start": 244,
            "end": 443,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_9@2",
            "content": "Moreover, in the context of ED, we suggest it would be beneficial for the LD to be trained with examples containing events, instead of non-event samples, as the presence of an event can then be incorporated into the generated representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_9",
            "start": 445,
            "end": 686,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_10@0",
            "content": "Hence, we propose refining the adversarial training process by only keeping the most informative examples while disregarding less useful ones.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_10",
            "start": 0,
            "end": 141,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_10@1",
            "content": "Our intuition as to what makes samples more informative for CLED is two-fold: First, we presume that presenting the LD with examples that are too different makes the discrimination task too simple.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_10",
            "start": 143,
            "end": 339,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_10@2",
            "content": "As mentioned previously, we would like the LD to learn a fine-grained distinction between the source and target languages which, in turn, improves the language-invariance of the encoder's representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_10",
            "start": 341,
            "end": 544,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_10@3",
            "content": "Thus, we suggest presenting the LD with examples that have similar contextual semantics, i.e., similar contextualized representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_10",
            "start": 546,
            "end": 679,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_10@4",
            "content": "Second, we consider that sentences containing events should provide an ED system with additional task-relevant information when compared against non-event samples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_10",
            "start": 681,
            "end": 843,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_10@5",
            "content": "Accordingly, we argue that event-containing sentences should have a larger probability of being selected for ALA training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_10",
            "start": 845,
            "end": 966,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_11@0",
            "content": "With these intuitions in mind, we propose Optimal Transport (OT) (Villani, 2008) as a natural solution to simultaneously incorporate both the similarity between sample representations and the likelihood of the samples containing an event into a single framework.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_11",
            "start": 0,
            "end": 261,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_11@1",
            "content": "Therefore, we cast sample selection as an OT problem in which we attempt to find the best alignment between the samples from the source and target languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_11",
            "start": 263,
            "end": 419,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_12@0",
            "content": "For our experiments, we focus on the widely used ACE05 (Walker et al., 2006) and ERE (Song et al., 2015) datasets which, in conjuction, contain event-annotations in 4 different languages: English, Spanish, Chinese, and Arabic.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_12",
            "start": 0,
            "end": 225,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_12@1",
            "content": "We work on 8 different language pairs by selecting different languages as the source and target.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_12",
            "start": 227,
            "end": 322,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_12@2",
            "content": "Our proposed model obtains new state-of-the-art results with considerable performance improvements (+ 2-3% in F1 scores) over competitive baselines and previously published results (M'hamdi et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_12",
            "start": 324,
            "end": 527,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_12@3",
            "content": "We believe these results demonstrate our model's efficacy and applicability at creating CLED systems.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_12",
            "start": 529,
            "end": 629,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_13@0",
            "content": "The rest of this paper is organized as follows: section 2 provides an thorough description of our proposed model, section 3 presents and analyses the results from our experiments, section 4 provides a brief review of related work, and section 5 includes our conclusions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_13",
            "start": 0,
            "end": 269,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_14@0",
            "content": "Model",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_14",
            "start": 0,
            "end": 4,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_15@0",
            "content": "Problem Definition",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_15",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_16@0",
            "content": "Following prior works (M'hamdi et al., 2019;Majewska et al., 2021), we treat ED as a sequence labeling problem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_16",
            "start": 0,
            "end": 110,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_16@1",
            "content": "Given a set D of word sequences w i = {w i1 , w i2 , ..., w in\u22121 , w in } and their corresponding label sequences y i = {y i1 , y i2 , ..., y in\u22121 , y in }, we use an encoder network E to obtain a contextualized vector representation of the words in the input sequence",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_16",
            "start": 112,
            "end": 379,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_17@0",
            "content": "h i = E(w i ) = {h i1 , h i2 , ..., h in\u22121 , h in }.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_17",
            "start": 0,
            "end": 51,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_18@0",
            "content": "Using such representations as input, a prediction network P computes a distribution over the set of possible labels and is trained in a supervised manner using the negative log-likelihood function L P :",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_18",
            "start": 0,
            "end": 201,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_19@0",
            "content": "L P = \u2212 |D| i=1 n j=1 logP (y ij |h ij )(1)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_19",
            "start": 0,
            "end": 42,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_20@0",
            "content": "In the cross-lingual transfer-learning setting, the data used to train the model and the data on which the model is tested come from different languages known as the source and target, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_20",
            "start": 0,
            "end": 197,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_20@1",
            "content": "As such, we deal with two datasets D src and D tgt .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_20",
            "start": 199,
            "end": 250,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_20@2",
            "content": "We assume that we do not have access to the gold labels of the target language y tgt , other than to evaluate our CLED model at testing time.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_20",
            "start": 252,
            "end": 392,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_21@0",
            "content": "Our goal is to define a model able to generate language-invariant word representations that are refined enough so that cross-lingual issues, such as the ones described in section 1, are properly handled.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_21",
            "start": 0,
            "end": 202,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_22@0",
            "content": "Baseline Model",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_22",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_23@0",
            "content": "Here, we briefly describe the BERT-CRF model proposed by M'hamdi et al. ( 2019) which was the previous state-of-the-art and serves as our main baseline.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_23",
            "start": 0,
            "end": 151,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_23@1",
            "content": "Using multilingual BERT (mBERT, (Devlin et al., 2019)) as its encoder, BERT-CRF generates robust, contextualized representations for words from different languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_23",
            "start": 153,
            "end": 316,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_23@2",
            "content": "For words that are split into multiple word-pieces, the average of the representation vectors for all comprising sub-pieces is used as the representation of the full word.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_23",
            "start": 318,
            "end": 488,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_24@0",
            "content": "For classification purposes, instead of assigning the labels of each token independently, BERT-CRF uses a Conditional Random Field (CRF) (Lafferty et al., 2001) layer on top of the prediction network to better capture the interactions between the label sequences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_24",
            "start": 0,
            "end": 262,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_24@1",
            "content": "In summary, the contextualized representation vectors h i generated by the mBERT encoder from the words in the sequence are then fed to a CRF layer which finds the optimal label sequence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_24",
            "start": 264,
            "end": 450,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_25@0",
            "content": "Adversarial Language Adaptation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_25",
            "start": 0,
            "end": 30,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_26@0",
            "content": "The pre-trained versions of MLMs like mBERT or XLM-RoBERTa (Conneau et al., 2019) generate contextualized representations with a certain degree of language-invariance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_26",
            "start": 0,
            "end": 166,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_26@1",
            "content": "This can be confirmed by their successful application in cross-lingual settings (M'hamdi et al., 2019;Majewska et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_26",
            "start": 168,
            "end": 292,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_26@2",
            "content": "However, a lingering issue is the difficulty of learning the nuances of the target language such as verb variations that do not exist in the source language used to train them.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_26",
            "start": 294,
            "end": 469,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_26@3",
            "content": "Majewska et al. (2021), for instance, propose to address this issue by injecting external verb knowledge into the encoder via taskspecific adapter modules (Pfeiffer et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_26",
            "start": 471,
            "end": 649,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_27@0",
            "content": "It is our intuition, however, that these issues can be mitigated by achieving a more refined level of language-invariance in the word representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_27",
            "start": 0,
            "end": 149,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_28@0",
            "content": "As such, we propose using Adversarial Language Adaptation (ALA) (Joty et al., 2017), a technique used to create language-invariant models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_28",
            "start": 0,
            "end": 137,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_28@1",
            "content": "The ALA framework consists in including a Language Discriminator (LD) whose purpose is to learn language-dependent features and be able to differentiate between the samples from either the source or the target languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_28",
            "start": 139,
            "end": 358,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_29@0",
            "content": "A fundamental characteristic of the ALA approach is its lack of requirements for annotated data in the target language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_29",
            "start": 0,
            "end": 118,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_29@1",
            "content": "As such, we can use data from both D src and D tgt .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_29",
            "start": 120,
            "end": 171,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_29@2",
            "content": "An auxiliary dataset D aux = {(w 1 , l 1 ), . . . , (w 2m , l 2m )} is created where w i is a text sequence from either D src or D tgt , and l i is a language label.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_29",
            "start": 173,
            "end": 337,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_29@3",
            "content": "The cardinality of D aux is |D aux | = 2m, where m is equal to the batch size.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_29",
            "start": 339,
            "end": 416,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_29@4",
            "content": "Text samples w 1 . . . w m \u2208 D src , and samples w m+1 . . . w 2m \u2208 D tgt .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_29",
            "start": 418,
            "end": 492,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_29@5",
            "content": "As described earlier, the encoder E receives the text sequences and produces a sequence of contextualized representations E(w i ) = h i = {h i0 , h i1 , h i2 , . . . , h in } where h i0 is the representation of the [CLS] token added at the beginning of every input sequence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_29",
            "start": 494,
            "end": 767,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_30@0",
            "content": "In our work, the LD is a a simple Multi-Layer Perceptron(MLP) network that takes h i0 as input and produces a single sigmoid output.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_30",
            "start": 0,
            "end": 131,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_30@1",
            "content": "It's trained with the usual binary cross-entropy loss function objective: LD loss = arg min LD L(LD(h i0 ), l i ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_30",
            "start": 133,
            "end": 246,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_31@0",
            "content": "As the LD learns to distinguish between the source and target languages, we concurrently train the encoder to \"fool\" the discriminator.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_31",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_31@1",
            "content": "In other words, the encoder must learn to generate representations that are language-invariant enough that the LD is unable to classify them while still remaining predictive for event-trigger classification.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_31",
            "start": 136,
            "end": 342,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_31@2",
            "content": "We optimize the following loss:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_31",
            "start": 344,
            "end": 374,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_32@0",
            "content": "arg min E,C n j=1 (L(C(h ij ), y ij )) \u2212 \u03bbL(LD(h i0 , l i )) (2)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_32",
            "start": 0,
            "end": 63,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_33@0",
            "content": "Where C refers to the CRF-based classifier network and \u03bb is a hyperparameter.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_33",
            "start": 0,
            "end": 76,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_34@0",
            "content": "Equation 2 is implemented by using a Gradient-Reversal Layer (GRL) (Ganin and Lempitsky, 2015) which acts as the identity during the forward pass, but reverses the direction of the gradients during the backward pass.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_34",
            "start": 0,
            "end": 215,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_34@1",
            "content": "The first term in Equation 2can, of course, only be applied for annotated data from the source language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_34",
            "start": 217,
            "end": 320,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_35@0",
            "content": "The GRL is applied to the input vectors, h i0 , of the LD.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_35",
            "start": 0,
            "end": 57,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_35@1",
            "content": "This way, the LD is being trained to differentiate between the two languages while the encoder is trained in the opposite direction, i.e. to generate sequence representations that are harder to discriminate.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_35",
            "start": 59,
            "end": 265,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_36@0",
            "content": "Adversarial Training Optimization",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_36",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_37@0",
            "content": "ALA has already been shown to be effective at generating language-invariant models (Joty et al., 2017;Chen et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_37",
            "start": 0,
            "end": 120,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_37@1",
            "content": "However, in regular ALA training, all samples in a batch, from both the source and target domains, are treated equally.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_37",
            "start": 122,
            "end": 240,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_37@2",
            "content": "That is, all samples are used as examples for the discriminator to learn how to better discern between the two domains.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_37",
            "start": 242,
            "end": 360,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_37@3",
            "content": "We propose that ALA effectiveness can be further improved by carefully selecting the samples with which to train the discriminator.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_37",
            "start": 362,
            "end": 492,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_37@4",
            "content": "We argue that some samples might be more informative than others and that, by only using such informative samples during training, better adaptation results can be achieved.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_37",
            "start": 494,
            "end": 666,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_38@0",
            "content": "We base our notion as to what makes a sample more informative on two factors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_38",
            "start": 0,
            "end": 76,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_38@1",
            "content": "First, we argue that presenting the LD with examples from the source and target language that are too dissimilar makes its task easier which, in turn, leads to the LD not learning the fine-grained distinctions between the languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_38",
            "start": 78,
            "end": 309,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_38@2",
            "content": "Instead, we propose using samples whose vector representations h i0 are close to each other in the embedding space.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_38",
            "start": 311,
            "end": 425,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_38@3",
            "content": "The intuition for this being that, as representations capture the contextual semantics of the samples, closer representations correspond to more similar examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_38",
            "start": 427,
            "end": 588,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_38@4",
            "content": "Second, we suggest that presenting the LD with samples containing events should make the encoder incorporate task-specific information into its representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_38",
            "start": 590,
            "end": 749,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_39@0",
            "content": "Optimal Transport",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_39",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_40@0",
            "content": "One challenge of using the two mentioned criteria for the ALA sample selection process is that they come with two different measures which are hard to combine.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_40",
            "start": 0,
            "end": 158,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_40@1",
            "content": "To address this, we propose using Optimal Transport (OT) (Villani, 2008) as a natural way to combine these two metrics into a single framework for sample selection.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_40",
            "start": 160,
            "end": 323,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_40@2",
            "content": "Optimal transport is, in broad terms, the problem of finding out the cheapest transformation between two discrete probability distributions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_40",
            "start": 325,
            "end": 464,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_40@3",
            "content": "It requires a cost function to determine the cost of transforming a data point in one distribution into a data point in the second distribution.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_40",
            "start": 466,
            "end": 609,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_40@4",
            "content": "When the cost function is based on a valid distance function, the minimum cost is known as the Wasserstein distance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_40",
            "start": 611,
            "end": 726,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_40@5",
            "content": "Formally, it solves the following optimization problem:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_40",
            "start": 728,
            "end": 782,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_41@0",
            "content": "\u03c0 * (s, t) = min \u03c0\u2208 (s,t) s\u2208S t\u2208T \u03c0(s, t) C(s, t) ds dt (3) s.t. s \u223c p(s) and t \u223c q(t)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_41",
            "start": 0,
            "end": 85,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_42@0",
            "content": "where S and T are the two domains to be transformed; p(s) and q(t) are the probability distributions of S and T , respectively; C is a cost function for mapping S to T , C(s, t) : S \u00d7 T \u2212\u2192 R + ; and finally, \u03c0 * (s, t) is the optimal joint distribution over the set of all joint distributions (s, t).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_42",
            "start": 0,
            "end": 299,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_42@1",
            "content": "The problem described by Equation 3 is, of course, intractable.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_42",
            "start": 301,
            "end": 363,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_42@2",
            "content": "Therefore, we use instead the Sinkhorn algorithm (Cuturi, 2013) which is an entropy-based relaxation of the discrete OT problem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_42",
            "start": 365,
            "end": 492,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_43@0",
            "content": "Problem Formulation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_43",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_44@0",
            "content": "We formulate the OT problem as follows: the domains S and T are defined as the representation vectors of the text samples in either the source h s i0 or the target h t j0 languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_44",
            "start": 0,
            "end": 180,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_44@1",
            "content": "We use the L2 distance between these representations as the cost function:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_44",
            "start": 182,
            "end": 255,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_45@0",
            "content": "C(h s i0 , h t j0 ) = ||h s i0 \u2212 h t j0 || 2",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_45",
            "start": 0,
            "end": 43,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_46@0",
            "content": "To define the marginal probability distributions p(s) and q(t) for the S and T domains, we propose including an Event-Presence (EP) prediction module and use its normalized likelihood scores as the probability distributions for S and T .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_46",
            "start": 0,
            "end": 236,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_46@1",
            "content": "Thus, the auxiliary dataset D aux is augmented to include an event-presence label e i for each sample.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_46",
            "start": 238,
            "end": 339,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_46@2",
            "content": "Of course, this can only be done for samples in the source language as the labels for the target-language data are unavailable:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_46",
            "start": 341,
            "end": 467,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_47@0",
            "content": "D aux = {(w 1 , l 1 , e 1 ), . . . , (w m , l m , e m ), (w m+1 , l m+1 ), . . . , (w 2m , l 2m )}",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_47",
            "start": 0,
            "end": 97,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_48@0",
            "content": "The EP module is then trained to optimize the following loss:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_48",
            "start": 0,
            "end": 60,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_49@0",
            "content": "EP loss = arg min EP L(EP (h i0 ), e i )(5)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_49",
            "start": 0,
            "end": 42,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_50@0",
            "content": "where i <= m, i.e., only using samples from the source language. The probability distributions p(s) and p(t) are the computed as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_50",
            "start": 0,
            "end": 136,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_51@0",
            "content": "p(s) = Sof tmax(EP (h s i0 ) | l i == s)(6)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_51",
            "start": 0,
            "end": 42,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_52@0",
            "content": "p(t) = Sof tmax(EP (h t i0 ) | l i == t)(7)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_52",
            "start": 0,
            "end": 42,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_53@0",
            "content": "Sample Selection",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_53",
            "start": 0,
            "end": 15,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_54@0",
            "content": "We use the OT solution matrix \u03c0 * , where an entry \u03c0 * (s, t) represents the optimal cost of transforming data point s \u2208 S into t \u2208 T , to compute an the overall similarity score v i of a sample h i0 \u2208 S to the samples in the target domain T by using the average distance:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_54",
            "start": 0,
            "end": 271,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_55@0",
            "content": "v i = m j \u03c0 * (h s i0 , h t j0 ) m(8)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_55",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_56@0",
            "content": "Correspondingly, we compute an overall similarity score v j of each sample h j0 \u2208 T to the samples in the source domain S:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_56",
            "start": 0,
            "end": 121,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_57@0",
            "content": "v j = m i \u03c0 * (h s i0 , h t j0 ) m (9)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_57",
            "start": 0,
            "end": 37,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_58@0",
            "content": "Lastly, we select a fraction, hyperparameter \u03b3, of samples with the best similarity scores from both the source and target languages, and only use these selected samples during ALA training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_58",
            "start": 0,
            "end": 189,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_59@0",
            "content": "OACLED Model",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_59",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_60@0",
            "content": "We train our Optimized Adversarial Cross-Lingual Event Detection (OACLED) model end-to-end with the following loss objective: L f ull = CRF loss + \u03b1LD loss + \u03b2EP loss (10) where \u03b1 and \u03b2 are trade-off hyperparameters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_60",
            "start": 0,
            "end": 215,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_61@0",
            "content": "Experiments",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_61",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_62@0",
            "content": "Datasets",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_62",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_63@0",
            "content": "We evaluate our model on the ACE05 (Walker et al., 2006) dataset which includes annotated eventtrigger data in 3 languages: English, Chinese and Arabic.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_63",
            "start": 0,
            "end": 151,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_63@1",
            "content": "To include an additional language in our experiments, we also evaluate on the ERE dataset which has annotated data in English and Spanish.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_63",
            "start": 153,
            "end": 290,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_63@2",
            "content": "Note that the ACE05 and ERE datasets do not share the same label set: ACE05 involves 33 distinct event types while ERE involves 38 event types.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_63",
            "start": 292,
            "end": 434,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_63@3",
            "content": "We follow the same data pre-processing and splits as in previous work (M'hamdi et al., 2019)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_63",
            "start": 436,
            "end": 527,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_64@0",
            "content": "Hyper-parameters",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_64",
            "start": 0,
            "end": 15,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_65@0",
            "content": "We fine-tune the hyper-parameters for our OA-CLED model using the development data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_65",
            "start": 0,
            "end": 82,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_65@1",
            "content": "We apply the following values based on the fine-tuning process:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_65",
            "start": 84,
            "end": 146,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_66@0",
            "content": "\u2022 AdamW as the optimizer. \u2022 5 warm up epochs. \u2022 A learning rate of 1e \u22125 for the transformer parameters and of 1e \u22124 for the rest of the parameters. \u2022 A batch size of 16. \u2022 300 for the dimensionality of the layers in feed-forwards networks. \u2022 A \u03b3 = 0.5 for the percentage of samples used in adversarial training. \u2022 A \u03bb = 0.001 as the scaling factor of the GRL layer. \u2022 An \u03b1 = 1 and \u03b2 = 0.001 as the trade-off parameters of the LD loss and ED loss, respectively. \u2022 A dropout of 10% for added regularization during training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_66",
            "start": 0,
            "end": 521,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_67@0",
            "content": "Main Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_67",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_68@0",
            "content": "In our experiments, we work with 8 distinct language pairs by selecting each of the available languages as either the source or target language: English-Chinese, Chinese-English, English-Arabic, Arabic-English, Chinese-Arabic, Arabic-Chinese, English-Spanish, and Spanish-English.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_68",
            "start": 0,
            "end": 279,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_69@0",
            "content": "The Chinese-Spanish, Spanish-Chinese, Arabic-Spanish, and Spanish-Arabic language combinations are unavailable due the previously mentioned incompatibility between the event type sets in ACE05 and ERE.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_69",
            "start": 0,
            "end": 200,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_70@0",
            "content": "We compare our OACLED model against 3 relevant baselines.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_70",
            "start": 0,
            "end": 56,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_70@1",
            "content": "First, the previous state-of-the-art CLED model BERT-CRF (M'hamdi et al., 2019) as described in section 2.2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_70",
            "start": 58,
            "end": 165,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_70@2",
            "content": "Second, the mBERT-2TA model (Majewska et al., 2021) which aims at improving cross-lingual performance by incorporating language-independent verb knowledge via task-specific adapters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_70",
            "start": 167,
            "end": 348,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_70@3",
            "content": "And third, XLM-R-CRF which is equivalent in all regards to BERT-CRF except that it uses XLM-RoBERTa (Conneau et al., 2019) as the encoder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_70",
            "start": 350,
            "end": 487,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_71@0",
            "content": "Table 2 and Table 3 show the results of our experiments on the ACE05 and ERE datasets, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_71",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_71@1",
            "content": "In all our experiments, we use the base transformer versions bert-base-cased and xlm-robertabase as the encoders, parameters are tuned on the development data of the source language, and all entries are the average of five runs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_71",
            "start": 101,
            "end": 328,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_72@0",
            "content": "From Tables 2 and 3, it should be noted that there is a substantial performance increase by performing the trivial change of replacing mBERT with XLM-RoBERTa as the encoder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_72",
            "start": 0,
            "end": 172,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_72@1",
            "content": "Furthermore, our OACLED model clearly and consistently outperforms the baselines for all language pairings, with the exception of the Chinese-Arabic pair.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_72",
            "start": 174,
            "end": 327,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_72@2",
            "content": "We attribute this to the impaired performance of XLM-RoBERTa as the encoder for that specific pair as can be confirmed by the poor performance of the XLM-R-CRF baseline on the same configuration.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_72",
            "start": 329,
            "end": 523,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_72@3",
            "content": "Most importantly, OACLED's improvement over the XLM-R-CRF baseline is present in every configuration, which validates the effectiveness of our optimized approach to ALA training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_72",
            "start": 525,
            "end": 702,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_73@0",
            "content": "Ablation Study",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_73",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_74@0",
            "content": "We identify 2 main components in our approach: using ALA to create refined language-invariant representations, and optimizing the adversarial training process by selecting a subset of samples chosen with OT to incorporate our measures of informativeness into the sample selection process.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_74",
            "start": 0,
            "end": 287,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_74@1",
            "content": "Of course, removing ALA training entirely restores the model to the baseline.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_74",
            "start": 289,
            "end": 365,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_74@2",
            "content": "However, adversarial training optimization via OT has various aspects to it.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_74",
            "start": 367,
            "end": 442,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_74@3",
            "content": "In order to understand the contribution of these aspects, we explore four different models: OACLED-OT presents the effects of removing sample selection entirely and using all available samples to train the LD; OACLED-L2 uses a constant distance between the unlabeled samples instead the standard L2 distance used in the Sinkhorn algorithm; OACLED-EP completely removes the EP module and a uniform distribution is used as the probability distributions for both languages; finally, OACLED-ED-Loss keeps the EP module, but removes its EP loss term from Equation 10.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_74",
            "start": 444,
            "end": 1005,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_74@4",
            "content": "The performance results of these models is presented in Table 4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_74",
            "start": 1007,
            "end": 1070,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_74@5",
            "content": "In this and the following sections (3.5, 3.6.2), we present the results of experiments using English as the sole source language as it is the source language most ubiquitously used.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_74",
            "start": 1072,
            "end": 1252,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_74@6",
            "content": "We, however, found consistency in the displayed effects for different source/target language configurations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_74",
            "start": 1254,
            "end": 1361,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_74@7",
            "content": "As expected, removing the sample selection through OT leads to the worst performance drop.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_74",
            "start": 1363,
            "end": 1452,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_74@8",
            "content": "This highlights the importance of selecting informative examples for the LD.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_74",
            "start": 1454,
            "end": 1529,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_74@9",
            "content": "Furthermore, removing the cost function also hurts performance greatly, which shows that a proper distance function is needed for the OT algorithm to work effectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_74",
            "start": 1531,
            "end": 1697,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_74@10",
            "content": "While the effects of removing the EP module and its corresponding loss term are not of the same magnitude, they are still significant.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_74",
            "start": 1699,
            "end": 1832,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_74@11",
            "content": "These results support our claim for the need and utility of all the components in our approach, showing that their inclusion is crucial in achieving state-of-the-art performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_74",
            "start": 1834,
            "end": 2011,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_75@0",
            "content": "Language Model Finetuning",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_75",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_76@0",
            "content": "The key contribution of our approach is to exploit unlabeled data in the target language, which is usually abundant, by introducing it into the training process to improve our model's language-invariant qualities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_76",
            "start": 0,
            "end": 212,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_77@0",
            "content": "To confirm the utility of our approach, Table 5 contrasts our model's performance against a baseline whose encoder has been finetuned with the same unlabeled data using the standard masked language model objective.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_77",
            "start": 0,
            "end": 213,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_77@1",
            "content": "It can be observed that our model outperforms the finetuned baseline in two out of the three target languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_77",
            "start": 215,
            "end": 324,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_77@2",
            "content": "Additionally, the difference in performance in those two instances is considerably larger (3.58% and 1.15%), than the setting in which the baseline performs better (0.13%).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_77",
            "start": 326,
            "end": 497,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_78@0",
            "content": "Analysis",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_78",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_79@0",
            "content": "Learned Representation Distances",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_79",
            "start": 0,
            "end": 31,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_80@0",
            "content": "First, we look at the distance between the sentencelevel representations h i0 generated by the encoder for different source/target language pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_80",
            "start": 0,
            "end": 145,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_80@1",
            "content": "Figure 1 shows a plot of such distances using cosine distance as the distance function.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_80",
            "start": 147,
            "end": 233,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_80@2",
            "content": "When computing the correlation with the performance results in Table 2, we obtain a score R = \u22120.6616, meaning there is moderate negative correlation between the distance of the representations and model performance, i.e. closer representations lead to better performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_80",
            "start": 235,
            "end": 506,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_81@0",
            "content": "Similarly, Table 6 shows a comparison of the distances between the representations generated by OACLED and those obtained by the XLM-R-CRF baseline.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_81",
            "start": 0,
            "end": 147,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_82@0",
            "content": "Baseline OACLED English/Chinese 3.64e-3 3.93e-6 English/Arabic 7.71e-2 2.08e-5 English/Spanish 5.4e-3 5.3e-6 Chinese/English 3.62e-3 3.87e-6 Arabic/English 4.16e-2 1.02e-5 Spanish/English 6.87e-3 1.49e-5",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_82",
            "start": 0,
            "end": 202,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_83@0",
            "content": "Table 6: Comparison of representation-vector distances for language pairs between our model and the baseline.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_83",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_84@0",
            "content": "We observe that OACLED representations are closer, by several orders of magnitude, than those obtained by the baseline.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_84",
            "start": 0,
            "end": 118,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_84@1",
            "content": "This supports our claim that our model's encoder generates more refined language-invariant representations than those obtained by the default version of XLM-RoBERTa.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_84",
            "start": 120,
            "end": 284,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_85@0",
            "content": "Access to Labeled Target Data",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_85",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_86@0",
            "content": "Previously, we discussed how a key feature of our approach is that it does not require annotated data in the target language and, instead, leverages the use of unlabeled data which is readily available.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_86",
            "start": 0,
            "end": 201,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_86@1",
            "content": "Nonetheless, we also explore the performance of our model in the event that there exists a small amount of annotated target data available.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_86",
            "start": 203,
            "end": 341,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_86@2",
            "content": "Figure 2 shows the results of our experiments when using different amounts of labeled target data during training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_86",
            "start": 343,
            "end": 456,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_86@3",
            "content": "It can be observed that OACLED consistently outperforms the baseline even when there is some availability of annotated data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_86",
            "start": 458,
            "end": 581,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_86@4",
            "content": "Additionally, performance steadily increases as more and more data is used.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_86",
            "start": 583,
            "end": 657,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_86@5",
            "content": "This conforms to expectations, and confirms that having labeled data in the target language available for training is ultimately beneficial to the model's performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_86",
            "start": 659,
            "end": 825,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_87@0",
            "content": "Case Study",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_87",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_88@0",
            "content": "Next, we look into our model's predictions and analyse instances where it outperforms the baseline to exemplify the advantages of dealing with optimized language-invariant representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_88",
            "start": 0,
            "end": 187,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_88@1",
            "content": "We identify two important patterns.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_88",
            "start": 189,
            "end": 223,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_89@0",
            "content": "First, our model seems to better classify events in the target language that involve trigger words that have distinct connotations that depend on context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_89",
            "start": 0,
            "end": 153,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_89@1",
            "content": "Specially those that are two distinct words in the source language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_89",
            "start": 155,
            "end": 221,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_89@2",
            "content": "For example, the Spanish word \"juicio\" can have two distinct meanings that are different words in English: \"trial\" and \"judgement\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_89",
            "start": 223,
            "end": 353,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_89@3",
            "content": "Our model correctly classifies it as a JUSTICE:TRIAL-HEARING trigger in the sentence \"Dos llamados a juicio fueron hechos por un jurado federal investigador\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_89",
            "start": 355,
            "end": 512,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_89@4",
            "content": "Meanwhile, the baseline fails to even recognize it as a trigger.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_89",
            "start": 514,
            "end": 577,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_89@5",
            "content": "Another example is the word \"detenido\", an adjective that can mean both \"detained\", in a criminal context, and \"stopped\", as in halted.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_89",
            "start": 579,
            "end": 713,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_89@6",
            "content": "Our model correctly classifies it in the sentence \"Padilla no deber\u00eda permanecer detenido durante meses alejado de otros reos\" as a JUSTICE:ARREST-JAIL trigger while the baseline fails to detect the event.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_89",
            "start": 715,
            "end": 919,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_89@7",
            "content": "We manually identified 23 of these polysemous triggers in the Spanish 2 test set and found that 19 (82.6%) were correctly classified by our OACLED model versus 14 (60.8%) by the baseline (27.8% improvement).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_89",
            "start": 921,
            "end": 1127,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_90@0",
            "content": "Additionally, we found our model correctly classifies verb conjugation variants that do not exist in the source language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_90",
            "start": 0,
            "end": 120,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_90@1",
            "content": "For instance, our model correctly recognizes the words \"venderlos\", \"vender\", \"vendes\", and \"vendedor\" (variants of the verb \"to buy\") as TRANSACTION:TRANSFER-OWNERSHIP triggers whereas the baseline incorrectly classifies them as being of the TRANSACTION:TRANSFER-MONEY type.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_90",
            "start": 122,
            "end": 396,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_90@2",
            "content": "As previously mentioned, Majewska et al. (2021) propose injecting external verb-knowledge into the training to help with verb interpretation for event extraction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_90",
            "start": 398,
            "end": 559,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_90@3",
            "content": "Our empirical results, however, outperform their reports which appears to imply that, at least for CLED, holistically learning the language-invariant features shared between the target and source languages works better than injecting language-specific verb knowledge.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_90",
            "start": 561,
            "end": 827,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_91@0",
            "content": "We believe these findings illustrate how, by introducing additional context in the form of unlabeled data, the model is able to learn fine-grained word representations that better capture the semantics of the words in the target language, and successfully deal with difficult cross-lingual issues.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_91",
            "start": 0,
            "end": 296,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_92@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_92",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_93@0",
            "content": "Research efforts on monolingual ED are extensive and varied.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_93",
            "start": 0,
            "end": 59,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_93@1",
            "content": "Hand-crafted, feature-based, languagespecific methods were the basis of early ED approaches (Ahn, 2006;Ji and Grishman, 2008;Patwardhan and Riloff, 2009;Liao and Grishman, 2010a,b;Hong et al., 2011;McClosky et al., 2011;Li et al., 2013;Miwa et al., 2014;Yang and Mitchell, 2016).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_93",
            "start": 61,
            "end": 339,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_93@2",
            "content": "More recent efforts have primarily made use of deep learning techniques such as convolutional neural networks (Nguyen and Grishman, 2015;Chen et al., 2015;Nguyen et al., 2016b), recurrent neural networks (Nguyen et al., 2016a;Sha et al., 2018;Lai et al., 2020), graph convolutional networks (Nguyen and Grishman, 2018;Yan et al., 2019;Nguyen et al., 2021a), adversarial networks (Hong et al., 2018;Zhang et al., 2019b), and pre-trained language models (Wadden et al., 2019;Zhang et al., 2019a;Yang et al., 2019;Zhang et al., 2020;Liu et al., 2020;Pouran Ben Veyseh et al., 2021b,a).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_93",
            "start": 341,
            "end": 922,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_94@0",
            "content": "Works on cross-lingual ED are not as prevalent and generally make use of cross-lingual resources employed to address the differences between languages such as bilingual dictionaries or parallel corpora (Muis et al., 2018;Liu et al., 2019) and, more recently, pre-trained multilingual language models (M'hamdi et al., 2019;Hambardzumyan et al., 2020;Majewska et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_94",
            "start": 0,
            "end": 371,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_94@1",
            "content": "Unlike these previous efforts, our method leverages unlabeled data to further refine the language-invariant qualities of the language models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_94",
            "start": 373,
            "end": 513,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_94@2",
            "content": "Adversarial Language Adaptation, inspired by models in domain adaptation research (Ganin and Lempitsky, 2015;Naik and Rose, 2020;Ngo Trung et al., 2021), has been successfuly applied at generating language-invariant models (Joty et al., 2017;Chen et al., 2018;Nguyen et al., 2021b).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_94",
            "start": 515,
            "end": 796,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_94@3",
            "content": "Our method improves upon these approaches optimizing the adversarial training process by selecting the most informative examples from the unlabeled data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_94",
            "start": 798,
            "end": 950,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_95@0",
            "content": "Additional examples of downstream applications of cross-lingual learning are document classification (Holger and Xian, 2018), named entity recognition (Xie et al., 2018) and part-of-speech tagging (Cohen et al., 2011).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_95",
            "start": 0,
            "end": 217,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_95@1",
            "content": "For a thorough review on cross-lingual learning, we refer the reader to Pikuliak et al. (2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_95",
            "start": 219,
            "end": 313,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_96@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_96",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_97@0",
            "content": "We present OACLED, a new model for crosslingual event detection that learns fine-grained language-invariant representations by optimizing the standard ALA training through optimaltransport-based sample selection.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_97",
            "start": 0,
            "end": 211,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_97@1",
            "content": "Our model achieves new state-of-the-art performance in our experiments on 8 different language pairs which demonstrate its robustness and effectiveness at generating refined language-invariant representations that allow for better event detection results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_97",
            "start": 213,
            "end": 467,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_97@2",
            "content": "Our analysis of its intermediate outputs and predictions confirm that OACLED's representations are indeed closer to each other and that this proximity translates into better handling of difficult cross-lingual instances.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_97",
            "start": 469,
            "end": 688,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_97@3",
            "content": "We also note that, while this work focuses on the event detection task, our proposed optimization of the adversarial training process is task independent and can be generalized to other related IE tasks when leveraging ALA is deemed beneficial.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_97",
            "start": 690,
            "end": 933,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_98@0",
            "content": "David Ahn, The stages of event extraction, 2006, Proceedings of the Workshop on Annotating and Reasoning about Time and Events, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_98",
            "start": 0,
            "end": 128,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_99@0",
            "content": "Xilun Chen, Yu Sun, Ben Athiwaratkun, Claire Cardie, Kilian Weinberger, Adversarial Deep Averaging Networks for Cross-Lingual Sentiment Classification, 2018, Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_99",
            "start": 0,
            "end": 221,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_100@0",
            "content": "Yubo Chen, Liheng Xu, Kang Liu, Daojian Zeng, Jun Zhao, Event extraction via dynamic multipooling convolutional neural networks, 2015, Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_100",
            "start": 0,
            "end": 225,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_101@0",
            "content": "B Shay, Dipanjan Cohen, Noah Das,  Smith, Unsupervised structure prediction with nonparallel multilingual guidance, 2011, Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_101",
            "start": 0,
            "end": 210,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_102@0",
            "content": "Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettlemoyer, Veselin Stoyanov, Unsupervised cross-lingual representation learning at scale, 2019, CoRR, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_102",
            "start": 0,
            "end": 239,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_103@0",
            "content": "Marco Cuturi, Sinkhorn distances: Lightspeed computation of optimal transport, 2013, Proceedings of the 26th International Conference on Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_103",
            "start": 0,
            "end": 176,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_104@0",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, Bert: Pre-training of deep bidirectional transformers for language understanding, 2019, NAACL-HLT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_104",
            "start": 0,
            "end": 161,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_105@0",
            "content": "Yaroslav Ganin, Victor Lempitsky, Unsupervised domain adaptation by backpropagation, 2015, Proceedings of the 32nd International Conference on Machine Learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_105",
            "start": 0,
            "end": 161,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_106@0",
            "content": "Karen Hambardzumyan, Hrant Khachatrian, Jonathan , The role of alignment of multilingual contextualized embeddings in zero-shot crosslingual transfer for event extraction, 2020-05, Collaborative Technologies and Data Science in Artificial Intelligence Applications, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_106",
            "start": 0,
            "end": 266,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_107@0",
            "content": "Schwenk Holger, Li Xian, A corpus for multiligual document classification in eight languages, 2018, Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_107",
            "start": 0,
            "end": 198,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_108@0",
            "content": "Yu Hong, Jianfeng Zhang, Bin Ma, Jianmin Yao, Guodong Zhou, Qiaoming Zhu, Using cross-entity inference to improve event extraction, 2011, Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_108",
            "start": 0,
            "end": 228,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_109@0",
            "content": "Yu Hong, Wenxuan Zhou, Jingli Zhang, Guodong Zhou, Qiaoming Zhu, Self-regulation: Employing a generative adversarial network to improve event detection, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_109",
            "start": 0,
            "end": 289,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_110@0",
            "content": "Heng Ji, Ralph Grishman, Refining event extraction through cross-document inference, 2008, Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_110",
            "start": 0,
            "end": 181,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_111@0",
            "content": "Shafiq Joty, Preslav Nakov, Llu\u00eds M\u00e0rquez, Israa Jaradat, Cross-language learning with adversarial neural networks, 2017, Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_111",
            "start": 0,
            "end": 209,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_112@0",
            "content": "John Lafferty, Andrew Mccallum, Fernando Pereira, Conditional random fields: Probabilistic models for segmenting and labeling sequence data, 2001, Proceedings of the Eighteenth International Conference on Machine Learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_112",
            "start": 0,
            "end": 223,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_113@0",
            "content": "Tuan Viet Dac Lai, Thien Huu Ngo Nguyen,  Nguyen, Event detection: Gate diversity and syntactic importance scores for graph convolution neural networks, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_113",
            "start": 0,
            "end": 255,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_114@0",
            "content": "Qi Li, Ji Heng, Liang Huang, Joint event extraction via structured prediction with global features, 2013, Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_114",
            "start": 0,
            "end": 196,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_115@0",
            "content": "Shasha Liao, Ralph Grishman, Filtered ranking for bootstrapping in event extraction, 2010, Proceedings of the International Conference on Computational Linguistics (COLING), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_115",
            "start": 0,
            "end": 174,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_116@0",
            "content": "Shasha Liao, Ralph Grishman, Using document level cross-event inference to improve event extraction, 2010, Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_116",
            "start": 0,
            "end": 197,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_117@0",
            "content": "Jian Liu, Yubo Chen, Kang Liu, Wei Bi, Xiaojiang Liu, Event extraction as machine reading comprehension, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_117",
            "start": 0,
            "end": 207,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_118@0",
            "content": "Jian Liu, Yubo Chen, Kang Liu, Neural cross-lingual event detection with minimal parallel resources, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_118",
            "start": 0,
            "end": 284,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_119@0",
            "content": "UNKNOWN, None, , Edoardo Maria Ponti, and Anna Korhonen. 2021. Verb knowledge injection for multilingual, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_119",
            "start": 0,
            "end": 106,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_120@0",
            "content": "Minh Trung, Thien Nguyen,  Huu Nguyen, One for all: Neural joint modeling of entities and events, 2019, Association for the Advancement of Artificial Inteligence (AAAI), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_120",
            "start": 0,
            "end": 170,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_121@0",
            "content": "Siddharth Patwardhan, Ellen Riloff, A unified model of phrasal and sentential evidence for information extraction, 2009, Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_121",
            "start": 0,
            "end": 212,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_122@0",
            "content": "Jonas Pfeiffer, Andreas R\u00fcckl\u00e9, Clifton Poth, Aishwarya Kamath, Ivan Vuli\u0107, Sebastian Ruder, Kyunghyun Cho, Iryna Gurevych, AdapterHub: A framework for adapting transformers, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_122",
            "start": 0,
            "end": 341,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_123@0",
            "content": "Mat\u00fa\u0161 Pikuliak, Mari\u00e1n \u0160imko, M\u00e1ria Bielikov\u00e1, Cross-lingual learning for text processing: A survey, 2021, Expert Systems with Applications, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_123",
            "start": 0,
            "end": 141,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_124@0",
            "content": ", Unleash GPT-2 power for event detection, , Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_124",
            "start": 0,
            "end": 209,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_125@0",
            "content": "Ben Amir Pouran, Minh Veyseh, Nghia Van Nguyen, Bonan Ngo Trung, Thien Huu Min,  Nguyen, Modeling document-level context for event detection via important context selection, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_125",
            "start": 0,
            "end": 268,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_126@0",
            "content": "Lei Sha, Feng Qian, Baobao Chang, Zhifang Sui, Jointly extracting event triggers and arguments by dependency-bridge rnn and tensor-based argument interaction, 2018, Proceedings of the Association for the Advancement of Artificial Intelligence (AAAI), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_126",
            "start": 0,
            "end": 251,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_127@0",
            "content": "UNKNOWN, None, , , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_127",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_128@0",
            "content": "Neville Ryant, Xiaoyi Ma, From light to rich ERE: Annotation of entities, relations, and events, 2015, Proceedings of the The 3rd Workshop on EVENTS: Definition, Detection, Coreference, and Representation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_128",
            "start": 0,
            "end": 206,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_129@0",
            "content": "UNKNOWN, None, 2008, Optimal Transport: Old and New. Grundlehren der mathematischen Wissenschaften, Springer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_129",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_130@0",
            "content": "David Wadden, Ulme Wennberg, Yi Luan, Hannaneh Hajishirzi, Entity, relation, and event extraction with contextualized span representations, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_130",
            "start": 0,
            "end": 320,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_131@0",
            "content": "Christopher Walker, Stephanie Strassel, Julie Medero, Kazuaki Maeda, Ace 2005 multilingual training corpus, 2006, Technical report, Linguistic Data Consortium, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_131",
            "start": 0,
            "end": 160,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_132@0",
            "content": "Jiateng Xie, Zhilin Yang, Graham Neubig, Noah Smith, Jaime Carbonell, Neural crosslingual named entity recognition with minimal resources, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_132",
            "start": 0,
            "end": 238,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_133@0",
            "content": "Haoran Yan, Xiaolong Jin, Xiangbin Meng, Jiafeng Guo, Xueqi Cheng, Event detection with multiorder graph convolution and aggregated attention, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_133",
            "start": 0,
            "end": 326,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_134@0",
            "content": "Bishan Yang, Tom Mitchell, Joint extraction of events and entities within a document context, 2016, Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_134",
            "start": 0,
            "end": 251,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_135@0",
            "content": "Sen Yang, Dawei Feng, Linbo Qiao, Zhigang Kan, Dongsheng Li, Exploring pre-trained language models for event extraction and generation, 2019, Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_135",
            "start": 0,
            "end": 232,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_136@0",
            "content": "UNKNOWN, None, 2019, Extracting entities and events as a single task using a transition-based neural model, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_136",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_137@0",
            "content": "Tongtao Zhang, Ji Heng, Avirup Sil, Joint Entity and Event Extraction with Generative Adversarial Imitation Learning, 2019, Data Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_137",
            "start": 0,
            "end": 143,
            "label": {}
        },
        {
            "ix": "39-ARR_v2_138@0",
            "content": "Yunyan Zhang, Guangluan Xu, Yang Wang, Daoyu Lin, Feng Li, Chenglong Wu, Jingyuan Zhang, Tinglei Huang, A question answering-based framework for one-step event argument extraction, 2020, IEEE Access, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "39-ARR_v2_138",
            "start": 0,
            "end": 200,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "39-ARR_v2_0",
            "tgt_ix": "39-ARR_v2_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_0",
            "tgt_ix": "39-ARR_v2_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_1",
            "tgt_ix": "39-ARR_v2_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_1",
            "tgt_ix": "39-ARR_v2_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_0",
            "tgt_ix": "39-ARR_v2_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_2",
            "tgt_ix": "39-ARR_v2_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_4",
            "tgt_ix": "39-ARR_v2_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_5",
            "tgt_ix": "39-ARR_v2_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_6",
            "tgt_ix": "39-ARR_v2_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_7",
            "tgt_ix": "39-ARR_v2_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_8",
            "tgt_ix": "39-ARR_v2_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_9",
            "tgt_ix": "39-ARR_v2_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_10",
            "tgt_ix": "39-ARR_v2_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_11",
            "tgt_ix": "39-ARR_v2_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_12",
            "tgt_ix": "39-ARR_v2_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_3",
            "tgt_ix": "39-ARR_v2_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_3",
            "tgt_ix": "39-ARR_v2_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_3",
            "tgt_ix": "39-ARR_v2_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_3",
            "tgt_ix": "39-ARR_v2_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_3",
            "tgt_ix": "39-ARR_v2_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_3",
            "tgt_ix": "39-ARR_v2_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_3",
            "tgt_ix": "39-ARR_v2_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_3",
            "tgt_ix": "39-ARR_v2_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_3",
            "tgt_ix": "39-ARR_v2_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_3",
            "tgt_ix": "39-ARR_v2_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_3",
            "tgt_ix": "39-ARR_v2_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_0",
            "tgt_ix": "39-ARR_v2_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_13",
            "tgt_ix": "39-ARR_v2_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_14",
            "tgt_ix": "39-ARR_v2_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_14",
            "tgt_ix": "39-ARR_v2_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_16",
            "tgt_ix": "39-ARR_v2_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_17",
            "tgt_ix": "39-ARR_v2_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_18",
            "tgt_ix": "39-ARR_v2_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_19",
            "tgt_ix": "39-ARR_v2_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_20",
            "tgt_ix": "39-ARR_v2_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_15",
            "tgt_ix": "39-ARR_v2_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_15",
            "tgt_ix": "39-ARR_v2_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_15",
            "tgt_ix": "39-ARR_v2_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_15",
            "tgt_ix": "39-ARR_v2_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_15",
            "tgt_ix": "39-ARR_v2_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_15",
            "tgt_ix": "39-ARR_v2_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_15",
            "tgt_ix": "39-ARR_v2_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_14",
            "tgt_ix": "39-ARR_v2_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_21",
            "tgt_ix": "39-ARR_v2_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_23",
            "tgt_ix": "39-ARR_v2_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_22",
            "tgt_ix": "39-ARR_v2_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_22",
            "tgt_ix": "39-ARR_v2_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_22",
            "tgt_ix": "39-ARR_v2_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_14",
            "tgt_ix": "39-ARR_v2_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_24",
            "tgt_ix": "39-ARR_v2_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_26",
            "tgt_ix": "39-ARR_v2_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_27",
            "tgt_ix": "39-ARR_v2_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_28",
            "tgt_ix": "39-ARR_v2_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_29",
            "tgt_ix": "39-ARR_v2_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_30",
            "tgt_ix": "39-ARR_v2_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_31",
            "tgt_ix": "39-ARR_v2_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_32",
            "tgt_ix": "39-ARR_v2_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_33",
            "tgt_ix": "39-ARR_v2_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_34",
            "tgt_ix": "39-ARR_v2_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_25",
            "tgt_ix": "39-ARR_v2_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_25",
            "tgt_ix": "39-ARR_v2_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_25",
            "tgt_ix": "39-ARR_v2_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_25",
            "tgt_ix": "39-ARR_v2_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_25",
            "tgt_ix": "39-ARR_v2_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_25",
            "tgt_ix": "39-ARR_v2_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_25",
            "tgt_ix": "39-ARR_v2_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_25",
            "tgt_ix": "39-ARR_v2_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_25",
            "tgt_ix": "39-ARR_v2_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_25",
            "tgt_ix": "39-ARR_v2_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_25",
            "tgt_ix": "39-ARR_v2_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_14",
            "tgt_ix": "39-ARR_v2_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_35",
            "tgt_ix": "39-ARR_v2_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_37",
            "tgt_ix": "39-ARR_v2_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_36",
            "tgt_ix": "39-ARR_v2_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_36",
            "tgt_ix": "39-ARR_v2_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_36",
            "tgt_ix": "39-ARR_v2_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_14",
            "tgt_ix": "39-ARR_v2_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_38",
            "tgt_ix": "39-ARR_v2_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_40",
            "tgt_ix": "39-ARR_v2_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_41",
            "tgt_ix": "39-ARR_v2_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_39",
            "tgt_ix": "39-ARR_v2_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_39",
            "tgt_ix": "39-ARR_v2_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_39",
            "tgt_ix": "39-ARR_v2_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_39",
            "tgt_ix": "39-ARR_v2_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_14",
            "tgt_ix": "39-ARR_v2_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_42",
            "tgt_ix": "39-ARR_v2_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_44",
            "tgt_ix": "39-ARR_v2_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_45",
            "tgt_ix": "39-ARR_v2_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_46",
            "tgt_ix": "39-ARR_v2_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_47",
            "tgt_ix": "39-ARR_v2_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_48",
            "tgt_ix": "39-ARR_v2_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_49",
            "tgt_ix": "39-ARR_v2_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_50",
            "tgt_ix": "39-ARR_v2_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_51",
            "tgt_ix": "39-ARR_v2_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_43",
            "tgt_ix": "39-ARR_v2_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_43",
            "tgt_ix": "39-ARR_v2_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_43",
            "tgt_ix": "39-ARR_v2_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_43",
            "tgt_ix": "39-ARR_v2_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_43",
            "tgt_ix": "39-ARR_v2_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_43",
            "tgt_ix": "39-ARR_v2_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_43",
            "tgt_ix": "39-ARR_v2_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_43",
            "tgt_ix": "39-ARR_v2_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_43",
            "tgt_ix": "39-ARR_v2_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_43",
            "tgt_ix": "39-ARR_v2_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_14",
            "tgt_ix": "39-ARR_v2_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_52",
            "tgt_ix": "39-ARR_v2_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_54",
            "tgt_ix": "39-ARR_v2_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_55",
            "tgt_ix": "39-ARR_v2_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_56",
            "tgt_ix": "39-ARR_v2_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_57",
            "tgt_ix": "39-ARR_v2_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_53",
            "tgt_ix": "39-ARR_v2_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_53",
            "tgt_ix": "39-ARR_v2_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_53",
            "tgt_ix": "39-ARR_v2_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_53",
            "tgt_ix": "39-ARR_v2_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_53",
            "tgt_ix": "39-ARR_v2_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_53",
            "tgt_ix": "39-ARR_v2_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_14",
            "tgt_ix": "39-ARR_v2_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_58",
            "tgt_ix": "39-ARR_v2_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_59",
            "tgt_ix": "39-ARR_v2_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_59",
            "tgt_ix": "39-ARR_v2_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_0",
            "tgt_ix": "39-ARR_v2_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_60",
            "tgt_ix": "39-ARR_v2_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_61",
            "tgt_ix": "39-ARR_v2_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_61",
            "tgt_ix": "39-ARR_v2_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_62",
            "tgt_ix": "39-ARR_v2_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_62",
            "tgt_ix": "39-ARR_v2_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_61",
            "tgt_ix": "39-ARR_v2_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_63",
            "tgt_ix": "39-ARR_v2_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_65",
            "tgt_ix": "39-ARR_v2_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_64",
            "tgt_ix": "39-ARR_v2_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_64",
            "tgt_ix": "39-ARR_v2_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_64",
            "tgt_ix": "39-ARR_v2_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_61",
            "tgt_ix": "39-ARR_v2_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_68",
            "tgt_ix": "39-ARR_v2_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_69",
            "tgt_ix": "39-ARR_v2_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_70",
            "tgt_ix": "39-ARR_v2_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_71",
            "tgt_ix": "39-ARR_v2_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_67",
            "tgt_ix": "39-ARR_v2_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_67",
            "tgt_ix": "39-ARR_v2_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_67",
            "tgt_ix": "39-ARR_v2_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_67",
            "tgt_ix": "39-ARR_v2_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_67",
            "tgt_ix": "39-ARR_v2_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_67",
            "tgt_ix": "39-ARR_v2_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_61",
            "tgt_ix": "39-ARR_v2_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_72",
            "tgt_ix": "39-ARR_v2_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_73",
            "tgt_ix": "39-ARR_v2_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_73",
            "tgt_ix": "39-ARR_v2_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_61",
            "tgt_ix": "39-ARR_v2_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_74",
            "tgt_ix": "39-ARR_v2_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_76",
            "tgt_ix": "39-ARR_v2_77",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_75",
            "tgt_ix": "39-ARR_v2_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_75",
            "tgt_ix": "39-ARR_v2_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_75",
            "tgt_ix": "39-ARR_v2_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_61",
            "tgt_ix": "39-ARR_v2_78",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_77",
            "tgt_ix": "39-ARR_v2_78",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_61",
            "tgt_ix": "39-ARR_v2_79",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_78",
            "tgt_ix": "39-ARR_v2_79",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_79",
            "tgt_ix": "39-ARR_v2_80",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_79",
            "tgt_ix": "39-ARR_v2_80",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_79",
            "tgt_ix": "39-ARR_v2_81",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_80",
            "tgt_ix": "39-ARR_v2_81",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_82",
            "tgt_ix": "39-ARR_v2_83",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_83",
            "tgt_ix": "39-ARR_v2_84",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_79",
            "tgt_ix": "39-ARR_v2_82",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_79",
            "tgt_ix": "39-ARR_v2_83",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_79",
            "tgt_ix": "39-ARR_v2_84",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_81",
            "tgt_ix": "39-ARR_v2_82",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_61",
            "tgt_ix": "39-ARR_v2_85",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_84",
            "tgt_ix": "39-ARR_v2_85",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_85",
            "tgt_ix": "39-ARR_v2_86",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_85",
            "tgt_ix": "39-ARR_v2_86",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_61",
            "tgt_ix": "39-ARR_v2_87",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_86",
            "tgt_ix": "39-ARR_v2_87",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_88",
            "tgt_ix": "39-ARR_v2_89",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_89",
            "tgt_ix": "39-ARR_v2_90",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_90",
            "tgt_ix": "39-ARR_v2_91",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_87",
            "tgt_ix": "39-ARR_v2_88",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_87",
            "tgt_ix": "39-ARR_v2_89",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_87",
            "tgt_ix": "39-ARR_v2_90",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_87",
            "tgt_ix": "39-ARR_v2_91",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_87",
            "tgt_ix": "39-ARR_v2_88",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_0",
            "tgt_ix": "39-ARR_v2_92",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_91",
            "tgt_ix": "39-ARR_v2_92",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_93",
            "tgt_ix": "39-ARR_v2_94",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_94",
            "tgt_ix": "39-ARR_v2_95",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_92",
            "tgt_ix": "39-ARR_v2_93",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_92",
            "tgt_ix": "39-ARR_v2_94",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_92",
            "tgt_ix": "39-ARR_v2_95",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_92",
            "tgt_ix": "39-ARR_v2_93",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_0",
            "tgt_ix": "39-ARR_v2_96",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_95",
            "tgt_ix": "39-ARR_v2_96",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_96",
            "tgt_ix": "39-ARR_v2_97",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_96",
            "tgt_ix": "39-ARR_v2_97",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "39-ARR_v2_0",
            "tgt_ix": "39-ARR_v2_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_1",
            "tgt_ix": "39-ARR_v2_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_2",
            "tgt_ix": "39-ARR_v2_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_2",
            "tgt_ix": "39-ARR_v2_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_2",
            "tgt_ix": "39-ARR_v2_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_2",
            "tgt_ix": "39-ARR_v2_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_2",
            "tgt_ix": "39-ARR_v2_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_2",
            "tgt_ix": "39-ARR_v2_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_2",
            "tgt_ix": "39-ARR_v2_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_2",
            "tgt_ix": "39-ARR_v2_2@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_2",
            "tgt_ix": "39-ARR_v2_2@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_3",
            "tgt_ix": "39-ARR_v2_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_4",
            "tgt_ix": "39-ARR_v2_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_4",
            "tgt_ix": "39-ARR_v2_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_4",
            "tgt_ix": "39-ARR_v2_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_4",
            "tgt_ix": "39-ARR_v2_4@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_4",
            "tgt_ix": "39-ARR_v2_4@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_5",
            "tgt_ix": "39-ARR_v2_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_5",
            "tgt_ix": "39-ARR_v2_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_5",
            "tgt_ix": "39-ARR_v2_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_6",
            "tgt_ix": "39-ARR_v2_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_6",
            "tgt_ix": "39-ARR_v2_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_6",
            "tgt_ix": "39-ARR_v2_6@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_6",
            "tgt_ix": "39-ARR_v2_6@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_6",
            "tgt_ix": "39-ARR_v2_6@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_6",
            "tgt_ix": "39-ARR_v2_6@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_6",
            "tgt_ix": "39-ARR_v2_6@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_7",
            "tgt_ix": "39-ARR_v2_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_7",
            "tgt_ix": "39-ARR_v2_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_7",
            "tgt_ix": "39-ARR_v2_7@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_7",
            "tgt_ix": "39-ARR_v2_7@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_7",
            "tgt_ix": "39-ARR_v2_7@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_7",
            "tgt_ix": "39-ARR_v2_7@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_8",
            "tgt_ix": "39-ARR_v2_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_8",
            "tgt_ix": "39-ARR_v2_8@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_8",
            "tgt_ix": "39-ARR_v2_8@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_8",
            "tgt_ix": "39-ARR_v2_8@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_8",
            "tgt_ix": "39-ARR_v2_8@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_9",
            "tgt_ix": "39-ARR_v2_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_9",
            "tgt_ix": "39-ARR_v2_9@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_9",
            "tgt_ix": "39-ARR_v2_9@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_10",
            "tgt_ix": "39-ARR_v2_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_10",
            "tgt_ix": "39-ARR_v2_10@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_10",
            "tgt_ix": "39-ARR_v2_10@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_10",
            "tgt_ix": "39-ARR_v2_10@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_10",
            "tgt_ix": "39-ARR_v2_10@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_10",
            "tgt_ix": "39-ARR_v2_10@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_11",
            "tgt_ix": "39-ARR_v2_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_11",
            "tgt_ix": "39-ARR_v2_11@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_12",
            "tgt_ix": "39-ARR_v2_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_12",
            "tgt_ix": "39-ARR_v2_12@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_12",
            "tgt_ix": "39-ARR_v2_12@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_12",
            "tgt_ix": "39-ARR_v2_12@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_13",
            "tgt_ix": "39-ARR_v2_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_14",
            "tgt_ix": "39-ARR_v2_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_15",
            "tgt_ix": "39-ARR_v2_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_16",
            "tgt_ix": "39-ARR_v2_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_16",
            "tgt_ix": "39-ARR_v2_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_17",
            "tgt_ix": "39-ARR_v2_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_18",
            "tgt_ix": "39-ARR_v2_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_19",
            "tgt_ix": "39-ARR_v2_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_20",
            "tgt_ix": "39-ARR_v2_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_20",
            "tgt_ix": "39-ARR_v2_20@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_20",
            "tgt_ix": "39-ARR_v2_20@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_21",
            "tgt_ix": "39-ARR_v2_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_22",
            "tgt_ix": "39-ARR_v2_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_23",
            "tgt_ix": "39-ARR_v2_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_23",
            "tgt_ix": "39-ARR_v2_23@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_23",
            "tgt_ix": "39-ARR_v2_23@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_24",
            "tgt_ix": "39-ARR_v2_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_24",
            "tgt_ix": "39-ARR_v2_24@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_25",
            "tgt_ix": "39-ARR_v2_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_26",
            "tgt_ix": "39-ARR_v2_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_26",
            "tgt_ix": "39-ARR_v2_26@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_26",
            "tgt_ix": "39-ARR_v2_26@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_26",
            "tgt_ix": "39-ARR_v2_26@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_27",
            "tgt_ix": "39-ARR_v2_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_28",
            "tgt_ix": "39-ARR_v2_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_28",
            "tgt_ix": "39-ARR_v2_28@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_29",
            "tgt_ix": "39-ARR_v2_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_29",
            "tgt_ix": "39-ARR_v2_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_29",
            "tgt_ix": "39-ARR_v2_29@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_29",
            "tgt_ix": "39-ARR_v2_29@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_29",
            "tgt_ix": "39-ARR_v2_29@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_29",
            "tgt_ix": "39-ARR_v2_29@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_30",
            "tgt_ix": "39-ARR_v2_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_30",
            "tgt_ix": "39-ARR_v2_30@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_31",
            "tgt_ix": "39-ARR_v2_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_31",
            "tgt_ix": "39-ARR_v2_31@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_31",
            "tgt_ix": "39-ARR_v2_31@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_32",
            "tgt_ix": "39-ARR_v2_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_33",
            "tgt_ix": "39-ARR_v2_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_34",
            "tgt_ix": "39-ARR_v2_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_34",
            "tgt_ix": "39-ARR_v2_34@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_35",
            "tgt_ix": "39-ARR_v2_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_35",
            "tgt_ix": "39-ARR_v2_35@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_36",
            "tgt_ix": "39-ARR_v2_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_37",
            "tgt_ix": "39-ARR_v2_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_37",
            "tgt_ix": "39-ARR_v2_37@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_37",
            "tgt_ix": "39-ARR_v2_37@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_37",
            "tgt_ix": "39-ARR_v2_37@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_37",
            "tgt_ix": "39-ARR_v2_37@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_38",
            "tgt_ix": "39-ARR_v2_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_38",
            "tgt_ix": "39-ARR_v2_38@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_38",
            "tgt_ix": "39-ARR_v2_38@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_38",
            "tgt_ix": "39-ARR_v2_38@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_38",
            "tgt_ix": "39-ARR_v2_38@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_39",
            "tgt_ix": "39-ARR_v2_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_40",
            "tgt_ix": "39-ARR_v2_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_40",
            "tgt_ix": "39-ARR_v2_40@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_40",
            "tgt_ix": "39-ARR_v2_40@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_40",
            "tgt_ix": "39-ARR_v2_40@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_40",
            "tgt_ix": "39-ARR_v2_40@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_40",
            "tgt_ix": "39-ARR_v2_40@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_41",
            "tgt_ix": "39-ARR_v2_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_42",
            "tgt_ix": "39-ARR_v2_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_42",
            "tgt_ix": "39-ARR_v2_42@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_42",
            "tgt_ix": "39-ARR_v2_42@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_43",
            "tgt_ix": "39-ARR_v2_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_44",
            "tgt_ix": "39-ARR_v2_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_44",
            "tgt_ix": "39-ARR_v2_44@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_45",
            "tgt_ix": "39-ARR_v2_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_46",
            "tgt_ix": "39-ARR_v2_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_46",
            "tgt_ix": "39-ARR_v2_46@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_46",
            "tgt_ix": "39-ARR_v2_46@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_47",
            "tgt_ix": "39-ARR_v2_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_48",
            "tgt_ix": "39-ARR_v2_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_49",
            "tgt_ix": "39-ARR_v2_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_50",
            "tgt_ix": "39-ARR_v2_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_51",
            "tgt_ix": "39-ARR_v2_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_52",
            "tgt_ix": "39-ARR_v2_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_53",
            "tgt_ix": "39-ARR_v2_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_54",
            "tgt_ix": "39-ARR_v2_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_55",
            "tgt_ix": "39-ARR_v2_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_56",
            "tgt_ix": "39-ARR_v2_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_57",
            "tgt_ix": "39-ARR_v2_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_58",
            "tgt_ix": "39-ARR_v2_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_59",
            "tgt_ix": "39-ARR_v2_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_60",
            "tgt_ix": "39-ARR_v2_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_61",
            "tgt_ix": "39-ARR_v2_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_62",
            "tgt_ix": "39-ARR_v2_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_63",
            "tgt_ix": "39-ARR_v2_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_63",
            "tgt_ix": "39-ARR_v2_63@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_63",
            "tgt_ix": "39-ARR_v2_63@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_63",
            "tgt_ix": "39-ARR_v2_63@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_64",
            "tgt_ix": "39-ARR_v2_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_65",
            "tgt_ix": "39-ARR_v2_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_65",
            "tgt_ix": "39-ARR_v2_65@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_66",
            "tgt_ix": "39-ARR_v2_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_67",
            "tgt_ix": "39-ARR_v2_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_68",
            "tgt_ix": "39-ARR_v2_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_69",
            "tgt_ix": "39-ARR_v2_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_70",
            "tgt_ix": "39-ARR_v2_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_70",
            "tgt_ix": "39-ARR_v2_70@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_70",
            "tgt_ix": "39-ARR_v2_70@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_70",
            "tgt_ix": "39-ARR_v2_70@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_71",
            "tgt_ix": "39-ARR_v2_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_71",
            "tgt_ix": "39-ARR_v2_71@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_72",
            "tgt_ix": "39-ARR_v2_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_72",
            "tgt_ix": "39-ARR_v2_72@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_72",
            "tgt_ix": "39-ARR_v2_72@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_72",
            "tgt_ix": "39-ARR_v2_72@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_73",
            "tgt_ix": "39-ARR_v2_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_74",
            "tgt_ix": "39-ARR_v2_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_74",
            "tgt_ix": "39-ARR_v2_74@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_74",
            "tgt_ix": "39-ARR_v2_74@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_74",
            "tgt_ix": "39-ARR_v2_74@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_74",
            "tgt_ix": "39-ARR_v2_74@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_74",
            "tgt_ix": "39-ARR_v2_74@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_74",
            "tgt_ix": "39-ARR_v2_74@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_74",
            "tgt_ix": "39-ARR_v2_74@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_74",
            "tgt_ix": "39-ARR_v2_74@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_74",
            "tgt_ix": "39-ARR_v2_74@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_74",
            "tgt_ix": "39-ARR_v2_74@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_74",
            "tgt_ix": "39-ARR_v2_74@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_75",
            "tgt_ix": "39-ARR_v2_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_76",
            "tgt_ix": "39-ARR_v2_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_77",
            "tgt_ix": "39-ARR_v2_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_77",
            "tgt_ix": "39-ARR_v2_77@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_77",
            "tgt_ix": "39-ARR_v2_77@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_78",
            "tgt_ix": "39-ARR_v2_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_79",
            "tgt_ix": "39-ARR_v2_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_80",
            "tgt_ix": "39-ARR_v2_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_80",
            "tgt_ix": "39-ARR_v2_80@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_80",
            "tgt_ix": "39-ARR_v2_80@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_81",
            "tgt_ix": "39-ARR_v2_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_82",
            "tgt_ix": "39-ARR_v2_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_83",
            "tgt_ix": "39-ARR_v2_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_84",
            "tgt_ix": "39-ARR_v2_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_84",
            "tgt_ix": "39-ARR_v2_84@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_85",
            "tgt_ix": "39-ARR_v2_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_86",
            "tgt_ix": "39-ARR_v2_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_86",
            "tgt_ix": "39-ARR_v2_86@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_86",
            "tgt_ix": "39-ARR_v2_86@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_86",
            "tgt_ix": "39-ARR_v2_86@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_86",
            "tgt_ix": "39-ARR_v2_86@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_86",
            "tgt_ix": "39-ARR_v2_86@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_87",
            "tgt_ix": "39-ARR_v2_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_88",
            "tgt_ix": "39-ARR_v2_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_88",
            "tgt_ix": "39-ARR_v2_88@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_89",
            "tgt_ix": "39-ARR_v2_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_89",
            "tgt_ix": "39-ARR_v2_89@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_89",
            "tgt_ix": "39-ARR_v2_89@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_89",
            "tgt_ix": "39-ARR_v2_89@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_89",
            "tgt_ix": "39-ARR_v2_89@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_89",
            "tgt_ix": "39-ARR_v2_89@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_89",
            "tgt_ix": "39-ARR_v2_89@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_89",
            "tgt_ix": "39-ARR_v2_89@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_90",
            "tgt_ix": "39-ARR_v2_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_90",
            "tgt_ix": "39-ARR_v2_90@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_90",
            "tgt_ix": "39-ARR_v2_90@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_90",
            "tgt_ix": "39-ARR_v2_90@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_91",
            "tgt_ix": "39-ARR_v2_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_92",
            "tgt_ix": "39-ARR_v2_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_93",
            "tgt_ix": "39-ARR_v2_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_93",
            "tgt_ix": "39-ARR_v2_93@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_93",
            "tgt_ix": "39-ARR_v2_93@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_94",
            "tgt_ix": "39-ARR_v2_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_94",
            "tgt_ix": "39-ARR_v2_94@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_94",
            "tgt_ix": "39-ARR_v2_94@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_94",
            "tgt_ix": "39-ARR_v2_94@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_95",
            "tgt_ix": "39-ARR_v2_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_95",
            "tgt_ix": "39-ARR_v2_95@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_96",
            "tgt_ix": "39-ARR_v2_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_97",
            "tgt_ix": "39-ARR_v2_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_97",
            "tgt_ix": "39-ARR_v2_97@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_97",
            "tgt_ix": "39-ARR_v2_97@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_97",
            "tgt_ix": "39-ARR_v2_97@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_98",
            "tgt_ix": "39-ARR_v2_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_99",
            "tgt_ix": "39-ARR_v2_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_100",
            "tgt_ix": "39-ARR_v2_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_101",
            "tgt_ix": "39-ARR_v2_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_102",
            "tgt_ix": "39-ARR_v2_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_103",
            "tgt_ix": "39-ARR_v2_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_104",
            "tgt_ix": "39-ARR_v2_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_105",
            "tgt_ix": "39-ARR_v2_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_106",
            "tgt_ix": "39-ARR_v2_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_107",
            "tgt_ix": "39-ARR_v2_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_108",
            "tgt_ix": "39-ARR_v2_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_109",
            "tgt_ix": "39-ARR_v2_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_110",
            "tgt_ix": "39-ARR_v2_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_111",
            "tgt_ix": "39-ARR_v2_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_112",
            "tgt_ix": "39-ARR_v2_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_113",
            "tgt_ix": "39-ARR_v2_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_114",
            "tgt_ix": "39-ARR_v2_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_115",
            "tgt_ix": "39-ARR_v2_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_116",
            "tgt_ix": "39-ARR_v2_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_117",
            "tgt_ix": "39-ARR_v2_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_118",
            "tgt_ix": "39-ARR_v2_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_119",
            "tgt_ix": "39-ARR_v2_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_120",
            "tgt_ix": "39-ARR_v2_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_121",
            "tgt_ix": "39-ARR_v2_121@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_122",
            "tgt_ix": "39-ARR_v2_122@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_123",
            "tgt_ix": "39-ARR_v2_123@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_124",
            "tgt_ix": "39-ARR_v2_124@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_125",
            "tgt_ix": "39-ARR_v2_125@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_126",
            "tgt_ix": "39-ARR_v2_126@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_127",
            "tgt_ix": "39-ARR_v2_127@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_128",
            "tgt_ix": "39-ARR_v2_128@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_129",
            "tgt_ix": "39-ARR_v2_129@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_130",
            "tgt_ix": "39-ARR_v2_130@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_131",
            "tgt_ix": "39-ARR_v2_131@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_132",
            "tgt_ix": "39-ARR_v2_132@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_133",
            "tgt_ix": "39-ARR_v2_133@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_134",
            "tgt_ix": "39-ARR_v2_134@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_135",
            "tgt_ix": "39-ARR_v2_135@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_136",
            "tgt_ix": "39-ARR_v2_136@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_137",
            "tgt_ix": "39-ARR_v2_137@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "39-ARR_v2_138",
            "tgt_ix": "39-ARR_v2_138@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 877,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "doc_id": "39-ARR",
        "version": 2
    }
}