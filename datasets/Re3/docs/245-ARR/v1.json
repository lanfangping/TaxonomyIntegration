{
    "nodes": [
        {
            "ix": "245-ARR_v1_0",
            "content": "MetaWeighting: Learning to Weight Tasks in Multi-Task Text Classification",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_2",
            "content": "Task weighting, which assigns weights on the including tasks during training, significantly matters the performance of Multi-task Learning (MTL); thus, recently, there has been an explosive interest in it. However, existing task weighting methods assign weights only based on the training loss, while ignoring the gap between the training loss and generalization loss. It degenerates MTL's performance. To address this issue, the present paper proposes a novel task weighting algorithm, which automatically weights the tasks via a learning-tolearn paradigm, referred to as MetaWeighting. Extensive experiments are conducted to validate the superiority of our proposed method in multi-task text classification.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "245-ARR_v1_4",
            "content": "Multi-task Learning (MTL) simultaneously learns multiple related tasks and aims to achieve better performance than learning each task independently (Caruana, 1993;Baxter, 2000). It has achieved great success in various applications; especially, in the text classification context, MTL can significantly outperform single task learning (Liu et al., 2017;Mao et al., 2021).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_5",
            "content": "In MTL, it is common for the including tasks to be competing. If we cannot properly balance these tasks, some tasks might dominate the training process and hurt the performance of other tasks, a phenomenon known as task imbalance. To address the task imbalance, the most widely used method is task weighting, which adaptively assigns weights on the tasks during training to balance their impacts. Various task weighting methods have been proposed and can be used in multi-task text classification, such as (Kendall et al., 2018;Sener and Koltun, 2018;Chen et al., 2018).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_6",
            "content": "However, existing task weighting methods compute the task weights only based on training losses or corresponding gradients. They ignore the gap between the training loss and generalization loss.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_7",
            "content": "To illustrate this gap, we report observations of our four-task topic classification experiment in Figure 1. The detailed experimental settings are introduced in the experiment section. Figure 1 demonstrates that training losses and generalization losses (estimated by the test losses) have different magnitudes; moreover, they have different patterns, such as a task might have largest training loss but have the lowest generalization loss among the tasks. This gap causes a mismatch between the task weights and tasks' generalization performance, which reduces effectiveness of the task weighting. To tackle this issue, this paper proposes a novel task weighting method based on a bi-level optimization problem, which aims to find task weights that explicitly optimize the generalization performance. Our proposed method computes task weights by solving this bi-level optimization problem and performs in a learning-to-learn manner; thus, dubbed MetaWeighting. MetaWeighting can improve the performance of multi-task text classification.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_8",
            "content": "To verify our theoretical analysis and validate the superiority of MetaWeighting, we conduct experiments on two classical text classification problems: sentiment analysis (on reviews) and topic classification (on news). The results demonstrate that MetaWeighting outperforms several state-of-the-art multi-task text classification methods.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_9",
            "content": "Related Works",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "245-ARR_v1_10",
            "content": "Existing task weighting strategies can be divided into two categories: weight adaptation methods and Pareto Optimization (PO)-based methods. The weight adaptation methods adaptively adjust the tasks' weights during training based on pre-defined heuristic, such as uncertainty (Kendall et al., 2018), task difficulty prioritization (Guo et al., 2018), gradient normalization (Chen et al., 2018), weight average (Liu et al., 2019) and task variance regularization (Mao et al., 2021). These methods only use training losses or their gradients to compute task weights while ignores the gap between the training loss and generalization loss.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_11",
            "content": "Besides, the PO-based methods formulate MTL as a multi-objective optimization problem and aim to find an arbitrary Pareto stationary solution (Sener and Koltun, 2018;Mahapatra and Rajan, 2020;Lin et al., 2020;Mao et al., 2020). However, in these methods, the learning objectives only involve training losses; thus, they can only achieve Pareto stationary points w.r.t training losses. They also ignore the gap between the training loss and generalization loss. Moreover, proposes that the PO-based methods can be also regarded as weight adaptation methods for they optimize the weighted sum of training losses as well.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_12",
            "content": "Overlooking the gap between the training loss and generalization loss would degenerate the performance of MTL. This paper proposes a novel task weighting method to solve this issue.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_13",
            "content": "Preliminaries",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "245-ARR_v1_14",
            "content": "L q t (\u03b8, D q t ) = 1 |D q t | (xt,yt)\u2208D q t l(h(x t , \u03b8 s , \u03b8 t ), y t ).",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_15",
            "content": "Hypergradient Descent",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "245-ARR_v1_16",
            "content": "Hypergradient Descent (HD) (Almeida et al., 1998;Baydin et al., 2018) provides an efficient way to apply gradient descent on hyper-parameters. Here, we take learning rate's HD as an example to introduce the basic form of HD. Given an objective function f (\u03b8) and previous parameters \u03b8 k\u22121 , gradient descent-based learning typically evaluates the gradient \u2207f (\u03b8 k\u22121 ) and moves against it to arrive at updated parameters",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_17",
            "content": "\u03b8 k = \u03b8 k\u22121 \u2212 \u03b7\u2207f (\u03b8 k\u22121 ),(1)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_18",
            "content": "where \u03b7 is the learning rate. HD derives an update rule for the learning rate \u03b7 itself. Based on Eq. ( 1) and the chain rule, we have",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_19",
            "content": "\u2202f (\u03b8 k ) \u2202\u03b7 = \u2207f (\u03b8 k ) \u2022 \u2202(\u03b8 k\u22121 \u2212\u03b7\u2207f (\u03b8 k\u22121 )) \u2202\u03b7 = \u2207f (\u03b8 k ) \u2022 (\u2212\u2207f (\u03b8 k\u22121 )),(2)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_20",
            "content": "with which we construct a update rule for \u03b7:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_21",
            "content": "\u03b7 k+1 = \u03b7 k + \u03b2\u2207f (\u03b8 k ) \u2022 \u2207f (\u03b8 k\u22121 ),(3)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_22",
            "content": "introducing \u03b2 as the hypergradient step size. In this paper, we extend HD to a bi-level multi-objective optimization problem.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_23",
            "content": "Common Descent Direction for Multiple Objectives",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "245-ARR_v1_24",
            "content": "When using gradient descent to jointly optimize multiple optimization objectives, we need to find a descent direction common to all the objectives. Based on the descent direction for each objective, (D\u00e9sid\u00e9ri, 2012) proposes a way to obtain the common descent direction, as in Theorem 1. This paper proposes a method to simultaneously optimize the tasks' generalization loss based on Theorem 1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_25",
            "content": "Theorem 1 ( (D\u00e9sid\u00e9ri, 2012)). Let A be a Hilbert space of finite or infinite dimension N . Let f i (z) (1 \u2264 i \u2264 n \u2264 N ) be n smooth functions of the vector z \u2208 A. and z 0 a particular admissible designpoint, at which the gradient-vectors are denoted g i = \u2207f i (z 0 ), and",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_26",
            "content": "U = {a \u2208 A|a = n i=1 \u03bbigi; \u03bbi > 0(\u2200i); n i=1 \u03bbi = 1}. (4)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_27",
            "content": "Let a * = arg min a\u2208 \u016a a , where U consists of the convex hull and closure of U. Then, if a * = 0, a * is a descent direction common to all the objectives.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_28",
            "content": "4 MetaWeighting for MTL",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_29",
            "content": "Gap Between Task Weighting and Generalization Performance",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "245-ARR_v1_30",
            "content": "MTL aims to improve the generalization performance of all the including tasks, which can be formulated via the following optimization problem.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_31",
            "content": "min \u03b8 L(\u03b8) = (L 1 (\u03b8), ..., L T (\u03b8)) ,(5)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_32",
            "content": "By contrast, existing task weighting strategies train a MTL model via the following objective.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_33",
            "content": "min \u03b8 1 T w t L tr t (\u03b8, D t ),(6)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_34",
            "content": "where the w t is adaptive during training and only depends on the training losses or their gradients.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_35",
            "content": "As the neural networks are usually heavily overparameterized (Allen-Zhu et al., 2019), the training losses cannot properly estimate the generalization losses. Thus, existing task weighting strategies, which tunes weights only based on the training losses, overlook the generalization losses. Obviously, there is a gap between these task weighting strategies and the generalization performance of MTL.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_36",
            "content": "MetaWeighting Problem",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "245-ARR_v1_37",
            "content": "To narrow the gap between task weighting strategies and generalization performance, we propose to automatically learn task weights that can reduce the generalization losses, namely learning to weight. This learning to weight problem is formlated via the following bi-level optimization problem, dubbed MetaWeighting.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_38",
            "content": "Problem 1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_39",
            "content": "min w (L 1 (\u03b8 * (w)), ..., L T (\u03b8 * (w))) s.t. \u03b8 * (w) = arg min \u03b8 1 T T t=1 w t L tr t (\u03b8, D t )(7)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_40",
            "content": "where w = (w 1 , w 2 , ..., w T ). This bi-level optimization problem combines ( 5) and ( 6) together, by solving which we can obtain task weights that benefit the generalization performance of MTL.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_41",
            "content": "However, the generalization loss is agnostic. To properly estimate the generalization loss, we randomly divide the training set D t into two subsets: support set D s t and query set D q t , where D s t is used to train a MTL model, and D q t is used to estimate generalization loss of the MTL model. In Section 5, we theoretically demonstrate that query loss is a good estimator for the generalization loss; besides, in Section 6.7, experimental analysis also supports that query loss is a good estimator.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_42",
            "content": "Based on the support-query split, the MetaWeighting problem is transformed into the following form.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_43",
            "content": "Problem 2. min w (L q 1 (\u03b8 * (w), D q 1 ), ..., L q T (\u03b8 * (w), D q T )) s.t. \u03b8 * (w) = arg min \u03b8 1 T T t=1 w t L s t (\u03b8, D s t )(8)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_44",
            "content": "MetaWeighting Algorithm",
            "ntype": "title",
            "meta": {
                "section": "4.3"
            }
        },
        {
            "ix": "245-ARR_v1_45",
            "content": "In the MetaWeighting problem, the inner optimization objective is embedded within the outer optimization objective. In MTL, the inner optimization objective is to minimize the weighted sum of task-specific training losses, which is typically optimized by means of iterative gradient descent; thus, Problem 2 can be formulated by the following problem in the k th learning iteration.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_46",
            "content": "Problem 3.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_47",
            "content": "min w (L q 1 (\u03b8 k , D q 1 ), ..., L q T (\u03b8 k , D q T )) s.t. \u03b8 k = \u03b8 k\u22121 \u2212 \u03b7 T T t=1 w t \u2207 \u03b8 L s t (\u03b8 k\u22121 , D s t )(9)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_48",
            "content": "To solve Problem 3, we adopt the Hypergradient Descent (HD) method. However, the original HD method (Almeida et al., 1998;Baydin et al., 2018) is proposed for single objective optimization, which can not used in our problem where a multiobjective optimization problem involves. In this section, this paper proposes a novel HD method for the multi-objective optimization setting, as in the following sections.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_49",
            "content": "Task-Specific Descent Direction",
            "ntype": "title",
            "meta": {
                "section": "4.3.1"
            }
        },
        {
            "ix": "245-ARR_v1_50",
            "content": "The learning objective of Problem 3 involves T objectives. We aim to find a gradient direction, moving against which all the objective can be optimized. To find this gradient direction, we first find the hypergradient direction w.r.t w (denoted as d t ) for each task. d t is computed by the following equation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_51",
            "content": "d t = \u2202L q t (\u03b8 k , D q t ) \u2202w = \u2207 \u03b8 L q t (\u03b8 k , D q t ) \u2022 \u2202\u03b8 k \u2202w = \u2212 \u03b7 T \u2207 \u03b8 L q t (\u03b8 k , D q t )\u2207 \u03b8 L s (\u03b8 k\u22121 , D s ). (10",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_52",
            "content": ")",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_53",
            "content": "where",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_54",
            "content": "\u2207 \u03b8 L s (\u03b8 k\u22121 , D s ) = (\u2207 \u03b8 L s 1 (\u03b8 k\u22121 , D s 1 ) , ..., \u2207 \u03b8 L s T (\u03b8 k\u22121 , D s T )",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_55",
            "content": "). Moving against d t , the generalization loss of task t can be optimized.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_56",
            "content": "Common Descent Direction",
            "ntype": "title",
            "meta": {
                "section": "4.3.2"
            }
        },
        {
            "ix": "245-ARR_v1_57",
            "content": "Base on d t , in this section, we find a common gradient direction, moving against which all the objective can be optimized. Let d = (d 1 , d 2 , ..., d T ) and d c be the common gradient direction. Theorem 1 presents that the following Eq. ( 11) is a common descent direction.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_58",
            "content": "d c = \u03bb * d (11",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_59",
            "content": ")",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_60",
            "content": "where",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_61",
            "content": "\u03bb * = arg min \u03bb { \u03bbd 2 2 |\u03bb1 = 1, \u03bb 0},(12)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_62",
            "content": "where 1 = (1, 1, ..., 1). Eq. ( 12) is a typical minimum Euclidean-norm point problem. We here adopt the widely used Frank-Wolfe optimization algorithm (Jaggi, 2013), a minimum-norm-point algorithm, to solve it. The Frank-Wolfe optimization algorithm is presented in Algorithm 2.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_63",
            "content": "MetaWeighting",
            "ntype": "title",
            "meta": {
                "section": "4.3.3"
            }
        },
        {
            "ix": "245-ARR_v1_64",
            "content": "Moving against d c , all the objective can be optimized; thus, the update rule of w is",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_65",
            "content": "w k+1 = w k \u2212 \u03b1d c . (13",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_66",
            "content": ")",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_67",
            "content": "where \u03b1 is the step size. Based on this update rule, the task weights are automatically learnt oriented by optimizing the generalization losses. Overall, we propose the MetaWeighting algorithm, which is presented in algorithmic form in Algorithm 1: MetaWeighting Algorithm Input: data {D s t } T t=1 and {D q t } T t=1 , step size \u03b1 for updating w, Number of learning iterations K. Initialize: w 0 = (1, 1, ..., 1), \u03b8 0 , \u03b7.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_68",
            "content": "for k = 1 to K do \u03b8 k = \u03b8 k\u22121 \u2212 \u03b7 T T t=1 w t \u2207 \u03b8 L s t (\u03b8 k\u22121 , D s t ). for t = 1 to T do d t = \u2212 \u03b7 T \u2207 \u03b8 L q t (\u03b8 k , D q t )\u2207 \u03b8 L s (\u03b8 k\u22121 , D s ). end for d = (d 1 , d 2 , ..., d T ) \u03bb * = arg min \u03bb { \u03bbd 2 2 |\u03bb1 = 1, \u03bb 0} (calls Algorithm 2). d c = \u03bb * d . w k+1 = w k \u2212 \u03b1d c . end for Algorithm 2: Frank-Wolfe Algorithm Input: Number of Iterations N . Initialize: \u03bb 0 = [ 1 T , ..., 1 T ]. B = d d. for i = 0 to N do v = arg min v\u2208{v 1=1,v 0} v B\u03bb. \u03b3 = arg min \u03b3\u2208[0,1] (\u03bb i +\u03b3(v \u2212\u03bb i )) B(\u03bb i +\u03b3(v \u2212\u03bb i )).",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_69",
            "content": "\u03bb i+1 = (1 \u2212 \u03b3)\u03bb i + \u03b3v. end for return: \u03bb N Algorithm 1. Our proposed method bridges the gap between task weighting and generalization performance of MTL.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_70",
            "content": "Theoretical Analysis",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "245-ARR_v1_71",
            "content": "In this section, we study the generalization error bound for MTL; furthermore, we compare the bound w.r.t training loss and the bound w.r.t the query loss. The comparison presents that the query loss is a more accurate estimation of the generalization loss than the training loss.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_72",
            "content": "Firstly, we derive the generalization error bound w.r.t training loss for MTL.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_73",
            "content": "Theorem 2. Assume we have n training samples for each task. Let \u03c3 = {{\u03c3 t i } n i=1 } T t=1 be a sequence of binary random variables such that each \u03c3 t i = \u00b11 is independent with probability 1/2. Then, \u2200\u03b4 \u2208 [0, 1], for all h(\u2022, \u03b8 s , \u03b8 1 , ..., \u03b8 T ) \u2208 H, with probability of at least 1 \u2212 \u03b4:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_74",
            "content": "1 T T t=1 (L t (\u03b8) \u2212 L tr t (\u03b8, D t )) \u2264 2R(l \u2022 H \u2022 D) + 4 2 log(4/\u03b4) T n . (14) where R(l\u2022H\u2022D) = E \u03c3 sup \u03b8 ( 1 T n T t=1 n i=1 \u03c3 t i l(h(x t i , \u03b8), y t i ).",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_75",
            "content": "(15) is the Rademacher complexity for MTL.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_76",
            "content": "Proof. The proof is provided in Appendix A.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_77",
            "content": "Next, we derive the generalization error bound w.r.t query loss for MTL.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_78",
            "content": "Theorem 3. Assume we have m training samples for each task. \u2200\u03b4 \u2208 [0, 1], with probability of at least 1 \u2212 \u03b4, for all h(\u2022, \u03b8 s , \u03b8 1 , ..., \u03b8 T ) \u2208 H, we have",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_79",
            "content": "1 T T t=1 (L t (\u03b8) \u2212 L q t (\u03b8, D q t )) \u2264 log(2/\u03b4) 2m .(16)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_80",
            "content": "Proof. The proof is provided in Appendix A.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_81",
            "content": "Comparing the bound ( 14) and ( 16), we can find that the upper bound for the query loss is tighter than that for the training loss. Taking m to be order of n, the query loss is a more accurate estimate of the generalization loss than the training loss by a factor that depends on the Rademacher complexity.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_82",
            "content": "Experiments",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "245-ARR_v1_83",
            "content": "In this section, we perform experimental studies on sentiment analysis to evaluate the performance of our proposed MetaWeighting and verify our theoretical analysis. The implementation is based on PyTorch (Paszke et al., 2019). The code is attached in the supplementary materials.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_84",
            "content": "Datasets",
            "ntype": "title",
            "meta": {
                "section": "6.1"
            }
        },
        {
            "ix": "245-ARR_v1_85",
            "content": "Sentiment Analysis 1 . We evaluate our algorithm on product reviews from Amazon. The dataset (Blitzer et al., 2007) contains product reviews from 14 domains, including books, DVDs, electronics, kitchen appliances and so on. We consider each domain as a binary classification task. Reviews with rating > 3 were labeled positive, those with rating < 3 were labeled negative, reviews with rating = 3 are discarded as the sentiments were ambiguous and hard to predict.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_86",
            "content": "Topic Classification 2 . We select 16 newsgroups from the 20 Newsgroup dataset, which is a collection of approximately 20,000 newsgroup documents that is partitioned (nearly) evenly across 20 different newsgroups, then formulate them into four 4-class classification tasks (as shown in Table 1) to evaluate the performance of our algorithm on topic classification.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_87",
            "content": "Baselines",
            "ntype": "title",
            "meta": {
                "section": "6.2"
            }
        },
        {
            "ix": "245-ARR_v1_88",
            "content": "We compare MASS-MTL with following baselines.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_89",
            "content": "Single-Task Learning (STL): learning each task independently.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_90",
            "content": "Uniform: learning tasks simultaneously using uniform task weights.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_91",
            "content": "Uncertainty: using the uncertainty weighting method proposed by (Kendall et al., 2018).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_92",
            "content": "GradNorm: using the gradient normalization method proposed by (Chen et al., 2018).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_93",
            "content": "MGDA: using the MGDA-UB method proposed by (Sener and Koltun, 2018).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_94",
            "content": "AdvMTL: using the adversarial Multi-task Learning method proposed by (Liu et al., 2017).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_95",
            "content": "TchebycheffAdv: using the Adversarial Tchebycheff procedure proposed by (Mao et al., 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_96",
            "content": "BanditMTL: using the BanditMTL method proposed by (Mao et al., 2021).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_97",
            "content": "Experimental Settings",
            "ntype": "title",
            "meta": {
                "section": "6.3"
            }
        },
        {
            "ix": "245-ARR_v1_98",
            "content": "We adopt the hard parameter-sharing MTL framework (Mao et al., 2021), where the shared representation extractor is built with TextCNN or BERT; besides, the task-specific module is formulated by means of one fully connected layer ending with a softmax function. For TextCNN, we adopt Pretrained GloVe (Pennington et al., 2014) word embeddings. For BERT, we adopt the pre-trained BERT-base model (uncased) provided by Hugging Each colored cluster illustrates the classification accuracy performance of a method over 10 runs. Our proposed MetaWeighting outperforms all baselines on ten of the fourteen tasks; besides, its average performance is superior to that of all baselines. Face (Wolf et al., 2020). We set \u03b1 to be 0.1 and 0.5 for sentiment analysis and topic classification respectively, and the query-split radio (radio of query samples to entire training samples) to be 0.1 for both sentiment analysis and topic classification. The detailed experimental settings are introduced in the Appendix B.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_99",
            "content": "U n if o r m A d v M T L M G D A G r a d N o r m U n c e",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_100",
            "content": "Classification Performance",
            "ntype": "title",
            "meta": {
                "section": "6.4"
            }
        },
        {
            "ix": "245-ARR_v1_101",
            "content": "We compare the proposed MetaWeighting with the baselines and report the results over 10 runs by plotting the classification accuracy of each task for both sentiment analysis and topic classification. 3. Due to space limitations, we provide the results for BERT in the Appendix C. All experimental results show that our proposed MetaWeighting outperforms all baselines and achieves state-of-the-art performance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_102",
            "content": "The Impact of Query-Split Radio",
            "ntype": "title",
            "meta": {
                "section": "6.5"
            }
        },
        {
            "ix": "245-ARR_v1_103",
            "content": "Let n be the size of the entire training set and m be the size of the query set. We define the querysplit radio as \u03c1 = m n to indicate the radio of query samples to the entire training samples. From the theoretical analysis of Section 5, we can see that the query loss can estimate generalization loss more accurately when \u03c1 increases, but increasing \u03c1 would hurt the training process for the size of support set decreases. Therefore, \u03c1 faces a trade-off between the performance estimation of generalization loss and training performance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_104",
            "content": "To investigate the impact of \u03c1, we record the changes in MetaWeighting's average classification accuracy w.r.t different values of \u03c1 in Fig. 4, where each boxplot visually illustrates the distribution of results over ten runs through displaying the data quartiles (first quartile and third quartile), minimum/maximum value and median. These experiments are conducted based on TextCNN. In this figure, as \u03c1 increases, the average accuracy of MetaWeighting first increases and then decreases. It verifies our theoretical analysis. For both sentiment analysis and topic classification, setting \u03c1 = 0.1 provides satisfactory results.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_105",
            "content": "Sensitive Study on \u03b1",
            "ntype": "title",
            "meta": {
                "section": "6.6"
            }
        },
        {
            "ix": "245-ARR_v1_106",
            "content": "In MetaWeighting, the step size \u03b1 is a hyperparameter. To determine whether the performance of MetaWeighting is sensitive to \u03b1, we conduct experiments on the classification accuracy performance of MetaWeighting w.r.t different values of \u03b1 based on the TextCNN model. The results of these experiments are presented in Figure 5 (boxplots over ten runs). As the figure shows, the performance of our proposed method is not very sensitive to \u03b1 when \u03b1 is within the range of 0.05 to 0.1 for sentiment analysis and 0.1 to 0.5 for topic classification. The results demonstrate that MetaWeighting can work well in a wide range of \u03b1 values.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_107",
            "content": "The Gap between the Training Loss, Query Loss and Generalization Loss",
            "ntype": "title",
            "meta": {
                "section": "6.7"
            }
        },
        {
            "ix": "245-ARR_v1_108",
            "content": "To experimentally verify that the query loss is a good estimator for generalization loss, we record the generalization loss (estimated by test loss), query loss and training loss for each task during training and report the results in Fig. 7 and 6 for sentiment analysis and topic classification respectively. From these figures, we can see that there is a large gap between the training and generalization loss, and the gap between the query and generalization loss is smaller than that between the training and generalization loss. The results verify our theoretical analysis in Section 5; furthermore, they experimentally support our motivation for MetaWeighting. In this section, TextCNN is used, and tasks have uniform weights during training. Fig. 1 is obtained under this setting as well.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_109",
            "content": "The Evolution of Task Weights",
            "ntype": "title",
            "meta": {
                "section": "6.8"
            }
        },
        {
            "ix": "245-ARR_v1_110",
            "content": "In this section, we observe the changes in task weights in the training process of MetaWeighting and compare these changes with four baselines (Uncertainty, Gradnorm, MGDA and BanditMTL). The results for sentiment analysis and topic classification are reported in Fig. 8 and 9 respectively. Due to space limitations, for sentiment analysis, we only report the results of the first four tasks here, and the results of the other ten tasks are presented in the Appendix D.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_111",
            "content": "From these figures, we can see that the weight adaption process of MetaWeighting is different with that of Uncertainty, Gradnorm, MGDA and BanditMTL. In MetaWeighting, the task weights are automatically learnt, and there is no pre-defined heuristic involved. It is verified by the evolution curves of task weights for MetaWeighting illustrated in Fig. 8 and 9, which fluctuate without any regular patterns.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_112",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "7"
            }
        },
        {
            "ix": "245-ARR_v1_113",
            "content": "This paper presents that the gap between the training loss and the generalization loss, which is overlooked by existing task weighting methods, is nonnegligible; furthermore, to narrow this gap, a novel task weighting method (dubbed MetaWeighting) is proposed. MetaWeighting works in a learningto-learn manner, which automatically learns the task weights without any pre-defined heuristic and achieves state-of-the-art performance. It has the potential to forge new trends in task weighting research.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_114",
            "content": "A Proof of the Theorem 2 and Theorem 3 Lemma 1 (McDiarmid's Inequality). Let V be some set and let f : V n \u2192 R be a function of n variables such that for some c > 0 , for all i \u2208 [n] and for all z 1 , ..., z n , z i \u2208 V we have",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_115",
            "content": "|f (z 1 , ..., z n )\u2212f (z 1 , ..., z i\u22121 , z i , z i+1 , ..., z n )| \u2264 c.",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_116",
            "content": "(17) Let Z 1 , ..., Z n be n independent random variables taking values in V . Then, with probability of at least 1 \u2212 \u03b4 we have",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_117",
            "content": "|f (Z 1 , ..., Z n )\u2212E[f (Z 1 , ..., Z n )]| \u2264 c n log(2/\u03b4) 2 . (18",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_118",
            "content": ")",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_119",
            "content": "Lemma 2 (Hoeffding's Inequality). Let z 1 , ..., z m be a a sequence of i.i.d. random variables and assume that for all i, E(z i ) = \u00b5 and P (a \u2264 z i \u2264 b) = 1. Then, for any > 0",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_120",
            "content": "In our setting, l(\u2022, \u2022) : Y t \u00d7 Y t \u2192 [0, 1], then c = 1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_121",
            "content": "We have",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_122",
            "content": "1 T T t=1 (L t (\u03b8) \u2212 L tr t (\u03b8, D t )) \u2264 2R(l \u2022 H \u2022 D) + 4 2 log(4/\u03b4) T n . (30",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_123",
            "content": ")",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_124",
            "content": "We conclude our proof.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_125",
            "content": "Based on the Hoeffding's Inequality (Lemma 2), we have the following theorem.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_126",
            "content": "Proof of Theorem 3.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_127",
            "content": "Proof. Based on the Hoeffding's Inequality (Lemma 2) and l(",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_128",
            "content": "\u2022, \u2022) : Y t \u00d7 Y t \u2192 [0, 1], for each h(\u2022, \u03b8 s , \u03b8 t ) \u2208 H t , we have P [|L t (\u03b8) \u2212 L q t (\u03b8, D t )| > ] \u2264 2exp(\u22122m 2 ).",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_129",
            "content": "(31) Then, with probability of at least 1\u22122exp(\u22122m 2 ), we have",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_130",
            "content": "|L t (\u03b8) \u2212 L q t (\u03b8, D t )| \u2264 .(32)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_131",
            "content": "Let \u03b4 = 2exp(\u22122m 2 ), we have that with probability of at least 1 \u2212 \u03b4,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_132",
            "content": "|L t (\u03b8) \u2212 L q t (\u03b8, D t )| \u2264 log(2/\u03b4) 2m .(33)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_133",
            "content": "Thus, for each task,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_134",
            "content": "L t (\u03b8) \u2212 L q t (\u03b8, D t ) \u2264 log(2/\u03b4) 2m . (34",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_135",
            "content": ")",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_136",
            "content": "Since the bound for each task are independent, we have",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_137",
            "content": "1 T T t=1 (L t (\u03b8) \u2212 L q t (\u03b8, D t )) \u2264 log(2/\u03b4) 2m .(35)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_138",
            "content": "We conclude our proof.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_139",
            "content": "We adopt the hard parameter-sharing MTL framework (Mao et al., 2021), where the shared representation extractor is built with TextCNN or BERT; besides, the task-specific module is formulated by means of one fully connected layer ending with a softmax function. The TextCNN module is structured with three parallel convolutional layers with kernels size of 3, 5, 7 respectively. For TextCNN, we adopt Pre-trained GloVe (Pennington et al., 2014) word embeddings. By contrast, the BERT module is formulated via a pre-trained BERT-base model provided by Hugging Face (Wolf et al., 2020), with a hidden size of 768, 12 Transformer blocks and 12 self-attention heads. We train the deep MTL network model in line with Algorithm 1. We set \u03b1 to be 0.1 and 0.5 for sentiment analysis and topic classification respectively, and the query-split radio (radio of query samples to entire training samples) to be 0.1 for both sentiment analysis and topic classification. We use the Adam optimizer (Kingma and Ba, 2015). We train over 3000 epochs for TextCNN and finetune over 50 epochs for BERT. For TextCNN, the learning rate is 1e \u2212 3 and the batch size is 256. For BERT, the learning rate is 2e \u2212 5 , the batch size is 32, and the max sequence length is 256. For the baselines, we search over the set {1e\u22125, 2e\u22125, 5e\u22125, 1e\u22124, 5e\u22124, 1e\u22123, 5e\u22123} learning rates and choose the model with best performance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_140",
            "content": "For the BERT-based MTL model, we compare the proposed MetaWeighting with the baselines and report the results over 10 runs by plotting the classification accuracy of each task for both sentiment analysis and topic classification in Fig. 10 and 11. AdvMTL and TchebycheffAdv are not available for BERT; thus, we do not compare with AdvMTL and compare with Tchebycheff which is Tcheby-cheffAdv without aversarial module (Mao et al., 2021). From these figures, we can see that our proposed MetaWeighting outperforms all baselines and achieves state-of-the-art performance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_141",
            "content": "Sentiment Analysis",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "245-ARR_v1_142",
            "content": "UNKNOWN, None, 1996, Weak convergence and empirical processes, Springer.",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": null,
                "title": null,
                "pub_date": "1996",
                "pub_title": "Weak convergence and empirical processes",
                "pub": "Springer"
            }
        },
        {
            "ix": "245-ARR_v1_143",
            "content": "UNKNOWN, None, 2019, Learning and generalization in overparameterized neural networks, going beyond two layers, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Learning and generalization in overparameterized neural networks, going beyond two layers",
                "pub": null
            }
        },
        {
            "ix": "245-ARR_v1_144",
            "content": "B Lu\u00eds, Thibault Almeida,  Langlois, D Jos\u00e9, Alexander Amaral,  Plakhov, Parameter adaptation in stochastic optimization, 1998, On-Line Learning in Neural Networks, Cambridge University Press.",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "B Lu\u00eds",
                    "Thibault Almeida",
                    " Langlois",
                    "D Jos\u00e9",
                    "Alexander Amaral",
                    " Plakhov"
                ],
                "title": "Parameter adaptation in stochastic optimization",
                "pub_date": "1998",
                "pub_title": "On-Line Learning in Neural Networks",
                "pub": "Cambridge University Press"
            }
        },
        {
            "ix": "245-ARR_v1_145",
            "content": "Jonathan Baxter, A model of inductive bias learning, 2000, Journal of artificial intelligence research, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Jonathan Baxter"
                ],
                "title": "A model of inductive bias learning",
                "pub_date": "2000",
                "pub_title": "Journal of artificial intelligence research",
                "pub": null
            }
        },
        {
            "ix": "245-ARR_v1_146",
            "content": "Robert Atilim Gunes Baydin, David Cornish, Mark Mart\u00ednez-Rubio, Frank Schmidt,  Wood, Online learning rate adaptation with hypergradient descent, 2018, ICLR, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Robert Atilim Gunes Baydin",
                    "David Cornish",
                    "Mark Mart\u00ednez-Rubio",
                    "Frank Schmidt",
                    " Wood"
                ],
                "title": "Online learning rate adaptation with hypergradient descent",
                "pub_date": "2018",
                "pub_title": "ICLR",
                "pub": null
            }
        },
        {
            "ix": "245-ARR_v1_147",
            "content": "John Blitzer, Mark Dredze, Fernando Pereira, Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification, 2007, ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "John Blitzer",
                    "Mark Dredze",
                    "Fernando Pereira"
                ],
                "title": "Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification",
                "pub_date": "2007",
                "pub_title": "ACL",
                "pub": null
            }
        },
        {
            "ix": "245-ARR_v1_148",
            "content": "Rich Caruana, Multitask learning: A knowledgebased source of inductive bias, 1993, ICML, .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "Rich Caruana"
                ],
                "title": "Multitask learning: A knowledgebased source of inductive bias",
                "pub_date": "1993",
                "pub_title": "ICML",
                "pub": null
            }
        },
        {
            "ix": "245-ARR_v1_149",
            "content": "Zhao Chen, Vijay Badrinarayanan, Chen-Yu Lee, Andrew Rabinovich, Gradnorm: Gradient normalization for adaptive loss balancing in deep multitask networks, 2018, ICML, .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Zhao Chen",
                    "Vijay Badrinarayanan",
                    "Chen-Yu Lee",
                    "Andrew Rabinovich"
                ],
                "title": "Gradnorm: Gradient normalization for adaptive loss balancing in deep multitask networks",
                "pub_date": "2018",
                "pub_title": "ICML",
                "pub": null
            }
        },
        {
            "ix": "245-ARR_v1_150",
            "content": "Jean-Antoine D\u00e9sid\u00e9ri, Multiple-gradient descent algorithm (mgda) for multiobjective optimization, 2012, Comptes Rendus Mathematique, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Jean-Antoine D\u00e9sid\u00e9ri"
                ],
                "title": "Multiple-gradient descent algorithm (mgda) for multiobjective optimization",
                "pub_date": "2012",
                "pub_title": "Comptes Rendus Mathematique",
                "pub": null
            }
        },
        {
            "ix": "245-ARR_v1_151",
            "content": "Michelle Guo, Albert Haque, De-An Huang, Serena Yeung, Li Fei-Fei, Dynamic task prioritization for multitask learning, 2018, ECCV, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Michelle Guo",
                    "Albert Haque",
                    "De-An Huang",
                    "Serena Yeung",
                    "Li Fei-Fei"
                ],
                "title": "Dynamic task prioritization for multitask learning",
                "pub_date": "2018",
                "pub_title": "ECCV",
                "pub": null
            }
        },
        {
            "ix": "245-ARR_v1_152",
            "content": "Martin Jaggi, Revisiting frank-wolfe: Projectionfree sparse convex optimization, 2013, ICML, .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Martin Jaggi"
                ],
                "title": "Revisiting frank-wolfe: Projectionfree sparse convex optimization",
                "pub_date": "2013",
                "pub_title": "ICML",
                "pub": null
            }
        },
        {
            "ix": "245-ARR_v1_153",
            "content": "Alex Kendall, Yarin Gal, Roberto Cipolla, Multi-task learning using uncertainty to weigh losses for scene geometry and semantics, 2018, CVPR, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Alex Kendall",
                    "Yarin Gal",
                    "Roberto Cipolla"
                ],
                "title": "Multi-task learning using uncertainty to weigh losses for scene geometry and semantics",
                "pub_date": "2018",
                "pub_title": "CVPR",
                "pub": null
            }
        },
        {
            "ix": "245-ARR_v1_154",
            "content": "UNKNOWN, None, 2015, Adam: A method for stochastic optimization, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": null,
                "title": null,
                "pub_date": "2015",
                "pub_title": "Adam: A method for stochastic optimization",
                "pub": null
            }
        },
        {
            "ix": "245-ARR_v1_155",
            "content": "UNKNOWN, None, 2020, Controllable pareto multi-task learning, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Controllable pareto multi-task learning",
                "pub": "CoRR"
            }
        },
        {
            "ix": "245-ARR_v1_156",
            "content": "Xi Lin, Hui-Ling Zhen, Zhenhua Li, Qingfu Zhang, Sam Kwong, Pareto multi-task learning, 2019, NIPS, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Xi Lin",
                    "Hui-Ling Zhen",
                    "Zhenhua Li",
                    "Qingfu Zhang",
                    "Sam Kwong"
                ],
                "title": "Pareto multi-task learning",
                "pub_date": "2019",
                "pub_title": "NIPS",
                "pub": null
            }
        },
        {
            "ix": "245-ARR_v1_157",
            "content": "Pengfei Liu, Xipeng Qiu, Xuanjing Huang, Adversarial multi-task learning for text classification, 2017, ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Pengfei Liu",
                    "Xipeng Qiu",
                    "Xuanjing Huang"
                ],
                "title": "Adversarial multi-task learning for text classification",
                "pub_date": "2017",
                "pub_title": "ACL",
                "pub": null
            }
        },
        {
            "ix": "245-ARR_v1_158",
            "content": "Shikun Liu, Edward Johns, Andrew Davison, End-to-end multi-task learning with attention, 2019, CVPR, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "Shikun Liu",
                    "Edward Johns",
                    "Andrew Davison"
                ],
                "title": "End-to-end multi-task learning with attention",
                "pub_date": "2019",
                "pub_title": "CVPR",
                "pub": null
            }
        },
        {
            "ix": "245-ARR_v1_159",
            "content": "Pingchuan Ma, Tao Du, Wojciech Matusik, Efficient continuous pareto exploration in multi-task learning, 2020, ICML, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Pingchuan Ma",
                    "Tao Du",
                    "Wojciech Matusik"
                ],
                "title": "Efficient continuous pareto exploration in multi-task learning",
                "pub_date": "2020",
                "pub_title": "ICML",
                "pub": null
            }
        },
        {
            "ix": "245-ARR_v1_160",
            "content": "Debabrata Mahapatra, Vaibhav Rajan, Multitask learning with user preferences: Gradient descent with controlled ascent in pareto optimization, 2020, ICML, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Debabrata Mahapatra",
                    "Vaibhav Rajan"
                ],
                "title": "Multitask learning with user preferences: Gradient descent with controlled ascent in pareto optimization",
                "pub_date": "2020",
                "pub_title": "ICML",
                "pub": null
            }
        },
        {
            "ix": "245-ARR_v1_161",
            "content": "Yuren Mao, Zekai Wang, Weiwei Liu, Xuemin Lin, Wenbin Hu, Banditmtl: Bandit-based multitask learning for text classification, 2021, ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "Yuren Mao",
                    "Zekai Wang",
                    "Weiwei Liu",
                    "Xuemin Lin",
                    "Wenbin Hu"
                ],
                "title": "Banditmtl: Bandit-based multitask learning for text classification",
                "pub_date": "2021",
                "pub_title": "ACL",
                "pub": null
            }
        },
        {
            "ix": "245-ARR_v1_162",
            "content": "Yuren Mao, Shuang Yun, Weiwei Liu, Bo Du, Tchebycheff procedure for multi-task text classification, 2020, ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Yuren Mao",
                    "Shuang Yun",
                    "Weiwei Liu",
                    "Bo Du"
                ],
                "title": "Tchebycheff procedure for multi-task text classification",
                "pub_date": "2020",
                "pub_title": "ACL",
                "pub": null
            }
        },
        {
            "ix": "245-ARR_v1_163",
            "content": "Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary Devito, Pytorch: An imperative style, high-performance deep learning library, 2019, NeurIPS, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "Adam Paszke",
                    "Sam Gross",
                    "Francisco Massa",
                    "Adam Lerer",
                    "James Bradbury",
                    "Gregory Chanan",
                    "Trevor Killeen",
                    "Zeming Lin",
                    "Natalia Gimelshein",
                    "Luca Antiga",
                    "Alban Desmaison",
                    "Andreas Kopf",
                    "Edward Yang",
                    "Zachary Devito"
                ],
                "title": "Pytorch: An imperative style, high-performance deep learning library",
                "pub_date": "2019",
                "pub_title": "NeurIPS",
                "pub": null
            }
        },
        {
            "ix": "245-ARR_v1_164",
            "content": "Jeffrey Pennington, Richard Socher, Christopher Manning, Glove: Global vectors for word representation, 2014, EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Jeffrey Pennington",
                    "Richard Socher",
                    "Christopher Manning"
                ],
                "title": "Glove: Global vectors for word representation",
                "pub_date": "2014",
                "pub_title": "EMNLP",
                "pub": null
            }
        },
        {
            "ix": "245-ARR_v1_165",
            "content": "UNKNOWN, None, 2018, Multitask learning as multi-objective optimization, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Multitask learning as multi-objective optimization",
                "pub": null
            }
        },
        {
            "ix": "245-ARR_v1_166",
            "content": "Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Clara Patrick Von Platen, Yacine Ma, Julien Jernite, Canwen Plu, Teven Xu, Sylvain Scao, Mariama Gugger, Quentin Drame, Alexander Lhoest,  Rush, Transformers: State-of-the-art natural language processing, 2020, EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Thomas Wolf",
                    "Lysandre Debut",
                    "Victor Sanh",
                    "Julien Chaumond",
                    "Clement Delangue",
                    "Anthony Moi",
                    "Pierric Cistac",
                    "Tim Rault",
                    "R\u00e9mi Louf",
                    "Morgan Funtowicz",
                    "Joe Davison",
                    "Sam Shleifer",
                    "Clara Patrick Von Platen",
                    "Yacine Ma",
                    "Julien Jernite",
                    "Canwen Plu",
                    "Teven Xu",
                    "Sylvain Scao",
                    "Mariama Gugger",
                    "Quentin Drame",
                    "Alexander Lhoest",
                    " Rush"
                ],
                "title": "Transformers: State-of-the-art natural language processing",
                "pub_date": "2020",
                "pub_title": "EMNLP",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "245-ARR_v1_0@0",
            "content": "MetaWeighting: Learning to Weight Tasks in Multi-Task Text Classification",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_0",
            "start": 0,
            "end": 72,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_2@0",
            "content": "Task weighting, which assigns weights on the including tasks during training, significantly matters the performance of Multi-task Learning (MTL); thus, recently, there has been an explosive interest in it.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_2",
            "start": 0,
            "end": 204,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_2@1",
            "content": "However, existing task weighting methods assign weights only based on the training loss, while ignoring the gap between the training loss and generalization loss.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_2",
            "start": 206,
            "end": 367,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_2@2",
            "content": "It degenerates MTL's performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_2",
            "start": 369,
            "end": 401,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_2@3",
            "content": "To address this issue, the present paper proposes a novel task weighting algorithm, which automatically weights the tasks via a learning-tolearn paradigm, referred to as MetaWeighting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_2",
            "start": 403,
            "end": 586,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_2@4",
            "content": "Extensive experiments are conducted to validate the superiority of our proposed method in multi-task text classification.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_2",
            "start": 588,
            "end": 708,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_4@0",
            "content": "Multi-task Learning (MTL) simultaneously learns multiple related tasks and aims to achieve better performance than learning each task independently (Caruana, 1993;Baxter, 2000).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_4",
            "start": 0,
            "end": 176,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_4@1",
            "content": "It has achieved great success in various applications; especially, in the text classification context, MTL can significantly outperform single task learning (Liu et al., 2017;Mao et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_4",
            "start": 178,
            "end": 370,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_5@0",
            "content": "In MTL, it is common for the including tasks to be competing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_5",
            "start": 0,
            "end": 60,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_5@1",
            "content": "If we cannot properly balance these tasks, some tasks might dominate the training process and hurt the performance of other tasks, a phenomenon known as task imbalance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_5",
            "start": 62,
            "end": 229,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_5@2",
            "content": "To address the task imbalance, the most widely used method is task weighting, which adaptively assigns weights on the tasks during training to balance their impacts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_5",
            "start": 231,
            "end": 395,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_5@3",
            "content": "Various task weighting methods have been proposed and can be used in multi-task text classification, such as (Kendall et al., 2018;Sener and Koltun, 2018;Chen et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_5",
            "start": 397,
            "end": 569,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_6@0",
            "content": "However, existing task weighting methods compute the task weights only based on training losses or corresponding gradients.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_6",
            "start": 0,
            "end": 122,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_6@1",
            "content": "They ignore the gap between the training loss and generalization loss.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_6",
            "start": 124,
            "end": 193,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_7@0",
            "content": "To illustrate this gap, we report observations of our four-task topic classification experiment in Figure 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_7",
            "start": 0,
            "end": 107,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_7@1",
            "content": "The detailed experimental settings are introduced in the experiment section.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_7",
            "start": 109,
            "end": 184,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_7@2",
            "content": "Figure 1 demonstrates that training losses and generalization losses (estimated by the test losses) have different magnitudes; moreover, they have different patterns, such as a task might have largest training loss but have the lowest generalization loss among the tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_7",
            "start": 186,
            "end": 456,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_7@3",
            "content": "This gap causes a mismatch between the task weights and tasks' generalization performance, which reduces effectiveness of the task weighting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_7",
            "start": 458,
            "end": 598,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_7@4",
            "content": "To tackle this issue, this paper proposes a novel task weighting method based on a bi-level optimization problem, which aims to find task weights that explicitly optimize the generalization performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_7",
            "start": 600,
            "end": 801,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_7@5",
            "content": "Our proposed method computes task weights by solving this bi-level optimization problem and performs in a learning-to-learn manner; thus, dubbed MetaWeighting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_7",
            "start": 803,
            "end": 961,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_7@6",
            "content": "MetaWeighting can improve the performance of multi-task text classification.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_7",
            "start": 963,
            "end": 1038,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_8@0",
            "content": "To verify our theoretical analysis and validate the superiority of MetaWeighting, we conduct experiments on two classical text classification problems: sentiment analysis (on reviews) and topic classification (on news).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_8",
            "start": 0,
            "end": 218,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_8@1",
            "content": "The results demonstrate that MetaWeighting outperforms several state-of-the-art multi-task text classification methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_8",
            "start": 220,
            "end": 338,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_9@0",
            "content": "Related Works",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_9",
            "start": 0,
            "end": 12,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_10@0",
            "content": "Existing task weighting strategies can be divided into two categories: weight adaptation methods and Pareto Optimization (PO)-based methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_10",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_10@1",
            "content": "The weight adaptation methods adaptively adjust the tasks' weights during training based on pre-defined heuristic, such as uncertainty (Kendall et al., 2018), task difficulty prioritization (Guo et al., 2018), gradient normalization (Chen et al., 2018), weight average (Liu et al., 2019) and task variance regularization (Mao et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_10",
            "start": 141,
            "end": 480,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_10@2",
            "content": "These methods only use training losses or their gradients to compute task weights while ignores the gap between the training loss and generalization loss.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_10",
            "start": 482,
            "end": 635,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_11@0",
            "content": "Besides, the PO-based methods formulate MTL as a multi-objective optimization problem and aim to find an arbitrary Pareto stationary solution (Sener and Koltun, 2018;Mahapatra and Rajan, 2020;Lin et al., 2020;Mao et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_11",
            "start": 0,
            "end": 226,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_11@1",
            "content": "However, in these methods, the learning objectives only involve training losses; thus, they can only achieve Pareto stationary points w.r.t training losses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_11",
            "start": 228,
            "end": 383,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_11@2",
            "content": "They also ignore the gap between the training loss and generalization loss.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_11",
            "start": 385,
            "end": 459,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_11@3",
            "content": "Moreover, proposes that the PO-based methods can be also regarded as weight adaptation methods for they optimize the weighted sum of training losses as well.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_11",
            "start": 461,
            "end": 617,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_12@0",
            "content": "Overlooking the gap between the training loss and generalization loss would degenerate the performance of MTL.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_12",
            "start": 0,
            "end": 109,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_12@1",
            "content": "This paper proposes a novel task weighting method to solve this issue.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_12",
            "start": 111,
            "end": 180,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_13@0",
            "content": "Preliminaries",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_13",
            "start": 0,
            "end": 12,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_14@0",
            "content": "L q t (\u03b8, D q t ) = 1 |D q t | (xt,yt)\u2208D q t l(h(x t , \u03b8 s , \u03b8 t ), y t ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_14",
            "start": 0,
            "end": 73,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_15@0",
            "content": "Hypergradient Descent",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_15",
            "start": 0,
            "end": 20,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_16@0",
            "content": "Hypergradient Descent (HD) (Almeida et al., 1998;Baydin et al., 2018) provides an efficient way to apply gradient descent on hyper-parameters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_16",
            "start": 0,
            "end": 141,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_16@1",
            "content": "Here, we take learning rate's HD as an example to introduce the basic form of HD.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_16",
            "start": 143,
            "end": 223,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_16@2",
            "content": "Given an objective function f (\u03b8) and previous parameters \u03b8 k\u22121 , gradient descent-based learning typically evaluates the gradient \u2207f (\u03b8 k\u22121 ) and moves against it to arrive at updated parameters",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_16",
            "start": 225,
            "end": 419,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_17@0",
            "content": "\u03b8 k = \u03b8 k\u22121 \u2212 \u03b7\u2207f (\u03b8 k\u22121 ),(1)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_17",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_18@0",
            "content": "where \u03b7 is the learning rate.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_18",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_18@1",
            "content": "HD derives an update rule for the learning rate \u03b7 itself.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_18",
            "start": 30,
            "end": 86,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_18@2",
            "content": "Based on Eq. ( 1) and the chain rule, we have",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_18",
            "start": 88,
            "end": 132,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_19@0",
            "content": "\u2202f (\u03b8 k ) \u2202\u03b7 = \u2207f (\u03b8 k ) \u2022 \u2202(\u03b8 k\u22121 \u2212\u03b7\u2207f (\u03b8 k\u22121 )) \u2202\u03b7 = \u2207f (\u03b8 k ) \u2022 (\u2212\u2207f (\u03b8 k\u22121 )),(2)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_19",
            "start": 0,
            "end": 84,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_20@0",
            "content": "with which we construct a update rule for \u03b7:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_20",
            "start": 0,
            "end": 43,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_21@0",
            "content": "\u03b7 k+1 = \u03b7 k + \u03b2\u2207f (\u03b8 k ) \u2022 \u2207f (\u03b8 k\u22121 ),(3)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_21",
            "start": 0,
            "end": 41,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_22@0",
            "content": "introducing \u03b2 as the hypergradient step size.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_22",
            "start": 0,
            "end": 44,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_22@1",
            "content": "In this paper, we extend HD to a bi-level multi-objective optimization problem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_22",
            "start": 46,
            "end": 124,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_23@0",
            "content": "Common Descent Direction for Multiple Objectives",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_23",
            "start": 0,
            "end": 47,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_24@0",
            "content": "When using gradient descent to jointly optimize multiple optimization objectives, we need to find a descent direction common to all the objectives.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_24",
            "start": 0,
            "end": 146,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_24@1",
            "content": "Based on the descent direction for each objective, (D\u00e9sid\u00e9ri, 2012) proposes a way to obtain the common descent direction, as in Theorem 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_24",
            "start": 148,
            "end": 286,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_24@2",
            "content": "This paper proposes a method to simultaneously optimize the tasks' generalization loss based on Theorem 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_24",
            "start": 288,
            "end": 393,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_25@0",
            "content": "Theorem 1 ( (D\u00e9sid\u00e9ri, 2012)).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_25",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_25@1",
            "content": "Let A be a Hilbert space of finite or infinite dimension N .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_25",
            "start": 31,
            "end": 90,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_25@2",
            "content": "Let f i (z) (1 \u2264 i \u2264 n \u2264 N ) be n smooth functions of the vector z \u2208 A. and z 0 a particular admissible designpoint, at which the gradient-vectors are denoted g i = \u2207f i (z 0 ), and",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_25",
            "start": 92,
            "end": 272,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_26@0",
            "content": "U = {a \u2208 A|a = n i=1 \u03bbigi; \u03bbi > 0(\u2200i); n i=1 \u03bbi = 1}. (4)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_26",
            "start": 0,
            "end": 56,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_27@0",
            "content": "Let a * = arg min a\u2208 \u016a a , where U consists of the convex hull and closure of U. Then, if a * = 0, a * is a descent direction common to all the objectives.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_27",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_28@0",
            "content": "4 MetaWeighting for MTL",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_28",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_29@0",
            "content": "Gap Between Task Weighting and Generalization Performance",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_29",
            "start": 0,
            "end": 56,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_30@0",
            "content": "MTL aims to improve the generalization performance of all the including tasks, which can be formulated via the following optimization problem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_30",
            "start": 0,
            "end": 141,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_31@0",
            "content": "min \u03b8 L(\u03b8) = (L 1 (\u03b8), ..., L T (\u03b8)) ,(5)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_31",
            "start": 0,
            "end": 40,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_32@0",
            "content": "By contrast, existing task weighting strategies train a MTL model via the following objective.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_32",
            "start": 0,
            "end": 93,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_33@0",
            "content": "min \u03b8 1 T w t L tr t (\u03b8, D t ),(6)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_33",
            "start": 0,
            "end": 33,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_34@0",
            "content": "where the w t is adaptive during training and only depends on the training losses or their gradients.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_34",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_35@0",
            "content": "As the neural networks are usually heavily overparameterized (Allen-Zhu et al., 2019), the training losses cannot properly estimate the generalization losses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_35",
            "start": 0,
            "end": 157,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_35@1",
            "content": "Thus, existing task weighting strategies, which tunes weights only based on the training losses, overlook the generalization losses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_35",
            "start": 159,
            "end": 290,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_35@2",
            "content": "Obviously, there is a gap between these task weighting strategies and the generalization performance of MTL.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_35",
            "start": 292,
            "end": 399,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_36@0",
            "content": "MetaWeighting Problem",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_36",
            "start": 0,
            "end": 20,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_37@0",
            "content": "To narrow the gap between task weighting strategies and generalization performance, we propose to automatically learn task weights that can reduce the generalization losses, namely learning to weight.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_37",
            "start": 0,
            "end": 199,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_37@1",
            "content": "This learning to weight problem is formlated via the following bi-level optimization problem, dubbed MetaWeighting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_37",
            "start": 201,
            "end": 315,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_38@0",
            "content": "Problem 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_38",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_39@0",
            "content": "min w (L 1 (\u03b8 * (w)), ..., L T (\u03b8 * (w))) s.t. \u03b8 * (w) = arg min \u03b8 1 T T t=1 w t L tr t (\u03b8, D t )(7)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_39",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_40@0",
            "content": "where w = (w 1 , w 2 , ..., w T ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_40",
            "start": 0,
            "end": 33,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_40@1",
            "content": "This bi-level optimization problem combines ( 5) and ( 6) together, by solving which we can obtain task weights that benefit the generalization performance of MTL.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_40",
            "start": 35,
            "end": 197,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_41@0",
            "content": "However, the generalization loss is agnostic.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_41",
            "start": 0,
            "end": 44,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_41@1",
            "content": "To properly estimate the generalization loss, we randomly divide the training set D t into two subsets: support set D s t and query set D q t , where D s t is used to train a MTL model, and D q t is used to estimate generalization loss of the MTL model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_41",
            "start": 46,
            "end": 298,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_41@2",
            "content": "In Section 5, we theoretically demonstrate that query loss is a good estimator for the generalization loss; besides, in Section 6.7, experimental analysis also supports that query loss is a good estimator.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_41",
            "start": 300,
            "end": 504,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_42@0",
            "content": "Based on the support-query split, the MetaWeighting problem is transformed into the following form.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_42",
            "start": 0,
            "end": 98,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_43@0",
            "content": "Problem 2. min w (L q 1 (\u03b8 * (w), D q 1 ), ..., L q T (\u03b8 * (w), D q T )) s.t. \u03b8 * (w) = arg min \u03b8 1 T T t=1 w t L s t (\u03b8, D s t )(8)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_43",
            "start": 0,
            "end": 131,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_44@0",
            "content": "MetaWeighting Algorithm",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_44",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_45@0",
            "content": "In the MetaWeighting problem, the inner optimization objective is embedded within the outer optimization objective.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_45",
            "start": 0,
            "end": 114,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_45@1",
            "content": "In MTL, the inner optimization objective is to minimize the weighted sum of task-specific training losses, which is typically optimized by means of iterative gradient descent; thus, Problem 2 can be formulated by the following problem in the k th learning iteration.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_45",
            "start": 116,
            "end": 381,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_46@0",
            "content": "Problem 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_46",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_47@0",
            "content": "min w (L q 1 (\u03b8 k , D q 1 ), ..., L q T (\u03b8 k , D q T )) s.t. \u03b8 k = \u03b8 k\u22121 \u2212 \u03b7 T T t=1 w t \u2207 \u03b8 L s t (\u03b8 k\u22121 , D s t )(9)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_47",
            "start": 0,
            "end": 117,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_48@0",
            "content": "To solve Problem 3, we adopt the Hypergradient Descent (HD) method.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_48",
            "start": 0,
            "end": 66,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_48@1",
            "content": "However, the original HD method (Almeida et al., 1998;Baydin et al., 2018) is proposed for single objective optimization, which can not used in our problem where a multiobjective optimization problem involves.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_48",
            "start": 68,
            "end": 276,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_48@2",
            "content": "In this section, this paper proposes a novel HD method for the multi-objective optimization setting, as in the following sections.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_48",
            "start": 278,
            "end": 407,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_49@0",
            "content": "Task-Specific Descent Direction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_49",
            "start": 0,
            "end": 30,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_50@0",
            "content": "The learning objective of Problem 3 involves T objectives.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_50",
            "start": 0,
            "end": 57,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_50@1",
            "content": "We aim to find a gradient direction, moving against which all the objective can be optimized.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_50",
            "start": 59,
            "end": 151,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_50@2",
            "content": "To find this gradient direction, we first find the hypergradient direction w.r.t w (denoted as d t ) for each task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_50",
            "start": 153,
            "end": 267,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_50@3",
            "content": "d t is computed by the following equation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_50",
            "start": 269,
            "end": 310,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_51@0",
            "content": "d t = \u2202L q t (\u03b8 k , D q t ) \u2202w = \u2207 \u03b8 L q t (\u03b8 k , D q t ) \u2022 \u2202\u03b8 k \u2202w = \u2212 \u03b7 T \u2207 \u03b8 L q t (\u03b8 k , D q t )\u2207 \u03b8 L s (\u03b8 k\u22121 , D s ). (10",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_51",
            "start": 0,
            "end": 126,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_52@0",
            "content": ")",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_52",
            "start": 0,
            "end": 0,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_53@0",
            "content": "where",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_53",
            "start": 0,
            "end": 4,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_54@0",
            "content": "\u2207 \u03b8 L s (\u03b8 k\u22121 , D s ) = (\u2207 \u03b8 L s 1 (\u03b8 k\u22121 , D s 1 ) , ..., \u2207 \u03b8 L s T (\u03b8 k\u22121 , D s T )",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_54",
            "start": 0,
            "end": 85,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_55@0",
            "content": ").",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_55",
            "start": 0,
            "end": 1,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_55@1",
            "content": "Moving against d t , the generalization loss of task t can be optimized.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_55",
            "start": 3,
            "end": 74,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_56@0",
            "content": "Common Descent Direction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_56",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_57@0",
            "content": "Base on d t , in this section, we find a common gradient direction, moving against which all the objective can be optimized.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_57",
            "start": 0,
            "end": 123,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_57@1",
            "content": "Let d = (d 1 , d 2 , ..., d T ) and d c be the common gradient direction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_57",
            "start": 125,
            "end": 197,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_57@2",
            "content": "Theorem 1 presents that the following Eq. ( 11) is a common descent direction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_57",
            "start": 199,
            "end": 276,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_58@0",
            "content": "d c = \u03bb * d (11",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_58",
            "start": 0,
            "end": 14,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_59@0",
            "content": ")",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_59",
            "start": 0,
            "end": 0,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_60@0",
            "content": "where",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_60",
            "start": 0,
            "end": 4,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_61@0",
            "content": "\u03bb * = arg min \u03bb { \u03bbd 2 2 |\u03bb1 = 1, \u03bb 0},(12)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_61",
            "start": 0,
            "end": 42,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_62@0",
            "content": "where 1 = (1, 1, ..., 1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_62",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_62@1",
            "content": "Eq. ( 12) is a typical minimum Euclidean-norm point problem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_62",
            "start": 26,
            "end": 85,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_62@2",
            "content": "We here adopt the widely used Frank-Wolfe optimization algorithm (Jaggi, 2013), a minimum-norm-point algorithm, to solve it.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_62",
            "start": 87,
            "end": 210,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_62@3",
            "content": "The Frank-Wolfe optimization algorithm is presented in Algorithm 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_62",
            "start": 212,
            "end": 278,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_63@0",
            "content": "MetaWeighting",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_63",
            "start": 0,
            "end": 12,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_64@0",
            "content": "Moving against d c , all the objective can be optimized; thus, the update rule of w is",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_64",
            "start": 0,
            "end": 85,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_65@0",
            "content": "w k+1 = w k \u2212 \u03b1d c . (13",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_65",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_66@0",
            "content": ")",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_66",
            "start": 0,
            "end": 0,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_67@0",
            "content": "where \u03b1 is the step size.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_67",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_67@1",
            "content": "Based on this update rule, the task weights are automatically learnt oriented by optimizing the generalization losses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_67",
            "start": 26,
            "end": 143,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_67@2",
            "content": "Overall, we propose the MetaWeighting algorithm, which is presented in algorithmic form in Algorithm 1: MetaWeighting Algorithm Input: data {D s t } T t=1 and {D q t } T t=1 , step size \u03b1 for updating w, Number of learning iterations K. Initialize: w 0 = (1, 1, ..., 1), \u03b8 0 , \u03b7.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_67",
            "start": 145,
            "end": 423,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_68@0",
            "content": "for k = 1 to K do \u03b8 k = \u03b8 k\u22121 \u2212 \u03b7 T T t=1 w t \u2207 \u03b8 L s t (\u03b8 k\u22121 , D s t ). for t = 1 to T do d t = \u2212 \u03b7 T \u2207 \u03b8 L q t (\u03b8 k , D q t )\u2207 \u03b8 L s (\u03b8 k\u22121 , D s ). end for d = (d 1 , d 2 , ..., d T ) \u03bb * = arg min \u03bb { \u03bbd 2 2 |\u03bb1 = 1, \u03bb 0} (calls Algorithm 2). d c = \u03bb * d . w k+1 = w k \u2212 \u03b1d c . end for Algorithm 2: Frank-Wolfe Algorithm Input: Number of Iterations N . Initialize: \u03bb 0 = [ 1 T , ..., 1 T ]. B = d d. for i = 0 to N do v = arg min v\u2208{v 1=1,v 0} v B\u03bb. \u03b3 = arg min \u03b3\u2208[0,1] (\u03bb i +\u03b3(v \u2212\u03bb i )) B(\u03bb i +\u03b3(v \u2212\u03bb i )).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_68",
            "start": 0,
            "end": 511,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_69@0",
            "content": "\u03bb i+1 = (1 \u2212 \u03b3)\u03bb i + \u03b3v. end for return: \u03bb N Algorithm 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_69",
            "start": 0,
            "end": 56,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_69@1",
            "content": "Our proposed method bridges the gap between task weighting and generalization performance of MTL.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_69",
            "start": 58,
            "end": 154,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_70@0",
            "content": "Theoretical Analysis",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_70",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_71@0",
            "content": "In this section, we study the generalization error bound for MTL; furthermore, we compare the bound w.r.t training loss and the bound w.r.t the query loss.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_71",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_71@1",
            "content": "The comparison presents that the query loss is a more accurate estimation of the generalization loss than the training loss.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_71",
            "start": 156,
            "end": 279,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_72@0",
            "content": "Firstly, we derive the generalization error bound w.r.t training loss for MTL.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_72",
            "start": 0,
            "end": 77,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_73@0",
            "content": "Theorem 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_73",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_73@1",
            "content": "Assume we have n training samples for each task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_73",
            "start": 11,
            "end": 58,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_73@2",
            "content": "Let \u03c3 = {{\u03c3 t i } n i=1 } T t=1 be a sequence of binary random variables such that each \u03c3 t i = \u00b11 is independent with probability 1/2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_73",
            "start": 60,
            "end": 194,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_73@3",
            "content": "Then, \u2200\u03b4 \u2208 [0, 1], for all h(\u2022, \u03b8 s , \u03b8 1 , ..., \u03b8 T ) \u2208 H, with probability of at least 1 \u2212 \u03b4:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_73",
            "start": 196,
            "end": 290,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_74@0",
            "content": "1 T T t=1 (L t (\u03b8) \u2212 L tr t (\u03b8, D t )) \u2264 2R(l \u2022 H \u2022 D) + 4 2 log(4/\u03b4) T n . (14) where R(l\u2022H\u2022D) = E \u03c3 sup \u03b8 ( 1 T n T t=1 n i=1 \u03c3 t i l(h(x t i , \u03b8), y t i ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_74",
            "start": 0,
            "end": 157,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_75@0",
            "content": "(15) is the Rademacher complexity for MTL.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_75",
            "start": 0,
            "end": 41,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_76@0",
            "content": "Proof.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_76",
            "start": 0,
            "end": 5,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_76@1",
            "content": "The proof is provided in Appendix A.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_76",
            "start": 7,
            "end": 42,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_77@0",
            "content": "Next, we derive the generalization error bound w.r.t query loss for MTL.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_77",
            "start": 0,
            "end": 71,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_78@0",
            "content": "Theorem 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_78",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_78@1",
            "content": "Assume we have m training samples for each task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_78",
            "start": 11,
            "end": 58,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_78@2",
            "content": "\u2200\u03b4 \u2208 [0, 1], with probability of at least 1 \u2212 \u03b4, for all h(\u2022, \u03b8 s , \u03b8 1 , ..., \u03b8 T ) \u2208 H, we have",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_78",
            "start": 60,
            "end": 156,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_79@0",
            "content": "1 T T t=1 (L t (\u03b8) \u2212 L q t (\u03b8, D q t )) \u2264 log(2/\u03b4) 2m .(16)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_79",
            "start": 0,
            "end": 58,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_80@0",
            "content": "Proof.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_80",
            "start": 0,
            "end": 5,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_80@1",
            "content": "The proof is provided in Appendix A.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_80",
            "start": 7,
            "end": 42,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_81@0",
            "content": "Comparing the bound ( 14) and ( 16), we can find that the upper bound for the query loss is tighter than that for the training loss.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_81",
            "start": 0,
            "end": 131,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_81@1",
            "content": "Taking m to be order of n, the query loss is a more accurate estimate of the generalization loss than the training loss by a factor that depends on the Rademacher complexity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_81",
            "start": 133,
            "end": 306,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_82@0",
            "content": "Experiments",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_82",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_83@0",
            "content": "In this section, we perform experimental studies on sentiment analysis to evaluate the performance of our proposed MetaWeighting and verify our theoretical analysis.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_83",
            "start": 0,
            "end": 164,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_83@1",
            "content": "The implementation is based on PyTorch (Paszke et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_83",
            "start": 166,
            "end": 226,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_83@2",
            "content": "The code is attached in the supplementary materials.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_83",
            "start": 228,
            "end": 279,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_84@0",
            "content": "Datasets",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_84",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_85@0",
            "content": "Sentiment Analysis 1 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_85",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_85@1",
            "content": "We evaluate our algorithm on product reviews from Amazon.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_85",
            "start": 23,
            "end": 79,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_85@2",
            "content": "The dataset (Blitzer et al., 2007) contains product reviews from 14 domains, including books, DVDs, electronics, kitchen appliances and so on.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_85",
            "start": 81,
            "end": 222,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_85@3",
            "content": "We consider each domain as a binary classification task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_85",
            "start": 224,
            "end": 279,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_85@4",
            "content": "Reviews with rating > 3 were labeled positive, those with rating < 3 were labeled negative, reviews with rating = 3 are discarded as the sentiments were ambiguous and hard to predict.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_85",
            "start": 281,
            "end": 463,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_86@0",
            "content": "Topic Classification 2 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_86",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_86@1",
            "content": "We select 16 newsgroups from the 20 Newsgroup dataset, which is a collection of approximately 20,000 newsgroup documents that is partitioned (nearly) evenly across 20 different newsgroups, then formulate them into four 4-class classification tasks (as shown in Table 1) to evaluate the performance of our algorithm on topic classification.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_86",
            "start": 25,
            "end": 363,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_87@0",
            "content": "Baselines",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_87",
            "start": 0,
            "end": 8,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_88@0",
            "content": "We compare MASS-MTL with following baselines.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_88",
            "start": 0,
            "end": 44,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_89@0",
            "content": "Single-Task Learning (STL): learning each task independently.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_89",
            "start": 0,
            "end": 60,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_90@0",
            "content": "Uniform: learning tasks simultaneously using uniform task weights.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_90",
            "start": 0,
            "end": 65,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_91@0",
            "content": "Uncertainty: using the uncertainty weighting method proposed by (Kendall et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_91",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_92@0",
            "content": "GradNorm: using the gradient normalization method proposed by (Chen et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_92",
            "start": 0,
            "end": 81,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_93@0",
            "content": "MGDA: using the MGDA-UB method proposed by (Sener and Koltun, 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_93",
            "start": 0,
            "end": 67,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_94@0",
            "content": "AdvMTL: using the adversarial Multi-task Learning method proposed by (Liu et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_94",
            "start": 0,
            "end": 87,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_95@0",
            "content": "TchebycheffAdv: using the Adversarial Tchebycheff procedure proposed by (Mao et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_95",
            "start": 0,
            "end": 90,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_96@0",
            "content": "BanditMTL: using the BanditMTL method proposed by (Mao et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_96",
            "start": 0,
            "end": 68,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_97@0",
            "content": "Experimental Settings",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_97",
            "start": 0,
            "end": 20,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_98@0",
            "content": "We adopt the hard parameter-sharing MTL framework (Mao et al., 2021), where the shared representation extractor is built with TextCNN or BERT; besides, the task-specific module is formulated by means of one fully connected layer ending with a softmax function.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_98",
            "start": 0,
            "end": 259,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_98@1",
            "content": "For TextCNN, we adopt Pretrained GloVe (Pennington et al., 2014) word embeddings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_98",
            "start": 261,
            "end": 341,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_98@2",
            "content": "For BERT, we adopt the pre-trained BERT-base model (uncased) provided by Hugging Each colored cluster illustrates the classification accuracy performance of a method over 10 runs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_98",
            "start": 343,
            "end": 521,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_98@3",
            "content": "Our proposed MetaWeighting outperforms all baselines on ten of the fourteen tasks; besides, its average performance is superior to that of all baselines.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_98",
            "start": 523,
            "end": 675,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_98@4",
            "content": "Face (Wolf et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_98",
            "start": 677,
            "end": 701,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_98@5",
            "content": "We set \u03b1 to be 0.1 and 0.5 for sentiment analysis and topic classification respectively, and the query-split radio (radio of query samples to entire training samples) to be 0.1 for both sentiment analysis and topic classification.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_98",
            "start": 703,
            "end": 932,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_98@6",
            "content": "The detailed experimental settings are introduced in the Appendix B.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_98",
            "start": 934,
            "end": 1001,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_99@0",
            "content": "U n if o r m A d v M T L M G D A G r a d N o r m U n c e",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_99",
            "start": 0,
            "end": 55,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_100@0",
            "content": "Classification Performance",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_100",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_101@0",
            "content": "We compare the proposed MetaWeighting with the baselines and report the results over 10 runs by plotting the classification accuracy of each task for both sentiment analysis and topic classification.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_101",
            "start": 0,
            "end": 198,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_101@1",
            "content": "3. Due to space limitations, we provide the results for BERT in the Appendix C. All experimental results show that our proposed MetaWeighting outperforms all baselines and achieves state-of-the-art performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_101",
            "start": 200,
            "end": 409,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_102@0",
            "content": "The Impact of Query-Split Radio",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_102",
            "start": 0,
            "end": 30,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_103@0",
            "content": "Let n be the size of the entire training set and m be the size of the query set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_103",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_103@1",
            "content": "We define the querysplit radio as \u03c1 = m n to indicate the radio of query samples to the entire training samples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_103",
            "start": 81,
            "end": 192,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_103@2",
            "content": "From the theoretical analysis of Section 5, we can see that the query loss can estimate generalization loss more accurately when \u03c1 increases, but increasing \u03c1 would hurt the training process for the size of support set decreases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_103",
            "start": 194,
            "end": 422,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_103@3",
            "content": "Therefore, \u03c1 faces a trade-off between the performance estimation of generalization loss and training performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_103",
            "start": 424,
            "end": 537,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_104@0",
            "content": "To investigate the impact of \u03c1, we record the changes in MetaWeighting's average classification accuracy w.r.t different values of \u03c1 in Fig. 4, where each boxplot visually illustrates the distribution of results over ten runs through displaying the data quartiles (first quartile and third quartile), minimum/maximum value and median.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_104",
            "start": 0,
            "end": 333,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_104@1",
            "content": "These experiments are conducted based on TextCNN.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_104",
            "start": 335,
            "end": 383,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_104@2",
            "content": "In this figure, as \u03c1 increases, the average accuracy of MetaWeighting first increases and then decreases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_104",
            "start": 385,
            "end": 489,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_104@3",
            "content": "It verifies our theoretical analysis.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_104",
            "start": 491,
            "end": 527,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_104@4",
            "content": "For both sentiment analysis and topic classification, setting \u03c1 = 0.1 provides satisfactory results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_104",
            "start": 529,
            "end": 628,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_105@0",
            "content": "Sensitive Study on \u03b1",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_105",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_106@0",
            "content": "In MetaWeighting, the step size \u03b1 is a hyperparameter.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_106",
            "start": 0,
            "end": 53,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_106@1",
            "content": "To determine whether the performance of MetaWeighting is sensitive to \u03b1, we conduct experiments on the classification accuracy performance of MetaWeighting w.r.t different values of \u03b1 based on the TextCNN model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_106",
            "start": 55,
            "end": 265,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_106@2",
            "content": "The results of these experiments are presented in Figure 5 (boxplots over ten runs).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_106",
            "start": 267,
            "end": 350,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_106@3",
            "content": "As the figure shows, the performance of our proposed method is not very sensitive to \u03b1 when \u03b1 is within the range of 0.05 to 0.1 for sentiment analysis and 0.1 to 0.5 for topic classification.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_106",
            "start": 352,
            "end": 543,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_106@4",
            "content": "The results demonstrate that MetaWeighting can work well in a wide range of \u03b1 values.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_106",
            "start": 545,
            "end": 629,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_107@0",
            "content": "The Gap between the Training Loss, Query Loss and Generalization Loss",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_107",
            "start": 0,
            "end": 68,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_108@0",
            "content": "To experimentally verify that the query loss is a good estimator for generalization loss, we record the generalization loss (estimated by test loss), query loss and training loss for each task during training and report the results in Fig. 7 and 6 for sentiment analysis and topic classification respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_108",
            "start": 0,
            "end": 308,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_108@1",
            "content": "From these figures, we can see that there is a large gap between the training and generalization loss, and the gap between the query and generalization loss is smaller than that between the training and generalization loss.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_108",
            "start": 310,
            "end": 532,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_108@2",
            "content": "The results verify our theoretical analysis in Section 5; furthermore, they experimentally support our motivation for MetaWeighting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_108",
            "start": 534,
            "end": 665,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_108@3",
            "content": "In this section, TextCNN is used, and tasks have uniform weights during training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_108",
            "start": 667,
            "end": 747,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_108@4",
            "content": "Fig. 1 is obtained under this setting as well.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_108",
            "start": 749,
            "end": 794,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_109@0",
            "content": "The Evolution of Task Weights",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_109",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_110@0",
            "content": "In this section, we observe the changes in task weights in the training process of MetaWeighting and compare these changes with four baselines (Uncertainty, Gradnorm, MGDA and BanditMTL).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_110",
            "start": 0,
            "end": 186,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_110@1",
            "content": "The results for sentiment analysis and topic classification are reported in Fig. 8 and 9 respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_110",
            "start": 188,
            "end": 289,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_110@2",
            "content": "Due to space limitations, for sentiment analysis, we only report the results of the first four tasks here, and the results of the other ten tasks are presented in the Appendix D.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_110",
            "start": 291,
            "end": 468,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_111@0",
            "content": "From these figures, we can see that the weight adaption process of MetaWeighting is different with that of Uncertainty, Gradnorm, MGDA and BanditMTL.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_111",
            "start": 0,
            "end": 148,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_111@1",
            "content": "In MetaWeighting, the task weights are automatically learnt, and there is no pre-defined heuristic involved.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_111",
            "start": 150,
            "end": 257,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_111@2",
            "content": "It is verified by the evolution curves of task weights for MetaWeighting illustrated in Fig. 8 and 9, which fluctuate without any regular patterns.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_111",
            "start": 259,
            "end": 405,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_112@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_112",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_113@0",
            "content": "This paper presents that the gap between the training loss and the generalization loss, which is overlooked by existing task weighting methods, is nonnegligible; furthermore, to narrow this gap, a novel task weighting method (dubbed MetaWeighting) is proposed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_113",
            "start": 0,
            "end": 259,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_113@1",
            "content": "MetaWeighting works in a learningto-learn manner, which automatically learns the task weights without any pre-defined heuristic and achieves state-of-the-art performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_113",
            "start": 261,
            "end": 430,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_113@2",
            "content": "It has the potential to forge new trends in task weighting research.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_113",
            "start": 432,
            "end": 499,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_114@0",
            "content": "A Proof of the Theorem 2 and Theorem 3 Lemma 1 (McDiarmid's Inequality).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_114",
            "start": 0,
            "end": 71,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_114@1",
            "content": "Let V be some set and let f : V n \u2192 R be a function of n variables such that for some c > 0 , for all i \u2208 [n] and for all z 1 , ..., z n , z i \u2208 V we have",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_114",
            "start": 73,
            "end": 226,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_115@0",
            "content": "|f (z 1 , ..., z n )\u2212f (z 1 , ..., z i\u22121 , z i , z i+1 , ..., z n )| \u2264 c.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_115",
            "start": 0,
            "end": 72,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_116@0",
            "content": "(17) Let Z 1 , ..., Z n be n independent random variables taking values in V .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_116",
            "start": 0,
            "end": 77,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_116@1",
            "content": "Then, with probability of at least 1 \u2212 \u03b4 we have",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_116",
            "start": 79,
            "end": 126,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_117@0",
            "content": "|f (Z 1 , ..., Z n )\u2212E[f (Z 1 , ..., Z n )]| \u2264 c n log(2/\u03b4) 2 . (18",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_117",
            "start": 0,
            "end": 66,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_118@0",
            "content": ")",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_118",
            "start": 0,
            "end": 0,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_119@0",
            "content": "Lemma 2 (Hoeffding's Inequality). Let z 1 , ..., z m be a a sequence of i.i.d. random variables and assume that for all i, E(z i ) = \u00b5 and P (a \u2264 z i \u2264 b) = 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_119",
            "start": 0,
            "end": 158,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_119@1",
            "content": "Then, for any > 0",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_119",
            "start": 160,
            "end": 176,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_120@0",
            "content": "In our setting, l(\u2022, \u2022) : Y t \u00d7 Y t \u2192 [0, 1], then c = 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_120",
            "start": 0,
            "end": 56,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_121@0",
            "content": "We have",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_121",
            "start": 0,
            "end": 6,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_122@0",
            "content": "1 T T t=1 (L t (\u03b8) \u2212 L tr t (\u03b8, D t )) \u2264 2R(l \u2022 H \u2022 D) + 4 2 log(4/\u03b4) T n . (30",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_122",
            "start": 0,
            "end": 78,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_123@0",
            "content": ")",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_123",
            "start": 0,
            "end": 0,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_124@0",
            "content": "We conclude our proof.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_124",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_125@0",
            "content": "Based on the Hoeffding's Inequality (Lemma 2), we have the following theorem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_125",
            "start": 0,
            "end": 76,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_126@0",
            "content": "Proof of Theorem 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_126",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_127@0",
            "content": "Proof.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_127",
            "start": 0,
            "end": 5,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_127@1",
            "content": "Based on the Hoeffding's Inequality (Lemma 2) and l(",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_127",
            "start": 7,
            "end": 58,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_128@0",
            "content": "\u2022, \u2022) : Y t \u00d7 Y t \u2192 [0, 1], for each h(\u2022, \u03b8 s , \u03b8 t ) \u2208 H t , we have P [|L t (\u03b8) \u2212 L q t (\u03b8, D t )| > ] \u2264 2exp(\u22122m 2 ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_128",
            "start": 0,
            "end": 119,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_129@0",
            "content": "(31) Then, with probability of at least 1\u22122exp(\u22122m 2 ), we have",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_129",
            "start": 0,
            "end": 62,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_130@0",
            "content": "|L t (\u03b8) \u2212 L q t (\u03b8, D t )| \u2264 .(32)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_130",
            "start": 0,
            "end": 34,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_131@0",
            "content": "Let \u03b4 = 2exp(\u22122m 2 ), we have that with probability of at least 1 \u2212 \u03b4,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_131",
            "start": 0,
            "end": 69,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_132@0",
            "content": "|L t (\u03b8) \u2212 L q t (\u03b8, D t )| \u2264 log(2/\u03b4) 2m .(33)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_132",
            "start": 0,
            "end": 46,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_133@0",
            "content": "Thus, for each task,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_133",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_134@0",
            "content": "L t (\u03b8) \u2212 L q t (\u03b8, D t ) \u2264 log(2/\u03b4) 2m . (34",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_134",
            "start": 0,
            "end": 44,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_135@0",
            "content": ")",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_135",
            "start": 0,
            "end": 0,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_136@0",
            "content": "Since the bound for each task are independent, we have",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_136",
            "start": 0,
            "end": 53,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_137@0",
            "content": "1 T T t=1 (L t (\u03b8) \u2212 L q t (\u03b8, D t )) \u2264 log(2/\u03b4) 2m .(35)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_137",
            "start": 0,
            "end": 56,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_138@0",
            "content": "We conclude our proof.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_138",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_139@0",
            "content": "We adopt the hard parameter-sharing MTL framework (Mao et al., 2021), where the shared representation extractor is built with TextCNN or BERT; besides, the task-specific module is formulated by means of one fully connected layer ending with a softmax function.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_139",
            "start": 0,
            "end": 259,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_139@1",
            "content": "The TextCNN module is structured with three parallel convolutional layers with kernels size of 3, 5, 7 respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_139",
            "start": 261,
            "end": 376,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_139@2",
            "content": "For TextCNN, we adopt Pre-trained GloVe (Pennington et al., 2014) word embeddings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_139",
            "start": 378,
            "end": 459,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_139@3",
            "content": "By contrast, the BERT module is formulated via a pre-trained BERT-base model provided by Hugging Face (Wolf et al., 2020), with a hidden size of 768, 12 Transformer blocks and 12 self-attention heads.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_139",
            "start": 461,
            "end": 660,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_139@4",
            "content": "We train the deep MTL network model in line with Algorithm 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_139",
            "start": 662,
            "end": 722,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_139@5",
            "content": "We set \u03b1 to be 0.1 and 0.5 for sentiment analysis and topic classification respectively, and the query-split radio (radio of query samples to entire training samples) to be 0.1 for both sentiment analysis and topic classification.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_139",
            "start": 724,
            "end": 953,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_139@6",
            "content": "We use the Adam optimizer (Kingma and Ba, 2015).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_139",
            "start": 955,
            "end": 1002,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_139@7",
            "content": "We train over 3000 epochs for TextCNN and finetune over 50 epochs for BERT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_139",
            "start": 1004,
            "end": 1078,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_139@8",
            "content": "For TextCNN, the learning rate is 1e \u2212 3 and the batch size is 256.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_139",
            "start": 1080,
            "end": 1146,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_139@9",
            "content": "For BERT, the learning rate is 2e \u2212 5 , the batch size is 32, and the max sequence length is 256.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_139",
            "start": 1148,
            "end": 1244,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_139@10",
            "content": "For the baselines, we search over the set {1e\u22125, 2e\u22125, 5e\u22125, 1e\u22124, 5e\u22124, 1e\u22123, 5e\u22123} learning rates and choose the model with best performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_139",
            "start": 1246,
            "end": 1388,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_140@0",
            "content": "For the BERT-based MTL model, we compare the proposed MetaWeighting with the baselines and report the results over 10 runs by plotting the classification accuracy of each task for both sentiment analysis and topic classification in Fig. 10 and 11.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_140",
            "start": 0,
            "end": 246,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_140@1",
            "content": "AdvMTL and TchebycheffAdv are not available for BERT; thus, we do not compare with AdvMTL and compare with Tchebycheff which is Tcheby-cheffAdv without aversarial module (Mao et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_140",
            "start": 248,
            "end": 436,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_140@2",
            "content": "From these figures, we can see that our proposed MetaWeighting outperforms all baselines and achieves state-of-the-art performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_140",
            "start": 438,
            "end": 568,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_141@0",
            "content": "Sentiment Analysis",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_141",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_142@0",
            "content": "UNKNOWN, None, 1996, Weak convergence and empirical processes, Springer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_142",
            "start": 0,
            "end": 71,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_143@0",
            "content": "UNKNOWN, None, 2019, Learning and generalization in overparameterized neural networks, going beyond two layers, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_143",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_144@0",
            "content": "B Lu\u00eds, Thibault Almeida,  Langlois, D Jos\u00e9, Alexander Amaral,  Plakhov, Parameter adaptation in stochastic optimization, 1998, On-Line Learning in Neural Networks, Cambridge University Press.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_144",
            "start": 0,
            "end": 191,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_145@0",
            "content": "Jonathan Baxter, A model of inductive bias learning, 2000, Journal of artificial intelligence research, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_145",
            "start": 0,
            "end": 104,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_146@0",
            "content": "Robert Atilim Gunes Baydin, David Cornish, Mark Mart\u00ednez-Rubio, Frank Schmidt,  Wood, Online learning rate adaptation with hypergradient descent, 2018, ICLR, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_146",
            "start": 0,
            "end": 158,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_147@0",
            "content": "John Blitzer, Mark Dredze, Fernando Pereira, Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification, 2007, ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_147",
            "start": 0,
            "end": 153,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_148@0",
            "content": "Rich Caruana, Multitask learning: A knowledgebased source of inductive bias, 1993, ICML, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_148",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_149@0",
            "content": "Zhao Chen, Vijay Badrinarayanan, Chen-Yu Lee, Andrew Rabinovich, Gradnorm: Gradient normalization for adaptive loss balancing in deep multitask networks, 2018, ICML, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_149",
            "start": 0,
            "end": 166,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_150@0",
            "content": "Jean-Antoine D\u00e9sid\u00e9ri, Multiple-gradient descent algorithm (mgda) for multiobjective optimization, 2012, Comptes Rendus Mathematique, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_150",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_151@0",
            "content": "Michelle Guo, Albert Haque, De-An Huang, Serena Yeung, Li Fei-Fei, Dynamic task prioritization for multitask learning, 2018, ECCV, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_151",
            "start": 0,
            "end": 131,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_152@0",
            "content": "Martin Jaggi, Revisiting frank-wolfe: Projectionfree sparse convex optimization, 2013, ICML, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_152",
            "start": 0,
            "end": 93,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_153@0",
            "content": "Alex Kendall, Yarin Gal, Roberto Cipolla, Multi-task learning using uncertainty to weigh losses for scene geometry and semantics, 2018, CVPR, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_153",
            "start": 0,
            "end": 142,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_154@0",
            "content": "UNKNOWN, None, 2015, Adam: A method for stochastic optimization, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_154",
            "start": 0,
            "end": 65,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_155@0",
            "content": "UNKNOWN, None, 2020, Controllable pareto multi-task learning, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_155",
            "start": 0,
            "end": 66,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_156@0",
            "content": "Xi Lin, Hui-Ling Zhen, Zhenhua Li, Qingfu Zhang, Sam Kwong, Pareto multi-task learning, 2019, NIPS, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_156",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_157@0",
            "content": "Pengfei Liu, Xipeng Qiu, Xuanjing Huang, Adversarial multi-task learning for text classification, 2017, ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_157",
            "start": 0,
            "end": 109,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_158@0",
            "content": "Shikun Liu, Edward Johns, Andrew Davison, End-to-end multi-task learning with attention, 2019, CVPR, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_158",
            "start": 0,
            "end": 101,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_159@0",
            "content": "Pingchuan Ma, Tao Du, Wojciech Matusik, Efficient continuous pareto exploration in multi-task learning, 2020, ICML, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_159",
            "start": 0,
            "end": 116,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_160@0",
            "content": "Debabrata Mahapatra, Vaibhav Rajan, Multitask learning with user preferences: Gradient descent with controlled ascent in pareto optimization, 2020, ICML, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_160",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_161@0",
            "content": "Yuren Mao, Zekai Wang, Weiwei Liu, Xuemin Lin, Wenbin Hu, Banditmtl: Bandit-based multitask learning for text classification, 2021, ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_161",
            "start": 0,
            "end": 137,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_162@0",
            "content": "Yuren Mao, Shuang Yun, Weiwei Liu, Bo Du, Tchebycheff procedure for multi-task text classification, 2020, ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_162",
            "start": 0,
            "end": 111,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_163@0",
            "content": "Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary Devito, Pytorch: An imperative style, high-performance deep learning library, 2019, NeurIPS, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_163",
            "start": 0,
            "end": 291,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_164@0",
            "content": "Jeffrey Pennington, Richard Socher, Christopher Manning, Glove: Global vectors for word representation, 2014, EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_164",
            "start": 0,
            "end": 117,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_165@0",
            "content": "UNKNOWN, None, 2018, Multitask learning as multi-objective optimization, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_165",
            "start": 0,
            "end": 73,
            "label": {}
        },
        {
            "ix": "245-ARR_v1_166@0",
            "content": "Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Clara Patrick Von Platen, Yacine Ma, Julien Jernite, Canwen Plu, Teven Xu, Sylvain Scao, Mariama Gugger, Quentin Drame, Alexander Lhoest,  Rush, Transformers: State-of-the-art natural language processing, 2020, EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "245-ARR_v1_166",
            "start": 0,
            "end": 391,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "245-ARR_v1_0",
            "tgt_ix": "245-ARR_v1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_0",
            "tgt_ix": "245-ARR_v1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_1",
            "tgt_ix": "245-ARR_v1_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_1",
            "tgt_ix": "245-ARR_v1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_0",
            "tgt_ix": "245-ARR_v1_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_2",
            "tgt_ix": "245-ARR_v1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_4",
            "tgt_ix": "245-ARR_v1_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_5",
            "tgt_ix": "245-ARR_v1_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_6",
            "tgt_ix": "245-ARR_v1_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_7",
            "tgt_ix": "245-ARR_v1_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_3",
            "tgt_ix": "245-ARR_v1_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_3",
            "tgt_ix": "245-ARR_v1_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_3",
            "tgt_ix": "245-ARR_v1_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_3",
            "tgt_ix": "245-ARR_v1_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_3",
            "tgt_ix": "245-ARR_v1_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_3",
            "tgt_ix": "245-ARR_v1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_0",
            "tgt_ix": "245-ARR_v1_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_8",
            "tgt_ix": "245-ARR_v1_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_10",
            "tgt_ix": "245-ARR_v1_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_11",
            "tgt_ix": "245-ARR_v1_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_9",
            "tgt_ix": "245-ARR_v1_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_9",
            "tgt_ix": "245-ARR_v1_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_9",
            "tgt_ix": "245-ARR_v1_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_9",
            "tgt_ix": "245-ARR_v1_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_0",
            "tgt_ix": "245-ARR_v1_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_12",
            "tgt_ix": "245-ARR_v1_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_13",
            "tgt_ix": "245-ARR_v1_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_13",
            "tgt_ix": "245-ARR_v1_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_13",
            "tgt_ix": "245-ARR_v1_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_14",
            "tgt_ix": "245-ARR_v1_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_16",
            "tgt_ix": "245-ARR_v1_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_17",
            "tgt_ix": "245-ARR_v1_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_18",
            "tgt_ix": "245-ARR_v1_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_19",
            "tgt_ix": "245-ARR_v1_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_20",
            "tgt_ix": "245-ARR_v1_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_21",
            "tgt_ix": "245-ARR_v1_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_15",
            "tgt_ix": "245-ARR_v1_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_15",
            "tgt_ix": "245-ARR_v1_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_15",
            "tgt_ix": "245-ARR_v1_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_15",
            "tgt_ix": "245-ARR_v1_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_15",
            "tgt_ix": "245-ARR_v1_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_15",
            "tgt_ix": "245-ARR_v1_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_15",
            "tgt_ix": "245-ARR_v1_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_15",
            "tgt_ix": "245-ARR_v1_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_13",
            "tgt_ix": "245-ARR_v1_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_22",
            "tgt_ix": "245-ARR_v1_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_24",
            "tgt_ix": "245-ARR_v1_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_25",
            "tgt_ix": "245-ARR_v1_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_26",
            "tgt_ix": "245-ARR_v1_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_27",
            "tgt_ix": "245-ARR_v1_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_23",
            "tgt_ix": "245-ARR_v1_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_23",
            "tgt_ix": "245-ARR_v1_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_23",
            "tgt_ix": "245-ARR_v1_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_23",
            "tgt_ix": "245-ARR_v1_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_23",
            "tgt_ix": "245-ARR_v1_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_23",
            "tgt_ix": "245-ARR_v1_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_0",
            "tgt_ix": "245-ARR_v1_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_28",
            "tgt_ix": "245-ARR_v1_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_30",
            "tgt_ix": "245-ARR_v1_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_31",
            "tgt_ix": "245-ARR_v1_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_32",
            "tgt_ix": "245-ARR_v1_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_33",
            "tgt_ix": "245-ARR_v1_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_34",
            "tgt_ix": "245-ARR_v1_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_29",
            "tgt_ix": "245-ARR_v1_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_29",
            "tgt_ix": "245-ARR_v1_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_29",
            "tgt_ix": "245-ARR_v1_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_29",
            "tgt_ix": "245-ARR_v1_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_29",
            "tgt_ix": "245-ARR_v1_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_29",
            "tgt_ix": "245-ARR_v1_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_29",
            "tgt_ix": "245-ARR_v1_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_0",
            "tgt_ix": "245-ARR_v1_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_35",
            "tgt_ix": "245-ARR_v1_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_37",
            "tgt_ix": "245-ARR_v1_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_38",
            "tgt_ix": "245-ARR_v1_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_39",
            "tgt_ix": "245-ARR_v1_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_40",
            "tgt_ix": "245-ARR_v1_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_41",
            "tgt_ix": "245-ARR_v1_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_42",
            "tgt_ix": "245-ARR_v1_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_36",
            "tgt_ix": "245-ARR_v1_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_36",
            "tgt_ix": "245-ARR_v1_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_36",
            "tgt_ix": "245-ARR_v1_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_36",
            "tgt_ix": "245-ARR_v1_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_36",
            "tgt_ix": "245-ARR_v1_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_36",
            "tgt_ix": "245-ARR_v1_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_36",
            "tgt_ix": "245-ARR_v1_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_36",
            "tgt_ix": "245-ARR_v1_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_0",
            "tgt_ix": "245-ARR_v1_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_43",
            "tgt_ix": "245-ARR_v1_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_45",
            "tgt_ix": "245-ARR_v1_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_46",
            "tgt_ix": "245-ARR_v1_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_47",
            "tgt_ix": "245-ARR_v1_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_44",
            "tgt_ix": "245-ARR_v1_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_44",
            "tgt_ix": "245-ARR_v1_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_44",
            "tgt_ix": "245-ARR_v1_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_44",
            "tgt_ix": "245-ARR_v1_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_44",
            "tgt_ix": "245-ARR_v1_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_44",
            "tgt_ix": "245-ARR_v1_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_48",
            "tgt_ix": "245-ARR_v1_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_50",
            "tgt_ix": "245-ARR_v1_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_51",
            "tgt_ix": "245-ARR_v1_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_52",
            "tgt_ix": "245-ARR_v1_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_53",
            "tgt_ix": "245-ARR_v1_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_54",
            "tgt_ix": "245-ARR_v1_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_49",
            "tgt_ix": "245-ARR_v1_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_49",
            "tgt_ix": "245-ARR_v1_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_49",
            "tgt_ix": "245-ARR_v1_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_49",
            "tgt_ix": "245-ARR_v1_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_49",
            "tgt_ix": "245-ARR_v1_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_49",
            "tgt_ix": "245-ARR_v1_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_49",
            "tgt_ix": "245-ARR_v1_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_44",
            "tgt_ix": "245-ARR_v1_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_55",
            "tgt_ix": "245-ARR_v1_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_57",
            "tgt_ix": "245-ARR_v1_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_58",
            "tgt_ix": "245-ARR_v1_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_59",
            "tgt_ix": "245-ARR_v1_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_60",
            "tgt_ix": "245-ARR_v1_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_61",
            "tgt_ix": "245-ARR_v1_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_56",
            "tgt_ix": "245-ARR_v1_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_56",
            "tgt_ix": "245-ARR_v1_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_56",
            "tgt_ix": "245-ARR_v1_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_56",
            "tgt_ix": "245-ARR_v1_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_56",
            "tgt_ix": "245-ARR_v1_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_56",
            "tgt_ix": "245-ARR_v1_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_56",
            "tgt_ix": "245-ARR_v1_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_44",
            "tgt_ix": "245-ARR_v1_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_62",
            "tgt_ix": "245-ARR_v1_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_64",
            "tgt_ix": "245-ARR_v1_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_65",
            "tgt_ix": "245-ARR_v1_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_66",
            "tgt_ix": "245-ARR_v1_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_67",
            "tgt_ix": "245-ARR_v1_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_68",
            "tgt_ix": "245-ARR_v1_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_63",
            "tgt_ix": "245-ARR_v1_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_63",
            "tgt_ix": "245-ARR_v1_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_63",
            "tgt_ix": "245-ARR_v1_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_63",
            "tgt_ix": "245-ARR_v1_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_63",
            "tgt_ix": "245-ARR_v1_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_63",
            "tgt_ix": "245-ARR_v1_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_63",
            "tgt_ix": "245-ARR_v1_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_0",
            "tgt_ix": "245-ARR_v1_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_69",
            "tgt_ix": "245-ARR_v1_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_71",
            "tgt_ix": "245-ARR_v1_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_72",
            "tgt_ix": "245-ARR_v1_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_73",
            "tgt_ix": "245-ARR_v1_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_74",
            "tgt_ix": "245-ARR_v1_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_75",
            "tgt_ix": "245-ARR_v1_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_76",
            "tgt_ix": "245-ARR_v1_77",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_77",
            "tgt_ix": "245-ARR_v1_78",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_78",
            "tgt_ix": "245-ARR_v1_79",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_79",
            "tgt_ix": "245-ARR_v1_80",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_80",
            "tgt_ix": "245-ARR_v1_81",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_70",
            "tgt_ix": "245-ARR_v1_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_70",
            "tgt_ix": "245-ARR_v1_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_70",
            "tgt_ix": "245-ARR_v1_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_70",
            "tgt_ix": "245-ARR_v1_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_70",
            "tgt_ix": "245-ARR_v1_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_70",
            "tgt_ix": "245-ARR_v1_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_70",
            "tgt_ix": "245-ARR_v1_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_70",
            "tgt_ix": "245-ARR_v1_78",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_70",
            "tgt_ix": "245-ARR_v1_79",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_70",
            "tgt_ix": "245-ARR_v1_80",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_70",
            "tgt_ix": "245-ARR_v1_81",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_70",
            "tgt_ix": "245-ARR_v1_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_0",
            "tgt_ix": "245-ARR_v1_82",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_81",
            "tgt_ix": "245-ARR_v1_82",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_82",
            "tgt_ix": "245-ARR_v1_83",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_82",
            "tgt_ix": "245-ARR_v1_83",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_82",
            "tgt_ix": "245-ARR_v1_84",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_83",
            "tgt_ix": "245-ARR_v1_84",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_85",
            "tgt_ix": "245-ARR_v1_86",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_84",
            "tgt_ix": "245-ARR_v1_85",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_84",
            "tgt_ix": "245-ARR_v1_86",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_84",
            "tgt_ix": "245-ARR_v1_85",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_82",
            "tgt_ix": "245-ARR_v1_87",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_86",
            "tgt_ix": "245-ARR_v1_87",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_88",
            "tgt_ix": "245-ARR_v1_89",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_89",
            "tgt_ix": "245-ARR_v1_90",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_90",
            "tgt_ix": "245-ARR_v1_91",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_91",
            "tgt_ix": "245-ARR_v1_92",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_92",
            "tgt_ix": "245-ARR_v1_93",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_93",
            "tgt_ix": "245-ARR_v1_94",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_94",
            "tgt_ix": "245-ARR_v1_95",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_95",
            "tgt_ix": "245-ARR_v1_96",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_87",
            "tgt_ix": "245-ARR_v1_88",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_87",
            "tgt_ix": "245-ARR_v1_89",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_87",
            "tgt_ix": "245-ARR_v1_90",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_87",
            "tgt_ix": "245-ARR_v1_91",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_87",
            "tgt_ix": "245-ARR_v1_92",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_87",
            "tgt_ix": "245-ARR_v1_93",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_87",
            "tgt_ix": "245-ARR_v1_94",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_87",
            "tgt_ix": "245-ARR_v1_95",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_87",
            "tgt_ix": "245-ARR_v1_96",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_87",
            "tgt_ix": "245-ARR_v1_88",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_82",
            "tgt_ix": "245-ARR_v1_97",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_96",
            "tgt_ix": "245-ARR_v1_97",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_97",
            "tgt_ix": "245-ARR_v1_98",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_97",
            "tgt_ix": "245-ARR_v1_98",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_97",
            "tgt_ix": "245-ARR_v1_99",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_98",
            "tgt_ix": "245-ARR_v1_99",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_82",
            "tgt_ix": "245-ARR_v1_100",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_99",
            "tgt_ix": "245-ARR_v1_100",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_100",
            "tgt_ix": "245-ARR_v1_101",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_100",
            "tgt_ix": "245-ARR_v1_101",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_82",
            "tgt_ix": "245-ARR_v1_102",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_101",
            "tgt_ix": "245-ARR_v1_102",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_103",
            "tgt_ix": "245-ARR_v1_104",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_102",
            "tgt_ix": "245-ARR_v1_103",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_102",
            "tgt_ix": "245-ARR_v1_104",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_102",
            "tgt_ix": "245-ARR_v1_103",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_82",
            "tgt_ix": "245-ARR_v1_105",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_104",
            "tgt_ix": "245-ARR_v1_105",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_105",
            "tgt_ix": "245-ARR_v1_106",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_105",
            "tgt_ix": "245-ARR_v1_106",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_82",
            "tgt_ix": "245-ARR_v1_107",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_106",
            "tgt_ix": "245-ARR_v1_107",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_107",
            "tgt_ix": "245-ARR_v1_108",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_107",
            "tgt_ix": "245-ARR_v1_108",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_82",
            "tgt_ix": "245-ARR_v1_109",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_108",
            "tgt_ix": "245-ARR_v1_109",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_110",
            "tgt_ix": "245-ARR_v1_111",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_109",
            "tgt_ix": "245-ARR_v1_110",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_109",
            "tgt_ix": "245-ARR_v1_111",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_109",
            "tgt_ix": "245-ARR_v1_110",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_0",
            "tgt_ix": "245-ARR_v1_112",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_111",
            "tgt_ix": "245-ARR_v1_112",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_113",
            "tgt_ix": "245-ARR_v1_114",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_114",
            "tgt_ix": "245-ARR_v1_115",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_115",
            "tgt_ix": "245-ARR_v1_116",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_116",
            "tgt_ix": "245-ARR_v1_117",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_117",
            "tgt_ix": "245-ARR_v1_118",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_118",
            "tgt_ix": "245-ARR_v1_119",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_119",
            "tgt_ix": "245-ARR_v1_120",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_120",
            "tgt_ix": "245-ARR_v1_121",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_121",
            "tgt_ix": "245-ARR_v1_122",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_122",
            "tgt_ix": "245-ARR_v1_123",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_123",
            "tgt_ix": "245-ARR_v1_124",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_124",
            "tgt_ix": "245-ARR_v1_125",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_125",
            "tgt_ix": "245-ARR_v1_126",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_126",
            "tgt_ix": "245-ARR_v1_127",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_127",
            "tgt_ix": "245-ARR_v1_128",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_128",
            "tgt_ix": "245-ARR_v1_129",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_129",
            "tgt_ix": "245-ARR_v1_130",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_130",
            "tgt_ix": "245-ARR_v1_131",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_131",
            "tgt_ix": "245-ARR_v1_132",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_132",
            "tgt_ix": "245-ARR_v1_133",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_133",
            "tgt_ix": "245-ARR_v1_134",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_134",
            "tgt_ix": "245-ARR_v1_135",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_135",
            "tgt_ix": "245-ARR_v1_136",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_136",
            "tgt_ix": "245-ARR_v1_137",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_137",
            "tgt_ix": "245-ARR_v1_138",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_113",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_114",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_115",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_116",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_117",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_118",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_119",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_120",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_121",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_122",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_123",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_124",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_125",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_126",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_127",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_128",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_129",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_130",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_131",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_132",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_133",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_134",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_135",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_136",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_137",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_138",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_113",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_139",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_138",
            "tgt_ix": "245-ARR_v1_139",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_140",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_139",
            "tgt_ix": "245-ARR_v1_140",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_141",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_140",
            "tgt_ix": "245-ARR_v1_141",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "245-ARR_v1_0",
            "tgt_ix": "245-ARR_v1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_1",
            "tgt_ix": "245-ARR_v1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_2",
            "tgt_ix": "245-ARR_v1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_2",
            "tgt_ix": "245-ARR_v1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_2",
            "tgt_ix": "245-ARR_v1_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_2",
            "tgt_ix": "245-ARR_v1_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_2",
            "tgt_ix": "245-ARR_v1_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_3",
            "tgt_ix": "245-ARR_v1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_4",
            "tgt_ix": "245-ARR_v1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_4",
            "tgt_ix": "245-ARR_v1_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_5",
            "tgt_ix": "245-ARR_v1_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_5",
            "tgt_ix": "245-ARR_v1_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_5",
            "tgt_ix": "245-ARR_v1_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_5",
            "tgt_ix": "245-ARR_v1_5@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_6",
            "tgt_ix": "245-ARR_v1_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_6",
            "tgt_ix": "245-ARR_v1_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_7",
            "tgt_ix": "245-ARR_v1_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_7",
            "tgt_ix": "245-ARR_v1_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_7",
            "tgt_ix": "245-ARR_v1_7@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_7",
            "tgt_ix": "245-ARR_v1_7@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_7",
            "tgt_ix": "245-ARR_v1_7@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_7",
            "tgt_ix": "245-ARR_v1_7@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_7",
            "tgt_ix": "245-ARR_v1_7@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_8",
            "tgt_ix": "245-ARR_v1_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_8",
            "tgt_ix": "245-ARR_v1_8@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_9",
            "tgt_ix": "245-ARR_v1_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_10",
            "tgt_ix": "245-ARR_v1_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_10",
            "tgt_ix": "245-ARR_v1_10@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_10",
            "tgt_ix": "245-ARR_v1_10@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_11",
            "tgt_ix": "245-ARR_v1_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_11",
            "tgt_ix": "245-ARR_v1_11@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_11",
            "tgt_ix": "245-ARR_v1_11@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_11",
            "tgt_ix": "245-ARR_v1_11@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_12",
            "tgt_ix": "245-ARR_v1_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_12",
            "tgt_ix": "245-ARR_v1_12@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_13",
            "tgt_ix": "245-ARR_v1_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_14",
            "tgt_ix": "245-ARR_v1_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_15",
            "tgt_ix": "245-ARR_v1_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_16",
            "tgt_ix": "245-ARR_v1_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_16",
            "tgt_ix": "245-ARR_v1_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_16",
            "tgt_ix": "245-ARR_v1_16@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_17",
            "tgt_ix": "245-ARR_v1_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_18",
            "tgt_ix": "245-ARR_v1_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_18",
            "tgt_ix": "245-ARR_v1_18@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_18",
            "tgt_ix": "245-ARR_v1_18@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_19",
            "tgt_ix": "245-ARR_v1_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_20",
            "tgt_ix": "245-ARR_v1_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_21",
            "tgt_ix": "245-ARR_v1_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_22",
            "tgt_ix": "245-ARR_v1_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_22",
            "tgt_ix": "245-ARR_v1_22@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_23",
            "tgt_ix": "245-ARR_v1_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_24",
            "tgt_ix": "245-ARR_v1_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_24",
            "tgt_ix": "245-ARR_v1_24@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_24",
            "tgt_ix": "245-ARR_v1_24@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_25",
            "tgt_ix": "245-ARR_v1_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_25",
            "tgt_ix": "245-ARR_v1_25@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_25",
            "tgt_ix": "245-ARR_v1_25@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_26",
            "tgt_ix": "245-ARR_v1_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_27",
            "tgt_ix": "245-ARR_v1_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_28",
            "tgt_ix": "245-ARR_v1_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_29",
            "tgt_ix": "245-ARR_v1_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_30",
            "tgt_ix": "245-ARR_v1_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_31",
            "tgt_ix": "245-ARR_v1_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_32",
            "tgt_ix": "245-ARR_v1_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_33",
            "tgt_ix": "245-ARR_v1_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_34",
            "tgt_ix": "245-ARR_v1_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_35",
            "tgt_ix": "245-ARR_v1_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_35",
            "tgt_ix": "245-ARR_v1_35@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_35",
            "tgt_ix": "245-ARR_v1_35@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_36",
            "tgt_ix": "245-ARR_v1_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_37",
            "tgt_ix": "245-ARR_v1_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_37",
            "tgt_ix": "245-ARR_v1_37@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_38",
            "tgt_ix": "245-ARR_v1_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_39",
            "tgt_ix": "245-ARR_v1_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_40",
            "tgt_ix": "245-ARR_v1_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_40",
            "tgt_ix": "245-ARR_v1_40@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_41",
            "tgt_ix": "245-ARR_v1_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_41",
            "tgt_ix": "245-ARR_v1_41@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_41",
            "tgt_ix": "245-ARR_v1_41@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_42",
            "tgt_ix": "245-ARR_v1_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_43",
            "tgt_ix": "245-ARR_v1_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_44",
            "tgt_ix": "245-ARR_v1_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_45",
            "tgt_ix": "245-ARR_v1_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_45",
            "tgt_ix": "245-ARR_v1_45@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_46",
            "tgt_ix": "245-ARR_v1_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_47",
            "tgt_ix": "245-ARR_v1_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_48",
            "tgt_ix": "245-ARR_v1_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_48",
            "tgt_ix": "245-ARR_v1_48@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_48",
            "tgt_ix": "245-ARR_v1_48@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_49",
            "tgt_ix": "245-ARR_v1_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_50",
            "tgt_ix": "245-ARR_v1_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_50",
            "tgt_ix": "245-ARR_v1_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_50",
            "tgt_ix": "245-ARR_v1_50@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_50",
            "tgt_ix": "245-ARR_v1_50@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_51",
            "tgt_ix": "245-ARR_v1_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_52",
            "tgt_ix": "245-ARR_v1_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_53",
            "tgt_ix": "245-ARR_v1_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_54",
            "tgt_ix": "245-ARR_v1_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_55",
            "tgt_ix": "245-ARR_v1_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_55",
            "tgt_ix": "245-ARR_v1_55@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_56",
            "tgt_ix": "245-ARR_v1_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_57",
            "tgt_ix": "245-ARR_v1_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_57",
            "tgt_ix": "245-ARR_v1_57@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_57",
            "tgt_ix": "245-ARR_v1_57@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_58",
            "tgt_ix": "245-ARR_v1_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_59",
            "tgt_ix": "245-ARR_v1_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_60",
            "tgt_ix": "245-ARR_v1_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_61",
            "tgt_ix": "245-ARR_v1_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_62",
            "tgt_ix": "245-ARR_v1_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_62",
            "tgt_ix": "245-ARR_v1_62@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_62",
            "tgt_ix": "245-ARR_v1_62@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_62",
            "tgt_ix": "245-ARR_v1_62@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_63",
            "tgt_ix": "245-ARR_v1_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_64",
            "tgt_ix": "245-ARR_v1_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_65",
            "tgt_ix": "245-ARR_v1_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_66",
            "tgt_ix": "245-ARR_v1_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_67",
            "tgt_ix": "245-ARR_v1_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_67",
            "tgt_ix": "245-ARR_v1_67@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_67",
            "tgt_ix": "245-ARR_v1_67@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_68",
            "tgt_ix": "245-ARR_v1_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_69",
            "tgt_ix": "245-ARR_v1_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_69",
            "tgt_ix": "245-ARR_v1_69@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_70",
            "tgt_ix": "245-ARR_v1_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_71",
            "tgt_ix": "245-ARR_v1_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_71",
            "tgt_ix": "245-ARR_v1_71@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_72",
            "tgt_ix": "245-ARR_v1_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_73",
            "tgt_ix": "245-ARR_v1_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_73",
            "tgt_ix": "245-ARR_v1_73@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_73",
            "tgt_ix": "245-ARR_v1_73@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_73",
            "tgt_ix": "245-ARR_v1_73@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_74",
            "tgt_ix": "245-ARR_v1_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_75",
            "tgt_ix": "245-ARR_v1_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_76",
            "tgt_ix": "245-ARR_v1_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_76",
            "tgt_ix": "245-ARR_v1_76@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_77",
            "tgt_ix": "245-ARR_v1_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_78",
            "tgt_ix": "245-ARR_v1_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_78",
            "tgt_ix": "245-ARR_v1_78@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_78",
            "tgt_ix": "245-ARR_v1_78@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_79",
            "tgt_ix": "245-ARR_v1_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_80",
            "tgt_ix": "245-ARR_v1_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_80",
            "tgt_ix": "245-ARR_v1_80@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_81",
            "tgt_ix": "245-ARR_v1_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_81",
            "tgt_ix": "245-ARR_v1_81@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_82",
            "tgt_ix": "245-ARR_v1_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_83",
            "tgt_ix": "245-ARR_v1_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_83",
            "tgt_ix": "245-ARR_v1_83@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_83",
            "tgt_ix": "245-ARR_v1_83@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_84",
            "tgt_ix": "245-ARR_v1_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_85",
            "tgt_ix": "245-ARR_v1_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_85",
            "tgt_ix": "245-ARR_v1_85@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_85",
            "tgt_ix": "245-ARR_v1_85@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_85",
            "tgt_ix": "245-ARR_v1_85@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_85",
            "tgt_ix": "245-ARR_v1_85@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_86",
            "tgt_ix": "245-ARR_v1_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_86",
            "tgt_ix": "245-ARR_v1_86@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_87",
            "tgt_ix": "245-ARR_v1_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_88",
            "tgt_ix": "245-ARR_v1_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_89",
            "tgt_ix": "245-ARR_v1_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_90",
            "tgt_ix": "245-ARR_v1_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_91",
            "tgt_ix": "245-ARR_v1_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_92",
            "tgt_ix": "245-ARR_v1_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_93",
            "tgt_ix": "245-ARR_v1_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_94",
            "tgt_ix": "245-ARR_v1_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_95",
            "tgt_ix": "245-ARR_v1_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_96",
            "tgt_ix": "245-ARR_v1_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_97",
            "tgt_ix": "245-ARR_v1_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_98",
            "tgt_ix": "245-ARR_v1_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_98",
            "tgt_ix": "245-ARR_v1_98@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_98",
            "tgt_ix": "245-ARR_v1_98@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_98",
            "tgt_ix": "245-ARR_v1_98@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_98",
            "tgt_ix": "245-ARR_v1_98@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_98",
            "tgt_ix": "245-ARR_v1_98@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_98",
            "tgt_ix": "245-ARR_v1_98@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_99",
            "tgt_ix": "245-ARR_v1_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_100",
            "tgt_ix": "245-ARR_v1_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_101",
            "tgt_ix": "245-ARR_v1_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_101",
            "tgt_ix": "245-ARR_v1_101@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_102",
            "tgt_ix": "245-ARR_v1_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_103",
            "tgt_ix": "245-ARR_v1_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_103",
            "tgt_ix": "245-ARR_v1_103@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_103",
            "tgt_ix": "245-ARR_v1_103@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_103",
            "tgt_ix": "245-ARR_v1_103@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_104",
            "tgt_ix": "245-ARR_v1_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_104",
            "tgt_ix": "245-ARR_v1_104@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_104",
            "tgt_ix": "245-ARR_v1_104@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_104",
            "tgt_ix": "245-ARR_v1_104@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_104",
            "tgt_ix": "245-ARR_v1_104@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_105",
            "tgt_ix": "245-ARR_v1_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_106",
            "tgt_ix": "245-ARR_v1_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_106",
            "tgt_ix": "245-ARR_v1_106@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_106",
            "tgt_ix": "245-ARR_v1_106@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_106",
            "tgt_ix": "245-ARR_v1_106@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_106",
            "tgt_ix": "245-ARR_v1_106@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_107",
            "tgt_ix": "245-ARR_v1_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_108",
            "tgt_ix": "245-ARR_v1_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_108",
            "tgt_ix": "245-ARR_v1_108@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_108",
            "tgt_ix": "245-ARR_v1_108@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_108",
            "tgt_ix": "245-ARR_v1_108@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_108",
            "tgt_ix": "245-ARR_v1_108@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_109",
            "tgt_ix": "245-ARR_v1_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_110",
            "tgt_ix": "245-ARR_v1_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_110",
            "tgt_ix": "245-ARR_v1_110@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_110",
            "tgt_ix": "245-ARR_v1_110@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_111",
            "tgt_ix": "245-ARR_v1_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_111",
            "tgt_ix": "245-ARR_v1_111@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_111",
            "tgt_ix": "245-ARR_v1_111@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_112",
            "tgt_ix": "245-ARR_v1_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_113",
            "tgt_ix": "245-ARR_v1_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_113",
            "tgt_ix": "245-ARR_v1_113@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_113",
            "tgt_ix": "245-ARR_v1_113@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_114",
            "tgt_ix": "245-ARR_v1_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_114",
            "tgt_ix": "245-ARR_v1_114@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_115",
            "tgt_ix": "245-ARR_v1_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_116",
            "tgt_ix": "245-ARR_v1_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_116",
            "tgt_ix": "245-ARR_v1_116@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_117",
            "tgt_ix": "245-ARR_v1_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_118",
            "tgt_ix": "245-ARR_v1_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_119",
            "tgt_ix": "245-ARR_v1_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_119",
            "tgt_ix": "245-ARR_v1_119@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_120",
            "tgt_ix": "245-ARR_v1_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_121",
            "tgt_ix": "245-ARR_v1_121@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_122",
            "tgt_ix": "245-ARR_v1_122@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_123",
            "tgt_ix": "245-ARR_v1_123@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_124",
            "tgt_ix": "245-ARR_v1_124@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_125",
            "tgt_ix": "245-ARR_v1_125@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_126",
            "tgt_ix": "245-ARR_v1_126@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_127",
            "tgt_ix": "245-ARR_v1_127@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_127",
            "tgt_ix": "245-ARR_v1_127@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_128",
            "tgt_ix": "245-ARR_v1_128@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_129",
            "tgt_ix": "245-ARR_v1_129@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_130",
            "tgt_ix": "245-ARR_v1_130@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_131",
            "tgt_ix": "245-ARR_v1_131@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_132",
            "tgt_ix": "245-ARR_v1_132@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_133",
            "tgt_ix": "245-ARR_v1_133@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_134",
            "tgt_ix": "245-ARR_v1_134@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_135",
            "tgt_ix": "245-ARR_v1_135@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_136",
            "tgt_ix": "245-ARR_v1_136@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_137",
            "tgt_ix": "245-ARR_v1_137@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_138",
            "tgt_ix": "245-ARR_v1_138@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_139",
            "tgt_ix": "245-ARR_v1_139@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_139",
            "tgt_ix": "245-ARR_v1_139@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_139",
            "tgt_ix": "245-ARR_v1_139@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_139",
            "tgt_ix": "245-ARR_v1_139@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_139",
            "tgt_ix": "245-ARR_v1_139@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_139",
            "tgt_ix": "245-ARR_v1_139@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_139",
            "tgt_ix": "245-ARR_v1_139@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_139",
            "tgt_ix": "245-ARR_v1_139@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_139",
            "tgt_ix": "245-ARR_v1_139@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_139",
            "tgt_ix": "245-ARR_v1_139@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_139",
            "tgt_ix": "245-ARR_v1_139@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_140",
            "tgt_ix": "245-ARR_v1_140@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_140",
            "tgt_ix": "245-ARR_v1_140@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_140",
            "tgt_ix": "245-ARR_v1_140@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_141",
            "tgt_ix": "245-ARR_v1_141@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_142",
            "tgt_ix": "245-ARR_v1_142@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_143",
            "tgt_ix": "245-ARR_v1_143@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_144",
            "tgt_ix": "245-ARR_v1_144@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_145",
            "tgt_ix": "245-ARR_v1_145@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_146",
            "tgt_ix": "245-ARR_v1_146@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_147",
            "tgt_ix": "245-ARR_v1_147@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_148",
            "tgt_ix": "245-ARR_v1_148@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_149",
            "tgt_ix": "245-ARR_v1_149@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_150",
            "tgt_ix": "245-ARR_v1_150@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_151",
            "tgt_ix": "245-ARR_v1_151@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_152",
            "tgt_ix": "245-ARR_v1_152@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_153",
            "tgt_ix": "245-ARR_v1_153@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_154",
            "tgt_ix": "245-ARR_v1_154@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_155",
            "tgt_ix": "245-ARR_v1_155@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_156",
            "tgt_ix": "245-ARR_v1_156@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_157",
            "tgt_ix": "245-ARR_v1_157@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_158",
            "tgt_ix": "245-ARR_v1_158@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_159",
            "tgt_ix": "245-ARR_v1_159@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_160",
            "tgt_ix": "245-ARR_v1_160@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_161",
            "tgt_ix": "245-ARR_v1_161@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_162",
            "tgt_ix": "245-ARR_v1_162@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_163",
            "tgt_ix": "245-ARR_v1_163@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_164",
            "tgt_ix": "245-ARR_v1_164@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_165",
            "tgt_ix": "245-ARR_v1_165@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "245-ARR_v1_166",
            "tgt_ix": "245-ARR_v1_166@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 1343,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "position_tag_type": "from_draft",
        "doc_id": "245-ARR",
        "version": 1
    }
}