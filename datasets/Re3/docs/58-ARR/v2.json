{
    "nodes": [
        {
            "ix": "58-ARR_v2_0",
            "content": "Multilingual Document-Level Translation Enables Zero-Shot Transfer From Sentences to Documents",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_2",
            "content": "Document-level neural machine translation (DocNMT) achieves coherent translations by incorporating cross-sentence context. However, for most language pairs there's a shortage of parallel documents, although parallel sentences are readily available. In this paper, we study whether and how contextual modeling in DocNMT is transferable via multilingual modeling. We focus on the scenario of zero-shot transfer from teacher languages with document level data to student languages with no documents but sentence level data, and for the first time treat document-level translation as a transfer learning problem. Using simple concatenation-based DocNMT, we explore the effect of 3 factors on the transfer: the number of teacher languages with document level data, the balance between document and sentence level data at training, and the data condition of parallel documents (genuine vs. backtranslated). Our experiments on Europarl-7 and IWSLT-10 show the feasibility of multilingual transfer for DocNMT, particularly on document-specific metrics. We observe that more teacher languages and adequate data balance both contribute to better transfer quality. Surprisingly, the transfer is less sensitive to the data condition, where multilingual DocNMT delivers decent performance with either backtranslated or genuine document pairs. * Work done while Biao Zhang was interning at Google Research.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "58-ARR_v2_4",
            "content": "Recent years have witnessed a trend moving from sentence-level neural machine translation (Sen-NMT) to its document-level counterpart (Doc-NMT). SenNMT inevitably suffers from translation errors related with document phenomena (Maruf et al., 2021) and delivers obviously inferior performance when compared against human translations and evaluated at a document level (L\u00e4ubli et al., 2018). Most efforts on DocNMT aim at improving contextual modeling via dedicated model architectures and/or decoding algorithms (Bawden et al., 2018;Voita et al., 2019; and heavily rely on large-scale parallel document resources. Nevertheless, document resources are unevenly distributed across language pairs, with most pairs having little to no such resources. 1 One promising way to accommodate languages with varied training data is multilingual modeling, as demonstrated in multilingual SenNMT (Firat et al., 2016;Johnson et al., 2017). By sharing parameters across languages, multilingual modeling encourages cross-lingual knowledge transfer, enabling performance improvement and even zeroshot transfer (Aharoni et al., 2019;Arivazhagan et al., 2019b;Zhang et al., , 2021. In the context of translation, however, most studies on multilingual transfer center around SenNMT, seldom going beyond sentence-level translation. So far, the question of whether and how document-level contextual modeling can be learned cross-lingually in multilingual DocNMT is still unanswered.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_5",
            "content": "In this paper, we study zero-shot generalization for DocNMT -the ability to attain plausible Doc-NMT quality for some focused (student) language pair(s), with only parallel sentences for the student but parallel documents for other (teacher) languages in the multilingual mix. The high-level research question we seek to answer is illustrated in Figure 1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_6",
            "content": "We resort to transfer learning via multilinguality to leverage document resources in teacher languages to help the student languages. We perform our analysis using a simple concatenation based DocNMT, where consecutive sentences are chained into one sequence for translation. We investigate three dimensions extensively to understand the transfer in multilingual DocNMT: 1) the number of languages with document level data (teacher languages), where we simplify our transfer setup to contain either only one teacher language (with N students) or N teachers (with one student); 2) the data balance for parallel documents, i.e. manipulating the ratio of document-level data to sentencelevel data during training; and 3) the data condition of parallel documents, where we adopt backtranslated parallel documents when only monolingual documents are given in teacher languages or use genuine parallel documents crawled natively.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_7",
            "content": "We conduct experiments on two publicly available datasets, namely Europarl-7 and IWSLT-10, covering 6 and 9 languages from/to English respectively. We analyze one-to-many (En\u2192Xx) and many-to-one (Xx\u2192En) translation scenarios separately. Following recent work (Ma et al., 2021), we adopt document-specific metrics for evaluation apart from BLEU and support our findings with human evaluations. We also propose a pronoun F1 metric (targeted at gendered pronouns: he/she) for Xx\u2192En translation, and employ accuracy on contrastive test sets (Bawden et al., 2018;M\u00fcller et al., 2018) for En\u2192Xx translation. Our main findings are summarized below:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_8",
            "content": "\u2022 Zero-shot transfer from sentences to documents is feasible through multilingual Doc-NMT modeling, particularly when evaluated with document-specific metrics. This is partially supported by human evaluation. \u2022 Transfer quality is strongly affected by the number of teacher languages that use document level data and the data balance for documents. Higher quality is achieved with more teacher languages and adequate document schedule, where the optimal balance varies across scenarios. \u2022 Surprisingly, transfer via back-translated documents performs comparable to transfer via genuine parallel documents. \u2022 Zero-shot transfer from high-resource document level languages and to low-resource sentence level ones is relatively easier, resulting in better transfer results.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_9",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "58-ARR_v2_10",
            "content": "Document-level MT Integrating document-level information meaningfully into NMT is a challenging task, which has inspired research not only on exploring advanced context-aware neural architectures, including simple concatenation-based models (Tiedemann and Scherrer, 2017;Junczys-Dowmunt, 2019;Lopes et al., 2020), multi-source models (Jean et al., 2017;Bawden et al., 2018;Zhang et al., 2018), hierarchical models (Miculicich et al., 2018;Zheng et al., 2020;, multi-pass models (Voita et al., 2019;Yu et al., 2020;Mansimov et al., 2021) and dynamic context models (Kang et al., 2020), to name a few.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_11",
            "content": "But it has also motivated the field to revisit the common protocols resorted for evaluation (Freitag et al., 2021). Despite the hard to measure success, all the above mentioned methods implicitly assume an abundance of document resources and overlook the data scarcity problem. In this study, we adopt the simple concatenation model as our experimental protocol, and leave the exploration of various input formatting options and modelling to future work. Considering the fast changing landscape of the (contextual) MT evaluation, we also provide multiple evaluation metrics including human evaluations, to give a full picture of the phenomena under investigation, while acknowledging the current imperfections of and disagreements on the right way of evaluating MT systems (Kocmi et al., 2021).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_12",
            "content": "Zero-Shot Transfer via Multilinguality Multilingual modeling often clusters sentences of similar meaning from different languages within a shared semantic space (Kudugunta et al., 2019;. Such representation space is hypothesized to enable zero-shot transfer, delivering improved performance in many cross-lingual tasks (Eriguchi et al., 2018;Hu et al., 2020;Chi et al., 2021;Ruder et al., 2021), especially based on large-scale pretrained multilingual Transformers (Devlin et al., 2019;Conneau and Lample, 2019;Xue et al., 2021). When it comes to transla-tion, multilingual SenNMT successfully achieves zero-shot translation, transferring sentence-level generation knowledge to language pairs unseen during training (Firat et al., 2016;Johnson et al., 2017;Gu et al., 2019;Arivazhagan et al., 2019a) even in massively multilingual settings (Aharoni et al., 2019;Arivazhagan et al., 2019b;Zhang et al., , 2021. Our study extends multilingual SenNMT to multilingual DocNMT and aims at document-level knowledge transfer from languages that have document level data to languages that only have sentence level data. To the best of our knowledge, our study is the first demonstrating the emergence of document-level zero-shot transfer across languages for multilingual machine translation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_13",
            "content": "Zero-Shot Transfer in Multilingual DocNMT",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "58-ARR_v2_14",
            "content": "We first formulate the zero-shot generalization framework explored in this paper. Given N+1 language pairs, we assume that all of them have parallel sentences for training, but only some of them have parallel documents (teachers). Through multilingual training, we study to what degree contextual modeling in document-supervised DocNMT can be transferred to those document-poor (student) languages as in Figure 1. Any form of parallel document for student languages is disallowed at training, ensuring that the transfer is measured zero-shot.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_15",
            "content": "Multilingual DocNMT",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "58-ARR_v2_16",
            "content": "We employ the concatenation-based method with a D2D structure for DocNMT, where D consecutive sentences in a document are concatenated into one sequence for translation (Junczys-Dowmunt, 2019;Sun et al., 2020). Sentence boundary is indicated by a special symbol \"[SEN]\". We adopt the language token method (Johnson et al., 2017) for multilingual DocNMT, using source and target language token for Xx\u2192En and En\u2192Xx translation respectively. Instead of appending this token to the source sequence, we add its embedding to each source word embedding to strengthen the language signal in a document translation setting.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_17",
            "content": "For training, we adopt a two-stage method: we first pretrain a multilingual SenNMT on sentence level data for all languages; then, we finetune it to obtain multilingual DocNMT on a mix of document level data from teacher languages and sentence level data from student languages. Our analysis requires training a large number of DocNMT models, and the two-stage method saves substantial amounts of computation by sharing the pretrained SenNMT. For evaluation, we distinguish sentencelevel inference (SenInfer) from its document-level counterpart (DocInfer). SenInfer translates sentences separately (out of context), while DocInfer translates D consecutive and non-overlapping sentences in context with each other. 2",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_18",
            "content": "Zero-Shot Setup",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "58-ARR_v2_19",
            "content": "We explore three factors for the zero-shot transfer:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_20",
            "content": "\u2022 The number of teacher languages The source of the transfer comes from teacher languages. Intuitively, both the number of teacher languages and their relevance to student language(s) affect the transfer result. However, exhaustively exploring all possible teacherstudent configurations in a multilingual setting will lead to a large search space that expands exponentially with respect to the total number of languages involved. Instead, we simplify our study by exploring two extreme transfer settings, namely N21 and 12N transfer. The first setting uses N teachers that incorporate document level data with 1 student having sentence level data only, while the second setting has 1 teacher and N students. Note that in either N21 or 12N transfer, there exist N teacher-student configurations, and we report average results over them. 3 \u2022 The data balance for parallel documents When varying the number of teacher languages, the proportion of document data at training also changes. Such imbalance could deeply affect transfer (Arivazhagan et al., 2019b). To offset this effect, we include the data balance for analysis by controlling the sampling ratio p of documents from 0.1 to 0.9 with a step size of 0.1. Note p is for documents in all teacher languages, and the relative proportion among teachers is always retained. \u2022 The data condition of parallel documents We also study when teacher languages have no parallel documents but only monolingual ones. Methods utilizing monolingual documents for DocNMT vary greatly. Following recent work (Sugiyama and Yoshinaga, 2019;Huo et al., 2020;Ul Haq et al., 2020), we adopt back-translation (BT) to construct pseudo parallel documents. Note that, for teacher languages, we replace all sentence level training data with pseudo documents rather than mixing them according to our empirical results in Appendix C.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_21",
            "content": "Experimental Settings",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "58-ARR_v2_22",
            "content": "Datasets We conduct experiments on two public datasets: Europarl-7 and IWSLT-10. Europarl-7 is extracted from European Parliament (v10) and has translations between English and N =6 different languages, including Czech, German, Finnish, French, Lithuanian and Polish (Koehn, 2005). This dataset offers sentence-aligned parallel documents (0.9K\u223c3.7K documents, 190K\u223c1.9M sentences) and also monolingual documents (9.7K\u223c11K documents, 0.65M\u223c2.28M sentences) for training. For evaluation, we use the WMT dev and test sets (Barrault et al., 2020) available for each language pair (from 2013 to 2020). In contrast, IWSLT-10 is collected from TED talks and covers translations between English and N =9 different languages, including Arabic, German, French, Italian, Japanese, Korean, Dutch, Romanian and Chinese (Cettolo et al., 2017). Unlike Europarl-7, the distribution of training data over languages in IWSLT-10 is much smoother (uniform). There are \u223c1.9K sentencealigned parallel documents with \u223c240K sentences for each language pair. We further collected about 1K TED talks for each language pair (crawled from Feb 2018 to Jan 2021) as monolingual documents.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_23",
            "content": "We use IWSLT17 dev and test sets for evaluation. Detailed statistics are given in Appendix A. We preprocess all texts with the byte pair encoding (BPE) algorithm (Sennrich et al., 2016) implemented in the sentencepiece toolkit (Kudo and Richardson, 2018), and set the vocabulary size to 32K and 64K for IWSLT-10 and Europarl-7, respectively.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_24",
            "content": "Model Details We use the Transformer-base model (Vaswani et al., 2017) for experiments with 6 encoder/decoder layers, 8 attention heads and a model dimension of 512/2048. We set D = 5 for DocNMT. We use Adam (Kingma and Ba, 2015) (\u03b2 1 = 0.9, \u03b2 2 = 0.98) for parameter update with a learning rate warmup step of 4K and label smoothing rate of 0.1. We apply dropout to residual connections and attention weights with a rate of 0.5 and 0.2, respectively. Other training and decoding details are given in Appendix B.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_25",
            "content": "Back-Translation Some of our models are trained using back-translated monolingual documents. Back-translations are obtained using bilingual SenNMT (independently for Europarl-7 and IWSLT-10). To train these models, we halve the BPE vocabulary size as well as the training steps.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_26",
            "content": "All other settings are kept as mentioned above.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_27",
            "content": "Evaluation Following previous work, we use BLEU (Post, 2018) 4 to measure the general translation quality. Document-level BLEU is calculated by counting n-gram at the document level instead of at the individual sentence level (Sun et al., 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_28",
            "content": "Measuring improvements to document phenomena in translation automatically remains challenging and oftentimes simple surface-based metrics such as BLEU (L\u00e4ubli et al., 2018) are not sensitive enough. Therefore, we evaluate our model on test sets that focus on such document phenomena. We use the contrastive test sets for En-De (M\u00fcller et al., 2018) and En-Fr (Bawden et al., 2018) which measure a model's ability to distinguish correct from incorrect anaphoric pronoun translations. We include 4 and 1 additional context sentences for En-De and En-Fr contrastive evaluation, respectively.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_29",
            "content": "Gender bias in translation models has attracted much attention recently (Kuczmarski and Johnson, 2018;Saunders and Byrne, 2020). We expect that contextual information can help to alleviate it. To this end, we introduce gendered pronoun F1 based on the following precision and recall scores to evaluate English translations:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_30",
            "content": "Precision = i,g\u2208G min(C g r i , C g h i ) i,g\u2208G C g h i Recall = i,g\u2208G min(C g r i , C g h i ) i,g\u2208G C g r i ,(1)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_31",
            "content": "where r i and h i denotes the i-th gold reference and hypothesis sentence respectively, comprising the gendered pronouns of interest G 5 . C g x denotes the count of pronoun g in sentence x.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_32",
            "content": "Finally, we conduct human evaluation to verify the performance delivered by zero-shot transfer. We work on En-De, Europarl-7, where we sample 50 source documents from the test set, and translate them into the target language using the corresponding models and decoding techniques. The translated documents are presented to bilingual human raters who are native in the non-English locale. The raters are asked to evaluate translation qualities while taking the full source document context into account. The raters assign a score in a 0-6 scale to every sentence-translation pair in the document, where 0 and 6 mean nonsense and perfect translations, respectively. For each model, the scores are aggregated across the entire test corpus and the average scores are reported. To ensure a fair diversity of ratings, each rater rates no more than 6 documents per model; an average of 18 raters evaluated each model independently. dard deviation over N configurations. 6 Overall, the document-level zero-shot transfer is achievable via multilingual modeling. Transfer-based DocNMT could successfully identify and translate the correct number of input sentences for student languages. With a proper sampling ratio for document-level data, student DocNMT yields better performance than its SenNMT counterpart, especially shown by document-specific evaluations (F1 and ACC).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_33",
            "content": "Results and Analysis",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "58-ARR_v2_34",
            "content": "Increasing teacher languages improves transfer. In En\u2192Xx and Xx\u2192En translation, we find that N21 transfer performs consistently better than 12N transfer on all metrics. This is reasonable since N21 transfer has N teacher languages, offering richer and more informative sources for transfer.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_35",
            "content": "Balancing between document and sentence data matters for transfer. We also observe that performance changes over the document proportion on all metrics in both 12N and N21 transfer. Applying more or fewer documents during training often hurts zero-shot transfer, indicating a trade-off. Roughly, setting p to 30%\u223c50% delivers good performance (Figure 2 and 3), although the optimal proportion depends.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_36",
            "content": "SenInfer underperforms DocInfer on documentspecific metrics. DocNMT w/ SenInfer performs similarly to SenNMT, and better than DocInfer on BLEU. When evaluating document phenomena, however, SenInfer shows clear insufficiency. This resonates with the findings of Ma et al. (2021).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_37",
            "content": "Can we achieve zero-shot transfer with monolingual documents? Yes. We next repeat our experiments with BT document pairs. Figure 4 and 5 show that BT performs surprisingly well on document-level zero-shot transfer. We observe almost the same performance pattern compared to training with genuine documents in all settings (En\u2192Xx and Xx\u2192En, N21 and 12N transfer and different metrics), although BLEU scores become worse and the optimal proportion also changes. We argue that the target-side genuine context information in BT documents helps contextual model- Table 3: Performance of different models on Europarl-7 and IWSLT-10. \u2021 : multilingual DocNMT trained on parallel documents from all language pairs. For 12N and N21 transfer, we report one group of results under the approximately optimal proportion p. Notice that the results for transfer experiments are averaged over different teacher-student configurations, while those for DocNMT \u2021 are for one model. We report absolute scores for SenNMT but relative scores for the others.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_38",
            "content": "ing (Ma et al., 2021). These results are promising, encouraging further research on exploring monolingual documents for multilingual DocNMT.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_39",
            "content": "Impact of high/low-resource languages on zeroshot transfer. The data distribution of Europarl-7 is highly skewed over languages, with Cs, Lt, Pl being relatively low-resource languages while De, Fi, Fr being high-resource ones. Studies on multilingual SenNMT have witnessed the transfer from high-resource to low-resource languages (Aharoni et al., 2019;. We next analyze how this data scale difference affects documentlevel zero-shot transfer. We mainly explore 12N transfer because of the single transfer source, avoiding interference from other teacher languages. Table 2 lists the results. Regardless of the data condition (genuine or BT document pairs), transferring from high-resource teacher languages often outperforms that from low-resource ones. Besides, transferring into low-resource student languages delivers better transfer than into high-resource ones. These suggest that increasing the document data for teacher languages benefits zero-shot transfer.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_40",
            "content": "Note we also provide transfer results from individual languages to De and Fr in Appendix D.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_41",
            "content": "We summarize the main results on both datasets in Table 3. Although IWSLT-10 (N=9) includes more (distant) languages and distributes quite differently over languages, the results on IWSLT-10 resemble those on Europarl-7. On both datasets, we observe that transfer, both 12N and N21, yields very positive results, particularly with document-specific metrics. Unlike Europarl-7, BT-based transfer per- Ratings are on a 0-6 scale; higher scores mean better quality.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_42",
            "content": "forms much worse than models trained on genuine document pairs on IWSLT-10. We ascribe this to the data scarcity, where only very small-scale monolingual documents are used for BT in IWSLT-10. This also reinforces our observation that more document resources benefits zero-shot transfer.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_43",
            "content": "Discussion",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "58-ARR_v2_44",
            "content": "Apart from automatic evaluation, we also offer human evaluation on En-De. We choose En-De as its WMT20 test set is intentionally constructed for DocNMT evaluation. Table 4 lists the results. We observe that zero-shot transfer matches and even surpasses SenNMT through N21 transfer, but fails with 12N transfer, although accuracy improvements on contrastive test sets show that both transfers are better than SenNMT. We conjecture that these contrastive test sets only target a limited number of document phenomena and thus can't fully reflect the overall translation quality and represent human preference. These numbers verify the feasibility of document-level zero-shot transfer through multilinguality. Besides, we find that genuine parallel documents benefit the transfer slightly more than BT-based pseudo ones, and that the supervised DocNMT reaches the best result under DocInfer.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_45",
            "content": "We surprisingly find that DocNMT with SenInfer yields very competitive performance, although no contextual information is used for decoding. We also observe that such decoding tends to produce longer translations than SenNMT despite using the same decoding hyperparameters. This behaviour should be shaped by the fact that DocNMT is biased towards long concatenated target references. This partially agrees with the recent argument that context improves DocNMT with some sort of regularization rather than teaching the model to deal with context (Kim et al., 2019). On the other hand, this challenges how to properly evaluate DocNMT.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_46",
            "content": "Another observation is that applying DocInfer to SenNMT delivers a significant accuracy improvement on En-Fr contrastive test set (+8.5%, Table 5), but slightly worse results on En-De. To accurately recognize the correct translation in these test sets, models need to leverage context. Such improvement might suggest that SenNMT has some limited capability of contextual modeling, but might just reflect the instability of small-scale test sets (only 200 cases in En-Fr test set, indicating a radius of around 7% for the 95% confidence interval). To some extent, this devalues the improvement achieved by 12N transfer as shown in Table 3, but strengthens the success of N21 transfer (often >9% gains).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_47",
            "content": "Conclusion and Future Work",
            "ntype": "title",
            "meta": {
                "section": "7"
            }
        },
        {
            "ix": "58-ARR_v2_48",
            "content": "This paper studies the variables playing role in achieving zero-shot document-level translation capability for languages that only have sentence level data (students), through multilingual transfer from languages that have access to document level data (teachers). We make the first step in this direction by extensively exploring properties of transfer by investigating three different variables. Our experiments on Europarl-7 and IWSLT-10 confirm the feasibility, where we discover that increasing document-supervised teacher languages thereby increasing the document training data size, adequately balancing between document and sentence data at training, and leveraging monolingual documents via back-translation all benefit zero-shot transfer in varying degrees. The transferability of contextual modeling in DocNMT demonstrates the potential of delivering multilingual DocNMT with limited document resources.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_49",
            "content": "Along with the success of document-level zeroshot transfer, problems with accurately estimating the document-level translation become challenging. BLEU often fails to capture document phenomena, while contrastive test sets only cover few document-level aspects. Neither perfectly correlates with human evaluation. Besides, whether the gains really come from contextual modeling is still unclear. Our human evaluation shows some preference to DocNMT with SenInfer where context is not used for decoding at all. Designing better evaluation protocols (either automatic or human) is again confirmed to be critical. Besides, performing analysis beyond 12N and N21 transfer deserves more effort and it is an interesting and plausible future direction to analyze how language similarity affects the transfer.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_50",
            "content": "Zaixiang Zheng, Xiang Yue, Shujian Huang, Jiajun Chen, and Alexandra Birch. 2020. Towards making the most of context in neural machine translation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_51",
            "content": "In Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20, pages 3983-3989. International Joint Conferences on Artificial Intelligence Organization. Main track.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_52",
            "content": "Table 6 shows the statistics for Europarl-7 and IWSLT-10. Compared to IWSLT-10, Europarl-7 includes fewer languages, but with higher quantity and more uneven distribution.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_53",
            "content": "We pretrain multilingual SenNMT for 100K and 300K steps on IWSLT-10 and Europarl-7 respectively, and adopt extra 20K finetuning steps for multilingual DocNMT. We train all models (Sen-NMT & DocNMT) with a fixed batch size of 1280 samples, and schedule the training data distribution over language pairs according to the sentence-level statistics (without oversampling, and this also applies to DocNMT). All such measures aim to ensure a fair comparison between SenNMT and DocNMT.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_54",
            "content": "For training, we truncate sequences with length limit of 100 and 512 for SenNMT and DocNMT separately. We average last 5 checkpoints for evaluation. Beam search is used for decoding with a beam size of 4 and length penalty of 0.6. During decoding, we disable the generation of the endof-sentence symbol for DocInfer until the model outputs the correct number of target translations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_55",
            "content": "The back-translated documents belong to extra training data. How to mix them with the genuine sentence pairs during training is questionable. Before further study, we first explore the impact of these documents on translation. Specifically, we sample p% BT documents for each language during training with the rest (1 \u2212 p%) being the original sentence pairs to testify the sensitivity of translation performance to p. Note the proportion p here differs from the one used in our main paper (where p denotes the proportion of parallel documents in all teacher languages to parallel sentences in student languages).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_56",
            "content": "Figure 6 shows that larger p generally yields better performance over all settings, similar to the results on genuine parallel documents as in Figure 7. Therefore, we replace all sentence pairs in teacher languages with the corresponding BT documents in our analysis.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_57",
            "content": "Languages to De/Fr",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_58",
            "content": "We mainly report average results over all transfer directions in the paper. Below we also show the transfer from individual languages to De and Fr on Europarl-7. Note the performance at language level is much noisy. We observe that different teacher languages yield slightly different transfer behaviors and transferring to Fr looks more promising. . This is fully supervised multilingual DocNMT, where pseudo documents are used for all languages. Also, note p denotes the proportion of documents for each language, rather than teacher languages.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "58-ARR_v2_59",
            "content": "Roee Aharoni, Melvin Johnson, Orhan Firat, Massively multilingual neural machine translation, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "Roee Aharoni",
                    "Melvin Johnson",
                    "Orhan Firat"
                ],
                "title": "Massively multilingual neural machine translation",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "58-ARR_v2_60",
            "content": "UNKNOWN, None, 2019, The missing ingredient in zero-shot neural machine translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "The missing ingredient in zero-shot neural machine translation",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_61",
            "content": "UNKNOWN, None, 2019, Massively multilingual neural machine translation in the wild: Findings and challenges, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Massively multilingual neural machine translation in the wild: Findings and challenges",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_62",
            "content": "UNKNOWN, None, , Santanu Pal, Matt Post, and Marcos Zampieri. 2020. Findings of the 2020 conference on machine translation (wmt20). In Proceedings of the Fifth Conference on Machine Translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Santanu Pal, Matt Post, and Marcos Zampieri. 2020. Findings of the 2020 conference on machine translation (wmt20). In Proceedings of the Fifth Conference on Machine Translation",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_63",
            "content": "Rachel Bawden, Rico Sennrich, Alexandra Birch, Barry Haddow, Evaluating discourse phenomena in neural machine translation, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Rachel Bawden",
                    "Rico Sennrich",
                    "Alexandra Birch",
                    "Barry Haddow"
                ],
                "title": "Evaluating discourse phenomena in neural machine translation",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "58-ARR_v2_64",
            "content": "M Cettolo, M Federico, L Bentivogli, J Niehues, S St\u00fcker, K Sudoh, K Yoshino, C Federmann, The iwslt 2017 evaluation campaign, 2017, The International Workshop on Spoken Language Translation (IWSLT), .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "M Cettolo",
                    "M Federico",
                    "L Bentivogli",
                    "J Niehues",
                    "S St\u00fcker",
                    "K Sudoh",
                    "K Yoshino",
                    "C Federmann"
                ],
                "title": "The iwslt 2017 evaluation campaign",
                "pub_date": "2017",
                "pub_title": "The International Workshop on Spoken Language Translation (IWSLT)",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_65",
            "content": "Junxuan Chen, Xiang Li, Jiarui Zhang, Chulun Zhou, Jianwei Cui, Bin Wang, Jinsong Su, Modeling discourse structure for document-level neural machine translation, 2020, Proceedings of the First Workshop on Automatic Simultaneous Translation, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "Junxuan Chen",
                    "Xiang Li",
                    "Jiarui Zhang",
                    "Chulun Zhou",
                    "Jianwei Cui",
                    "Bin Wang",
                    "Jinsong Su"
                ],
                "title": "Modeling discourse structure for document-level neural machine translation",
                "pub_date": "2020",
                "pub_title": "Proceedings of the First Workshop on Automatic Simultaneous Translation",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "58-ARR_v2_66",
            "content": "Zewen Chi, Li Dong, Furu Wei, Nan Yang, Saksham Singhal, Wenhui Wang, Xia Song, Xian-Ling Mao, Heyan Huang, Ming Zhou, InfoXLM: An information-theoretic framework for cross-lingual language model pre-training, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Zewen Chi",
                    "Li Dong",
                    "Furu Wei",
                    "Nan Yang",
                    "Saksham Singhal",
                    "Wenhui Wang",
                    "Xia Song",
                    "Xian-Ling Mao",
                    "Heyan Huang",
                    "Ming Zhou"
                ],
                "title": "InfoXLM: An information-theoretic framework for cross-lingual language model pre-training",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "58-ARR_v2_67",
            "content": "Alexis Conneau, Guillaume Lample, Crosslingual language model pretraining, 2019, Advances in Neural Information Processing Systems, Curran Associates, Inc.",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Alexis Conneau",
                    "Guillaume Lample"
                ],
                "title": "Crosslingual language model pretraining",
                "pub_date": "2019",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": "Curran Associates, Inc"
            }
        },
        {
            "ix": "58-ARR_v2_68",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long and Short Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Jacob Devlin",
                    "Ming-Wei Chang",
                    "Kenton Lee",
                    "Kristina Toutanova"
                ],
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Long and Short Papers"
            }
        },
        {
            "ix": "58-ARR_v2_69",
            "content": "UNKNOWN, None, 2018, Zeroshot cross-lingual classification using multilingual neural machine translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Zeroshot cross-lingual classification using multilingual neural machine translation",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_70",
            "content": "Orhan Firat, Kyunghyun Cho, Yoshua Bengio, Multi-way, multilingual neural machine translation with a shared attention mechanism, 2016, Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Orhan Firat",
                    "Kyunghyun Cho",
                    "Yoshua Bengio"
                ],
                "title": "Multi-way, multilingual neural machine translation with a shared attention mechanism",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "58-ARR_v2_71",
            "content": "Markus Freitag, George Foster, David Grangier, Viresh Ratnakar, Qijun Tan, and Wolfgang Macherey. 2021. Experts, Errors, and Context: A Large-Scale Study of Human Evaluation for Machine Translation, , Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Markus Freitag",
                    "George Foster",
                    "David Grangier",
                    "Viresh Ratnakar"
                ],
                "title": "Qijun Tan, and Wolfgang Macherey. 2021. Experts, Errors, and Context: A Large-Scale Study of Human Evaluation for Machine Translation",
                "pub_date": null,
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_72",
            "content": "Jiatao Gu, Yong Wang, Kyunghyun Cho, O Victor,  Li, Improved zero-shot neural machine translation via ignoring spurious correlations, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    "Jiatao Gu",
                    "Yong Wang",
                    "Kyunghyun Cho",
                    "O Victor",
                    " Li"
                ],
                "title": "Improved zero-shot neural machine translation via ignoring spurious correlations",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_73",
            "content": "Junjie Hu, Sebastian Ruder, Aditya Siddhant, Graham Neubig, Orhan Firat, Melvin Johnson, XTREME: A massively multilingual multitask benchmark for evaluating cross-lingual generalisation, 2020, Proceedings of the 37th International Conference on Machine Learning, PMLR.",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Junjie Hu",
                    "Sebastian Ruder",
                    "Aditya Siddhant",
                    "Graham Neubig",
                    "Orhan Firat",
                    "Melvin Johnson"
                ],
                "title": "XTREME: A massively multilingual multitask benchmark for evaluating cross-lingual generalisation",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 37th International Conference on Machine Learning",
                "pub": "PMLR"
            }
        },
        {
            "ix": "58-ARR_v2_74",
            "content": "Jingjing Huo, Christian Herold, Yingbo Gao, Leonard Dahlmann, Shahram Khadivi, Hermann Ney, Diving deep into context-aware neural machine translation, 2020, Proceedings of the Fifth Conference on Machine Translation, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Jingjing Huo",
                    "Christian Herold",
                    "Yingbo Gao",
                    "Leonard Dahlmann",
                    "Shahram Khadivi",
                    "Hermann Ney"
                ],
                "title": "Diving deep into context-aware neural machine translation",
                "pub_date": "2020",
                "pub_title": "Proceedings of the Fifth Conference on Machine Translation",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "58-ARR_v2_75",
            "content": "UNKNOWN, None, 2017, Does neural machine translation benefit from larger context?, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": "Does neural machine translation benefit from larger context?",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_76",
            "content": "Melvin Johnson, Mike Schuster, Quoc Le, Maxim Krikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat, Fernanda Vi\u00e9gas, Martin Wattenberg, Greg Corrado, Macduff Hughes, Jeffrey Dean, Google's multilingual neural machine translation system: Enabling zero-shot translation, 2017, Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Melvin Johnson",
                    "Mike Schuster",
                    "Quoc Le",
                    "Maxim Krikun",
                    "Yonghui Wu",
                    "Zhifeng Chen",
                    "Nikhil Thorat",
                    "Fernanda Vi\u00e9gas",
                    "Martin Wattenberg",
                    "Greg Corrado",
                    "Macduff Hughes",
                    "Jeffrey Dean"
                ],
                "title": "Google's multilingual neural machine translation system: Enabling zero-shot translation",
                "pub_date": "2017",
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_77",
            "content": "Marcin Junczys-Dowmunt, Microsoft translator at WMT 2019: Towards large-scale document-level neural machine translation, 2019, Proceedings of the Fourth Conference on Machine Translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Marcin Junczys-Dowmunt"
                ],
                "title": "Microsoft translator at WMT 2019: Towards large-scale document-level neural machine translation",
                "pub_date": "2019",
                "pub_title": "Proceedings of the Fourth Conference on Machine Translation",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_78",
            "content": "Xiaomian Kang, Yang Zhao, Jiajun Zhang, Chengqing Zong, Dynamic context selection for document-level neural machine translation via reinforcement learning, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "Xiaomian Kang",
                    "Yang Zhao",
                    "Jiajun Zhang",
                    "Chengqing Zong"
                ],
                "title": "Dynamic context selection for document-level neural machine translation via reinforcement learning",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "58-ARR_v2_79",
            "content": "Yunsu Kim, Thanh Duc, Hermann Tran,  Ney, When and why is document-level context useful in neural machine translation?, 2019, Proceedings of the Fourth Workshop on Discourse in Machine Translation, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Yunsu Kim",
                    "Thanh Duc",
                    "Hermann Tran",
                    " Ney"
                ],
                "title": "When and why is document-level context useful in neural machine translation?",
                "pub_date": "2019",
                "pub_title": "Proceedings of the Fourth Workshop on Discourse in Machine Translation",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "58-ARR_v2_80",
            "content": "P Diederik, Jimmy Kingma,  Ba, Adam: A method for stochastic optimization, 2015, International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "P Diederik",
                    "Jimmy Kingma",
                    " Ba"
                ],
                "title": "Adam: A method for stochastic optimization",
                "pub_date": "2015",
                "pub_title": "International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_81",
            "content": "Tom Kocmi, Christian Federmann, Roman Grundkiewicz, Marcin Junczys-Dowmunt, To ship or not to ship: An extensive evaluation of automatic metrics for machine translation, 2021, Proceedings of the Sixth Conference on Machine Translation, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Tom Kocmi",
                    "Christian Federmann",
                    "Roman Grundkiewicz",
                    "Marcin Junczys-Dowmunt"
                ],
                "title": "To ship or not to ship: An extensive evaluation of automatic metrics for machine translation",
                "pub_date": "2021",
                "pub_title": "Proceedings of the Sixth Conference on Machine Translation",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "58-ARR_v2_82",
            "content": "Philipp Koehn, Europarl: A Parallel Corpus for Statistical Machine Translation, 2005, Conference Proceedings: the tenth Machine Translation Summit, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Philipp Koehn"
                ],
                "title": "Europarl: A Parallel Corpus for Statistical Machine Translation",
                "pub_date": "2005",
                "pub_title": "Conference Proceedings: the tenth Machine Translation Summit",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_83",
            "content": "UNKNOWN, None, 2018, Genderaware natural language translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Genderaware natural language translation",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_84",
            "content": "Taku Kudo, John Richardson, SentencePiece: A simple and language independent subword tokenizer and detokenizer for neural text processing, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Taku Kudo",
                    "John Richardson"
                ],
                "title": "SentencePiece: A simple and language independent subword tokenizer and detokenizer for neural text processing",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "58-ARR_v2_85",
            "content": "Sneha Kudugunta, Ankur Bapna, Isaac Caswell, Orhan Firat, Investigating multilingual NMT representations at scale, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": [
                    "Sneha Kudugunta",
                    "Ankur Bapna",
                    "Isaac Caswell",
                    "Orhan Firat"
                ],
                "title": "Investigating multilingual NMT representations at scale",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "58-ARR_v2_86",
            "content": "Samuel L\u00e4ubli, Rico Sennrich, Martin Volk, Has machine translation achieved human parity? a case for document-level evaluation, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": [
                    "Samuel L\u00e4ubli",
                    "Rico Sennrich",
                    "Martin Volk"
                ],
                "title": "Has machine translation achieved human parity? a case for document-level evaluation",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "58-ARR_v2_87",
            "content": "Ant\u00f3nio Lopes, M Amin Farajian, Rachel Bawden, Michael Zhang, Andr\u00e9 Martins, Document-level neural MT: A systematic comparison, 2020, Proceedings of the 22nd Annual Conference of the European Association for Machine Translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Ant\u00f3nio Lopes",
                    "M Amin Farajian",
                    "Rachel Bawden",
                    "Michael Zhang",
                    "Andr\u00e9 Martins"
                ],
                "title": "Document-level neural MT: A systematic comparison",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 22nd Annual Conference of the European Association for Machine Translation",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_88",
            "content": "UNKNOWN, None, 2021, A comparison of approaches to document-level machine translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "A comparison of approaches to document-level machine translation",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_89",
            "content": "Elman Mansimov, G\u00e1bor Melis, Lei Yu, Capturing document context inside sentence-level neural machine translation models with self-training, 2021, Proceedings of the 2nd Workshop on Computational Approaches to Discourse, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": [
                    "Elman Mansimov",
                    "G\u00e1bor Melis",
                    "Lei Yu"
                ],
                "title": "Capturing document context inside sentence-level neural machine translation models with self-training",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2nd Workshop on Computational Approaches to Discourse",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_90",
            "content": "Sameen Maruf, Fahimeh Saleh, Gholamreza Haffari, A survey on document-level neural machine translation: Methods and evaluation, 2021, ACM Comput. Surv, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": [
                    "Sameen Maruf",
                    "Fahimeh Saleh",
                    "Gholamreza Haffari"
                ],
                "title": "A survey on document-level neural machine translation: Methods and evaluation",
                "pub_date": "2021",
                "pub_title": "ACM Comput. Surv",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_91",
            "content": "Lesly Miculicich, Dhananjay Ram, Nikolaos Pappas, James Henderson, Document-level neural machine translation with hierarchical attention networks, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": [
                    "Lesly Miculicich",
                    "Dhananjay Ram",
                    "Nikolaos Pappas",
                    "James Henderson"
                ],
                "title": "Document-level neural machine translation with hierarchical attention networks",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_92",
            "content": "Mathias M\u00fcller, Annette Rios, Elena Voita, Rico Sennrich, A large-scale test set for the evaluation of context-aware pronoun translation in neural machine translation, 2018, Proceedings of the Third Conference on Machine Translation: Research Papers, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": [
                    "Mathias M\u00fcller",
                    "Annette Rios",
                    "Elena Voita",
                    "Rico Sennrich"
                ],
                "title": "A large-scale test set for the evaluation of context-aware pronoun translation in neural machine translation",
                "pub_date": "2018",
                "pub_title": "Proceedings of the Third Conference on Machine Translation: Research Papers",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "58-ARR_v2_93",
            "content": "Matt Post, A call for clarity in reporting BLEU scores, 2018, Proceedings of the Third Conference on Machine Translation: Research Papers, .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": [
                    "Matt Post"
                ],
                "title": "A call for clarity in reporting BLEU scores",
                "pub_date": "2018",
                "pub_title": "Proceedings of the Third Conference on Machine Translation: Research Papers",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_94",
            "content": "UNKNOWN, None, 2021, Xtreme-r: Towards more challenging and nuanced multilingual evaluation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Xtreme-r: Towards more challenging and nuanced multilingual evaluation",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_95",
            "content": "Danielle Saunders, Bill Byrne, Reducing gender bias in neural machine translation as a domain adaptation problem, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "Danielle Saunders",
                    "Bill Byrne"
                ],
                "title": "Reducing gender bias in neural machine translation as a domain adaptation problem",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "58-ARR_v2_96",
            "content": "Rico Sennrich, Barry Haddow, Alexandra Birch, Neural machine translation of rare words with subword units, 2016, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": [
                    "Rico Sennrich",
                    "Barry Haddow",
                    "Alexandra Birch"
                ],
                "title": "Neural machine translation of rare words with subword units",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "58-ARR_v2_97",
            "content": "Aditya Siddhant, Melvin Johnson, Henry Tsai, Naveen Ari, Jason Riesa, Ankur Bapna, Orhan Firat, Karthik Raman, Evaluating the cross-lingual effectiveness of massively multilingual neural machine translation, 2020, Proceedings of the AAAI Conference on Artificial Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": [
                    "Aditya Siddhant",
                    "Melvin Johnson",
                    "Henry Tsai",
                    "Naveen Ari",
                    "Jason Riesa",
                    "Ankur Bapna",
                    "Orhan Firat",
                    "Karthik Raman"
                ],
                "title": "Evaluating the cross-lingual effectiveness of massively multilingual neural machine translation",
                "pub_date": "2020",
                "pub_title": "Proceedings of the AAAI Conference on Artificial Intelligence",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_98",
            "content": "Amane Sugiyama, Naoki Yoshinaga, Data augmentation using back-translation for contextaware neural machine translation, 2019, Proceedings of the Fourth Workshop on Discourse in Machine Translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": [
                    "Amane Sugiyama",
                    "Naoki Yoshinaga"
                ],
                "title": "Data augmentation using back-translation for contextaware neural machine translation",
                "pub_date": "2019",
                "pub_title": "Proceedings of the Fourth Workshop on Discourse in Machine Translation",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_99",
            "content": "UNKNOWN, None, 2020, Capturing longer context for document-level neural machine translation: A multi-resolutional approach, .",
            "ntype": "ref",
            "meta": {
                "xid": "b40",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Capturing longer context for document-level neural machine translation: A multi-resolutional approach",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_100",
            "content": "J\u00f6rg Tiedemann, Yves Scherrer, Neural machine translation with extended context, 2017, Proceedings of the Third Workshop on Discourse in Machine Translation, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b41",
                "authors": [
                    "J\u00f6rg Tiedemann",
                    "Yves Scherrer"
                ],
                "title": "Neural machine translation with extended context",
                "pub_date": "2017",
                "pub_title": "Proceedings of the Third Workshop on Discourse in Machine Translation",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "58-ARR_v2_101",
            "content": ", Document level NMT of low-resource languages with backtranslation, 2020, Proceedings of the Fifth Conference on Machine Translation, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b42",
                "authors": [],
                "title": "Document level NMT of low-resource languages with backtranslation",
                "pub_date": "2020",
                "pub_title": "Proceedings of the Fifth Conference on Machine Translation",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "58-ARR_v2_102",
            "content": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, Illia Kaiser,  Polosukhin, Attention is all you need, 2017, Advances in Neural Information Processing Systems, Curran Associates, Inc.",
            "ntype": "ref",
            "meta": {
                "xid": "b43",
                "authors": [
                    "Ashish Vaswani",
                    "Noam Shazeer",
                    "Niki Parmar",
                    "Jakob Uszkoreit",
                    "Llion Jones",
                    "Aidan Gomez",
                    "Illia Kaiser",
                    " Polosukhin"
                ],
                "title": "Attention is all you need",
                "pub_date": "2017",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": "Curran Associates, Inc"
            }
        },
        {
            "ix": "58-ARR_v2_103",
            "content": "Elena Voita, Rico Sennrich, Ivan Titov, When a good translation is wrong in context: Context-aware machine translation improves on deixis, ellipsis, and lexical cohesion, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b44",
                "authors": [
                    "Elena Voita",
                    "Rico Sennrich",
                    "Ivan Titov"
                ],
                "title": "When a good translation is wrong in context: Context-aware machine translation improves on deixis, ellipsis, and lexical cohesion",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_104",
            "content": "Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, and Colin Raffel. 2021. mT5: A massively multilingual pre-trained text-to-text transformer, , Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b45",
                "authors": [
                    "Linting Xue",
                    "Noah Constant",
                    "Adam Roberts",
                    "Mihir Kale",
                    "Rami Al-Rfou",
                    "Aditya Siddhant"
                ],
                "title": "Aditya Barua, and Colin Raffel. 2021. mT5: A massively multilingual pre-trained text-to-text transformer",
                "pub_date": null,
                "pub_title": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_105",
            "content": "Lei Yu, Laurent Sartran, Wojciech Stokowiec, Wang Ling, Lingpeng Kong, Phil Blunsom, Chris Dyer, Better document-level machine translation with Bayes' rule, 2020, Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b46",
                "authors": [
                    "Lei Yu",
                    "Laurent Sartran",
                    "Wojciech Stokowiec",
                    "Wang Ling",
                    "Lingpeng Kong",
                    "Phil Blunsom",
                    "Chris Dyer"
                ],
                "title": "Better document-level machine translation with Bayes' rule",
                "pub_date": "2020",
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_106",
            "content": "Biao Zhang, Ankur Bapna, Rico Sennrich, Orhan Firat, Share or not? learning to schedule language-specific capacity for multilingual translation, 2021, International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b47",
                "authors": [
                    "Biao Zhang",
                    "Ankur Bapna",
                    "Rico Sennrich",
                    "Orhan Firat"
                ],
                "title": "Share or not? learning to schedule language-specific capacity for multilingual translation",
                "pub_date": "2021",
                "pub_title": "International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_107",
            "content": "Biao Zhang, Philip Williams, Ivan Titov, Rico Sennrich, Improving massively multilingual neural machine translation and zero-shot translation, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b48",
                "authors": [
                    "Biao Zhang",
                    "Philip Williams",
                    "Ivan Titov",
                    "Rico Sennrich"
                ],
                "title": "Improving massively multilingual neural machine translation and zero-shot translation",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "58-ARR_v2_108",
            "content": "Jiacheng Zhang, Huanbo Luan, Maosong Sun, Feifei Zhai, Jingfang Xu, Min Zhang, Yang Liu, Improving the transformer translation model with document-level context, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b49",
                "authors": [
                    "Jiacheng Zhang",
                    "Huanbo Luan",
                    "Maosong Sun",
                    "Feifei Zhai",
                    "Jingfang Xu",
                    "Min Zhang",
                    "Yang Liu"
                ],
                "title": "Improving the transformer translation model with document-level context",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "pub": "Association for Computational Linguistics"
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "58-ARR_v2_0@0",
            "content": "Multilingual Document-Level Translation Enables Zero-Shot Transfer From Sentences to Documents",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_0",
            "start": 0,
            "end": 93,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_2@0",
            "content": "Document-level neural machine translation (DocNMT) achieves coherent translations by incorporating cross-sentence context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_2",
            "start": 0,
            "end": 121,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_2@1",
            "content": "However, for most language pairs there's a shortage of parallel documents, although parallel sentences are readily available.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_2",
            "start": 123,
            "end": 247,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_2@2",
            "content": "In this paper, we study whether and how contextual modeling in DocNMT is transferable via multilingual modeling.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_2",
            "start": 249,
            "end": 360,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_2@3",
            "content": "We focus on the scenario of zero-shot transfer from teacher languages with document level data to student languages with no documents but sentence level data, and for the first time treat document-level translation as a transfer learning problem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_2",
            "start": 362,
            "end": 607,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_2@4",
            "content": "Using simple concatenation-based DocNMT, we explore the effect of 3 factors on the transfer: the number of teacher languages with document level data, the balance between document and sentence level data at training, and the data condition of parallel documents (genuine vs. backtranslated).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_2",
            "start": 609,
            "end": 899,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_2@5",
            "content": "Our experiments on Europarl-7 and IWSLT-10 show the feasibility of multilingual transfer for DocNMT, particularly on document-specific metrics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_2",
            "start": 901,
            "end": 1043,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_2@6",
            "content": "We observe that more teacher languages and adequate data balance both contribute to better transfer quality.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_2",
            "start": 1045,
            "end": 1152,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_2@7",
            "content": "Surprisingly, the transfer is less sensitive to the data condition, where multilingual DocNMT delivers decent performance with either backtranslated or genuine document pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_2",
            "start": 1154,
            "end": 1328,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_2@8",
            "content": "* Work done while Biao Zhang was interning at Google Research.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_2",
            "start": 1330,
            "end": 1391,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_4@0",
            "content": "Recent years have witnessed a trend moving from sentence-level neural machine translation (Sen-NMT) to its document-level counterpart (Doc-NMT).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_4",
            "start": 0,
            "end": 143,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_4@1",
            "content": "SenNMT inevitably suffers from translation errors related with document phenomena (Maruf et al., 2021) and delivers obviously inferior performance when compared against human translations and evaluated at a document level (L\u00e4ubli et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_4",
            "start": 145,
            "end": 388,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_4@2",
            "content": "Most efforts on DocNMT aim at improving contextual modeling via dedicated model architectures and/or decoding algorithms (Bawden et al., 2018;Voita et al., 2019; and heavily rely on large-scale parallel document resources.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_4",
            "start": 390,
            "end": 611,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_4@3",
            "content": "Nevertheless, document resources are unevenly distributed across language pairs, with most pairs having little to no such resources.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_4",
            "start": 613,
            "end": 744,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_4@4",
            "content": "1 One promising way to accommodate languages with varied training data is multilingual modeling, as demonstrated in multilingual SenNMT (Firat et al., 2016;Johnson et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_4",
            "start": 746,
            "end": 923,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_4@5",
            "content": "By sharing parameters across languages, multilingual modeling encourages cross-lingual knowledge transfer, enabling performance improvement and even zeroshot transfer (Aharoni et al., 2019;Arivazhagan et al., 2019b;Zhang et al., , 2021.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_4",
            "start": 925,
            "end": 1160,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_4@6",
            "content": "In the context of translation, however, most studies on multilingual transfer center around SenNMT, seldom going beyond sentence-level translation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_4",
            "start": 1162,
            "end": 1308,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_4@7",
            "content": "So far, the question of whether and how document-level contextual modeling can be learned cross-lingually in multilingual DocNMT is still unanswered.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_4",
            "start": 1310,
            "end": 1458,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_5@0",
            "content": "In this paper, we study zero-shot generalization for DocNMT -the ability to attain plausible Doc-NMT quality for some focused (student) language pair(s), with only parallel sentences for the student but parallel documents for other (teacher) languages in the multilingual mix.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_5",
            "start": 0,
            "end": 275,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_5@1",
            "content": "The high-level research question we seek to answer is illustrated in Figure 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_5",
            "start": 277,
            "end": 354,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_6@0",
            "content": "We resort to transfer learning via multilinguality to leverage document resources in teacher languages to help the student languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_6",
            "start": 0,
            "end": 132,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_6@1",
            "content": "We perform our analysis using a simple concatenation based DocNMT, where consecutive sentences are chained into one sequence for translation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_6",
            "start": 134,
            "end": 274,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_6@2",
            "content": "We investigate three dimensions extensively to understand the transfer in multilingual DocNMT: 1) the number of languages with document level data (teacher languages), where we simplify our transfer setup to contain either only one teacher language (with N students) or N teachers (with one student); 2) the data balance for parallel documents, i.e. manipulating the ratio of document-level data to sentencelevel data during training; and 3) the data condition of parallel documents, where we adopt backtranslated parallel documents when only monolingual documents are given in teacher languages or use genuine parallel documents crawled natively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_6",
            "start": 276,
            "end": 922,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_7@0",
            "content": "We conduct experiments on two publicly available datasets, namely Europarl-7 and IWSLT-10, covering 6 and 9 languages from/to English respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_7",
            "start": 0,
            "end": 146,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_7@1",
            "content": "We analyze one-to-many (En\u2192Xx) and many-to-one (Xx\u2192En) translation scenarios separately.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_7",
            "start": 148,
            "end": 235,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_7@2",
            "content": "Following recent work (Ma et al., 2021), we adopt document-specific metrics for evaluation apart from BLEU and support our findings with human evaluations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_7",
            "start": 237,
            "end": 391,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_7@3",
            "content": "We also propose a pronoun F1 metric (targeted at gendered pronouns: he/she) for Xx\u2192En translation, and employ accuracy on contrastive test sets (Bawden et al., 2018;M\u00fcller et al., 2018) for En\u2192Xx translation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_7",
            "start": 393,
            "end": 600,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_7@4",
            "content": "Our main findings are summarized below:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_7",
            "start": 602,
            "end": 640,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_8@0",
            "content": "\u2022 Zero-shot transfer from sentences to documents is feasible through multilingual Doc-NMT modeling, particularly when evaluated with document-specific metrics. This is partially supported by human evaluation. \u2022 Transfer quality is strongly affected by the number of teacher languages that use document level data and the data balance for documents. Higher quality is achieved with more teacher languages and adequate document schedule, where the optimal balance varies across scenarios. \u2022 Surprisingly, transfer via back-translated documents performs comparable to transfer via genuine parallel documents. \u2022 Zero-shot transfer from high-resource document level languages and to low-resource sentence level ones is relatively easier, resulting in better transfer results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_8",
            "start": 0,
            "end": 769,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_9@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_9",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_10@0",
            "content": "Document-level MT Integrating document-level information meaningfully into NMT is a challenging task, which has inspired research not only on exploring advanced context-aware neural architectures, including simple concatenation-based models (Tiedemann and Scherrer, 2017;Junczys-Dowmunt, 2019;Lopes et al., 2020), multi-source models (Jean et al., 2017;Bawden et al., 2018;Zhang et al., 2018), hierarchical models (Miculicich et al., 2018;Zheng et al., 2020;, multi-pass models (Voita et al., 2019;Yu et al., 2020;Mansimov et al., 2021) and dynamic context models (Kang et al., 2020), to name a few.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_10",
            "start": 0,
            "end": 598,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_11@0",
            "content": "But it has also motivated the field to revisit the common protocols resorted for evaluation (Freitag et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_11",
            "start": 0,
            "end": 114,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_11@1",
            "content": "Despite the hard to measure success, all the above mentioned methods implicitly assume an abundance of document resources and overlook the data scarcity problem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_11",
            "start": 116,
            "end": 276,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_11@2",
            "content": "In this study, we adopt the simple concatenation model as our experimental protocol, and leave the exploration of various input formatting options and modelling to future work.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_11",
            "start": 278,
            "end": 453,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_11@3",
            "content": "Considering the fast changing landscape of the (contextual) MT evaluation, we also provide multiple evaluation metrics including human evaluations, to give a full picture of the phenomena under investigation, while acknowledging the current imperfections of and disagreements on the right way of evaluating MT systems (Kocmi et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_11",
            "start": 455,
            "end": 793,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_12@0",
            "content": "Zero-Shot Transfer via Multilinguality Multilingual modeling often clusters sentences of similar meaning from different languages within a shared semantic space (Kudugunta et al., 2019;. Such representation space is hypothesized to enable zero-shot transfer, delivering improved performance in many cross-lingual tasks (Eriguchi et al., 2018;Hu et al., 2020;Chi et al., 2021;Ruder et al., 2021), especially based on large-scale pretrained multilingual Transformers (Devlin et al., 2019;Conneau and Lample, 2019;Xue et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_12",
            "start": 0,
            "end": 528,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_12@1",
            "content": "When it comes to transla-tion, multilingual SenNMT successfully achieves zero-shot translation, transferring sentence-level generation knowledge to language pairs unseen during training (Firat et al., 2016;Johnson et al., 2017;Gu et al., 2019;Arivazhagan et al., 2019a) even in massively multilingual settings (Aharoni et al., 2019;Arivazhagan et al., 2019b;Zhang et al., , 2021.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_12",
            "start": 530,
            "end": 908,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_12@2",
            "content": "Our study extends multilingual SenNMT to multilingual DocNMT and aims at document-level knowledge transfer from languages that have document level data to languages that only have sentence level data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_12",
            "start": 910,
            "end": 1109,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_12@3",
            "content": "To the best of our knowledge, our study is the first demonstrating the emergence of document-level zero-shot transfer across languages for multilingual machine translation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_12",
            "start": 1111,
            "end": 1282,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_13@0",
            "content": "Zero-Shot Transfer in Multilingual DocNMT",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_13",
            "start": 0,
            "end": 40,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_14@0",
            "content": "We first formulate the zero-shot generalization framework explored in this paper.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_14",
            "start": 0,
            "end": 80,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_14@1",
            "content": "Given N+1 language pairs, we assume that all of them have parallel sentences for training, but only some of them have parallel documents (teachers).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_14",
            "start": 82,
            "end": 229,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_14@2",
            "content": "Through multilingual training, we study to what degree contextual modeling in document-supervised DocNMT can be transferred to those document-poor (student) languages as in Figure 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_14",
            "start": 231,
            "end": 412,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_14@3",
            "content": "Any form of parallel document for student languages is disallowed at training, ensuring that the transfer is measured zero-shot.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_14",
            "start": 414,
            "end": 541,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_15@0",
            "content": "Multilingual DocNMT",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_15",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_16@0",
            "content": "We employ the concatenation-based method with a D2D structure for DocNMT, where D consecutive sentences in a document are concatenated into one sequence for translation (Junczys-Dowmunt, 2019;Sun et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_16",
            "start": 0,
            "end": 209,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_16@1",
            "content": "Sentence boundary is indicated by a special symbol \"[SEN]\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_16",
            "start": 211,
            "end": 269,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_16@2",
            "content": "We adopt the language token method (Johnson et al., 2017) for multilingual DocNMT, using source and target language token for Xx\u2192En and En\u2192Xx translation respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_16",
            "start": 271,
            "end": 437,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_16@3",
            "content": "Instead of appending this token to the source sequence, we add its embedding to each source word embedding to strengthen the language signal in a document translation setting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_16",
            "start": 439,
            "end": 613,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_17@0",
            "content": "For training, we adopt a two-stage method: we first pretrain a multilingual SenNMT on sentence level data for all languages; then, we finetune it to obtain multilingual DocNMT on a mix of document level data from teacher languages and sentence level data from student languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_17",
            "start": 0,
            "end": 277,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_17@1",
            "content": "Our analysis requires training a large number of DocNMT models, and the two-stage method saves substantial amounts of computation by sharing the pretrained SenNMT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_17",
            "start": 279,
            "end": 441,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_17@2",
            "content": "For evaluation, we distinguish sentencelevel inference (SenInfer) from its document-level counterpart (DocInfer).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_17",
            "start": 443,
            "end": 555,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_17@3",
            "content": "SenInfer translates sentences separately (out of context), while DocInfer translates D consecutive and non-overlapping sentences in context with each other.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_17",
            "start": 557,
            "end": 712,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_17@4",
            "content": "2",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_17",
            "start": 714,
            "end": 714,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_18@0",
            "content": "Zero-Shot Setup",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_18",
            "start": 0,
            "end": 14,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_19@0",
            "content": "We explore three factors for the zero-shot transfer:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_19",
            "start": 0,
            "end": 51,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_20@0",
            "content": "\u2022 The number of teacher languages The source of the transfer comes from teacher languages. Intuitively, both the number of teacher languages and their relevance to student language(s) affect the transfer result. However, exhaustively exploring all possible teacherstudent configurations in a multilingual setting will lead to a large search space that expands exponentially with respect to the total number of languages involved. Instead, we simplify our study by exploring two extreme transfer settings, namely N21 and 12N transfer. The first setting uses N teachers that incorporate document level data with 1 student having sentence level data only, while the second setting has 1 teacher and N students. Note that in either N21 or 12N transfer, there exist N teacher-student configurations, and we report average results over them. 3 \u2022 The data balance for parallel documents When varying the number of teacher languages, the proportion of document data at training also changes. Such imbalance could deeply affect transfer (Arivazhagan et al., 2019b). To offset this effect, we include the data balance for analysis by controlling the sampling ratio p of documents from 0.1 to 0.9 with a step size of 0.1. Note p is for documents in all teacher languages, and the relative proportion among teachers is always retained. \u2022 The data condition of parallel documents We also study when teacher languages have no parallel documents but only monolingual ones. Methods utilizing monolingual documents for DocNMT vary greatly. Following recent work (Sugiyama and Yoshinaga, 2019;Huo et al., 2020;Ul Haq et al., 2020), we adopt back-translation (BT) to construct pseudo parallel documents. Note that, for teacher languages, we replace all sentence level training data with pseudo documents rather than mixing them according to our empirical results in Appendix C.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_20",
            "start": 0,
            "end": 1857,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_21@0",
            "content": "Experimental Settings",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_21",
            "start": 0,
            "end": 20,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_22@0",
            "content": "Datasets We conduct experiments on two public datasets: Europarl-7 and IWSLT-10.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_22",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_22@1",
            "content": "Europarl-7 is extracted from European Parliament (v10) and has translations between English and N =6 different languages, including Czech, German, Finnish, French, Lithuanian and Polish (Koehn, 2005).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_22",
            "start": 81,
            "end": 280,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_22@2",
            "content": "This dataset offers sentence-aligned parallel documents (0.9K\u223c3.7K documents, 190K\u223c1.9M sentences) and also monolingual documents (9.7K\u223c11K documents, 0.65M\u223c2.28M sentences) for training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_22",
            "start": 282,
            "end": 468,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_22@3",
            "content": "For evaluation, we use the WMT dev and test sets (Barrault et al., 2020) available for each language pair (from 2013 to 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_22",
            "start": 470,
            "end": 595,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_22@4",
            "content": "In contrast, IWSLT-10 is collected from TED talks and covers translations between English and N =9 different languages, including Arabic, German, French, Italian, Japanese, Korean, Dutch, Romanian and Chinese (Cettolo et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_22",
            "start": 597,
            "end": 828,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_22@5",
            "content": "Unlike Europarl-7, the distribution of training data over languages in IWSLT-10 is much smoother (uniform).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_22",
            "start": 830,
            "end": 936,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_22@6",
            "content": "There are \u223c1.9K sentencealigned parallel documents with \u223c240K sentences for each language pair.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_22",
            "start": 938,
            "end": 1032,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_22@7",
            "content": "We further collected about 1K TED talks for each language pair (crawled from Feb 2018 to Jan 2021) as monolingual documents.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_22",
            "start": 1034,
            "end": 1157,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_23@0",
            "content": "We use IWSLT17 dev and test sets for evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_23",
            "start": 0,
            "end": 47,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_23@1",
            "content": "Detailed statistics are given in Appendix A. We preprocess all texts with the byte pair encoding (BPE) algorithm (Sennrich et al., 2016) implemented in the sentencepiece toolkit (Kudo and Richardson, 2018), and set the vocabulary size to 32K and 64K for IWSLT-10 and Europarl-7, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_23",
            "start": 49,
            "end": 340,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_24@0",
            "content": "Model Details We use the Transformer-base model (Vaswani et al., 2017) for experiments with 6 encoder/decoder layers, 8 attention heads and a model dimension of 512/2048.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_24",
            "start": 0,
            "end": 169,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_24@1",
            "content": "We set D = 5 for DocNMT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_24",
            "start": 171,
            "end": 194,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_24@2",
            "content": "We use Adam (Kingma and Ba, 2015) (\u03b2 1 = 0.9, \u03b2 2 = 0.98) for parameter update with a learning rate warmup step of 4K and label smoothing rate of 0.1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_24",
            "start": 196,
            "end": 345,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_24@3",
            "content": "We apply dropout to residual connections and attention weights with a rate of 0.5 and 0.2, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_24",
            "start": 347,
            "end": 450,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_24@4",
            "content": "Other training and decoding details are given in Appendix B.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_24",
            "start": 452,
            "end": 511,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_25@0",
            "content": "Back-Translation Some of our models are trained using back-translated monolingual documents.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_25",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_25@1",
            "content": "Back-translations are obtained using bilingual SenNMT (independently for Europarl-7 and IWSLT-10).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_25",
            "start": 93,
            "end": 190,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_25@2",
            "content": "To train these models, we halve the BPE vocabulary size as well as the training steps.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_25",
            "start": 192,
            "end": 277,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_26@0",
            "content": "All other settings are kept as mentioned above.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_26",
            "start": 0,
            "end": 46,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_27@0",
            "content": "Evaluation Following previous work, we use BLEU (Post, 2018) 4 to measure the general translation quality.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_27",
            "start": 0,
            "end": 105,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_27@1",
            "content": "Document-level BLEU is calculated by counting n-gram at the document level instead of at the individual sentence level (Sun et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_27",
            "start": 107,
            "end": 244,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_28@0",
            "content": "Measuring improvements to document phenomena in translation automatically remains challenging and oftentimes simple surface-based metrics such as BLEU (L\u00e4ubli et al., 2018) are not sensitive enough.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_28",
            "start": 0,
            "end": 197,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_28@1",
            "content": "Therefore, we evaluate our model on test sets that focus on such document phenomena.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_28",
            "start": 199,
            "end": 282,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_28@2",
            "content": "We use the contrastive test sets for En-De (M\u00fcller et al., 2018) and En-Fr (Bawden et al., 2018) which measure a model's ability to distinguish correct from incorrect anaphoric pronoun translations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_28",
            "start": 284,
            "end": 481,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_28@3",
            "content": "We include 4 and 1 additional context sentences for En-De and En-Fr contrastive evaluation, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_28",
            "start": 483,
            "end": 587,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_29@0",
            "content": "Gender bias in translation models has attracted much attention recently (Kuczmarski and Johnson, 2018;Saunders and Byrne, 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_29",
            "start": 0,
            "end": 127,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_29@1",
            "content": "We expect that contextual information can help to alleviate it.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_29",
            "start": 129,
            "end": 191,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_29@2",
            "content": "To this end, we introduce gendered pronoun F1 based on the following precision and recall scores to evaluate English translations:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_29",
            "start": 193,
            "end": 322,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_30@0",
            "content": "Precision = i,g\u2208G min(C g r i , C g h i ) i,g\u2208G C g h i Recall = i,g\u2208G min(C g r i , C g h i ) i,g\u2208G C g r i ,(1)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_30",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_31@0",
            "content": "where r i and h i denotes the i-th gold reference and hypothesis sentence respectively, comprising the gendered pronouns of interest G 5 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_31",
            "start": 0,
            "end": 137,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_31@1",
            "content": "C g x denotes the count of pronoun g in sentence x.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_31",
            "start": 139,
            "end": 189,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_32@0",
            "content": "Finally, we conduct human evaluation to verify the performance delivered by zero-shot transfer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_32",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_32@1",
            "content": "We work on En-De, Europarl-7, where we sample 50 source documents from the test set, and translate them into the target language using the corresponding models and decoding techniques.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_32",
            "start": 96,
            "end": 279,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_32@2",
            "content": "The translated documents are presented to bilingual human raters who are native in the non-English locale.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_32",
            "start": 281,
            "end": 386,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_32@3",
            "content": "The raters are asked to evaluate translation qualities while taking the full source document context into account.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_32",
            "start": 388,
            "end": 501,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_32@4",
            "content": "The raters assign a score in a 0-6 scale to every sentence-translation pair in the document, where 0 and 6 mean nonsense and perfect translations, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_32",
            "start": 503,
            "end": 662,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_32@5",
            "content": "For each model, the scores are aggregated across the entire test corpus and the average scores are reported.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_32",
            "start": 664,
            "end": 771,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_32@6",
            "content": "To ensure a fair diversity of ratings, each rater rates no more than 6 documents per model; an average of 18 raters evaluated each model independently.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_32",
            "start": 773,
            "end": 923,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_32@7",
            "content": "dard deviation over N configurations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_32",
            "start": 925,
            "end": 961,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_32@8",
            "content": "6 Overall, the document-level zero-shot transfer is achievable via multilingual modeling.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_32",
            "start": 963,
            "end": 1051,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_32@9",
            "content": "Transfer-based DocNMT could successfully identify and translate the correct number of input sentences for student languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_32",
            "start": 1053,
            "end": 1176,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_32@10",
            "content": "With a proper sampling ratio for document-level data, student DocNMT yields better performance than its SenNMT counterpart, especially shown by document-specific evaluations (F1 and ACC).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_32",
            "start": 1178,
            "end": 1364,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_33@0",
            "content": "Results and Analysis",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_33",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_34@0",
            "content": "Increasing teacher languages improves transfer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_34",
            "start": 0,
            "end": 46,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_34@1",
            "content": "In En\u2192Xx and Xx\u2192En translation, we find that N21 transfer performs consistently better than 12N transfer on all metrics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_34",
            "start": 48,
            "end": 167,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_34@2",
            "content": "This is reasonable since N21 transfer has N teacher languages, offering richer and more informative sources for transfer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_34",
            "start": 169,
            "end": 289,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_35@0",
            "content": "Balancing between document and sentence data matters for transfer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_35",
            "start": 0,
            "end": 65,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_35@1",
            "content": "We also observe that performance changes over the document proportion on all metrics in both 12N and N21 transfer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_35",
            "start": 67,
            "end": 180,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_35@2",
            "content": "Applying more or fewer documents during training often hurts zero-shot transfer, indicating a trade-off.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_35",
            "start": 182,
            "end": 285,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_35@3",
            "content": "Roughly, setting p to 30%\u223c50% delivers good performance (Figure 2 and 3), although the optimal proportion depends.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_35",
            "start": 287,
            "end": 400,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_36@0",
            "content": "SenInfer underperforms DocInfer on documentspecific metrics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_36",
            "start": 0,
            "end": 59,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_36@1",
            "content": "DocNMT w/ SenInfer performs similarly to SenNMT, and better than DocInfer on BLEU.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_36",
            "start": 61,
            "end": 142,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_36@2",
            "content": "When evaluating document phenomena, however, SenInfer shows clear insufficiency.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_36",
            "start": 144,
            "end": 223,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_36@3",
            "content": "This resonates with the findings of Ma et al. (2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_36",
            "start": 225,
            "end": 277,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_37@0",
            "content": "Can we achieve zero-shot transfer with monolingual documents? Yes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_37",
            "start": 0,
            "end": 65,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_37@1",
            "content": "We next repeat our experiments with BT document pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_37",
            "start": 67,
            "end": 120,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_37@2",
            "content": "Figure 4 and 5 show that BT performs surprisingly well on document-level zero-shot transfer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_37",
            "start": 122,
            "end": 213,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_37@3",
            "content": "We observe almost the same performance pattern compared to training with genuine documents in all settings (En\u2192Xx and Xx\u2192En, N21 and 12N transfer and different metrics), although BLEU scores become worse and the optimal proportion also changes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_37",
            "start": 215,
            "end": 458,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_37@4",
            "content": "We argue that the target-side genuine context information in BT documents helps contextual model- Table 3: Performance of different models on Europarl-7 and IWSLT-10.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_37",
            "start": 460,
            "end": 625,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_37@5",
            "content": "\u2021 : multilingual DocNMT trained on parallel documents from all language pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_37",
            "start": 627,
            "end": 704,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_37@6",
            "content": "For 12N and N21 transfer, we report one group of results under the approximately optimal proportion p. Notice that the results for transfer experiments are averaged over different teacher-student configurations, while those for DocNMT \u2021 are for one model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_37",
            "start": 706,
            "end": 960,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_37@7",
            "content": "We report absolute scores for SenNMT but relative scores for the others.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_37",
            "start": 962,
            "end": 1033,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_38@0",
            "content": "ing (Ma et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_38",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_38@1",
            "content": "These results are promising, encouraging further research on exploring monolingual documents for multilingual DocNMT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_38",
            "start": 23,
            "end": 139,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_39@0",
            "content": "Impact of high/low-resource languages on zeroshot transfer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_39",
            "start": 0,
            "end": 58,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_39@1",
            "content": "The data distribution of Europarl-7 is highly skewed over languages, with Cs, Lt, Pl being relatively low-resource languages while De, Fi, Fr being high-resource ones.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_39",
            "start": 60,
            "end": 226,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_39@2",
            "content": "Studies on multilingual SenNMT have witnessed the transfer from high-resource to low-resource languages (Aharoni et al., 2019;. We next analyze how this data scale difference affects documentlevel zero-shot transfer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_39",
            "start": 228,
            "end": 443,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_39@3",
            "content": "We mainly explore 12N transfer because of the single transfer source, avoiding interference from other teacher languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_39",
            "start": 445,
            "end": 565,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_39@4",
            "content": "Table 2 lists the results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_39",
            "start": 567,
            "end": 592,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_39@5",
            "content": "Regardless of the data condition (genuine or BT document pairs), transferring from high-resource teacher languages often outperforms that from low-resource ones.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_39",
            "start": 594,
            "end": 754,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_39@6",
            "content": "Besides, transferring into low-resource student languages delivers better transfer than into high-resource ones.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_39",
            "start": 756,
            "end": 867,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_39@7",
            "content": "These suggest that increasing the document data for teacher languages benefits zero-shot transfer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_39",
            "start": 869,
            "end": 966,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_40@0",
            "content": "Note we also provide transfer results from individual languages to De and Fr in Appendix D.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_40",
            "start": 0,
            "end": 90,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_41@0",
            "content": "We summarize the main results on both datasets in Table 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_41",
            "start": 0,
            "end": 57,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_41@1",
            "content": "Although IWSLT-10 (N=9) includes more (distant) languages and distributes quite differently over languages, the results on IWSLT-10 resemble those on Europarl-7.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_41",
            "start": 59,
            "end": 219,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_41@2",
            "content": "On both datasets, we observe that transfer, both 12N and N21, yields very positive results, particularly with document-specific metrics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_41",
            "start": 221,
            "end": 356,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_41@3",
            "content": "Unlike Europarl-7, BT-based transfer per- Ratings are on a 0-6 scale; higher scores mean better quality.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_41",
            "start": 358,
            "end": 461,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_42@0",
            "content": "forms much worse than models trained on genuine document pairs on IWSLT-10.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_42",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_42@1",
            "content": "We ascribe this to the data scarcity, where only very small-scale monolingual documents are used for BT in IWSLT-10.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_42",
            "start": 76,
            "end": 191,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_42@2",
            "content": "This also reinforces our observation that more document resources benefits zero-shot transfer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_42",
            "start": 193,
            "end": 286,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_43@0",
            "content": "Discussion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_43",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_44@0",
            "content": "Apart from automatic evaluation, we also offer human evaluation on En-De.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_44",
            "start": 0,
            "end": 72,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_44@1",
            "content": "We choose En-De as its WMT20 test set is intentionally constructed for DocNMT evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_44",
            "start": 74,
            "end": 162,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_44@2",
            "content": "Table 4 lists the results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_44",
            "start": 164,
            "end": 189,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_44@3",
            "content": "We observe that zero-shot transfer matches and even surpasses SenNMT through N21 transfer, but fails with 12N transfer, although accuracy improvements on contrastive test sets show that both transfers are better than SenNMT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_44",
            "start": 191,
            "end": 414,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_44@4",
            "content": "We conjecture that these contrastive test sets only target a limited number of document phenomena and thus can't fully reflect the overall translation quality and represent human preference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_44",
            "start": 416,
            "end": 605,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_44@5",
            "content": "These numbers verify the feasibility of document-level zero-shot transfer through multilinguality.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_44",
            "start": 607,
            "end": 704,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_44@6",
            "content": "Besides, we find that genuine parallel documents benefit the transfer slightly more than BT-based pseudo ones, and that the supervised DocNMT reaches the best result under DocInfer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_44",
            "start": 706,
            "end": 886,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_45@0",
            "content": "We surprisingly find that DocNMT with SenInfer yields very competitive performance, although no contextual information is used for decoding.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_45",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_45@1",
            "content": "We also observe that such decoding tends to produce longer translations than SenNMT despite using the same decoding hyperparameters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_45",
            "start": 141,
            "end": 272,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_45@2",
            "content": "This behaviour should be shaped by the fact that DocNMT is biased towards long concatenated target references.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_45",
            "start": 274,
            "end": 383,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_45@3",
            "content": "This partially agrees with the recent argument that context improves DocNMT with some sort of regularization rather than teaching the model to deal with context (Kim et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_45",
            "start": 385,
            "end": 564,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_45@4",
            "content": "On the other hand, this challenges how to properly evaluate DocNMT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_45",
            "start": 566,
            "end": 632,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_46@0",
            "content": "Another observation is that applying DocInfer to SenNMT delivers a significant accuracy improvement on En-Fr contrastive test set (+8.5%, Table 5), but slightly worse results on En-De.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_46",
            "start": 0,
            "end": 183,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_46@1",
            "content": "To accurately recognize the correct translation in these test sets, models need to leverage context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_46",
            "start": 185,
            "end": 284,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_46@2",
            "content": "Such improvement might suggest that SenNMT has some limited capability of contextual modeling, but might just reflect the instability of small-scale test sets (only 200 cases in En-Fr test set, indicating a radius of around 7% for the 95% confidence interval).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_46",
            "start": 286,
            "end": 545,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_46@3",
            "content": "To some extent, this devalues the improvement achieved by 12N transfer as shown in Table 3, but strengthens the success of N21 transfer (often >9% gains).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_46",
            "start": 547,
            "end": 700,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_47@0",
            "content": "Conclusion and Future Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_47",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_48@0",
            "content": "This paper studies the variables playing role in achieving zero-shot document-level translation capability for languages that only have sentence level data (students), through multilingual transfer from languages that have access to document level data (teachers).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_48",
            "start": 0,
            "end": 263,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_48@1",
            "content": "We make the first step in this direction by extensively exploring properties of transfer by investigating three different variables.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_48",
            "start": 265,
            "end": 396,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_48@2",
            "content": "Our experiments on Europarl-7 and IWSLT-10 confirm the feasibility, where we discover that increasing document-supervised teacher languages thereby increasing the document training data size, adequately balancing between document and sentence data at training, and leveraging monolingual documents via back-translation all benefit zero-shot transfer in varying degrees.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_48",
            "start": 398,
            "end": 766,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_48@3",
            "content": "The transferability of contextual modeling in DocNMT demonstrates the potential of delivering multilingual DocNMT with limited document resources.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_48",
            "start": 768,
            "end": 913,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_49@0",
            "content": "Along with the success of document-level zeroshot transfer, problems with accurately estimating the document-level translation become challenging.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_49",
            "start": 0,
            "end": 145,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_49@1",
            "content": "BLEU often fails to capture document phenomena, while contrastive test sets only cover few document-level aspects.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_49",
            "start": 147,
            "end": 260,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_49@2",
            "content": "Neither perfectly correlates with human evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_49",
            "start": 262,
            "end": 312,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_49@3",
            "content": "Besides, whether the gains really come from contextual modeling is still unclear.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_49",
            "start": 314,
            "end": 394,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_49@4",
            "content": "Our human evaluation shows some preference to DocNMT with SenInfer where context is not used for decoding at all.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_49",
            "start": 396,
            "end": 508,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_49@5",
            "content": "Designing better evaluation protocols (either automatic or human) is again confirmed to be critical.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_49",
            "start": 510,
            "end": 609,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_49@6",
            "content": "Besides, performing analysis beyond 12N and N21 transfer deserves more effort and it is an interesting and plausible future direction to analyze how language similarity affects the transfer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_49",
            "start": 611,
            "end": 800,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_50@0",
            "content": "Zaixiang Zheng, Xiang Yue, Shujian Huang, Jiajun Chen, and Alexandra Birch. 2020.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_50",
            "start": 0,
            "end": 80,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_50@1",
            "content": "Towards making the most of context in neural machine translation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_50",
            "start": 82,
            "end": 146,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_51@0",
            "content": "In Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20, pages 3983-3989.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_51",
            "start": 0,
            "end": 119,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_51@1",
            "content": "International Joint Conferences on Artificial Intelligence Organization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_51",
            "start": 121,
            "end": 192,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_51@2",
            "content": "Main track.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_51",
            "start": 194,
            "end": 204,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_52@0",
            "content": "Table 6 shows the statistics for Europarl-7 and IWSLT-10.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_52",
            "start": 0,
            "end": 56,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_52@1",
            "content": "Compared to IWSLT-10, Europarl-7 includes fewer languages, but with higher quantity and more uneven distribution.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_52",
            "start": 58,
            "end": 170,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_53@0",
            "content": "We pretrain multilingual SenNMT for 100K and 300K steps on IWSLT-10 and Europarl-7 respectively, and adopt extra 20K finetuning steps for multilingual DocNMT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_53",
            "start": 0,
            "end": 157,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_53@1",
            "content": "We train all models (Sen-NMT & DocNMT) with a fixed batch size of 1280 samples, and schedule the training data distribution over language pairs according to the sentence-level statistics (without oversampling, and this also applies to DocNMT).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_53",
            "start": 159,
            "end": 401,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_53@2",
            "content": "All such measures aim to ensure a fair comparison between SenNMT and DocNMT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_53",
            "start": 403,
            "end": 478,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_54@0",
            "content": "For training, we truncate sequences with length limit of 100 and 512 for SenNMT and DocNMT separately.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_54",
            "start": 0,
            "end": 101,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_54@1",
            "content": "We average last 5 checkpoints for evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_54",
            "start": 103,
            "end": 147,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_54@2",
            "content": "Beam search is used for decoding with a beam size of 4 and length penalty of 0.6.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_54",
            "start": 149,
            "end": 229,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_54@3",
            "content": "During decoding, we disable the generation of the endof-sentence symbol for DocInfer until the model outputs the correct number of target translations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_54",
            "start": 231,
            "end": 381,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_55@0",
            "content": "The back-translated documents belong to extra training data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_55",
            "start": 0,
            "end": 59,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_55@1",
            "content": "How to mix them with the genuine sentence pairs during training is questionable.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_55",
            "start": 61,
            "end": 140,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_55@2",
            "content": "Before further study, we first explore the impact of these documents on translation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_55",
            "start": 142,
            "end": 225,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_55@3",
            "content": "Specifically, we sample p% BT documents for each language during training with the rest (1 \u2212 p%) being the original sentence pairs to testify the sensitivity of translation performance to p.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_55",
            "start": 227,
            "end": 416,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_55@4",
            "content": "Note the proportion p here differs from the one used in our main paper (where p denotes the proportion of parallel documents in all teacher languages to parallel sentences in student languages).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_55",
            "start": 418,
            "end": 611,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_56@0",
            "content": "Figure 6 shows that larger p generally yields better performance over all settings, similar to the results on genuine parallel documents as in Figure 7.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_56",
            "start": 0,
            "end": 151,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_56@1",
            "content": "Therefore, we replace all sentence pairs in teacher languages with the corresponding BT documents in our analysis.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_56",
            "start": 153,
            "end": 266,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_57@0",
            "content": "Languages to De/Fr",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_57",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_58@0",
            "content": "We mainly report average results over all transfer directions in the paper.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_58",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_58@1",
            "content": "Below we also show the transfer from individual languages to De and Fr on Europarl-7.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_58",
            "start": 76,
            "end": 160,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_58@2",
            "content": "Note the performance at language level is much noisy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_58",
            "start": 162,
            "end": 214,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_58@3",
            "content": "We observe that different teacher languages yield slightly different transfer behaviors and transferring to Fr looks more promising. .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_58",
            "start": 216,
            "end": 349,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_58@4",
            "content": "This is fully supervised multilingual DocNMT, where pseudo documents are used for all languages. Also, note p denotes the proportion of documents for each language, rather than teacher languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_58",
            "start": 351,
            "end": 545,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_59@0",
            "content": "Roee Aharoni, Melvin Johnson, Orhan Firat, Massively multilingual neural machine translation, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_59",
            "start": 0,
            "end": 285,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_60@0",
            "content": "UNKNOWN, None, 2019, The missing ingredient in zero-shot neural machine translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_60",
            "start": 0,
            "end": 85,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_61@0",
            "content": "UNKNOWN, None, 2019, Massively multilingual neural machine translation in the wild: Findings and challenges, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_61",
            "start": 0,
            "end": 109,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_62@0",
            "content": "UNKNOWN, None, , Santanu Pal, Matt Post, and Marcos Zampieri. 2020. Findings of the 2020 conference on machine translation (wmt20). In Proceedings of the Fifth Conference on Machine Translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_62",
            "start": 0,
            "end": 195,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_63@0",
            "content": "Rachel Bawden, Rico Sennrich, Alexandra Birch, Barry Haddow, Evaluating discourse phenomena in neural machine translation, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_63",
            "start": 0,
            "end": 314,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_64@0",
            "content": "M Cettolo, M Federico, L Bentivogli, J Niehues, S St\u00fcker, K Sudoh, K Yoshino, C Federmann, The iwslt 2017 evaluation campaign, 2017, The International Workshop on Spoken Language Translation (IWSLT), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_64",
            "start": 0,
            "end": 200,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_65@0",
            "content": "Junxuan Chen, Xiang Li, Jiarui Zhang, Chulun Zhou, Jianwei Cui, Bin Wang, Jinsong Su, Modeling discourse structure for document-level neural machine translation, 2020, Proceedings of the First Workshop on Automatic Simultaneous Translation, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_65",
            "start": 0,
            "end": 282,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_66@0",
            "content": "Zewen Chi, Li Dong, Furu Wei, Nan Yang, Saksham Singhal, Wenhui Wang, Xia Song, Xian-Ling Mao, Heyan Huang, Ming Zhou, InfoXLM: An information-theoretic framework for cross-lingual language model pre-training, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_66",
            "start": 0,
            "end": 401,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_67@0",
            "content": "Alexis Conneau, Guillaume Lample, Crosslingual language model pretraining, 2019, Advances in Neural Information Processing Systems, Curran Associates, Inc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_67",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_68@0",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long and Short Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_68",
            "start": 0,
            "end": 315,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_69@0",
            "content": "UNKNOWN, None, 2018, Zeroshot cross-lingual classification using multilingual neural machine translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_69",
            "start": 0,
            "end": 106,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_70@0",
            "content": "Orhan Firat, Kyunghyun Cho, Yoshua Bengio, Multi-way, multilingual neural machine translation with a shared attention mechanism, 2016, Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_70",
            "start": 0,
            "end": 320,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_71@0",
            "content": "Markus Freitag, George Foster, David Grangier, Viresh Ratnakar, Qijun Tan, and Wolfgang Macherey. 2021. Experts, Errors, and Context: A Large-Scale Study of Human Evaluation for Machine Translation, , Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_71",
            "start": 0,
            "end": 264,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_72@0",
            "content": "Jiatao Gu, Yong Wang, Kyunghyun Cho, O Victor,  Li, Improved zero-shot neural machine translation via ignoring spurious correlations, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_72",
            "start": 0,
            "end": 229,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_73@0",
            "content": "Junjie Hu, Sebastian Ruder, Aditya Siddhant, Graham Neubig, Orhan Firat, Melvin Johnson, XTREME: A massively multilingual multitask benchmark for evaluating cross-lingual generalisation, 2020, Proceedings of the 37th International Conference on Machine Learning, PMLR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_73",
            "start": 0,
            "end": 267,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_74@0",
            "content": "Jingjing Huo, Christian Herold, Yingbo Gao, Leonard Dahlmann, Shahram Khadivi, Hermann Ney, Diving deep into context-aware neural machine translation, 2020, Proceedings of the Fifth Conference on Machine Translation, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_74",
            "start": 0,
            "end": 258,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_75@0",
            "content": "UNKNOWN, None, 2017, Does neural machine translation benefit from larger context?, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_75",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_76@0",
            "content": "Melvin Johnson, Mike Schuster, Quoc Le, Maxim Krikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat, Fernanda Vi\u00e9gas, Martin Wattenberg, Greg Corrado, Macduff Hughes, Jeffrey Dean, Google's multilingual neural machine translation system: Enabling zero-shot translation, 2017, Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_76",
            "start": 0,
            "end": 333,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_77@0",
            "content": "Marcin Junczys-Dowmunt, Microsoft translator at WMT 2019: Towards large-scale document-level neural machine translation, 2019, Proceedings of the Fourth Conference on Machine Translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_77",
            "start": 0,
            "end": 188,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_78@0",
            "content": "Xiaomian Kang, Yang Zhao, Jiajun Zhang, Chengqing Zong, Dynamic context selection for document-level neural machine translation via reinforcement learning, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_78",
            "start": 0,
            "end": 299,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_79@0",
            "content": "Yunsu Kim, Thanh Duc, Hermann Tran,  Ney, When and why is document-level context useful in neural machine translation?, 2019, Proceedings of the Fourth Workshop on Discourse in Machine Translation, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_79",
            "start": 0,
            "end": 239,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_80@0",
            "content": "P Diederik, Jimmy Kingma,  Ba, Adam: A method for stochastic optimization, 2015, International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_80",
            "start": 0,
            "end": 135,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_81@0",
            "content": "Tom Kocmi, Christian Federmann, Roman Grundkiewicz, Marcin Junczys-Dowmunt, To ship or not to ship: An extensive evaluation of automatic metrics for machine translation, 2021, Proceedings of the Sixth Conference on Machine Translation, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_81",
            "start": 0,
            "end": 285,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_82@0",
            "content": "Philipp Koehn, Europarl: A Parallel Corpus for Statistical Machine Translation, 2005, Conference Proceedings: the tenth Machine Translation Summit, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_82",
            "start": 0,
            "end": 148,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_83@0",
            "content": "UNKNOWN, None, 2018, Genderaware natural language translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_83",
            "start": 0,
            "end": 63,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_84@0",
            "content": "Taku Kudo, John Richardson, SentencePiece: A simple and language independent subword tokenizer and detokenizer for neural text processing, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_84",
            "start": 0,
            "end": 297,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_85@0",
            "content": "Sneha Kudugunta, Ankur Bapna, Isaac Caswell, Orhan Firat, Investigating multilingual NMT representations at scale, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_85",
            "start": 0,
            "end": 339,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_86@0",
            "content": "Samuel L\u00e4ubli, Rico Sennrich, Martin Volk, Has machine translation achieved human parity? a case for document-level evaluation, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_86",
            "start": 0,
            "end": 263,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_87@0",
            "content": "Ant\u00f3nio Lopes, M Amin Farajian, Rachel Bawden, Michael Zhang, Andr\u00e9 Martins, Document-level neural MT: A systematic comparison, 2020, Proceedings of the 22nd Annual Conference of the European Association for Machine Translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_87",
            "start": 0,
            "end": 229,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_88@0",
            "content": "UNKNOWN, None, 2021, A comparison of approaches to document-level machine translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_88",
            "start": 0,
            "end": 87,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_89@0",
            "content": "Elman Mansimov, G\u00e1bor Melis, Lei Yu, Capturing document context inside sentence-level neural machine translation models with self-training, 2021, Proceedings of the 2nd Workshop on Computational Approaches to Discourse, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_89",
            "start": 0,
            "end": 220,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_90@0",
            "content": "Sameen Maruf, Fahimeh Saleh, Gholamreza Haffari, A survey on document-level neural machine translation: Methods and evaluation, 2021, ACM Comput. Surv, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_90",
            "start": 0,
            "end": 152,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_91@0",
            "content": "Lesly Miculicich, Dhananjay Ram, Nikolaos Pappas, James Henderson, Document-level neural machine translation with hierarchical attention networks, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_91",
            "start": 0,
            "end": 241,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_92@0",
            "content": "Mathias M\u00fcller, Annette Rios, Elena Voita, Rico Sennrich, A large-scale test set for the evaluation of context-aware pronoun translation in neural machine translation, 2018, Proceedings of the Third Conference on Machine Translation: Research Papers, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_92",
            "start": 0,
            "end": 292,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_93@0",
            "content": "Matt Post, A call for clarity in reporting BLEU scores, 2018, Proceedings of the Third Conference on Machine Translation: Research Papers, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_93",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_94@0",
            "content": "UNKNOWN, None, 2021, Xtreme-r: Towards more challenging and nuanced multilingual evaluation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_94",
            "start": 0,
            "end": 93,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_95@0",
            "content": "Danielle Saunders, Bill Byrne, Reducing gender bias in neural machine translation as a domain adaptation problem, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_95",
            "start": 0,
            "end": 258,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_96@0",
            "content": "Rico Sennrich, Barry Haddow, Alexandra Birch, Neural machine translation of rare words with subword units, 2016, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_96",
            "start": 0,
            "end": 213,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_97@0",
            "content": "Aditya Siddhant, Melvin Johnson, Henry Tsai, Naveen Ari, Jason Riesa, Ankur Bapna, Orhan Firat, Karthik Raman, Evaluating the cross-lingual effectiveness of massively multilingual neural machine translation, 2020, Proceedings of the AAAI Conference on Artificial Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_97",
            "start": 0,
            "end": 277,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_98@0",
            "content": "Amane Sugiyama, Naoki Yoshinaga, Data augmentation using back-translation for contextaware neural machine translation, 2019, Proceedings of the Fourth Workshop on Discourse in Machine Translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_98",
            "start": 0,
            "end": 197,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_99@0",
            "content": "UNKNOWN, None, 2020, Capturing longer context for document-level neural machine translation: A multi-resolutional approach, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_99",
            "start": 0,
            "end": 124,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_100@0",
            "content": "J\u00f6rg Tiedemann, Yves Scherrer, Neural machine translation with extended context, 2017, Proceedings of the Third Workshop on Discourse in Machine Translation, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_100",
            "start": 0,
            "end": 199,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_101@0",
            "content": ", Document level NMT of low-resource languages with backtranslation, 2020, Proceedings of the Fifth Conference on Machine Translation, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_101",
            "start": 0,
            "end": 184,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_102@0",
            "content": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, Illia Kaiser,  Polosukhin, Attention is all you need, 2017, Advances in Neural Information Processing Systems, Curran Associates, Inc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_102",
            "start": 0,
            "end": 219,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_103@0",
            "content": "Elena Voita, Rico Sennrich, Ivan Titov, When a good translation is wrong in context: Context-aware machine translation improves on deixis, ellipsis, and lexical cohesion, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_103",
            "start": 0,
            "end": 266,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_104@0",
            "content": "Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, and Colin Raffel. 2021. mT5: A massively multilingual pre-trained text-to-text transformer, , Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_104",
            "start": 0,
            "end": 337,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_105@0",
            "content": "Lei Yu, Laurent Sartran, Wojciech Stokowiec, Wang Ling, Lingpeng Kong, Phil Blunsom, Chris Dyer, Better document-level machine translation with Bayes' rule, 2020, Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_105",
            "start": 0,
            "end": 226,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_106@0",
            "content": "Biao Zhang, Ankur Bapna, Rico Sennrich, Orhan Firat, Share or not? learning to schedule language-specific capacity for multilingual translation, 2021, International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_106",
            "start": 0,
            "end": 205,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_107@0",
            "content": "Biao Zhang, Philip Williams, Ivan Titov, Rico Sennrich, Improving massively multilingual neural machine translation and zero-shot translation, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_107",
            "start": 0,
            "end": 238,
            "label": {}
        },
        {
            "ix": "58-ARR_v2_108@0",
            "content": "Jiacheng Zhang, Huanbo Luan, Maosong Sun, Feifei Zhai, Jingfang Xu, Min Zhang, Yang Liu, Improving the transformer translation model with document-level context, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "58-ARR_v2_108",
            "start": 0,
            "end": 297,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "58-ARR_v2_0",
            "tgt_ix": "58-ARR_v2_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_0",
            "tgt_ix": "58-ARR_v2_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_1",
            "tgt_ix": "58-ARR_v2_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_1",
            "tgt_ix": "58-ARR_v2_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_0",
            "tgt_ix": "58-ARR_v2_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_2",
            "tgt_ix": "58-ARR_v2_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_4",
            "tgt_ix": "58-ARR_v2_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_5",
            "tgt_ix": "58-ARR_v2_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_6",
            "tgt_ix": "58-ARR_v2_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_7",
            "tgt_ix": "58-ARR_v2_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_3",
            "tgt_ix": "58-ARR_v2_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_3",
            "tgt_ix": "58-ARR_v2_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_3",
            "tgt_ix": "58-ARR_v2_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_3",
            "tgt_ix": "58-ARR_v2_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_3",
            "tgt_ix": "58-ARR_v2_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_3",
            "tgt_ix": "58-ARR_v2_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_0",
            "tgt_ix": "58-ARR_v2_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_10",
            "tgt_ix": "58-ARR_v2_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_11",
            "tgt_ix": "58-ARR_v2_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_9",
            "tgt_ix": "58-ARR_v2_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_9",
            "tgt_ix": "58-ARR_v2_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_9",
            "tgt_ix": "58-ARR_v2_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_9",
            "tgt_ix": "58-ARR_v2_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_0",
            "tgt_ix": "58-ARR_v2_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_12",
            "tgt_ix": "58-ARR_v2_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_13",
            "tgt_ix": "58-ARR_v2_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_13",
            "tgt_ix": "58-ARR_v2_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_13",
            "tgt_ix": "58-ARR_v2_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_14",
            "tgt_ix": "58-ARR_v2_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_16",
            "tgt_ix": "58-ARR_v2_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_15",
            "tgt_ix": "58-ARR_v2_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_15",
            "tgt_ix": "58-ARR_v2_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_15",
            "tgt_ix": "58-ARR_v2_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_13",
            "tgt_ix": "58-ARR_v2_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_17",
            "tgt_ix": "58-ARR_v2_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_19",
            "tgt_ix": "58-ARR_v2_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_18",
            "tgt_ix": "58-ARR_v2_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_18",
            "tgt_ix": "58-ARR_v2_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_18",
            "tgt_ix": "58-ARR_v2_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_0",
            "tgt_ix": "58-ARR_v2_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_22",
            "tgt_ix": "58-ARR_v2_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_23",
            "tgt_ix": "58-ARR_v2_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_24",
            "tgt_ix": "58-ARR_v2_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_25",
            "tgt_ix": "58-ARR_v2_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_26",
            "tgt_ix": "58-ARR_v2_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_27",
            "tgt_ix": "58-ARR_v2_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_28",
            "tgt_ix": "58-ARR_v2_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_29",
            "tgt_ix": "58-ARR_v2_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_30",
            "tgt_ix": "58-ARR_v2_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_31",
            "tgt_ix": "58-ARR_v2_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_21",
            "tgt_ix": "58-ARR_v2_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_21",
            "tgt_ix": "58-ARR_v2_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_21",
            "tgt_ix": "58-ARR_v2_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_21",
            "tgt_ix": "58-ARR_v2_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_21",
            "tgt_ix": "58-ARR_v2_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_21",
            "tgt_ix": "58-ARR_v2_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_21",
            "tgt_ix": "58-ARR_v2_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_21",
            "tgt_ix": "58-ARR_v2_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_21",
            "tgt_ix": "58-ARR_v2_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_21",
            "tgt_ix": "58-ARR_v2_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_21",
            "tgt_ix": "58-ARR_v2_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_21",
            "tgt_ix": "58-ARR_v2_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_0",
            "tgt_ix": "58-ARR_v2_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_32",
            "tgt_ix": "58-ARR_v2_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_34",
            "tgt_ix": "58-ARR_v2_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_35",
            "tgt_ix": "58-ARR_v2_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_36",
            "tgt_ix": "58-ARR_v2_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_37",
            "tgt_ix": "58-ARR_v2_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_38",
            "tgt_ix": "58-ARR_v2_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_39",
            "tgt_ix": "58-ARR_v2_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_33",
            "tgt_ix": "58-ARR_v2_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_33",
            "tgt_ix": "58-ARR_v2_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_33",
            "tgt_ix": "58-ARR_v2_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_33",
            "tgt_ix": "58-ARR_v2_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_33",
            "tgt_ix": "58-ARR_v2_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_33",
            "tgt_ix": "58-ARR_v2_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_33",
            "tgt_ix": "58-ARR_v2_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_33",
            "tgt_ix": "58-ARR_v2_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_41",
            "tgt_ix": "58-ARR_v2_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_33",
            "tgt_ix": "58-ARR_v2_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_33",
            "tgt_ix": "58-ARR_v2_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_40",
            "tgt_ix": "58-ARR_v2_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_0",
            "tgt_ix": "58-ARR_v2_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_42",
            "tgt_ix": "58-ARR_v2_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_44",
            "tgt_ix": "58-ARR_v2_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_45",
            "tgt_ix": "58-ARR_v2_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_43",
            "tgt_ix": "58-ARR_v2_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_43",
            "tgt_ix": "58-ARR_v2_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_43",
            "tgt_ix": "58-ARR_v2_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_43",
            "tgt_ix": "58-ARR_v2_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_0",
            "tgt_ix": "58-ARR_v2_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_46",
            "tgt_ix": "58-ARR_v2_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_48",
            "tgt_ix": "58-ARR_v2_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_49",
            "tgt_ix": "58-ARR_v2_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_50",
            "tgt_ix": "58-ARR_v2_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_47",
            "tgt_ix": "58-ARR_v2_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_47",
            "tgt_ix": "58-ARR_v2_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_47",
            "tgt_ix": "58-ARR_v2_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_47",
            "tgt_ix": "58-ARR_v2_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_47",
            "tgt_ix": "58-ARR_v2_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_47",
            "tgt_ix": "58-ARR_v2_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_51",
            "tgt_ix": "58-ARR_v2_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_53",
            "tgt_ix": "58-ARR_v2_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_47",
            "tgt_ix": "58-ARR_v2_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_47",
            "tgt_ix": "58-ARR_v2_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_52",
            "tgt_ix": "58-ARR_v2_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_55",
            "tgt_ix": "58-ARR_v2_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_47",
            "tgt_ix": "58-ARR_v2_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_47",
            "tgt_ix": "58-ARR_v2_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_54",
            "tgt_ix": "58-ARR_v2_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_57",
            "tgt_ix": "58-ARR_v2_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_47",
            "tgt_ix": "58-ARR_v2_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_47",
            "tgt_ix": "58-ARR_v2_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_56",
            "tgt_ix": "58-ARR_v2_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "58-ARR_v2_0",
            "tgt_ix": "58-ARR_v2_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_1",
            "tgt_ix": "58-ARR_v2_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_2",
            "tgt_ix": "58-ARR_v2_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_2",
            "tgt_ix": "58-ARR_v2_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_2",
            "tgt_ix": "58-ARR_v2_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_2",
            "tgt_ix": "58-ARR_v2_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_2",
            "tgt_ix": "58-ARR_v2_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_2",
            "tgt_ix": "58-ARR_v2_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_2",
            "tgt_ix": "58-ARR_v2_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_2",
            "tgt_ix": "58-ARR_v2_2@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_2",
            "tgt_ix": "58-ARR_v2_2@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_3",
            "tgt_ix": "58-ARR_v2_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_4",
            "tgt_ix": "58-ARR_v2_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_4",
            "tgt_ix": "58-ARR_v2_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_4",
            "tgt_ix": "58-ARR_v2_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_4",
            "tgt_ix": "58-ARR_v2_4@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_4",
            "tgt_ix": "58-ARR_v2_4@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_4",
            "tgt_ix": "58-ARR_v2_4@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_4",
            "tgt_ix": "58-ARR_v2_4@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_4",
            "tgt_ix": "58-ARR_v2_4@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_5",
            "tgt_ix": "58-ARR_v2_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_5",
            "tgt_ix": "58-ARR_v2_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_6",
            "tgt_ix": "58-ARR_v2_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_6",
            "tgt_ix": "58-ARR_v2_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_6",
            "tgt_ix": "58-ARR_v2_6@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_7",
            "tgt_ix": "58-ARR_v2_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_7",
            "tgt_ix": "58-ARR_v2_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_7",
            "tgt_ix": "58-ARR_v2_7@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_7",
            "tgt_ix": "58-ARR_v2_7@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_7",
            "tgt_ix": "58-ARR_v2_7@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_8",
            "tgt_ix": "58-ARR_v2_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_9",
            "tgt_ix": "58-ARR_v2_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_10",
            "tgt_ix": "58-ARR_v2_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_11",
            "tgt_ix": "58-ARR_v2_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_11",
            "tgt_ix": "58-ARR_v2_11@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_11",
            "tgt_ix": "58-ARR_v2_11@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_11",
            "tgt_ix": "58-ARR_v2_11@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_12",
            "tgt_ix": "58-ARR_v2_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_12",
            "tgt_ix": "58-ARR_v2_12@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_12",
            "tgt_ix": "58-ARR_v2_12@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_12",
            "tgt_ix": "58-ARR_v2_12@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_13",
            "tgt_ix": "58-ARR_v2_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_14",
            "tgt_ix": "58-ARR_v2_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_14",
            "tgt_ix": "58-ARR_v2_14@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_14",
            "tgt_ix": "58-ARR_v2_14@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_14",
            "tgt_ix": "58-ARR_v2_14@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_15",
            "tgt_ix": "58-ARR_v2_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_16",
            "tgt_ix": "58-ARR_v2_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_16",
            "tgt_ix": "58-ARR_v2_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_16",
            "tgt_ix": "58-ARR_v2_16@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_16",
            "tgt_ix": "58-ARR_v2_16@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_17",
            "tgt_ix": "58-ARR_v2_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_17",
            "tgt_ix": "58-ARR_v2_17@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_17",
            "tgt_ix": "58-ARR_v2_17@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_17",
            "tgt_ix": "58-ARR_v2_17@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_17",
            "tgt_ix": "58-ARR_v2_17@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_18",
            "tgt_ix": "58-ARR_v2_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_19",
            "tgt_ix": "58-ARR_v2_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_20",
            "tgt_ix": "58-ARR_v2_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_21",
            "tgt_ix": "58-ARR_v2_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_22",
            "tgt_ix": "58-ARR_v2_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_22",
            "tgt_ix": "58-ARR_v2_22@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_22",
            "tgt_ix": "58-ARR_v2_22@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_22",
            "tgt_ix": "58-ARR_v2_22@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_22",
            "tgt_ix": "58-ARR_v2_22@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_22",
            "tgt_ix": "58-ARR_v2_22@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_22",
            "tgt_ix": "58-ARR_v2_22@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_22",
            "tgt_ix": "58-ARR_v2_22@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_23",
            "tgt_ix": "58-ARR_v2_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_23",
            "tgt_ix": "58-ARR_v2_23@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_24",
            "tgt_ix": "58-ARR_v2_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_24",
            "tgt_ix": "58-ARR_v2_24@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_24",
            "tgt_ix": "58-ARR_v2_24@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_24",
            "tgt_ix": "58-ARR_v2_24@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_24",
            "tgt_ix": "58-ARR_v2_24@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_25",
            "tgt_ix": "58-ARR_v2_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_25",
            "tgt_ix": "58-ARR_v2_25@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_25",
            "tgt_ix": "58-ARR_v2_25@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_26",
            "tgt_ix": "58-ARR_v2_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_27",
            "tgt_ix": "58-ARR_v2_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_27",
            "tgt_ix": "58-ARR_v2_27@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_28",
            "tgt_ix": "58-ARR_v2_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_28",
            "tgt_ix": "58-ARR_v2_28@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_28",
            "tgt_ix": "58-ARR_v2_28@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_28",
            "tgt_ix": "58-ARR_v2_28@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_29",
            "tgt_ix": "58-ARR_v2_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_29",
            "tgt_ix": "58-ARR_v2_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_29",
            "tgt_ix": "58-ARR_v2_29@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_30",
            "tgt_ix": "58-ARR_v2_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_31",
            "tgt_ix": "58-ARR_v2_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_31",
            "tgt_ix": "58-ARR_v2_31@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_32",
            "tgt_ix": "58-ARR_v2_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_32",
            "tgt_ix": "58-ARR_v2_32@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_32",
            "tgt_ix": "58-ARR_v2_32@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_32",
            "tgt_ix": "58-ARR_v2_32@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_32",
            "tgt_ix": "58-ARR_v2_32@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_32",
            "tgt_ix": "58-ARR_v2_32@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_32",
            "tgt_ix": "58-ARR_v2_32@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_32",
            "tgt_ix": "58-ARR_v2_32@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_32",
            "tgt_ix": "58-ARR_v2_32@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_32",
            "tgt_ix": "58-ARR_v2_32@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_32",
            "tgt_ix": "58-ARR_v2_32@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_33",
            "tgt_ix": "58-ARR_v2_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_34",
            "tgt_ix": "58-ARR_v2_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_34",
            "tgt_ix": "58-ARR_v2_34@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_34",
            "tgt_ix": "58-ARR_v2_34@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_35",
            "tgt_ix": "58-ARR_v2_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_35",
            "tgt_ix": "58-ARR_v2_35@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_35",
            "tgt_ix": "58-ARR_v2_35@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_35",
            "tgt_ix": "58-ARR_v2_35@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_36",
            "tgt_ix": "58-ARR_v2_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_36",
            "tgt_ix": "58-ARR_v2_36@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_36",
            "tgt_ix": "58-ARR_v2_36@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_36",
            "tgt_ix": "58-ARR_v2_36@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_37",
            "tgt_ix": "58-ARR_v2_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_37",
            "tgt_ix": "58-ARR_v2_37@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_37",
            "tgt_ix": "58-ARR_v2_37@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_37",
            "tgt_ix": "58-ARR_v2_37@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_37",
            "tgt_ix": "58-ARR_v2_37@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_37",
            "tgt_ix": "58-ARR_v2_37@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_37",
            "tgt_ix": "58-ARR_v2_37@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_37",
            "tgt_ix": "58-ARR_v2_37@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_38",
            "tgt_ix": "58-ARR_v2_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_38",
            "tgt_ix": "58-ARR_v2_38@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_39",
            "tgt_ix": "58-ARR_v2_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_39",
            "tgt_ix": "58-ARR_v2_39@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_39",
            "tgt_ix": "58-ARR_v2_39@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_39",
            "tgt_ix": "58-ARR_v2_39@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_39",
            "tgt_ix": "58-ARR_v2_39@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_39",
            "tgt_ix": "58-ARR_v2_39@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_39",
            "tgt_ix": "58-ARR_v2_39@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_39",
            "tgt_ix": "58-ARR_v2_39@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_40",
            "tgt_ix": "58-ARR_v2_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_41",
            "tgt_ix": "58-ARR_v2_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_41",
            "tgt_ix": "58-ARR_v2_41@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_41",
            "tgt_ix": "58-ARR_v2_41@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_41",
            "tgt_ix": "58-ARR_v2_41@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_42",
            "tgt_ix": "58-ARR_v2_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_42",
            "tgt_ix": "58-ARR_v2_42@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_42",
            "tgt_ix": "58-ARR_v2_42@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_43",
            "tgt_ix": "58-ARR_v2_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_44",
            "tgt_ix": "58-ARR_v2_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_44",
            "tgt_ix": "58-ARR_v2_44@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_44",
            "tgt_ix": "58-ARR_v2_44@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_44",
            "tgt_ix": "58-ARR_v2_44@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_44",
            "tgt_ix": "58-ARR_v2_44@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_44",
            "tgt_ix": "58-ARR_v2_44@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_44",
            "tgt_ix": "58-ARR_v2_44@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_45",
            "tgt_ix": "58-ARR_v2_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_45",
            "tgt_ix": "58-ARR_v2_45@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_45",
            "tgt_ix": "58-ARR_v2_45@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_45",
            "tgt_ix": "58-ARR_v2_45@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_45",
            "tgt_ix": "58-ARR_v2_45@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_46",
            "tgt_ix": "58-ARR_v2_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_46",
            "tgt_ix": "58-ARR_v2_46@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_46",
            "tgt_ix": "58-ARR_v2_46@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_46",
            "tgt_ix": "58-ARR_v2_46@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_47",
            "tgt_ix": "58-ARR_v2_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_48",
            "tgt_ix": "58-ARR_v2_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_48",
            "tgt_ix": "58-ARR_v2_48@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_48",
            "tgt_ix": "58-ARR_v2_48@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_48",
            "tgt_ix": "58-ARR_v2_48@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_49",
            "tgt_ix": "58-ARR_v2_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_49",
            "tgt_ix": "58-ARR_v2_49@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_49",
            "tgt_ix": "58-ARR_v2_49@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_49",
            "tgt_ix": "58-ARR_v2_49@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_49",
            "tgt_ix": "58-ARR_v2_49@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_49",
            "tgt_ix": "58-ARR_v2_49@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_49",
            "tgt_ix": "58-ARR_v2_49@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_50",
            "tgt_ix": "58-ARR_v2_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_50",
            "tgt_ix": "58-ARR_v2_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_51",
            "tgt_ix": "58-ARR_v2_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_51",
            "tgt_ix": "58-ARR_v2_51@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_51",
            "tgt_ix": "58-ARR_v2_51@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_52",
            "tgt_ix": "58-ARR_v2_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_52",
            "tgt_ix": "58-ARR_v2_52@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_53",
            "tgt_ix": "58-ARR_v2_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_53",
            "tgt_ix": "58-ARR_v2_53@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_53",
            "tgt_ix": "58-ARR_v2_53@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_54",
            "tgt_ix": "58-ARR_v2_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_54",
            "tgt_ix": "58-ARR_v2_54@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_54",
            "tgt_ix": "58-ARR_v2_54@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_54",
            "tgt_ix": "58-ARR_v2_54@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_55",
            "tgt_ix": "58-ARR_v2_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_55",
            "tgt_ix": "58-ARR_v2_55@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_55",
            "tgt_ix": "58-ARR_v2_55@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_55",
            "tgt_ix": "58-ARR_v2_55@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_55",
            "tgt_ix": "58-ARR_v2_55@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_56",
            "tgt_ix": "58-ARR_v2_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_56",
            "tgt_ix": "58-ARR_v2_56@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_57",
            "tgt_ix": "58-ARR_v2_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_58",
            "tgt_ix": "58-ARR_v2_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_58",
            "tgt_ix": "58-ARR_v2_58@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_58",
            "tgt_ix": "58-ARR_v2_58@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_58",
            "tgt_ix": "58-ARR_v2_58@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_58",
            "tgt_ix": "58-ARR_v2_58@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_59",
            "tgt_ix": "58-ARR_v2_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_60",
            "tgt_ix": "58-ARR_v2_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_61",
            "tgt_ix": "58-ARR_v2_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_62",
            "tgt_ix": "58-ARR_v2_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_63",
            "tgt_ix": "58-ARR_v2_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_64",
            "tgt_ix": "58-ARR_v2_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_65",
            "tgt_ix": "58-ARR_v2_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_66",
            "tgt_ix": "58-ARR_v2_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_67",
            "tgt_ix": "58-ARR_v2_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_68",
            "tgt_ix": "58-ARR_v2_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_69",
            "tgt_ix": "58-ARR_v2_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_70",
            "tgt_ix": "58-ARR_v2_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_71",
            "tgt_ix": "58-ARR_v2_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_72",
            "tgt_ix": "58-ARR_v2_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_73",
            "tgt_ix": "58-ARR_v2_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_74",
            "tgt_ix": "58-ARR_v2_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_75",
            "tgt_ix": "58-ARR_v2_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_76",
            "tgt_ix": "58-ARR_v2_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_77",
            "tgt_ix": "58-ARR_v2_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_78",
            "tgt_ix": "58-ARR_v2_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_79",
            "tgt_ix": "58-ARR_v2_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_80",
            "tgt_ix": "58-ARR_v2_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_81",
            "tgt_ix": "58-ARR_v2_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_82",
            "tgt_ix": "58-ARR_v2_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_83",
            "tgt_ix": "58-ARR_v2_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_84",
            "tgt_ix": "58-ARR_v2_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_85",
            "tgt_ix": "58-ARR_v2_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_86",
            "tgt_ix": "58-ARR_v2_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_87",
            "tgt_ix": "58-ARR_v2_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_88",
            "tgt_ix": "58-ARR_v2_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_89",
            "tgt_ix": "58-ARR_v2_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_90",
            "tgt_ix": "58-ARR_v2_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_91",
            "tgt_ix": "58-ARR_v2_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_92",
            "tgt_ix": "58-ARR_v2_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_93",
            "tgt_ix": "58-ARR_v2_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_94",
            "tgt_ix": "58-ARR_v2_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_95",
            "tgt_ix": "58-ARR_v2_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_96",
            "tgt_ix": "58-ARR_v2_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_97",
            "tgt_ix": "58-ARR_v2_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_98",
            "tgt_ix": "58-ARR_v2_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_99",
            "tgt_ix": "58-ARR_v2_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_100",
            "tgt_ix": "58-ARR_v2_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_101",
            "tgt_ix": "58-ARR_v2_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_102",
            "tgt_ix": "58-ARR_v2_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_103",
            "tgt_ix": "58-ARR_v2_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_104",
            "tgt_ix": "58-ARR_v2_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_105",
            "tgt_ix": "58-ARR_v2_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_106",
            "tgt_ix": "58-ARR_v2_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_107",
            "tgt_ix": "58-ARR_v2_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "58-ARR_v2_108",
            "tgt_ix": "58-ARR_v2_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 787,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "doc_id": "58-ARR",
        "version": 2
    }
}