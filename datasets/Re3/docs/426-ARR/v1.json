{
    "nodes": [
        {
            "ix": "426-ARR_v1_0",
            "content": "Challenging America: Modeling language in longer time scales",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_2",
            "content": "The aim of the paper is to apply, for historical texts, the methodology used commonly to solve various NLP tasks defined for contemporary data, i.e. pre-train and fine-tune large Transformer models. This paper introduces an ML challenge, named Challenging America (Chal-lAm), based on OCR-ed excerpts from historical newspapers collected from the Chronicling America portal. ChallAm provides a dataset of clippings, labeled with metadata on their origin, and paired with their textual contents retrieved by an OCR tool. Three, publicly available, ML tasks are defined in the challenge: to determine the article date, to detect the location of the issue, and to deduce a word in a text gap (cloze test). Strong baselines are provided for all three ChallAm tasks. In particular, we pretrained a RoBERTa model from scratch from the historical texts. We also discuss the issues of discrimination and hate-speech present in the historical American texts.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "426-ARR_v1_4",
            "content": "The dominant approach in the design of current NLP solutions consists in (pre-)training a large neural language model, usually applying a Transformer architecture, such as GPT-2, RoBERTa or T5, and fine-tuning the model for specific tasks (Devlin et al., 2018;Raffel et al., 2019). The solutions are evaluated on benchmarks such as GLUE ((Wang et al., 2018)) or SuperGLUE ((Wang et al., 2019)), which allow comparing the performance of various methods designed for the same purpose. A main feature of a good NLP benchmark is the clear separation between train and test sets. This requirement prevents data contamination, when the model (pre-)trained on huge data might have \"seen\" the test set.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_5",
            "content": "The expansion of digital information is proceeding in two directions on the temporal axis. In the forward direction, new data are made publicly available on the Internet every second. What is less obvious is that, in the backward direction, older and older historical documents are digitized and disseminated publicly.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_6",
            "content": "To the best of our knowledge, our paper introduces the first benchmark which serves to use and evaluate the \"pre-train and fine-tune scenario\" applied to a massive collection of historical texts.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_7",
            "content": "The very idea of building language models on historical data is not new. The Google Ngram Viewer (Michel et al., 2011) is based on large amounts of texts from digitized books. The corpus as a whole is not open for the NLP community -only raw n-gram statistics are available. The temporal information is crude (at best, the year of publication is given) and the corpus is heterogeneous (in fact, it is a dump of digitized books of any origin).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_8",
            "content": "In our research, we use one of the richest sources of homogeneous historical documents, Chronicling America, a collection of digitized newspapers that cover the publication period of over 300 years (with significant coverage of 150 years), and design an NLP benchmark that may open new opportunities for the modeling of the historical language.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_9",
            "content": "Recently, time-aware language models such as Temporal T5 (Dhingra et al., 2021) and Tem-poBERT (Rosin et al., 2021) have been proposed. They focus on modern texts dated yearly, whereas we extend language modeling towards both longer time scales and more fine-grained (daily) resolution, using massive amounts of historical texts.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_10",
            "content": "The contribution of this paper is as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_11",
            "content": "\u2022 We extracted a large corpus of English historical texts that may serve to pre-train historical language models (Section 5).",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_12",
            "content": "These are the main features of the corpus:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_13",
            "content": "the corpus size is 201 GB, which is comparable with contemporary text data for training massive language models, such as GPT-2, RoBERTa or T5; the corpus is free of spam and noisy data (although the quality of OCR processing varies); texts are dated with a daily resolution, hence a new dimension of time (on a fine-grained level) can be introduced into language modeling; the whole corpus is made publicly available;",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_14",
            "content": "\u2022 Based on selected excerpts from Chronicling America, we define a suite of challenges (named Challanging America, or ChallAm in short) with three ML tasks combining layout recognition, information extraction and semantic inference (Section 7). We hope that ChallAm will give rise to a historical equivalent of the GLUE (Wang et al., 2018) or Su-perGLUE (Wang et al., 2019) benchmarks.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_15",
            "content": "-In particular, we provide a tool for the intrinsic evaluation of language models based on a word-gap task, which calculates the model perplexity in a comparative scenario (the tool may be used in competitive shared-tasks) (Section 7.3).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_16",
            "content": "\u2022 We propose a \"future-proof\" methodology for the creation of NLP challenges: a challenge is automatically updated whenever the underlying corpus is enriched (Section 6.3). \u2022 We introduce a method for data preparation that prevents data contamination (Section 6.3). \u2022 We train base Transformer (RoBERTa) models for historical texts (Section 5). The models are trained on texts spanning 100 years, dated with a daily resolution. \u2022 We provide strong baselines for three ChronAm challenges (Section 8). \u2022 We take under consideration the issue of discrimination and hate speech in the historical American texts. To this end we have applied up-to date methods to filter out the abusive content from the data (Section 9).",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_17",
            "content": "Chronicling America",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "426-ARR_v1_18",
            "content": "In 2005 a partnership between the National Endowment for the Humanities and the Library of Congress launched the National Digital Newspaper Program, to develop a database of digitized documents with easy access. The result of this 15-year effort is Chronicling America -a website 1 which provides access to selected digitized newspapers, published from 1690 to the present. The collection includes approximately 140 000 bibliographic title entries and 600 000 library holdings records, converted to the MARCXML format. The portal supports an API which allows accessing of the data in various ways, such as the JSON format, BulkData (bulk access to data) or Linked Data, 2 or searching of the database with the OpenSearch protocol. 3 . The accessibility of data in various forms makes Chronicling America a valuable source for the creation of datasets and benchmarks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_19",
            "content": "The portal serves as a resource for various research activities. Cultural historians may track performances and events of their interest in a resource which is easily and openly accessible, as opposed to commercial databases or \"relatively small collections of cultural heritage organizations whose online resources are isolated and difficult to search\" (Clark, 2014). The database enables searching for the first historical usages of word terms. For instance, thanks to the Chronicling America portal, it was discovered in (Cibaroglu, 2019) that the term \"fake news\" was first used in 1889 in the Polish newspaper Ameryka.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_20",
            "content": "The resource is helpful in research aiming to improve the output of the OCR process. The authors of (Nguyen et al., 2019) study OCR errors occurring in several digital databases -including Chronicling America -and compare them with human-generated misspellings. The research results in several suggestions for the design of OCR post-processing methods. The implementation of an unsupervised approach in the correction of OCR documents is described in (Dong and Smith, 2018). Two million issues from the Chronicling America collection of historic U.S. newspapers are used in a sequence-to-sequence model with attention.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_21",
            "content": "Chronicling America is a type of digitized resource that may be of wide use for both humanities and computational research. We prepared datasets and challenges based on the data from the Chronicling America resource. We hope that our initiative will bring about research that will facilitate the development of ML-based processing tools, and consequently increase access to digitized resources for the humanities.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_22",
            "content": "An example of an ML tool based on Chronicling America is described in (Lee et al., 2020). The task consisted in predicting bounding boxes around various types of visual content: photographs, illustrations, comics, editorial cartoons, maps, headlines and advertisements. The training set was crowdsourced and included over 48K bounding boxes for seven classes. Using a pre-trained Faster-RCNN detection object, the researchers achieved an average accuracy of 63.4%. Both the training set and the model weights file are publicly available. Still, it is difficult to estimate the value of the results achieved without any comparison with other models trained on the same data.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_23",
            "content": "In our proposal we go a step further. We provide and make available training data from Chronicling America for three ML tasks. For each task we develop and share baseline solutions. Alternative solutions can be submitted to an evaluation platform to be evaluated automatically and compares against the baselines.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_24",
            "content": "Similar Machine Learning datasets and challenges",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "426-ARR_v1_25",
            "content": "This section concerns ML challenges which deliver labeled OCR documents as training data, a definition of the processing task, and an evaluation environment to estimate the performance of uploaded solutions. More often than not, such challenges concern either layout recognition (localization of layout elements) or Key Information Extraction (finding, in a document, precisely specified business-actionable pieces of information). Layout recognition in Japanese historical texts is described in (Shen et al., 2020). The authors use deep learning-based approaches to detect seven types of layout element categories: Page Frame, Text Region, Text Row, Title Region, etc. Some Key Information Extraction tasks are presented in (Stanis\u0142awek et al., 2021). The two datasets described there contain, respectively, NDA documents and financial reports from charity organizations. The tasks for the datasets consist in detecting data points, such as effective dates, interested parties, charity address, income, spending. The authors provide several baseline solutions for the two tasks, which apply up-to-date methods, pointing out that there is still room for improvement in the KIE research area. A challenge that comprises both layout recognition and KIE is presented in (Huang et al., 2019) -the challenge is opened for the recognition of OCR-scanned receipts. In this competition (named ICDAR2019) three tasks are set up: Scanned Receipt Text Localization, Scanned Receipt OCR, and Key Information Extraction from Scanned Receipts. A common feature of the above-mentioned challenges is the goal of retrieving information that is explicit in the data (a text fragment or layout coordinates). Our tasks in ChallAm go a step further: the goal is to infer the information from the OCR image rather than just retrieve it.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_26",
            "content": "Similar challenges for two out of the three tasks introduced in this paper have been proposed before for the Polish language:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_27",
            "content": "\u2022 a challenge for temporal identification (Grali\u0144ski and Wierzcho\u0144, 2018); the challenge was based on a set of texts coming from Polish digital libraries, dated between the years 1814 and 2013; \u2022 a challenge for \"filling the gap\" (Retro-Gap) (Grali\u0144ski, 2017) with the same training set as above.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_28",
            "content": "The training sets for those challenges were purely textual. Here, we introduce the challenges with the addition of original images (clippings), though we do not use graphical features in baselines yet.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_29",
            "content": "Data processing",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "426-ARR_v1_30",
            "content": "The PDF files were downloaded from Chronicling America and processed using a pipeline primarily developed for extracting texts from Polish digital libraries (Grali\u0144ski, 2013(Grali\u0144ski, , 2019. Firstly, the metadata (including URL addresses for PDF files) were extracted by a custom web crawler and then normalized; for instance, titles were normalized using regular expressions (e.g. The Bismarck tribune.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_31",
            "content": "[volume], May 31, 1921 was normalized to THE BISMARCK TRIBUNE). Secondly, the PDF files were downloaded and the English texts were processed into DjVu files (as this is the target format for the pipeline) using the pdf2dvju tool 4 . The original OCR text layer was retained (the files were not re-OCRed, even though, in some cases, the quality of OCR was low). 1 shows a summary of the data obtained at each processing step. Two factors were responsible for the fact that not 100% of files were retained at each phase: (1) issues in the processing procedures (e.g. download failures due to random network problems or errors in the PDF-to-DjVu procedure that might be handled later); (2) some files are simply yet to be finally processed in the ongoing procedure.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_32",
            "content": "The procedure is executed in a continuous manner to allow the future processing of new files that are yet to be digitized and made public by the Chronicling America initiative. This solution requires a future-proof procedure for splitting and preparing data for machine-learning challenges. For instance, the assignment of documents to the training, development and test sets should not change when the raw data set is expanded. Such a procedure is described in Section 6.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_33",
            "content": "Data for unsupervised training",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "426-ARR_v1_34",
            "content": "The state of the art in most NLP tasks is obtained by training a neural-network language model on a large collection of texts in an unsupervised manner and fine-tuning the model on a given downstream task. At present, the most popular architectures for language models are Transformer (Devlin et al., 2018) models (earlier, e.g. Word2vec (Mikolov et al., 2013) or LSTM models (Peters et al., 2017)). The data on which such models are trained are almost always modern Internet texts. The high volume of texts available at Chronicling America, on the other hand, makes it possible to train large Transformer models for historical texts.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_35",
            "content": "Using a pre-trained language model on a downstream task bears the risk of data contamination -the model might have been trained on the task test set and this might give it an unfair edge (see (Brown et al., 2020) for a study of data contamination in the case of the GPT-3 model when used for popular English NLP test sets). This issue should be taken into account from the very beginning. In our case, we release a dump of all Chronicling America texts (for pre-training language models), but limited only to the 50% of texts that would be assigned to the training set (according to the MD5 hash). This dump contains all the texts, not just the excerpts described in Section 6.2. As the size of the dump is 74.0G characters, it is on par with the text material used to train, for instance, the GPT-2 model.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_36",
            "content": "We also release a RoBERTa Base ChallAm model trained on the text corpus. The model was trained from scratch, i.e. it was not based on the weights of the original RoBERTa model . The BPE dictionary was also induced anew.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_37",
            "content": "Two versions of the RoBERTa ChallAm model were prepared: one was trained with temporal metadata encoded as a prefix of the form year: YYYY, month: MM, day: DD, weekday: WD, another, for comparison, without such a prefix. The ChallAm models have the same numbers of parameters as the original RoBERTa Base (125M). Each model was trained on two Tesla V100 32GB GPUs for 9 days.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_38",
            "content": "Procedure for preparing challenges",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "426-ARR_v1_39",
            "content": "We created a pipeline that can generate various machine learning challenges. The pipeline input should consist of DjVu image files, text (OCR image), and metadata. Our main goals are to keep a clear distinction between dataset splits and to assure the reproducibility of the pipeline. This allows potential improvement to current challenges and the generation of new challenges without dataset leaks in the future. We achieved this by employing stable pseudo-randomness by calculating an MD5 hash on a given ID and taking the modulo remainder from integers from certain preset intervals. These pseudo-random assignments are not dependent on any library, platform, or programming language (using a fixed seed for the pseudo-random generator might not give the same guarantees as using MD5 hashes), so they are easy to reproduce. This procedure is crucial to make sure that challenges are future-proof, i.e.:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_40",
            "content": "\u2022 when the challenges are re-generated on the same Chronicling America files, exactly the same results are obtained (including text and image excerpts; see Section 6.2); \u2022 when the challenges are re-generated on a larger set of files (e.g. when new files are digitized for the Chronicling America project), the assignments of existing items to the train/dev/test sets will not change.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_41",
            "content": "Dataset structure",
            "ntype": "title",
            "meta": {
                "section": "6.1"
            }
        },
        {
            "ix": "426-ARR_v1_42",
            "content": "All three of our machine learning challenges consist of training (train), development (dev), and test sets. Each document in each set consists of excerpts from a newspaper edition. One newspaper edition provides a maximum of one excerpt. Excerpts in the datasets are available as both a cropped PNG file from the newspaper scan (a \"clipping\") and its OCR text. This makes it possible to employ image features in machine learning models (e.g. font features, paper quality). A solution might even disregard the existing OCR text layer and re-OCR the clipping or just employ an end-to-end model. (The OCR layer is given as it is, with no manual correction done -this is to simulate realistic conditions in which a downstream task is to be performed without a perfect text layer.) Sometimes additional metadata are given. For the train and dev datasets, we provide the expected data. For the test dataset, the expected data are not released. These data are used by the evaluation platform during submission evaluation. All newspaper and edition IDs are encoded to prevent participants from checking the newspaper edition in the Chronicling America database. The train and dev data may consist of all documents which meet our criteria for text excerpts, so the data may be unbalanced with respect to publishing years and locations. We tried to balance the test sets as regards the years of publication (the year-prediction and word-gap challenges) or locations (the geo-prediction challenge), though it is not always possible due to large imbalances in the original material.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_43",
            "content": "Selecting text excerpts",
            "ntype": "title",
            "meta": {
                "section": "6.2"
            }
        },
        {
            "ix": "426-ARR_v1_44",
            "content": "The details of the procedure for selection of text excerpts is given in Appendix A. A sample excerpt is shown in Figure 1a. Note that excerpts are selected using a stable pseudo-random procedure based on the newspaper edition ID (similarly to the way the train/dev/test split is done, see Section 6.3).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_45",
            "content": "Train/dev/test split",
            "ntype": "title",
            "meta": {
                "section": "6.3"
            }
        },
        {
            "ix": "426-ARR_v1_46",
            "content": "Each newspaper has its newspaper ID (i.e. normalized title, as described in Section ), and each newspaper edition has its newspaper edition ID. We separate newspapers within datasets, so for instance, if one newspaper edition is assigned to the dev set, all editions of that newspaper are assigned to the dev set. All challenges share common train and dev datasets and no challenges share the same test set. This prevents one from checking expected data from other challenges. The set splits are as follows: 50% for train, 10% for dev, 5% for each challenge test set. This makes it possible to generate eight challenges with different test sets. In other words, there is room for another five challenges in the future (again this is consistent with the \"future-proof\" principle of the whole endeavor).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_47",
            "content": "Challenging America tasks",
            "ntype": "title",
            "meta": {
                "section": "7"
            }
        },
        {
            "ix": "426-ARR_v1_48",
            "content": "In this section, we describe the three tasks defined in the challenge. They are released on an evaluation platform, which enables the calculation of metrics both offline and online, as well as the submission of solutions. An example of text from an excerpt given in those tasks is shown in Figure 1b.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_49",
            "content": "RetroTemp",
            "ntype": "title",
            "meta": {
                "section": "7.1"
            }
        },
        {
            "ix": "426-ARR_v1_50",
            "content": "This is a temporal classification task. Given a normalized newspaper title and a text excerpt, the task is to predict the publishing date. The date should be given in fractional year format (e.g. 1 June 1918 is represented as the number 1918.4137, and 31 December 1870 as 1870.9973).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_51",
            "content": "Hence, solutions to the challenge should predict the publication date with the greatest precision possible (i.e. day if possible). The fractional format will make it easy to accommodate even more precise timestamps, for example, if modern Internet texts (e.g. tweets) are to be added to the dataset.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_52",
            "content": "Due to the regression nature of the problem, the evaluation metric is RMSE (root mean square error).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_53",
            "content": "The motivation behind the RetroTemp challenge is to design tools that may help supplement the missing metadata for historical texts (the older the document, the more often it is not labeled with a time stamp). Even if all documents in a collection are time-stamped, such tools may be useful for finding errors and anomalies in metadata.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_54",
            "content": "RetroGeo",
            "ntype": "title",
            "meta": {
                "section": "7.2"
            }
        },
        {
            "ix": "426-ARR_v1_55",
            "content": "The task is to predict the place where the newspaper was published, given a normalized newspaper title, text excerpt, and publishing date in fractional year format. The expected format is a latitude and longitude. In the evaluation the distance on the sphere between output and expected data is calculated using the haversine formula, and the mean The motivation for the task (besides the supplementation of missing or wrong data) is to allow research on news propagation. Even if a news article is labeled with the localization of its issue, an automatic tool may infer that it was originally published somewhere else.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_56",
            "content": "RetroGap",
            "ntype": "title",
            "meta": {
                "section": "7.3"
            }
        },
        {
            "ix": "426-ARR_v1_57",
            "content": "This is a task for language modeling. The middle word of an excerpt is removed in the input document (in both text and image), and the task is to predict the removed word, given the normalized newspaper title, the text excerpt, and the publishing date in fractional year format (in other words, it is a cloze task). The output should contain a probability distribution for the removed word (not just a word or a single probability). The metric is perplexity; PerplexityHashed, to be precise, as implemented in the GEval evaluation tool , the modification is analogous to LogLossHashed in (Grali\u0144ski, 2017), its goal is to ensure proper evaluation in the competitive (shared-task) setup (i.e. avoid self-reported probabilities and ensure objective comparison of all reported solutions, including out-of-vocabulary words).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_58",
            "content": "Statistics",
            "ntype": "title",
            "meta": {
                "section": "7.4"
            }
        },
        {
            "ix": "426-ARR_v1_59",
            "content": "The data consists of the text excerpts written between the years 1798 and 1963. The mean publication year of the text excerpts is 1891. Excerpts between the years 1833 and 1925 make up about 96% of the data in the train set (cf. Figure 2a), but only 85% in the dev and test sets, which are more uniform (due to balancing described in Section 6.3, cf. Figure 2c). There are 432 000 excerpts in the train set, 10 500 in the dev set and 8 500 in the test set. These numbers are consistent across the challenges. The average excerpt length is 1 745 characters with 323.8 words, each one containing from 150 words up to 583 words.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_60",
            "content": "The length of each text in the excerpts seems to have a negative correlation with publication datethe later the text was published, the shorter snippet text (on average) it contains (see Figure 2b and 2d).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_61",
            "content": "Baselines",
            "ntype": "title",
            "meta": {
                "section": "8"
            }
        },
        {
            "ix": "426-ARR_v1_62",
            "content": "Baselines for all three tasks are available at the evaluation platform. 5 The baselines (see Tables 2 and 3) include, for each model, its score in the appropriate metric as well as the Git SHA1 reference code (in curly brackets). 6 We distinguish between self-contained submissions, which use only data provided in the task, and non-self-contained submissions, which use external data, e.g. publicly available pre-trained transform- More detailed analysis of the baseline performance is given in Appendix C. The current top performing models have the most difficulty with texts which (1) are older, (2) contain OCR noise, (3) come from less popular locations (especially, in the west).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_63",
            "content": "RetroTemp and RetroGeo",
            "ntype": "title",
            "meta": {
                "section": "8.1"
            }
        },
        {
            "ix": "426-ARR_v1_64",
            "content": "The baseline solutions for RetroTemp and Retro-Geo were prepared similarly. RetroGeo requires two values (latitude and longitude) -we treat them separately and train two separate models for them.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_65",
            "content": "For the self-contained models we provide the mean value from the train test, the linear regression based on TF-IDF and the BiLSTM (bidirectional long short-term memory) method.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_66",
            "content": "For non-self-contained submissions, we incorporate RoBERTa models released in two versions: base (125M params) and large (355M params). The output features are averaged, and the linear layer is added on top of this. Both RoBERTa and the linear layer were fine-tuned during training.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_67",
            "content": "The best self-contained models are BiLSTM submissions in both tasks. Non-self-contained submissions result in much higher scores than self-contained models. In both tasks, RoBERTa-large with linear layer provides better results than RoBERTa-base.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_68",
            "content": "For the RetroTemp challenge we also provide results obtained with the RoBERTa model pretrained from scratch (see Section 5). Even though the model without time-related prefix was used, the results are significantly better than the original RoBERTa Base: the confidence intervals obtained with bootstrap sampling are, respectively, 10.81\u00b10.21 and 12.10\u00b10.22 (single runs are reported).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_69",
            "content": "Hyperparameter setup is described in Appendix B.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_70",
            "content": "RetroGap",
            "ntype": "title",
            "meta": {
                "section": "8.2"
            }
        },
        {
            "ix": "426-ARR_v1_71",
            "content": "For non-self-contained submissions, we applied RoBERTa in base and large version without any fine-tuning. Since standard RoBERTa training does not incorporate any data, but text, we didn't include temporal metadata during inference.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_72",
            "content": "For self-contained submissions, we applied RoBERTa Challam base both in version with a date and without a date.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_73",
            "content": "RoBERTa ChallAm base with date is better than RoBERTa ChallAm base without date. This means the incorporation of temporal metadata has a positive impact on MLM task. Both self-contained submissions are better than the standard RoBERTa base, so our models trained on historical data per-",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_74",
            "content": "Ethical issues",
            "ntype": "title",
            "meta": {
                "section": "9"
            }
        },
        {
            "ix": "426-ARR_v1_75",
            "content": "We share the data from Chronicling America, following the statement of the Library of Congress: \"The Library of Congress believes that the newspapers in Chronicling America are in the public domain or have no known copyright restrictions.\" 7 Historical texts from American newspapers may be discriminatory, either explicitly or implicitly, particularly regarding race and gender. Recent years have seen research on the detection of discriminatory texts. In (Xia et al., 2020) adversarial training is used to mitigate racial bias. In (Field and Tsvetkov, 2020) the authors \"take an unsupervised approach to identifying gender bias against women at a comment level and present a model that can surface text likely to contain bias.\" The most recent experiments on the topic ( (Caselli et al., 2021), (Aluru et al., 2020) result in re-trained BERT models for abusive language detection in English. We use one of them, DeHateBERT (Aluru et al., 2020), to filter out the abusive texts in the ChallAm dataset. We filtered out items that either (1) are marked as abusive speech by DeHateBERT with the probability greater than 0.75 or (2) contain words from a list of blocked words. The fraction of filtered out texts was 2.04-2.40% (depending on the challenge and set).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_76",
            "content": "Conclusions",
            "ntype": "title",
            "meta": {
                "section": "10"
            }
        },
        {
            "ix": "426-ARR_v1_77",
            "content": "This paper has introduced a challenge based on OCR excerpts from the Chronicling America portal. The challenge consists of three tasks: guessing the publication date, guessing the publication location, and filling a gap with a word. We propose baseline solutions for all three tasks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_78",
            "content": "Chronicling America is an ongoing project, as we define our challenge in such a way that it can easily evolve in parallel with the development of Chronicling America. Firstly, any new materials appearing on the portal can be automatically incorporated into our challenge. Secondly, the challenge is open for five yet undefined ML tasks. A Procedure for selecting text excerpts",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_79",
            "content": "The OCR text follows the newspaper layout, which is defined by the following entities: page, column, line. Each entity has x 0 , y 0 , x 1 , y 1 coordinates of text in the DjVu document. Still, various errors may occur in the OCR newspaper layout (e.g. two columns may be split into one). We intend to select only excerpts which preserve the correct output.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_80",
            "content": "To this end, we select only excerpts that fulfill the following conditions:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_81",
            "content": "1. There are between 150 and 600 text tokens in the excerpt. The tokens are words separated by whitespaces.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_82",
            "content": "2. The y coordinates of each line are below the y coordinates of the previous line.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_83",
            "content": "3. The x 0 coordinate of each line does not differ by more than 15% from the x 0 coordinate of the previous line.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_84",
            "content": "4. The x 1 coordinate is not shifted to the right more than 15% from the x 1 coordinate of the previous line.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_85",
            "content": "If the newspaper edition contains no such excerpts, we reject it. If there is more than one such excerpt, we select one excerpt using a stable pseudo-random procedure based on the newspaper edition ID.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_86",
            "content": "This procedure produces text excerpts with images consisting of OCR texts only. The excerpts are downsized to reduce the size to an appropriate degree to maintain good quality. We do not pre-process images in any other way, so excerpts may have different sizes, height-to-width ratios, and colors.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_87",
            "content": "Hyperparameters were determined on the development set, training on a limited number of examples. In particular, for fine-tuning RoBERTa models the following hyperparameters were used:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_88",
            "content": "\u2022 optimizer: AdamW \u2022 learning rate: 0.000001 \u2022 batch size: 4 \u2022 early-stopping patience: 3 \u2022 warm-up steps: 10000",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_89",
            "content": "See Table 4 and 5 for the list of top 30 features correlating most with, respectively, the worst and bad results in ChallAm challenges (as returned by the GEval tool with the option -worst-features -numerical-features ). The features are tokens within the input (in:), expected output (exp:) and the actual output (out:), or numerical features such as high/low value (:=+/:=-) or length/shortness of a text (:+#/:-#).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_90",
            "content": "As can be seen the bottleneck for the current best model is due to:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_91",
            "content": "\u2022 old texts (:=-in RetroTemp), \u2022 OCR noise (cf. short words such ni, ol, j or punctuation marks likely to be introduced by OCR misrecognitions), \u2022 less popular publication locations (especially far west).",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_92",
            "content": "Obviously, year references (1902,1904) make it easy to guess the publication texts (in RetroTemp), whereas in RetroGap some non-content words such as the, and, of are easy to guess for the language model (even if their garbaged form, e.g. ot, ol, needs to be accounted for in the probability distribution).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "426-ARR_v1_93",
            "content": "UNKNOWN, None, 2020, Deep learning models for multilingual hate speech detection, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Deep learning models for multilingual hate speech detection",
                "pub": null
            }
        },
        {
            "ix": "426-ARR_v1_94",
            "content": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, None, , Ilya Sutskever, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Tom Brown",
                    "Benjamin Mann",
                    "Nick Ryder",
                    "Melanie Subbiah",
                    "Jared Kaplan",
                    "Prafulla Dhariwal",
                    "Arvind Neelakantan",
                    "Pranav Shyam",
                    "Girish Sastry",
                    "Amanda Askell",
                    "Sandhini Agarwal",
                    "Ariel Herbert-Voss",
                    "Gretchen Krueger",
                    "Tom Henighan",
                    "Rewon Child",
                    "Aditya Ramesh",
                    "Daniel Ziegler",
                    "Jeffrey Wu",
                    "Clemens Winter",
                    "Christopher Hesse",
                    "Mark Chen",
                    "Eric Sigler",
                    "Mateusz Litwin"
                ],
                "title": null,
                "pub_date": null,
                "pub_title": "Ilya Sutskever",
                "pub": null
            }
        },
        {
            "ix": "426-ARR_v1_95",
            "content": "UNKNOWN, None, 2021, HateBERT: Retraining BERT for abusive language detection in english, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "HateBERT: Retraining BERT for abusive language detection in english",
                "pub": null
            }
        },
        {
            "ix": "426-ARR_v1_96",
            "content": "UNKNOWN, None, 2019, Post-truth in social media, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Post-truth in social media",
                "pub": null
            }
        },
        {
            "ix": "426-ARR_v1_97",
            "content": "Maribeth Clark, A survey of online digital newspaper and genealogy archives: Resources, cost, and access, 2014, Journal of the Society for American Music, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Maribeth Clark"
                ],
                "title": "A survey of online digital newspaper and genealogy archives: Resources, cost, and access",
                "pub_date": "2014",
                "pub_title": "Journal of the Society for American Music",
                "pub": null
            }
        },
        {
            "ix": "426-ARR_v1_98",
            "content": "UNKNOWN, None, 2018, BERT: Pre-training of deep bidirectional transformers for language understanding, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "pub": null
            }
        },
        {
            "ix": "426-ARR_v1_99",
            "content": "UNKNOWN, None, 2021, Time-aware language models as temporal knowledge bases, .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Time-aware language models as temporal knowledge bases",
                "pub": null
            }
        },
        {
            "ix": "426-ARR_v1_100",
            "content": "UNKNOWN, None, 2018, Multi-input attention for unsupervised OCR correction, .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Multi-input attention for unsupervised OCR correction",
                "pub": null
            }
        },
        {
            "ix": "426-ARR_v1_101",
            "content": "UNKNOWN, None, 2004, Unsupervised discovery of implicit gender bias. CoRR, abs, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": null,
                "title": null,
                "pub_date": "2004",
                "pub_title": "Unsupervised discovery of implicit gender bias. CoRR, abs",
                "pub": null
            }
        },
        {
            "ix": "426-ARR_v1_102",
            "content": "Filip Grali\u0144ski, Piotr Wierzcho\u0144, RetroC-A Corpus for Evaluating Temporal Classifiers, 2015, Human Language Technology. Challenges for Computer Science and Linguistics. 7th Language and Technology Conference, Springer.",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Filip Grali\u0144ski",
                    "Piotr Wierzcho\u0144"
                ],
                "title": "RetroC-A Corpus for Evaluating Temporal Classifiers",
                "pub_date": "2015",
                "pub_title": "Human Language Technology. Challenges for Computer Science and Linguistics. 7th Language and Technology Conference",
                "pub": "Springer"
            }
        },
        {
            "ix": "426-ARR_v1_103",
            "content": "Filip Grali\u0144ski, Anna Wr\u00f3blewska, Tomasz Stanis\u0142awek, Kamil Grabowski, Tomasz G\u00f3recki, GEval: Tool for debugging NLP datasets and models, 2019, Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Filip Grali\u0144ski",
                    "Anna Wr\u00f3blewska",
                    "Tomasz Stanis\u0142awek",
                    "Kamil Grabowski",
                    "Tomasz G\u00f3recki"
                ],
                "title": "GEval: Tool for debugging NLP datasets and models",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "426-ARR_v1_104",
            "content": "Filip Grali\u0144ski, Polish digital libraries as a text corpus, 2013, Proceedings of 6th Language & Technology Conference, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Filip Grali\u0144ski"
                ],
                "title": "Polish digital libraries as a text corpus",
                "pub_date": "2013",
                "pub_title": "Proceedings of 6th Language & Technology Conference",
                "pub": null
            }
        },
        {
            "ix": "426-ARR_v1_105",
            "content": "Filip Grali\u0144ski, Temporal) language models as a competitive challenge, 2017, Proceedings of the 8th Language & Technology Conference, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Filip Grali\u0144ski"
                ],
                "title": "Temporal) language models as a competitive challenge",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 8th Language & Technology Conference",
                "pub": null
            }
        },
        {
            "ix": "426-ARR_v1_106",
            "content": "Filip Grali\u0144ski, Against the Arrow of Time. Theory and Practice of Mining Massive Corpora of Polish Historical Texts for Linguistic and Historical Research, 2019, Wydawnictwo Naukowe UAM, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    "Filip Grali\u0144ski"
                ],
                "title": "Against the Arrow of Time. Theory and Practice of Mining Massive Corpora of Polish Historical Texts for Linguistic and Historical Research",
                "pub_date": "2019",
                "pub_title": "Wydawnictwo Naukowe UAM",
                "pub": null
            }
        },
        {
            "ix": "426-ARR_v1_107",
            "content": "Zheng Huang, Kai Chen, Jianhua He, Xiang Bai, Dimosthenis Karatzas, Shijian Lu, C Jawahar, ICDAR2019 competition on scanned receipt OCR and information extraction, 2019, International Conference on Document Analysis and Recognition (ICDAR), .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Zheng Huang",
                    "Kai Chen",
                    "Jianhua He",
                    "Xiang Bai",
                    "Dimosthenis Karatzas",
                    "Shijian Lu",
                    "C Jawahar"
                ],
                "title": "ICDAR2019 competition on scanned receipt OCR and information extraction",
                "pub_date": "2019",
                "pub_title": "International Conference on Document Analysis and Recognition (ICDAR)",
                "pub": null
            }
        },
        {
            "ix": "426-ARR_v1_108",
            "content": "UNKNOWN, None, 2020, The newspaper navigator dataset: Extracting and analyzing visual content from 16 million historic newspaper pages in Chronicling America, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "The newspaper navigator dataset: Extracting and analyzing visual content from 16 million historic newspaper pages in Chronicling America",
                "pub": null
            }
        },
        {
            "ix": "426-ARR_v1_109",
            "content": "UNKNOWN, None, 2019, RoBERTa: A robustly optimized BERT pretraining approach, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "RoBERTa: A robustly optimized BERT pretraining approach",
                "pub": null
            }
        },
        {
            "ix": "426-ARR_v1_110",
            "content": "Jean-Baptiste Michel, Yuan Kui Shen, Aviva Presser Aiden, Adrian Veres, K Matthew,  Gray, P Joseph, Dale Pickett, Dan Hoiberg, Peter Clancy, Jon Norvig,  Orwant, Quantitative analysis of culture using millions of digitized books, 2011, science, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Jean-Baptiste Michel",
                    "Yuan Kui Shen",
                    "Aviva Presser Aiden",
                    "Adrian Veres",
                    "K Matthew",
                    " Gray",
                    "P Joseph",
                    "Dale Pickett",
                    "Dan Hoiberg",
                    "Peter Clancy",
                    "Jon Norvig",
                    " Orwant"
                ],
                "title": "Quantitative analysis of culture using millions of digitized books",
                "pub_date": "2011",
                "pub_title": "science",
                "pub": null
            }
        },
        {
            "ix": "426-ARR_v1_111",
            "content": "UNKNOWN, None, 2013, Efficient estimation of word representations in vector space, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": null,
                "title": null,
                "pub_date": "2013",
                "pub_title": "Efficient estimation of word representations in vector space",
                "pub": null
            }
        },
        {
            "ix": "426-ARR_v1_112",
            "content": "Thi-Tuyet-Hai Nguyen, Adam Jatowt, Mickael Coustaty, Antoine Nhu-Van Nguyen,  Doucet, Deep statistical analysis of OCR errors for effective post-OCR processing, 2019, Proceedings of the 18th Joint Conference on Digital Libraries, JCDL '19, IEEE Press.",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "Thi-Tuyet-Hai Nguyen",
                    "Adam Jatowt",
                    "Mickael Coustaty",
                    "Antoine Nhu-Van Nguyen",
                    " Doucet"
                ],
                "title": "Deep statistical analysis of OCR errors for effective post-OCR processing",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 18th Joint Conference on Digital Libraries, JCDL '19",
                "pub": "IEEE Press"
            }
        },
        {
            "ix": "426-ARR_v1_113",
            "content": "UNKNOWN, None, 2017, Semi-supervised sequence tagging with bidirectional language models, .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": "Semi-supervised sequence tagging with bidirectional language models",
                "pub": null
            }
        },
        {
            "ix": "426-ARR_v1_114",
            "content": "UNKNOWN, None, 2019, Exploring the limits of transfer learning with a unified text-to-text transformer, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
                "pub": null
            }
        },
        {
            "ix": "426-ARR_v1_115",
            "content": "UNKNOWN, None, 2021, Time masking for temporal language models, .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Time masking for temporal language models",
                "pub": null
            }
        },
        {
            "ix": "426-ARR_v1_116",
            "content": "UNKNOWN, None, 2004, A large dataset of historical Japanese documents with complex layouts. CoRR, abs, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": null,
                "title": null,
                "pub_date": "2004",
                "pub_title": "A large dataset of historical Japanese documents with complex layouts. CoRR, abs",
                "pub": null
            }
        },
        {
            "ix": "426-ARR_v1_117",
            "content": ", 487287 in<LeftContext>:i in<Text>:ol exp:31.760037 out:! in<Text>:cold exp:-81.772437 exp:; in<Text>:contemplate exp:24.562557 in<LeftContext>: * in<Text>:nI exp:-71.880373 in<RightContext>:l in<Text>:thee exp:44.814771 out, 1945-06, in<LeftContext>:e Table 5: Features highly correlating with good results RetroTemp RetroGeo RetroGap in<Text>:Democratic exp:44.007274 out:Of in<Text>:defeat exp:-80.85675 out:The in<Text>:Secretary exp:40.900892 out:ana in<Text>:notice exp:-77, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [],
                "title": "487287 in<LeftContext>:i in<Text>:ol exp:31.760037 out:! in<Text>:cold exp:-81.772437 exp:; in<Text>:contemplate exp:24.562557 in<LeftContext>: * in<Text>:nI exp:-71.880373 in<RightContext>:l in<Text>:thee exp:44.814771 out",
                "pub_date": "1945-06",
                "pub_title": "in<LeftContext>:e Table 5: Features highly correlating with good results RetroTemp RetroGeo RetroGap in<Text>:Democratic exp:44.007274 out:Of in<Text>:defeat exp:-80.85675 out:The in<Text>:Secretary exp:40.900892 out:ana in<Text>:notice exp:-77",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "426-ARR_v1_0@0",
            "content": "Challenging America: Modeling language in longer time scales",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_0",
            "start": 0,
            "end": 59,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_2@0",
            "content": "The aim of the paper is to apply, for historical texts, the methodology used commonly to solve various NLP tasks defined for contemporary data, i.e. pre-train and fine-tune large Transformer models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_2",
            "start": 0,
            "end": 197,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_2@1",
            "content": "This paper introduces an ML challenge, named Challenging America (Chal-lAm), based on OCR-ed excerpts from historical newspapers collected from the Chronicling America portal.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_2",
            "start": 199,
            "end": 373,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_2@2",
            "content": "ChallAm provides a dataset of clippings, labeled with metadata on their origin, and paired with their textual contents retrieved by an OCR tool.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_2",
            "start": 375,
            "end": 518,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_2@3",
            "content": "Three, publicly available, ML tasks are defined in the challenge: to determine the article date, to detect the location of the issue, and to deduce a word in a text gap (cloze test).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_2",
            "start": 520,
            "end": 701,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_2@4",
            "content": "Strong baselines are provided for all three ChallAm tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_2",
            "start": 703,
            "end": 760,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_2@5",
            "content": "In particular, we pretrained a RoBERTa model from scratch from the historical texts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_2",
            "start": 762,
            "end": 845,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_2@6",
            "content": "We also discuss the issues of discrimination and hate-speech present in the historical American texts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_2",
            "start": 847,
            "end": 948,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_4@0",
            "content": "The dominant approach in the design of current NLP solutions consists in (pre-)training a large neural language model, usually applying a Transformer architecture, such as GPT-2, RoBERTa or T5, and fine-tuning the model for specific tasks (Devlin et al., 2018;Raffel et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_4",
            "start": 0,
            "end": 280,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_4@1",
            "content": "The solutions are evaluated on benchmarks such as GLUE ((Wang et al., 2018)) or SuperGLUE ((Wang et al., 2019)), which allow comparing the performance of various methods designed for the same purpose.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_4",
            "start": 282,
            "end": 481,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_4@2",
            "content": "A main feature of a good NLP benchmark is the clear separation between train and test sets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_4",
            "start": 483,
            "end": 573,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_4@3",
            "content": "This requirement prevents data contamination, when the model (pre-)trained on huge data might have \"seen\" the test set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_4",
            "start": 575,
            "end": 693,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_5@0",
            "content": "The expansion of digital information is proceeding in two directions on the temporal axis.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_5",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_5@1",
            "content": "In the forward direction, new data are made publicly available on the Internet every second.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_5",
            "start": 91,
            "end": 182,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_5@2",
            "content": "What is less obvious is that, in the backward direction, older and older historical documents are digitized and disseminated publicly.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_5",
            "start": 184,
            "end": 317,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_6@0",
            "content": "To the best of our knowledge, our paper introduces the first benchmark which serves to use and evaluate the \"pre-train and fine-tune scenario\" applied to a massive collection of historical texts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_6",
            "start": 0,
            "end": 194,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_7@0",
            "content": "The very idea of building language models on historical data is not new.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_7",
            "start": 0,
            "end": 71,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_7@1",
            "content": "The Google Ngram Viewer (Michel et al., 2011) is based on large amounts of texts from digitized books.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_7",
            "start": 73,
            "end": 174,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_7@2",
            "content": "The corpus as a whole is not open for the NLP community -only raw n-gram statistics are available.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_7",
            "start": 176,
            "end": 273,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_7@3",
            "content": "The temporal information is crude (at best, the year of publication is given) and the corpus is heterogeneous (in fact, it is a dump of digitized books of any origin).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_7",
            "start": 275,
            "end": 441,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_8@0",
            "content": "In our research, we use one of the richest sources of homogeneous historical documents, Chronicling America, a collection of digitized newspapers that cover the publication period of over 300 years (with significant coverage of 150 years), and design an NLP benchmark that may open new opportunities for the modeling of the historical language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_8",
            "start": 0,
            "end": 343,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_9@0",
            "content": "Recently, time-aware language models such as Temporal T5 (Dhingra et al., 2021) and Tem-poBERT (Rosin et al., 2021) have been proposed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_9",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_9@1",
            "content": "They focus on modern texts dated yearly, whereas we extend language modeling towards both longer time scales and more fine-grained (daily) resolution, using massive amounts of historical texts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_9",
            "start": 136,
            "end": 328,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_10@0",
            "content": "The contribution of this paper is as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_10",
            "start": 0,
            "end": 44,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_11@0",
            "content": "\u2022 We extracted a large corpus of English historical texts that may serve to pre-train historical language models (Section 5).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_11",
            "start": 0,
            "end": 124,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_12@0",
            "content": "These are the main features of the corpus:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_12",
            "start": 0,
            "end": 41,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_13@0",
            "content": "the corpus size is 201 GB, which is comparable with contemporary text data for training massive language models, such as GPT-2, RoBERTa or T5; the corpus is free of spam and noisy data (although the quality of OCR processing varies); texts are dated with a daily resolution, hence a new dimension of time (on a fine-grained level) can be introduced into language modeling; the whole corpus is made publicly available;",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_13",
            "start": 0,
            "end": 416,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_14@0",
            "content": "\u2022 Based on selected excerpts from Chronicling America, we define a suite of challenges (named Challanging America, or ChallAm in short) with three ML tasks combining layout recognition, information extraction and semantic inference (Section 7). We hope that ChallAm will give rise to a historical equivalent of the GLUE (Wang et al., 2018) or Su-perGLUE (Wang et al., 2019) benchmarks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_14",
            "start": 0,
            "end": 384,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_15@0",
            "content": "-In particular, we provide a tool for the intrinsic evaluation of language models based on a word-gap task, which calculates the model perplexity in a comparative scenario (the tool may be used in competitive shared-tasks) (Section 7.3).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_15",
            "start": 0,
            "end": 236,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_16@0",
            "content": "\u2022 We propose a \"future-proof\" methodology for the creation of NLP challenges: a challenge is automatically updated whenever the underlying corpus is enriched (Section 6.3). \u2022 We introduce a method for data preparation that prevents data contamination (Section 6.3). \u2022 We train base Transformer (RoBERTa) models for historical texts (Section 5). The models are trained on texts spanning 100 years, dated with a daily resolution. \u2022 We provide strong baselines for three ChronAm challenges (Section 8). \u2022 We take under consideration the issue of discrimination and hate speech in the historical American texts. To this end we have applied up-to date methods to filter out the abusive content from the data (Section 9).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_16",
            "start": 0,
            "end": 714,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_17@0",
            "content": "Chronicling America",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_17",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_18@0",
            "content": "In 2005 a partnership between the National Endowment for the Humanities and the Library of Congress launched the National Digital Newspaper Program, to develop a database of digitized documents with easy access.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_18",
            "start": 0,
            "end": 210,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_18@1",
            "content": "The result of this 15-year effort is Chronicling America -a website 1 which provides access to selected digitized newspapers, published from 1690 to the present.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_18",
            "start": 212,
            "end": 372,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_18@2",
            "content": "The collection includes approximately 140 000 bibliographic title entries and 600 000 library holdings records, converted to the MARCXML format.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_18",
            "start": 374,
            "end": 517,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_18@3",
            "content": "The portal supports an API which allows accessing of the data in various ways, such as the JSON format, BulkData (bulk access to data) or Linked Data, 2 or searching of the database with the OpenSearch protocol.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_18",
            "start": 519,
            "end": 729,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_18@4",
            "content": "3 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_18",
            "start": 731,
            "end": 733,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_18@5",
            "content": "The accessibility of data in various forms makes Chronicling America a valuable source for the creation of datasets and benchmarks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_18",
            "start": 735,
            "end": 865,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_19@0",
            "content": "The portal serves as a resource for various research activities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_19",
            "start": 0,
            "end": 63,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_19@1",
            "content": "Cultural historians may track performances and events of their interest in a resource which is easily and openly accessible, as opposed to commercial databases or \"relatively small collections of cultural heritage organizations whose online resources are isolated and difficult to search\" (Clark, 2014).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_19",
            "start": 65,
            "end": 367,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_19@2",
            "content": "The database enables searching for the first historical usages of word terms.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_19",
            "start": 369,
            "end": 445,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_19@3",
            "content": "For instance, thanks to the Chronicling America portal, it was discovered in (Cibaroglu, 2019) that the term \"fake news\" was first used in 1889 in the Polish newspaper Ameryka.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_19",
            "start": 447,
            "end": 622,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_20@0",
            "content": "The resource is helpful in research aiming to improve the output of the OCR process.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_20",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_20@1",
            "content": "The authors of (Nguyen et al., 2019) study OCR errors occurring in several digital databases -including Chronicling America -and compare them with human-generated misspellings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_20",
            "start": 85,
            "end": 260,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_20@2",
            "content": "The research results in several suggestions for the design of OCR post-processing methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_20",
            "start": 262,
            "end": 351,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_20@3",
            "content": "The implementation of an unsupervised approach in the correction of OCR documents is described in (Dong and Smith, 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_20",
            "start": 353,
            "end": 473,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_20@4",
            "content": "Two million issues from the Chronicling America collection of historic U.S. newspapers are used in a sequence-to-sequence model with attention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_20",
            "start": 475,
            "end": 617,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_21@0",
            "content": "Chronicling America is a type of digitized resource that may be of wide use for both humanities and computational research.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_21",
            "start": 0,
            "end": 122,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_21@1",
            "content": "We prepared datasets and challenges based on the data from the Chronicling America resource.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_21",
            "start": 124,
            "end": 215,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_21@2",
            "content": "We hope that our initiative will bring about research that will facilitate the development of ML-based processing tools, and consequently increase access to digitized resources for the humanities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_21",
            "start": 217,
            "end": 412,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_22@0",
            "content": "An example of an ML tool based on Chronicling America is described in (Lee et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_22",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_22@1",
            "content": "The task consisted in predicting bounding boxes around various types of visual content: photographs, illustrations, comics, editorial cartoons, maps, headlines and advertisements.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_22",
            "start": 90,
            "end": 268,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_22@2",
            "content": "The training set was crowdsourced and included over 48K bounding boxes for seven classes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_22",
            "start": 270,
            "end": 358,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_22@3",
            "content": "Using a pre-trained Faster-RCNN detection object, the researchers achieved an average accuracy of 63.4%.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_22",
            "start": 360,
            "end": 463,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_22@4",
            "content": "Both the training set and the model weights file are publicly available.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_22",
            "start": 465,
            "end": 536,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_22@5",
            "content": "Still, it is difficult to estimate the value of the results achieved without any comparison with other models trained on the same data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_22",
            "start": 538,
            "end": 672,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_23@0",
            "content": "In our proposal we go a step further.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_23",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_23@1",
            "content": "We provide and make available training data from Chronicling America for three ML tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_23",
            "start": 38,
            "end": 125,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_23@2",
            "content": "For each task we develop and share baseline solutions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_23",
            "start": 127,
            "end": 180,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_23@3",
            "content": "Alternative solutions can be submitted to an evaluation platform to be evaluated automatically and compares against the baselines.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_23",
            "start": 182,
            "end": 311,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_24@0",
            "content": "Similar Machine Learning datasets and challenges",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_24",
            "start": 0,
            "end": 47,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_25@0",
            "content": "This section concerns ML challenges which deliver labeled OCR documents as training data, a definition of the processing task, and an evaluation environment to estimate the performance of uploaded solutions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_25",
            "start": 0,
            "end": 206,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_25@1",
            "content": "More often than not, such challenges concern either layout recognition (localization of layout elements) or Key Information Extraction (finding, in a document, precisely specified business-actionable pieces of information).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_25",
            "start": 208,
            "end": 430,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_25@2",
            "content": "Layout recognition in Japanese historical texts is described in (Shen et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_25",
            "start": 432,
            "end": 515,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_25@3",
            "content": "The authors use deep learning-based approaches to detect seven types of layout element categories: Page Frame, Text Region, Text Row, Title Region, etc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_25",
            "start": 517,
            "end": 668,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_25@4",
            "content": "Some Key Information Extraction tasks are presented in (Stanis\u0142awek et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_25",
            "start": 670,
            "end": 751,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_25@5",
            "content": "The two datasets described there contain, respectively, NDA documents and financial reports from charity organizations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_25",
            "start": 753,
            "end": 871,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_25@6",
            "content": "The tasks for the datasets consist in detecting data points, such as effective dates, interested parties, charity address, income, spending.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_25",
            "start": 873,
            "end": 1012,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_25@7",
            "content": "The authors provide several baseline solutions for the two tasks, which apply up-to-date methods, pointing out that there is still room for improvement in the KIE research area.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_25",
            "start": 1014,
            "end": 1190,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_25@8",
            "content": "A challenge that comprises both layout recognition and KIE is presented in (Huang et al., 2019) -the challenge is opened for the recognition of OCR-scanned receipts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_25",
            "start": 1192,
            "end": 1356,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_25@9",
            "content": "In this competition (named ICDAR2019) three tasks are set up: Scanned Receipt Text Localization, Scanned Receipt OCR, and Key Information Extraction from Scanned Receipts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_25",
            "start": 1358,
            "end": 1528,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_25@10",
            "content": "A common feature of the above-mentioned challenges is the goal of retrieving information that is explicit in the data (a text fragment or layout coordinates).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_25",
            "start": 1530,
            "end": 1687,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_25@11",
            "content": "Our tasks in ChallAm go a step further: the goal is to infer the information from the OCR image rather than just retrieve it.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_25",
            "start": 1689,
            "end": 1813,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_26@0",
            "content": "Similar challenges for two out of the three tasks introduced in this paper have been proposed before for the Polish language:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_26",
            "start": 0,
            "end": 124,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_27@0",
            "content": "\u2022 a challenge for temporal identification (Grali\u0144ski and Wierzcho\u0144, 2018); the challenge was based on a set of texts coming from Polish digital libraries, dated between the years 1814 and 2013; \u2022 a challenge for \"filling the gap\" (Retro-Gap) (Grali\u0144ski, 2017) with the same training set as above.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_27",
            "start": 0,
            "end": 295,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_28@0",
            "content": "The training sets for those challenges were purely textual.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_28",
            "start": 0,
            "end": 58,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_28@1",
            "content": "Here, we introduce the challenges with the addition of original images (clippings), though we do not use graphical features in baselines yet.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_28",
            "start": 60,
            "end": 200,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_29@0",
            "content": "Data processing",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_29",
            "start": 0,
            "end": 14,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_30@0",
            "content": "The PDF files were downloaded from Chronicling America and processed using a pipeline primarily developed for extracting texts from Polish digital libraries (Grali\u0144ski, 2013(Grali\u0144ski, , 2019.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_30",
            "start": 0,
            "end": 191,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_30@1",
            "content": "Firstly, the metadata (including URL addresses for PDF files) were extracted by a custom web crawler and then normalized; for instance, titles were normalized using regular expressions (e.g. The Bismarck tribune.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_30",
            "start": 193,
            "end": 404,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_31@0",
            "content": "[volume], May 31, 1921 was normalized to THE BISMARCK TRIBUNE).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_31",
            "start": 0,
            "end": 62,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_31@1",
            "content": "Secondly, the PDF files were downloaded and the English texts were processed into DjVu files (as this is the target format for the pipeline) using the pdf2dvju tool 4 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_31",
            "start": 64,
            "end": 231,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_31@2",
            "content": "The original OCR text layer was retained (the files were not re-OCRed, even though, in some cases, the quality of OCR was low).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_31",
            "start": 233,
            "end": 359,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_31@3",
            "content": "1 shows a summary of the data obtained at each processing step.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_31",
            "start": 361,
            "end": 423,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_31@4",
            "content": "Two factors were responsible for the fact that not 100% of files were retained at each phase: (1) issues in the processing procedures (e.g. download failures due to random network problems or errors in the PDF-to-DjVu procedure that might be handled later); (2) some files are simply yet to be finally processed in the ongoing procedure.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_31",
            "start": 425,
            "end": 761,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_32@0",
            "content": "The procedure is executed in a continuous manner to allow the future processing of new files that are yet to be digitized and made public by the Chronicling America initiative.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_32",
            "start": 0,
            "end": 175,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_32@1",
            "content": "This solution requires a future-proof procedure for splitting and preparing data for machine-learning challenges.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_32",
            "start": 177,
            "end": 289,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_32@2",
            "content": "For instance, the assignment of documents to the training, development and test sets should not change when the raw data set is expanded.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_32",
            "start": 291,
            "end": 427,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_32@3",
            "content": "Such a procedure is described in Section 6.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_32",
            "start": 429,
            "end": 471,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_33@0",
            "content": "Data for unsupervised training",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_33",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_34@0",
            "content": "The state of the art in most NLP tasks is obtained by training a neural-network language model on a large collection of texts in an unsupervised manner and fine-tuning the model on a given downstream task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_34",
            "start": 0,
            "end": 204,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_34@1",
            "content": "At present, the most popular architectures for language models are Transformer (Devlin et al., 2018) models (earlier, e.g. Word2vec (Mikolov et al., 2013) or LSTM models (Peters et al., 2017)).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_34",
            "start": 206,
            "end": 398,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_34@2",
            "content": "The data on which such models are trained are almost always modern Internet texts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_34",
            "start": 400,
            "end": 481,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_34@3",
            "content": "The high volume of texts available at Chronicling America, on the other hand, makes it possible to train large Transformer models for historical texts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_34",
            "start": 483,
            "end": 633,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_35@0",
            "content": "Using a pre-trained language model on a downstream task bears the risk of data contamination -the model might have been trained on the task test set and this might give it an unfair edge (see (Brown et al., 2020) for a study of data contamination in the case of the GPT-3 model when used for popular English NLP test sets).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_35",
            "start": 0,
            "end": 322,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_35@1",
            "content": "This issue should be taken into account from the very beginning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_35",
            "start": 324,
            "end": 387,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_35@2",
            "content": "In our case, we release a dump of all Chronicling America texts (for pre-training language models), but limited only to the 50% of texts that would be assigned to the training set (according to the MD5 hash).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_35",
            "start": 389,
            "end": 596,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_35@3",
            "content": "This dump contains all the texts, not just the excerpts described in Section 6.2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_35",
            "start": 598,
            "end": 678,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_35@4",
            "content": "As the size of the dump is 74.0G characters, it is on par with the text material used to train, for instance, the GPT-2 model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_35",
            "start": 680,
            "end": 805,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_36@0",
            "content": "We also release a RoBERTa Base ChallAm model trained on the text corpus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_36",
            "start": 0,
            "end": 71,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_36@1",
            "content": "The model was trained from scratch, i.e. it was not based on the weights of the original RoBERTa model .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_36",
            "start": 73,
            "end": 176,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_36@2",
            "content": "The BPE dictionary was also induced anew.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_36",
            "start": 178,
            "end": 218,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_37@0",
            "content": "Two versions of the RoBERTa ChallAm model were prepared: one was trained with temporal metadata encoded as a prefix of the form year: YYYY, month: MM, day: DD, weekday: WD, another, for comparison, without such a prefix.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_37",
            "start": 0,
            "end": 219,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_37@1",
            "content": "The ChallAm models have the same numbers of parameters as the original RoBERTa Base (125M).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_37",
            "start": 221,
            "end": 311,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_37@2",
            "content": "Each model was trained on two Tesla V100 32GB GPUs for 9 days.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_37",
            "start": 313,
            "end": 374,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_38@0",
            "content": "Procedure for preparing challenges",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_38",
            "start": 0,
            "end": 33,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_39@0",
            "content": "We created a pipeline that can generate various machine learning challenges.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_39",
            "start": 0,
            "end": 75,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_39@1",
            "content": "The pipeline input should consist of DjVu image files, text (OCR image), and metadata.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_39",
            "start": 77,
            "end": 162,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_39@2",
            "content": "Our main goals are to keep a clear distinction between dataset splits and to assure the reproducibility of the pipeline.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_39",
            "start": 164,
            "end": 283,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_39@3",
            "content": "This allows potential improvement to current challenges and the generation of new challenges without dataset leaks in the future.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_39",
            "start": 285,
            "end": 413,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_39@4",
            "content": "We achieved this by employing stable pseudo-randomness by calculating an MD5 hash on a given ID and taking the modulo remainder from integers from certain preset intervals.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_39",
            "start": 415,
            "end": 586,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_39@5",
            "content": "These pseudo-random assignments are not dependent on any library, platform, or programming language (using a fixed seed for the pseudo-random generator might not give the same guarantees as using MD5 hashes), so they are easy to reproduce.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_39",
            "start": 588,
            "end": 826,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_39@6",
            "content": "This procedure is crucial to make sure that challenges are future-proof, i.e.:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_39",
            "start": 828,
            "end": 905,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_40@0",
            "content": "\u2022 when the challenges are re-generated on the same Chronicling America files, exactly the same results are obtained (including text and image excerpts; see Section 6.2); \u2022 when the challenges are re-generated on a larger set of files (e.g. when new files are digitized for the Chronicling America project), the assignments of existing items to the train/dev/test sets will not change.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_40",
            "start": 0,
            "end": 383,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_41@0",
            "content": "Dataset structure",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_41",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_42@0",
            "content": "All three of our machine learning challenges consist of training (train), development (dev), and test sets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_42",
            "start": 0,
            "end": 106,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_42@1",
            "content": "Each document in each set consists of excerpts from a newspaper edition.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_42",
            "start": 108,
            "end": 179,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_42@2",
            "content": "One newspaper edition provides a maximum of one excerpt.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_42",
            "start": 181,
            "end": 236,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_42@3",
            "content": "Excerpts in the datasets are available as both a cropped PNG file from the newspaper scan (a \"clipping\") and its OCR text.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_42",
            "start": 238,
            "end": 359,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_42@4",
            "content": "This makes it possible to employ image features in machine learning models (e.g. font features, paper quality).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_42",
            "start": 361,
            "end": 471,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_42@5",
            "content": "A solution might even disregard the existing OCR text layer and re-OCR the clipping or just employ an end-to-end model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_42",
            "start": 473,
            "end": 591,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_42@6",
            "content": "(The OCR layer is given as it is, with no manual correction done -this is to simulate realistic conditions in which a downstream task is to be performed without a perfect text layer.)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_42",
            "start": 593,
            "end": 775,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_42@7",
            "content": "Sometimes additional metadata are given.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_42",
            "start": 777,
            "end": 816,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_42@8",
            "content": "For the train and dev datasets, we provide the expected data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_42",
            "start": 818,
            "end": 878,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_42@9",
            "content": "For the test dataset, the expected data are not released.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_42",
            "start": 880,
            "end": 936,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_42@10",
            "content": "These data are used by the evaluation platform during submission evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_42",
            "start": 938,
            "end": 1013,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_42@11",
            "content": "All newspaper and edition IDs are encoded to prevent participants from checking the newspaper edition in the Chronicling America database.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_42",
            "start": 1015,
            "end": 1152,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_42@12",
            "content": "The train and dev data may consist of all documents which meet our criteria for text excerpts, so the data may be unbalanced with respect to publishing years and locations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_42",
            "start": 1154,
            "end": 1325,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_42@13",
            "content": "We tried to balance the test sets as regards the years of publication (the year-prediction and word-gap challenges) or locations (the geo-prediction challenge), though it is not always possible due to large imbalances in the original material.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_42",
            "start": 1327,
            "end": 1569,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_43@0",
            "content": "Selecting text excerpts",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_43",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_44@0",
            "content": "The details of the procedure for selection of text excerpts is given in Appendix A. A sample excerpt is shown in Figure 1a.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_44",
            "start": 0,
            "end": 122,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_44@1",
            "content": "Note that excerpts are selected using a stable pseudo-random procedure based on the newspaper edition ID (similarly to the way the train/dev/test split is done, see Section 6.3).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_44",
            "start": 124,
            "end": 301,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_45@0",
            "content": "Train/dev/test split",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_45",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_46@0",
            "content": "Each newspaper has its newspaper ID (i.e. normalized title, as described in Section ), and each newspaper edition has its newspaper edition ID.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_46",
            "start": 0,
            "end": 142,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_46@1",
            "content": "We separate newspapers within datasets, so for instance, if one newspaper edition is assigned to the dev set, all editions of that newspaper are assigned to the dev set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_46",
            "start": 144,
            "end": 312,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_46@2",
            "content": "All challenges share common train and dev datasets and no challenges share the same test set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_46",
            "start": 314,
            "end": 406,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_46@3",
            "content": "This prevents one from checking expected data from other challenges.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_46",
            "start": 408,
            "end": 475,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_46@4",
            "content": "The set splits are as follows: 50% for train, 10% for dev, 5% for each challenge test set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_46",
            "start": 477,
            "end": 566,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_46@5",
            "content": "This makes it possible to generate eight challenges with different test sets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_46",
            "start": 568,
            "end": 644,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_46@6",
            "content": "In other words, there is room for another five challenges in the future (again this is consistent with the \"future-proof\" principle of the whole endeavor).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_46",
            "start": 646,
            "end": 800,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_47@0",
            "content": "Challenging America tasks",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_47",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_48@0",
            "content": "In this section, we describe the three tasks defined in the challenge.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_48",
            "start": 0,
            "end": 69,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_48@1",
            "content": "They are released on an evaluation platform, which enables the calculation of metrics both offline and online, as well as the submission of solutions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_48",
            "start": 71,
            "end": 220,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_48@2",
            "content": "An example of text from an excerpt given in those tasks is shown in Figure 1b.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_48",
            "start": 222,
            "end": 299,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_49@0",
            "content": "RetroTemp",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_49",
            "start": 0,
            "end": 8,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_50@0",
            "content": "This is a temporal classification task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_50",
            "start": 0,
            "end": 38,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_50@1",
            "content": "Given a normalized newspaper title and a text excerpt, the task is to predict the publishing date.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_50",
            "start": 40,
            "end": 137,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_50@2",
            "content": "The date should be given in fractional year format (e.g. 1 June 1918 is represented as the number 1918.4137, and 31 December 1870 as 1870.9973).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_50",
            "start": 139,
            "end": 282,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_51@0",
            "content": "Hence, solutions to the challenge should predict the publication date with the greatest precision possible (i.e. day if possible).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_51",
            "start": 0,
            "end": 129,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_51@1",
            "content": "The fractional format will make it easy to accommodate even more precise timestamps, for example, if modern Internet texts (e.g. tweets) are to be added to the dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_51",
            "start": 131,
            "end": 298,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_52@0",
            "content": "Due to the regression nature of the problem, the evaluation metric is RMSE (root mean square error).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_52",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_53@0",
            "content": "The motivation behind the RetroTemp challenge is to design tools that may help supplement the missing metadata for historical texts (the older the document, the more often it is not labeled with a time stamp).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_53",
            "start": 0,
            "end": 208,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_53@1",
            "content": "Even if all documents in a collection are time-stamped, such tools may be useful for finding errors and anomalies in metadata.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_53",
            "start": 210,
            "end": 335,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_54@0",
            "content": "RetroGeo",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_54",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_55@0",
            "content": "The task is to predict the place where the newspaper was published, given a normalized newspaper title, text excerpt, and publishing date in fractional year format.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_55",
            "start": 0,
            "end": 163,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_55@1",
            "content": "The expected format is a latitude and longitude.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_55",
            "start": 165,
            "end": 212,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_55@2",
            "content": "In the evaluation the distance on the sphere between output and expected data is calculated using the haversine formula, and the mean The motivation for the task (besides the supplementation of missing or wrong data) is to allow research on news propagation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_55",
            "start": 214,
            "end": 471,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_55@3",
            "content": "Even if a news article is labeled with the localization of its issue, an automatic tool may infer that it was originally published somewhere else.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_55",
            "start": 473,
            "end": 618,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_56@0",
            "content": "RetroGap",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_56",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_57@0",
            "content": "This is a task for language modeling.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_57",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_57@1",
            "content": "The middle word of an excerpt is removed in the input document (in both text and image), and the task is to predict the removed word, given the normalized newspaper title, the text excerpt, and the publishing date in fractional year format (in other words, it is a cloze task).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_57",
            "start": 38,
            "end": 314,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_57@2",
            "content": "The output should contain a probability distribution for the removed word (not just a word or a single probability).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_57",
            "start": 316,
            "end": 431,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_57@3",
            "content": "The metric is perplexity; PerplexityHashed, to be precise, as implemented in the GEval evaluation tool , the modification is analogous to LogLossHashed in (Grali\u0144ski, 2017), its goal is to ensure proper evaluation in the competitive (shared-task) setup (i.e. avoid self-reported probabilities and ensure objective comparison of all reported solutions, including out-of-vocabulary words).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_57",
            "start": 433,
            "end": 819,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_58@0",
            "content": "Statistics",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_58",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_59@0",
            "content": "The data consists of the text excerpts written between the years 1798 and 1963.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_59",
            "start": 0,
            "end": 78,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_59@1",
            "content": "The mean publication year of the text excerpts is 1891.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_59",
            "start": 80,
            "end": 134,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_59@2",
            "content": "Excerpts between the years 1833 and 1925 make up about 96% of the data in the train set (cf. Figure 2a), but only 85% in the dev and test sets, which are more uniform (due to balancing described in Section 6.3, cf. Figure 2c).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_59",
            "start": 136,
            "end": 361,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_59@3",
            "content": "There are 432 000 excerpts in the train set, 10 500 in the dev set and 8 500 in the test set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_59",
            "start": 363,
            "end": 455,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_59@4",
            "content": "These numbers are consistent across the challenges.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_59",
            "start": 457,
            "end": 507,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_59@5",
            "content": "The average excerpt length is 1 745 characters with 323.8 words, each one containing from 150 words up to 583 words.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_59",
            "start": 509,
            "end": 624,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_60@0",
            "content": "The length of each text in the excerpts seems to have a negative correlation with publication datethe later the text was published, the shorter snippet text (on average) it contains (see Figure 2b and 2d).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_60",
            "start": 0,
            "end": 204,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_61@0",
            "content": "Baselines",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_61",
            "start": 0,
            "end": 8,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_62@0",
            "content": "Baselines for all three tasks are available at the evaluation platform.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_62",
            "start": 0,
            "end": 70,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_62@1",
            "content": "5 The baselines (see Tables 2 and 3) include, for each model, its score in the appropriate metric as well as the Git SHA1 reference code (in curly brackets).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_62",
            "start": 72,
            "end": 228,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_62@2",
            "content": "6 We distinguish between self-contained submissions, which use only data provided in the task, and non-self-contained submissions, which use external data, e.g. publicly available pre-trained transform- More detailed analysis of the baseline performance is given in Appendix C. The current top performing models have the most difficulty with texts which (1) are older, (2) contain OCR noise, (3) come from less popular locations (especially, in the west).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_62",
            "start": 230,
            "end": 684,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_63@0",
            "content": "RetroTemp and RetroGeo",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_63",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_64@0",
            "content": "The baseline solutions for RetroTemp and Retro-Geo were prepared similarly.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_64",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_64@1",
            "content": "RetroGeo requires two values (latitude and longitude) -we treat them separately and train two separate models for them.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_64",
            "start": 76,
            "end": 194,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_65@0",
            "content": "For the self-contained models we provide the mean value from the train test, the linear regression based on TF-IDF and the BiLSTM (bidirectional long short-term memory) method.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_65",
            "start": 0,
            "end": 175,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_66@0",
            "content": "For non-self-contained submissions, we incorporate RoBERTa models released in two versions: base (125M params) and large (355M params).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_66",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_66@1",
            "content": "The output features are averaged, and the linear layer is added on top of this.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_66",
            "start": 136,
            "end": 214,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_66@2",
            "content": "Both RoBERTa and the linear layer were fine-tuned during training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_66",
            "start": 216,
            "end": 281,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_67@0",
            "content": "The best self-contained models are BiLSTM submissions in both tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_67",
            "start": 0,
            "end": 67,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_67@1",
            "content": "Non-self-contained submissions result in much higher scores than self-contained models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_67",
            "start": 69,
            "end": 155,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_67@2",
            "content": "In both tasks, RoBERTa-large with linear layer provides better results than RoBERTa-base.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_67",
            "start": 157,
            "end": 245,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_68@0",
            "content": "For the RetroTemp challenge we also provide results obtained with the RoBERTa model pretrained from scratch (see Section 5).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_68",
            "start": 0,
            "end": 123,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_68@1",
            "content": "Even though the model without time-related prefix was used, the results are significantly better than the original RoBERTa Base: the confidence intervals obtained with bootstrap sampling are, respectively, 10.81\u00b10.21 and 12.10\u00b10.22 (single runs are reported).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_68",
            "start": 125,
            "end": 383,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_69@0",
            "content": "Hyperparameter setup is described in Appendix B.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_69",
            "start": 0,
            "end": 47,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_70@0",
            "content": "RetroGap",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_70",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_71@0",
            "content": "For non-self-contained submissions, we applied RoBERTa in base and large version without any fine-tuning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_71",
            "start": 0,
            "end": 104,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_71@1",
            "content": "Since standard RoBERTa training does not incorporate any data, but text, we didn't include temporal metadata during inference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_71",
            "start": 106,
            "end": 231,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_72@0",
            "content": "For self-contained submissions, we applied RoBERTa Challam base both in version with a date and without a date.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_72",
            "start": 0,
            "end": 110,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_73@0",
            "content": "RoBERTa ChallAm base with date is better than RoBERTa ChallAm base without date.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_73",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_73@1",
            "content": "This means the incorporation of temporal metadata has a positive impact on MLM task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_73",
            "start": 81,
            "end": 164,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_73@2",
            "content": "Both self-contained submissions are better than the standard RoBERTa base, so our models trained on historical data per-",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_73",
            "start": 166,
            "end": 285,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_74@0",
            "content": "Ethical issues",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_74",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_75@0",
            "content": "We share the data from Chronicling America, following the statement of the Library of Congress: \"The Library of Congress believes that the newspapers in Chronicling America are in the public domain or have no known copyright restrictions.\" 7 Historical texts from American newspapers may be discriminatory, either explicitly or implicitly, particularly regarding race and gender.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_75",
            "start": 0,
            "end": 378,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_75@1",
            "content": "Recent years have seen research on the detection of discriminatory texts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_75",
            "start": 380,
            "end": 452,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_75@2",
            "content": "In (Xia et al., 2020) adversarial training is used to mitigate racial bias.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_75",
            "start": 454,
            "end": 528,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_75@3",
            "content": "In (Field and Tsvetkov, 2020) the authors \"take an unsupervised approach to identifying gender bias against women at a comment level and present a model that can surface text likely to contain bias.\"",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_75",
            "start": 530,
            "end": 728,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_75@4",
            "content": "The most recent experiments on the topic ( (Caselli et al., 2021), (Aluru et al., 2020) result in re-trained BERT models for abusive language detection in English.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_75",
            "start": 730,
            "end": 892,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_75@5",
            "content": "We use one of them, DeHateBERT (Aluru et al., 2020), to filter out the abusive texts in the ChallAm dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_75",
            "start": 894,
            "end": 1001,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_75@6",
            "content": "We filtered out items that either (1) are marked as abusive speech by DeHateBERT with the probability greater than 0.75 or (2) contain words from a list of blocked words.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_75",
            "start": 1003,
            "end": 1172,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_75@7",
            "content": "The fraction of filtered out texts was 2.04-2.40% (depending on the challenge and set).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_75",
            "start": 1174,
            "end": 1260,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_76@0",
            "content": "Conclusions",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_76",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_77@0",
            "content": "This paper has introduced a challenge based on OCR excerpts from the Chronicling America portal.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_77",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_77@1",
            "content": "The challenge consists of three tasks: guessing the publication date, guessing the publication location, and filling a gap with a word.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_77",
            "start": 97,
            "end": 231,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_77@2",
            "content": "We propose baseline solutions for all three tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_77",
            "start": 233,
            "end": 282,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_78@0",
            "content": "Chronicling America is an ongoing project, as we define our challenge in such a way that it can easily evolve in parallel with the development of Chronicling America.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_78",
            "start": 0,
            "end": 165,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_78@1",
            "content": "Firstly, any new materials appearing on the portal can be automatically incorporated into our challenge.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_78",
            "start": 167,
            "end": 270,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_78@2",
            "content": "Secondly, the challenge is open for five yet undefined ML tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_78",
            "start": 272,
            "end": 335,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_78@3",
            "content": "A Procedure for selecting text excerpts",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_78",
            "start": 337,
            "end": 375,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_79@0",
            "content": "The OCR text follows the newspaper layout, which is defined by the following entities: page, column, line.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_79",
            "start": 0,
            "end": 105,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_79@1",
            "content": "Each entity has x 0 , y 0 , x 1 , y 1 coordinates of text in the DjVu document.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_79",
            "start": 107,
            "end": 185,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_79@2",
            "content": "Still, various errors may occur in the OCR newspaper layout (e.g. two columns may be split into one).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_79",
            "start": 187,
            "end": 287,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_79@3",
            "content": "We intend to select only excerpts which preserve the correct output.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_79",
            "start": 289,
            "end": 356,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_80@0",
            "content": "To this end, we select only excerpts that fulfill the following conditions:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_80",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_81@0",
            "content": "1. There are between 150 and 600 text tokens in the excerpt.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_81",
            "start": 0,
            "end": 59,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_81@1",
            "content": "The tokens are words separated by whitespaces.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_81",
            "start": 61,
            "end": 106,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_82@0",
            "content": "2. The y coordinates of each line are below the y coordinates of the previous line.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_82",
            "start": 0,
            "end": 82,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_83@0",
            "content": "3. The x 0 coordinate of each line does not differ by more than 15% from the x 0 coordinate of the previous line.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_83",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_84@0",
            "content": "4. The x 1 coordinate is not shifted to the right more than 15% from the x 1 coordinate of the previous line.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_84",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_85@0",
            "content": "If the newspaper edition contains no such excerpts, we reject it.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_85",
            "start": 0,
            "end": 64,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_85@1",
            "content": "If there is more than one such excerpt, we select one excerpt using a stable pseudo-random procedure based on the newspaper edition ID.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_85",
            "start": 66,
            "end": 200,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_86@0",
            "content": "This procedure produces text excerpts with images consisting of OCR texts only.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_86",
            "start": 0,
            "end": 78,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_86@1",
            "content": "The excerpts are downsized to reduce the size to an appropriate degree to maintain good quality.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_86",
            "start": 80,
            "end": 175,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_86@2",
            "content": "We do not pre-process images in any other way, so excerpts may have different sizes, height-to-width ratios, and colors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_86",
            "start": 177,
            "end": 296,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_87@0",
            "content": "Hyperparameters were determined on the development set, training on a limited number of examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_87",
            "start": 0,
            "end": 96,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_87@1",
            "content": "In particular, for fine-tuning RoBERTa models the following hyperparameters were used:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_87",
            "start": 98,
            "end": 183,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_88@0",
            "content": "\u2022 optimizer: AdamW \u2022 learning rate: 0.000001 \u2022 batch size: 4 \u2022 early-stopping patience: 3 \u2022 warm-up steps: 10000",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_88",
            "start": 0,
            "end": 111,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_89@0",
            "content": "See Table 4 and 5 for the list of top 30 features correlating most with, respectively, the worst and bad results in ChallAm challenges (as returned by the GEval tool with the option -worst-features -numerical-features ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_89",
            "start": 0,
            "end": 219,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_89@1",
            "content": "The features are tokens within the input (in:), expected output (exp:) and the actual output (out:), or numerical features such as high/low value (:=+/:=-) or length/shortness of a text (:+#/:-#).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_89",
            "start": 221,
            "end": 416,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_90@0",
            "content": "As can be seen the bottleneck for the current best model is due to:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_90",
            "start": 0,
            "end": 66,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_91@0",
            "content": "\u2022 old texts (:=-in RetroTemp), \u2022 OCR noise (cf. short words such ni, ol, j or punctuation marks likely to be introduced by OCR misrecognitions), \u2022 less popular publication locations (especially far west).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_91",
            "start": 0,
            "end": 203,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_92@0",
            "content": "Obviously, year references (1902,1904) make it easy to guess the publication texts (in RetroTemp), whereas in RetroGap some non-content words such as the, and, of are easy to guess for the language model (even if their garbaged form, e.g. ot, ol, needs to be accounted for in the probability distribution).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_92",
            "start": 0,
            "end": 305,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_93@0",
            "content": "UNKNOWN, None, 2020, Deep learning models for multilingual hate speech detection, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_93",
            "start": 0,
            "end": 82,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_94@0",
            "content": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, None, , Ilya Sutskever, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_94",
            "start": 0,
            "end": 377,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_95@0",
            "content": "UNKNOWN, None, 2021, HateBERT: Retraining BERT for abusive language detection in english, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_95",
            "start": 0,
            "end": 90,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_96@0",
            "content": "UNKNOWN, None, 2019, Post-truth in social media, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_96",
            "start": 0,
            "end": 49,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_97@0",
            "content": "Maribeth Clark, A survey of online digital newspaper and genealogy archives: Resources, cost, and access, 2014, Journal of the Society for American Music, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_97",
            "start": 0,
            "end": 155,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_98@0",
            "content": "UNKNOWN, None, 2018, BERT: Pre-training of deep bidirectional transformers for language understanding, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_98",
            "start": 0,
            "end": 103,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_99@0",
            "content": "UNKNOWN, None, 2021, Time-aware language models as temporal knowledge bases, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_99",
            "start": 0,
            "end": 77,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_100@0",
            "content": "UNKNOWN, None, 2018, Multi-input attention for unsupervised OCR correction, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_100",
            "start": 0,
            "end": 76,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_101@0",
            "content": "UNKNOWN, None, 2004, Unsupervised discovery of implicit gender bias. CoRR, abs, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_101",
            "start": 0,
            "end": 80,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_102@0",
            "content": "Filip Grali\u0144ski, Piotr Wierzcho\u0144, RetroC-A Corpus for Evaluating Temporal Classifiers, 2015, Human Language Technology. Challenges for Computer Science and Linguistics. 7th Language and Technology Conference, Springer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_102",
            "start": 0,
            "end": 217,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_103@0",
            "content": "Filip Grali\u0144ski, Anna Wr\u00f3blewska, Tomasz Stanis\u0142awek, Kamil Grabowski, Tomasz G\u00f3recki, GEval: Tool for debugging NLP datasets and models, 2019, Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_103",
            "start": 0,
            "end": 287,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_104@0",
            "content": "Filip Grali\u0144ski, Polish digital libraries as a text corpus, 2013, Proceedings of 6th Language & Technology Conference, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_104",
            "start": 0,
            "end": 119,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_105@0",
            "content": "Filip Grali\u0144ski, Temporal) language models as a competitive challenge, 2017, Proceedings of the 8th Language & Technology Conference, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_105",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_106@0",
            "content": "Filip Grali\u0144ski, Against the Arrow of Time. Theory and Practice of Mining Massive Corpora of Polish Historical Texts for Linguistic and Historical Research, 2019, Wydawnictwo Naukowe UAM, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_106",
            "start": 0,
            "end": 188,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_107@0",
            "content": "Zheng Huang, Kai Chen, Jianhua He, Xiang Bai, Dimosthenis Karatzas, Shijian Lu, C Jawahar, ICDAR2019 competition on scanned receipt OCR and information extraction, 2019, International Conference on Document Analysis and Recognition (ICDAR), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_107",
            "start": 0,
            "end": 241,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_108@0",
            "content": "UNKNOWN, None, 2020, The newspaper navigator dataset: Extracting and analyzing visual content from 16 million historic newspaper pages in Chronicling America, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_108",
            "start": 0,
            "end": 159,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_109@0",
            "content": "UNKNOWN, None, 2019, RoBERTa: A robustly optimized BERT pretraining approach, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_109",
            "start": 0,
            "end": 78,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_110@0",
            "content": "Jean-Baptiste Michel, Yuan Kui Shen, Aviva Presser Aiden, Adrian Veres, K Matthew,  Gray, P Joseph, Dale Pickett, Dan Hoiberg, Peter Clancy, Jon Norvig,  Orwant, Quantitative analysis of culture using millions of digitized books, 2011, science, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_110",
            "start": 0,
            "end": 245,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_111@0",
            "content": "UNKNOWN, None, 2013, Efficient estimation of word representations in vector space, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_111",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_112@0",
            "content": "Thi-Tuyet-Hai Nguyen, Adam Jatowt, Mickael Coustaty, Antoine Nhu-Van Nguyen,  Doucet, Deep statistical analysis of OCR errors for effective post-OCR processing, 2019, Proceedings of the 18th Joint Conference on Digital Libraries, JCDL '19, IEEE Press.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_112",
            "start": 0,
            "end": 250,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_113@0",
            "content": "UNKNOWN, None, 2017, Semi-supervised sequence tagging with bidirectional language models, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_113",
            "start": 0,
            "end": 90,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_114@0",
            "content": "UNKNOWN, None, 2019, Exploring the limits of transfer learning with a unified text-to-text transformer, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_114",
            "start": 0,
            "end": 104,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_115@0",
            "content": "UNKNOWN, None, 2021, Time masking for temporal language models, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_115",
            "start": 0,
            "end": 64,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_116@0",
            "content": "UNKNOWN, None, 2004, A large dataset of historical Japanese documents with complex layouts. CoRR, abs, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_116",
            "start": 0,
            "end": 103,
            "label": {}
        },
        {
            "ix": "426-ARR_v1_117@0",
            "content": ", 487287 in<LeftContext>:i in<Text>:ol exp:31.760037 out:! in<Text>:cold exp:-81.772437 exp:; in<Text>:contemplate exp:24.562557 in<LeftContext>: * in<Text>:nI exp:-71.880373 in<RightContext>:l in<Text>:thee exp:44.814771 out, 1945-06, in<LeftContext>:e Table 5: Features highly correlating with good results RetroTemp RetroGeo RetroGap in<Text>:Democratic exp:44.007274 out:Of in<Text>:defeat exp:-80.85675 out:The in<Text>:Secretary exp:40.900892 out:ana in<Text>:notice exp:-77, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "426-ARR_v1_117",
            "start": 0,
            "end": 482,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "426-ARR_v1_0",
            "tgt_ix": "426-ARR_v1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_0",
            "tgt_ix": "426-ARR_v1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_1",
            "tgt_ix": "426-ARR_v1_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_1",
            "tgt_ix": "426-ARR_v1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_0",
            "tgt_ix": "426-ARR_v1_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_2",
            "tgt_ix": "426-ARR_v1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_4",
            "tgt_ix": "426-ARR_v1_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_5",
            "tgt_ix": "426-ARR_v1_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_6",
            "tgt_ix": "426-ARR_v1_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_7",
            "tgt_ix": "426-ARR_v1_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_8",
            "tgt_ix": "426-ARR_v1_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_9",
            "tgt_ix": "426-ARR_v1_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_10",
            "tgt_ix": "426-ARR_v1_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_12",
            "tgt_ix": "426-ARR_v1_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_13",
            "tgt_ix": "426-ARR_v1_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_15",
            "tgt_ix": "426-ARR_v1_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_3",
            "tgt_ix": "426-ARR_v1_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_3",
            "tgt_ix": "426-ARR_v1_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_3",
            "tgt_ix": "426-ARR_v1_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_3",
            "tgt_ix": "426-ARR_v1_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_3",
            "tgt_ix": "426-ARR_v1_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_3",
            "tgt_ix": "426-ARR_v1_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_3",
            "tgt_ix": "426-ARR_v1_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_3",
            "tgt_ix": "426-ARR_v1_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_3",
            "tgt_ix": "426-ARR_v1_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_3",
            "tgt_ix": "426-ARR_v1_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_3",
            "tgt_ix": "426-ARR_v1_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_3",
            "tgt_ix": "426-ARR_v1_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_3",
            "tgt_ix": "426-ARR_v1_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_3",
            "tgt_ix": "426-ARR_v1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_0",
            "tgt_ix": "426-ARR_v1_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_18",
            "tgt_ix": "426-ARR_v1_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_19",
            "tgt_ix": "426-ARR_v1_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_20",
            "tgt_ix": "426-ARR_v1_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_21",
            "tgt_ix": "426-ARR_v1_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_22",
            "tgt_ix": "426-ARR_v1_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_17",
            "tgt_ix": "426-ARR_v1_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_17",
            "tgt_ix": "426-ARR_v1_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_17",
            "tgt_ix": "426-ARR_v1_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_17",
            "tgt_ix": "426-ARR_v1_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_17",
            "tgt_ix": "426-ARR_v1_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_17",
            "tgt_ix": "426-ARR_v1_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_17",
            "tgt_ix": "426-ARR_v1_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_0",
            "tgt_ix": "426-ARR_v1_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_23",
            "tgt_ix": "426-ARR_v1_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_25",
            "tgt_ix": "426-ARR_v1_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_26",
            "tgt_ix": "426-ARR_v1_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_24",
            "tgt_ix": "426-ARR_v1_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_24",
            "tgt_ix": "426-ARR_v1_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_24",
            "tgt_ix": "426-ARR_v1_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_24",
            "tgt_ix": "426-ARR_v1_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_24",
            "tgt_ix": "426-ARR_v1_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_0",
            "tgt_ix": "426-ARR_v1_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_28",
            "tgt_ix": "426-ARR_v1_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_30",
            "tgt_ix": "426-ARR_v1_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_31",
            "tgt_ix": "426-ARR_v1_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_29",
            "tgt_ix": "426-ARR_v1_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_29",
            "tgt_ix": "426-ARR_v1_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_29",
            "tgt_ix": "426-ARR_v1_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_29",
            "tgt_ix": "426-ARR_v1_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_0",
            "tgt_ix": "426-ARR_v1_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_32",
            "tgt_ix": "426-ARR_v1_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_34",
            "tgt_ix": "426-ARR_v1_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_35",
            "tgt_ix": "426-ARR_v1_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_36",
            "tgt_ix": "426-ARR_v1_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_33",
            "tgt_ix": "426-ARR_v1_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_33",
            "tgt_ix": "426-ARR_v1_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_33",
            "tgt_ix": "426-ARR_v1_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_33",
            "tgt_ix": "426-ARR_v1_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_33",
            "tgt_ix": "426-ARR_v1_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_0",
            "tgt_ix": "426-ARR_v1_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_37",
            "tgt_ix": "426-ARR_v1_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_39",
            "tgt_ix": "426-ARR_v1_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_38",
            "tgt_ix": "426-ARR_v1_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_38",
            "tgt_ix": "426-ARR_v1_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_38",
            "tgt_ix": "426-ARR_v1_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_38",
            "tgt_ix": "426-ARR_v1_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_41",
            "tgt_ix": "426-ARR_v1_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_41",
            "tgt_ix": "426-ARR_v1_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_38",
            "tgt_ix": "426-ARR_v1_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_42",
            "tgt_ix": "426-ARR_v1_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_43",
            "tgt_ix": "426-ARR_v1_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_43",
            "tgt_ix": "426-ARR_v1_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_38",
            "tgt_ix": "426-ARR_v1_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_44",
            "tgt_ix": "426-ARR_v1_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_45",
            "tgt_ix": "426-ARR_v1_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_45",
            "tgt_ix": "426-ARR_v1_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_0",
            "tgt_ix": "426-ARR_v1_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_46",
            "tgt_ix": "426-ARR_v1_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_47",
            "tgt_ix": "426-ARR_v1_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_47",
            "tgt_ix": "426-ARR_v1_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_47",
            "tgt_ix": "426-ARR_v1_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_48",
            "tgt_ix": "426-ARR_v1_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_50",
            "tgt_ix": "426-ARR_v1_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_51",
            "tgt_ix": "426-ARR_v1_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_52",
            "tgt_ix": "426-ARR_v1_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_49",
            "tgt_ix": "426-ARR_v1_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_49",
            "tgt_ix": "426-ARR_v1_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_49",
            "tgt_ix": "426-ARR_v1_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_49",
            "tgt_ix": "426-ARR_v1_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_49",
            "tgt_ix": "426-ARR_v1_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_47",
            "tgt_ix": "426-ARR_v1_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_53",
            "tgt_ix": "426-ARR_v1_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_54",
            "tgt_ix": "426-ARR_v1_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_54",
            "tgt_ix": "426-ARR_v1_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_47",
            "tgt_ix": "426-ARR_v1_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_55",
            "tgt_ix": "426-ARR_v1_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_56",
            "tgt_ix": "426-ARR_v1_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_56",
            "tgt_ix": "426-ARR_v1_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_47",
            "tgt_ix": "426-ARR_v1_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_57",
            "tgt_ix": "426-ARR_v1_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_59",
            "tgt_ix": "426-ARR_v1_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_58",
            "tgt_ix": "426-ARR_v1_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_58",
            "tgt_ix": "426-ARR_v1_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_58",
            "tgt_ix": "426-ARR_v1_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_0",
            "tgt_ix": "426-ARR_v1_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_60",
            "tgt_ix": "426-ARR_v1_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_61",
            "tgt_ix": "426-ARR_v1_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_61",
            "tgt_ix": "426-ARR_v1_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_61",
            "tgt_ix": "426-ARR_v1_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_62",
            "tgt_ix": "426-ARR_v1_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_64",
            "tgt_ix": "426-ARR_v1_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_65",
            "tgt_ix": "426-ARR_v1_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_66",
            "tgt_ix": "426-ARR_v1_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_67",
            "tgt_ix": "426-ARR_v1_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_68",
            "tgt_ix": "426-ARR_v1_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_63",
            "tgt_ix": "426-ARR_v1_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_63",
            "tgt_ix": "426-ARR_v1_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_63",
            "tgt_ix": "426-ARR_v1_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_63",
            "tgt_ix": "426-ARR_v1_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_63",
            "tgt_ix": "426-ARR_v1_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_63",
            "tgt_ix": "426-ARR_v1_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_63",
            "tgt_ix": "426-ARR_v1_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_61",
            "tgt_ix": "426-ARR_v1_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_69",
            "tgt_ix": "426-ARR_v1_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_71",
            "tgt_ix": "426-ARR_v1_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_72",
            "tgt_ix": "426-ARR_v1_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_70",
            "tgt_ix": "426-ARR_v1_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_70",
            "tgt_ix": "426-ARR_v1_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_70",
            "tgt_ix": "426-ARR_v1_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_70",
            "tgt_ix": "426-ARR_v1_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_0",
            "tgt_ix": "426-ARR_v1_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_73",
            "tgt_ix": "426-ARR_v1_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_74",
            "tgt_ix": "426-ARR_v1_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_74",
            "tgt_ix": "426-ARR_v1_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_3",
            "tgt_ix": "426-ARR_v1_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_75",
            "tgt_ix": "426-ARR_v1_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_77",
            "tgt_ix": "426-ARR_v1_78",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_78",
            "tgt_ix": "426-ARR_v1_79",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_79",
            "tgt_ix": "426-ARR_v1_80",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_80",
            "tgt_ix": "426-ARR_v1_81",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_81",
            "tgt_ix": "426-ARR_v1_82",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_82",
            "tgt_ix": "426-ARR_v1_83",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_83",
            "tgt_ix": "426-ARR_v1_84",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_84",
            "tgt_ix": "426-ARR_v1_85",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_85",
            "tgt_ix": "426-ARR_v1_86",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_76",
            "tgt_ix": "426-ARR_v1_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_76",
            "tgt_ix": "426-ARR_v1_78",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_76",
            "tgt_ix": "426-ARR_v1_79",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_76",
            "tgt_ix": "426-ARR_v1_80",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_76",
            "tgt_ix": "426-ARR_v1_81",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_76",
            "tgt_ix": "426-ARR_v1_82",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_76",
            "tgt_ix": "426-ARR_v1_83",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_76",
            "tgt_ix": "426-ARR_v1_84",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_76",
            "tgt_ix": "426-ARR_v1_85",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_76",
            "tgt_ix": "426-ARR_v1_86",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_76",
            "tgt_ix": "426-ARR_v1_77",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_87",
            "tgt_ix": "426-ARR_v1_88",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_76",
            "tgt_ix": "426-ARR_v1_87",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_76",
            "tgt_ix": "426-ARR_v1_88",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_86",
            "tgt_ix": "426-ARR_v1_87",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_89",
            "tgt_ix": "426-ARR_v1_90",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_90",
            "tgt_ix": "426-ARR_v1_91",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_76",
            "tgt_ix": "426-ARR_v1_89",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_76",
            "tgt_ix": "426-ARR_v1_90",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_76",
            "tgt_ix": "426-ARR_v1_91",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_76",
            "tgt_ix": "426-ARR_v1_92",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "426-ARR_v1_0",
            "tgt_ix": "426-ARR_v1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_1",
            "tgt_ix": "426-ARR_v1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_2",
            "tgt_ix": "426-ARR_v1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_2",
            "tgt_ix": "426-ARR_v1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_2",
            "tgt_ix": "426-ARR_v1_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_2",
            "tgt_ix": "426-ARR_v1_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_2",
            "tgt_ix": "426-ARR_v1_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_2",
            "tgt_ix": "426-ARR_v1_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_2",
            "tgt_ix": "426-ARR_v1_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_3",
            "tgt_ix": "426-ARR_v1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_4",
            "tgt_ix": "426-ARR_v1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_4",
            "tgt_ix": "426-ARR_v1_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_4",
            "tgt_ix": "426-ARR_v1_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_4",
            "tgt_ix": "426-ARR_v1_4@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_5",
            "tgt_ix": "426-ARR_v1_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_5",
            "tgt_ix": "426-ARR_v1_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_5",
            "tgt_ix": "426-ARR_v1_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_6",
            "tgt_ix": "426-ARR_v1_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_7",
            "tgt_ix": "426-ARR_v1_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_7",
            "tgt_ix": "426-ARR_v1_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_7",
            "tgt_ix": "426-ARR_v1_7@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_7",
            "tgt_ix": "426-ARR_v1_7@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_8",
            "tgt_ix": "426-ARR_v1_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_9",
            "tgt_ix": "426-ARR_v1_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_9",
            "tgt_ix": "426-ARR_v1_9@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_10",
            "tgt_ix": "426-ARR_v1_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_11",
            "tgt_ix": "426-ARR_v1_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_12",
            "tgt_ix": "426-ARR_v1_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_13",
            "tgt_ix": "426-ARR_v1_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_14",
            "tgt_ix": "426-ARR_v1_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_15",
            "tgt_ix": "426-ARR_v1_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_16",
            "tgt_ix": "426-ARR_v1_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_17",
            "tgt_ix": "426-ARR_v1_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_18",
            "tgt_ix": "426-ARR_v1_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_18",
            "tgt_ix": "426-ARR_v1_18@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_18",
            "tgt_ix": "426-ARR_v1_18@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_18",
            "tgt_ix": "426-ARR_v1_18@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_18",
            "tgt_ix": "426-ARR_v1_18@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_18",
            "tgt_ix": "426-ARR_v1_18@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_19",
            "tgt_ix": "426-ARR_v1_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_19",
            "tgt_ix": "426-ARR_v1_19@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_19",
            "tgt_ix": "426-ARR_v1_19@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_19",
            "tgt_ix": "426-ARR_v1_19@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_20",
            "tgt_ix": "426-ARR_v1_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_20",
            "tgt_ix": "426-ARR_v1_20@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_20",
            "tgt_ix": "426-ARR_v1_20@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_20",
            "tgt_ix": "426-ARR_v1_20@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_20",
            "tgt_ix": "426-ARR_v1_20@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_21",
            "tgt_ix": "426-ARR_v1_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_21",
            "tgt_ix": "426-ARR_v1_21@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_21",
            "tgt_ix": "426-ARR_v1_21@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_22",
            "tgt_ix": "426-ARR_v1_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_22",
            "tgt_ix": "426-ARR_v1_22@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_22",
            "tgt_ix": "426-ARR_v1_22@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_22",
            "tgt_ix": "426-ARR_v1_22@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_22",
            "tgt_ix": "426-ARR_v1_22@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_22",
            "tgt_ix": "426-ARR_v1_22@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_23",
            "tgt_ix": "426-ARR_v1_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_23",
            "tgt_ix": "426-ARR_v1_23@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_23",
            "tgt_ix": "426-ARR_v1_23@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_23",
            "tgt_ix": "426-ARR_v1_23@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_24",
            "tgt_ix": "426-ARR_v1_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_25",
            "tgt_ix": "426-ARR_v1_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_25",
            "tgt_ix": "426-ARR_v1_25@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_25",
            "tgt_ix": "426-ARR_v1_25@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_25",
            "tgt_ix": "426-ARR_v1_25@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_25",
            "tgt_ix": "426-ARR_v1_25@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_25",
            "tgt_ix": "426-ARR_v1_25@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_25",
            "tgt_ix": "426-ARR_v1_25@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_25",
            "tgt_ix": "426-ARR_v1_25@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_25",
            "tgt_ix": "426-ARR_v1_25@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_25",
            "tgt_ix": "426-ARR_v1_25@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_25",
            "tgt_ix": "426-ARR_v1_25@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_25",
            "tgt_ix": "426-ARR_v1_25@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_26",
            "tgt_ix": "426-ARR_v1_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_27",
            "tgt_ix": "426-ARR_v1_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_28",
            "tgt_ix": "426-ARR_v1_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_28",
            "tgt_ix": "426-ARR_v1_28@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_29",
            "tgt_ix": "426-ARR_v1_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_30",
            "tgt_ix": "426-ARR_v1_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_30",
            "tgt_ix": "426-ARR_v1_30@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_31",
            "tgt_ix": "426-ARR_v1_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_31",
            "tgt_ix": "426-ARR_v1_31@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_31",
            "tgt_ix": "426-ARR_v1_31@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_31",
            "tgt_ix": "426-ARR_v1_31@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_31",
            "tgt_ix": "426-ARR_v1_31@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_32",
            "tgt_ix": "426-ARR_v1_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_32",
            "tgt_ix": "426-ARR_v1_32@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_32",
            "tgt_ix": "426-ARR_v1_32@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_32",
            "tgt_ix": "426-ARR_v1_32@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_33",
            "tgt_ix": "426-ARR_v1_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_34",
            "tgt_ix": "426-ARR_v1_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_34",
            "tgt_ix": "426-ARR_v1_34@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_34",
            "tgt_ix": "426-ARR_v1_34@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_34",
            "tgt_ix": "426-ARR_v1_34@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_35",
            "tgt_ix": "426-ARR_v1_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_35",
            "tgt_ix": "426-ARR_v1_35@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_35",
            "tgt_ix": "426-ARR_v1_35@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_35",
            "tgt_ix": "426-ARR_v1_35@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_35",
            "tgt_ix": "426-ARR_v1_35@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_36",
            "tgt_ix": "426-ARR_v1_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_36",
            "tgt_ix": "426-ARR_v1_36@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_36",
            "tgt_ix": "426-ARR_v1_36@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_37",
            "tgt_ix": "426-ARR_v1_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_37",
            "tgt_ix": "426-ARR_v1_37@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_37",
            "tgt_ix": "426-ARR_v1_37@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_38",
            "tgt_ix": "426-ARR_v1_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_39",
            "tgt_ix": "426-ARR_v1_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_39",
            "tgt_ix": "426-ARR_v1_39@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_39",
            "tgt_ix": "426-ARR_v1_39@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_39",
            "tgt_ix": "426-ARR_v1_39@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_39",
            "tgt_ix": "426-ARR_v1_39@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_39",
            "tgt_ix": "426-ARR_v1_39@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_39",
            "tgt_ix": "426-ARR_v1_39@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_40",
            "tgt_ix": "426-ARR_v1_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_41",
            "tgt_ix": "426-ARR_v1_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_42",
            "tgt_ix": "426-ARR_v1_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_42",
            "tgt_ix": "426-ARR_v1_42@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_42",
            "tgt_ix": "426-ARR_v1_42@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_42",
            "tgt_ix": "426-ARR_v1_42@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_42",
            "tgt_ix": "426-ARR_v1_42@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_42",
            "tgt_ix": "426-ARR_v1_42@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_42",
            "tgt_ix": "426-ARR_v1_42@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_42",
            "tgt_ix": "426-ARR_v1_42@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_42",
            "tgt_ix": "426-ARR_v1_42@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_42",
            "tgt_ix": "426-ARR_v1_42@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_42",
            "tgt_ix": "426-ARR_v1_42@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_42",
            "tgt_ix": "426-ARR_v1_42@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_42",
            "tgt_ix": "426-ARR_v1_42@12",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_42",
            "tgt_ix": "426-ARR_v1_42@13",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_43",
            "tgt_ix": "426-ARR_v1_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_44",
            "tgt_ix": "426-ARR_v1_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_44",
            "tgt_ix": "426-ARR_v1_44@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_45",
            "tgt_ix": "426-ARR_v1_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_46",
            "tgt_ix": "426-ARR_v1_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_46",
            "tgt_ix": "426-ARR_v1_46@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_46",
            "tgt_ix": "426-ARR_v1_46@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_46",
            "tgt_ix": "426-ARR_v1_46@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_46",
            "tgt_ix": "426-ARR_v1_46@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_46",
            "tgt_ix": "426-ARR_v1_46@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_46",
            "tgt_ix": "426-ARR_v1_46@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_47",
            "tgt_ix": "426-ARR_v1_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_48",
            "tgt_ix": "426-ARR_v1_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_48",
            "tgt_ix": "426-ARR_v1_48@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_48",
            "tgt_ix": "426-ARR_v1_48@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_49",
            "tgt_ix": "426-ARR_v1_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_50",
            "tgt_ix": "426-ARR_v1_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_50",
            "tgt_ix": "426-ARR_v1_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_50",
            "tgt_ix": "426-ARR_v1_50@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_51",
            "tgt_ix": "426-ARR_v1_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_51",
            "tgt_ix": "426-ARR_v1_51@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_52",
            "tgt_ix": "426-ARR_v1_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_53",
            "tgt_ix": "426-ARR_v1_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_53",
            "tgt_ix": "426-ARR_v1_53@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_54",
            "tgt_ix": "426-ARR_v1_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_55",
            "tgt_ix": "426-ARR_v1_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_55",
            "tgt_ix": "426-ARR_v1_55@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_55",
            "tgt_ix": "426-ARR_v1_55@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_55",
            "tgt_ix": "426-ARR_v1_55@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_56",
            "tgt_ix": "426-ARR_v1_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_57",
            "tgt_ix": "426-ARR_v1_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_57",
            "tgt_ix": "426-ARR_v1_57@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_57",
            "tgt_ix": "426-ARR_v1_57@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_57",
            "tgt_ix": "426-ARR_v1_57@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_58",
            "tgt_ix": "426-ARR_v1_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_59",
            "tgt_ix": "426-ARR_v1_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_59",
            "tgt_ix": "426-ARR_v1_59@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_59",
            "tgt_ix": "426-ARR_v1_59@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_59",
            "tgt_ix": "426-ARR_v1_59@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_59",
            "tgt_ix": "426-ARR_v1_59@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_59",
            "tgt_ix": "426-ARR_v1_59@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_60",
            "tgt_ix": "426-ARR_v1_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_61",
            "tgt_ix": "426-ARR_v1_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_62",
            "tgt_ix": "426-ARR_v1_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_62",
            "tgt_ix": "426-ARR_v1_62@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_62",
            "tgt_ix": "426-ARR_v1_62@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_63",
            "tgt_ix": "426-ARR_v1_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_64",
            "tgt_ix": "426-ARR_v1_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_64",
            "tgt_ix": "426-ARR_v1_64@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_65",
            "tgt_ix": "426-ARR_v1_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_66",
            "tgt_ix": "426-ARR_v1_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_66",
            "tgt_ix": "426-ARR_v1_66@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_66",
            "tgt_ix": "426-ARR_v1_66@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_67",
            "tgt_ix": "426-ARR_v1_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_67",
            "tgt_ix": "426-ARR_v1_67@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_67",
            "tgt_ix": "426-ARR_v1_67@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_68",
            "tgt_ix": "426-ARR_v1_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_68",
            "tgt_ix": "426-ARR_v1_68@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_69",
            "tgt_ix": "426-ARR_v1_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_70",
            "tgt_ix": "426-ARR_v1_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_71",
            "tgt_ix": "426-ARR_v1_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_71",
            "tgt_ix": "426-ARR_v1_71@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_72",
            "tgt_ix": "426-ARR_v1_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_73",
            "tgt_ix": "426-ARR_v1_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_73",
            "tgt_ix": "426-ARR_v1_73@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_73",
            "tgt_ix": "426-ARR_v1_73@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_74",
            "tgt_ix": "426-ARR_v1_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_75",
            "tgt_ix": "426-ARR_v1_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_75",
            "tgt_ix": "426-ARR_v1_75@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_75",
            "tgt_ix": "426-ARR_v1_75@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_75",
            "tgt_ix": "426-ARR_v1_75@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_75",
            "tgt_ix": "426-ARR_v1_75@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_75",
            "tgt_ix": "426-ARR_v1_75@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_75",
            "tgt_ix": "426-ARR_v1_75@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_75",
            "tgt_ix": "426-ARR_v1_75@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_76",
            "tgt_ix": "426-ARR_v1_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_77",
            "tgt_ix": "426-ARR_v1_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_77",
            "tgt_ix": "426-ARR_v1_77@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_77",
            "tgt_ix": "426-ARR_v1_77@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_78",
            "tgt_ix": "426-ARR_v1_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_78",
            "tgt_ix": "426-ARR_v1_78@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_78",
            "tgt_ix": "426-ARR_v1_78@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_78",
            "tgt_ix": "426-ARR_v1_78@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_79",
            "tgt_ix": "426-ARR_v1_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_79",
            "tgt_ix": "426-ARR_v1_79@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_79",
            "tgt_ix": "426-ARR_v1_79@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_79",
            "tgt_ix": "426-ARR_v1_79@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_80",
            "tgt_ix": "426-ARR_v1_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_81",
            "tgt_ix": "426-ARR_v1_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_81",
            "tgt_ix": "426-ARR_v1_81@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_82",
            "tgt_ix": "426-ARR_v1_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_83",
            "tgt_ix": "426-ARR_v1_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_84",
            "tgt_ix": "426-ARR_v1_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_85",
            "tgt_ix": "426-ARR_v1_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_85",
            "tgt_ix": "426-ARR_v1_85@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_86",
            "tgt_ix": "426-ARR_v1_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_86",
            "tgt_ix": "426-ARR_v1_86@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_86",
            "tgt_ix": "426-ARR_v1_86@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_87",
            "tgt_ix": "426-ARR_v1_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_87",
            "tgt_ix": "426-ARR_v1_87@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_88",
            "tgt_ix": "426-ARR_v1_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_89",
            "tgt_ix": "426-ARR_v1_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_89",
            "tgt_ix": "426-ARR_v1_89@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_90",
            "tgt_ix": "426-ARR_v1_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_91",
            "tgt_ix": "426-ARR_v1_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_92",
            "tgt_ix": "426-ARR_v1_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_93",
            "tgt_ix": "426-ARR_v1_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_94",
            "tgt_ix": "426-ARR_v1_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_95",
            "tgt_ix": "426-ARR_v1_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_96",
            "tgt_ix": "426-ARR_v1_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_97",
            "tgt_ix": "426-ARR_v1_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_98",
            "tgt_ix": "426-ARR_v1_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_99",
            "tgt_ix": "426-ARR_v1_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_100",
            "tgt_ix": "426-ARR_v1_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_101",
            "tgt_ix": "426-ARR_v1_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_102",
            "tgt_ix": "426-ARR_v1_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_103",
            "tgt_ix": "426-ARR_v1_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_104",
            "tgt_ix": "426-ARR_v1_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_105",
            "tgt_ix": "426-ARR_v1_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_106",
            "tgt_ix": "426-ARR_v1_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_107",
            "tgt_ix": "426-ARR_v1_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_108",
            "tgt_ix": "426-ARR_v1_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_109",
            "tgt_ix": "426-ARR_v1_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_110",
            "tgt_ix": "426-ARR_v1_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_111",
            "tgt_ix": "426-ARR_v1_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_112",
            "tgt_ix": "426-ARR_v1_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_113",
            "tgt_ix": "426-ARR_v1_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_114",
            "tgt_ix": "426-ARR_v1_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_115",
            "tgt_ix": "426-ARR_v1_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_116",
            "tgt_ix": "426-ARR_v1_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "426-ARR_v1_117",
            "tgt_ix": "426-ARR_v1_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 1402,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "position_tag_type": "from_draft",
        "doc_id": "426-ARR",
        "version": 1
    }
}