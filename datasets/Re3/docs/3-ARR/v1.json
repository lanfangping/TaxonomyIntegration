{
    "nodes": [
        {
            "ix": "3-ARR_v1_0",
            "content": "Document-Level Relation Extraction with Sentences Importance Estimation and Focusing",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_2",
            "content": "Document-level relation extraction (DocRE) aims to determine the relation between two entities from a document of multiple sentences. Recent studies typically represent the entire document by sequence-or graphbased models to predict the relations of all entity pairs. However, we find that such a model is not robust and exhibits bizarre behaviors: it predicts correctly when an entire test document is fed as input, but errs when non-evidence sentences are removed. To this end, we propose a Sentence Importance Estimation and Focusing (SIEF) framework for DocRE, where we design a sentence importance score and a sentence focusing loss, encouraging DocRE models to focus on evidence sentences. Experimental results on two domains show that our SIEF not only improves overall performance, but also makes DocRE models more robust. Moreover, SIEF is a general framework, shown to be effective when combined with a variety of base DocRE models. 1",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "3-ARR_v1_4",
            "content": "Document-level relation extraction (DocRE) aims to predict entity relations across multiple sentences. It plays a crucial role in a variety of knowledgebased applications, such as question answering (Sorokin and Gurevych, 2017) and large-scale knowledge graph construction (Baldini Soares et al., 2019). Different from sentence-level relation extraction (Zeng et al., 2014;Xiao and Liu, 2016;Yu et al., 2017;Song et al., 2019), the supporting evidence in the DocRE setting may involve multiple sentences scattering in the document. Thus, DocRE is more a realistic setting, attracting increasing attention in the field of information extraction. Most recent DocRE studies use the entire document as a clue to predict the relations of all entity pairs without concerning where the evidence is located (Nan et al., 2020;Zeng et al., 2020;Xu et al., 2021a,b). However, one can identify the relation of a specific entity pair from a few sentences. show that irrelevant sentences in the document would hinder the performance of the model.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_5",
            "content": "Moreover, we observe that a DocRE model, trained on the entire document, may err when non-evidence sentences are removed. In Figure 1, for example, we need to identify the relation \"MemberOf\" between the entities Brad Wilk and Rage Against the Machine. The evidence sentences are [1,2], and humans can easily identify such a relation when reading sentences [1,2] only. However, the recent DocRE model GAIN (Zeng et al., 2020) identifies the relation \"MemberOf\" correctly from the entire document [1,2,3], but predicts \"not MemberOf\" from sentences [1,2]. Intuitively, removing sentence [3] should not change the results, as this sentence does not provide information regarding whether \"not MemberOf\" holds or not for the two entities. Such model behaviors are undesired, because it shows that the model is not robust and lacks interpretability.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_6",
            "content": "To this end, we propose a novel Sentence Importance Estimation and Focusing (SIEF) framework to encourage the model to focus on evidence sentences for predicting the relation of an entity pair. Specifically, we first evaluate the importance of each sentence by the difference between the output probabilities of the document with and without this sentence. If the predicted probability of a relation does not change, or even increases, when a sentence is removed, it typically indicates that the sentence is non-evidence. Then, we propose an auxiliary loss to encourage the model to produce the same output distribution, when the entire document is fed as input and when a non-evidence sentence is removed. In this way, the model pays more attention to the evidence sentences for the classification. Our SIEF method is a general framework that can be combined with different underlying DocRE models.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_7",
            "content": "We evaluated the generality and effectiveness of our approach on the large-scale DocRED dataset (Yao et al., 2019). Experimental results show that the proposed approach combines well with various recent DocRE models and significantly improves the performance. Moreover, the proposed approach outperforms a variety of models on DocRED dataset. We further evaluated our approach on a dialogue relation extraction dataset, DialogRE (Yu et al., 2020); our SIEF yields consistent improvement, showing the generality of our approach in different domains.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_8",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "3-ARR_v1_9",
            "content": "Relation extraction (RE) can be categorized by its granularity, such as sentence-level (Doddington et al., 2004;Xu et al., 2016; and document-level (Gupta et al., 2019;Zhu et al., 2019). Early work mainly focuses on sentencelevel relation extraction. Pantel and Pennacchiotti (2006) propose a rule-based approach, and Mintz et al. (2009) design features for classifying relations. In the past several years, neural networks have become a prevailing approach for relation extraction (Xu et al., 2015;Song et al., 2019).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_10",
            "content": "Document-level relation extraction (DocRE) is attracting increasing attention in the community, as it considers the interactions across entity mentions expressed in different sentences Yao et al., 2019). Compared with the sentence level, DocRE requires the model collecting and integrating inter-sentence information effectively. Recent efforts design sequence-based and graphbased models to address such a problem.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_11",
            "content": "Sequence-based DocRE models encode a document by the sequence of words and/or sentences, for example, using the Transformer architecture (Devlin et al., 2019). Zhou et al. (2021) argue that the Transformer attentions are able to extract useful contextual features across sentences for DocRE, and they adopt an adaptive threshold for each entity pair. Zhang et al. (2021) model DocRE as a semantic segmentation task and predict an entity-level relation matrix to capture local and global information.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_12",
            "content": "Graph-based DocRE models abstract a document by graphical structures. For example, a node can be a sentence, a mention, and/or an entity; their co-occurrence is modeled by an edge. Then graph neural networks are applied to aggregate inter-sentence information (Quirk and Poon, 2017;Christopoulou et al., 2019;Zeng et al., 2020). Zeng et al. (2020) construct double graphs, applying graph neural networks to mention-document graphs and performing path reasoning over entity graphs. Xu et al. (2021a) explicitly incorporate logical reasoning, commonsense reasoning, and coreference reasoning into DocRE, based on both sequence and graph features.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_13",
            "content": "Different from previous work, our paper proposes SIEF as a general framework that can be combined with various sequence-based and graph-based DocRE models. In our approach, we propose a sentence importance score and a sentence focusing loss to encourage the model to focus on evidence sentences, improving the robustness and the overall performance of DocRE models.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_14",
            "content": "Problem Definition",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "3-ARR_v1_15",
            "content": "In this section, we present formulation of document relation extraction (DocRE). Consider an unstructured document comprising N sentences, D = {s 1 , s 2 , \u2022 \u2022 \u2022 , s N }, where each sentence s n are a sequence words. Typically, the document D is annotated with entity mentions, each mention (e.g., U.S. and USA) labeled by its conceptual entity e and its entity type (e.g., location).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_16",
            "content": "A DocRE model F is usually formulated as multi-label classification (Yao et al., 2019). F j predicts whether the jth relation holds for the ith marked entity pair in a document, given by",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_17",
            "content": "P ij = F j (D, e i h , e it ) = Pr[r ij = 1|D, e i h , e it ]",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_18",
            "content": "(1) where e i h is the head entity and e it is the tail entity; r ij \u2208 {0, 1} is the groundtruth label regarding",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_19",
            "content": "[1] The Sacramento Bee is a daily newspaper published in Sacramento, California, in the United States.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_20",
            "content": "[2] Since its founding in 1857, The Bee has become the largest newspaper in Sacramento, the fifth largest newspaper in California, and the 27th largest paper in the U.S.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_21",
            "content": "[3] The Bee is the flagship of the American McClatchy Company. entity pair i and relation j.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_22",
            "content": "To train the model, the binary cross-entropy loss is used as the objective for parameter estimation:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_23",
            "content": "L rel = \u2212 D\u2208C i h =it j\u2208R {r ij log P ij +(1 \u2212 r ij ) log(1 \u2212 P ij )} (2)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_24",
            "content": "where C denotes the entire corpus and R denotes the set of relation types.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_25",
            "content": "During inference, we obtain the relation(s) of a given entity pair by thresholding the predicted probabilities, following most previous work (Yao et al., 2019;Zhou et al., 2021).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_26",
            "content": "Methodology",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "3-ARR_v1_27",
            "content": "In this section, we will describe our approach in detail. The overview of our framework is shown in Figure 2. First, we describe the estimation of sentence importance in Section 4.1. Sentences with low importance scores are treated as nonevidence. Then, Sections 4.2 and 4.3 present our approach encouraging the model to produce the same output distribution, when the entire document is fed as input and when non-evidence sentences are removed. Section 4.4 further presents the architectures of DocRE models.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_28",
            "content": "Sentence Importance Estimation",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "3-ARR_v1_29",
            "content": "We estimate the importance of each sentence for a specific entity pair. Low-scored sentences will be treated as non-evidence, and in principle, can be removed without changing DocRE predictions.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_30",
            "content": "We propose a sentence importance score based on the DocRE predictions with and without the sentence in question. Our observation is that the relation extraction task is usually monotonic to evidence, i.e., (non-strictly) more relations will be predicted with more sentences. If we remove a sentence and the predicted probability of a relation decreases, then the sentence is likely to be the evidence. If the predicted probability does not change, then the sentence is likely to be nonevidence. Moreover, the predicted probability may sometimes increase when a sentence is removed, in which case the DocRE model is not robust, as this violates monotonicity.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_31",
            "content": "Formally, we consider removing one sentence at a time, and the document with the nth sentence removed is denoted by",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_32",
            "content": "D(\u2212n) = {s 1 , \u2022 \u2022 \u2022 , s n\u22121 , s n+1 , \u2022 \u2022 \u2022 , s N }.",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_33",
            "content": "For a DocRE model F , we obtain the classification probabilities P ij = F j (D, e i h , e it ) based on the original document, and",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_34",
            "content": "P (\u2212n) ij = F j ( D(\u2212n) , e i h , e it ) with sentence n removed.",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_35",
            "content": "We propose the importance score as",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_36",
            "content": "g (\u2212n) ij = P ij log P ij P (\u2212n) ij (3)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_37",
            "content": "The formula appears similar to Kullback-Leibler (KL) divergence. However, we only take one term in the KL summation, because the KL divergence, albeit asymmetric in its two arguments, cannot model the increase or decrease of",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_38",
            "content": "P (\u2212n) ij , whereas our g (\u2212n) ij",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_39",
            "content": "is monotonically decreasing with",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_40",
            "content": "P (\u2212n) ij .",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_41",
            "content": "Compared with a naive difference or ratio between P ij and",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_42",
            "content": "P (\u2212n) ij",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_43",
            "content": ", we find that our KL-like score is more robust in the scale of P ij when determining non-evidence sentences.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_44",
            "content": "We treat a sentence n as non-evidence if g",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_45",
            "content": "(\u2212n) ij",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_46",
            "content": "< \u03b2 for a thresholding hyperparameter \u03b2. The resulting set of non-evidence sentences is denoted by K ij for the an entity pair (e i h , e it ) and relation j.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_47",
            "content": "Sentence Focusing Loss",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "3-ARR_v1_48",
            "content": "We propose a sentence focusing loss to encourage the model to produce the same output distribution when the entire document is fed as input and when non-evidence sentences are removed.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_49",
            "content": "Ideally, the predicted probability should remain the same if we remove any combination of the sentences in K ij . Therefore, we penalize the extent to which the predicted probability is changed.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_50",
            "content": "We propose the sentence focusing loss as:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_51",
            "content": "L sf = \u2212 D\u2208C i h =it j\u2208R J ij \u2286K ij {P ij log( P (\u2212J ij ) ij ) +(1 \u2212 P ij ) log(1 \u2212 P (\u2212J i ) ij )} (4) where J ij is a subset of K ij and P (\u2212J ij ) ij = F j (D\\J ij , e i h , e it ) is the predicted probability with J ij removed from D. And the final loss is L = L rel + L sf .",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_52",
            "content": "Essentially, our sentence focusing loss ensures P ij is close to",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_53",
            "content": "P (\u2212J ij ) ij",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_54",
            "content": ", which intuitively makes sense because non-evidence sentences should not affect the prediction. Our approach can also be thought of as a way of data augmentation. However, compared with one-hot groundtruth labels, our sentence focusing loss works with soft labels P ij and",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_55",
            "content": "P (\u2212J ij ) ij",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_56",
            "content": ", which are believed to contain more information (Hinton et al., 2015), and our gradient propagates to both P ij and",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_57",
            "content": "P (\u2212J ij ) ij",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_58",
            "content": "for training. The calculation of Eqn. ( 4) is time-and resourceconsuming, because the number of the subsets J ij grows combinatorially with the number of nonevidence sentences. To this end, we propose a simplified training strategy to approximate Eqn. (4) in the next subsection.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_59",
            "content": "Training Strategy",
            "ntype": "title",
            "meta": {
                "section": "4.3"
            }
        },
        {
            "ix": "3-ARR_v1_60",
            "content": "We propose a strategy to simplify the calculation and the training procedure. Concretely, we only remove one non-evidence sentence in K ij at a time instead of a subset of J ij \u2286 K ij , and we aggregate the effect of different non-evidence sentences by:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_61",
            "content": "L sf = \u2212 D\u2208C N n=1 i h =it j\u2208R I(g (\u2212n) ij < \u03b2) {P ij log( P (\u2212n) ij ) + (1 \u2212 P ij ) log(1 \u2212 P (\u2212n) ij )}",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_62",
            "content": "(5) where I is the indicator function. Essentially, we linearly approximate the combination of multiple non-evidence sentences in (4) by an outer summation. In this way, the number of terms does not grow combinatorially, but linearly w.r.t. N .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_63",
            "content": "In implementation, we further simply the summation over n by Monte Carlo sampling of a randomly selected sentence n in each gradient update. The loss is reformulated as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_64",
            "content": "L sf = \u2212 D\u2208C i h =it j\u2208R I(g (\u2212n) ij < \u03b2) {P ij log( P (\u2212n) ij ) + (1 \u2212 P ij ) log(1 \u2212 P (\u2212n) ij )} (6)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_65",
            "content": "As seen, we need to forward the base models twice in each update, with and without the sentence n. propose a similar idea but train different entity pairs in a document based on different sets of sentences; all sentence are processed repeatedly among entity pairs in a document. Their approach is much computationally slower than ours.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_66",
            "content": "To sum up, the proposed SIEF framework identifies non-evidence sentences and penalizes the difference of predicted probabilities when a nonevidence sentence is removed. Our approach is a generic framework and can be adapted to various DocRE model easily, without introducing extra parameters into the model.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_67",
            "content": "DocRE Model Architectures",
            "ntype": "title",
            "meta": {
                "section": "4.4"
            }
        },
        {
            "ix": "3-ARR_v1_68",
            "content": "Our SIEF can be applied to various base DocRE models. To evaluate its generality, we consider the following recent models.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_69",
            "content": "BiLSTM (Yao et al., 2019) 2 . A bi-directional long short term memory (BiLSTM) encodes the document, and an entity is representated by BiLSTM's hidden states, averaged over entity mentions. The head and tail entity representations are fed to a multi-layer perceptron (MLP) for relation extraction.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_70",
            "content": "BERT base (Devlin et al., 2019) 3 . A pre-trained language model is used for document encoding.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_71",
            "content": "HeterGSAN (Xu et al., 2021b) 4 . HeterGSAN is a recent graph-based DocRED model, which constructs a heterogeneous graph of sentence, mention, and entity nodes; it uses graph neural networks for relation extraction.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_72",
            "content": "GAIN (Zeng et al., 2020) 3 . GAIN constructs two graphs: mention-document graphs and entity graphs separately, and performs graph and path reasonings. When combining our SIEF with GAIN, we achieve the best performance among all the base models with SIEF on DocRED. Thus, we will explain this model in more detail.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_73",
            "content": "Essentially, a node in the mention-document graph is either a mention or a document. The mentions are connected to its document, and two mentions are connected if they co-occur in one sentence. In the entity graph, two entities are connected if they are mentioned in one sentence. To classify the relation, GNN is applied to the mentiondocument graph, enhanced with path information in the entity graph, shown in Figure 3.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_74",
            "content": "When combining SIEF with GAIN, we randomly remove one sentence from the document. The corresponding nodes and edges are removed in the GAIN's graphs. Then we obtain the output probabilities with and without the sentence, P ij and 3) is below a threshold \u03b2, the sentence is treated as non-evidence for the entity pair (e i h , e it ) and relation j. We apply the sentence focusing loss Eqn. (4) to improve the robustness.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_75",
            "content": "P (\u2212n) ij separately. If the sentence important score g (\u2212n) ij in Eqn. (",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_76",
            "content": "For prediction, we apply the trained DocRE model to the entire document, because with our approach the model is already robust when nonevidence sentences are presented. Empirical results will show that our SIEF consistently improves the performance of base DocRE models.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_77",
            "content": "Experiments",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "3-ARR_v1_78",
            "content": "Setup",
            "ntype": "title",
            "meta": {
                "section": "5.1"
            }
        },
        {
            "ix": "3-ARR_v1_79",
            "content": "Datasets. DocRED is a large-scale humanannotated dataset for document-level relation extraction (Yao et al., 2019).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_80",
            "content": "The dataset is constructed from Wikipedia and Wikidata, containing 3053 documents for training, 1000 for development, and 1000 for test. In total, it has 132,375 entities and 56,354 relational facts in 96 relation types. More than 40% of the relational facts require reasoning over multiple sentences. The standard evaluation metrics are F1 and Ign F1 (Yao et al., 2019;Zeng et al., 2020), where Ign F1 refers to the F1 score excluding the relational facts in the training set.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_81",
            "content": "We also evaluated our approach on DialogRE (V2, Yu et al., 2020), which contains 36 relation types (17 of which are interpersonal). We followed the standard split of 1073 training dialogues, 358 validation, and 357 test. Following Yu et al. (2020), we report macro F1 scores in both the standard and conversational settings; the latter is denoted by F1 c .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_82",
            "content": "Competing Methods. We experimented our SIEF on a number of base models, namely, BiLSTM, BERT base , HeterGSAN, and GAIN (Section 4.4). These base models are all considered for comparison.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_83",
            "content": "For DocRED, we consider additional competing methods as follows: Two Phase , which first predicts whether the entity pair has a relation and then predicts the relation type. LSR (Nan et al., 2020), which constructs the graph by inducing a latent document-level graph.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_84",
            "content": "Reconstructor (Xu et al., 2021b), which encourages the model to reconstruct a reasoning path during training. DRN (Xu et al., 2021a), which considers different reasoning skills explicitly and uses graph representation and context representation to model the reasoning skills. ATLOP (Zhou et al., 2021), which aggregates contextual information by the Transformer attentions and adopts an adaptive threshold for different entity pairs. DocuNet (Zhang et al., 2021), which models DocRE as a semantic segmentation task.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_85",
            "content": "For DialogRE, we followed Yu et al. ( 2020) and considered BERT and BERT s for comparison, 5 where BERT s prevents a model from overfitting by replacing of the interpersonal augment with a special token.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_86",
            "content": "Implementation Details.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_87",
            "content": "We use the repository 2,3,4,5 of base models to implement our approach. We mostly followed the standard hyperparameters used in the base models. Our SIEF has one hyperparameter \u03b2 in Eqn. (5). It was set to 0.8, and Section 5.2 presents the effect of tuning \u03b2. Our code can be found in Footnote 1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_88",
            "content": "Test Ign F1 F1 Ign F1 F1 DocRE Systems with GloVe LSR (Nan et al., 2020) 48.82 55.17 52.15 54.18 Reconstructor (Xu et al., 2021b) 54.25 55.70 53.25 55.13 DRN (Xu et al., 2021a 54.61 56.49 54.35 56.33 BiLSTM (Yao et al., 2019) 48 (Nan et al., 2020) 52.43 59.00 56.97 59.05 Reconstructor (Xu et al., 2021b) 58.13 60.18 57.12 59.45 DRN (Xu et al., 2021a) 59.33 61.39 59.15 61.37 ATLOP (Zhou et al., 2021) 59.22 61.09 59.31 61.30 DocuNet (Zhang et al., 2021) 59.86 61.83 59.93 61.86 BERT base (Ye et al., 2020) 54",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_89",
            "content": "Results and Analyses",
            "ntype": "title",
            "meta": {
                "section": "5.2"
            }
        },
        {
            "ix": "3-ARR_v1_90",
            "content": "Main results. Table 1 presents the detailed results on the development and test sets of the DocRED dataset. We first compare DocRE systems with GloVe embeddings (Yao et al., 2019). We see that the proposed SIEF method significantly improves the performance of all base models, including the sequence model (i.e., BiLSTM) and graph models (i.e., HeterGSAN and GAIN); the average improvement is 2.05 points in terms of test F1. This shows that SIEF is compatible with both sequence and graph models, indicating the generality and effectiveness of the proposed method. For the DocRE system with BERT base , SIEF also consistently improves the base models, showing that SIEF is complementary to the modern BERT architecture. Especially, combining SIEF and GAIN (Zeng et al., 2020) with BERT base encoding yields state-of-the-art performance in terms of F1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_91",
            "content": "We further conducted experiments on the DialogRE dataset, and compare our approach with the BERT baselines in Yu et al. (2020) the results are consistent with the improvement on DocRED, as our SIEF largely improves F1 and F1 c for both base models. This further confirms the generality of our approach in different domains.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_92",
            "content": "In the rest of this section, we present in-depth analyses to better understand our model with DocRED as the testbed. All base models use GloVe embeddings as opposed to BERT due to efficiency concerns.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_93",
            "content": "Intra-and Inter-Sentence Performance. We breakdown the relation classification performance into intra-sentence reasoning and inter-sentence reasoning. Ideally, if only one sentence is needed to determine the relation of an entity pair, then it belongs to the intra-sentence category; if two or more sentences are needed, then it belongs to the inter-sentence category. We follow Nan et al. (2020) and approximate it by checking whether two entities are mentioned in one sentence.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_94",
            "content": "The results are shown in Table 3. SIEF again consistently improves base models in terms of both Intra-F1 and Inter-F1. However, the improvement on Intra-F1 is larger than that on Inter-F1. This is because our SIEF encourages the model to focus on evidence by removing one sentence at a time, but does not explicitly model sentence relations. Based on this analysis, we plan to extend the SIEF framework with multi-sentence DocRE reasoning in our future work.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_95",
            "content": "Performance of predicting evidence sentences. In our paper, we propose a sentence importance score to measure how much a sentence contributes to the classification without using additional annotation. We evaluate such performance in Table 4 by Precision, Recall, and F1 scores against manually annotated evidence sentences that are provided in the dataset. In this analysis, we do not perform relation prediction, but concern about entity pairs knowingly having certain relations. Specifically, for entity pair (e i h , e it ) with relation j, we calculate the importance score g",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_96",
            "content": "(\u2212n) ij",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_97",
            "content": "for each sentence and cut off evidence/non-evidence sentences with a threshold based on the development F1 score.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_98",
            "content": "As seen, all base models achieve above 60% F1, suggesting that the proposed importance score is indeed indicative for predicting evidence and nonevidence sentences.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_99",
            "content": "With the proposed SIEF framework, the performance improves for all metrics, with an average improvement of 2.95 F1 points across three base models. This further verifies that our SIEF framework not only improves relation extraction performance, but also is able to better detect evidence and non-evidence sentences, which is important for the robustness of machine learning models.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_100",
            "content": "Robustness of DocRE models. We further investigate the robustness of DocRE models by showing the difference between the predicted distributions with and without non-evidence sentences. We show in Figure 5 the scatter plots of the probability P based on the entire document and the probability P",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_101",
            "content": "(\u2212n) ij",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_102",
            "content": "with a random non-evidence sentence removed.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_103",
            "content": "As shown in the figure, the points of the base models (left magenta plots) scatters over a wider range, whereas our SIEF training (right cyan plots) makes them more concentrated on the diagonal, indicating that the prediction P ij on the entire document is mostly the same as P (\u2212n) ij with a nonevidence removed. This shows the robustness of SIEF-trained models, as they are less sensitive to non-evidences sentences for DocRE. Analysis on hyperparameter \u03b2. Our SIEF framework has one hyperaparameter \u03b2 that controls how strict we treat a sentence as evidence or nonevidence (in Section 4.3). We analyze the effect of \u03b2 in Figure 4.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_104",
            "content": "As seen, our SIEF approach consistently benefits the base models with a large range of \u03b2 values. Intuitively, if \u03b2 is too small, very few sentences will be treated as non-evidence and our sentence focusing loss is less effective; if \u03b2 is too large, it has a high false positive rate of non-evidence sentences. Empirically, a moderate \u03b2 around (0.6-0.8) yields the highest performance. From the plots, we also see that our hyperparameter \u03b2 is insensitive to the base models, justifying our design of Eqn. (3).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_105",
            "content": "Sentence importance score VS other heuristics. To investigate the effectiveness of our sentence importance score in Eqn. (3), we compare it with several alternative heuristics: 1) We randomly select half of the sentences as the nonevidence set, denoted by Rand; and 2) We consider the non-evidence set as the sentences without entity mentions, denoted by NoMention.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_106",
            "content": "The results of the performance in terms of F1 and Ign F1 on the development set are shown in Table 5. As seen, the simple heuristic Rand outperforms the base model, as Rand can be thought of as noisy data augmentation. The NoMention heuristic outperforms Rand, as sentences without entity mentions are more likely to be non-evidence. Moroever, SIEF is superior to both Rand and NoMention, showing that our sentence importance scores is a more effective indicator of evidence and non-evidence sentences.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_107",
            "content": "Our sentence focusing loss VS learning from groundtruth. We encourage the DocRE models to generate consistent output probabilities with and without non-evidence (in Section 4.2) by a cross-entropy loss between two soft distributions P ij and",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_108",
            "content": "P (\u2212n) ij .",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_109",
            "content": "To investigate the effect of such a sentence focusing loss, we compare it with an alternative choice: we learn P (\u2212n) ij directly from the groundtruth label r ij .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_110",
            "content": "Table 6 shows the results on the development set in terms of F1 and Ign F1. As seen, both methods can improve the performance of the base models. This confirms that removing non-evidence sentences can serve as a way of data augmentation, boosting the performance of DocRE models. Moreover, we observe that our sentence focusing loss is better than learning from the groundtruth labels, showing that the soft predictions provide more information than one-hot labels, consistent with knowledge distillation literature (Hinton et al., 2015).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_111",
            "content": "Case Study. Figure 6 shows a case study of GAIN and GAIN+SIEF models. For the entity pair (Brad Wilk, Rage Against the Machine), both GAIN and GAIN+SIEF predicts the relation \"MemberOf\", which is consistent with the reference. We see that Sentence 3 is non-evidence, and in principle, it should not affect DocRE prediction in this case. However, the base GAIN model makes a wrong prediction \"not MemberOf\", as the predicted probability is below the threshold, which is determined by validation based on predicted binary probabilities of all relations. By contrast, our SIEF model is able to make correct predictions when different non-evidence sentences are removed, demonstrating its robustness.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_112",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "3-ARR_v1_113",
            "content": "In this paper, we propose a novel Sentence Information Estimation and Focusing (SIEF) approach to document relation extraction (DocRE). We design a sentence importance score and a sentence focusing loss to encourage the model to focus on evidence sentences. The proposed SIEF is a general framework, and can be combined with various base DocRE models. Experimental results show that SIEF consistently improves the performance of base models in different domains, and that it improves the robustness of DocRE models.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "3-ARR_v1_114",
            "content": "Livio Baldini, Nicholas Soares, Jeffrey Fitzgerald, Tom Ling,  Kwiatkowski, Matching the blanks: Distributional similarity for relation learning, 2019, Proceedings of the Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    " Livio Baldini",
                    "Nicholas Soares",
                    "Jeffrey Fitzgerald",
                    "Tom Ling",
                    " Kwiatkowski"
                ],
                "title": "Matching the blanks: Distributional similarity for relation learning",
                "pub_date": "2019",
                "pub_title": "Proceedings of the Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_115",
            "content": "Fenia Christopoulou, Makoto Miwa, Sophia Ananiadou, Connecting the dots: Documentlevel neural relation extraction with edge-oriented graphs, 2019, Proceedings of the Conference on Empirical Methods in Natural Language Processing and the International Joint Conference on Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Fenia Christopoulou",
                    "Makoto Miwa",
                    "Sophia Ananiadou"
                ],
                "title": "Connecting the dots: Documentlevel neural relation extraction with edge-oriented graphs",
                "pub_date": "2019",
                "pub_title": "Proceedings of the Conference on Empirical Methods in Natural Language Processing and the International Joint Conference on Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_116",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "Jacob Devlin",
                    "Ming-Wei Chang",
                    "Kenton Lee",
                    "Kristina Toutanova"
                ],
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "pub_date": "2019",
                "pub_title": "Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_117",
            "content": "George Doddington, Alexis Mitchell, Mark Przybocki, Lance Ramshaw, Stephanie Strassel, Ralph Weischedel, The automatic content extraction (ACE) program -tasks, data, and evaluation, 2004, Proceedings of the Fourth International Conference on Language Resources and Evaluation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "George Doddington",
                    "Alexis Mitchell",
                    "Mark Przybocki",
                    "Lance Ramshaw",
                    "Stephanie Strassel",
                    "Ralph Weischedel"
                ],
                "title": "The automatic content extraction (ACE) program -tasks, data, and evaluation",
                "pub_date": "2004",
                "pub_title": "Proceedings of the Fourth International Conference on Language Resources and Evaluation",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_118",
            "content": "Pankaj Gupta, Subburam Rajaram, Hinrich Sch\u00fctze, Thomas Runkler, Neural relation extraction within and across sentence boundaries, 2019, Proceedings of the Association for the Advance of Artificial Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Pankaj Gupta",
                    "Subburam Rajaram",
                    "Hinrich Sch\u00fctze",
                    "Thomas Runkler"
                ],
                "title": "Neural relation extraction within and across sentence boundaries",
                "pub_date": "2019",
                "pub_title": "Proceedings of the Association for the Advance of Artificial Intelligence",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_119",
            "content": "Geoffrey Hinton, Oriol Vinyals, Jeffrey Dean, Distilling the knowledge in a neural network, 2015, Proceedings of the Annual Conference on Neural Information Processing Systems Deep Learning and Representation Learning Workshop, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "Geoffrey Hinton",
                    "Oriol Vinyals",
                    "Jeffrey Dean"
                ],
                "title": "Distilling the knowledge in a neural network",
                "pub_date": "2015",
                "pub_title": "Proceedings of the Annual Conference on Neural Information Processing Systems Deep Learning and Representation Learning Workshop",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_120",
            "content": "Quzhe Huang, Shengqi Zhu, Yansong Feng, Yuan Ye, Yuxuan Lai, Dongyan Zhao, Three sentences are all you need: Local path enhanced document relation extraction, 2021, Proceedings of the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "Quzhe Huang",
                    "Shengqi Zhu",
                    "Yansong Feng",
                    "Yuan Ye",
                    "Yuxuan Lai",
                    "Dongyan Zhao"
                ],
                "title": "Three sentences are all you need: Local path enhanced document relation extraction",
                "pub_date": "2021",
                "pub_title": "Proceedings of the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_121",
            "content": "Jiao Li, Yueping Sun, Robin Johnson, Daniela Sciaky, Chih-Hsuan Wei, Robert Leaman, Allan Davis, Carolyn Mattingly, Thomas Wiegers, Zhiyong Lu, BioCreative V CDR task corpus: A resource for chemical disease relation extraction, 2016, Database: The Journal of Biological Databases and Curation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Jiao Li",
                    "Yueping Sun",
                    "Robin Johnson",
                    "Daniela Sciaky",
                    "Chih-Hsuan Wei",
                    "Robert Leaman",
                    "Allan Davis",
                    "Carolyn Mattingly",
                    "Thomas Wiegers",
                    "Zhiyong Lu"
                ],
                "title": "BioCreative V CDR task corpus: A resource for chemical disease relation extraction",
                "pub_date": "2016",
                "pub_title": "Database: The Journal of Biological Databases and Curation",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_122",
            "content": "Mike Mintz, Steven Bills, Rion Snow, Daniel Jurafsky, Distant supervision for relation extraction without labeled data, 2009, Proceedings of the Joint Conference of the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Mike Mintz",
                    "Steven Bills",
                    "Rion Snow",
                    "Daniel Jurafsky"
                ],
                "title": "Distant supervision for relation extraction without labeled data",
                "pub_date": "2009",
                "pub_title": "Proceedings of the Joint Conference of the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_123",
            "content": "Guoshun Nan, Zhijiang Guo, Ivan Sekulic, Wei Lu, Reasoning with latent structure refinement for document-level relation extraction, 2020, Proceedings of the Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Guoshun Nan",
                    "Zhijiang Guo",
                    "Ivan Sekulic",
                    "Wei Lu"
                ],
                "title": "Reasoning with latent structure refinement for document-level relation extraction",
                "pub_date": "2020",
                "pub_title": "Proceedings of the Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_124",
            "content": "Patrick Pantel, Marco Pennacchiotti, Espresso: Leveraging generic patterns for automatically harvesting semantic relations, 2006, Proceedings of the International Conference on Computational Linguistics and Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Patrick Pantel",
                    "Marco Pennacchiotti"
                ],
                "title": "Espresso: Leveraging generic patterns for automatically harvesting semantic relations",
                "pub_date": "2006",
                "pub_title": "Proceedings of the International Conference on Computational Linguistics and Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_125",
            "content": "Chris Quirk, Hoifung Poon, Distant supervision for relation extraction beyond the sentence boundary, 2017, Proceedings of the Conference of the European Chapter, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Chris Quirk",
                    "Hoifung Poon"
                ],
                "title": "Distant supervision for relation extraction beyond the sentence boundary",
                "pub_date": "2017",
                "pub_title": "Proceedings of the Conference of the European Chapter",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "3-ARR_v1_126",
            "content": "Linfeng Song, Yue Zhang, Daniel Gildea, Mo Yu, Zhiguo Wang, Jinsong Su, Leveraging dependency forest for neural medical relation extraction, 2019, Proceedings of the Conference on Empirical Methods in Natural Language Processing and the International Joint Conference on Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Linfeng Song",
                    "Yue Zhang",
                    "Daniel Gildea",
                    "Mo Yu",
                    "Zhiguo Wang",
                    "Jinsong Su"
                ],
                "title": "Leveraging dependency forest for neural medical relation extraction",
                "pub_date": "2019",
                "pub_title": "Proceedings of the Conference on Empirical Methods in Natural Language Processing and the International Joint Conference on Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_127",
            "content": "Daniil Sorokin, Iryna Gurevych, Contextaware representations for knowledge base relation extraction, 2017, Proceedings of the Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    "Daniil Sorokin",
                    "Iryna Gurevych"
                ],
                "title": "Contextaware representations for knowledge base relation extraction",
                "pub_date": "2017",
                "pub_title": "Proceedings of the Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_128",
            "content": "UNKNOWN, None, 2019, Fine-tune BERT for DocRED with two-step process, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Fine-tune BERT for DocRED with two-step process",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_129",
            "content": "Zhepei Wei, Jianlin Su, Yue Wang, Yuan Tian, Yi Chang, A novel cascade binary tagging framework for relational triple extraction, 2020, Proceedings of the Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Zhepei Wei",
                    "Jianlin Su",
                    "Yue Wang",
                    "Yuan Tian",
                    "Yi Chang"
                ],
                "title": "A novel cascade binary tagging framework for relational triple extraction",
                "pub_date": "2020",
                "pub_title": "Proceedings of the Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_130",
            "content": "Minguang Xiao, Cong Liu, Semantic relation classification via hierarchical recurrent neural network with attention, 2016, Proceedings of the International Conference on Computational Linguistics: Technical Papers, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "Minguang Xiao",
                    "Cong Liu"
                ],
                "title": "Semantic relation classification via hierarchical recurrent neural network with attention",
                "pub_date": "2016",
                "pub_title": "Proceedings of the International Conference on Computational Linguistics: Technical Papers",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_131",
            "content": "Wang Xu, Kehai Chen, Tiejun Zhao, Discriminative reasoning for document-level relation extraction, 2021, Findings of the Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Wang Xu",
                    "Kehai Chen",
                    "Tiejun Zhao"
                ],
                "title": "Discriminative reasoning for document-level relation extraction",
                "pub_date": "2021",
                "pub_title": "Findings of the Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_132",
            "content": "Wang Xu, Kehai Chen, Tiejun Zhao, Document-level relation extraction with reconstruction, 2021, Proceedings of the Association for the Advance of Artificial Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Wang Xu",
                    "Kehai Chen",
                    "Tiejun Zhao"
                ],
                "title": "Document-level relation extraction with reconstruction",
                "pub_date": "2021",
                "pub_title": "Proceedings of the Association for the Advance of Artificial Intelligence",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_133",
            "content": "Yan Xu, Ran Jia, Lili Mou, Ge Li, Yunchuan Chen, Yangyang Lu, Zhi Jin, Improved relation classification by deep recurrent neural networks with data augmentation, 2016, Proceedings of the International Conference on Computational Linguistics: Technical Papers, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "Yan Xu",
                    "Ran Jia",
                    "Lili Mou",
                    "Ge Li",
                    "Yunchuan Chen",
                    "Yangyang Lu",
                    "Zhi Jin"
                ],
                "title": "Improved relation classification by deep recurrent neural networks with data augmentation",
                "pub_date": "2016",
                "pub_title": "Proceedings of the International Conference on Computational Linguistics: Technical Papers",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_134",
            "content": "Yan Xu, Lili Mou, Ge Li, Yunchuan Chen, Hao Peng, Zhi Jin, Classifying relations via long short term memory networks along shortest dependency paths, 2015, Proceedings of the Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Yan Xu",
                    "Lili Mou",
                    "Ge Li",
                    "Yunchuan Chen",
                    "Hao Peng",
                    "Zhi Jin"
                ],
                "title": "Classifying relations via long short term memory networks along shortest dependency paths",
                "pub_date": "2015",
                "pub_title": "Proceedings of the Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_135",
            "content": "Yuan Yao, Deming Ye, Peng Li, Xu Han, Yankai Lin, Zhenghao Liu, Zhiyuan Liu, Lixin Huang, Jie Zhou, Maosong Sun, DocRED: A large-scale document-level relation extraction dataset, 2019, Proceedings of the Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "Yuan Yao",
                    "Deming Ye",
                    "Peng Li",
                    "Xu Han",
                    "Yankai Lin",
                    "Zhenghao Liu",
                    "Zhiyuan Liu",
                    "Lixin Huang",
                    "Jie Zhou",
                    "Maosong Sun"
                ],
                "title": "DocRED: A large-scale document-level relation extraction dataset",
                "pub_date": "2019",
                "pub_title": "Proceedings of the Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_136",
            "content": "Deming Ye, Yankai Lin, Jiaju Du, Zhenghao Liu, Peng Li, Maosong Sun, Zhiyuan Liu, Coreferential reasoning learning for language representation, 2020, Proceedings of the Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Deming Ye",
                    "Yankai Lin",
                    "Jiaju Du",
                    "Zhenghao Liu",
                    "Peng Li",
                    "Maosong Sun",
                    "Zhiyuan Liu"
                ],
                "title": "Coreferential reasoning learning for language representation",
                "pub_date": "2020",
                "pub_title": "Proceedings of the Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_137",
            "content": "Dian Yu, Kai Sun, Claire Cardie, Dong Yu, Dialogue-based relation extraction, 2020, Proceedings of the Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Dian Yu",
                    "Kai Sun",
                    "Claire Cardie",
                    "Dong Yu"
                ],
                "title": "Dialogue-based relation extraction",
                "pub_date": "2020",
                "pub_title": "Proceedings of the Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_138",
            "content": "Mo Yu, Wenpeng Yin,  Kazi Saidul Hasan, Bing Cicero Dos Santos, Bowen Xiang,  Zhou, Improved neural relation detection for knowledge base question answering, 2017, Proceedings of the Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Mo Yu",
                    "Wenpeng Yin",
                    " Kazi Saidul Hasan",
                    "Bing Cicero Dos Santos",
                    "Bowen Xiang",
                    " Zhou"
                ],
                "title": "Improved neural relation detection for knowledge base question answering",
                "pub_date": "2017",
                "pub_title": "Proceedings of the Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_139",
            "content": "Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou, Jun Zhao, Relation classification via convolutional deep neural network, 2014, Proceedings of the International Conference on Computational Linguistics: Technical Papers, .",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Daojian Zeng",
                    "Kang Liu",
                    "Siwei Lai",
                    "Guangyou Zhou",
                    "Jun Zhao"
                ],
                "title": "Relation classification via convolutional deep neural network",
                "pub_date": "2014",
                "pub_title": "Proceedings of the International Conference on Computational Linguistics: Technical Papers",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_140",
            "content": "Shuang Zeng, Runxin Xu, Baobao Chang, Lei Li, Double graph based reasoning for document-level relation extraction, 2020, Proceedings of the Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": [
                    "Shuang Zeng",
                    "Runxin Xu",
                    "Baobao Chang",
                    "Lei Li"
                ],
                "title": "Double graph based reasoning for document-level relation extraction",
                "pub_date": "2020",
                "pub_title": "Proceedings of the Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_141",
            "content": "Ningyu Zhang, Xiang Chen, Xin Xie, Shumin Deng, Chuanqi Tan, Mosha Chen, Fei Huang, Luo Si, Huajun Chen, Document-level relation extraction as semantic segmentation, 2021, Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": [
                    "Ningyu Zhang",
                    "Xiang Chen",
                    "Xin Xie",
                    "Shumin Deng",
                    "Chuanqi Tan",
                    "Mosha Chen",
                    "Fei Huang",
                    "Luo Si",
                    "Huajun Chen"
                ],
                "title": "Document-level relation extraction as semantic segmentation",
                "pub_date": "2021",
                "pub_title": "Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_142",
            "content": "Wenxuan Zhou, Kevin Huang, Tengyu Ma, Jing Huang, Document-level relation extraction with adaptive thresholding and localized context pooling, 2021, Proceedings of the Association for the Advance of Artificial Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Wenxuan Zhou",
                    "Kevin Huang",
                    "Tengyu Ma",
                    "Jing Huang"
                ],
                "title": "Document-level relation extraction with adaptive thresholding and localized context pooling",
                "pub_date": "2021",
                "pub_title": "Proceedings of the Association for the Advance of Artificial Intelligence",
                "pub": null
            }
        },
        {
            "ix": "3-ARR_v1_143",
            "content": "Hao Zhu, Yankai Lin, Zhiyuan Liu, Jie Fu, Graph neural networks with generated parameters for relation extraction, 2019, Proceedings of the Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "Hao Zhu",
                    "Yankai Lin",
                    "Zhiyuan Liu",
                    "Jie Fu"
                ],
                "title": "Graph neural networks with generated parameters for relation extraction",
                "pub_date": "2019",
                "pub_title": "Proceedings of the Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "3-ARR_v1_0@0",
            "content": "Document-Level Relation Extraction with Sentences Importance Estimation and Focusing",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_0",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_2@0",
            "content": "Document-level relation extraction (DocRE) aims to determine the relation between two entities from a document of multiple sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_2",
            "start": 0,
            "end": 132,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_2@1",
            "content": "Recent studies typically represent the entire document by sequence-or graphbased models to predict the relations of all entity pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_2",
            "start": 134,
            "end": 266,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_2@2",
            "content": "However, we find that such a model is not robust and exhibits bizarre behaviors: it predicts correctly when an entire test document is fed as input, but errs when non-evidence sentences are removed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_2",
            "start": 268,
            "end": 465,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_2@3",
            "content": "To this end, we propose a Sentence Importance Estimation and Focusing (SIEF) framework for DocRE, where we design a sentence importance score and a sentence focusing loss, encouraging DocRE models to focus on evidence sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_2",
            "start": 467,
            "end": 694,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_2@4",
            "content": "Experimental results on two domains show that our SIEF not only improves overall performance, but also makes DocRE models more robust.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_2",
            "start": 696,
            "end": 829,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_2@5",
            "content": "Moreover, SIEF is a general framework, shown to be effective when combined with a variety of base DocRE models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_2",
            "start": 831,
            "end": 941,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_2@6",
            "content": "1",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_2",
            "start": 943,
            "end": 943,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_4@0",
            "content": "Document-level relation extraction (DocRE) aims to predict entity relations across multiple sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_4",
            "start": 0,
            "end": 101,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_4@1",
            "content": "It plays a crucial role in a variety of knowledgebased applications, such as question answering (Sorokin and Gurevych, 2017) and large-scale knowledge graph construction (Baldini Soares et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_4",
            "start": 103,
            "end": 302,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_4@2",
            "content": "Different from sentence-level relation extraction (Zeng et al., 2014;Xiao and Liu, 2016;Yu et al., 2017;Song et al., 2019), the supporting evidence in the DocRE setting may involve multiple sentences scattering in the document.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_4",
            "start": 304,
            "end": 530,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_4@3",
            "content": "Thus, DocRE is more a realistic setting, attracting increasing attention in the field of information extraction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_4",
            "start": 532,
            "end": 643,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_4@4",
            "content": "Most recent DocRE studies use the entire document as a clue to predict the relations of all entity pairs without concerning where the evidence is located (Nan et al., 2020;Zeng et al., 2020;Xu et al., 2021a,b).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_4",
            "start": 645,
            "end": 854,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_4@5",
            "content": "However, one can identify the relation of a specific entity pair from a few sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_4",
            "start": 856,
            "end": 941,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_4@6",
            "content": "show that irrelevant sentences in the document would hinder the performance of the model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_4",
            "start": 943,
            "end": 1031,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_5@0",
            "content": "Moreover, we observe that a DocRE model, trained on the entire document, may err when non-evidence sentences are removed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_5",
            "start": 0,
            "end": 120,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_5@1",
            "content": "In Figure 1, for example, we need to identify the relation \"MemberOf\" between the entities Brad Wilk and Rage Against the Machine.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_5",
            "start": 122,
            "end": 251,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_5@2",
            "content": "The evidence sentences are [1,2], and humans can easily identify such a relation when reading sentences [1,2] only.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_5",
            "start": 253,
            "end": 367,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_5@3",
            "content": "However, the recent DocRE model GAIN (Zeng et al., 2020) identifies the relation \"MemberOf\" correctly from the entire document [1,2,3], but predicts \"not MemberOf\" from sentences [1,2].",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_5",
            "start": 369,
            "end": 553,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_5@4",
            "content": "Intuitively, removing sentence [3] should not change the results, as this sentence does not provide information regarding whether \"not MemberOf\" holds or not for the two entities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_5",
            "start": 555,
            "end": 733,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_5@5",
            "content": "Such model behaviors are undesired, because it shows that the model is not robust and lacks interpretability.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_5",
            "start": 735,
            "end": 843,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_6@0",
            "content": "To this end, we propose a novel Sentence Importance Estimation and Focusing (SIEF) framework to encourage the model to focus on evidence sentences for predicting the relation of an entity pair.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_6",
            "start": 0,
            "end": 192,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_6@1",
            "content": "Specifically, we first evaluate the importance of each sentence by the difference between the output probabilities of the document with and without this sentence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_6",
            "start": 194,
            "end": 355,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_6@2",
            "content": "If the predicted probability of a relation does not change, or even increases, when a sentence is removed, it typically indicates that the sentence is non-evidence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_6",
            "start": 357,
            "end": 520,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_6@3",
            "content": "Then, we propose an auxiliary loss to encourage the model to produce the same output distribution, when the entire document is fed as input and when a non-evidence sentence is removed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_6",
            "start": 522,
            "end": 705,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_6@4",
            "content": "In this way, the model pays more attention to the evidence sentences for the classification.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_6",
            "start": 707,
            "end": 798,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_6@5",
            "content": "Our SIEF method is a general framework that can be combined with different underlying DocRE models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_6",
            "start": 800,
            "end": 898,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_7@0",
            "content": "We evaluated the generality and effectiveness of our approach on the large-scale DocRED dataset (Yao et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_7",
            "start": 0,
            "end": 114,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_7@1",
            "content": "Experimental results show that the proposed approach combines well with various recent DocRE models and significantly improves the performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_7",
            "start": 116,
            "end": 258,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_7@2",
            "content": "Moreover, the proposed approach outperforms a variety of models on DocRED dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_7",
            "start": 260,
            "end": 341,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_7@3",
            "content": "We further evaluated our approach on a dialogue relation extraction dataset, DialogRE (Yu et al., 2020); our SIEF yields consistent improvement, showing the generality of our approach in different domains.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_7",
            "start": 343,
            "end": 547,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_8@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_8",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_9@0",
            "content": "Relation extraction (RE) can be categorized by its granularity, such as sentence-level (Doddington et al., 2004;Xu et al., 2016; and document-level (Gupta et al., 2019;Zhu et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_9",
            "start": 0,
            "end": 185,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_9@1",
            "content": "Early work mainly focuses on sentencelevel relation extraction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_9",
            "start": 187,
            "end": 249,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_9@2",
            "content": "Pantel and Pennacchiotti (2006) propose a rule-based approach, and Mintz et al. (2009) design features for classifying relations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_9",
            "start": 251,
            "end": 379,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_9@3",
            "content": "In the past several years, neural networks have become a prevailing approach for relation extraction (Xu et al., 2015;Song et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_9",
            "start": 381,
            "end": 517,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_10@0",
            "content": "Document-level relation extraction (DocRE) is attracting increasing attention in the community, as it considers the interactions across entity mentions expressed in different sentences Yao et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_10",
            "start": 0,
            "end": 202,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_10@1",
            "content": "Compared with the sentence level, DocRE requires the model collecting and integrating inter-sentence information effectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_10",
            "start": 204,
            "end": 328,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_10@2",
            "content": "Recent efforts design sequence-based and graphbased models to address such a problem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_10",
            "start": 330,
            "end": 414,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_11@0",
            "content": "Sequence-based DocRE models encode a document by the sequence of words and/or sentences, for example, using the Transformer architecture (Devlin et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_11",
            "start": 0,
            "end": 158,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_11@1",
            "content": "Zhou et al. (2021) argue that the Transformer attentions are able to extract useful contextual features across sentences for DocRE, and they adopt an adaptive threshold for each entity pair.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_11",
            "start": 160,
            "end": 349,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_11@2",
            "content": "Zhang et al. (2021) model DocRE as a semantic segmentation task and predict an entity-level relation matrix to capture local and global information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_11",
            "start": 351,
            "end": 498,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_12@0",
            "content": "Graph-based DocRE models abstract a document by graphical structures.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_12",
            "start": 0,
            "end": 68,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_12@1",
            "content": "For example, a node can be a sentence, a mention, and/or an entity; their co-occurrence is modeled by an edge.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_12",
            "start": 70,
            "end": 179,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_12@2",
            "content": "Then graph neural networks are applied to aggregate inter-sentence information (Quirk and Poon, 2017;Christopoulou et al., 2019;Zeng et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_12",
            "start": 181,
            "end": 327,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_12@3",
            "content": "Zeng et al. (2020) construct double graphs, applying graph neural networks to mention-document graphs and performing path reasoning over entity graphs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_12",
            "start": 329,
            "end": 479,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_12@4",
            "content": "Xu et al. (2021a) explicitly incorporate logical reasoning, commonsense reasoning, and coreference reasoning into DocRE, based on both sequence and graph features.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_12",
            "start": 481,
            "end": 643,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_13@0",
            "content": "Different from previous work, our paper proposes SIEF as a general framework that can be combined with various sequence-based and graph-based DocRE models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_13",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_13@1",
            "content": "In our approach, we propose a sentence importance score and a sentence focusing loss to encourage the model to focus on evidence sentences, improving the robustness and the overall performance of DocRE models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_13",
            "start": 156,
            "end": 364,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_14@0",
            "content": "Problem Definition",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_14",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_15@0",
            "content": "In this section, we present formulation of document relation extraction (DocRE).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_15",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_15@1",
            "content": "Consider an unstructured document comprising N sentences, D = {s 1 , s 2 , \u2022 \u2022 \u2022 , s N }, where each sentence s n are a sequence words.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_15",
            "start": 81,
            "end": 215,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_15@2",
            "content": "Typically, the document D is annotated with entity mentions, each mention (e.g., U.S. and USA) labeled by its conceptual entity e and its entity type (e.g., location).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_15",
            "start": 217,
            "end": 383,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_16@0",
            "content": "A DocRE model F is usually formulated as multi-label classification (Yao et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_16",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_16@1",
            "content": "F j predicts whether the jth relation holds for the ith marked entity pair in a document, given by",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_16",
            "start": 88,
            "end": 185,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_17@0",
            "content": "P ij = F j (D, e i h , e it ) = Pr[r ij = 1|D, e i h , e it ]",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_17",
            "start": 0,
            "end": 60,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_18@0",
            "content": "(1) where e i h is the head entity and e it is the tail entity; r ij \u2208 {0, 1} is the groundtruth label regarding",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_18",
            "start": 0,
            "end": 111,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_19@0",
            "content": "[1] The Sacramento Bee is a daily newspaper published in Sacramento, California, in the United States.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_19",
            "start": 0,
            "end": 101,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_20@0",
            "content": "[2] Since its founding in 1857, The Bee has become the largest newspaper in Sacramento, the fifth largest newspaper in California, and the 27th largest paper in the U.S.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_20",
            "start": 0,
            "end": 168,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_21@0",
            "content": "[3] The Bee is the flagship of the American McClatchy Company. entity pair i and relation j.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_21",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_22@0",
            "content": "To train the model, the binary cross-entropy loss is used as the objective for parameter estimation:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_22",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_23@0",
            "content": "L rel = \u2212 D\u2208C i h =it j\u2208R {r ij log P ij +(1 \u2212 r ij ) log(1 \u2212 P ij )} (2)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_23",
            "start": 0,
            "end": 72,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_24@0",
            "content": "where C denotes the entire corpus and R denotes the set of relation types.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_24",
            "start": 0,
            "end": 73,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_25@0",
            "content": "During inference, we obtain the relation(s) of a given entity pair by thresholding the predicted probabilities, following most previous work (Yao et al., 2019;Zhou et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_25",
            "start": 0,
            "end": 177,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_26@0",
            "content": "Methodology",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_26",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_27@0",
            "content": "In this section, we will describe our approach in detail.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_27",
            "start": 0,
            "end": 56,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_27@1",
            "content": "The overview of our framework is shown in Figure 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_27",
            "start": 58,
            "end": 108,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_27@2",
            "content": "First, we describe the estimation of sentence importance in Section 4.1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_27",
            "start": 110,
            "end": 181,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_27@3",
            "content": "Sentences with low importance scores are treated as nonevidence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_27",
            "start": 183,
            "end": 246,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_27@4",
            "content": "Then, Sections 4.2 and 4.3 present our approach encouraging the model to produce the same output distribution, when the entire document is fed as input and when non-evidence sentences are removed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_27",
            "start": 248,
            "end": 443,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_27@5",
            "content": "Section 4.4 further presents the architectures of DocRE models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_27",
            "start": 445,
            "end": 507,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_28@0",
            "content": "Sentence Importance Estimation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_28",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_29@0",
            "content": "We estimate the importance of each sentence for a specific entity pair.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_29",
            "start": 0,
            "end": 70,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_29@1",
            "content": "Low-scored sentences will be treated as non-evidence, and in principle, can be removed without changing DocRE predictions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_29",
            "start": 72,
            "end": 193,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_30@0",
            "content": "We propose a sentence importance score based on the DocRE predictions with and without the sentence in question.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_30",
            "start": 0,
            "end": 111,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_30@1",
            "content": "Our observation is that the relation extraction task is usually monotonic to evidence, i.e., (non-strictly) more relations will be predicted with more sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_30",
            "start": 113,
            "end": 273,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_30@2",
            "content": "If we remove a sentence and the predicted probability of a relation decreases, then the sentence is likely to be the evidence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_30",
            "start": 275,
            "end": 400,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_30@3",
            "content": "If the predicted probability does not change, then the sentence is likely to be nonevidence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_30",
            "start": 402,
            "end": 493,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_30@4",
            "content": "Moreover, the predicted probability may sometimes increase when a sentence is removed, in which case the DocRE model is not robust, as this violates monotonicity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_30",
            "start": 495,
            "end": 656,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_31@0",
            "content": "Formally, we consider removing one sentence at a time, and the document with the nth sentence removed is denoted by",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_31",
            "start": 0,
            "end": 114,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_32@0",
            "content": "D(\u2212n) = {s 1 , \u2022 \u2022 \u2022 , s n\u22121 , s n+1 , \u2022 \u2022 \u2022 , s N }.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_32",
            "start": 0,
            "end": 52,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_33@0",
            "content": "For a DocRE model F , we obtain the classification probabilities P ij = F j (D, e i h , e it ) based on the original document, and",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_33",
            "start": 0,
            "end": 129,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_34@0",
            "content": "P (\u2212n) ij = F j ( D(\u2212n) , e i h , e it ) with sentence n removed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_34",
            "start": 0,
            "end": 64,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_35@0",
            "content": "We propose the importance score as",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_35",
            "start": 0,
            "end": 33,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_36@0",
            "content": "g (\u2212n) ij = P ij log P ij P (\u2212n) ij (3)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_36",
            "start": 0,
            "end": 38,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_37@0",
            "content": "The formula appears similar to Kullback-Leibler (KL) divergence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_37",
            "start": 0,
            "end": 63,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_37@1",
            "content": "However, we only take one term in the KL summation, because the KL divergence, albeit asymmetric in its two arguments, cannot model the increase or decrease of",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_37",
            "start": 65,
            "end": 223,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_38@0",
            "content": "P (\u2212n) ij , whereas our g (\u2212n) ij",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_38",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_39@0",
            "content": "is monotonically decreasing with",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_39",
            "start": 0,
            "end": 31,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_40@0",
            "content": "P (\u2212n) ij .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_40",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_41@0",
            "content": "Compared with a naive difference or ratio between P ij and",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_41",
            "start": 0,
            "end": 57,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_42@0",
            "content": "P (\u2212n) ij",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_42",
            "start": 0,
            "end": 8,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_43@0",
            "content": ", we find that our KL-like score is more robust in the scale of P ij when determining non-evidence sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_43",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_44@0",
            "content": "We treat a sentence n as non-evidence if g",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_44",
            "start": 0,
            "end": 41,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_45@0",
            "content": "(\u2212n) ij",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_45",
            "start": 0,
            "end": 6,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_46@0",
            "content": "< \u03b2 for a thresholding hyperparameter \u03b2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_46",
            "start": 0,
            "end": 39,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_46@1",
            "content": "The resulting set of non-evidence sentences is denoted by K ij for the an entity pair (e i h , e it ) and relation j.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_46",
            "start": 41,
            "end": 157,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_47@0",
            "content": "Sentence Focusing Loss",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_47",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_48@0",
            "content": "We propose a sentence focusing loss to encourage the model to produce the same output distribution when the entire document is fed as input and when non-evidence sentences are removed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_48",
            "start": 0,
            "end": 183,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_49@0",
            "content": "Ideally, the predicted probability should remain the same if we remove any combination of the sentences in K ij .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_49",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_49@1",
            "content": "Therefore, we penalize the extent to which the predicted probability is changed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_49",
            "start": 114,
            "end": 193,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_50@0",
            "content": "We propose the sentence focusing loss as:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_50",
            "start": 0,
            "end": 40,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_51@0",
            "content": "L sf = \u2212 D\u2208C i h =it j\u2208R J ij \u2286K ij {P ij log( P (\u2212J ij ) ij ) +(1 \u2212 P ij ) log(1 \u2212 P (\u2212J i ) ij )} (4) where J ij is a subset of K ij and P (\u2212J ij ) ij = F j (D\\J ij , e i h , e it ) is the predicted probability with J ij removed from D. And the final loss is L = L rel + L sf .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_51",
            "start": 0,
            "end": 278,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_52@0",
            "content": "Essentially, our sentence focusing loss ensures P ij is close to",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_52",
            "start": 0,
            "end": 63,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_53@0",
            "content": "P (\u2212J ij ) ij",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_53",
            "start": 0,
            "end": 12,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_54@0",
            "content": ", which intuitively makes sense because non-evidence sentences should not affect the prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_54",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_54@1",
            "content": "Our approach can also be thought of as a way of data augmentation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_54",
            "start": 97,
            "end": 162,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_54@2",
            "content": "However, compared with one-hot groundtruth labels, our sentence focusing loss works with soft labels P ij and",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_54",
            "start": 164,
            "end": 272,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_55@0",
            "content": "P (\u2212J ij ) ij",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_55",
            "start": 0,
            "end": 12,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_56@0",
            "content": ", which are believed to contain more information (Hinton et al., 2015), and our gradient propagates to both P ij and",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_56",
            "start": 0,
            "end": 115,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_57@0",
            "content": "P (\u2212J ij ) ij",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_57",
            "start": 0,
            "end": 12,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_58@0",
            "content": "for training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_58",
            "start": 0,
            "end": 12,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_58@1",
            "content": "The calculation of Eqn. ( 4) is time-and resourceconsuming, because the number of the subsets J ij grows combinatorially with the number of nonevidence sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_58",
            "start": 14,
            "end": 175,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_58@2",
            "content": "To this end, we propose a simplified training strategy to approximate Eqn. (4) in the next subsection.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_58",
            "start": 177,
            "end": 278,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_59@0",
            "content": "Training Strategy",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_59",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_60@0",
            "content": "We propose a strategy to simplify the calculation and the training procedure.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_60",
            "start": 0,
            "end": 76,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_60@1",
            "content": "Concretely, we only remove one non-evidence sentence in K ij at a time instead of a subset of J ij \u2286 K ij , and we aggregate the effect of different non-evidence sentences by:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_60",
            "start": 78,
            "end": 252,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_61@0",
            "content": "L sf = \u2212 D\u2208C N n=1 i h =it j\u2208R I(g (\u2212n) ij < \u03b2) {P ij log( P (\u2212n) ij ) + (1 \u2212 P ij ) log(1 \u2212 P (\u2212n) ij )}",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_61",
            "start": 0,
            "end": 104,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_62@0",
            "content": "(5) where I is the indicator function.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_62",
            "start": 0,
            "end": 37,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_62@1",
            "content": "Essentially, we linearly approximate the combination of multiple non-evidence sentences in (4) by an outer summation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_62",
            "start": 39,
            "end": 155,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_62@2",
            "content": "In this way, the number of terms does not grow combinatorially, but linearly w.r.t. N .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_62",
            "start": 157,
            "end": 243,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_63@0",
            "content": "In implementation, we further simply the summation over n by Monte Carlo sampling of a randomly selected sentence n in each gradient update.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_63",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_63@1",
            "content": "The loss is reformulated as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_63",
            "start": 141,
            "end": 176,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_64@0",
            "content": "L sf = \u2212 D\u2208C i h =it j\u2208R I(g (\u2212n) ij < \u03b2) {P ij log( P (\u2212n) ij ) + (1 \u2212 P ij ) log(1 \u2212 P (\u2212n) ij )} (6)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_64",
            "start": 0,
            "end": 102,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_65@0",
            "content": "As seen, we need to forward the base models twice in each update, with and without the sentence n. propose a similar idea but train different entity pairs in a document based on different sets of sentences; all sentence are processed repeatedly among entity pairs in a document.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_65",
            "start": 0,
            "end": 277,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_65@1",
            "content": "Their approach is much computationally slower than ours.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_65",
            "start": 279,
            "end": 334,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_66@0",
            "content": "To sum up, the proposed SIEF framework identifies non-evidence sentences and penalizes the difference of predicted probabilities when a nonevidence sentence is removed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_66",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_66@1",
            "content": "Our approach is a generic framework and can be adapted to various DocRE model easily, without introducing extra parameters into the model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_66",
            "start": 169,
            "end": 306,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_67@0",
            "content": "DocRE Model Architectures",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_67",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_68@0",
            "content": "Our SIEF can be applied to various base DocRE models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_68",
            "start": 0,
            "end": 52,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_68@1",
            "content": "To evaluate its generality, we consider the following recent models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_68",
            "start": 54,
            "end": 121,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_69@0",
            "content": "BiLSTM (Yao et al., 2019) 2 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_69",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_69@1",
            "content": "A bi-directional long short term memory (BiLSTM) encodes the document, and an entity is representated by BiLSTM's hidden states, averaged over entity mentions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_69",
            "start": 30,
            "end": 188,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_69@2",
            "content": "The head and tail entity representations are fed to a multi-layer perceptron (MLP) for relation extraction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_69",
            "start": 190,
            "end": 296,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_70@0",
            "content": "BERT base (Devlin et al., 2019) 3 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_70",
            "start": 0,
            "end": 34,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_70@1",
            "content": "A pre-trained language model is used for document encoding.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_70",
            "start": 36,
            "end": 94,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_71@0",
            "content": "HeterGSAN (Xu et al., 2021b) 4 . HeterGSAN is a recent graph-based DocRED model, which constructs a heterogeneous graph of sentence, mention, and entity nodes; it uses graph neural networks for relation extraction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_71",
            "start": 0,
            "end": 213,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_72@0",
            "content": "GAIN (Zeng et al., 2020) 3 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_72",
            "start": 0,
            "end": 27,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_72@1",
            "content": "GAIN constructs two graphs: mention-document graphs and entity graphs separately, and performs graph and path reasonings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_72",
            "start": 29,
            "end": 149,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_72@2",
            "content": "When combining our SIEF with GAIN, we achieve the best performance among all the base models with SIEF on DocRED.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_72",
            "start": 151,
            "end": 263,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_72@3",
            "content": "Thus, we will explain this model in more detail.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_72",
            "start": 265,
            "end": 312,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_73@0",
            "content": "Essentially, a node in the mention-document graph is either a mention or a document.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_73",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_73@1",
            "content": "The mentions are connected to its document, and two mentions are connected if they co-occur in one sentence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_73",
            "start": 85,
            "end": 192,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_73@2",
            "content": "In the entity graph, two entities are connected if they are mentioned in one sentence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_73",
            "start": 194,
            "end": 279,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_73@3",
            "content": "To classify the relation, GNN is applied to the mentiondocument graph, enhanced with path information in the entity graph, shown in Figure 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_73",
            "start": 281,
            "end": 421,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_74@0",
            "content": "When combining SIEF with GAIN, we randomly remove one sentence from the document.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_74",
            "start": 0,
            "end": 80,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_74@1",
            "content": "The corresponding nodes and edges are removed in the GAIN's graphs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_74",
            "start": 82,
            "end": 148,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_74@2",
            "content": "Then we obtain the output probabilities with and without the sentence, P ij and 3) is below a threshold \u03b2, the sentence is treated as non-evidence for the entity pair (e i h , e it ) and relation j. We apply the sentence focusing loss Eqn. (4) to improve the robustness.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_74",
            "start": 150,
            "end": 419,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_75@0",
            "content": "P (\u2212n) ij separately. If the sentence important score g (\u2212n) ij in Eqn. (",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_75",
            "start": 0,
            "end": 72,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_76@0",
            "content": "For prediction, we apply the trained DocRE model to the entire document, because with our approach the model is already robust when nonevidence sentences are presented.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_76",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_76@1",
            "content": "Empirical results will show that our SIEF consistently improves the performance of base DocRE models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_76",
            "start": 169,
            "end": 269,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_77@0",
            "content": "Experiments",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_77",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_78@0",
            "content": "Setup",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_78",
            "start": 0,
            "end": 4,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_79@0",
            "content": "Datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_79",
            "start": 0,
            "end": 8,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_79@1",
            "content": "DocRED is a large-scale humanannotated dataset for document-level relation extraction (Yao et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_79",
            "start": 10,
            "end": 114,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_80@0",
            "content": "The dataset is constructed from Wikipedia and Wikidata, containing 3053 documents for training, 1000 for development, and 1000 for test.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_80",
            "start": 0,
            "end": 135,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_80@1",
            "content": "In total, it has 132,375 entities and 56,354 relational facts in 96 relation types.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_80",
            "start": 137,
            "end": 219,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_80@2",
            "content": "More than 40% of the relational facts require reasoning over multiple sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_80",
            "start": 221,
            "end": 300,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_80@3",
            "content": "The standard evaluation metrics are F1 and Ign F1 (Yao et al., 2019;Zeng et al., 2020), where Ign F1 refers to the F1 score excluding the relational facts in the training set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_80",
            "start": 302,
            "end": 476,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_81@0",
            "content": "We also evaluated our approach on DialogRE (V2, Yu et al., 2020), which contains 36 relation types (17 of which are interpersonal).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_81",
            "start": 0,
            "end": 130,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_81@1",
            "content": "We followed the standard split of 1073 training dialogues, 358 validation, and 357 test.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_81",
            "start": 132,
            "end": 219,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_81@2",
            "content": "Following Yu et al. (2020), we report macro F1 scores in both the standard and conversational settings; the latter is denoted by F1 c .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_81",
            "start": 221,
            "end": 355,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_82@0",
            "content": "Competing Methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_82",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_82@1",
            "content": "We experimented our SIEF on a number of base models, namely, BiLSTM, BERT base , HeterGSAN, and GAIN (Section 4.4).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_82",
            "start": 19,
            "end": 133,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_82@2",
            "content": "These base models are all considered for comparison.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_82",
            "start": 135,
            "end": 186,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_83@0",
            "content": "For DocRED, we consider additional competing methods as follows: Two Phase , which first predicts whether the entity pair has a relation and then predicts the relation type.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_83",
            "start": 0,
            "end": 172,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_83@1",
            "content": "LSR (Nan et al., 2020), which constructs the graph by inducing a latent document-level graph.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_83",
            "start": 174,
            "end": 266,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_84@0",
            "content": "Reconstructor (Xu et al., 2021b), which encourages the model to reconstruct a reasoning path during training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_84",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_84@1",
            "content": "DRN (Xu et al., 2021a), which considers different reasoning skills explicitly and uses graph representation and context representation to model the reasoning skills.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_84",
            "start": 110,
            "end": 274,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_84@2",
            "content": "ATLOP (Zhou et al., 2021), which aggregates contextual information by the Transformer attentions and adopts an adaptive threshold for different entity pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_84",
            "start": 276,
            "end": 432,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_84@3",
            "content": "DocuNet (Zhang et al., 2021), which models DocRE as a semantic segmentation task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_84",
            "start": 434,
            "end": 514,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_85@0",
            "content": "For DialogRE, we followed Yu et al. ( 2020) and considered BERT and BERT s for comparison, 5 where BERT s prevents a model from overfitting by replacing of the interpersonal augment with a special token.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_85",
            "start": 0,
            "end": 202,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_86@0",
            "content": "Implementation Details.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_86",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_87@0",
            "content": "We use the repository 2,3,4,5 of base models to implement our approach.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_87",
            "start": 0,
            "end": 70,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_87@1",
            "content": "We mostly followed the standard hyperparameters used in the base models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_87",
            "start": 72,
            "end": 143,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_87@2",
            "content": "Our SIEF has one hyperparameter \u03b2 in Eqn. (5).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_87",
            "start": 145,
            "end": 190,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_87@3",
            "content": "It was set to 0.8, and Section 5.2 presents the effect of tuning \u03b2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_87",
            "start": 192,
            "end": 258,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_87@4",
            "content": "Our code can be found in Footnote 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_87",
            "start": 260,
            "end": 295,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_88@0",
            "content": "Test Ign F1 F1 Ign F1 F1 DocRE Systems with GloVe LSR (Nan et al., 2020) 48.82 55.17 52.15 54.18 Reconstructor (Xu et al., 2021b) 54.25 55.70 53.25 55.13 DRN (Xu et al., 2021a 54.61 56.49 54.35 56.33 BiLSTM (Yao et al., 2019) 48 (Nan et al., 2020) 52.43 59.00 56.97 59.05 Reconstructor (Xu et al., 2021b) 58.13 60.18 57.12 59.45 DRN (Xu et al., 2021a) 59.33 61.39 59.15 61.37 ATLOP (Zhou et al., 2021) 59.22 61.09 59.31 61.30 DocuNet (Zhang et al., 2021) 59.86 61.83 59.93 61.86 BERT base (Ye et al., 2020) 54",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_88",
            "start": 0,
            "end": 508,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_89@0",
            "content": "Results and Analyses",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_89",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_90@0",
            "content": "Main results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_90",
            "start": 0,
            "end": 12,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_90@1",
            "content": "Table 1 presents the detailed results on the development and test sets of the DocRED dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_90",
            "start": 14,
            "end": 106,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_90@2",
            "content": "We first compare DocRE systems with GloVe embeddings (Yao et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_90",
            "start": 108,
            "end": 179,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_90@3",
            "content": "We see that the proposed SIEF method significantly improves the performance of all base models, including the sequence model (i.e., BiLSTM) and graph models (i.e., HeterGSAN and GAIN); the average improvement is 2.05 points in terms of test F1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_90",
            "start": 181,
            "end": 424,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_90@4",
            "content": "This shows that SIEF is compatible with both sequence and graph models, indicating the generality and effectiveness of the proposed method.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_90",
            "start": 426,
            "end": 564,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_90@5",
            "content": "For the DocRE system with BERT base , SIEF also consistently improves the base models, showing that SIEF is complementary to the modern BERT architecture.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_90",
            "start": 566,
            "end": 719,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_90@6",
            "content": "Especially, combining SIEF and GAIN (Zeng et al., 2020) with BERT base encoding yields state-of-the-art performance in terms of F1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_90",
            "start": 721,
            "end": 851,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_91@0",
            "content": "We further conducted experiments on the DialogRE dataset, and compare our approach with the BERT baselines in Yu et al. (2020) the results are consistent with the improvement on DocRED, as our SIEF largely improves F1 and F1 c for both base models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_91",
            "start": 0,
            "end": 247,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_91@1",
            "content": "This further confirms the generality of our approach in different domains.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_91",
            "start": 249,
            "end": 322,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_92@0",
            "content": "In the rest of this section, we present in-depth analyses to better understand our model with DocRED as the testbed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_92",
            "start": 0,
            "end": 115,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_92@1",
            "content": "All base models use GloVe embeddings as opposed to BERT due to efficiency concerns.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_92",
            "start": 117,
            "end": 199,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_93@0",
            "content": "Intra-and Inter-Sentence Performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_93",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_93@1",
            "content": "We breakdown the relation classification performance into intra-sentence reasoning and inter-sentence reasoning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_93",
            "start": 38,
            "end": 149,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_93@2",
            "content": "Ideally, if only one sentence is needed to determine the relation of an entity pair, then it belongs to the intra-sentence category; if two or more sentences are needed, then it belongs to the inter-sentence category.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_93",
            "start": 151,
            "end": 367,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_93@3",
            "content": "We follow Nan et al. (2020) and approximate it by checking whether two entities are mentioned in one sentence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_93",
            "start": 369,
            "end": 478,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_94@0",
            "content": "The results are shown in Table 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_94",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_94@1",
            "content": "SIEF again consistently improves base models in terms of both Intra-F1 and Inter-F1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_94",
            "start": 34,
            "end": 117,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_94@2",
            "content": "However, the improvement on Intra-F1 is larger than that on Inter-F1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_94",
            "start": 119,
            "end": 187,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_94@3",
            "content": "This is because our SIEF encourages the model to focus on evidence by removing one sentence at a time, but does not explicitly model sentence relations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_94",
            "start": 189,
            "end": 340,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_94@4",
            "content": "Based on this analysis, we plan to extend the SIEF framework with multi-sentence DocRE reasoning in our future work.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_94",
            "start": 342,
            "end": 457,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_95@0",
            "content": "Performance of predicting evidence sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_95",
            "start": 0,
            "end": 44,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_95@1",
            "content": "In our paper, we propose a sentence importance score to measure how much a sentence contributes to the classification without using additional annotation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_95",
            "start": 46,
            "end": 199,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_95@2",
            "content": "We evaluate such performance in Table 4 by Precision, Recall, and F1 scores against manually annotated evidence sentences that are provided in the dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_95",
            "start": 201,
            "end": 355,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_95@3",
            "content": "In this analysis, we do not perform relation prediction, but concern about entity pairs knowingly having certain relations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_95",
            "start": 357,
            "end": 479,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_95@4",
            "content": "Specifically, for entity pair (e i h , e it ) with relation j, we calculate the importance score g",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_95",
            "start": 481,
            "end": 578,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_96@0",
            "content": "(\u2212n) ij",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_96",
            "start": 0,
            "end": 6,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_97@0",
            "content": "for each sentence and cut off evidence/non-evidence sentences with a threshold based on the development F1 score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_97",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_98@0",
            "content": "As seen, all base models achieve above 60% F1, suggesting that the proposed importance score is indeed indicative for predicting evidence and nonevidence sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_98",
            "start": 0,
            "end": 163,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_99@0",
            "content": "With the proposed SIEF framework, the performance improves for all metrics, with an average improvement of 2.95 F1 points across three base models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_99",
            "start": 0,
            "end": 146,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_99@1",
            "content": "This further verifies that our SIEF framework not only improves relation extraction performance, but also is able to better detect evidence and non-evidence sentences, which is important for the robustness of machine learning models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_99",
            "start": 148,
            "end": 380,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_100@0",
            "content": "Robustness of DocRE models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_100",
            "start": 0,
            "end": 26,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_100@1",
            "content": "We further investigate the robustness of DocRE models by showing the difference between the predicted distributions with and without non-evidence sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_100",
            "start": 28,
            "end": 183,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_100@2",
            "content": "We show in Figure 5 the scatter plots of the probability P based on the entire document and the probability P",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_100",
            "start": 185,
            "end": 293,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_101@0",
            "content": "(\u2212n) ij",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_101",
            "start": 0,
            "end": 6,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_102@0",
            "content": "with a random non-evidence sentence removed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_102",
            "start": 0,
            "end": 43,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_103@0",
            "content": "As shown in the figure, the points of the base models (left magenta plots) scatters over a wider range, whereas our SIEF training (right cyan plots) makes them more concentrated on the diagonal, indicating that the prediction P ij on the entire document is mostly the same as P (\u2212n) ij with a nonevidence removed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_103",
            "start": 0,
            "end": 312,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_103@1",
            "content": "This shows the robustness of SIEF-trained models, as they are less sensitive to non-evidences sentences for DocRE.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_103",
            "start": 314,
            "end": 427,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_103@2",
            "content": "Analysis on hyperparameter \u03b2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_103",
            "start": 429,
            "end": 457,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_103@3",
            "content": "Our SIEF framework has one hyperaparameter \u03b2 that controls how strict we treat a sentence as evidence or nonevidence (in Section 4.3).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_103",
            "start": 459,
            "end": 592,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_103@4",
            "content": "We analyze the effect of \u03b2 in Figure 4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_103",
            "start": 594,
            "end": 632,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_104@0",
            "content": "As seen, our SIEF approach consistently benefits the base models with a large range of \u03b2 values.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_104",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_104@1",
            "content": "Intuitively, if \u03b2 is too small, very few sentences will be treated as non-evidence and our sentence focusing loss is less effective; if \u03b2 is too large, it has a high false positive rate of non-evidence sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_104",
            "start": 97,
            "end": 308,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_104@2",
            "content": "Empirically, a moderate \u03b2 around (0.6-0.8) yields the highest performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_104",
            "start": 310,
            "end": 383,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_104@3",
            "content": "From the plots, we also see that our hyperparameter \u03b2 is insensitive to the base models, justifying our design of Eqn. (3).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_104",
            "start": 385,
            "end": 507,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_105@0",
            "content": "Sentence importance score VS other heuristics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_105",
            "start": 0,
            "end": 45,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_105@1",
            "content": "To investigate the effectiveness of our sentence importance score in Eqn. (3), we compare it with several alternative heuristics: 1) We randomly select half of the sentences as the nonevidence set, denoted by Rand; and 2) We consider the non-evidence set as the sentences without entity mentions, denoted by NoMention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_105",
            "start": 47,
            "end": 364,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_106@0",
            "content": "The results of the performance in terms of F1 and Ign F1 on the development set are shown in Table 5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_106",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_106@1",
            "content": "As seen, the simple heuristic Rand outperforms the base model, as Rand can be thought of as noisy data augmentation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_106",
            "start": 102,
            "end": 217,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_106@2",
            "content": "The NoMention heuristic outperforms Rand, as sentences without entity mentions are more likely to be non-evidence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_106",
            "start": 219,
            "end": 332,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_106@3",
            "content": "Moroever, SIEF is superior to both Rand and NoMention, showing that our sentence importance scores is a more effective indicator of evidence and non-evidence sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_106",
            "start": 334,
            "end": 501,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_107@0",
            "content": "Our sentence focusing loss VS learning from groundtruth.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_107",
            "start": 0,
            "end": 55,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_107@1",
            "content": "We encourage the DocRE models to generate consistent output probabilities with and without non-evidence (in Section 4.2) by a cross-entropy loss between two soft distributions P ij and",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_107",
            "start": 57,
            "end": 240,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_108@0",
            "content": "P (\u2212n) ij .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_108",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_109@0",
            "content": "To investigate the effect of such a sentence focusing loss, we compare it with an alternative choice: we learn P (\u2212n) ij directly from the groundtruth label r ij .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_109",
            "start": 0,
            "end": 162,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_110@0",
            "content": "Table 6 shows the results on the development set in terms of F1 and Ign F1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_110",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_110@1",
            "content": "As seen, both methods can improve the performance of the base models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_110",
            "start": 76,
            "end": 144,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_110@2",
            "content": "This confirms that removing non-evidence sentences can serve as a way of data augmentation, boosting the performance of DocRE models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_110",
            "start": 146,
            "end": 278,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_110@3",
            "content": "Moreover, we observe that our sentence focusing loss is better than learning from the groundtruth labels, showing that the soft predictions provide more information than one-hot labels, consistent with knowledge distillation literature (Hinton et al., 2015).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_110",
            "start": 280,
            "end": 537,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_111@0",
            "content": "Case Study.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_111",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_111@1",
            "content": "Figure 6 shows a case study of GAIN and GAIN+SIEF models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_111",
            "start": 12,
            "end": 68,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_111@2",
            "content": "For the entity pair (Brad Wilk, Rage Against the Machine), both GAIN and GAIN+SIEF predicts the relation \"MemberOf\", which is consistent with the reference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_111",
            "start": 70,
            "end": 225,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_111@3",
            "content": "We see that Sentence 3 is non-evidence, and in principle, it should not affect DocRE prediction in this case.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_111",
            "start": 227,
            "end": 335,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_111@4",
            "content": "However, the base GAIN model makes a wrong prediction \"not MemberOf\", as the predicted probability is below the threshold, which is determined by validation based on predicted binary probabilities of all relations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_111",
            "start": 337,
            "end": 550,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_111@5",
            "content": "By contrast, our SIEF model is able to make correct predictions when different non-evidence sentences are removed, demonstrating its robustness.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_111",
            "start": 552,
            "end": 695,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_112@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_112",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_113@0",
            "content": "In this paper, we propose a novel Sentence Information Estimation and Focusing (SIEF) approach to document relation extraction (DocRE).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_113",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_113@1",
            "content": "We design a sentence importance score and a sentence focusing loss to encourage the model to focus on evidence sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_113",
            "start": 136,
            "end": 256,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_113@2",
            "content": "The proposed SIEF is a general framework, and can be combined with various base DocRE models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_113",
            "start": 258,
            "end": 350,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_113@3",
            "content": "Experimental results show that SIEF consistently improves the performance of base models in different domains, and that it improves the robustness of DocRE models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_113",
            "start": 352,
            "end": 514,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_114@0",
            "content": "Livio Baldini, Nicholas Soares, Jeffrey Fitzgerald, Tom Ling,  Kwiatkowski, Matching the blanks: Distributional similarity for relation learning, 2019, Proceedings of the Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_114",
            "start": 0,
            "end": 236,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_115@0",
            "content": "Fenia Christopoulou, Makoto Miwa, Sophia Ananiadou, Connecting the dots: Documentlevel neural relation extraction with edge-oriented graphs, 2019, Proceedings of the Conference on Empirical Methods in Natural Language Processing and the International Joint Conference on Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_115",
            "start": 0,
            "end": 300,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_116@0",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_116",
            "start": 0,
            "end": 260,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_117@0",
            "content": "George Doddington, Alexis Mitchell, Mark Przybocki, Lance Ramshaw, Stephanie Strassel, Ralph Weischedel, The automatic content extraction (ACE) program -tasks, data, and evaluation, 2004, Proceedings of the Fourth International Conference on Language Resources and Evaluation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_117",
            "start": 0,
            "end": 277,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_118@0",
            "content": "Pankaj Gupta, Subburam Rajaram, Hinrich Sch\u00fctze, Thomas Runkler, Neural relation extraction within and across sentence boundaries, 2019, Proceedings of the Association for the Advance of Artificial Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_118",
            "start": 0,
            "end": 212,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_119@0",
            "content": "Geoffrey Hinton, Oriol Vinyals, Jeffrey Dean, Distilling the knowledge in a neural network, 2015, Proceedings of the Annual Conference on Neural Information Processing Systems Deep Learning and Representation Learning Workshop, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_119",
            "start": 0,
            "end": 228,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_120@0",
            "content": "Quzhe Huang, Shengqi Zhu, Yansong Feng, Yuan Ye, Yuxuan Lai, Dongyan Zhao, Three sentences are all you need: Local path enhanced document relation extraction, 2021, Proceedings of the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_120",
            "start": 0,
            "end": 319,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_121@0",
            "content": "Jiao Li, Yueping Sun, Robin Johnson, Daniela Sciaky, Chih-Hsuan Wei, Robert Leaman, Allan Davis, Carolyn Mattingly, Thomas Wiegers, Zhiyong Lu, BioCreative V CDR task corpus: A resource for chemical disease relation extraction, 2016, Database: The Journal of Biological Databases and Curation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_121",
            "start": 0,
            "end": 294,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_122@0",
            "content": "Mike Mintz, Steven Bills, Rion Snow, Daniel Jurafsky, Distant supervision for relation extraction without labeled data, 2009, Proceedings of the Joint Conference of the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_122",
            "start": 0,
            "end": 304,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_123@0",
            "content": "Guoshun Nan, Zhijiang Guo, Ivan Sekulic, Wei Lu, Reasoning with latent structure refinement for document-level relation extraction, 2020, Proceedings of the Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_123",
            "start": 0,
            "end": 222,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_124@0",
            "content": "Patrick Pantel, Marco Pennacchiotti, Espresso: Leveraging generic patterns for automatically harvesting semantic relations, 2006, Proceedings of the International Conference on Computational Linguistics and Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_124",
            "start": 0,
            "end": 272,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_125@0",
            "content": "Chris Quirk, Hoifung Poon, Distant supervision for relation extraction beyond the sentence boundary, 2017, Proceedings of the Conference of the European Chapter, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_125",
            "start": 0,
            "end": 203,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_126@0",
            "content": "Linfeng Song, Yue Zhang, Daniel Gildea, Mo Yu, Zhiguo Wang, Jinsong Su, Leveraging dependency forest for neural medical relation extraction, 2019, Proceedings of the Conference on Empirical Methods in Natural Language Processing and the International Joint Conference on Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_126",
            "start": 0,
            "end": 300,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_127@0",
            "content": "Daniil Sorokin, Iryna Gurevych, Contextaware representations for knowledge base relation extraction, 2017, Proceedings of the Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_127",
            "start": 0,
            "end": 190,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_128@0",
            "content": "UNKNOWN, None, 2019, Fine-tune BERT for DocRED with two-step process, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_128",
            "start": 0,
            "end": 70,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_129@0",
            "content": "Zhepei Wei, Jianlin Su, Yue Wang, Yuan Tian, Yi Chang, A novel cascade binary tagging framework for relational triple extraction, 2020, Proceedings of the Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_129",
            "start": 0,
            "end": 220,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_130@0",
            "content": "Minguang Xiao, Cong Liu, Semantic relation classification via hierarchical recurrent neural network with attention, 2016, Proceedings of the International Conference on Computational Linguistics: Technical Papers, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_130",
            "start": 0,
            "end": 214,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_131@0",
            "content": "Wang Xu, Kehai Chen, Tiejun Zhao, Discriminative reasoning for document-level relation extraction, 2021, Findings of the Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_131",
            "start": 0,
            "end": 186,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_132@0",
            "content": "Wang Xu, Kehai Chen, Tiejun Zhao, Document-level relation extraction with reconstruction, 2021, Proceedings of the Association for the Advance of Artificial Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_132",
            "start": 0,
            "end": 171,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_133@0",
            "content": "Yan Xu, Ran Jia, Lili Mou, Ge Li, Yunchuan Chen, Yangyang Lu, Zhi Jin, Improved relation classification by deep recurrent neural networks with data augmentation, 2016, Proceedings of the International Conference on Computational Linguistics: Technical Papers, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_133",
            "start": 0,
            "end": 260,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_134@0",
            "content": "Yan Xu, Lili Mou, Ge Li, Yunchuan Chen, Hao Peng, Zhi Jin, Classifying relations via long short term memory networks along shortest dependency paths, 2015, Proceedings of the Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_134",
            "start": 0,
            "end": 239,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_135@0",
            "content": "Yuan Yao, Deming Ye, Peng Li, Xu Han, Yankai Lin, Zhenghao Liu, Zhiyuan Liu, Lixin Huang, Jie Zhou, Maosong Sun, DocRED: A large-scale document-level relation extraction dataset, 2019, Proceedings of the Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_135",
            "start": 0,
            "end": 269,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_136@0",
            "content": "Deming Ye, Yankai Lin, Jiaju Du, Zhenghao Liu, Peng Li, Maosong Sun, Zhiyuan Liu, Coreferential reasoning learning for language representation, 2020, Proceedings of the Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_136",
            "start": 0,
            "end": 233,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_137@0",
            "content": "Dian Yu, Kai Sun, Claire Cardie, Dong Yu, Dialogue-based relation extraction, 2020, Proceedings of the Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_137",
            "start": 0,
            "end": 168,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_138@0",
            "content": "Mo Yu, Wenpeng Yin,  Kazi Saidul Hasan, Bing Cicero Dos Santos, Bowen Xiang,  Zhou, Improved neural relation detection for knowledge base question answering, 2017, Proceedings of the Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_138",
            "start": 0,
            "end": 248,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_139@0",
            "content": "Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou, Jun Zhao, Relation classification via convolutional deep neural network, 2014, Proceedings of the International Conference on Computational Linguistics: Technical Papers, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_139",
            "start": 0,
            "end": 221,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_140@0",
            "content": "Shuang Zeng, Runxin Xu, Baobao Chang, Lei Li, Double graph based reasoning for document-level relation extraction, 2020, Proceedings of the Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_140",
            "start": 0,
            "end": 204,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_141@0",
            "content": "Ningyu Zhang, Xiang Chen, Xin Xie, Shumin Deng, Chuanqi Tan, Mosha Chen, Fei Huang, Luo Si, Huajun Chen, Document-level relation extraction as semantic segmentation, 2021, Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_141",
            "start": 0,
            "end": 260,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_142@0",
            "content": "Wenxuan Zhou, Kevin Huang, Tengyu Ma, Jing Huang, Document-level relation extraction with adaptive thresholding and localized context pooling, 2021, Proceedings of the Association for the Advance of Artificial Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_142",
            "start": 0,
            "end": 224,
            "label": {}
        },
        {
            "ix": "3-ARR_v1_143@0",
            "content": "Hao Zhu, Yankai Lin, Zhiyuan Liu, Jie Fu, Graph neural networks with generated parameters for relation extraction, 2019, Proceedings of the Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "3-ARR_v1_143",
            "start": 0,
            "end": 205,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "3-ARR_v1_0",
            "tgt_ix": "3-ARR_v1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_0",
            "tgt_ix": "3-ARR_v1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_1",
            "tgt_ix": "3-ARR_v1_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_1",
            "tgt_ix": "3-ARR_v1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_0",
            "tgt_ix": "3-ARR_v1_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_2",
            "tgt_ix": "3-ARR_v1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_4",
            "tgt_ix": "3-ARR_v1_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_5",
            "tgt_ix": "3-ARR_v1_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_6",
            "tgt_ix": "3-ARR_v1_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_3",
            "tgt_ix": "3-ARR_v1_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_3",
            "tgt_ix": "3-ARR_v1_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_3",
            "tgt_ix": "3-ARR_v1_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_3",
            "tgt_ix": "3-ARR_v1_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_3",
            "tgt_ix": "3-ARR_v1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_0",
            "tgt_ix": "3-ARR_v1_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_7",
            "tgt_ix": "3-ARR_v1_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_9",
            "tgt_ix": "3-ARR_v1_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_10",
            "tgt_ix": "3-ARR_v1_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_11",
            "tgt_ix": "3-ARR_v1_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_12",
            "tgt_ix": "3-ARR_v1_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_8",
            "tgt_ix": "3-ARR_v1_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_8",
            "tgt_ix": "3-ARR_v1_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_8",
            "tgt_ix": "3-ARR_v1_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_8",
            "tgt_ix": "3-ARR_v1_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_8",
            "tgt_ix": "3-ARR_v1_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_8",
            "tgt_ix": "3-ARR_v1_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_0",
            "tgt_ix": "3-ARR_v1_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_13",
            "tgt_ix": "3-ARR_v1_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_15",
            "tgt_ix": "3-ARR_v1_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_16",
            "tgt_ix": "3-ARR_v1_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_17",
            "tgt_ix": "3-ARR_v1_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_18",
            "tgt_ix": "3-ARR_v1_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_19",
            "tgt_ix": "3-ARR_v1_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_20",
            "tgt_ix": "3-ARR_v1_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_21",
            "tgt_ix": "3-ARR_v1_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_22",
            "tgt_ix": "3-ARR_v1_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_23",
            "tgt_ix": "3-ARR_v1_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_24",
            "tgt_ix": "3-ARR_v1_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_14",
            "tgt_ix": "3-ARR_v1_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_14",
            "tgt_ix": "3-ARR_v1_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_14",
            "tgt_ix": "3-ARR_v1_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_14",
            "tgt_ix": "3-ARR_v1_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_14",
            "tgt_ix": "3-ARR_v1_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_14",
            "tgt_ix": "3-ARR_v1_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_14",
            "tgt_ix": "3-ARR_v1_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_14",
            "tgt_ix": "3-ARR_v1_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_14",
            "tgt_ix": "3-ARR_v1_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_14",
            "tgt_ix": "3-ARR_v1_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_14",
            "tgt_ix": "3-ARR_v1_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_14",
            "tgt_ix": "3-ARR_v1_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_0",
            "tgt_ix": "3-ARR_v1_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_25",
            "tgt_ix": "3-ARR_v1_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_26",
            "tgt_ix": "3-ARR_v1_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_26",
            "tgt_ix": "3-ARR_v1_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_26",
            "tgt_ix": "3-ARR_v1_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_27",
            "tgt_ix": "3-ARR_v1_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_29",
            "tgt_ix": "3-ARR_v1_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_30",
            "tgt_ix": "3-ARR_v1_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_31",
            "tgt_ix": "3-ARR_v1_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_32",
            "tgt_ix": "3-ARR_v1_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_33",
            "tgt_ix": "3-ARR_v1_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_34",
            "tgt_ix": "3-ARR_v1_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_35",
            "tgt_ix": "3-ARR_v1_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_36",
            "tgt_ix": "3-ARR_v1_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_37",
            "tgt_ix": "3-ARR_v1_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_38",
            "tgt_ix": "3-ARR_v1_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_39",
            "tgt_ix": "3-ARR_v1_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_40",
            "tgt_ix": "3-ARR_v1_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_41",
            "tgt_ix": "3-ARR_v1_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_42",
            "tgt_ix": "3-ARR_v1_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_43",
            "tgt_ix": "3-ARR_v1_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_44",
            "tgt_ix": "3-ARR_v1_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_45",
            "tgt_ix": "3-ARR_v1_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_28",
            "tgt_ix": "3-ARR_v1_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_28",
            "tgt_ix": "3-ARR_v1_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_28",
            "tgt_ix": "3-ARR_v1_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_28",
            "tgt_ix": "3-ARR_v1_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_28",
            "tgt_ix": "3-ARR_v1_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_28",
            "tgt_ix": "3-ARR_v1_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_28",
            "tgt_ix": "3-ARR_v1_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_28",
            "tgt_ix": "3-ARR_v1_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_28",
            "tgt_ix": "3-ARR_v1_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_28",
            "tgt_ix": "3-ARR_v1_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_28",
            "tgt_ix": "3-ARR_v1_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_28",
            "tgt_ix": "3-ARR_v1_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_28",
            "tgt_ix": "3-ARR_v1_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_28",
            "tgt_ix": "3-ARR_v1_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_28",
            "tgt_ix": "3-ARR_v1_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_28",
            "tgt_ix": "3-ARR_v1_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_28",
            "tgt_ix": "3-ARR_v1_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_28",
            "tgt_ix": "3-ARR_v1_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_28",
            "tgt_ix": "3-ARR_v1_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_26",
            "tgt_ix": "3-ARR_v1_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_46",
            "tgt_ix": "3-ARR_v1_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_48",
            "tgt_ix": "3-ARR_v1_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_49",
            "tgt_ix": "3-ARR_v1_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_50",
            "tgt_ix": "3-ARR_v1_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_51",
            "tgt_ix": "3-ARR_v1_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_52",
            "tgt_ix": "3-ARR_v1_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_53",
            "tgt_ix": "3-ARR_v1_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_54",
            "tgt_ix": "3-ARR_v1_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_55",
            "tgt_ix": "3-ARR_v1_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_56",
            "tgt_ix": "3-ARR_v1_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_57",
            "tgt_ix": "3-ARR_v1_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_47",
            "tgt_ix": "3-ARR_v1_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_47",
            "tgt_ix": "3-ARR_v1_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_47",
            "tgt_ix": "3-ARR_v1_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_47",
            "tgt_ix": "3-ARR_v1_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_47",
            "tgt_ix": "3-ARR_v1_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_47",
            "tgt_ix": "3-ARR_v1_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_47",
            "tgt_ix": "3-ARR_v1_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_47",
            "tgt_ix": "3-ARR_v1_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_47",
            "tgt_ix": "3-ARR_v1_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_47",
            "tgt_ix": "3-ARR_v1_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_47",
            "tgt_ix": "3-ARR_v1_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_47",
            "tgt_ix": "3-ARR_v1_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_26",
            "tgt_ix": "3-ARR_v1_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_58",
            "tgt_ix": "3-ARR_v1_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_60",
            "tgt_ix": "3-ARR_v1_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_61",
            "tgt_ix": "3-ARR_v1_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_62",
            "tgt_ix": "3-ARR_v1_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_63",
            "tgt_ix": "3-ARR_v1_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_64",
            "tgt_ix": "3-ARR_v1_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_65",
            "tgt_ix": "3-ARR_v1_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_59",
            "tgt_ix": "3-ARR_v1_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_59",
            "tgt_ix": "3-ARR_v1_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_59",
            "tgt_ix": "3-ARR_v1_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_59",
            "tgt_ix": "3-ARR_v1_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_59",
            "tgt_ix": "3-ARR_v1_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_59",
            "tgt_ix": "3-ARR_v1_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_59",
            "tgt_ix": "3-ARR_v1_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_59",
            "tgt_ix": "3-ARR_v1_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_26",
            "tgt_ix": "3-ARR_v1_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_66",
            "tgt_ix": "3-ARR_v1_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_68",
            "tgt_ix": "3-ARR_v1_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_69",
            "tgt_ix": "3-ARR_v1_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_70",
            "tgt_ix": "3-ARR_v1_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_71",
            "tgt_ix": "3-ARR_v1_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_72",
            "tgt_ix": "3-ARR_v1_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_73",
            "tgt_ix": "3-ARR_v1_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_74",
            "tgt_ix": "3-ARR_v1_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_75",
            "tgt_ix": "3-ARR_v1_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_67",
            "tgt_ix": "3-ARR_v1_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_67",
            "tgt_ix": "3-ARR_v1_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_67",
            "tgt_ix": "3-ARR_v1_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_67",
            "tgt_ix": "3-ARR_v1_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_67",
            "tgt_ix": "3-ARR_v1_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_67",
            "tgt_ix": "3-ARR_v1_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_67",
            "tgt_ix": "3-ARR_v1_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_67",
            "tgt_ix": "3-ARR_v1_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_67",
            "tgt_ix": "3-ARR_v1_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_67",
            "tgt_ix": "3-ARR_v1_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_0",
            "tgt_ix": "3-ARR_v1_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_76",
            "tgt_ix": "3-ARR_v1_77",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_77",
            "tgt_ix": "3-ARR_v1_78",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_77",
            "tgt_ix": "3-ARR_v1_78",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_79",
            "tgt_ix": "3-ARR_v1_80",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_80",
            "tgt_ix": "3-ARR_v1_81",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_81",
            "tgt_ix": "3-ARR_v1_82",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_82",
            "tgt_ix": "3-ARR_v1_83",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_83",
            "tgt_ix": "3-ARR_v1_84",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_84",
            "tgt_ix": "3-ARR_v1_85",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_85",
            "tgt_ix": "3-ARR_v1_86",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_86",
            "tgt_ix": "3-ARR_v1_87",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_78",
            "tgt_ix": "3-ARR_v1_79",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_78",
            "tgt_ix": "3-ARR_v1_80",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_78",
            "tgt_ix": "3-ARR_v1_81",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_78",
            "tgt_ix": "3-ARR_v1_82",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_78",
            "tgt_ix": "3-ARR_v1_83",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_78",
            "tgt_ix": "3-ARR_v1_84",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_78",
            "tgt_ix": "3-ARR_v1_85",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_78",
            "tgt_ix": "3-ARR_v1_86",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_78",
            "tgt_ix": "3-ARR_v1_87",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_78",
            "tgt_ix": "3-ARR_v1_79",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_78",
            "tgt_ix": "3-ARR_v1_88",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_87",
            "tgt_ix": "3-ARR_v1_88",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_77",
            "tgt_ix": "3-ARR_v1_89",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_88",
            "tgt_ix": "3-ARR_v1_89",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_90",
            "tgt_ix": "3-ARR_v1_91",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_91",
            "tgt_ix": "3-ARR_v1_92",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_92",
            "tgt_ix": "3-ARR_v1_93",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_93",
            "tgt_ix": "3-ARR_v1_94",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_94",
            "tgt_ix": "3-ARR_v1_95",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_95",
            "tgt_ix": "3-ARR_v1_96",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_96",
            "tgt_ix": "3-ARR_v1_97",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_97",
            "tgt_ix": "3-ARR_v1_98",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_98",
            "tgt_ix": "3-ARR_v1_99",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_99",
            "tgt_ix": "3-ARR_v1_100",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_100",
            "tgt_ix": "3-ARR_v1_101",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_101",
            "tgt_ix": "3-ARR_v1_102",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_102",
            "tgt_ix": "3-ARR_v1_103",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_103",
            "tgt_ix": "3-ARR_v1_104",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_104",
            "tgt_ix": "3-ARR_v1_105",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_105",
            "tgt_ix": "3-ARR_v1_106",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_106",
            "tgt_ix": "3-ARR_v1_107",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_107",
            "tgt_ix": "3-ARR_v1_108",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_108",
            "tgt_ix": "3-ARR_v1_109",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_109",
            "tgt_ix": "3-ARR_v1_110",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_110",
            "tgt_ix": "3-ARR_v1_111",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_89",
            "tgt_ix": "3-ARR_v1_90",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_89",
            "tgt_ix": "3-ARR_v1_91",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_89",
            "tgt_ix": "3-ARR_v1_92",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_89",
            "tgt_ix": "3-ARR_v1_93",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_89",
            "tgt_ix": "3-ARR_v1_94",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_89",
            "tgt_ix": "3-ARR_v1_95",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_89",
            "tgt_ix": "3-ARR_v1_96",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_89",
            "tgt_ix": "3-ARR_v1_97",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_89",
            "tgt_ix": "3-ARR_v1_98",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_89",
            "tgt_ix": "3-ARR_v1_99",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_89",
            "tgt_ix": "3-ARR_v1_100",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_89",
            "tgt_ix": "3-ARR_v1_101",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_89",
            "tgt_ix": "3-ARR_v1_102",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_89",
            "tgt_ix": "3-ARR_v1_103",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_89",
            "tgt_ix": "3-ARR_v1_104",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_89",
            "tgt_ix": "3-ARR_v1_105",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_89",
            "tgt_ix": "3-ARR_v1_106",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_89",
            "tgt_ix": "3-ARR_v1_107",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_89",
            "tgt_ix": "3-ARR_v1_108",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_89",
            "tgt_ix": "3-ARR_v1_109",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_89",
            "tgt_ix": "3-ARR_v1_110",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_89",
            "tgt_ix": "3-ARR_v1_111",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_89",
            "tgt_ix": "3-ARR_v1_90",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_0",
            "tgt_ix": "3-ARR_v1_112",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_111",
            "tgt_ix": "3-ARR_v1_112",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_112",
            "tgt_ix": "3-ARR_v1_113",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_112",
            "tgt_ix": "3-ARR_v1_113",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "3-ARR_v1_0",
            "tgt_ix": "3-ARR_v1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_1",
            "tgt_ix": "3-ARR_v1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_2",
            "tgt_ix": "3-ARR_v1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_2",
            "tgt_ix": "3-ARR_v1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_2",
            "tgt_ix": "3-ARR_v1_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_2",
            "tgt_ix": "3-ARR_v1_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_2",
            "tgt_ix": "3-ARR_v1_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_2",
            "tgt_ix": "3-ARR_v1_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_2",
            "tgt_ix": "3-ARR_v1_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_3",
            "tgt_ix": "3-ARR_v1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_4",
            "tgt_ix": "3-ARR_v1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_4",
            "tgt_ix": "3-ARR_v1_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_4",
            "tgt_ix": "3-ARR_v1_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_4",
            "tgt_ix": "3-ARR_v1_4@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_4",
            "tgt_ix": "3-ARR_v1_4@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_4",
            "tgt_ix": "3-ARR_v1_4@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_4",
            "tgt_ix": "3-ARR_v1_4@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_5",
            "tgt_ix": "3-ARR_v1_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_5",
            "tgt_ix": "3-ARR_v1_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_5",
            "tgt_ix": "3-ARR_v1_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_5",
            "tgt_ix": "3-ARR_v1_5@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_5",
            "tgt_ix": "3-ARR_v1_5@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_5",
            "tgt_ix": "3-ARR_v1_5@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_6",
            "tgt_ix": "3-ARR_v1_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_6",
            "tgt_ix": "3-ARR_v1_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_6",
            "tgt_ix": "3-ARR_v1_6@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_6",
            "tgt_ix": "3-ARR_v1_6@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_6",
            "tgt_ix": "3-ARR_v1_6@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_6",
            "tgt_ix": "3-ARR_v1_6@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_7",
            "tgt_ix": "3-ARR_v1_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_7",
            "tgt_ix": "3-ARR_v1_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_7",
            "tgt_ix": "3-ARR_v1_7@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_7",
            "tgt_ix": "3-ARR_v1_7@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_8",
            "tgt_ix": "3-ARR_v1_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_9",
            "tgt_ix": "3-ARR_v1_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_9",
            "tgt_ix": "3-ARR_v1_9@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_9",
            "tgt_ix": "3-ARR_v1_9@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_9",
            "tgt_ix": "3-ARR_v1_9@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_10",
            "tgt_ix": "3-ARR_v1_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_10",
            "tgt_ix": "3-ARR_v1_10@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_10",
            "tgt_ix": "3-ARR_v1_10@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_11",
            "tgt_ix": "3-ARR_v1_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_11",
            "tgt_ix": "3-ARR_v1_11@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_11",
            "tgt_ix": "3-ARR_v1_11@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_12",
            "tgt_ix": "3-ARR_v1_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_12",
            "tgt_ix": "3-ARR_v1_12@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_12",
            "tgt_ix": "3-ARR_v1_12@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_12",
            "tgt_ix": "3-ARR_v1_12@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_12",
            "tgt_ix": "3-ARR_v1_12@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_13",
            "tgt_ix": "3-ARR_v1_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_13",
            "tgt_ix": "3-ARR_v1_13@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_14",
            "tgt_ix": "3-ARR_v1_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_15",
            "tgt_ix": "3-ARR_v1_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_15",
            "tgt_ix": "3-ARR_v1_15@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_15",
            "tgt_ix": "3-ARR_v1_15@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_16",
            "tgt_ix": "3-ARR_v1_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_16",
            "tgt_ix": "3-ARR_v1_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_17",
            "tgt_ix": "3-ARR_v1_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_18",
            "tgt_ix": "3-ARR_v1_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_19",
            "tgt_ix": "3-ARR_v1_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_20",
            "tgt_ix": "3-ARR_v1_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_21",
            "tgt_ix": "3-ARR_v1_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_22",
            "tgt_ix": "3-ARR_v1_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_23",
            "tgt_ix": "3-ARR_v1_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_24",
            "tgt_ix": "3-ARR_v1_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_25",
            "tgt_ix": "3-ARR_v1_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_26",
            "tgt_ix": "3-ARR_v1_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_27",
            "tgt_ix": "3-ARR_v1_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_27",
            "tgt_ix": "3-ARR_v1_27@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_27",
            "tgt_ix": "3-ARR_v1_27@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_27",
            "tgt_ix": "3-ARR_v1_27@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_27",
            "tgt_ix": "3-ARR_v1_27@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_27",
            "tgt_ix": "3-ARR_v1_27@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_28",
            "tgt_ix": "3-ARR_v1_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_29",
            "tgt_ix": "3-ARR_v1_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_29",
            "tgt_ix": "3-ARR_v1_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_30",
            "tgt_ix": "3-ARR_v1_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_30",
            "tgt_ix": "3-ARR_v1_30@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_30",
            "tgt_ix": "3-ARR_v1_30@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_30",
            "tgt_ix": "3-ARR_v1_30@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_30",
            "tgt_ix": "3-ARR_v1_30@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_31",
            "tgt_ix": "3-ARR_v1_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_32",
            "tgt_ix": "3-ARR_v1_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_33",
            "tgt_ix": "3-ARR_v1_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_34",
            "tgt_ix": "3-ARR_v1_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_35",
            "tgt_ix": "3-ARR_v1_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_36",
            "tgt_ix": "3-ARR_v1_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_37",
            "tgt_ix": "3-ARR_v1_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_37",
            "tgt_ix": "3-ARR_v1_37@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_38",
            "tgt_ix": "3-ARR_v1_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_39",
            "tgt_ix": "3-ARR_v1_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_40",
            "tgt_ix": "3-ARR_v1_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_41",
            "tgt_ix": "3-ARR_v1_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_42",
            "tgt_ix": "3-ARR_v1_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_43",
            "tgt_ix": "3-ARR_v1_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_44",
            "tgt_ix": "3-ARR_v1_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_45",
            "tgt_ix": "3-ARR_v1_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_46",
            "tgt_ix": "3-ARR_v1_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_46",
            "tgt_ix": "3-ARR_v1_46@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_47",
            "tgt_ix": "3-ARR_v1_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_48",
            "tgt_ix": "3-ARR_v1_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_49",
            "tgt_ix": "3-ARR_v1_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_49",
            "tgt_ix": "3-ARR_v1_49@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_50",
            "tgt_ix": "3-ARR_v1_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_51",
            "tgt_ix": "3-ARR_v1_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_52",
            "tgt_ix": "3-ARR_v1_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_53",
            "tgt_ix": "3-ARR_v1_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_54",
            "tgt_ix": "3-ARR_v1_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_54",
            "tgt_ix": "3-ARR_v1_54@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_54",
            "tgt_ix": "3-ARR_v1_54@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_55",
            "tgt_ix": "3-ARR_v1_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_56",
            "tgt_ix": "3-ARR_v1_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_57",
            "tgt_ix": "3-ARR_v1_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_58",
            "tgt_ix": "3-ARR_v1_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_58",
            "tgt_ix": "3-ARR_v1_58@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_58",
            "tgt_ix": "3-ARR_v1_58@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_59",
            "tgt_ix": "3-ARR_v1_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_60",
            "tgt_ix": "3-ARR_v1_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_60",
            "tgt_ix": "3-ARR_v1_60@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_61",
            "tgt_ix": "3-ARR_v1_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_62",
            "tgt_ix": "3-ARR_v1_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_62",
            "tgt_ix": "3-ARR_v1_62@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_62",
            "tgt_ix": "3-ARR_v1_62@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_63",
            "tgt_ix": "3-ARR_v1_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_63",
            "tgt_ix": "3-ARR_v1_63@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_64",
            "tgt_ix": "3-ARR_v1_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_65",
            "tgt_ix": "3-ARR_v1_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_65",
            "tgt_ix": "3-ARR_v1_65@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_66",
            "tgt_ix": "3-ARR_v1_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_66",
            "tgt_ix": "3-ARR_v1_66@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_67",
            "tgt_ix": "3-ARR_v1_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_68",
            "tgt_ix": "3-ARR_v1_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_68",
            "tgt_ix": "3-ARR_v1_68@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_69",
            "tgt_ix": "3-ARR_v1_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_69",
            "tgt_ix": "3-ARR_v1_69@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_69",
            "tgt_ix": "3-ARR_v1_69@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_70",
            "tgt_ix": "3-ARR_v1_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_70",
            "tgt_ix": "3-ARR_v1_70@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_71",
            "tgt_ix": "3-ARR_v1_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_72",
            "tgt_ix": "3-ARR_v1_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_72",
            "tgt_ix": "3-ARR_v1_72@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_72",
            "tgt_ix": "3-ARR_v1_72@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_72",
            "tgt_ix": "3-ARR_v1_72@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_73",
            "tgt_ix": "3-ARR_v1_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_73",
            "tgt_ix": "3-ARR_v1_73@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_73",
            "tgt_ix": "3-ARR_v1_73@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_73",
            "tgt_ix": "3-ARR_v1_73@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_74",
            "tgt_ix": "3-ARR_v1_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_74",
            "tgt_ix": "3-ARR_v1_74@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_74",
            "tgt_ix": "3-ARR_v1_74@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_75",
            "tgt_ix": "3-ARR_v1_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_76",
            "tgt_ix": "3-ARR_v1_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_76",
            "tgt_ix": "3-ARR_v1_76@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_77",
            "tgt_ix": "3-ARR_v1_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_78",
            "tgt_ix": "3-ARR_v1_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_79",
            "tgt_ix": "3-ARR_v1_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_79",
            "tgt_ix": "3-ARR_v1_79@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_80",
            "tgt_ix": "3-ARR_v1_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_80",
            "tgt_ix": "3-ARR_v1_80@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_80",
            "tgt_ix": "3-ARR_v1_80@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_80",
            "tgt_ix": "3-ARR_v1_80@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_81",
            "tgt_ix": "3-ARR_v1_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_81",
            "tgt_ix": "3-ARR_v1_81@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_81",
            "tgt_ix": "3-ARR_v1_81@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_82",
            "tgt_ix": "3-ARR_v1_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_82",
            "tgt_ix": "3-ARR_v1_82@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_82",
            "tgt_ix": "3-ARR_v1_82@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_83",
            "tgt_ix": "3-ARR_v1_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_83",
            "tgt_ix": "3-ARR_v1_83@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_84",
            "tgt_ix": "3-ARR_v1_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_84",
            "tgt_ix": "3-ARR_v1_84@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_84",
            "tgt_ix": "3-ARR_v1_84@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_84",
            "tgt_ix": "3-ARR_v1_84@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_85",
            "tgt_ix": "3-ARR_v1_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_86",
            "tgt_ix": "3-ARR_v1_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_87",
            "tgt_ix": "3-ARR_v1_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_87",
            "tgt_ix": "3-ARR_v1_87@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_87",
            "tgt_ix": "3-ARR_v1_87@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_87",
            "tgt_ix": "3-ARR_v1_87@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_87",
            "tgt_ix": "3-ARR_v1_87@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_88",
            "tgt_ix": "3-ARR_v1_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_89",
            "tgt_ix": "3-ARR_v1_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_90",
            "tgt_ix": "3-ARR_v1_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_90",
            "tgt_ix": "3-ARR_v1_90@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_90",
            "tgt_ix": "3-ARR_v1_90@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_90",
            "tgt_ix": "3-ARR_v1_90@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_90",
            "tgt_ix": "3-ARR_v1_90@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_90",
            "tgt_ix": "3-ARR_v1_90@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_90",
            "tgt_ix": "3-ARR_v1_90@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_91",
            "tgt_ix": "3-ARR_v1_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_91",
            "tgt_ix": "3-ARR_v1_91@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_92",
            "tgt_ix": "3-ARR_v1_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_92",
            "tgt_ix": "3-ARR_v1_92@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_93",
            "tgt_ix": "3-ARR_v1_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_93",
            "tgt_ix": "3-ARR_v1_93@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_93",
            "tgt_ix": "3-ARR_v1_93@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_93",
            "tgt_ix": "3-ARR_v1_93@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_94",
            "tgt_ix": "3-ARR_v1_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_94",
            "tgt_ix": "3-ARR_v1_94@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_94",
            "tgt_ix": "3-ARR_v1_94@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_94",
            "tgt_ix": "3-ARR_v1_94@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_94",
            "tgt_ix": "3-ARR_v1_94@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_95",
            "tgt_ix": "3-ARR_v1_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_95",
            "tgt_ix": "3-ARR_v1_95@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_95",
            "tgt_ix": "3-ARR_v1_95@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_95",
            "tgt_ix": "3-ARR_v1_95@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_95",
            "tgt_ix": "3-ARR_v1_95@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_96",
            "tgt_ix": "3-ARR_v1_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_97",
            "tgt_ix": "3-ARR_v1_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_98",
            "tgt_ix": "3-ARR_v1_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_99",
            "tgt_ix": "3-ARR_v1_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_99",
            "tgt_ix": "3-ARR_v1_99@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_100",
            "tgt_ix": "3-ARR_v1_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_100",
            "tgt_ix": "3-ARR_v1_100@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_100",
            "tgt_ix": "3-ARR_v1_100@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_101",
            "tgt_ix": "3-ARR_v1_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_102",
            "tgt_ix": "3-ARR_v1_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_103",
            "tgt_ix": "3-ARR_v1_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_103",
            "tgt_ix": "3-ARR_v1_103@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_103",
            "tgt_ix": "3-ARR_v1_103@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_103",
            "tgt_ix": "3-ARR_v1_103@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_103",
            "tgt_ix": "3-ARR_v1_103@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_104",
            "tgt_ix": "3-ARR_v1_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_104",
            "tgt_ix": "3-ARR_v1_104@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_104",
            "tgt_ix": "3-ARR_v1_104@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_104",
            "tgt_ix": "3-ARR_v1_104@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_105",
            "tgt_ix": "3-ARR_v1_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_105",
            "tgt_ix": "3-ARR_v1_105@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_106",
            "tgt_ix": "3-ARR_v1_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_106",
            "tgt_ix": "3-ARR_v1_106@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_106",
            "tgt_ix": "3-ARR_v1_106@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_106",
            "tgt_ix": "3-ARR_v1_106@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_107",
            "tgt_ix": "3-ARR_v1_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_107",
            "tgt_ix": "3-ARR_v1_107@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_108",
            "tgt_ix": "3-ARR_v1_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_109",
            "tgt_ix": "3-ARR_v1_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_110",
            "tgt_ix": "3-ARR_v1_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_110",
            "tgt_ix": "3-ARR_v1_110@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_110",
            "tgt_ix": "3-ARR_v1_110@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_110",
            "tgt_ix": "3-ARR_v1_110@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_111",
            "tgt_ix": "3-ARR_v1_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_111",
            "tgt_ix": "3-ARR_v1_111@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_111",
            "tgt_ix": "3-ARR_v1_111@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_111",
            "tgt_ix": "3-ARR_v1_111@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_111",
            "tgt_ix": "3-ARR_v1_111@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_111",
            "tgt_ix": "3-ARR_v1_111@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_112",
            "tgt_ix": "3-ARR_v1_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_113",
            "tgt_ix": "3-ARR_v1_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_113",
            "tgt_ix": "3-ARR_v1_113@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_113",
            "tgt_ix": "3-ARR_v1_113@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_113",
            "tgt_ix": "3-ARR_v1_113@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_114",
            "tgt_ix": "3-ARR_v1_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_115",
            "tgt_ix": "3-ARR_v1_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_116",
            "tgt_ix": "3-ARR_v1_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_117",
            "tgt_ix": "3-ARR_v1_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_118",
            "tgt_ix": "3-ARR_v1_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_119",
            "tgt_ix": "3-ARR_v1_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_120",
            "tgt_ix": "3-ARR_v1_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_121",
            "tgt_ix": "3-ARR_v1_121@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_122",
            "tgt_ix": "3-ARR_v1_122@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_123",
            "tgt_ix": "3-ARR_v1_123@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_124",
            "tgt_ix": "3-ARR_v1_124@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_125",
            "tgt_ix": "3-ARR_v1_125@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_126",
            "tgt_ix": "3-ARR_v1_126@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_127",
            "tgt_ix": "3-ARR_v1_127@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_128",
            "tgt_ix": "3-ARR_v1_128@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_129",
            "tgt_ix": "3-ARR_v1_129@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_130",
            "tgt_ix": "3-ARR_v1_130@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_131",
            "tgt_ix": "3-ARR_v1_131@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_132",
            "tgt_ix": "3-ARR_v1_132@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_133",
            "tgt_ix": "3-ARR_v1_133@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_134",
            "tgt_ix": "3-ARR_v1_134@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_135",
            "tgt_ix": "3-ARR_v1_135@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_136",
            "tgt_ix": "3-ARR_v1_136@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_137",
            "tgt_ix": "3-ARR_v1_137@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_138",
            "tgt_ix": "3-ARR_v1_138@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_139",
            "tgt_ix": "3-ARR_v1_139@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_140",
            "tgt_ix": "3-ARR_v1_140@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_141",
            "tgt_ix": "3-ARR_v1_141@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_142",
            "tgt_ix": "3-ARR_v1_142@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "3-ARR_v1_143",
            "tgt_ix": "3-ARR_v1_143@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 1413,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "position_tag_type": "from_draft",
        "doc_id": "3-ARR",
        "version": 1
    }
}