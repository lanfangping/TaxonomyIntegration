{
    "nodes": [
        {
            "ix": "284-ARR_v1_0",
            "content": "Zero-shot Cross-lingual Conversational Semantic Role Labeling",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_2",
            "content": "While conversational semantic role labeling (CSRL) has shown its usefulness on Chinese conversational tasks, it is still under-explored in non-Chinese languages due to the lack of multilingual CSRL annotations for the parser training. To avoid expensive data collection and error-propagation of translation-based methods, we present a simple but effective approach to perform zero-shot cross-lingual CSRL. Our model implicitly learns language-agnostic, conversational structure-aware and semantically rich representations with the hierarchical encoders and elaborately designed pre-training objectives. Experimental results show that our model outperforms all baselines by large margins on two newly collected English CSRL test sets. More importantly, we confirm the usefulness of CSRL to non-Chinese conversational tasks such as the question-in-context rewriting task in English and the multi-turn dialogue response generation tasks in English, German and Japanese by incorporating the CSRL information into the downstream conversation-based models. We believe this finding is significant and will facilitate the research of non-Chinese dialogue tasks which suffer the problems of ellipsis and anaphora.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "284-ARR_v1_4",
            "content": "Conversational Semantic Role Labeling (CSRL) (Xu et al., 2021) is a recently proposed dialogue understanding task, which aims to extract predicateargument pairs from the entire conversation. Figure 1 illustrates a CSRL example where a CSRL parser is required to identify \"\u300a\u6cf0\u5766\u5c3c\u514b\u53f7\u300b(Titanic)\" as the ARG1 argument of the predicate \"\u770b \u8fc7 (watched)\" and the ARG0 argument of the predicate \"\u662f (is)\". We can see that in the original conversation, \"\u300a\u6cf0\u5766\u5c3c\u514b\u53f7\u300b(Titanic)\" is omitted in the second turn and referred as \"\u8fd9 (this)\" in the last turn. By recovering the dropped and referred components in conversation, CSRL has shown its usefulness to a set of Chinese dialogue tasks, including multi-turn dialogue rewriting (Su et al., 2019) and response generation (Wu et al., 2019). However, there remains a paucity of evidence on its effectiveness towards non-Chinese languages owing to the lack of multilingual CSRL models. To adapt a model into new languages, previous solutions can be divided into three categories: 1) manually annotating a new dataset in the target language (Daza and Frank, 2020) 2) borrowing machine translation and word alignment techniques to transfer the dataset from the source language into the target language (Daza and Frank, 2019;Fei et al., 2020a) 3) zero-shot transfer learning with multilingual pre-trained language model (Rijhwani et al., 2019;Sherborne and Lapata, 2021). Due to the fact that manually collecting annotations is costly and translation-based methods might introduce translation or word alignment errors, zeroshot cross-lingual transfer learning is more practical to the NLP community.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_5",
            "content": "Recent works have witnessed prominent performances of multilingual pre-trained language models (PrLMs) (Devlin et al., 2019;Conneau et al., 2020) on cross-lingual tasks, including machine translation (Lin et al., 2020;Chen et al., 2021), semantic role labeling (SRL) (Conia and Navigli, 2020;Conia et al., 2021) and semantic parsing (Fei et al., 2020b;Sherborne and Lapata, 2021). However, cross-lingual CSRL, as a combination of three challenging tasks (i.e., cross-lingual task, dialogue task and SRL task), suffers three outstanding difficulties: 1) latent space alignment -how to map word representations of different languages into an overlapping space; 2) conversation structure encoding -how to capture high-level dialogue features such as speaker dependency and temporal dependency; and 3) semantic arguments identification -how to highlight the relations between the predicate and its arguments, wherein PrLMs can only partially encode multilingual inputs to an overlapping vector space. Although there are some success that can separately achieve structural conversation encoding (Mehri et al., 2019;Zhang and Zhao, 2021) and semantic arguments identification (Wu et al., 2021a), a unified method for jointly solving these problems is still under-explored, especially in a cross-lingual scenario.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_6",
            "content": "In this work, we summarize our contributions as follows: (1) We propose a simple but effective model which consists of three modules, namely cross-lingual language model (CLM), structureaware conversation encoder (SA-Encoder) and predicate-argument encoder (PA-Encoder), and five well-designed pre-training objectives. Our model implicitly learns language-agnostic, conversational structure-aware and semantically rich representations to perform zero-shot cross-lingual CSRL. (2) Experiments show that our method achieves impressive cross-lingual performance on the language pair (Zh\u2192En) , and outperforms all baselines on the two newly collected English CSRL test sets. (3) We confirm the usefulness of CSRL to the questionin-context rewriting task in English and multi-turn response generation tasks in English, German and Japanese. We believe this finding is important and will facilitate the research of non-Chinese dialogue tasks that suffer from ellipsis and anaphora. (4) We will release our code, the new annotated English CSRL test sets and checkpoints of our best models to facilitate the further research.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_7",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "284-ARR_v1_8",
            "content": "Zero-shot cross-lingual transfer learning. Recently, thanks to the rapid development of multilingual pre-trained language models such as multilingual BERT (Devlin et al., 2019) and XLM-R (Conneau et al., 2020), a number of approaches have been proposed for zero-shot cross-lingual transfer learning on various downstream tasks, including semantic parsing (Sherborne and Lapata, 2021), natural language generation (Shen et al., 2018) and understanding Lauscher et al., 2020). In this work, we claim our method is zeroshot because no non-Chinese CSRL annotations are seen during the CSRL training stage. For decoding, we directly use the cross-lingual CSRL model trained on Chinese CSRL data to analyze conversations in other languages. To our best knowledge, our work is the first step to cross-lingual CSRL.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_9",
            "content": "Conversational semantic role labeling. While ellipsis and anaphora frequently occur in dialogues, Xu et al. (2021) observed that most of the dropped or referred components can be found in dialogue histories. Following this observation, they proposed conversational semantic role labeling (CSRL) which required the model to find predicateargument structures over the entire conversation instead of a single sentence. In this way, when analyzing a predicate in the latest utterance, a CSRL model needs to consider both the current turn and previous turns to search potential arguments, and thus might recover the omitted components. Furthermore, Xu et al. (2020Xu et al. ( , 2021) also confirmed the usefulness of CSRL to Chinese dialogue tasks by applying CSRL information into downstream dialogue tasks. However, there are still two main problems to be solved for CSRL task: (1) the performance of current state-of-the-art CSRL model (Xu et al., 2021) is still far from satisfactory due to the lack of high-level conversational and semantic features modeling; (2) the usefulness of CSRL to conversational tasks in non-Chinese languages has not been confirmed yet due to the lack of cross-lingual CSRL models. In this work, we primarily focus on the latter problem and propose a simple but effective model to perform cross-lingual CSRL. We would like to distinguish our work from the concurrent work (Wu et al., 2021b) which purely focuses on improving the monolingual CSRL performance where they try to model predicate-aware representations. This solution could benefit to monolingual CSRL task, but hurt the cross-lingual performance, because the relative positions of the predicates may differ from language to language.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_10",
            "content": "Methodology",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "284-ARR_v1_11",
            "content": "Following Xu et al. (2021), we solve the CSRL task as a sequence labeling problem. Formally, given a dialogue C = {u 1 , u 2 , ..., u N } of N utterances, where u i = {w i 1 , w a word is the predicate or not, our goal is to assign each word with a semantic role label l \u2208 L where L is the label set. We also incorporate speaker role indicator r to distinguish speakers, and dialogue turn indicator t to distinguish dialogue turns.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_12",
            "content": "Architecture",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "284-ARR_v1_13",
            "content": "Cross-lingual Language Model (CLM) We concatenate all utterances into a sequence and then use a pre-trained cross-lingual language model such as XLM-R (Conneau et al., 2020) or mBERT (Devlin et al., 2019) to capture the syntactic and semantic characteristics. Following Conia et al. (2021), we obtain word representations e \u2208 R |S|\u00d7d by concatenating the hidden states of the four top-most layers of the language model, where |S| is the sequence length and d is the dimension of the hidden state.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_14",
            "content": "Structure-aware Conversation Encoder (SC-Encoder) Different from standard SRL (Carreras and M\u00e0rquez, 2005), CSRL requires the models to find arguments from not only the current turn, but also previous turns, thus bringing more challenges of dialogue modeling. To address this problem, we propose a universal structure-aware conversation encoder which comprises of two parts, i.e., wordlevel encoder and utterance-level encoder. Formally, with the speaker role embedding r \u2208 R |S|\u00d7d and dialogue turn embedding t \u2208 R |S|\u00d7d , the wordlevel encoder computes a sequence of timestep encodings s \u2208 R |S|\u00d7d as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_15",
            "content": "s j (i,k) = e i k \u2295 t i k \u2295 r i k if j = 0 s j\u22121 (i,k) \u2295 MTRANS j (s j\u22121 (i,k) ) otherwise (1)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_16",
            "content": "where s j (i,k) is the timestep encoding of k-th token in i-th utterance from j-th word-level encoder layer while j \u2208 (0, . . . , N 1 ), \u2295 represents vector concatenation, and MTRANS is the Modified Transformer encoder layer. Concretely, we replace the [Add] operation in the first residual connection layer with [Concat] because we argue that concatenation is a superior approach to preserve the information from previous layers 1 .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_17",
            "content": "We obtain utterance representations u \u2208 R N \u00d7d by max-pooling over words in the same utterance. Then we pass the resulting utterance representations u through a stack of Bi-LSTM (Hochreiter and Schmidhuber, 1997) layers to obtain the sequentially encoded utterance representations u \u2032 \u2208 R N \u00d7d . Finally, we combine the utterance-level feature u \u2032 with the word-level feature s to obtain structure-aware dialogue context representations g \u2208 R |S|\u00d7d as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_18",
            "content": "g i k = Swish(W g [s N 1 (i,k) \u2295 u \u2032 i ] + b g )(2)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_19",
            "content": "where Swish(x) = x \u2022 sigmoid(x) is a non-linear activation function, s N 1 i,k is the encoding of k-th token in i-th utterance from the last layer of the word-level encoder. W g and b g are trainable parameters.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_20",
            "content": "We introduce the third module (i.e., predicateargument encoder) whose goal is to capture the relations between each predicate-argument couple that appears in the conversation. Similar with the word-level encoder, we use a stack of MTRANS layers to implement this encoder. Formally, with the predicate embedding p \u2208 R |S|\u00d7d , the model calculates the predicate-specific argument encodings a \u2208 R |S|\u00d7d as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_21",
            "content": "a j (i,k) = g i k \u2295 p i k if j = 0 a j\u22121 (i,k) \u2295 MTRANS j (a j\u22121 (i,k) ) otherwise (3)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_22",
            "content": "where a j (i,k) is the argument encoding of k-th token in i-th utterance from j-th encoder layer while j \u2208 (0, . . . , N 2 ). Finally, we obtain the semantic role encoding l using the resulting argument encodings from the last layer of the predicate-argument encoder:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_23",
            "content": "l i k = Swish(W l a N 2 (i,k) + b l )(4)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_24",
            "content": "In particular, our proposed model is mostly language-agnostic since we do not explicitly introduce any language-specific knowledge such as word order, part-of-speech tags or dependent relations, and only introduce the predicate indicator that might contain some language-specific information in the semantic module, which would not affect latent space alignment and dialogue modeling.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_25",
            "content": "Pre-training Objectives",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "284-ARR_v1_26",
            "content": "Besides the universal model, we also elaborately design five pre-training objectives to model taskspecific but language-agnostic features for better cross-lingual performance. In this section, we divide our pre-training objectives into three groups according to the challenges to be solved.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_27",
            "content": "Latent space alignment In cross-lingual language module, we use mBERT or XLM-R to align the latent space of different languages. Although mBERT and XLM-R have exhibited good alignment ability, even both of them are trained with unpaired data, we may further improve it when we have access to parallel data. We first use translation language model (TLM) (Conneau and Lample, 2019) to learn word-level alignment ability. Concretely, we concatenate parallel sentences as a single consecutive token sequence with special tokens separating them and then perform masked language modeling (MLM) (Devlin et al., 2019) on the concatenated sequence. Besides, we also attempt to improve sentence-level alignment ability using hard parallel sentence identification (HPSI). Specifically, we select a pair of parallel or non-parallel sentences from the training set with equal probability. Then the model is required to predict whether the sampled sentence pair is parallel or not. Different from the standard PSI (Dou and Neubig, 2021), we sample the non-parallel sentence upon the n-gram similarity or construct it by text perturbation (details in Appendix A) instead of in a random manner. Figure 3 illustrates the workflows of TLM and HPSI. We pre-train the CLM using the combination of TLM and HPSI, finally achieving latent space alignment.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_28",
            "content": "Conversation structure encoding Although there are a number of pre-training objectives proposed to learn dialogue context representations (Mehri et al., 2019) and structural representations (Zhang and Zhao, 2021), we tend to explicitly model speaker dependency and temporal dependency in the conversation, both of which have been proven to be critical to CSRL task (Xu et al., 2021).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_29",
            "content": "We first propose speaker role identification (SPI) to learn speaker dependency in the conversation. Specifically, we randomly sample K 1 % utterances and replace their speaker indicators with special mask tags. To make the task harder and effective, we split the utterances into clauses if only two interlocutors utter in turn in a conversation. The goal of SPI is to predict the masked speaker roles according to the corrupted speaker indicators and context. Secondly, we borrow utterance order permutation (UOR) to encourage the model to be aware of temporal connections among utterances in the context. Concretely, given a set of utterances, we randomly shuffle the last K 2 % utterances and require the model to organize them into a coherent context. Figure 4 illustrates the workflows of SPI and UOR. We pre-train the SC-Encoder using the combination of SPI and UOR.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_30",
            "content": "The core of all SRL-related tasks is to recognize the predicateargument pairs from the input. Therefore, we propose semantic arguments identification (SAI) objective to strengthen the correlations between the predicate and its arguments with the help of external standard SRL corpus, i.e., CoNLL-2012. Specifically, for each SRL sample, we only focus on those arguments, including ARG0-4, ARG-LOC, ARG-TMP and ARG-PRP, all of which are defined in both SRL and CSRL tasks. The model is encouraged to find the textual spans of these arguments with the given predicate. We believe this objective would benefit to boundary detection, especially for location and temporal arguments. Figure 5 illustrates the workflow of SAI. We drop the SC-Encoder to fit in standard SRL samples which do not have any conversational characteristics.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_31",
            "content": "Training",
            "ntype": "title",
            "meta": {
                "section": "3.3"
            }
        },
        {
            "ix": "284-ARR_v1_32",
            "content": "Hierarchical Pre-training The pre-training is hierarchically conducted according to different modules, and the pre-training of the upper module is based on the pre-trained lower modules. Specifically, we first train CLM module with TLM and HPSI; then we train SC-Encoder with SPI and UOR while keeping the weights of pre-trained CLM module unchanged; finally we train PA-Encoder with SAI while freezing the weights of pre-trained CLM and SC-Encoder modules. Hopefully, we expect that each module could acquire different knowledge with specific pre-training objectives. (2021) where DuConv annotations are splitted into 80%/10%/10% as train/dev/in-domain test set. Furthermore, we manually collect two CSRL test sets 2 for cross-lingual evaluation based on Persona-Chat (Zhang et al., 2018) and CMU-DoG (Zhou et al., 2018), both of which are English conversation datasets. The CSRL data annotation is difficult because it needs great expertise in SRL and dialogue. So we only explore cross-lingual CSRL on Chinese\u2192English (Zh\u2192En) here, and we leave other languages for future work.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_33",
            "content": "Pre-training data For TLM and HPSI objectives which requires parallel data to enhance alignment ability, we choose IWSLT'14 English\u2194Chinese (En\u2194Zh) translations 3 . For SPI and UOR objectives whose goal is to model high-level conversational features, we select samples from Chinese conversation dataset (i.e., DuConv) and English conversation datasets (i.e., Persona-Chat and CMU-DoG) with equal probability. For SAI, we borrow the Chinese and English SRL annotations from CoNLL-2012(Pradhan et al., 2012.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_34",
            "content": "We stress that by keeping the sampling balance of Chinese and English data for every pre-training objective and sharing all parameters across the languages, our model would capture task-specific but language-agnostic features.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_35",
            "content": "Experimental Setup",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "284-ARR_v1_36",
            "content": "Following previous work (Xu et al., 2021), we evaluate our system on micro-average F1 all , F1 cross and F1 intra over the (predicate, argument, label) tuples, wherein we calculate F1 cross and F1 intra over the arguments in the different, or same turn as the predicate. We refer these two types of arguments as cross-arguments and intra-arguments.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_37",
            "content": "Main Results",
            "ntype": "title",
            "meta": {
                "section": "4.3"
            }
        },
        {
            "ix": "284-ARR_v1_38",
            "content": "Table 1 summarized the results of all compared methods on DuConv, Persona-Chat and CMU-DoG datasets. Firstly, we can see that our method achieves competitive performance over all datasets, especially in cross-lingual scenario where our method outperforms the baselines by large margins no matter fine-tuning or freezing the language model during the CSRL training stage. Although CSAGN exceeds our method on DuConv test set, it fails to work well in cross-lingual scenario. We think this is because it heavily relies on the rich features from the Chinese pre-trained language model and it is overfitting on the predicate-aware information. Superior to CSAGN, our model with the multilingual backbone achieves outstanding performance on both language in-domain and crosslingual datasets. This observation is expected because (1) our model is language-agnostic which makes the cross-lingual transfer easier;",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_39",
            "content": "(2) our model captures high-level conversational features in SC-Encoder, thus enhancing the capacities of the model to recognize cross-arguments;",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_40",
            "content": "(3) rich semantic features are modeled by PA-Encoder, which would improve the capacities of the model to recognize intra-arguments.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_41",
            "content": "Secondly, although our model has achieved good performance over all datasets, further improvements can be observed after incorporating the proposed pre-training objectives, especially when freezing the parameters of the language model. Exceptionally, we find that the performance on the CMU-DoG dataset heavily drops after introducing the pre-training objectives, especially in terms of F1 intra . We think this is because the semantic argument spans in CoNLL-2012 are relatively different from those in CMU-DoG, thus leading to the vague boundary detection and performance drop. To verify this assumption, we conduct an ablation study by removing SAI from the pre-training stage. Interestingly, we observe substantial improvements over F1 all and F1 intra , suggesting that pre-training on CoNLL-2012 does hurt the performance on CMU-DoG. Furthermore, we also find that fine-tuning all parameters leads to slightly better performance than freezing the language model during the CSRL training stage. This finding is consistent with the previous work (Conia et al., 2021).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_42",
            "content": "Table 2 presents the results of ablation studies on pre-training objectives and different modules. For the pre-training objectives, we found that (1) removing TLM & HPSI objective hurts the performance consistently but slightly; (2) SPI & UOR objectives help the model to better identify the cross-arguments; (3) SAI objective helps to find intra-arguments on DuConv and Persona-Chat, but might hurt the F1 intra score on CMU-DoG; (4) hierarchical pre-training is superior to end-to-end pre-training which simultaneously optimizes all auxiliary objectives. We think this is because the end2end pre-training is extremely unstable and confuses the optimization process of the model.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_43",
            "content": "For model components, we found that only removing one of the SC-Encoder, PA-Encoder or MTRANS slightly affect the performance. However, the performance heavily decreases when SC-Encoder and PA-Encoder are both removed. We think the reason is that at least one module is needed to capture the high-level features on the top of the language model. We preserve these two modules in our model since they essentially learn different abilities, i.e., the ability of dialogue modeling and semantics modeling, which also makes our model more explainable. et al. (2021) has confirmed the usefulness of CSRL by applying CSRL parsing results to two Chinese dialogue tasks, including dialogue context rewriting and dialogue response generation. In the same vein, we also explore whether CSRL could benefit to the same non-Chinese dialogue tasks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_44",
            "content": "Applications",
            "ntype": "title",
            "meta": {
                "section": "4.4"
            }
        },
        {
            "ix": "284-ARR_v1_45",
            "content": "Question-in-context Rewriting Question-incontext rewriting (Elgohary et al., 2019) is a challenging task which requires the model to resolve the conversational dependencies between the question and the context, and then rewrite the original question into independent one. This is an example in Table 3. The question \"who did they play in the playoffs?\" cannot be independently understood without knowing \"they\" refer to, but it can be resolved with the given context.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_46",
            "content": "Since the CSRL models can identify the predicate-argument structures from the entire conversation, we believe that it can help this rewriting task by searching the dropped or referred components from the context. For example, in Table 3, our CSRL parser can find that the ARG0 of the predicate \"play\" is \"the Colts\". Motivated by this observation, we attempt to borrow CSRL to help the question rewriting with the context. We first employ the pre-trained cross-lingual CSRL parser (Ours XLM-R + pre-train ) to extract predicate-argument pairs from conversations. We adopt the model proposed in (Xu et al., 2020) to achieve the rewriting. More details about the model are in Appendix F.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_47",
            "content": "Since the rewriting datasets are only available in Chinese and English, we hereby only evaluate on CANARD (Elgohary et al., 2019) which is a widely used English question rewriting dataset, and report the BLEU scores. mance against the state-of-the-art rewriting models, i.e., SARG (Huang et al., 2020) and RUN (Liu et al., 2020a), and significantly outperforms the baseline method (Bahdanau et al., 2014). Note that, in this part, we are more focused on the improvements after introducing CSRL information. We find that the scores across all metrics are improved with the aid of CSRL. To figure out the reasons of these improvements, we investigate which type of questions could benefit from CSRL information most. By comparing the rewritten questions of different methods, we find that the questions that require information completion, especially those containing referred components (around 15% cases), benefit from CSRL most. This observation is in line with our expectation that our CSRL parser could consistently offer essential guidance by recovering the dropped or referred text components.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_48",
            "content": "Multi-turn Dialogue Response Generation Besides the rewriting task that is heavily affected by omitted components, we also explore the usefulness of CSRL to multi-turn dialogue response generation, one of the main challenges in dialogue community. In contrast to single-turn dialogue response generation, multi-turn dialogues suffer more frequently occurred ellipsis and anaphora, which leads to vague context representations. To this end, we attempt to employ CSRL to build better context representations. In specific, we highlight the words picked up by the CSRL parser, and then teach the model to pay more attention on those words which would hold more semantic features. We evaluate on three dialogue datasets in different languages, including Persona-Chat (Zhang et al., 2018) in English, BConTrast (Farajian et al., 2020) in German and BSD (Rikters et al., 2019) in Japanese. We report BLEU-1/2 and Distinct-1/2 scores for the comparison. We employ the pre-trained cross-lingual CSRL parser (Ours XLM-R ) to analyze the latest utterance, and obtain the predicate-argument pairs. Then the concatenated sequence of the extracted pairs and the context is fed into our model for response generation. We adopt the UniLM (Dong et al., 2019) or mBART (Liu et al., 2020b) as our generation model. More implementation details are in Appendix F.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_49",
            "content": "Table 4 summarizes the results on three datasets. We can see that the models with different backbones can consistently benefit from the additional introduced CSRL information. While substantial gains from CSRL information are obtained on English and Japanese dialogues, smaller improvements are observed on the German dialogue task. We think this is because English is well-represented in pre-trained multilingual models and Japanese is more similar to Chinese while German accounts for none of both. Apart from automatic evaluation criteria, we also conduct human evaluation on the English dataset. Specifically, we randomly select 200 generated responses for each method, and then recruit three annotators to evaluate the coherence and informativeness of the response against the conversation context by giving a score ranging from 1(worst) to 5(best). We find that the method with CSRL wins in 35% cases, and ties with the vanilla model in around 55% cases. With more careful analysis, we find that the responses that contains entities mentioned in histories benefit from CSRL information most. We think this is because nonephrases are more likely to be recognized as semantic arguments by CSRL parser, and then receive more attentions during encoding.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_50",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "284-ARR_v1_51",
            "content": "In this work, we propose a simple but effective model with five pre-training objectives to perform zero-shot cross-lingual CSRL, and also confirm the usefulness of CSRL to non-Chinese dialogue tasks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_52",
            "content": "Following previous work (Robinson et al., 2020;Wei et al., 2020) which suggests that contrastive learning of representations benefits from hard negative samples, we also try to select hard negative samples for PSI task based on n-gram similarity and text perturbation. Specifically, for each sentence, we calculate its n-gram similarity scores to other sentences, where n = 1, 2, 3, 4, and then we select the sentence with the highest score at each gram as the candidate sentence; additionally, we construct the corrupted sentence as the candidate by token deletion, token replacement and token order permutation. Finally, we sample from the candidate set created by n-gram similarity at 40% time and from the candidate set created by text perturbation at 60% time.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_53",
            "content": "To overcome the information forgetting of hierarchical models, we attempt to modify the standard Transformer to better reserve the information from the previous layers. In specific, we try following variants:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_54",
            "content": "\u2022 MTRANS. Our intuition of substituting the summation with concatenation is that the residual layer with concatenation would introduce additional parameters, and we expect these additional parameters to retain more history information. As shown in Table 1, we obtain some gains while using MTRANS. Additionally, we also report the F1 all scores on DuConv/Persona-Chat/CMU-DoG datasets while using LATER-MTRANS and BOTH-MTRANS here.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_55",
            "content": "Following the instructions in Xu et al. (2021), we manually collect two out-of-domain CSRL test sets based on English dialogue datasets Persona-Chat (Zhang et al., 2018) and CMU-DoG (Zhou et al., 2018). Specifically, we also annotate the arguments ARG0-4, ARG-TMP, ARG-LOC and ARG-PRP and require that the labeled arguments can only appear in the current turn or the previous turns. We employ three annotators who have studied Chinese CSRL annotations for a period time before this annotation. The first two annotators are required to label all cases and any disagreements between them are solved by the third annotator. The statistics of the datasets are listed in Table 6.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_56",
            "content": "We implement the model in PyTorch (Paszke et al., 2019), and use the pre-trained language model of multilingual BERT (mBERT) or XLM-RoBERTa (XLM-R) made available by the Transformer library (Wolf et al., 2020) as the backbone. We train the model using AdamW (Loshchilov and Hutter, 2018) with a linear learning rate schedule. For each model, we run five different random seeds and report the average score. More details and hyper-parameters are listed in Table 8.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_57",
            "content": "We compare to following baseline models, 1. SimpleBERT/SimpleXLMR (Shi and Lin, 2019). It uses the Chinese BERT or XLM-R as the backbone and simply concatenates the entire dialogue context with the predicate.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_58",
            "content": "2. CSRL-BERT/XLMR (Xu et al., 2021). It uses the Chinese BERT or XLM-R as the backbone but attempts to encode the conversation structural information by integrating the dialogue turn and speaker embeddings in the input embedding layer.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_59",
            "content": "3. CSAGN/CSAGN-XLMR (Wu et al., 2021b",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_60",
            "content": "Rewriting Model. We adopt the model proposed in (Xu et al., 2020) which directly concatenates the predicate-argument structures, the conversation context and the question as a sequence, and then feeds them into the model with special attention masks. During decoding, the model takes CSRL pairs and the context to generate the rewritten question word by word. The input representation, attention strategies and loss function of our model are same as (Xu et al., 2020)'s. We initialize the model using the base BERT model and use AdamW with a linear learning rate schedule to update parameters. Note that we only attempt to introduce the CSRL information as a condition into our generationbased model. We did not include the CSRL information into the state-of-the-art rewriting models, i.e., SARG and RUN because these models rewrite the sentence by learning a text editing matrix instead of directly learning the distributions of the target words. Unfortunately, there are no straightforward ways to include our CSRL information into these models to help the matrix learning.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_61",
            "content": "Response Generation Model. Our model for response generation is directly borrowed from UniLM (Dong et al., 2019) or mBART (Liu et al., 2020b). For UniLM, the generation process is same with the rewriting task, wherein the extracted semantic pairs, the context and the response are concatenated into a sequence and encoded with the special mask. For mBART, we just concatenate the extracted predicate-argument pairs with the context into a sequence, and then feed the sequence into the encoder for training; during decoding, our model takes semantic information and the context as input to generate the response word by word. The input representation, attention strategies for CSRL structures and loss function are same as the rewriter model's. We initialize the model using the base multilingual BERT or mBART and use AdamW with a linear learning rate schedule to update parameters.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_62",
            "content": "We report some more detailed experimental results here. Table 7 summarize the standard deviations of the main evaluation results on three datasets.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_63",
            "content": "We list the hyper-parameters of CSRL experiments (Table 8), rewriting experiments (Table 9) and response experiments (",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "284-ARR_v1_64",
            "content": "UNKNOWN, None, 2014, Neural machine translation by jointly learning to align and translate, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": null,
                "title": null,
                "pub_date": "2014",
                "pub_title": "Neural machine translation by jointly learning to align and translate",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_65",
            "content": "Xavier Carreras, Llu\u00eds M\u00e0rquez, Introduction to the conll-2005 shared task: Semantic role labeling, 2005, Proceedings of the ninth conference on computational natural language learning (CoNLL-2005), .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Xavier Carreras",
                    "Llu\u00eds M\u00e0rquez"
                ],
                "title": "Introduction to the conll-2005 shared task: Semantic role labeling",
                "pub_date": "2005",
                "pub_title": "Proceedings of the ninth conference on computational natural language learning (CoNLL-2005)",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_66",
            "content": "Guanhua Chen, Shuming Ma, Yun Chen, Li Dong, Dongdong Zhang, Jia Pan, Wenping Wang, Furu Wei, Zero-shot cross-lingual transfer of neural machine translation with multilingual pretrained encoders, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "Guanhua Chen",
                    "Shuming Ma",
                    "Yun Chen",
                    "Li Dong",
                    "Dongdong Zhang",
                    "Jia Pan",
                    "Wenping Wang",
                    "Furu Wei"
                ],
                "title": "Zero-shot cross-lingual transfer of neural machine translation with multilingual pretrained encoders",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "284-ARR_v1_67",
            "content": "Simone Conia, Andrea Bacciu, Roberto Navigli, Unifying cross-lingual semantic role labeling with heterogeneous linguistic resources, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Simone Conia",
                    "Andrea Bacciu",
                    "Roberto Navigli"
                ],
                "title": "Unifying cross-lingual semantic role labeling with heterogeneous linguistic resources",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_68",
            "content": "Simone Conia, Roberto Navigli, Bridging the gap in multilingual semantic role labeling: a language-agnostic approach, 2020, Proceedings of the 28th International Conference on Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Simone Conia",
                    "Roberto Navigli"
                ],
                "title": "Bridging the gap in multilingual semantic role labeling: a language-agnostic approach",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 28th International Conference on Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_69",
            "content": "Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettlemoyer, Veselin Stoyanov, Unsupervised cross-lingual representation learning at scale, 2020, ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "Alexis Conneau",
                    "Kartikay Khandelwal",
                    "Naman Goyal",
                    "Vishrav Chaudhary",
                    "Guillaume Wenzek",
                    "Francisco Guzm\u00e1n",
                    "Edouard Grave",
                    "Myle Ott",
                    "Luke Zettlemoyer",
                    "Veselin Stoyanov"
                ],
                "title": "Unsupervised cross-lingual representation learning at scale",
                "pub_date": "2020",
                "pub_title": "ACL",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_70",
            "content": "Alexis Conneau, Guillaume , Crosslingual language model pretraining, 2019, Advances in Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "Alexis Conneau",
                    "Guillaume "
                ],
                "title": "Crosslingual language model pretraining",
                "pub_date": "2019",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_71",
            "content": "Angel Daza, Anette Frank, Translate and label! an encoder-decoder approach for cross-lingual semantic role labeling, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Angel Daza",
                    "Anette Frank"
                ],
                "title": "Translate and label! an encoder-decoder approach for cross-lingual semantic role labeling",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_72",
            "content": "Angel Daza, Anette Frank, X-srl: A parallel cross-lingual semantic role labeling dataset, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Angel Daza",
                    "Anette Frank"
                ],
                "title": "X-srl: A parallel cross-lingual semantic role labeling dataset",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_73",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, Bert: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Jacob Devlin",
                    "Ming-Wei Chang",
                    "Kenton Lee",
                    "Kristina Toutanova"
                ],
                "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_74",
            "content": "Li Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou, Hsiao-Wuen Hon, Unified language model pre-training for natural language understanding and generation, 2019, Proceedings of the 33rd International Conference on Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Li Dong",
                    "Nan Yang",
                    "Wenhui Wang",
                    "Furu Wei",
                    "Xiaodong Liu",
                    "Yu Wang",
                    "Jianfeng Gao",
                    "Ming Zhou",
                    "Hsiao-Wuen Hon"
                ],
                "title": "Unified language model pre-training for natural language understanding and generation",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 33rd International Conference on Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_75",
            "content": "Yi Zi, Graham Dou,  Neubig, Word alignment by fine-tuning embeddings on parallel corpora, 2021, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Yi Zi",
                    "Graham Dou",
                    " Neubig"
                ],
                "title": "Word alignment by fine-tuning embeddings on parallel corpora",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_76",
            "content": "Ahmed Elgohary, Denis Peskov, Jordan Boyd-Graber, Can you unpack that? learning to rewrite questions-in-context, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Ahmed Elgohary",
                    "Denis Peskov",
                    "Jordan Boyd-Graber"
                ],
                "title": "Can you unpack that? learning to rewrite questions-in-context",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "284-ARR_v1_77",
            "content": "M Amin Farajian, V Ant\u00f3nio,  Lopes, F Andr\u00e9, Sameen Martins, Gholamreza Maruf,  Haffari, Findings of the wmt 2020 shared task on chat translation, 2020, Proceedings of the Fifth Conference on Machine Translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    " M Amin Farajian",
                    "V Ant\u00f3nio",
                    " Lopes",
                    "F Andr\u00e9",
                    "Sameen Martins",
                    "Gholamreza Maruf",
                    " Haffari"
                ],
                "title": "Findings of the wmt 2020 shared task on chat translation",
                "pub_date": "2020",
                "pub_title": "Proceedings of the Fifth Conference on Machine Translation",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_78",
            "content": "Meishan Hao Fei, Donghong Zhang,  Ji, Cross-lingual semantic role labeling with highquality translated training corpus, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Meishan Hao Fei",
                    "Donghong Zhang",
                    " Ji"
                ],
                "title": "Cross-lingual semantic role labeling with highquality translated training corpus",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_79",
            "content": "Meishan Hao Fei, Fei Zhang, Donghong Li,  Ji, Cross-lingual semantic role labeling with model transfer, 2020, IEEE/ACM Transactions on Audio, Speech, and Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Meishan Hao Fei",
                    "Fei Zhang",
                    "Donghong Li",
                    " Ji"
                ],
                "title": "Cross-lingual semantic role labeling with model transfer",
                "pub_date": "2020",
                "pub_title": "IEEE/ACM Transactions on Audio, Speech, and Language Processing",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_80",
            "content": "Sepp Hochreiter, J\u00fcrgen Schmidhuber, Long short-term memory, 1997, Neural computation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "Sepp Hochreiter",
                    "J\u00fcrgen Schmidhuber"
                ],
                "title": "Long short-term memory",
                "pub_date": "1997",
                "pub_title": "Neural computation",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_81",
            "content": "UNKNOWN, None, 2020, Sarg: A novel semi autoregressive generator for multi-turn incomplete utterance restoration, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Sarg: A novel semi autoregressive generator for multi-turn incomplete utterance restoration",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_82",
            "content": "Anne Lauscher, Vinit Ravishankar, Ivan Vuli\u0107, Goran Glava\u0161, From zero to hero: On the limitations of zero-shot language transfer with multilingual transformers, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Anne Lauscher",
                    "Vinit Ravishankar",
                    "Ivan Vuli\u0107",
                    "Goran Glava\u0161"
                ],
                "title": "From zero to hero: On the limitations of zero-shot language transfer with multilingual transformers",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_83",
            "content": "Zehui Lin, Xiao Pan, Mingxuan Wang, Xipeng Qiu, Jiangtao Feng, Hao Zhou, Lei Li, Pretraining multilingual neural machine translation by leveraging alignment information, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "Zehui Lin",
                    "Xiao Pan",
                    "Mingxuan Wang",
                    "Xipeng Qiu",
                    "Jiangtao Feng",
                    "Hao Zhou",
                    "Lei Li"
                ],
                "title": "Pretraining multilingual neural machine translation by leveraging alignment information",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_84",
            "content": "Qian Liu, Bei Chen, Jian-Guang Lou, Bin Zhou, Dongmei Zhang, Incomplete utterance rewriting as semantic segmentation, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Qian Liu",
                    "Bei Chen",
                    "Jian-Guang Lou",
                    "Bin Zhou",
                    "Dongmei Zhang"
                ],
                "title": "Incomplete utterance rewriting as semantic segmentation",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_85",
            "content": "Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer, Multilingual denoising pre-training for neural machine translation, 2020, Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "Yinhan Liu",
                    "Jiatao Gu",
                    "Naman Goyal",
                    "Xian Li",
                    "Sergey Edunov",
                    "Marjan Ghazvininejad",
                    "Mike Lewis",
                    "Luke Zettlemoyer"
                ],
                "title": "Multilingual denoising pre-training for neural machine translation",
                "pub_date": "2020",
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_86",
            "content": "Zihan Liu, Jamin Shin, Yan Xu, Genta Indra Winata, Peng Xu, Andrea Madotto, Pascale Fung, Zero-shot cross-lingual dialogue systems with transferable latent variables, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Zihan Liu",
                    "Jamin Shin",
                    "Yan Xu",
                    "Genta Indra Winata",
                    "Peng Xu",
                    "Andrea Madotto",
                    "Pascale Fung"
                ],
                "title": "Zero-shot cross-lingual dialogue systems with transferable latent variables",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_87",
            "content": "Ilya Loshchilov, Frank Hutter, Decoupled weight decay regularization, 2018, International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Ilya Loshchilov",
                    "Frank Hutter"
                ],
                "title": "Decoupled weight decay regularization",
                "pub_date": "2018",
                "pub_title": "International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_88",
            "content": "Shikib Mehri, Evgeniia Razumovskaia, Tiancheng Zhao, Maxine Eskenazi, Pretraining methods for dialog context representation learning, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Shikib Mehri",
                    "Evgeniia Razumovskaia",
                    "Tiancheng Zhao",
                    "Maxine Eskenazi"
                ],
                "title": "Pretraining methods for dialog context representation learning",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_89",
            "content": "Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Pytorch: An imperative style, high-performance deep learning library, 2019, Advances in neural information processing systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Adam Paszke",
                    "Sam Gross",
                    "Francisco Massa",
                    "Adam Lerer",
                    "James Bradbury",
                    "Gregory Chanan",
                    "Trevor Killeen",
                    "Zeming Lin",
                    "Natalia Gimelshein",
                    "Luca Antiga"
                ],
                "title": "Pytorch: An imperative style, high-performance deep learning library",
                "pub_date": "2019",
                "pub_title": "Advances in neural information processing systems",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_90",
            "content": "Alessandro Sameer Pradhan, Nianwen Moschitti, Olga Xue, Yuchen Uryupina,  Zhang, Conll-2012 shared task: Modeling multilingual unrestricted coreference in ontonotes, 2012, Joint Conference on EMNLP and CoNLL-Shared Task, .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": [
                    "Alessandro Sameer Pradhan",
                    "Nianwen Moschitti",
                    "Olga Xue",
                    "Yuchen Uryupina",
                    " Zhang"
                ],
                "title": "Conll-2012 shared task: Modeling multilingual unrestricted coreference in ontonotes",
                "pub_date": "2012",
                "pub_title": "Joint Conference on EMNLP and CoNLL-Shared Task",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_91",
            "content": "Shruti Rijhwani, Jiateng Xie, Graham Neubig, Jaime Carbonell, Zero-shot neural transfer for cross-lingual entity linking, 2019, Proceedings of the AAAI Conference on Artificial Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": [
                    "Shruti Rijhwani",
                    "Jiateng Xie",
                    "Graham Neubig",
                    "Jaime Carbonell"
                ],
                "title": "Zero-shot neural transfer for cross-lingual entity linking",
                "pub_date": "2019",
                "pub_title": "Proceedings of the AAAI Conference on Artificial Intelligence",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_92",
            "content": "Mat\u012bss Rikters, Ryokan Ri, Tong Li, Toshiaki Nakazawa, Designing the business conversation corpus, 2019, Proceedings of the 6th Workshop on Asian Translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Mat\u012bss Rikters",
                    "Ryokan Ri",
                    "Tong Li",
                    "Toshiaki Nakazawa"
                ],
                "title": "Designing the business conversation corpus",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 6th Workshop on Asian Translation",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_93",
            "content": "Joshua Robinson, Ching-Yao Chuang, Suvrit Sra, Stefanie Jegelka, Contrastive learning with hard negative samples, 2020, International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "Joshua Robinson",
                    "Ching-Yao Chuang",
                    "Suvrit Sra",
                    "Stefanie Jegelka"
                ],
                "title": "Contrastive learning with hard negative samples",
                "pub_date": "2020",
                "pub_title": "International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_94",
            "content": "Yun Shi-Qi Shen, Cheng Chen, Zhi-Yuan Yang, Mao-Song Liu,  Sun, Zero-shot cross-lingual neural headline generation, 2018, IEEE/ACM Transactions on Audio, Speech, and Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": [
                    "Yun Shi-Qi Shen",
                    "Cheng Chen",
                    "Zhi-Yuan Yang",
                    "Mao-Song Liu",
                    " Sun"
                ],
                "title": "Zero-shot cross-lingual neural headline generation",
                "pub_date": "2018",
                "pub_title": "IEEE/ACM Transactions on Audio, Speech, and Language Processing",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_95",
            "content": "UNKNOWN, None, 2021, Zeroshot cross-lingual semantic parsing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Zeroshot cross-lingual semantic parsing",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_96",
            "content": "UNKNOWN, None, 2019, Simple bert models for relation extraction and semantic role labeling, .",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Simple bert models for relation extraction and semantic role labeling",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_97",
            "content": "Hui Su, Xiaoyu Shen, Rongzhi Zhang, Fei Sun, Pengwei Hu, Cheng Niu, Jie Zhou, Improving multi-turn dialogue modelling with utterance ReWriter, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": [
                    "Hui Su",
                    "Xiaoyu Shen",
                    "Rongzhi Zhang",
                    "Fei Sun",
                    "Pengwei Hu",
                    "Cheng Niu",
                    "Jie Zhou"
                ],
                "title": "Improving multi-turn dialogue modelling with utterance ReWriter",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_98",
            "content": "Xiangpeng Wei, Rongxiang Weng, Yue Hu, Luxi Xing, Heng Yu, Weihua Luo, On learning universal representations across languages, 2020, International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": [
                    "Xiangpeng Wei",
                    "Rongxiang Weng",
                    "Yue Hu",
                    "Luxi Xing",
                    "Heng Yu",
                    "Weihua Luo"
                ],
                "title": "On learning universal representations across languages",
                "pub_date": "2020",
                "pub_title": "International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_99",
            "content": "Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, Transformers: State-of-the-art natural language processing, 2020, EMNLP (Demos), .",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": [
                    "Thomas Wolf",
                    "Lysandre Debut",
                    "Victor Sanh",
                    "Julien Chaumond",
                    "Clement Delangue",
                    "Anthony Moi",
                    "Pierric Cistac",
                    "Tim Rault",
                    "R\u00e9mi Louf",
                    "Morgan Funtowicz"
                ],
                "title": "Transformers: State-of-the-art natural language processing",
                "pub_date": "2020",
                "pub_title": "EMNLP (Demos)",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_100",
            "content": "Han Wu, Kun Xu, Linfeng Song, Lifeng Jin, Haisong Zhang, Linqi Song, Domain-adaptive pretraining methods for dialogue understanding, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Short Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "Han Wu",
                    "Kun Xu",
                    "Linfeng Song",
                    "Lifeng Jin",
                    "Haisong Zhang",
                    "Linqi Song"
                ],
                "title": "Domain-adaptive pretraining methods for dialogue understanding",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
                "pub": "Short Papers"
            }
        },
        {
            "ix": "284-ARR_v1_101",
            "content": "Han Wu, Kun Xu, Linqi Song, CSAGN: Conversational structure aware graph network for conversational semantic role labeling, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": [
                    "Han Wu",
                    "Kun Xu",
                    "Linqi Song"
                ],
                "title": "CSAGN: Conversational structure aware graph network for conversational semantic role labeling",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_102",
            "content": "Wenquan Wu, Zhen Guo, Xiangyang Zhou, Hua Wu, Xiyuan Zhang, Rongzhong Lian, Haifeng Wang, Proactive human-machine conversation with explicit conversation goal, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": [
                    "Wenquan Wu",
                    "Zhen Guo",
                    "Xiangyang Zhou",
                    "Hua Wu",
                    "Xiyuan Zhang",
                    "Rongzhong Lian",
                    "Haifeng Wang"
                ],
                "title": "Proactive human-machine conversation with explicit conversation goal",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "284-ARR_v1_103",
            "content": "UNKNOWN, None, 2016, Google's neural machine translation system: Bridging the gap between human and machine translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": null,
                "title": null,
                "pub_date": "2016",
                "pub_title": "Google's neural machine translation system: Bridging the gap between human and machine translation",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_104",
            "content": "Kun Xu, Haochen Tan, Linfeng Song, Han Wu, Haisong Zhang, Linqi Song, Dong Yu, Semantic role labeling guided multi-turn dialogue rewriter, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b40",
                "authors": [
                    "Kun Xu",
                    "Haochen Tan",
                    "Linfeng Song",
                    "Han Wu",
                    "Haisong Zhang",
                    "Linqi Song",
                    "Dong Yu"
                ],
                "title": "Semantic role labeling guided multi-turn dialogue rewriter",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_105",
            "content": "Kun Xu, Han Wu, Linfeng Song, Haisong Zhang, Linqi Song, Dong Yu, Conversational semantic role labeling, 2021, Speech, and Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b41",
                "authors": [
                    "Kun Xu",
                    "Han Wu",
                    "Linfeng Song",
                    "Haisong Zhang",
                    "Linqi Song",
                    "Dong Yu"
                ],
                "title": "Conversational semantic role labeling",
                "pub_date": "2021",
                "pub_title": "Speech, and Language Processing",
                "pub": null
            }
        },
        {
            "ix": "284-ARR_v1_106",
            "content": "Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, Jason Weston, Personalizing dialogue agents: I have a dog, do you have pets too?, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b42",
                "authors": [
                    "Saizheng Zhang",
                    "Emily Dinan",
                    "Jack Urbanek",
                    "Arthur Szlam",
                    "Douwe Kiela",
                    "Jason Weston"
                ],
                "title": "Personalizing dialogue agents: I have a dog, do you have pets too?",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "284-ARR_v1_107",
            "content": "Zhuosheng Zhang, Hai Zhao, Structural pretraining for dialogue comprehension, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b43",
                "authors": [
                    "Zhuosheng Zhang",
                    "Hai Zhao"
                ],
                "title": "Structural pretraining for dialogue comprehension",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "284-ARR_v1_108",
            "content": "Kangyan Zhou, Shrimai Prabhumoye, Alan Black, A dataset for document grounded conversations, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b44",
                "authors": [
                    "Kangyan Zhou",
                    "Shrimai Prabhumoye",
                    "Alan Black"
                ],
                "title": "A dataset for document grounded conversations",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "284-ARR_v1_0@0",
            "content": "Zero-shot Cross-lingual Conversational Semantic Role Labeling",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_0",
            "start": 0,
            "end": 60,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_2@0",
            "content": "While conversational semantic role labeling (CSRL) has shown its usefulness on Chinese conversational tasks, it is still under-explored in non-Chinese languages due to the lack of multilingual CSRL annotations for the parser training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_2",
            "start": 0,
            "end": 233,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_2@1",
            "content": "To avoid expensive data collection and error-propagation of translation-based methods, we present a simple but effective approach to perform zero-shot cross-lingual CSRL.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_2",
            "start": 235,
            "end": 404,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_2@2",
            "content": "Our model implicitly learns language-agnostic, conversational structure-aware and semantically rich representations with the hierarchical encoders and elaborately designed pre-training objectives.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_2",
            "start": 406,
            "end": 601,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_2@3",
            "content": "Experimental results show that our model outperforms all baselines by large margins on two newly collected English CSRL test sets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_2",
            "start": 603,
            "end": 732,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_2@4",
            "content": "More importantly, we confirm the usefulness of CSRL to non-Chinese conversational tasks such as the question-in-context rewriting task in English and the multi-turn dialogue response generation tasks in English, German and Japanese by incorporating the CSRL information into the downstream conversation-based models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_2",
            "start": 734,
            "end": 1049,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_2@5",
            "content": "We believe this finding is significant and will facilitate the research of non-Chinese dialogue tasks which suffer the problems of ellipsis and anaphora.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_2",
            "start": 1051,
            "end": 1203,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_4@0",
            "content": "Conversational Semantic Role Labeling (CSRL) (Xu et al., 2021) is a recently proposed dialogue understanding task, which aims to extract predicateargument pairs from the entire conversation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_4",
            "start": 0,
            "end": 189,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_4@1",
            "content": "Figure 1 illustrates a CSRL example where a CSRL parser is required to identify \"\u300a\u6cf0\u5766\u5c3c\u514b\u53f7\u300b(Titanic)\" as the ARG1 argument of the predicate \"\u770b \u8fc7 (watched)\" and the ARG0 argument of the predicate \"\u662f (is)\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_4",
            "start": 191,
            "end": 391,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_4@2",
            "content": "We can see that in the original conversation, \"\u300a\u6cf0\u5766\u5c3c\u514b\u53f7\u300b(Titanic)\" is omitted in the second turn and referred as \"\u8fd9 (this)\" in the last turn.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_4",
            "start": 393,
            "end": 531,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_4@3",
            "content": "By recovering the dropped and referred components in conversation, CSRL has shown its usefulness to a set of Chinese dialogue tasks, including multi-turn dialogue rewriting (Su et al., 2019) and response generation (Wu et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_4",
            "start": 533,
            "end": 765,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_4@4",
            "content": "However, there remains a paucity of evidence on its effectiveness towards non-Chinese languages owing to the lack of multilingual CSRL models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_4",
            "start": 767,
            "end": 908,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_4@5",
            "content": "To adapt a model into new languages, previous solutions can be divided into three categories: 1) manually annotating a new dataset in the target language (Daza and Frank, 2020) 2) borrowing machine translation and word alignment techniques to transfer the dataset from the source language into the target language (Daza and Frank, 2019;Fei et al., 2020a) 3) zero-shot transfer learning with multilingual pre-trained language model (Rijhwani et al., 2019;Sherborne and Lapata, 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_4",
            "start": 910,
            "end": 1391,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_4@6",
            "content": "Due to the fact that manually collecting annotations is costly and translation-based methods might introduce translation or word alignment errors, zeroshot cross-lingual transfer learning is more practical to the NLP community.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_4",
            "start": 1393,
            "end": 1619,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_5@0",
            "content": "Recent works have witnessed prominent performances of multilingual pre-trained language models (PrLMs) (Devlin et al., 2019;Conneau et al., 2020) on cross-lingual tasks, including machine translation (Lin et al., 2020;Chen et al., 2021), semantic role labeling (SRL) (Conia and Navigli, 2020;Conia et al., 2021) and semantic parsing (Fei et al., 2020b;Sherborne and Lapata, 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_5",
            "start": 0,
            "end": 379,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_5@1",
            "content": "However, cross-lingual CSRL, as a combination of three challenging tasks (i.e., cross-lingual task, dialogue task and SRL task), suffers three outstanding difficulties: 1) latent space alignment -how to map word representations of different languages into an overlapping space; 2) conversation structure encoding -how to capture high-level dialogue features such as speaker dependency and temporal dependency; and 3) semantic arguments identification -how to highlight the relations between the predicate and its arguments, wherein PrLMs can only partially encode multilingual inputs to an overlapping vector space.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_5",
            "start": 381,
            "end": 995,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_5@2",
            "content": "Although there are some success that can separately achieve structural conversation encoding (Mehri et al., 2019;Zhang and Zhao, 2021) and semantic arguments identification (Wu et al., 2021a), a unified method for jointly solving these problems is still under-explored, especially in a cross-lingual scenario.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_5",
            "start": 997,
            "end": 1305,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_6@0",
            "content": "In this work, we summarize our contributions as follows: (1) We propose a simple but effective model which consists of three modules, namely cross-lingual language model (CLM), structureaware conversation encoder (SA-Encoder) and predicate-argument encoder (PA-Encoder), and five well-designed pre-training objectives.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_6",
            "start": 0,
            "end": 317,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_6@1",
            "content": "Our model implicitly learns language-agnostic, conversational structure-aware and semantically rich representations to perform zero-shot cross-lingual CSRL.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_6",
            "start": 319,
            "end": 474,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_6@2",
            "content": "(2) Experiments show that our method achieves impressive cross-lingual performance on the language pair (Zh\u2192En) , and outperforms all baselines on the two newly collected English CSRL test sets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_6",
            "start": 476,
            "end": 669,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_6@3",
            "content": "(3) We confirm the usefulness of CSRL to the questionin-context rewriting task in English and multi-turn response generation tasks in English, German and Japanese.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_6",
            "start": 671,
            "end": 833,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_6@4",
            "content": "We believe this finding is important and will facilitate the research of non-Chinese dialogue tasks that suffer from ellipsis and anaphora.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_6",
            "start": 835,
            "end": 973,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_6@5",
            "content": "(4) We will release our code, the new annotated English CSRL test sets and checkpoints of our best models to facilitate the further research.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_6",
            "start": 975,
            "end": 1115,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_7@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_7",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_8@0",
            "content": "Zero-shot cross-lingual transfer learning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_8",
            "start": 0,
            "end": 41,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_8@1",
            "content": "Recently, thanks to the rapid development of multilingual pre-trained language models such as multilingual BERT (Devlin et al., 2019) and XLM-R (Conneau et al., 2020), a number of approaches have been proposed for zero-shot cross-lingual transfer learning on various downstream tasks, including semantic parsing (Sherborne and Lapata, 2021), natural language generation (Shen et al., 2018) and understanding Lauscher et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_8",
            "start": 43,
            "end": 473,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_8@2",
            "content": "In this work, we claim our method is zeroshot because no non-Chinese CSRL annotations are seen during the CSRL training stage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_8",
            "start": 475,
            "end": 600,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_8@3",
            "content": "For decoding, we directly use the cross-lingual CSRL model trained on Chinese CSRL data to analyze conversations in other languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_8",
            "start": 602,
            "end": 733,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_8@4",
            "content": "To our best knowledge, our work is the first step to cross-lingual CSRL.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_8",
            "start": 735,
            "end": 806,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_9@0",
            "content": "Conversational semantic role labeling.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_9",
            "start": 0,
            "end": 37,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_9@1",
            "content": "While ellipsis and anaphora frequently occur in dialogues, Xu et al. (2021) observed that most of the dropped or referred components can be found in dialogue histories.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_9",
            "start": 39,
            "end": 206,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_9@2",
            "content": "Following this observation, they proposed conversational semantic role labeling (CSRL) which required the model to find predicateargument structures over the entire conversation instead of a single sentence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_9",
            "start": 208,
            "end": 414,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_9@3",
            "content": "In this way, when analyzing a predicate in the latest utterance, a CSRL model needs to consider both the current turn and previous turns to search potential arguments, and thus might recover the omitted components.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_9",
            "start": 416,
            "end": 629,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_9@4",
            "content": "Furthermore, Xu et al. (2020Xu et al. ( , 2021) also confirmed the usefulness of CSRL to Chinese dialogue tasks by applying CSRL information into downstream dialogue tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_9",
            "start": 631,
            "end": 802,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_9@5",
            "content": "However, there are still two main problems to be solved for CSRL task: (1) the performance of current state-of-the-art CSRL model (Xu et al., 2021) is still far from satisfactory due to the lack of high-level conversational and semantic features modeling; (2) the usefulness of CSRL to conversational tasks in non-Chinese languages has not been confirmed yet due to the lack of cross-lingual CSRL models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_9",
            "start": 804,
            "end": 1207,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_9@6",
            "content": "In this work, we primarily focus on the latter problem and propose a simple but effective model to perform cross-lingual CSRL.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_9",
            "start": 1209,
            "end": 1334,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_9@7",
            "content": "We would like to distinguish our work from the concurrent work (Wu et al., 2021b) which purely focuses on improving the monolingual CSRL performance where they try to model predicate-aware representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_9",
            "start": 1336,
            "end": 1540,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_9@8",
            "content": "This solution could benefit to monolingual CSRL task, but hurt the cross-lingual performance, because the relative positions of the predicates may differ from language to language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_9",
            "start": 1542,
            "end": 1721,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_10@0",
            "content": "Methodology",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_10",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_11@0",
            "content": "Following Xu et al. (2021), we solve the CSRL task as a sequence labeling problem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_11",
            "start": 0,
            "end": 81,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_11@1",
            "content": "Formally, given a dialogue C = {u 1 , u 2 , ..., u N } of N utterances, where u i = {w i 1 , w a word is the predicate or not, our goal is to assign each word with a semantic role label l \u2208 L where L is the label set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_11",
            "start": 83,
            "end": 299,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_11@2",
            "content": "We also incorporate speaker role indicator r to distinguish speakers, and dialogue turn indicator t to distinguish dialogue turns.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_11",
            "start": 301,
            "end": 430,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_12@0",
            "content": "Architecture",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_12",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_13@0",
            "content": "Cross-lingual Language Model (CLM) We concatenate all utterances into a sequence and then use a pre-trained cross-lingual language model such as XLM-R (Conneau et al., 2020) or mBERT (Devlin et al., 2019) to capture the syntactic and semantic characteristics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_13",
            "start": 0,
            "end": 258,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_13@1",
            "content": "Following Conia et al. (2021), we obtain word representations e \u2208 R |S|\u00d7d by concatenating the hidden states of the four top-most layers of the language model, where |S| is the sequence length and d is the dimension of the hidden state.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_13",
            "start": 260,
            "end": 495,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_14@0",
            "content": "Structure-aware Conversation Encoder (SC-Encoder) Different from standard SRL (Carreras and M\u00e0rquez, 2005), CSRL requires the models to find arguments from not only the current turn, but also previous turns, thus bringing more challenges of dialogue modeling.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_14",
            "start": 0,
            "end": 258,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_14@1",
            "content": "To address this problem, we propose a universal structure-aware conversation encoder which comprises of two parts, i.e., wordlevel encoder and utterance-level encoder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_14",
            "start": 260,
            "end": 426,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_14@2",
            "content": "Formally, with the speaker role embedding r \u2208 R |S|\u00d7d and dialogue turn embedding t \u2208 R |S|\u00d7d , the wordlevel encoder computes a sequence of timestep encodings s \u2208 R |S|\u00d7d as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_14",
            "start": 428,
            "end": 610,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_15@0",
            "content": "s j (i,k) = e i k \u2295 t i k \u2295 r i k if j = 0 s j\u22121 (i,k) \u2295 MTRANS j (s j\u22121 (i,k) ) otherwise (1)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_15",
            "start": 0,
            "end": 93,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_16@0",
            "content": "where s j (i,k) is the timestep encoding of k-th token in i-th utterance from j-th word-level encoder layer while j \u2208 (0, . . . , N 1 ), \u2295 represents vector concatenation, and MTRANS is the Modified Transformer encoder layer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_16",
            "start": 0,
            "end": 224,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_16@1",
            "content": "Concretely, we replace the [Add] operation in the first residual connection layer with [Concat] because we argue that concatenation is a superior approach to preserve the information from previous layers 1 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_16",
            "start": 226,
            "end": 432,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_17@0",
            "content": "We obtain utterance representations u \u2208 R N \u00d7d by max-pooling over words in the same utterance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_17",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_17@1",
            "content": "Then we pass the resulting utterance representations u through a stack of Bi-LSTM (Hochreiter and Schmidhuber, 1997) layers to obtain the sequentially encoded utterance representations u \u2032 \u2208 R N \u00d7d .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_17",
            "start": 96,
            "end": 294,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_17@2",
            "content": "Finally, we combine the utterance-level feature u \u2032 with the word-level feature s to obtain structure-aware dialogue context representations g \u2208 R |S|\u00d7d as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_17",
            "start": 296,
            "end": 459,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_18@0",
            "content": "g i k = Swish(W g [s N 1 (i,k) \u2295 u \u2032 i ] + b g )(2)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_18",
            "start": 0,
            "end": 50,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_19@0",
            "content": "where Swish(x) = x \u2022 sigmoid(x) is a non-linear activation function, s N 1 i,k is the encoding of k-th token in i-th utterance from the last layer of the word-level encoder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_19",
            "start": 0,
            "end": 172,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_19@1",
            "content": "W g and b g are trainable parameters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_19",
            "start": 174,
            "end": 210,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_20@0",
            "content": "We introduce the third module (i.e., predicateargument encoder) whose goal is to capture the relations between each predicate-argument couple that appears in the conversation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_20",
            "start": 0,
            "end": 174,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_20@1",
            "content": "Similar with the word-level encoder, we use a stack of MTRANS layers to implement this encoder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_20",
            "start": 176,
            "end": 270,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_20@2",
            "content": "Formally, with the predicate embedding p \u2208 R |S|\u00d7d , the model calculates the predicate-specific argument encodings a \u2208 R |S|\u00d7d as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_20",
            "start": 272,
            "end": 410,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_21@0",
            "content": "a j (i,k) = g i k \u2295 p i k if j = 0 a j\u22121 (i,k) \u2295 MTRANS j (a j\u22121 (i,k) ) otherwise (3)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_21",
            "start": 0,
            "end": 85,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_22@0",
            "content": "where a j (i,k) is the argument encoding of k-th token in i-th utterance from j-th encoder layer while j \u2208 (0, . . . , N 2 ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_22",
            "start": 0,
            "end": 124,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_22@1",
            "content": "Finally, we obtain the semantic role encoding l using the resulting argument encodings from the last layer of the predicate-argument encoder:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_22",
            "start": 126,
            "end": 266,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_23@0",
            "content": "l i k = Swish(W l a N 2 (i,k) + b l )(4)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_23",
            "start": 0,
            "end": 39,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_24@0",
            "content": "In particular, our proposed model is mostly language-agnostic since we do not explicitly introduce any language-specific knowledge such as word order, part-of-speech tags or dependent relations, and only introduce the predicate indicator that might contain some language-specific information in the semantic module, which would not affect latent space alignment and dialogue modeling.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_24",
            "start": 0,
            "end": 383,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_25@0",
            "content": "Pre-training Objectives",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_25",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_26@0",
            "content": "Besides the universal model, we also elaborately design five pre-training objectives to model taskspecific but language-agnostic features for better cross-lingual performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_26",
            "start": 0,
            "end": 174,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_26@1",
            "content": "In this section, we divide our pre-training objectives into three groups according to the challenges to be solved.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_26",
            "start": 176,
            "end": 289,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_27@0",
            "content": "Latent space alignment In cross-lingual language module, we use mBERT or XLM-R to align the latent space of different languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_27",
            "start": 0,
            "end": 127,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_27@1",
            "content": "Although mBERT and XLM-R have exhibited good alignment ability, even both of them are trained with unpaired data, we may further improve it when we have access to parallel data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_27",
            "start": 129,
            "end": 305,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_27@2",
            "content": "We first use translation language model (TLM) (Conneau and Lample, 2019) to learn word-level alignment ability.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_27",
            "start": 307,
            "end": 417,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_27@3",
            "content": "Concretely, we concatenate parallel sentences as a single consecutive token sequence with special tokens separating them and then perform masked language modeling (MLM) (Devlin et al., 2019) on the concatenated sequence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_27",
            "start": 419,
            "end": 638,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_27@4",
            "content": "Besides, we also attempt to improve sentence-level alignment ability using hard parallel sentence identification (HPSI).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_27",
            "start": 640,
            "end": 759,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_27@5",
            "content": "Specifically, we select a pair of parallel or non-parallel sentences from the training set with equal probability.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_27",
            "start": 761,
            "end": 874,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_27@6",
            "content": "Then the model is required to predict whether the sampled sentence pair is parallel or not.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_27",
            "start": 876,
            "end": 966,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_27@7",
            "content": "Different from the standard PSI (Dou and Neubig, 2021), we sample the non-parallel sentence upon the n-gram similarity or construct it by text perturbation (details in Appendix A) instead of in a random manner.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_27",
            "start": 968,
            "end": 1177,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_27@8",
            "content": "Figure 3 illustrates the workflows of TLM and HPSI.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_27",
            "start": 1179,
            "end": 1229,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_27@9",
            "content": "We pre-train the CLM using the combination of TLM and HPSI, finally achieving latent space alignment.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_27",
            "start": 1231,
            "end": 1331,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_28@0",
            "content": "Conversation structure encoding Although there are a number of pre-training objectives proposed to learn dialogue context representations (Mehri et al., 2019) and structural representations (Zhang and Zhao, 2021), we tend to explicitly model speaker dependency and temporal dependency in the conversation, both of which have been proven to be critical to CSRL task (Xu et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_28",
            "start": 0,
            "end": 382,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_29@0",
            "content": "We first propose speaker role identification (SPI) to learn speaker dependency in the conversation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_29",
            "start": 0,
            "end": 98,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_29@1",
            "content": "Specifically, we randomly sample K 1 % utterances and replace their speaker indicators with special mask tags.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_29",
            "start": 100,
            "end": 209,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_29@2",
            "content": "To make the task harder and effective, we split the utterances into clauses if only two interlocutors utter in turn in a conversation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_29",
            "start": 211,
            "end": 344,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_29@3",
            "content": "The goal of SPI is to predict the masked speaker roles according to the corrupted speaker indicators and context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_29",
            "start": 346,
            "end": 458,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_29@4",
            "content": "Secondly, we borrow utterance order permutation (UOR) to encourage the model to be aware of temporal connections among utterances in the context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_29",
            "start": 460,
            "end": 604,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_29@5",
            "content": "Concretely, given a set of utterances, we randomly shuffle the last K 2 % utterances and require the model to organize them into a coherent context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_29",
            "start": 606,
            "end": 753,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_29@6",
            "content": "Figure 4 illustrates the workflows of SPI and UOR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_29",
            "start": 755,
            "end": 804,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_29@7",
            "content": "We pre-train the SC-Encoder using the combination of SPI and UOR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_29",
            "start": 806,
            "end": 870,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_30@0",
            "content": "The core of all SRL-related tasks is to recognize the predicateargument pairs from the input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_30",
            "start": 0,
            "end": 92,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_30@1",
            "content": "Therefore, we propose semantic arguments identification (SAI) objective to strengthen the correlations between the predicate and its arguments with the help of external standard SRL corpus, i.e., CoNLL-2012.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_30",
            "start": 94,
            "end": 300,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_30@2",
            "content": "Specifically, for each SRL sample, we only focus on those arguments, including ARG0-4, ARG-LOC, ARG-TMP and ARG-PRP, all of which are defined in both SRL and CSRL tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_30",
            "start": 302,
            "end": 470,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_30@3",
            "content": "The model is encouraged to find the textual spans of these arguments with the given predicate.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_30",
            "start": 472,
            "end": 565,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_30@4",
            "content": "We believe this objective would benefit to boundary detection, especially for location and temporal arguments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_30",
            "start": 567,
            "end": 676,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_30@5",
            "content": "Figure 5 illustrates the workflow of SAI.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_30",
            "start": 678,
            "end": 718,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_30@6",
            "content": "We drop the SC-Encoder to fit in standard SRL samples which do not have any conversational characteristics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_30",
            "start": 720,
            "end": 826,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_31@0",
            "content": "Training",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_31",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_32@0",
            "content": "Hierarchical Pre-training The pre-training is hierarchically conducted according to different modules, and the pre-training of the upper module is based on the pre-trained lower modules.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_32",
            "start": 0,
            "end": 185,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_32@1",
            "content": "Specifically, we first train CLM module with TLM and HPSI; then we train SC-Encoder with SPI and UOR while keeping the weights of pre-trained CLM module unchanged; finally we train PA-Encoder with SAI while freezing the weights of pre-trained CLM and SC-Encoder modules.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_32",
            "start": 187,
            "end": 456,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_32@2",
            "content": "Hopefully, we expect that each module could acquire different knowledge with specific pre-training objectives.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_32",
            "start": 458,
            "end": 567,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_32@3",
            "content": "(2021) where DuConv annotations are splitted into 80%/10%/10% as train/dev/in-domain test set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_32",
            "start": 569,
            "end": 662,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_32@4",
            "content": "Furthermore, we manually collect two CSRL test sets 2 for cross-lingual evaluation based on Persona-Chat (Zhang et al., 2018) and CMU-DoG (Zhou et al., 2018), both of which are English conversation datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_32",
            "start": 664,
            "end": 870,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_32@5",
            "content": "The CSRL data annotation is difficult because it needs great expertise in SRL and dialogue.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_32",
            "start": 872,
            "end": 962,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_32@6",
            "content": "So we only explore cross-lingual CSRL on Chinese\u2192English (Zh\u2192En) here, and we leave other languages for future work.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_32",
            "start": 964,
            "end": 1079,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_33@0",
            "content": "Pre-training data For TLM and HPSI objectives which requires parallel data to enhance alignment ability, we choose IWSLT'14 English\u2194Chinese (En\u2194Zh) translations 3 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_33",
            "start": 0,
            "end": 163,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_33@1",
            "content": "For SPI and UOR objectives whose goal is to model high-level conversational features, we select samples from Chinese conversation dataset (i.e., DuConv) and English conversation datasets (i.e., Persona-Chat and CMU-DoG) with equal probability.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_33",
            "start": 165,
            "end": 407,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_33@2",
            "content": "For SAI, we borrow the Chinese and English SRL annotations from CoNLL-2012(Pradhan et al., 2012.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_33",
            "start": 409,
            "end": 504,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_34@0",
            "content": "We stress that by keeping the sampling balance of Chinese and English data for every pre-training objective and sharing all parameters across the languages, our model would capture task-specific but language-agnostic features.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_34",
            "start": 0,
            "end": 225,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_35@0",
            "content": "Experimental Setup",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_35",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_36@0",
            "content": "Following previous work (Xu et al., 2021), we evaluate our system on micro-average F1 all , F1 cross and F1 intra over the (predicate, argument, label) tuples, wherein we calculate F1 cross and F1 intra over the arguments in the different, or same turn as the predicate.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_36",
            "start": 0,
            "end": 269,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_36@1",
            "content": "We refer these two types of arguments as cross-arguments and intra-arguments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_36",
            "start": 271,
            "end": 347,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_37@0",
            "content": "Main Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_37",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_38@0",
            "content": "Table 1 summarized the results of all compared methods on DuConv, Persona-Chat and CMU-DoG datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_38",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_38@1",
            "content": "Firstly, we can see that our method achieves competitive performance over all datasets, especially in cross-lingual scenario where our method outperforms the baselines by large margins no matter fine-tuning or freezing the language model during the CSRL training stage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_38",
            "start": 101,
            "end": 369,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_38@2",
            "content": "Although CSAGN exceeds our method on DuConv test set, it fails to work well in cross-lingual scenario.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_38",
            "start": 371,
            "end": 472,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_38@3",
            "content": "We think this is because it heavily relies on the rich features from the Chinese pre-trained language model and it is overfitting on the predicate-aware information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_38",
            "start": 474,
            "end": 638,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_38@4",
            "content": "Superior to CSAGN, our model with the multilingual backbone achieves outstanding performance on both language in-domain and crosslingual datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_38",
            "start": 640,
            "end": 785,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_38@5",
            "content": "This observation is expected because (1) our model is language-agnostic which makes the cross-lingual transfer easier;",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_38",
            "start": 787,
            "end": 904,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_39@0",
            "content": "(2) our model captures high-level conversational features in SC-Encoder, thus enhancing the capacities of the model to recognize cross-arguments;",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_39",
            "start": 0,
            "end": 144,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_40@0",
            "content": "(3) rich semantic features are modeled by PA-Encoder, which would improve the capacities of the model to recognize intra-arguments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_40",
            "start": 0,
            "end": 130,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_41@0",
            "content": "Secondly, although our model has achieved good performance over all datasets, further improvements can be observed after incorporating the proposed pre-training objectives, especially when freezing the parameters of the language model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_41",
            "start": 0,
            "end": 234,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_41@1",
            "content": "Exceptionally, we find that the performance on the CMU-DoG dataset heavily drops after introducing the pre-training objectives, especially in terms of F1 intra .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_41",
            "start": 236,
            "end": 396,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_41@2",
            "content": "We think this is because the semantic argument spans in CoNLL-2012 are relatively different from those in CMU-DoG, thus leading to the vague boundary detection and performance drop.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_41",
            "start": 398,
            "end": 578,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_41@3",
            "content": "To verify this assumption, we conduct an ablation study by removing SAI from the pre-training stage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_41",
            "start": 580,
            "end": 679,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_41@4",
            "content": "Interestingly, we observe substantial improvements over F1 all and F1 intra , suggesting that pre-training on CoNLL-2012 does hurt the performance on CMU-DoG. Furthermore, we also find that fine-tuning all parameters leads to slightly better performance than freezing the language model during the CSRL training stage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_41",
            "start": 681,
            "end": 998,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_41@5",
            "content": "This finding is consistent with the previous work (Conia et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_41",
            "start": 1000,
            "end": 1070,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_42@0",
            "content": "Table 2 presents the results of ablation studies on pre-training objectives and different modules.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_42",
            "start": 0,
            "end": 97,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_42@1",
            "content": "For the pre-training objectives, we found that (1) removing TLM & HPSI objective hurts the performance consistently but slightly; (2) SPI & UOR objectives help the model to better identify the cross-arguments; (3) SAI objective helps to find intra-arguments on DuConv and Persona-Chat, but might hurt the F1 intra score on CMU-DoG; (4) hierarchical pre-training is superior to end-to-end pre-training which simultaneously optimizes all auxiliary objectives.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_42",
            "start": 99,
            "end": 555,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_42@2",
            "content": "We think this is because the end2end pre-training is extremely unstable and confuses the optimization process of the model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_42",
            "start": 557,
            "end": 679,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_43@0",
            "content": "For model components, we found that only removing one of the SC-Encoder, PA-Encoder or MTRANS slightly affect the performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_43",
            "start": 0,
            "end": 125,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_43@1",
            "content": "However, the performance heavily decreases when SC-Encoder and PA-Encoder are both removed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_43",
            "start": 127,
            "end": 217,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_43@2",
            "content": "We think the reason is that at least one module is needed to capture the high-level features on the top of the language model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_43",
            "start": 219,
            "end": 344,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_43@3",
            "content": "We preserve these two modules in our model since they essentially learn different abilities, i.e., the ability of dialogue modeling and semantics modeling, which also makes our model more explainable.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_43",
            "start": 346,
            "end": 545,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_43@4",
            "content": "et al. (2021) has confirmed the usefulness of CSRL by applying CSRL parsing results to two Chinese dialogue tasks, including dialogue context rewriting and dialogue response generation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_43",
            "start": 547,
            "end": 731,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_43@5",
            "content": "In the same vein, we also explore whether CSRL could benefit to the same non-Chinese dialogue tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_43",
            "start": 733,
            "end": 832,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_44@0",
            "content": "Applications",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_44",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_45@0",
            "content": "Question-in-context Rewriting Question-incontext rewriting (Elgohary et al., 2019) is a challenging task which requires the model to resolve the conversational dependencies between the question and the context, and then rewrite the original question into independent one.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_45",
            "start": 0,
            "end": 270,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_45@1",
            "content": "This is an example in Table 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_45",
            "start": 272,
            "end": 301,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_45@2",
            "content": "The question \"who did they play in the playoffs?\" cannot be independently understood without knowing \"they\" refer to, but it can be resolved with the given context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_45",
            "start": 303,
            "end": 466,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_46@0",
            "content": "Since the CSRL models can identify the predicate-argument structures from the entire conversation, we believe that it can help this rewriting task by searching the dropped or referred components from the context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_46",
            "start": 0,
            "end": 211,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_46@1",
            "content": "For example, in Table 3, our CSRL parser can find that the ARG0 of the predicate \"play\" is \"the Colts\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_46",
            "start": 213,
            "end": 315,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_46@2",
            "content": "Motivated by this observation, we attempt to borrow CSRL to help the question rewriting with the context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_46",
            "start": 317,
            "end": 421,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_46@3",
            "content": "We first employ the pre-trained cross-lingual CSRL parser (Ours XLM-R + pre-train ) to extract predicate-argument pairs from conversations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_46",
            "start": 423,
            "end": 561,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_46@4",
            "content": "We adopt the model proposed in (Xu et al., 2020) to achieve the rewriting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_46",
            "start": 563,
            "end": 636,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_46@5",
            "content": "More details about the model are in Appendix F.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_46",
            "start": 638,
            "end": 684,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_47@0",
            "content": "Since the rewriting datasets are only available in Chinese and English, we hereby only evaluate on CANARD (Elgohary et al., 2019) which is a widely used English question rewriting dataset, and report the BLEU scores.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_47",
            "start": 0,
            "end": 215,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_47@1",
            "content": "mance against the state-of-the-art rewriting models, i.e., SARG (Huang et al., 2020) and RUN (Liu et al., 2020a), and significantly outperforms the baseline method (Bahdanau et al., 2014).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_47",
            "start": 217,
            "end": 404,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_47@2",
            "content": "Note that, in this part, we are more focused on the improvements after introducing CSRL information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_47",
            "start": 406,
            "end": 505,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_47@3",
            "content": "We find that the scores across all metrics are improved with the aid of CSRL.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_47",
            "start": 507,
            "end": 583,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_47@4",
            "content": "To figure out the reasons of these improvements, we investigate which type of questions could benefit from CSRL information most.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_47",
            "start": 585,
            "end": 713,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_47@5",
            "content": "By comparing the rewritten questions of different methods, we find that the questions that require information completion, especially those containing referred components (around 15% cases), benefit from CSRL most.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_47",
            "start": 715,
            "end": 928,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_47@6",
            "content": "This observation is in line with our expectation that our CSRL parser could consistently offer essential guidance by recovering the dropped or referred text components.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_47",
            "start": 930,
            "end": 1097,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_48@0",
            "content": "Multi-turn Dialogue Response Generation Besides the rewriting task that is heavily affected by omitted components, we also explore the usefulness of CSRL to multi-turn dialogue response generation, one of the main challenges in dialogue community.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_48",
            "start": 0,
            "end": 246,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_48@1",
            "content": "In contrast to single-turn dialogue response generation, multi-turn dialogues suffer more frequently occurred ellipsis and anaphora, which leads to vague context representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_48",
            "start": 248,
            "end": 425,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_48@2",
            "content": "To this end, we attempt to employ CSRL to build better context representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_48",
            "start": 427,
            "end": 505,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_48@3",
            "content": "In specific, we highlight the words picked up by the CSRL parser, and then teach the model to pay more attention on those words which would hold more semantic features.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_48",
            "start": 507,
            "end": 674,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_48@4",
            "content": "We evaluate on three dialogue datasets in different languages, including Persona-Chat (Zhang et al., 2018) in English, BConTrast (Farajian et al., 2020) in German and BSD (Rikters et al., 2019) in Japanese.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_48",
            "start": 676,
            "end": 881,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_48@5",
            "content": "We report BLEU-1/2 and Distinct-1/2 scores for the comparison.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_48",
            "start": 883,
            "end": 944,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_48@6",
            "content": "We employ the pre-trained cross-lingual CSRL parser (Ours XLM-R ) to analyze the latest utterance, and obtain the predicate-argument pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_48",
            "start": 946,
            "end": 1084,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_48@7",
            "content": "Then the concatenated sequence of the extracted pairs and the context is fed into our model for response generation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_48",
            "start": 1086,
            "end": 1201,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_48@8",
            "content": "We adopt the UniLM (Dong et al., 2019) or mBART (Liu et al., 2020b) as our generation model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_48",
            "start": 1203,
            "end": 1294,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_48@9",
            "content": "More implementation details are in Appendix F.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_48",
            "start": 1296,
            "end": 1341,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_49@0",
            "content": "Table 4 summarizes the results on three datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_49",
            "start": 0,
            "end": 48,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_49@1",
            "content": "We can see that the models with different backbones can consistently benefit from the additional introduced CSRL information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_49",
            "start": 50,
            "end": 174,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_49@2",
            "content": "While substantial gains from CSRL information are obtained on English and Japanese dialogues, smaller improvements are observed on the German dialogue task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_49",
            "start": 176,
            "end": 331,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_49@3",
            "content": "We think this is because English is well-represented in pre-trained multilingual models and Japanese is more similar to Chinese while German accounts for none of both.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_49",
            "start": 333,
            "end": 499,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_49@4",
            "content": "Apart from automatic evaluation criteria, we also conduct human evaluation on the English dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_49",
            "start": 501,
            "end": 598,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_49@5",
            "content": "Specifically, we randomly select 200 generated responses for each method, and then recruit three annotators to evaluate the coherence and informativeness of the response against the conversation context by giving a score ranging from 1(worst) to 5(best).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_49",
            "start": 600,
            "end": 853,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_49@6",
            "content": "We find that the method with CSRL wins in 35% cases, and ties with the vanilla model in around 55% cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_49",
            "start": 855,
            "end": 959,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_49@7",
            "content": "With more careful analysis, we find that the responses that contains entities mentioned in histories benefit from CSRL information most.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_49",
            "start": 961,
            "end": 1096,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_49@8",
            "content": "We think this is because nonephrases are more likely to be recognized as semantic arguments by CSRL parser, and then receive more attentions during encoding.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_49",
            "start": 1098,
            "end": 1254,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_50@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_50",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_51@0",
            "content": "In this work, we propose a simple but effective model with five pre-training objectives to perform zero-shot cross-lingual CSRL, and also confirm the usefulness of CSRL to non-Chinese dialogue tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_51",
            "start": 0,
            "end": 198,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_52@0",
            "content": "Following previous work (Robinson et al., 2020;Wei et al., 2020) which suggests that contrastive learning of representations benefits from hard negative samples, we also try to select hard negative samples for PSI task based on n-gram similarity and text perturbation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_52",
            "start": 0,
            "end": 267,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_52@1",
            "content": "Specifically, for each sentence, we calculate its n-gram similarity scores to other sentences, where n = 1, 2, 3, 4, and then we select the sentence with the highest score at each gram as the candidate sentence; additionally, we construct the corrupted sentence as the candidate by token deletion, token replacement and token order permutation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_52",
            "start": 269,
            "end": 612,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_52@2",
            "content": "Finally, we sample from the candidate set created by n-gram similarity at 40% time and from the candidate set created by text perturbation at 60% time.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_52",
            "start": 614,
            "end": 764,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_53@0",
            "content": "To overcome the information forgetting of hierarchical models, we attempt to modify the standard Transformer to better reserve the information from the previous layers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_53",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_53@1",
            "content": "In specific, we try following variants:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_53",
            "start": 169,
            "end": 207,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_54@0",
            "content": "\u2022 MTRANS. Our intuition of substituting the summation with concatenation is that the residual layer with concatenation would introduce additional parameters, and we expect these additional parameters to retain more history information. As shown in Table 1, we obtain some gains while using MTRANS. Additionally, we also report the F1 all scores on DuConv/Persona-Chat/CMU-DoG datasets while using LATER-MTRANS and BOTH-MTRANS here.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_54",
            "start": 0,
            "end": 430,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_55@0",
            "content": "Following the instructions in Xu et al. (2021), we manually collect two out-of-domain CSRL test sets based on English dialogue datasets Persona-Chat (Zhang et al., 2018) and CMU-DoG (Zhou et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_55",
            "start": 0,
            "end": 201,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_55@1",
            "content": "Specifically, we also annotate the arguments ARG0-4, ARG-TMP, ARG-LOC and ARG-PRP and require that the labeled arguments can only appear in the current turn or the previous turns.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_55",
            "start": 203,
            "end": 381,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_55@2",
            "content": "We employ three annotators who have studied Chinese CSRL annotations for a period time before this annotation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_55",
            "start": 383,
            "end": 492,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_55@3",
            "content": "The first two annotators are required to label all cases and any disagreements between them are solved by the third annotator.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_55",
            "start": 494,
            "end": 619,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_55@4",
            "content": "The statistics of the datasets are listed in Table 6.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_55",
            "start": 621,
            "end": 673,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_56@0",
            "content": "We implement the model in PyTorch (Paszke et al., 2019), and use the pre-trained language model of multilingual BERT (mBERT) or XLM-RoBERTa (XLM-R) made available by the Transformer library (Wolf et al., 2020) as the backbone.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_56",
            "start": 0,
            "end": 225,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_56@1",
            "content": "We train the model using AdamW (Loshchilov and Hutter, 2018) with a linear learning rate schedule.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_56",
            "start": 227,
            "end": 324,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_56@2",
            "content": "For each model, we run five different random seeds and report the average score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_56",
            "start": 326,
            "end": 405,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_56@3",
            "content": "More details and hyper-parameters are listed in Table 8.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_56",
            "start": 407,
            "end": 462,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_57@0",
            "content": "We compare to following baseline models, 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_57",
            "start": 0,
            "end": 42,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_57@1",
            "content": "SimpleBERT/SimpleXLMR (Shi and Lin, 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_57",
            "start": 44,
            "end": 85,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_57@2",
            "content": "It uses the Chinese BERT or XLM-R as the backbone and simply concatenates the entire dialogue context with the predicate.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_57",
            "start": 87,
            "end": 207,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_58@0",
            "content": "2. CSRL-BERT/XLMR (Xu et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_58",
            "start": 0,
            "end": 35,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_58@1",
            "content": "It uses the Chinese BERT or XLM-R as the backbone but attempts to encode the conversation structural information by integrating the dialogue turn and speaker embeddings in the input embedding layer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_58",
            "start": 37,
            "end": 234,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_59@0",
            "content": "3. CSAGN/CSAGN-XLMR (Wu et al., 2021b",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_59",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_60@0",
            "content": "Rewriting Model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_60",
            "start": 0,
            "end": 15,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_60@1",
            "content": "We adopt the model proposed in (Xu et al., 2020) which directly concatenates the predicate-argument structures, the conversation context and the question as a sequence, and then feeds them into the model with special attention masks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_60",
            "start": 17,
            "end": 249,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_60@2",
            "content": "During decoding, the model takes CSRL pairs and the context to generate the rewritten question word by word.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_60",
            "start": 251,
            "end": 358,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_60@3",
            "content": "The input representation, attention strategies and loss function of our model are same as (Xu et al., 2020)'s.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_60",
            "start": 360,
            "end": 469,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_60@4",
            "content": "We initialize the model using the base BERT model and use AdamW with a linear learning rate schedule to update parameters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_60",
            "start": 471,
            "end": 592,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_60@5",
            "content": "Note that we only attempt to introduce the CSRL information as a condition into our generationbased model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_60",
            "start": 594,
            "end": 699,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_60@6",
            "content": "We did not include the CSRL information into the state-of-the-art rewriting models, i.e., SARG and RUN because these models rewrite the sentence by learning a text editing matrix instead of directly learning the distributions of the target words.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_60",
            "start": 701,
            "end": 946,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_60@7",
            "content": "Unfortunately, there are no straightforward ways to include our CSRL information into these models to help the matrix learning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_60",
            "start": 948,
            "end": 1074,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_61@0",
            "content": "Response Generation Model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_61",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_61@1",
            "content": "Our model for response generation is directly borrowed from UniLM (Dong et al., 2019) or mBART (Liu et al., 2020b).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_61",
            "start": 27,
            "end": 141,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_61@2",
            "content": "For UniLM, the generation process is same with the rewriting task, wherein the extracted semantic pairs, the context and the response are concatenated into a sequence and encoded with the special mask.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_61",
            "start": 143,
            "end": 343,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_61@3",
            "content": "For mBART, we just concatenate the extracted predicate-argument pairs with the context into a sequence, and then feed the sequence into the encoder for training; during decoding, our model takes semantic information and the context as input to generate the response word by word.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_61",
            "start": 345,
            "end": 623,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_61@4",
            "content": "The input representation, attention strategies for CSRL structures and loss function are same as the rewriter model's.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_61",
            "start": 625,
            "end": 742,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_61@5",
            "content": "We initialize the model using the base multilingual BERT or mBART and use AdamW with a linear learning rate schedule to update parameters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_61",
            "start": 744,
            "end": 881,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_62@0",
            "content": "We report some more detailed experimental results here.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_62",
            "start": 0,
            "end": 54,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_62@1",
            "content": "Table 7 summarize the standard deviations of the main evaluation results on three datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_62",
            "start": 56,
            "end": 146,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_63@0",
            "content": "We list the hyper-parameters of CSRL experiments (Table 8), rewriting experiments (Table 9) and response experiments (",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_63",
            "start": 0,
            "end": 117,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_64@0",
            "content": "UNKNOWN, None, 2014, Neural machine translation by jointly learning to align and translate, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_64",
            "start": 0,
            "end": 92,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_65@0",
            "content": "Xavier Carreras, Llu\u00eds M\u00e0rquez, Introduction to the conll-2005 shared task: Semantic role labeling, 2005, Proceedings of the ninth conference on computational natural language learning (CoNLL-2005), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_65",
            "start": 0,
            "end": 199,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_66@0",
            "content": "Guanhua Chen, Shuming Ma, Yun Chen, Li Dong, Dongdong Zhang, Jia Pan, Wenping Wang, Furu Wei, Zero-shot cross-lingual transfer of neural machine translation with multilingual pretrained encoders, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_66",
            "start": 0,
            "end": 331,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_67@0",
            "content": "Simone Conia, Andrea Bacciu, Roberto Navigli, Unifying cross-lingual semantic role labeling with heterogeneous linguistic resources, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_67",
            "start": 0,
            "end": 283,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_68@0",
            "content": "Simone Conia, Roberto Navigli, Bridging the gap in multilingual semantic role labeling: a language-agnostic approach, 2020, Proceedings of the 28th International Conference on Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_68",
            "start": 0,
            "end": 203,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_69@0",
            "content": "Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettlemoyer, Veselin Stoyanov, Unsupervised cross-lingual representation learning at scale, 2020, ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_69",
            "start": 0,
            "end": 238,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_70@0",
            "content": "Alexis Conneau, Guillaume , Crosslingual language model pretraining, 2019, Advances in Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_70",
            "start": 0,
            "end": 126,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_71@0",
            "content": "Angel Daza, Anette Frank, Translate and label! an encoder-decoder approach for cross-lingual semantic role labeling, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_71",
            "start": 0,
            "end": 300,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_72@0",
            "content": "Angel Daza, Anette Frank, X-srl: A parallel cross-lingual semantic role labeling dataset, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_72",
            "start": 0,
            "end": 192,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_73@0",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, Bert: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_73",
            "start": 0,
            "end": 294,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_74@0",
            "content": "Li Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou, Hsiao-Wuen Hon, Unified language model pre-training for natural language understanding and generation, 2019, Proceedings of the 33rd International Conference on Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_74",
            "start": 0,
            "end": 290,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_75@0",
            "content": "Yi Zi, Graham Dou,  Neubig, Word alignment by fine-tuning embeddings on parallel corpora, 2021, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_75",
            "start": 0,
            "end": 218,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_76@0",
            "content": "Ahmed Elgohary, Denis Peskov, Jordan Boyd-Graber, Can you unpack that? learning to rewrite questions-in-context, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_76",
            "start": 0,
            "end": 337,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_77@0",
            "content": "M Amin Farajian, V Ant\u00f3nio,  Lopes, F Andr\u00e9, Sameen Martins, Gholamreza Maruf,  Haffari, Findings of the wmt 2020 shared task on chat translation, 2020, Proceedings of the Fifth Conference on Machine Translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_77",
            "start": 0,
            "end": 213,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_78@0",
            "content": "Meishan Hao Fei, Donghong Zhang,  Ji, Cross-lingual semantic role labeling with highquality translated training corpus, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_78",
            "start": 0,
            "end": 215,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_79@0",
            "content": "Meishan Hao Fei, Fei Zhang, Donghong Li,  Ji, Cross-lingual semantic role labeling with model transfer, 2020, IEEE/ACM Transactions on Audio, Speech, and Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_79",
            "start": 0,
            "end": 175,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_80@0",
            "content": "Sepp Hochreiter, J\u00fcrgen Schmidhuber, Long short-term memory, 1997, Neural computation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_80",
            "start": 0,
            "end": 87,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_81@0",
            "content": "UNKNOWN, None, 2020, Sarg: A novel semi autoregressive generator for multi-turn incomplete utterance restoration, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_81",
            "start": 0,
            "end": 114,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_82@0",
            "content": "Anne Lauscher, Vinit Ravishankar, Ivan Vuli\u0107, Goran Glava\u0161, From zero to hero: On the limitations of zero-shot language transfer with multilingual transformers, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_82",
            "start": 0,
            "end": 263,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_83@0",
            "content": "Zehui Lin, Xiao Pan, Mingxuan Wang, Xipeng Qiu, Jiangtao Feng, Hao Zhou, Lei Li, Pretraining multilingual neural machine translation by leveraging alignment information, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_83",
            "start": 0,
            "end": 272,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_84@0",
            "content": "Qian Liu, Bei Chen, Jian-Guang Lou, Bin Zhou, Dongmei Zhang, Incomplete utterance rewriting as semantic segmentation, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_84",
            "start": 0,
            "end": 220,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_85@0",
            "content": "Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer, Multilingual denoising pre-training for neural machine translation, 2020, Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_85",
            "start": 0,
            "end": 249,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_86@0",
            "content": "Zihan Liu, Jamin Shin, Yan Xu, Genta Indra Winata, Peng Xu, Andrea Madotto, Pascale Fung, Zero-shot cross-lingual dialogue systems with transferable latent variables, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_86",
            "start": 0,
            "end": 350,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_87@0",
            "content": "Ilya Loshchilov, Frank Hutter, Decoupled weight decay regularization, 2018, International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_87",
            "start": 0,
            "end": 130,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_88@0",
            "content": "Shikib Mehri, Evgeniia Razumovskaia, Tiancheng Zhao, Maxine Eskenazi, Pretraining methods for dialog context representation learning, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_88",
            "start": 0,
            "end": 229,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_89@0",
            "content": "Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Pytorch: An imperative style, high-performance deep learning library, 2019, Advances in neural information processing systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_89",
            "start": 0,
            "end": 273,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_90@0",
            "content": "Alessandro Sameer Pradhan, Nianwen Moschitti, Olga Xue, Yuchen Uryupina,  Zhang, Conll-2012 shared task: Modeling multilingual unrestricted coreference in ontonotes, 2012, Joint Conference on EMNLP and CoNLL-Shared Task, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_90",
            "start": 0,
            "end": 221,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_91@0",
            "content": "Shruti Rijhwani, Jiateng Xie, Graham Neubig, Jaime Carbonell, Zero-shot neural transfer for cross-lingual entity linking, 2019, Proceedings of the AAAI Conference on Artificial Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_91",
            "start": 0,
            "end": 191,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_92@0",
            "content": "Mat\u012bss Rikters, Ryokan Ri, Tong Li, Toshiaki Nakazawa, Designing the business conversation corpus, 2019, Proceedings of the 6th Workshop on Asian Translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_92",
            "start": 0,
            "end": 159,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_93@0",
            "content": "Joshua Robinson, Ching-Yao Chuang, Suvrit Sra, Stefanie Jegelka, Contrastive learning with hard negative samples, 2020, International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_93",
            "start": 0,
            "end": 174,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_94@0",
            "content": "Yun Shi-Qi Shen, Cheng Chen, Zhi-Yuan Yang, Mao-Song Liu,  Sun, Zero-shot cross-lingual neural headline generation, 2018, IEEE/ACM Transactions on Audio, Speech, and Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_94",
            "start": 0,
            "end": 187,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_95@0",
            "content": "UNKNOWN, None, 2021, Zeroshot cross-lingual semantic parsing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_95",
            "start": 0,
            "end": 62,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_96@0",
            "content": "UNKNOWN, None, 2019, Simple bert models for relation extraction and semantic role labeling, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_96",
            "start": 0,
            "end": 92,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_97@0",
            "content": "Hui Su, Xiaoyu Shen, Rongzhi Zhang, Fei Sun, Pengwei Hu, Cheng Niu, Jie Zhou, Improving multi-turn dialogue modelling with utterance ReWriter, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_97",
            "start": 0,
            "end": 238,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_98@0",
            "content": "Xiangpeng Wei, Rongxiang Weng, Yue Hu, Luxi Xing, Heng Yu, Weihua Luo, On learning universal representations across languages, 2020, International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_98",
            "start": 0,
            "end": 187,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_99@0",
            "content": "Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, Transformers: State-of-the-art natural language processing, 2020, EMNLP (Demos), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_99",
            "start": 0,
            "end": 227,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_100@0",
            "content": "Han Wu, Kun Xu, Linfeng Song, Lifeng Jin, Haisong Zhang, Linqi Song, Domain-adaptive pretraining methods for dialogue understanding, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Short Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_100",
            "start": 0,
            "end": 315,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_101@0",
            "content": "Han Wu, Kun Xu, Linqi Song, CSAGN: Conversational structure aware graph network for conversational semantic role labeling, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_101",
            "start": 0,
            "end": 217,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_102@0",
            "content": "Wenquan Wu, Zhen Guo, Xiangyang Zhou, Hua Wu, Xiyuan Zhang, Rongzhong Lian, Haifeng Wang, Proactive human-machine conversation with explicit conversation goal, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_102",
            "start": 0,
            "end": 296,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_103@0",
            "content": "UNKNOWN, None, 2016, Google's neural machine translation system: Bridging the gap between human and machine translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_103",
            "start": 0,
            "end": 121,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_104@0",
            "content": "Kun Xu, Haochen Tan, Linfeng Song, Han Wu, Haisong Zhang, Linqi Song, Dong Yu, Semantic role labeling guided multi-turn dialogue rewriter, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_104",
            "start": 0,
            "end": 241,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_105@0",
            "content": "Kun Xu, Han Wu, Linfeng Song, Haisong Zhang, Linqi Song, Dong Yu, Conversational semantic role labeling, 2021, Speech, and Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_105",
            "start": 0,
            "end": 144,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_106@0",
            "content": "Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, Jason Weston, Personalizing dialogue agents: I have a dog, do you have pets too?, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_106",
            "start": 0,
            "end": 258,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_107@0",
            "content": "Zhuosheng Zhang, Hai Zhao, Structural pretraining for dialogue comprehension, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_107",
            "start": 0,
            "end": 297,
            "label": {}
        },
        {
            "ix": "284-ARR_v1_108@0",
            "content": "Kangyan Zhou, Shrimai Prabhumoye, Alan Black, A dataset for document grounded conversations, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "284-ARR_v1_108",
            "start": 0,
            "end": 187,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "284-ARR_v1_0",
            "tgt_ix": "284-ARR_v1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_0",
            "tgt_ix": "284-ARR_v1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_1",
            "tgt_ix": "284-ARR_v1_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_1",
            "tgt_ix": "284-ARR_v1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_0",
            "tgt_ix": "284-ARR_v1_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_2",
            "tgt_ix": "284-ARR_v1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_4",
            "tgt_ix": "284-ARR_v1_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_5",
            "tgt_ix": "284-ARR_v1_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_3",
            "tgt_ix": "284-ARR_v1_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_3",
            "tgt_ix": "284-ARR_v1_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_3",
            "tgt_ix": "284-ARR_v1_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_3",
            "tgt_ix": "284-ARR_v1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_0",
            "tgt_ix": "284-ARR_v1_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_6",
            "tgt_ix": "284-ARR_v1_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_8",
            "tgt_ix": "284-ARR_v1_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_7",
            "tgt_ix": "284-ARR_v1_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_7",
            "tgt_ix": "284-ARR_v1_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_7",
            "tgt_ix": "284-ARR_v1_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_0",
            "tgt_ix": "284-ARR_v1_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_9",
            "tgt_ix": "284-ARR_v1_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_10",
            "tgt_ix": "284-ARR_v1_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_10",
            "tgt_ix": "284-ARR_v1_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_10",
            "tgt_ix": "284-ARR_v1_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_11",
            "tgt_ix": "284-ARR_v1_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_13",
            "tgt_ix": "284-ARR_v1_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_14",
            "tgt_ix": "284-ARR_v1_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_15",
            "tgt_ix": "284-ARR_v1_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_16",
            "tgt_ix": "284-ARR_v1_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_17",
            "tgt_ix": "284-ARR_v1_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_18",
            "tgt_ix": "284-ARR_v1_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_12",
            "tgt_ix": "284-ARR_v1_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_12",
            "tgt_ix": "284-ARR_v1_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_12",
            "tgt_ix": "284-ARR_v1_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_12",
            "tgt_ix": "284-ARR_v1_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_12",
            "tgt_ix": "284-ARR_v1_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_12",
            "tgt_ix": "284-ARR_v1_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_12",
            "tgt_ix": "284-ARR_v1_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_12",
            "tgt_ix": "284-ARR_v1_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_20",
            "tgt_ix": "284-ARR_v1_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_21",
            "tgt_ix": "284-ARR_v1_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_22",
            "tgt_ix": "284-ARR_v1_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_23",
            "tgt_ix": "284-ARR_v1_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_12",
            "tgt_ix": "284-ARR_v1_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_12",
            "tgt_ix": "284-ARR_v1_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_12",
            "tgt_ix": "284-ARR_v1_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_12",
            "tgt_ix": "284-ARR_v1_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_12",
            "tgt_ix": "284-ARR_v1_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_19",
            "tgt_ix": "284-ARR_v1_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_10",
            "tgt_ix": "284-ARR_v1_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_24",
            "tgt_ix": "284-ARR_v1_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_26",
            "tgt_ix": "284-ARR_v1_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_27",
            "tgt_ix": "284-ARR_v1_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_28",
            "tgt_ix": "284-ARR_v1_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_25",
            "tgt_ix": "284-ARR_v1_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_25",
            "tgt_ix": "284-ARR_v1_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_25",
            "tgt_ix": "284-ARR_v1_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_25",
            "tgt_ix": "284-ARR_v1_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_25",
            "tgt_ix": "284-ARR_v1_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_25",
            "tgt_ix": "284-ARR_v1_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_29",
            "tgt_ix": "284-ARR_v1_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_10",
            "tgt_ix": "284-ARR_v1_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_30",
            "tgt_ix": "284-ARR_v1_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_31",
            "tgt_ix": "284-ARR_v1_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_31",
            "tgt_ix": "284-ARR_v1_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_33",
            "tgt_ix": "284-ARR_v1_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_31",
            "tgt_ix": "284-ARR_v1_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_31",
            "tgt_ix": "284-ARR_v1_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_32",
            "tgt_ix": "284-ARR_v1_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_0",
            "tgt_ix": "284-ARR_v1_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_34",
            "tgt_ix": "284-ARR_v1_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_35",
            "tgt_ix": "284-ARR_v1_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_35",
            "tgt_ix": "284-ARR_v1_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_0",
            "tgt_ix": "284-ARR_v1_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_36",
            "tgt_ix": "284-ARR_v1_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_38",
            "tgt_ix": "284-ARR_v1_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_39",
            "tgt_ix": "284-ARR_v1_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_40",
            "tgt_ix": "284-ARR_v1_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_41",
            "tgt_ix": "284-ARR_v1_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_42",
            "tgt_ix": "284-ARR_v1_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_37",
            "tgt_ix": "284-ARR_v1_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_37",
            "tgt_ix": "284-ARR_v1_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_37",
            "tgt_ix": "284-ARR_v1_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_37",
            "tgt_ix": "284-ARR_v1_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_37",
            "tgt_ix": "284-ARR_v1_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_37",
            "tgt_ix": "284-ARR_v1_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_37",
            "tgt_ix": "284-ARR_v1_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_0",
            "tgt_ix": "284-ARR_v1_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_43",
            "tgt_ix": "284-ARR_v1_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_45",
            "tgt_ix": "284-ARR_v1_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_46",
            "tgt_ix": "284-ARR_v1_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_47",
            "tgt_ix": "284-ARR_v1_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_48",
            "tgt_ix": "284-ARR_v1_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_44",
            "tgt_ix": "284-ARR_v1_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_44",
            "tgt_ix": "284-ARR_v1_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_44",
            "tgt_ix": "284-ARR_v1_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_44",
            "tgt_ix": "284-ARR_v1_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_44",
            "tgt_ix": "284-ARR_v1_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_44",
            "tgt_ix": "284-ARR_v1_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_0",
            "tgt_ix": "284-ARR_v1_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_49",
            "tgt_ix": "284-ARR_v1_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_50",
            "tgt_ix": "284-ARR_v1_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_50",
            "tgt_ix": "284-ARR_v1_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_50",
            "tgt_ix": "284-ARR_v1_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_51",
            "tgt_ix": "284-ARR_v1_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_53",
            "tgt_ix": "284-ARR_v1_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_50",
            "tgt_ix": "284-ARR_v1_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_50",
            "tgt_ix": "284-ARR_v1_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_52",
            "tgt_ix": "284-ARR_v1_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_50",
            "tgt_ix": "284-ARR_v1_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_50",
            "tgt_ix": "284-ARR_v1_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_55",
            "tgt_ix": "284-ARR_v1_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_57",
            "tgt_ix": "284-ARR_v1_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_58",
            "tgt_ix": "284-ARR_v1_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_50",
            "tgt_ix": "284-ARR_v1_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_50",
            "tgt_ix": "284-ARR_v1_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_50",
            "tgt_ix": "284-ARR_v1_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_56",
            "tgt_ix": "284-ARR_v1_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_60",
            "tgt_ix": "284-ARR_v1_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_50",
            "tgt_ix": "284-ARR_v1_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_50",
            "tgt_ix": "284-ARR_v1_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_59",
            "tgt_ix": "284-ARR_v1_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_50",
            "tgt_ix": "284-ARR_v1_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_61",
            "tgt_ix": "284-ARR_v1_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_50",
            "tgt_ix": "284-ARR_v1_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_62",
            "tgt_ix": "284-ARR_v1_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "284-ARR_v1_0",
            "tgt_ix": "284-ARR_v1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_1",
            "tgt_ix": "284-ARR_v1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_2",
            "tgt_ix": "284-ARR_v1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_2",
            "tgt_ix": "284-ARR_v1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_2",
            "tgt_ix": "284-ARR_v1_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_2",
            "tgt_ix": "284-ARR_v1_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_2",
            "tgt_ix": "284-ARR_v1_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_2",
            "tgt_ix": "284-ARR_v1_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_3",
            "tgt_ix": "284-ARR_v1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_4",
            "tgt_ix": "284-ARR_v1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_4",
            "tgt_ix": "284-ARR_v1_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_4",
            "tgt_ix": "284-ARR_v1_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_4",
            "tgt_ix": "284-ARR_v1_4@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_4",
            "tgt_ix": "284-ARR_v1_4@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_4",
            "tgt_ix": "284-ARR_v1_4@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_4",
            "tgt_ix": "284-ARR_v1_4@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_5",
            "tgt_ix": "284-ARR_v1_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_5",
            "tgt_ix": "284-ARR_v1_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_5",
            "tgt_ix": "284-ARR_v1_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_6",
            "tgt_ix": "284-ARR_v1_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_6",
            "tgt_ix": "284-ARR_v1_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_6",
            "tgt_ix": "284-ARR_v1_6@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_6",
            "tgt_ix": "284-ARR_v1_6@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_6",
            "tgt_ix": "284-ARR_v1_6@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_6",
            "tgt_ix": "284-ARR_v1_6@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_7",
            "tgt_ix": "284-ARR_v1_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_8",
            "tgt_ix": "284-ARR_v1_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_8",
            "tgt_ix": "284-ARR_v1_8@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_8",
            "tgt_ix": "284-ARR_v1_8@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_8",
            "tgt_ix": "284-ARR_v1_8@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_8",
            "tgt_ix": "284-ARR_v1_8@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_9",
            "tgt_ix": "284-ARR_v1_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_9",
            "tgt_ix": "284-ARR_v1_9@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_9",
            "tgt_ix": "284-ARR_v1_9@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_9",
            "tgt_ix": "284-ARR_v1_9@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_9",
            "tgt_ix": "284-ARR_v1_9@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_9",
            "tgt_ix": "284-ARR_v1_9@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_9",
            "tgt_ix": "284-ARR_v1_9@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_9",
            "tgt_ix": "284-ARR_v1_9@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_9",
            "tgt_ix": "284-ARR_v1_9@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_10",
            "tgt_ix": "284-ARR_v1_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_11",
            "tgt_ix": "284-ARR_v1_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_11",
            "tgt_ix": "284-ARR_v1_11@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_11",
            "tgt_ix": "284-ARR_v1_11@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_12",
            "tgt_ix": "284-ARR_v1_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_13",
            "tgt_ix": "284-ARR_v1_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_13",
            "tgt_ix": "284-ARR_v1_13@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_14",
            "tgt_ix": "284-ARR_v1_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_14",
            "tgt_ix": "284-ARR_v1_14@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_14",
            "tgt_ix": "284-ARR_v1_14@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_15",
            "tgt_ix": "284-ARR_v1_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_16",
            "tgt_ix": "284-ARR_v1_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_16",
            "tgt_ix": "284-ARR_v1_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_17",
            "tgt_ix": "284-ARR_v1_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_17",
            "tgt_ix": "284-ARR_v1_17@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_17",
            "tgt_ix": "284-ARR_v1_17@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_18",
            "tgt_ix": "284-ARR_v1_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_19",
            "tgt_ix": "284-ARR_v1_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_19",
            "tgt_ix": "284-ARR_v1_19@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_20",
            "tgt_ix": "284-ARR_v1_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_20",
            "tgt_ix": "284-ARR_v1_20@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_20",
            "tgt_ix": "284-ARR_v1_20@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_21",
            "tgt_ix": "284-ARR_v1_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_22",
            "tgt_ix": "284-ARR_v1_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_22",
            "tgt_ix": "284-ARR_v1_22@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_23",
            "tgt_ix": "284-ARR_v1_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_24",
            "tgt_ix": "284-ARR_v1_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_25",
            "tgt_ix": "284-ARR_v1_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_26",
            "tgt_ix": "284-ARR_v1_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_26",
            "tgt_ix": "284-ARR_v1_26@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_27",
            "tgt_ix": "284-ARR_v1_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_27",
            "tgt_ix": "284-ARR_v1_27@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_27",
            "tgt_ix": "284-ARR_v1_27@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_27",
            "tgt_ix": "284-ARR_v1_27@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_27",
            "tgt_ix": "284-ARR_v1_27@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_27",
            "tgt_ix": "284-ARR_v1_27@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_27",
            "tgt_ix": "284-ARR_v1_27@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_27",
            "tgt_ix": "284-ARR_v1_27@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_27",
            "tgt_ix": "284-ARR_v1_27@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_27",
            "tgt_ix": "284-ARR_v1_27@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_28",
            "tgt_ix": "284-ARR_v1_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_29",
            "tgt_ix": "284-ARR_v1_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_29",
            "tgt_ix": "284-ARR_v1_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_29",
            "tgt_ix": "284-ARR_v1_29@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_29",
            "tgt_ix": "284-ARR_v1_29@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_29",
            "tgt_ix": "284-ARR_v1_29@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_29",
            "tgt_ix": "284-ARR_v1_29@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_29",
            "tgt_ix": "284-ARR_v1_29@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_29",
            "tgt_ix": "284-ARR_v1_29@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_30",
            "tgt_ix": "284-ARR_v1_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_30",
            "tgt_ix": "284-ARR_v1_30@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_30",
            "tgt_ix": "284-ARR_v1_30@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_30",
            "tgt_ix": "284-ARR_v1_30@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_30",
            "tgt_ix": "284-ARR_v1_30@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_30",
            "tgt_ix": "284-ARR_v1_30@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_30",
            "tgt_ix": "284-ARR_v1_30@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_31",
            "tgt_ix": "284-ARR_v1_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_32",
            "tgt_ix": "284-ARR_v1_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_32",
            "tgt_ix": "284-ARR_v1_32@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_32",
            "tgt_ix": "284-ARR_v1_32@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_32",
            "tgt_ix": "284-ARR_v1_32@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_32",
            "tgt_ix": "284-ARR_v1_32@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_32",
            "tgt_ix": "284-ARR_v1_32@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_32",
            "tgt_ix": "284-ARR_v1_32@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_33",
            "tgt_ix": "284-ARR_v1_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_33",
            "tgt_ix": "284-ARR_v1_33@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_33",
            "tgt_ix": "284-ARR_v1_33@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_34",
            "tgt_ix": "284-ARR_v1_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_35",
            "tgt_ix": "284-ARR_v1_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_36",
            "tgt_ix": "284-ARR_v1_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_36",
            "tgt_ix": "284-ARR_v1_36@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_37",
            "tgt_ix": "284-ARR_v1_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_38",
            "tgt_ix": "284-ARR_v1_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_38",
            "tgt_ix": "284-ARR_v1_38@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_38",
            "tgt_ix": "284-ARR_v1_38@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_38",
            "tgt_ix": "284-ARR_v1_38@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_38",
            "tgt_ix": "284-ARR_v1_38@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_38",
            "tgt_ix": "284-ARR_v1_38@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_39",
            "tgt_ix": "284-ARR_v1_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_40",
            "tgt_ix": "284-ARR_v1_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_41",
            "tgt_ix": "284-ARR_v1_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_41",
            "tgt_ix": "284-ARR_v1_41@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_41",
            "tgt_ix": "284-ARR_v1_41@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_41",
            "tgt_ix": "284-ARR_v1_41@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_41",
            "tgt_ix": "284-ARR_v1_41@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_41",
            "tgt_ix": "284-ARR_v1_41@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_42",
            "tgt_ix": "284-ARR_v1_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_42",
            "tgt_ix": "284-ARR_v1_42@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_42",
            "tgt_ix": "284-ARR_v1_42@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_43",
            "tgt_ix": "284-ARR_v1_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_43",
            "tgt_ix": "284-ARR_v1_43@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_43",
            "tgt_ix": "284-ARR_v1_43@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_43",
            "tgt_ix": "284-ARR_v1_43@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_43",
            "tgt_ix": "284-ARR_v1_43@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_43",
            "tgt_ix": "284-ARR_v1_43@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_44",
            "tgt_ix": "284-ARR_v1_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_45",
            "tgt_ix": "284-ARR_v1_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_45",
            "tgt_ix": "284-ARR_v1_45@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_45",
            "tgt_ix": "284-ARR_v1_45@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_46",
            "tgt_ix": "284-ARR_v1_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_46",
            "tgt_ix": "284-ARR_v1_46@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_46",
            "tgt_ix": "284-ARR_v1_46@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_46",
            "tgt_ix": "284-ARR_v1_46@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_46",
            "tgt_ix": "284-ARR_v1_46@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_46",
            "tgt_ix": "284-ARR_v1_46@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_47",
            "tgt_ix": "284-ARR_v1_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_47",
            "tgt_ix": "284-ARR_v1_47@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_47",
            "tgt_ix": "284-ARR_v1_47@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_47",
            "tgt_ix": "284-ARR_v1_47@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_47",
            "tgt_ix": "284-ARR_v1_47@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_47",
            "tgt_ix": "284-ARR_v1_47@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_47",
            "tgt_ix": "284-ARR_v1_47@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_48",
            "tgt_ix": "284-ARR_v1_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_48",
            "tgt_ix": "284-ARR_v1_48@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_48",
            "tgt_ix": "284-ARR_v1_48@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_48",
            "tgt_ix": "284-ARR_v1_48@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_48",
            "tgt_ix": "284-ARR_v1_48@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_48",
            "tgt_ix": "284-ARR_v1_48@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_48",
            "tgt_ix": "284-ARR_v1_48@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_48",
            "tgt_ix": "284-ARR_v1_48@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_48",
            "tgt_ix": "284-ARR_v1_48@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_48",
            "tgt_ix": "284-ARR_v1_48@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_49",
            "tgt_ix": "284-ARR_v1_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_49",
            "tgt_ix": "284-ARR_v1_49@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_49",
            "tgt_ix": "284-ARR_v1_49@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_49",
            "tgt_ix": "284-ARR_v1_49@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_49",
            "tgt_ix": "284-ARR_v1_49@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_49",
            "tgt_ix": "284-ARR_v1_49@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_49",
            "tgt_ix": "284-ARR_v1_49@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_49",
            "tgt_ix": "284-ARR_v1_49@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_49",
            "tgt_ix": "284-ARR_v1_49@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_50",
            "tgt_ix": "284-ARR_v1_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_51",
            "tgt_ix": "284-ARR_v1_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_52",
            "tgt_ix": "284-ARR_v1_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_52",
            "tgt_ix": "284-ARR_v1_52@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_52",
            "tgt_ix": "284-ARR_v1_52@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_53",
            "tgt_ix": "284-ARR_v1_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_53",
            "tgt_ix": "284-ARR_v1_53@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_54",
            "tgt_ix": "284-ARR_v1_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_55",
            "tgt_ix": "284-ARR_v1_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_55",
            "tgt_ix": "284-ARR_v1_55@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_55",
            "tgt_ix": "284-ARR_v1_55@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_55",
            "tgt_ix": "284-ARR_v1_55@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_55",
            "tgt_ix": "284-ARR_v1_55@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_56",
            "tgt_ix": "284-ARR_v1_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_56",
            "tgt_ix": "284-ARR_v1_56@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_56",
            "tgt_ix": "284-ARR_v1_56@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_56",
            "tgt_ix": "284-ARR_v1_56@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_57",
            "tgt_ix": "284-ARR_v1_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_57",
            "tgt_ix": "284-ARR_v1_57@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_57",
            "tgt_ix": "284-ARR_v1_57@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_58",
            "tgt_ix": "284-ARR_v1_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_58",
            "tgt_ix": "284-ARR_v1_58@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_59",
            "tgt_ix": "284-ARR_v1_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_60",
            "tgt_ix": "284-ARR_v1_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_60",
            "tgt_ix": "284-ARR_v1_60@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_60",
            "tgt_ix": "284-ARR_v1_60@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_60",
            "tgt_ix": "284-ARR_v1_60@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_60",
            "tgt_ix": "284-ARR_v1_60@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_60",
            "tgt_ix": "284-ARR_v1_60@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_60",
            "tgt_ix": "284-ARR_v1_60@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_60",
            "tgt_ix": "284-ARR_v1_60@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_61",
            "tgt_ix": "284-ARR_v1_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_61",
            "tgt_ix": "284-ARR_v1_61@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_61",
            "tgt_ix": "284-ARR_v1_61@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_61",
            "tgt_ix": "284-ARR_v1_61@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_61",
            "tgt_ix": "284-ARR_v1_61@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_61",
            "tgt_ix": "284-ARR_v1_61@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_62",
            "tgt_ix": "284-ARR_v1_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_62",
            "tgt_ix": "284-ARR_v1_62@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_63",
            "tgt_ix": "284-ARR_v1_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_64",
            "tgt_ix": "284-ARR_v1_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_65",
            "tgt_ix": "284-ARR_v1_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_66",
            "tgt_ix": "284-ARR_v1_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_67",
            "tgt_ix": "284-ARR_v1_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_68",
            "tgt_ix": "284-ARR_v1_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_69",
            "tgt_ix": "284-ARR_v1_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_70",
            "tgt_ix": "284-ARR_v1_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_71",
            "tgt_ix": "284-ARR_v1_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_72",
            "tgt_ix": "284-ARR_v1_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_73",
            "tgt_ix": "284-ARR_v1_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_74",
            "tgt_ix": "284-ARR_v1_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_75",
            "tgt_ix": "284-ARR_v1_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_76",
            "tgt_ix": "284-ARR_v1_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_77",
            "tgt_ix": "284-ARR_v1_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_78",
            "tgt_ix": "284-ARR_v1_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_79",
            "tgt_ix": "284-ARR_v1_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_80",
            "tgt_ix": "284-ARR_v1_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_81",
            "tgt_ix": "284-ARR_v1_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_82",
            "tgt_ix": "284-ARR_v1_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_83",
            "tgt_ix": "284-ARR_v1_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_84",
            "tgt_ix": "284-ARR_v1_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_85",
            "tgt_ix": "284-ARR_v1_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_86",
            "tgt_ix": "284-ARR_v1_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_87",
            "tgt_ix": "284-ARR_v1_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_88",
            "tgt_ix": "284-ARR_v1_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_89",
            "tgt_ix": "284-ARR_v1_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_90",
            "tgt_ix": "284-ARR_v1_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_91",
            "tgt_ix": "284-ARR_v1_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_92",
            "tgt_ix": "284-ARR_v1_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_93",
            "tgt_ix": "284-ARR_v1_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_94",
            "tgt_ix": "284-ARR_v1_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_95",
            "tgt_ix": "284-ARR_v1_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_96",
            "tgt_ix": "284-ARR_v1_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_97",
            "tgt_ix": "284-ARR_v1_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_98",
            "tgt_ix": "284-ARR_v1_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_99",
            "tgt_ix": "284-ARR_v1_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_100",
            "tgt_ix": "284-ARR_v1_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_101",
            "tgt_ix": "284-ARR_v1_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_102",
            "tgt_ix": "284-ARR_v1_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_103",
            "tgt_ix": "284-ARR_v1_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_104",
            "tgt_ix": "284-ARR_v1_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_105",
            "tgt_ix": "284-ARR_v1_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_106",
            "tgt_ix": "284-ARR_v1_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_107",
            "tgt_ix": "284-ARR_v1_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "284-ARR_v1_108",
            "tgt_ix": "284-ARR_v1_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 1365,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "position_tag_type": "from_draft",
        "doc_id": "284-ARR",
        "version": 1
    }
}