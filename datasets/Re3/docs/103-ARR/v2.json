{
    "nodes": [
        {
            "ix": "103-ARR_v2_0",
            "content": "Textual Entailment for Event Argument Extraction: Zero-and Few-Shot with Multi-Source Learning",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_2",
            "content": "Recent work has shown that NLP tasks such as Relation Extraction (RE) can be recasted as Textual Entailment tasks using verbalizations, with strong performance in zero-shot and fewshot settings thanks to pre-trained entailment models. The fact that relations in current RE datasets are easily verbalized casts doubts on whether entailment would be effective in more complex tasks. In this work we show that entailment is also effective in Event Argument Extraction (EAE), reducing the need of manual annotation to 50% and 20% in ACE and WikiEvents respectively, while achieving the same performance as with full training. More importantly, we show that recasting EAE as entailment alleviates the dependency on schemas, which has been a roadblock for transferring annotations between domains. Thanks to the entailment, the multi-source transfer between ACE and WikiEvents further reduces annotation down to 10% and 5% (respectively) of the full training without transfer. Our analysis shows that the key to good results is the use of several entailment datasets to pre-train the entailment model. Similar to previous approaches, our method requires a small amount of effort for manual verbalization: only less than 15 minutes per event argument type is needed, and comparable results can be achieved with users with different level of expertise.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "103-ARR_v2_4",
            "content": "Building Information Extraction (IE) systems for real-world applications is very costly and has suffered from data-scarcity problems, due in part to the expertise and time required to annotate training data at a large scale with sufficient consistency, but also due to poor transfer between domains: IE annotations depend on the schema used in each domain, and moving to new domains requires new schemas, new annotation guidelines and the manual annotation of new data. In many cases, there is some information overlap between schemas, but performing transfer learning to leverage such overlap (i.e. learning from multiple sources) can be difficult: it often requires manually mapping labels between schemas, which is typically brittle, cumbersome and requires costly domain expertise (Kalfoglou and Schorlemmer, 2003).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_5",
            "content": "In order to save annotation effort, recent work recasts IE tasks as Textual Entailment tasks (White et al., 2017;Poliak et al., 2018a;Levy et al., 2017;. For instance, manually verbalize each relation type in the Relation Extraction (RE) dataset TACRED (Zhang et al., 2017) to generate hypotheses for each test example, and then apply an entailment model to output the relation type of the hypothesis with highest entailment probability. The entailment model is typically based on large language models pre-trained on entailment datasets such as MNLI (Williams et al., 2018). The approach obtains very strong results on zero-shot and few-shot scenarios, but we note that TACRED contains relations between two entities that are easily verbalizable, 1 casting doubts on whether entailment would be effective in more complex IE tasks. Event Argument Extraction (EAE) involves more complex contexts, higher ambiguity in the words that trigger events, and depends on the event type in addition to the relation (see Figure 1).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_6",
            "content": "In this work, we present the first system for EAE that addresses the task as an entailment problem. We empirically show the robustness of the method on the zero-shot, few-shot and full training regimes, obtaining state-of-the-art results on ACE (Walker et al., 2006) and WikiEvents . In addition, we make the following contributions:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_7",
            "content": "(1) We show that our method reduces schema dependency, as it improves the performance on the WikiEvents results using additional ACE training data and vice versa with no extra manual work. (2) Ablation results show that training with several NLI datasets is significantly better than just using MNLI.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_8",
            "content": "(3) Our analysis of the manual work required for writing templates and annotating arguments sheds light in the sweet spot for future applications, and shows that template writing does not require much domain expertise as shown by the results using an independent novice template writer. We make the code, templates and models publicly available. 2",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_9",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "103-ARR_v2_10",
            "content": "Textual Entailment Given a textual premise and a hypothesis, the task is to decide whether the premise entails or contradicts (or is neutral to) the hypothesis (Dagan et al., 2006). The current stateof-the-art uses large pre-trained Language Models (LM) (Lan et al., 2020;Liu et al., 2019;Conneau et al., 2020;Lewis et al., 2020;He et al., 2021) fine-tuned on manually annotated datasets such as SNLI (Bowman et al., 2015), MNLI (Williams et al., 2018), FEVER (Thorne et al., 2018) or ANLI (Nie et al., 2020). The task is also known as Natural Language Inference (NLI).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_11",
            "content": "Prompt and Pivot task based learning has emerged as a candidate solution for data-scarcity problems (Le Scao and Rush, 2021;Min et al., 2021;Liu et al., 2021a). The use of discrete Schick and Sch\u00fctze, 2021a,b,c) or continuous (Liu et al., 2021b) prompts allowed language models to perform significantly better on many text classification tasks. Closely related to our approach, several works make use of a highresource supervised task such as Question Answering or entailment as pivot tasks (Yin et al., 2019(Yin et al., , 2020Wang et al., 2021;Sainz and Rigau, 2021;McCann et al., 2018). In the case of entailment, Dagan et al. (2006) converted QA data to entailment manually and Demszky et al. (2018) did it automatically. Other semantic tasks such as Named Entity Recognition, Relation Extraction and Semantic Role Labelling have also been reformulated as entailment by automatically converting data into the entailment format (White et al., 2017;Poliak et al., 2018a;Levy et al., 2017;.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_12",
            "content": "Multi-task learning reformulates multiple tasks to a single and common task via prompting large pre-trained language models, leveraging multiple data sources to improve each task of interest. Such approaches have shown improvements in supervised (Subramanian et al., 2018;Raffel et al., 2020;Aribandi et al., 2022) and zero-shot scenarios (Sanh et al., 2022;Wei et al., 2021a). While using the language modelling task as a pivot shows strong performance with very large language models, it is not clear that smaller models can benefit from this strategy in the same way. Wei et al. (2021a) and Mishra et al. (2022) obtained contradictory results. In a similar way, Question Answering has been proposed as a pivot task for multi-task learning but without promising results (McCann et al., 2018). In this work, we explore multi-source learning, where datasets from different or similar tasks are used to build a model for the target task.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_13",
            "content": "Event Argument Extraction is a sub-task of Event Extraction. The goal is to identify arguments or fillers for a specific slot (a.k.a., role) in an event template. This task has been largely explored on the Message Understanding Conference (MUC, Grishman and Sundheim (1996)) and later on Automatic Content Evaluation (ACE). ACE focused mainly on sentence level evaluation due to the difficulty of the task at the time. Recently, new benchmarks such as RAMS and WikiEvents have emerged with the aim of addressing document level information extraction similar to MUC. However, most of the interest is still focused on the sentence level.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_14",
            "content": "EAE has been recently addressed by end-to-end event extraction models (Wadden et al., 2019;Lin et al., 2020;Li et al., 2021a), instead of treating it as an independent task (Du and Cardie, 2020a), as we do, or as a subtask in a pipeline (Lyu et al., 2021). Lately, with the recent paradigm shift to prompt design learning (Min et al., 2021), several works reformulated the task as a Question Answering problem Feng et al., 2020;Du and Cardie, 2020b;Wei et al., 2021b;Lyu et al., 2021;Sulem et al., 2022) or as a Constrained Text Generation problem Du et al., 2021; using predefined prompts, questions or templates. We instead reformulate the task as a textual entailment problem.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_15",
            "content": "Approach",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "103-ARR_v2_16",
            "content": "In order to cast EAE as an entailment task, we verbalize event argument instances using a set of intuitive and linguistically motivated templates to capture the event argument roles, and then per-Figure 1: Entailment-based Event Argument Extraction. On the left, input information: the context, the event trigger (hired) and the argument candidate (John D. Idol), alongside the types of both. On the middle, some hypothesis verbalized using the templates: the green box is entailed, the yellow box matches the type constraint but it is not entailed, and the rest do not satisfy type constraints. On the right, the output with the inferred role (Person).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_17",
            "content": "form inferences with entailment models. The entailment model can be additionally trained with EAE training data converted into the entailment format, similar to . Figure 1 shows the general workflow of the method. First, the possible roles are verbalized by means of predefined templates and the input, which comprises the context, trigger and argument candidate. Then, an entailment model is used to generate the entailment probability for each verbalization. To predict the role, the most probable hypothesis (verbalization) is chosen among the roles that satisfy the evententity 3 constraints. A more detailed description of each component follows.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_18",
            "content": "Label verbalization is attained using templates that combine the information of the instance and express a specific label. Different role verbalizations are shown in Figure 1. A verbalization is generated using templates that have been manually written based on the task guidelines of each dataset. The templates involve the candidate argument, and optionally the event trigger. In some cases, in order to produce a grammatical hypothesis, placeholders corresponding to the agent or theme are also introduced, which can be generic, e.g. someone, or dependent of the argument role, e.g. defendant.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_19",
            "content": "We defined several template types (see Table 1) to guide the creation of templates more systematically. In Section 5.1 we describe the process to create templates, and in Section 7 we analyse the differences between independent template developers and how this did not affect performance. The templates created for the ACE dataset are listed in Appendix C.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_20",
            "content": "Entailment model. Given a premise and hypothesis, the model returns the probabilities of the hypothesis being entailed by, contradicted to or neutral to the premise. In principle, any model trained on the NLI task can be used.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_21",
            "content": "Inference takes into account three key factors to output the role label for an argument candidate: the entailment probabilities of each verbalization, the type constraints of the specific role, and a threshold. Argument candidates which do not match the type constraints are discarded. From the rest, we return the role of the verbalized hypothesis with highest entailment probability, unless the probability is lower than the threshold, in which case we return the negative class. 4 Training. Our entailment-based model can be applied without any training on the EAE task, in a zero-shot fashion, or, alternatively, the entailment model can be finetuned using training data from the EAE dataset. For this purpose, we convert the EAE training dataset into a NLI format, i.e we generate entailment, neutral and contradiction hypotheses heuristically from the data using the templates themselves. For each positive labeled example (a candidate that is an argument) we sample N E entailment hypotheses using the templates that correspond to the correct label and N N neutral hypotheses using templates from different roles. For each negative example (the candidate is not an argument of the event) we create N C contradiction hypotheses using any template at random. The {arg} inspected something.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_22",
            "content": "Table 1: The four main template categories used to create the role verbalizations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_23",
            "content": "Entailment for Multi-source Learning",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "103-ARR_v2_24",
            "content": "We hypothesize that two similar IE tasks can benefit from each other even if they do not share the same schema or domain. Although this hypothesis is very intuitive and it has been demonstrated on several works for tasks other than IE (see Multitask learning on Section 2), actual IE models are limited by schema dependency, which makes it almost impossible to learn from datasets annotated with different IE schemas. One option is to perform a manual mapping between schemas, which is costly and often inaccurate (Kalfoglou and Schorlemmer, 2003). Our approach instead is domain and schema agnostic, and therefore allows to learning from multiple sources seamlessly. Given that the sources are recast into a single format in a common entailment formulation, it suffices to fine-tune the model in sequence across the sources.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_25",
            "content": "To check our hypothesis we split tasks according to the following criteria: (1) IE sources like Relation Extraction that are different from EAE (e.g. TACRED), and (2) EAE sources using different schemas (e.g. WikiEvents and ACE). Figure 2 summarizes the tasks and datasets used in this work, including the four natural language understanding datasets.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_26",
            "content": "Experimental Setup",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "103-ARR_v2_27",
            "content": "In this section, we describe the methodology for template development, evaluation setting, the baselines used in our experiments, and the computation infrastructure specifications.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_28",
            "content": "Methodology for verbalization",
            "ntype": "title",
            "meta": {
                "section": "5.1"
            }
        },
        {
            "ix": "103-ARR_v2_29",
            "content": "The templates used to generate the verbalizations were created based on the annotation guidelines of each dataset. During the creation, the template developers had access to the guidelines that describe each of the roles (which can include one or two examples) and a NLI model that the developer could use to verify whether the generated verbalizations of these examples were entailed by the model. The developer was allowed a maximum of 15 minutes per role, and spent 5 and 12 hours 5 to create the templates for ACE and WikiEvents respectively.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_30",
            "content": "Evaluation",
            "ntype": "title",
            "meta": {
                "section": "5.2"
            }
        },
        {
            "ix": "103-ARR_v2_31",
            "content": "Datasets. We carried out our evaluation on two different EAE datasets: ACE (Walker et al., 2006) and WikiEvents Arabic texts. We worked only on the English EAE task. The WikiEvents dataset is instead more focused on document-level argument extraction task. Although the last is intended to be use as a document-level benchmark we focused on the sentence-level extraction 6 for two reasons: to maintain consistency with ACE dataset and because the nearest occurrence of the arguments are inside the sentence of the event trigger in almost all examples. For both ACE and WikiEvents, we split the training data into different amounts (0%, 1%, 5%, 10%, 20% and 100%) following to also evaluate our system on extreme data scarcity scenarios. Table 2 shows the amount of examples per split. The total amount refers to the addition of all positives and negatives trigger-candidate pairs.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_32",
            "content": "Metrics. We have used the standard F1-Score, which is a common metric on IE tasks. Along with that, we propose the use of the Area Under the Curve (AUC) for better model comparison across all scenarios. The reported AUC scores are computed with all splits for the main results and just with 0%, 5% and 100% for the multi-source results, and therefore, they are not comparable.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_33",
            "content": "Baselines and Models",
            "ntype": "title",
            "meta": {
                "section": "5.3"
            }
        },
        {
            "ix": "103-ARR_v2_34",
            "content": "Baselines. Our main point of comparison is our re-implementation of EM (Baldini Soares et al., 2019), as we can run it on the same few-shot splits as our system and allow for head-to-head comparison. EM is a state-of-the-art (Zhou and Chen, 2021) model that uses ROBERTA LARGE as a backbone. In addition we also report results of the state-of-the-art models that have been run on our same experimental setup, having access to gold event-trigger and entity annotations. On ACE, we report the results of BERTEE and RCEE_ER, both reported at , which correspond to a BERT (Devlin et al., 2019) based baseline and a QA based pivot approach that leverages SQuAD (Rajpurkar et al., 2016) data. Unfortunately the data splits used by are not available 7 and thus, only the results for zero-shot (i.e. 0% training data) and full training (i.e. 100% training data) are directly comparable. Regarding WikiEvents Gen-Arg uses gold triggers, but not gold entity information, so we decided to report Coref-F1 8 which refers to the F1-Score of predicting at least one of the gold entity coreferential chain as argument.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_35",
            "content": "NLI models used in this work are based on the RoBERTa large (Liu et al., 2019) checkpoint, and are available via HuggingFace Transformer's model repository (Wolf et al., 2020). The main results use a model trained on all MNLI, SNLI, FEVER and ANLI, and in the analysis we also report the results of a model using just MNLI (see Appendix A for more information, including hyperparameters used).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_36",
            "content": "Infrastructure",
            "ntype": "title",
            "meta": {
                "section": "5.4"
            }
        },
        {
            "ix": "103-ARR_v2_37",
            "content": "All the experiments were done in a single RTX 2080ti (11Gb) with a 250W power consumption. The average training times are: 9 0.36h/epoch for ACE, 0.52h/epoch for WikiEvents and 2.86 h/epoch for TACRED. In total, 464.56 hours (154.86 if only a single run is done) of computation time are required to reproduce all the experiments, that in our setting corresponds to 21.36 kgCO 2 eq carbon footprint 10 (roughly equivalent to the CO 2 emitted by 88.2 km driven by an average car).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_38",
            "content": "Results",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "103-ARR_v2_39",
            "content": "Main results. system is the best in all cases. In both datasets the EM baseline is outperformed by the NLI system.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_40",
            "content": "Multi-source results. Sequentially fine-tuning our NLI model in TA-CRED and then in our target task shows small improvements on low-resource scenarios (0% split for ACE, 0% and 5% splits for WikiEvents). Training on the three sources sequentially does not seem to yield further improvements.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_41",
            "content": "Figure 3 shows the performance of our NLI and multi-source enhanced NLI+ systems along with the EM baseline (data from Tables 3 and 4). The curves show that our NLI+ systems only need 10% and 5% of the data (on ACE and WikiEvents, respectively) to outperform the EM baseline that uses 100% of the training data.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_42",
            "content": "Analysis",
            "ntype": "title",
            "meta": {
                "section": "7"
            }
        },
        {
            "ix": "103-ARR_v2_43",
            "content": "After performing the main experiments we did some additional analysis.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_44",
            "content": "A perfect NLI model should, in theory, solve any task that is framed correctly as entailment. Of course, there is not \"perfect\" NLI model. In fact, current state-of-the-art NLI models tend to learn artifacts and lexical patterns (Gururangan et al., 2018;Poliak et al., 2018b;Tsuchiya, 2018;Glockner et al., 2018;Geva et al., 2019;McCoy et al., Table 5: Ablation on NLI datasets used to-pretrain our NLI model on three datasets. NLI for our system using MNLI, FEVER, SNLI and ANLI (taken Table 3) and NLI MNLI only for our system when using MNLI only.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_45",
            "content": "2019) instead of the task itself. Motivated by these issues, datasets like ANLI (Nie et al., 2020) were adversarially created to alleviate them. The lack of robustness of NLI models gets amplified when it comes to a cross-task evaluation. For instance, the model trained on MNLI achieves 90.2 accuracy on MNLI and 31.4, 29.5 and 55.6 F1-Score on ACE, WikiEvents and TACRED respectively (cf. Table 5). Adding FEVER, SNLI and ANLI to the training improves MNLI accuracy only 0.8 points to 91.0, but zero-shot scores on ACE, WikiEvents and TACRED improve +9.2, +6.4 and +1.2 respectively. In few-shot and full-training scenarios, the results also improve when using several NLI datasets. Our results suggest that new, more challenging NLI datasets, as well as NLI datasets automatically generated from other sources (as done in this work with WikiEvents and ACE) will yield more robust entailment models, and could further increase the performance of entailment-based EAE and IE. The impact of different template developers.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_46",
            "content": "In order to test the robustness of the templates, we enrolled a linguist with experience in NLP annotation but no prior contact with the project nor access to the original templates from the main developer.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_47",
            "content": "Under the same time and resource conditions, she was asked to write templates for the ACE dataset.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_48",
            "content": "The templates written by the main developer and the linguist vary in different ways: (1) the number of created templates per role and (2) the verbalization style, as the main developer tended to use finite and conjugated verbs while the linguist tended to use infinitives and lemmas. The templates of both are available in Appendix C.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_49",
            "content": "To study the performance of the templates of each developer per role, Figure 4 shows the instances that a system correctly classified and the other system did not, and vice versa. The bars display the recall, as they are normalized by the frequencies of the roles. Missing bars on a row means that both performed the same on that role (e.g. Seller). When only a blue bar is shown (e.g. Org) it means that the main developer recovered arguments which the linguist did not, and there were no examples where the linguist recovered arguments that the developer did not. The same applies to situations where there is only purple bars. Roles with mixed results include examples where one or the other succeeded. As we can see, the approaches seem to be complementary, with the linguist having a higher recall with the roles that are more associated with classical semantic roles. Table 6 shows that in general, the templates of the linguist perform similarly to those of the main developer, except for 100% of the data, where the templates of the main developer were slightly better. Verbalizations vs. annotations Finally, we carried out an experiment to compare the time and effort requirements of annotation vs. writing the templates. To that end, the linguist re-annotated a small portion of ACE with the same information she had as she was creating the templates. That is, given the argument candidates for each event trigger in the document, she needs to decide whether the candidate was an argument and the type of the argument. She has access to the guidelines (similar to creating the templates), though she did not study them beforehand. Note also that she did the annotations after writing the templates, so she was already familiar with the slots. Under these conditions, she annotated 46 pairs (event trigger, potential argument candidate) in 30 minutes. Taking into account that ACE has 16.5000 such pairs, it would take approximately 180 hours to annotate ACE training part. Note that in practice, ACE requires much more time than our estimate to achieve the desired level of quality: the ACE annotation procedure involved double annotation and a second pass with a senior annotator (Doddington et al., 2004). For an analysis of the annotation procedure the interested reader is referred to Min and Grishman (2012). Based on our estimation, 9 hours would allow an annotator to annotate 5% of the dataset which yields a 37.5 F1 (Figure 5), while 5 hours of template building yields 40.6 F1-Score in the zero-shot setting. With 18 hours 10% would be annotated and the F1-Score will be 50.9, while 5 hours of template building and 9 hours of annotations would yield 57. Figure 5 plots the performance according to manual hours on ACE, showing the huge gains provided by the initial 5 hours writing templates, plus the reuse of WikiEvents annotations. According to our experience, more hours on template building does not necessarily lead to improvements (contrary to annotation), so a sweet spot for time investment seems to be to firstly create templates, and then spend the remaining budget on annotating examples.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_50",
            "content": "On another note, the linguist mentioned that writing templates is more natural and rewarding than annotating examples, which is more repetitive, stressful and tiresome. When writing templates, she was thinking in an abstract manner, trying to find generalizations, while she was paying attention to concrete cases when doing annotation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_51",
            "content": "Conclusions",
            "ntype": "title",
            "meta": {
                "section": "8"
            }
        },
        {
            "ix": "103-ARR_v2_52",
            "content": "This paper shows the entailment-based approach for event argument extraction is extremely effective in zero-shot, few-shot and full train scenarios both on ACE and WikiEvents, outperforming previous methods. First of all, recasting EAE as an entailment task allows it to reuse annotations from different event schemas, achieving large gains when transferring annotations between ACE and WikiEvents, and also some gains in the zero-shot performance when transferring annotations from a relation extraction model such as TACRED. Secondly, we show that using additional training entailment datasets improves results significantly over just using MNLI, not only on EAE but also on TA-CRED. Thirdly, we show that the relatively short time spent writing manual templates is much more effective than the time spent on doing annotations, with a sweet spot where the annotation effort is split between the two, with large savings in manual labour. Lastly, we show that an independent linguist is able to write templates with comparable performance without any special training. We think that our results and analysis support the potential of entailment models for other NLP tasks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_53",
            "content": "Our work paves the way for a new paradigm for IE, where the expert defines the schema using natural language and directly runs those specifications, annotating a handful of examples in the process, and allowing for quick trial-and-error iterations. Sainz et al. (2022) propose a user interface alongside this paradigm. More generally, inference capability could be extended, acquired and applied from other tasks, in a research avenue where entailment and task performance improve in tandem.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_54",
            "content": "On this section we describe the hyperparameters we have used on our experiments. All the hyperparameters optimized on this work were optimized for the 100% split with the batch-size fixed to 32, and used on the rest. The Table 7 describes the hyperparameters used on EM, NLI and NLI MNLI only variants, for the NLI+ the same hyperparameters as NLI were used. We have found that the same exact hyperparameters were the best on ACE, WikiEvents and TACRED datasets. For the future, we plan to test new hyperparameter sets that uses bigger batch-sizes, as recent works (Aribandi et al., 2022) suggest to be optimal for multi-task and -source learning experiments. The pre-trained NLI models used on this work can be downloaded from the HuggingFace Models repository: NLI MNLI only (roberta-large-mnli) and NLI (ynie/roberta-large-snli_mnli_ fever_anli_R1_R2_R3-nli).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_55",
            "content": "The fine-tuned models derived from this work will be uploaded to HuggingFace Models repository. Check the GitHub repository for updated information.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_56",
            "content": "The Figure 6 shows the per role absolute improvement obtained by training on different tasks over the 0% NLI system. Overall, we can see that training on ACE or WikiEvents improves almost all the roles and training on TACRED improves some and some others do not. A result that was unexpected is that there are few roles on WikiEvents that after training on WikiEvents become worse in contrary to training on ACE. This could be explained by the differences among the frequency distributions that the train, development and test sets of WikiEvents has. Moreover, there are some roles on WikiEvents that decreases in all training scenarios, this suggests us that sequential fine-tuning might be not the best option for this type of multi-source learning and therefore further ways should be explored.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_57",
            "content": "The next table contains the templates written by both developers for the ACE arguments. We follow the notation introduced in Section 5.1. In addition, we also consider information from the event, such as the type on different granularity levels, including {trg_type} for the trigger type (e.g. Movement from Movement.Transport) and {trg_subtype} for the subtype of the trigger, e.g. Transport from Movement.Transport).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "103-ARR_v2_58",
            "content": "Vamsi Aribandi, Yi Tay, Tal Schuster, Jinfeng Rao, Huaixiu Steven Zheng, Sanket Vaibhav Mehta, Honglei Zhuang, Q Vinh, Dara Tran, Jianmo Bahri, Jai Ni, Kai Gupta, Sebastian Hui, Donald Ruder,  Metzler, Ext5: Towards extreme multi-task scaling for transfer learning, 2022, International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "Vamsi Aribandi",
                    "Yi Tay",
                    "Tal Schuster",
                    "Jinfeng Rao",
                    "Huaixiu Steven Zheng",
                    "Sanket Vaibhav Mehta",
                    "Honglei Zhuang",
                    "Q Vinh",
                    "Dara Tran",
                    "Jianmo Bahri",
                    "Jai Ni",
                    "Kai Gupta",
                    "Sebastian Hui",
                    "Donald Ruder",
                    " Metzler"
                ],
                "title": "Ext5: Towards extreme multi-task scaling for transfer learning",
                "pub_date": "2022",
                "pub_title": "International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_59",
            "content": "Livio Baldini, Nicholas Soares, Jeffrey Fitzgerald, Tom Ling,  Kwiatkowski, Matching the blanks: Distributional similarity for relation learning, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    " Livio Baldini",
                    "Nicholas Soares",
                    "Jeffrey Fitzgerald",
                    "Tom Ling",
                    " Kwiatkowski"
                ],
                "title": "Matching the blanks: Distributional similarity for relation learning",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_60",
            "content": "R Samuel, Gabor Bowman, Christopher Angeli, Christopher Potts,  Manning, A large annotated corpus for learning natural language inference, 2015, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "R Samuel",
                    "Gabor Bowman",
                    "Christopher Angeli",
                    "Christopher Potts",
                    " Manning"
                ],
                "title": "A large annotated corpus for learning natural language inference",
                "pub_date": "2015",
                "pub_title": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_61",
            "content": "Yunmo Chen, Tongfei Chen, Seth Ebner, Aaron White, Benjamin Van Durme, Reading the manual: Event extraction as definition comprehension, 2020, Proceedings of the Fourth Workshop on Structured Prediction for NLP, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Yunmo Chen",
                    "Tongfei Chen",
                    "Seth Ebner",
                    "Aaron White",
                    "Benjamin Van Durme"
                ],
                "title": "Reading the manual: Event extraction as definition comprehension",
                "pub_date": "2020",
                "pub_title": "Proceedings of the Fourth Workshop on Structured Prediction for NLP",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_62",
            "content": "Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettlemoyer, Veselin Stoyanov, Unsupervised cross-lingual representation learning at scale, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Alexis Conneau",
                    "Kartikay Khandelwal",
                    "Naman Goyal",
                    "Vishrav Chaudhary",
                    "Guillaume Wenzek",
                    "Francisco Guzm\u00e1n",
                    "Edouard Grave",
                    "Myle Ott",
                    "Luke Zettlemoyer",
                    "Veselin Stoyanov"
                ],
                "title": "Unsupervised cross-lingual representation learning at scale",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_63",
            "content": "Oren Ido Dagan, Bernardo Glickman,  Magnini, The pascal recognising textual entailment challenge, 2006, Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment, Springer.",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "Oren Ido Dagan",
                    "Bernardo Glickman",
                    " Magnini"
                ],
                "title": "The pascal recognising textual entailment challenge",
                "pub_date": "2006",
                "pub_title": "Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment",
                "pub": "Springer"
            }
        },
        {
            "ix": "103-ARR_v2_64",
            "content": "UNKNOWN, None, 2018, Transforming question answering datasets into natural language inference datasets, .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Transforming question answering datasets into natural language inference datasets",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_65",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Jacob Devlin",
                    "Ming-Wei Chang",
                    "Kenton Lee",
                    "Kristina Toutanova"
                ],
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_66",
            "content": "Alexis George R Doddington,  Mitchell, A Mark,  Przybocki, A Lance, Stephanie Ramshaw, Ralph Strassel,  Weischedel, The Automatic Content Extraction (ACE) Program Tasks, Data, and Evaluation, 2004, Language Resources and Evaluation Conference (LREC), .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Alexis George R Doddington",
                    " Mitchell",
                    "A Mark",
                    " Przybocki",
                    "A Lance",
                    "Stephanie Ramshaw",
                    "Ralph Strassel",
                    " Weischedel"
                ],
                "title": "The Automatic Content Extraction (ACE) Program Tasks, Data, and Evaluation",
                "pub_date": "2004",
                "pub_title": "Language Resources and Evaluation Conference (LREC)",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_67",
            "content": "UNKNOWN, None, 2020, Document-level event role filler extraction using multi-granularity contextualized encoding, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Document-level event role filler extraction using multi-granularity contextualized encoding",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_68",
            "content": "Xinya Du, Claire Cardie, Event extraction by answering (almost) natural questions, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Xinya Du",
                    "Claire Cardie"
                ],
                "title": "Event extraction by answering (almost) natural questions",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_69",
            "content": "Xinya Du, Alexander Rush, Claire Cardie, GRIT: Generative role-filler transformers for document-level event entity extraction, 2021, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Xinya Du",
                    "Alexander Rush",
                    "Claire Cardie"
                ],
                "title": "GRIT: Generative role-filler transformers for document-level event entity extraction",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_70",
            "content": "Seth Ebner, Patrick Xia, Ryan Culkin, Kyle Rawlins, Benjamin Van Durme, Multi-sentence argument linking, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Seth Ebner",
                    "Patrick Xia",
                    "Ryan Culkin",
                    "Kyle Rawlins",
                    "Benjamin Van Durme"
                ],
                "title": "Multi-sentence argument linking",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_71",
            "content": "UNKNOWN, None, 2020, Probing and fine-tuning reading comprehension models for few-shot event extraction, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Probing and fine-tuning reading comprehension models for few-shot event extraction",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_72",
            "content": "Tianyu Gao, Adam Fisch, Danqi Chen, Making pre-trained language models better few-shot learners, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Tianyu Gao",
                    "Adam Fisch",
                    "Danqi Chen"
                ],
                "title": "Making pre-trained language models better few-shot learners",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "103-ARR_v2_73",
            "content": "Mor Geva, Yoav Goldberg, Jonathan Berant, Are we modeling the task or the annotator? an investigation of annotator bias in natural language understanding datasets, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Mor Geva",
                    "Yoav Goldberg",
                    "Jonathan Berant"
                ],
                "title": "Are we modeling the task or the annotator? an investigation of annotator bias in natural language understanding datasets",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_74",
            "content": "Max Glockner, Vered Shwartz, Yoav Goldberg, Breaking NLI systems with sentences that require simple lexical inferences, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "Max Glockner",
                    "Vered Shwartz",
                    "Yoav Goldberg"
                ],
                "title": "Breaking NLI systems with sentences that require simple lexical inferences",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_75",
            "content": "Ralph Grishman, Beth Sundheim, Message Understanding Conference-6: A brief history, 1996, The 16th International Conference on Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Ralph Grishman",
                    "Beth Sundheim"
                ],
                "title": "Message Understanding Conference-6: A brief history",
                "pub_date": "1996",
                "pub_title": "The 16th International Conference on Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_76",
            "content": "Swabha Suchin Gururangan, Omer Swayamdipta, Roy Levy, Samuel Schwartz, Noah Bowman,  Smith, Annotation artifacts in natural language inference data, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Swabha Suchin Gururangan",
                    "Omer Swayamdipta",
                    "Roy Levy",
                    "Samuel Schwartz",
                    "Noah Bowman",
                    " Smith"
                ],
                "title": "Annotation artifacts in natural language inference data",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_77",
            "content": "UNKNOWN, None, 2021, Deberta: Decoding-enhanced bert with disentangled attention, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Deberta: Decoding-enhanced bert with disentangled attention",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_78",
            "content": "UNKNOWN, None, 2003, Ontology mapping: the state of the art. The knowledge engineering review, .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": null,
                "title": null,
                "pub_date": "2003",
                "pub_title": "Ontology mapping: the state of the art. The knowledge engineering review",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_79",
            "content": "Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut, Albert: A lite bert for self-supervised learning of language representations, 2020, International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "Zhenzhong Lan",
                    "Mingda Chen",
                    "Sebastian Goodman",
                    "Kevin Gimpel",
                    "Piyush Sharma",
                    "Radu Soricut"
                ],
                "title": "Albert: A lite bert for self-supervised learning of language representations",
                "pub_date": "2020",
                "pub_title": "International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_80",
            "content": "Le Teven, Alexander Scao,  Rush, How many data points is a prompt worth, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Le Teven",
                    "Alexander Scao",
                    " Rush"
                ],
                "title": "How many data points is a prompt worth",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_81",
            "content": "Omer Levy, Minjoon Seo, Eunsol Choi, Luke Zettlemoyer, Zero-shot relation extraction via reading comprehension, 2017, Proceedings of the 21st Conference on Computational Natural Language Learning, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Omer Levy",
                    "Minjoon Seo",
                    "Eunsol Choi",
                    "Luke Zettlemoyer"
                ],
                "title": "Zero-shot relation extraction via reading comprehension",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 21st Conference on Computational Natural Language Learning",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_82",
            "content": "Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, Luke Zettlemoyer, BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Mike Lewis",
                    "Yinhan Liu",
                    "Naman Goyal",
                    "Marjan Ghazvininejad",
                    "Abdelrahman Mohamed",
                    "Omer Levy",
                    "Veselin Stoyanov",
                    "Luke Zettlemoyer"
                ],
                "title": "BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_83",
            "content": "Fayuan Li, Weihua Peng, Yuguang Chen, Quan Wang, Lu Pan, Yajuan Lyu, Yong Zhu, Event extraction as multi-turn question answering, 2020, Findings of the Association for Computational Linguistics: EMNLP 2020, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Fayuan Li",
                    "Weihua Peng",
                    "Yuguang Chen",
                    "Quan Wang",
                    "Lu Pan",
                    "Yajuan Lyu",
                    "Yong Zhu"
                ],
                "title": "Event extraction as multi-turn question answering",
                "pub_date": "2020",
                "pub_title": "Findings of the Association for Computational Linguistics: EMNLP 2020",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_84",
            "content": "Manling Li, Sha Li, Zhenhailong Wang, Lifu Huang, Kyunghyun Cho, Heng Ji, Jiawei Han, Clare Voss, The future is not one-dimensional: Complex event schema induction by graph modeling for event prediction, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": [
                    "Manling Li",
                    "Sha Li",
                    "Zhenhailong Wang",
                    "Lifu Huang",
                    "Kyunghyun Cho",
                    "Heng Ji",
                    "Jiawei Han",
                    "Clare Voss"
                ],
                "title": "The future is not one-dimensional: Complex event schema induction by graph modeling for event prediction",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_85",
            "content": "Sha Li, Ji Heng, Jiawei Han, Documentlevel event argument extraction by conditional generation, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": [
                    "Sha Li",
                    "Ji Heng",
                    "Jiawei Han"
                ],
                "title": "Documentlevel event argument extraction by conditional generation",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_86",
            "content": "Ying Lin, Heng Ji, Fei Huang, Lingfei Wu, A joint neural model for information extraction with global features, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Ying Lin",
                    "Heng Ji",
                    "Fei Huang",
                    "Lingfei Wu"
                ],
                "title": "A joint neural model for information extraction with global features",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_87",
            "content": "Jian Liu, Yubo Chen, Kang Liu, Wei Bi, Xiaojiang Liu, Event extraction as machine reading comprehension, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "Jian Liu",
                    "Yubo Chen",
                    "Kang Liu",
                    "Wei Bi",
                    "Xiaojiang Liu"
                ],
                "title": "Event extraction as machine reading comprehension",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_88",
            "content": "UNKNOWN, None, 2021, Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_89",
            "content": "UNKNOWN, None, , Zhilin Yang, and Jie Tang. 2021b. P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Zhilin Yang, and Jie Tang. 2021b. P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_90",
            "content": "UNKNOWN, None, 2019, Roberta: A robustly optimized bert pretraining approach, .",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Roberta: A robustly optimized bert pretraining approach",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_91",
            "content": "Qing Lyu, Hongming Zhang, Elior Sulem, Dan Roth, Zero-shot event extraction via transfer learning: Challenges and insights, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": [
                    "Qing Lyu",
                    "Hongming Zhang",
                    "Elior Sulem",
                    "Dan Roth"
                ],
                "title": "Zero-shot event extraction via transfer learning: Challenges and insights",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_92",
            "content": "UNKNOWN, None, 2018, The natural language decathlon: Multitask learning as question answering, .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "The natural language decathlon: Multitask learning as question answering",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_93",
            "content": "Tom Mccoy, Ellie Pavlick, Tal Linzen, Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": [
                    "Tom Mccoy",
                    "Ellie Pavlick",
                    "Tal Linzen"
                ],
                "title": "Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_94",
            "content": "Bonan Min, Ralph Grishman, Compensating for Annotation Errors in Training a Relation Extractor, 2012, Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "Bonan Min",
                    "Ralph Grishman"
                ],
                "title": "Compensating for Annotation Errors in Training a Relation Extractor",
                "pub_date": "2012",
                "pub_title": "Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_95",
            "content": "UNKNOWN, None, 2021, Recent advances in natural language processing via large pre-trained language models: A survey, .",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Recent advances in natural language processing via large pre-trained language models: A survey",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_96",
            "content": "Swaroop Mishra, Daniel Khashabi, Chitta Baral, Hannaneh Hajishirzi, Cross-task generalization via natural language crowdsourcing instructions, 2022, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": [
                    "Swaroop Mishra",
                    "Daniel Khashabi",
                    "Chitta Baral",
                    "Hannaneh Hajishirzi"
                ],
                "title": "Cross-task generalization via natural language crowdsourcing instructions",
                "pub_date": "2022",
                "pub_title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_97",
            "content": "Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, Douwe Kiela, Adversarial NLI: A new benchmark for natural language understanding, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": [
                    "Yixin Nie",
                    "Adina Williams",
                    "Emily Dinan",
                    "Mohit Bansal",
                    "Jason Weston",
                    "Douwe Kiela"
                ],
                "title": "Adversarial NLI: A new benchmark for natural language understanding",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_98",
            "content": "UNKNOWN, None, 2018, Towards a unified natural language inference framework to evaluate sentence representations, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b40",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Towards a unified natural language inference framework to evaluate sentence representations",
                "pub": "CoRR"
            }
        },
        {
            "ix": "103-ARR_v2_99",
            "content": "Adam Poliak, Jason Naradowsky, Aparajita Haldar, Rachel Rudinger, Benjamin Van Durme, Hypothesis only baselines in natural language inference, 2018, Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b41",
                "authors": [
                    "Adam Poliak",
                    "Jason Naradowsky",
                    "Aparajita Haldar",
                    "Rachel Rudinger",
                    "Benjamin Van Durme"
                ],
                "title": "Hypothesis only baselines in natural language inference",
                "pub_date": "2018",
                "pub_title": "Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_100",
            "content": "Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter Liu, Exploring the limits of transfer learning with a unified text-to-text transformer, 2020, Journal of Machine Learning Research, .",
            "ntype": "ref",
            "meta": {
                "xid": "b42",
                "authors": [
                    "Colin Raffel",
                    "Noam Shazeer",
                    "Adam Roberts",
                    "Katherine Lee",
                    "Sharan Narang",
                    "Michael Matena",
                    "Yanqi Zhou",
                    "Wei Li",
                    "Peter Liu"
                ],
                "title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
                "pub_date": "2020",
                "pub_title": "Journal of Machine Learning Research",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_101",
            "content": "Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang, SQuAD: 100,000+ questions for machine comprehension of text, 2016, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b43",
                "authors": [
                    "Pranav Rajpurkar",
                    "Jian Zhang",
                    "Konstantin Lopyrev",
                    "Percy Liang"
                ],
                "title": "SQuAD: 100,000+ questions for machine comprehension of text",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_102",
            "content": "Oscar Sainz, Oier Lopez De Lacalle, Gorka Labaka, Ander Barrena, Eneko Agirre, Label verbalization and entailment for effective zero and fewshot relation extraction, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b44",
                "authors": [
                    "Oscar Sainz",
                    "Oier Lopez De Lacalle",
                    "Gorka Labaka",
                    "Ander Barrena",
                    "Eneko Agirre"
                ],
                "title": "Label verbalization and entailment for effective zero and fewshot relation extraction",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_103",
            "content": "Oscar Sainz, Haoling Qiu, Oier Lopez De Lacalle, Agirre Eneko, Bonan Min, ZS4IE: A toolkit for zero-shot information extraction with simple verbalizations, 2022, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations, Online and, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b45",
                "authors": [
                    "Oscar Sainz",
                    "Haoling Qiu",
                    "Oier Lopez De Lacalle",
                    "Agirre Eneko",
                    "Bonan Min"
                ],
                "title": "ZS4IE: A toolkit for zero-shot information extraction with simple verbalizations",
                "pub_date": "2022",
                "pub_title": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations, Online and",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_104",
            "content": "Oscar Sainz, German Rigau, Ask2Transformers: Zero-shot domain labelling with pretrained language models, 2021, Proceedings of the 11th Global Wordnet Conference, .",
            "ntype": "ref",
            "meta": {
                "xid": "b46",
                "authors": [
                    "Oscar Sainz",
                    "German Rigau"
                ],
                "title": "Ask2Transformers: Zero-shot domain labelling with pretrained language models",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 11th Global Wordnet Conference",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_105",
            "content": "Victor Sanh, Albert Webson, Colin Raffel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, Canwen Bari, Urmish Xu, Shanya Thakker, Eliza Sharma Sharma, Taewoon Szczechla, Gunjan Kim, Nihal Chhablani, Debajyoti Nayak, Jonathan Datta, Mike Chang,  Tian-Jian, Han Jiang, Matteo Wang, Sheng Manica,  Shen, Multitask prompted training enables zero-shot task generalization, 2022, International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b47",
                "authors": [
                    "Victor Sanh",
                    "Albert Webson",
                    "Colin Raffel",
                    "Stephen Bach",
                    "Lintang Sutawika",
                    "Zaid Alyafeai",
                    "Antoine Chaffin",
                    "Arnaud Stiegler",
                    "Arun Raja",
                    "Manan Dey",
                    "Canwen Bari",
                    "Urmish Xu",
                    "Shanya Thakker",
                    "Eliza Sharma Sharma",
                    "Taewoon Szczechla",
                    "Gunjan Kim",
                    "Nihal Chhablani",
                    "Debajyoti Nayak",
                    "Jonathan Datta",
                    "Mike Chang",
                    " Tian-Jian",
                    "Han Jiang",
                    "Matteo Wang",
                    "Sheng Manica",
                    " Shen"
                ],
                "title": "Multitask prompted training enables zero-shot task generalization",
                "pub_date": "2022",
                "pub_title": "International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_106",
            "content": "Timo Schick, Hinrich Sch\u00fctze, Exploiting cloze-questions for few-shot text classification and natural language inference, 2021, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, .",
            "ntype": "ref",
            "meta": {
                "xid": "b48",
                "authors": [
                    "Timo Schick",
                    "Hinrich Sch\u00fctze"
                ],
                "title": "Exploiting cloze-questions for few-shot text classification and natural language inference",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_107",
            "content": "Timo Schick, Hinrich Sch\u00fctze, Few-shot text generation with natural language instructions, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b49",
                "authors": [
                    "Timo Schick",
                    "Hinrich Sch\u00fctze"
                ],
                "title": "Few-shot text generation with natural language instructions",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_108",
            "content": "Timo Schick, Hinrich Sch\u00fctze, It's not just size that matters: Small language models are also fewshot learners, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b50",
                "authors": [
                    "Timo Schick",
                    "Hinrich Sch\u00fctze"
                ],
                "title": "It's not just size that matters: Small language models are also fewshot learners",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_109",
            "content": "Sandeep Subramanian, Adam Trischler, Yoshua Bengio, Christopher Pal, Learning general purpose distributed sentence representations via large scale multi-task learning, 2018, International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b51",
                "authors": [
                    "Sandeep Subramanian",
                    "Adam Trischler",
                    "Yoshua Bengio",
                    "Christopher Pal"
                ],
                "title": "Learning general purpose distributed sentence representations via large scale multi-task learning",
                "pub_date": "2018",
                "pub_title": "International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_110",
            "content": "Elior Sulem, Jamaal Hay, Dan Roth, Yes, No or IDK: The challenge of unanswerable Yes/No questions, 2022, Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b52",
                "authors": [
                    "Elior Sulem",
                    "Jamaal Hay",
                    "Dan Roth"
                ],
                "title": "Yes, No or IDK: The challenge of unanswerable Yes/No questions",
                "pub_date": "2022",
                "pub_title": "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_111",
            "content": "James Thorne, Andreas Vlachos, Christos Christodoulopoulos, Arpit Mittal, FEVER: a large-scale dataset for fact extraction and VERification, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b53",
                "authors": [
                    "James Thorne",
                    "Andreas Vlachos",
                    "Christos Christodoulopoulos",
                    "Arpit Mittal"
                ],
                "title": "FEVER: a large-scale dataset for fact extraction and VERification",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_112",
            "content": "Masatoshi Tsuchiya, Performance impact caused by hidden bias of training data for recognizing textual entailment, 2018, Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018), .",
            "ntype": "ref",
            "meta": {
                "xid": "b54",
                "authors": [
                    "Masatoshi Tsuchiya"
                ],
                "title": "Performance impact caused by hidden bias of training data for recognizing textual entailment",
                "pub_date": "2018",
                "pub_title": "Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_113",
            "content": "David Wadden, Ulme Wennberg, Yi Luan, Hannaneh Hajishirzi, Entity, relation, and event extraction with contextualized span representations, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b55",
                "authors": [
                    "David Wadden",
                    "Ulme Wennberg",
                    "Yi Luan",
                    "Hannaneh Hajishirzi"
                ],
                "title": "Entity, relation, and event extraction with contextualized span representations",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_114",
            "content": "UNKNOWN, None, 2006, Ace 2005 multilingual training corpus. Linguistic Data Consortium, .",
            "ntype": "ref",
            "meta": {
                "xid": "b56",
                "authors": null,
                "title": null,
                "pub_date": "2006",
                "pub_title": "Ace 2005 multilingual training corpus. Linguistic Data Consortium",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_115",
            "content": "UNKNOWN, None, 2021, , .",
            "ntype": "ref",
            "meta": {
                "xid": "b57",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": null,
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_116",
            "content": "UNKNOWN, None, , , .",
            "ntype": "ref",
            "meta": {
                "xid": "b58",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": null,
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_117",
            "content": "Kaiwen Wei, Xian Sun, Zequn Zhang, Jingyuan Zhang, Guo Zhi, Li Jin, Trigger is not sufficient: Exploiting frame-aware knowledge for implicit event argument extraction, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b59",
                "authors": [
                    "Kaiwen Wei",
                    "Xian Sun",
                    "Zequn Zhang",
                    "Jingyuan Zhang",
                    "Guo Zhi",
                    "Li Jin"
                ],
                "title": "Trigger is not sufficient: Exploiting frame-aware knowledge for implicit event argument extraction",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "103-ARR_v2_118",
            "content": "Aaron Steven White, Pushpendre Rastogi, Kevin Duh, Benjamin Van Durme, Inference is everything: Recasting semantic resources into a unified evaluation framework, 2017, Proceedings of the Eighth International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b60",
                "authors": [
                    "Aaron Steven White",
                    "Pushpendre Rastogi",
                    "Kevin Duh",
                    "Benjamin Van Durme"
                ],
                "title": "Inference is everything: Recasting semantic resources into a unified evaluation framework",
                "pub_date": "2017",
                "pub_title": "Proceedings of the Eighth International Joint Conference on Natural Language Processing",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "103-ARR_v2_119",
            "content": "Adina Williams, Nikita Nangia, Samuel Bowman, A broad-coverage challenge corpus for sentence understanding through inference, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b61",
                "authors": [
                    "Adina Williams",
                    "Nikita Nangia",
                    "Samuel Bowman"
                ],
                "title": "A broad-coverage challenge corpus for sentence understanding through inference",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "103-ARR_v2_120",
            "content": "Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Clara Patrick Von Platen, Yacine Ma, Julien Jernite, Canwen Plu, Teven Xu, Sylvain Scao, Mariama Gugger, Quentin Drame, Alexander Lhoest,  Rush, Transformers: State-of-the-art natural language processing, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b62",
                "authors": [
                    "Thomas Wolf",
                    "Lysandre Debut",
                    "Victor Sanh",
                    "Julien Chaumond",
                    "Clement Delangue",
                    "Anthony Moi",
                    "Pierric Cistac",
                    "Tim Rault",
                    "Remi Louf",
                    "Morgan Funtowicz",
                    "Joe Davison",
                    "Sam Shleifer",
                    "Clara Patrick Von Platen",
                    "Yacine Ma",
                    "Julien Jernite",
                    "Canwen Plu",
                    "Teven Xu",
                    "Sylvain Scao",
                    "Mariama Gugger",
                    "Quentin Drame",
                    "Alexander Lhoest",
                    " Rush"
                ],
                "title": "Transformers: State-of-the-art natural language processing",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_121",
            "content": "Wenpeng Yin, Jamaal Hay, Dan Roth, Benchmarking zero-shot text classification: Datasets, evaluation and entailment approach, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b63",
                "authors": [
                    "Wenpeng Yin",
                    "Jamaal Hay",
                    "Dan Roth"
                ],
                "title": "Benchmarking zero-shot text classification: Datasets, evaluation and entailment approach",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_122",
            "content": "Wenpeng Yin, Dragomir Nazneen Fatema Rajani, Richard Radev, Caiming Socher,  Xiong, Universal natural language processing with limited annotations: Try few-shot textual entailment as a start, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b64",
                "authors": [
                    "Wenpeng Yin",
                    "Dragomir Nazneen Fatema Rajani",
                    "Richard Radev",
                    "Caiming Socher",
                    " Xiong"
                ],
                "title": "Universal natural language processing with limited annotations: Try few-shot textual entailment as a start",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "103-ARR_v2_123",
            "content": "Yuhao Zhang, Victor Zhong, Danqi Chen, Gabor Angeli, Christopher Manning, Position-aware attention and supervised data improve slot filling, 2017, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b65",
                "authors": [
                    "Yuhao Zhang",
                    "Victor Zhong",
                    "Danqi Chen",
                    "Gabor Angeli",
                    "Christopher Manning"
                ],
                "title": "Position-aware attention and supervised data improve slot filling",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "103-ARR_v2_124",
            "content": "UNKNOWN, None, 2021, An improved baseline for sentence-level relation extraction, .",
            "ntype": "ref",
            "meta": {
                "xid": "b66",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "An improved baseline for sentence-level relation extraction",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "103-ARR_v2_0@0",
            "content": "Textual Entailment for Event Argument Extraction: Zero-and Few-Shot with Multi-Source Learning",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_0",
            "start": 0,
            "end": 93,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_2@0",
            "content": "Recent work has shown that NLP tasks such as Relation Extraction (RE) can be recasted as Textual Entailment tasks using verbalizations, with strong performance in zero-shot and fewshot settings thanks to pre-trained entailment models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_2",
            "start": 0,
            "end": 233,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_2@1",
            "content": "The fact that relations in current RE datasets are easily verbalized casts doubts on whether entailment would be effective in more complex tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_2",
            "start": 235,
            "end": 379,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_2@2",
            "content": "In this work we show that entailment is also effective in Event Argument Extraction (EAE), reducing the need of manual annotation to 50% and 20% in ACE and WikiEvents respectively, while achieving the same performance as with full training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_2",
            "start": 381,
            "end": 620,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_2@3",
            "content": "More importantly, we show that recasting EAE as entailment alleviates the dependency on schemas, which has been a roadblock for transferring annotations between domains.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_2",
            "start": 622,
            "end": 790,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_2@4",
            "content": "Thanks to the entailment, the multi-source transfer between ACE and WikiEvents further reduces annotation down to 10% and 5% (respectively) of the full training without transfer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_2",
            "start": 792,
            "end": 969,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_2@5",
            "content": "Our analysis shows that the key to good results is the use of several entailment datasets to pre-train the entailment model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_2",
            "start": 971,
            "end": 1094,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_2@6",
            "content": "Similar to previous approaches, our method requires a small amount of effort for manual verbalization: only less than 15 minutes per event argument type is needed, and comparable results can be achieved with users with different level of expertise.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_2",
            "start": 1096,
            "end": 1343,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_4@0",
            "content": "Building Information Extraction (IE) systems for real-world applications is very costly and has suffered from data-scarcity problems, due in part to the expertise and time required to annotate training data at a large scale with sufficient consistency, but also due to poor transfer between domains: IE annotations depend on the schema used in each domain, and moving to new domains requires new schemas, new annotation guidelines and the manual annotation of new data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_4",
            "start": 0,
            "end": 468,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_4@1",
            "content": "In many cases, there is some information overlap between schemas, but performing transfer learning to leverage such overlap (i.e. learning from multiple sources) can be difficult: it often requires manually mapping labels between schemas, which is typically brittle, cumbersome and requires costly domain expertise (Kalfoglou and Schorlemmer, 2003).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_4",
            "start": 470,
            "end": 818,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_5@0",
            "content": "In order to save annotation effort, recent work recasts IE tasks as Textual Entailment tasks (White et al., 2017;Poliak et al., 2018a;Levy et al., 2017;. For instance, manually verbalize each relation type in the Relation Extraction (RE) dataset TACRED (Zhang et al., 2017) to generate hypotheses for each test example, and then apply an entailment model to output the relation type of the hypothesis with highest entailment probability.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_5",
            "start": 0,
            "end": 436,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_5@1",
            "content": "The entailment model is typically based on large language models pre-trained on entailment datasets such as MNLI (Williams et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_5",
            "start": 438,
            "end": 574,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_5@2",
            "content": "The approach obtains very strong results on zero-shot and few-shot scenarios, but we note that TACRED contains relations between two entities that are easily verbalizable, 1 casting doubts on whether entailment would be effective in more complex IE tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_5",
            "start": 576,
            "end": 830,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_5@3",
            "content": "Event Argument Extraction (EAE) involves more complex contexts, higher ambiguity in the words that trigger events, and depends on the event type in addition to the relation (see Figure 1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_5",
            "start": 832,
            "end": 1019,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_6@0",
            "content": "In this work, we present the first system for EAE that addresses the task as an entailment problem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_6",
            "start": 0,
            "end": 98,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_6@1",
            "content": "We empirically show the robustness of the method on the zero-shot, few-shot and full training regimes, obtaining state-of-the-art results on ACE (Walker et al., 2006) and WikiEvents .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_6",
            "start": 100,
            "end": 282,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_6@2",
            "content": "In addition, we make the following contributions:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_6",
            "start": 284,
            "end": 332,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_7@0",
            "content": "(1) We show that our method reduces schema dependency, as it improves the performance on the WikiEvents results using additional ACE training data and vice versa with no extra manual work.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_7",
            "start": 0,
            "end": 187,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_7@1",
            "content": "(2) Ablation results show that training with several NLI datasets is significantly better than just using MNLI.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_7",
            "start": 189,
            "end": 299,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_8@0",
            "content": "(3) Our analysis of the manual work required for writing templates and annotating arguments sheds light in the sweet spot for future applications, and shows that template writing does not require much domain expertise as shown by the results using an independent novice template writer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_8",
            "start": 0,
            "end": 285,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_8@1",
            "content": "We make the code, templates and models publicly available.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_8",
            "start": 287,
            "end": 344,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_8@2",
            "content": "2",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_8",
            "start": 346,
            "end": 346,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_9@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_9",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_10@0",
            "content": "Textual Entailment Given a textual premise and a hypothesis, the task is to decide whether the premise entails or contradicts (or is neutral to) the hypothesis (Dagan et al., 2006).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_10",
            "start": 0,
            "end": 180,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_10@1",
            "content": "The current stateof-the-art uses large pre-trained Language Models (LM) (Lan et al., 2020;Liu et al., 2019;Conneau et al., 2020;Lewis et al., 2020;He et al., 2021) fine-tuned on manually annotated datasets such as SNLI (Bowman et al., 2015), MNLI (Williams et al., 2018), FEVER (Thorne et al., 2018) or ANLI (Nie et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_10",
            "start": 182,
            "end": 508,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_10@2",
            "content": "The task is also known as Natural Language Inference (NLI).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_10",
            "start": 510,
            "end": 568,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_11@0",
            "content": "Prompt and Pivot task based learning has emerged as a candidate solution for data-scarcity problems (Le Scao and Rush, 2021;Min et al., 2021;Liu et al., 2021a).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_11",
            "start": 0,
            "end": 159,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_11@1",
            "content": "The use of discrete Schick and Sch\u00fctze, 2021a,b,c) or continuous (Liu et al., 2021b) prompts allowed language models to perform significantly better on many text classification tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_11",
            "start": 161,
            "end": 343,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_11@2",
            "content": "Closely related to our approach, several works make use of a highresource supervised task such as Question Answering or entailment as pivot tasks (Yin et al., 2019(Yin et al., , 2020Wang et al., 2021;Sainz and Rigau, 2021;McCann et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_11",
            "start": 345,
            "end": 587,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_11@3",
            "content": "In the case of entailment, Dagan et al. (2006) converted QA data to entailment manually and Demszky et al. (2018) did it automatically.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_11",
            "start": 589,
            "end": 723,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_11@4",
            "content": "Other semantic tasks such as Named Entity Recognition, Relation Extraction and Semantic Role Labelling have also been reformulated as entailment by automatically converting data into the entailment format (White et al., 2017;Poliak et al., 2018a;Levy et al., 2017;.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_11",
            "start": 725,
            "end": 989,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_12@0",
            "content": "Multi-task learning reformulates multiple tasks to a single and common task via prompting large pre-trained language models, leveraging multiple data sources to improve each task of interest.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_12",
            "start": 0,
            "end": 190,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_12@1",
            "content": "Such approaches have shown improvements in supervised (Subramanian et al., 2018;Raffel et al., 2020;Aribandi et al., 2022) and zero-shot scenarios (Sanh et al., 2022;Wei et al., 2021a).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_12",
            "start": 192,
            "end": 376,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_12@2",
            "content": "While using the language modelling task as a pivot shows strong performance with very large language models, it is not clear that smaller models can benefit from this strategy in the same way.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_12",
            "start": 378,
            "end": 569,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_12@3",
            "content": "Wei et al. (2021a) and Mishra et al. (2022) obtained contradictory results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_12",
            "start": 571,
            "end": 645,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_12@4",
            "content": "In a similar way, Question Answering has been proposed as a pivot task for multi-task learning but without promising results (McCann et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_12",
            "start": 647,
            "end": 793,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_12@5",
            "content": "In this work, we explore multi-source learning, where datasets from different or similar tasks are used to build a model for the target task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_12",
            "start": 795,
            "end": 935,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_13@0",
            "content": "Event Argument Extraction is a sub-task of Event Extraction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_13",
            "start": 0,
            "end": 59,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_13@1",
            "content": "The goal is to identify arguments or fillers for a specific slot (a.k.a., role) in an event template.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_13",
            "start": 61,
            "end": 161,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_13@2",
            "content": "This task has been largely explored on the Message Understanding Conference (MUC, Grishman and Sundheim (1996)) and later on Automatic Content Evaluation (ACE).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_13",
            "start": 163,
            "end": 322,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_13@3",
            "content": "ACE focused mainly on sentence level evaluation due to the difficulty of the task at the time.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_13",
            "start": 324,
            "end": 417,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_13@4",
            "content": "Recently, new benchmarks such as RAMS and WikiEvents have emerged with the aim of addressing document level information extraction similar to MUC.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_13",
            "start": 419,
            "end": 564,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_13@5",
            "content": "However, most of the interest is still focused on the sentence level.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_13",
            "start": 566,
            "end": 634,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_14@0",
            "content": "EAE has been recently addressed by end-to-end event extraction models (Wadden et al., 2019;Lin et al., 2020;Li et al., 2021a), instead of treating it as an independent task (Du and Cardie, 2020a), as we do, or as a subtask in a pipeline (Lyu et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_14",
            "start": 0,
            "end": 255,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_14@1",
            "content": "Lately, with the recent paradigm shift to prompt design learning (Min et al., 2021), several works reformulated the task as a Question Answering problem Feng et al., 2020;Du and Cardie, 2020b;Wei et al., 2021b;Lyu et al., 2021;Sulem et al., 2022) or as a Constrained Text Generation problem Du et al., 2021; using predefined prompts, questions or templates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_14",
            "start": 257,
            "end": 613,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_14@2",
            "content": "We instead reformulate the task as a textual entailment problem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_14",
            "start": 615,
            "end": 678,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_15@0",
            "content": "Approach",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_15",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_16@0",
            "content": "In order to cast EAE as an entailment task, we verbalize event argument instances using a set of intuitive and linguistically motivated templates to capture the event argument roles, and then per-Figure 1: Entailment-based Event Argument Extraction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_16",
            "start": 0,
            "end": 248,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_16@1",
            "content": "On the left, input information: the context, the event trigger (hired) and the argument candidate (John D. Idol), alongside the types of both.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_16",
            "start": 250,
            "end": 391,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_16@2",
            "content": "On the middle, some hypothesis verbalized using the templates: the green box is entailed, the yellow box matches the type constraint but it is not entailed, and the rest do not satisfy type constraints.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_16",
            "start": 393,
            "end": 594,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_16@3",
            "content": "On the right, the output with the inferred role (Person).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_16",
            "start": 596,
            "end": 652,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_17@0",
            "content": "form inferences with entailment models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_17",
            "start": 0,
            "end": 38,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_17@1",
            "content": "The entailment model can be additionally trained with EAE training data converted into the entailment format, similar to .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_17",
            "start": 40,
            "end": 161,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_17@2",
            "content": "Figure 1 shows the general workflow of the method.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_17",
            "start": 163,
            "end": 212,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_17@3",
            "content": "First, the possible roles are verbalized by means of predefined templates and the input, which comprises the context, trigger and argument candidate.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_17",
            "start": 214,
            "end": 362,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_17@4",
            "content": "Then, an entailment model is used to generate the entailment probability for each verbalization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_17",
            "start": 364,
            "end": 459,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_17@5",
            "content": "To predict the role, the most probable hypothesis (verbalization) is chosen among the roles that satisfy the evententity 3 constraints.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_17",
            "start": 461,
            "end": 595,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_17@6",
            "content": "A more detailed description of each component follows.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_17",
            "start": 597,
            "end": 650,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_18@0",
            "content": "Label verbalization is attained using templates that combine the information of the instance and express a specific label.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_18",
            "start": 0,
            "end": 121,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_18@1",
            "content": "Different role verbalizations are shown in Figure 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_18",
            "start": 123,
            "end": 174,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_18@2",
            "content": "A verbalization is generated using templates that have been manually written based on the task guidelines of each dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_18",
            "start": 176,
            "end": 297,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_18@3",
            "content": "The templates involve the candidate argument, and optionally the event trigger.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_18",
            "start": 299,
            "end": 377,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_18@4",
            "content": "In some cases, in order to produce a grammatical hypothesis, placeholders corresponding to the agent or theme are also introduced, which can be generic, e.g. someone, or dependent of the argument role, e.g. defendant.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_18",
            "start": 379,
            "end": 595,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_19@0",
            "content": "We defined several template types (see Table 1) to guide the creation of templates more systematically.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_19",
            "start": 0,
            "end": 102,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_19@1",
            "content": "In Section 5.1 we describe the process to create templates, and in Section 7 we analyse the differences between independent template developers and how this did not affect performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_19",
            "start": 104,
            "end": 287,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_19@2",
            "content": "The templates created for the ACE dataset are listed in Appendix C.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_19",
            "start": 289,
            "end": 355,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_20@0",
            "content": "Entailment model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_20",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_20@1",
            "content": "Given a premise and hypothesis, the model returns the probabilities of the hypothesis being entailed by, contradicted to or neutral to the premise.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_20",
            "start": 18,
            "end": 164,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_20@2",
            "content": "In principle, any model trained on the NLI task can be used.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_20",
            "start": 166,
            "end": 225,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_21@0",
            "content": "Inference takes into account three key factors to output the role label for an argument candidate: the entailment probabilities of each verbalization, the type constraints of the specific role, and a threshold.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_21",
            "start": 0,
            "end": 209,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_21@1",
            "content": "Argument candidates which do not match the type constraints are discarded.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_21",
            "start": 211,
            "end": 284,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_21@2",
            "content": "From the rest, we return the role of the verbalized hypothesis with highest entailment probability, unless the probability is lower than the threshold, in which case we return the negative class.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_21",
            "start": 286,
            "end": 480,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_21@3",
            "content": "4 Training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_21",
            "start": 482,
            "end": 492,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_21@4",
            "content": "Our entailment-based model can be applied without any training on the EAE task, in a zero-shot fashion, or, alternatively, the entailment model can be finetuned using training data from the EAE dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_21",
            "start": 494,
            "end": 695,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_21@5",
            "content": "For this purpose, we convert the EAE training dataset into a NLI format, i.e we generate entailment, neutral and contradiction hypotheses heuristically from the data using the templates themselves.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_21",
            "start": 697,
            "end": 893,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_21@6",
            "content": "For each positive labeled example (a candidate that is an argument) we sample N E entailment hypotheses using the templates that correspond to the correct label and N N neutral hypotheses using templates from different roles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_21",
            "start": 895,
            "end": 1119,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_21@7",
            "content": "For each negative example (the candidate is not an argument of the event) we create N C contradiction hypotheses using any template at random.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_21",
            "start": 1121,
            "end": 1262,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_21@8",
            "content": "The {arg} inspected something.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_21",
            "start": 1264,
            "end": 1293,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_22@0",
            "content": "Table 1: The four main template categories used to create the role verbalizations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_22",
            "start": 0,
            "end": 81,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_23@0",
            "content": "Entailment for Multi-source Learning",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_23",
            "start": 0,
            "end": 35,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_24@0",
            "content": "We hypothesize that two similar IE tasks can benefit from each other even if they do not share the same schema or domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_24",
            "start": 0,
            "end": 120,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_24@1",
            "content": "Although this hypothesis is very intuitive and it has been demonstrated on several works for tasks other than IE (see Multitask learning on Section 2), actual IE models are limited by schema dependency, which makes it almost impossible to learn from datasets annotated with different IE schemas.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_24",
            "start": 122,
            "end": 416,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_24@2",
            "content": "One option is to perform a manual mapping between schemas, which is costly and often inaccurate (Kalfoglou and Schorlemmer, 2003).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_24",
            "start": 418,
            "end": 547,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_24@3",
            "content": "Our approach instead is domain and schema agnostic, and therefore allows to learning from multiple sources seamlessly.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_24",
            "start": 549,
            "end": 666,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_24@4",
            "content": "Given that the sources are recast into a single format in a common entailment formulation, it suffices to fine-tune the model in sequence across the sources.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_24",
            "start": 668,
            "end": 824,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_25@0",
            "content": "To check our hypothesis we split tasks according to the following criteria: (1) IE sources like Relation Extraction that are different from EAE (e.g. TACRED), and (2) EAE sources using different schemas (e.g. WikiEvents and ACE).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_25",
            "start": 0,
            "end": 228,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_25@1",
            "content": "Figure 2 summarizes the tasks and datasets used in this work, including the four natural language understanding datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_25",
            "start": 230,
            "end": 350,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_26@0",
            "content": "Experimental Setup",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_26",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_27@0",
            "content": "In this section, we describe the methodology for template development, evaluation setting, the baselines used in our experiments, and the computation infrastructure specifications.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_27",
            "start": 0,
            "end": 179,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_28@0",
            "content": "Methodology for verbalization",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_28",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_29@0",
            "content": "The templates used to generate the verbalizations were created based on the annotation guidelines of each dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_29",
            "start": 0,
            "end": 113,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_29@1",
            "content": "During the creation, the template developers had access to the guidelines that describe each of the roles (which can include one or two examples) and a NLI model that the developer could use to verify whether the generated verbalizations of these examples were entailed by the model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_29",
            "start": 115,
            "end": 397,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_29@2",
            "content": "The developer was allowed a maximum of 15 minutes per role, and spent 5 and 12 hours 5 to create the templates for ACE and WikiEvents respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_29",
            "start": 399,
            "end": 545,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_30@0",
            "content": "Evaluation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_30",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_31@0",
            "content": "Datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_31",
            "start": 0,
            "end": 8,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_31@1",
            "content": "We carried out our evaluation on two different EAE datasets: ACE (Walker et al., 2006) and WikiEvents Arabic texts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_31",
            "start": 10,
            "end": 124,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_31@2",
            "content": "We worked only on the English EAE task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_31",
            "start": 126,
            "end": 164,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_31@3",
            "content": "The WikiEvents dataset is instead more focused on document-level argument extraction task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_31",
            "start": 166,
            "end": 255,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_31@4",
            "content": "Although the last is intended to be use as a document-level benchmark we focused on the sentence-level extraction 6 for two reasons: to maintain consistency with ACE dataset and because the nearest occurrence of the arguments are inside the sentence of the event trigger in almost all examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_31",
            "start": 257,
            "end": 550,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_31@5",
            "content": "For both ACE and WikiEvents, we split the training data into different amounts (0%, 1%, 5%, 10%, 20% and 100%) following to also evaluate our system on extreme data scarcity scenarios.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_31",
            "start": 552,
            "end": 735,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_31@6",
            "content": "Table 2 shows the amount of examples per split.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_31",
            "start": 737,
            "end": 783,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_31@7",
            "content": "The total amount refers to the addition of all positives and negatives trigger-candidate pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_31",
            "start": 785,
            "end": 879,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_32@0",
            "content": "Metrics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_32",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_32@1",
            "content": "We have used the standard F1-Score, which is a common metric on IE tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_32",
            "start": 9,
            "end": 81,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_32@2",
            "content": "Along with that, we propose the use of the Area Under the Curve (AUC) for better model comparison across all scenarios.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_32",
            "start": 83,
            "end": 201,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_32@3",
            "content": "The reported AUC scores are computed with all splits for the main results and just with 0%, 5% and 100% for the multi-source results, and therefore, they are not comparable.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_32",
            "start": 203,
            "end": 375,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_33@0",
            "content": "Baselines and Models",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_33",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_34@0",
            "content": "Baselines.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_34",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_34@1",
            "content": "Our main point of comparison is our re-implementation of EM (Baldini Soares et al., 2019), as we can run it on the same few-shot splits as our system and allow for head-to-head comparison.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_34",
            "start": 11,
            "end": 198,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_34@2",
            "content": "EM is a state-of-the-art (Zhou and Chen, 2021) model that uses ROBERTA LARGE as a backbone.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_34",
            "start": 200,
            "end": 290,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_34@3",
            "content": "In addition we also report results of the state-of-the-art models that have been run on our same experimental setup, having access to gold event-trigger and entity annotations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_34",
            "start": 292,
            "end": 467,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_34@4",
            "content": "On ACE, we report the results of BERTEE and RCEE_ER, both reported at , which correspond to a BERT (Devlin et al., 2019) based baseline and a QA based pivot approach that leverages SQuAD (Rajpurkar et al., 2016) data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_34",
            "start": 469,
            "end": 685,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_34@5",
            "content": "Unfortunately the data splits used by are not available 7 and thus, only the results for zero-shot (i.e. 0% training data) and full training (i.e. 100% training data) are directly comparable.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_34",
            "start": 687,
            "end": 877,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_34@6",
            "content": "Regarding WikiEvents Gen-Arg uses gold triggers, but not gold entity information, so we decided to report Coref-F1 8 which refers to the F1-Score of predicting at least one of the gold entity coreferential chain as argument.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_34",
            "start": 879,
            "end": 1102,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_35@0",
            "content": "NLI models used in this work are based on the RoBERTa large (Liu et al., 2019) checkpoint, and are available via HuggingFace Transformer's model repository (Wolf et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_35",
            "start": 0,
            "end": 175,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_35@1",
            "content": "The main results use a model trained on all MNLI, SNLI, FEVER and ANLI, and in the analysis we also report the results of a model using just MNLI (see Appendix A for more information, including hyperparameters used).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_35",
            "start": 177,
            "end": 392,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_36@0",
            "content": "Infrastructure",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_36",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_37@0",
            "content": "All the experiments were done in a single RTX 2080ti (11Gb) with a 250W power consumption.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_37",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_37@1",
            "content": "The average training times are: 9 0.36h/epoch for ACE, 0.52h/epoch for WikiEvents and 2.86 h/epoch for TACRED.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_37",
            "start": 91,
            "end": 200,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_37@2",
            "content": "In total, 464.56 hours (154.86 if only a single run is done) of computation time are required to reproduce all the experiments, that in our setting corresponds to 21.36 kgCO 2 eq carbon footprint 10 (roughly equivalent to the CO 2 emitted by 88.2 km driven by an average car).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_37",
            "start": 202,
            "end": 477,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_38@0",
            "content": "Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_38",
            "start": 0,
            "end": 6,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_39@0",
            "content": "Main results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_39",
            "start": 0,
            "end": 12,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_39@1",
            "content": "system is the best in all cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_39",
            "start": 14,
            "end": 45,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_39@2",
            "content": "In both datasets the EM baseline is outperformed by the NLI system.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_39",
            "start": 47,
            "end": 113,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_40@0",
            "content": "Multi-source results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_40",
            "start": 0,
            "end": 20,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_40@1",
            "content": "Sequentially fine-tuning our NLI model in TA-CRED and then in our target task shows small improvements on low-resource scenarios (0% split for ACE, 0% and 5% splits for WikiEvents).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_40",
            "start": 22,
            "end": 202,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_40@2",
            "content": "Training on the three sources sequentially does not seem to yield further improvements.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_40",
            "start": 204,
            "end": 290,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_41@0",
            "content": "Figure 3 shows the performance of our NLI and multi-source enhanced NLI+ systems along with the EM baseline (data from Tables 3 and 4).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_41",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_41@1",
            "content": "The curves show that our NLI+ systems only need 10% and 5% of the data (on ACE and WikiEvents, respectively) to outperform the EM baseline that uses 100% of the training data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_41",
            "start": 136,
            "end": 310,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_42@0",
            "content": "Analysis",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_42",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_43@0",
            "content": "After performing the main experiments we did some additional analysis.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_43",
            "start": 0,
            "end": 69,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_44@0",
            "content": "A perfect NLI model should, in theory, solve any task that is framed correctly as entailment.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_44",
            "start": 0,
            "end": 92,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_44@1",
            "content": "Of course, there is not \"perfect\" NLI model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_44",
            "start": 94,
            "end": 137,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_44@2",
            "content": "In fact, current state-of-the-art NLI models tend to learn artifacts and lexical patterns (Gururangan et al., 2018;Poliak et al., 2018b;Tsuchiya, 2018;Glockner et al., 2018;Geva et al., 2019;McCoy et al., Table 5: Ablation on NLI datasets used to-pretrain our NLI model on three datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_44",
            "start": 139,
            "end": 426,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_44@3",
            "content": "NLI for our system using MNLI, FEVER, SNLI and ANLI (taken Table 3) and NLI MNLI only for our system when using MNLI only.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_44",
            "start": 428,
            "end": 549,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_45@0",
            "content": "2019) instead of the task itself.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_45",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_45@1",
            "content": "Motivated by these issues, datasets like ANLI (Nie et al., 2020) were adversarially created to alleviate them.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_45",
            "start": 34,
            "end": 143,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_45@2",
            "content": "The lack of robustness of NLI models gets amplified when it comes to a cross-task evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_45",
            "start": 145,
            "end": 237,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_45@3",
            "content": "For instance, the model trained on MNLI achieves 90.2 accuracy on MNLI and 31.4, 29.5 and 55.6 F1-Score on ACE, WikiEvents and TACRED respectively (cf. Table 5).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_45",
            "start": 239,
            "end": 399,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_45@4",
            "content": "Adding FEVER, SNLI and ANLI to the training improves MNLI accuracy only 0.8 points to 91.0, but zero-shot scores on ACE, WikiEvents and TACRED improve +9.2, +6.4 and +1.2 respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_45",
            "start": 401,
            "end": 584,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_45@5",
            "content": "In few-shot and full-training scenarios, the results also improve when using several NLI datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_45",
            "start": 586,
            "end": 683,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_45@6",
            "content": "Our results suggest that new, more challenging NLI datasets, as well as NLI datasets automatically generated from other sources (as done in this work with WikiEvents and ACE) will yield more robust entailment models, and could further increase the performance of entailment-based EAE and IE.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_45",
            "start": 685,
            "end": 975,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_45@7",
            "content": "The impact of different template developers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_45",
            "start": 977,
            "end": 1020,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_46@0",
            "content": "In order to test the robustness of the templates, we enrolled a linguist with experience in NLP annotation but no prior contact with the project nor access to the original templates from the main developer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_46",
            "start": 0,
            "end": 205,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_47@0",
            "content": "Under the same time and resource conditions, she was asked to write templates for the ACE dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_47",
            "start": 0,
            "end": 97,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_48@0",
            "content": "The templates written by the main developer and the linguist vary in different ways: (1) the number of created templates per role and (2) the verbalization style, as the main developer tended to use finite and conjugated verbs while the linguist tended to use infinitives and lemmas.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_48",
            "start": 0,
            "end": 282,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_48@1",
            "content": "The templates of both are available in Appendix C.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_48",
            "start": 284,
            "end": 333,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_49@0",
            "content": "To study the performance of the templates of each developer per role, Figure 4 shows the instances that a system correctly classified and the other system did not, and vice versa.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_49",
            "start": 0,
            "end": 178,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_49@1",
            "content": "The bars display the recall, as they are normalized by the frequencies of the roles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_49",
            "start": 180,
            "end": 263,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_49@2",
            "content": "Missing bars on a row means that both performed the same on that role (e.g. Seller).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_49",
            "start": 265,
            "end": 348,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_49@3",
            "content": "When only a blue bar is shown (e.g. Org) it means that the main developer recovered arguments which the linguist did not, and there were no examples where the linguist recovered arguments that the developer did not.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_49",
            "start": 350,
            "end": 564,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_49@4",
            "content": "The same applies to situations where there is only purple bars.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_49",
            "start": 566,
            "end": 628,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_49@5",
            "content": "Roles with mixed results include examples where one or the other succeeded.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_49",
            "start": 630,
            "end": 704,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_49@6",
            "content": "As we can see, the approaches seem to be complementary, with the linguist having a higher recall with the roles that are more associated with classical semantic roles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_49",
            "start": 706,
            "end": 872,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_49@7",
            "content": "Table 6 shows that in general, the templates of the linguist perform similarly to those of the main developer, except for 100% of the data, where the templates of the main developer were slightly better.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_49",
            "start": 874,
            "end": 1076,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_49@8",
            "content": "Verbalizations vs. annotations Finally, we carried out an experiment to compare the time and effort requirements of annotation vs. writing the templates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_49",
            "start": 1078,
            "end": 1230,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_49@9",
            "content": "To that end, the linguist re-annotated a small portion of ACE with the same information she had as she was creating the templates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_49",
            "start": 1232,
            "end": 1361,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_49@10",
            "content": "That is, given the argument candidates for each event trigger in the document, she needs to decide whether the candidate was an argument and the type of the argument.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_49",
            "start": 1363,
            "end": 1528,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_49@11",
            "content": "She has access to the guidelines (similar to creating the templates), though she did not study them beforehand.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_49",
            "start": 1530,
            "end": 1640,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_49@12",
            "content": "Note also that she did the annotations after writing the templates, so she was already familiar with the slots.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_49",
            "start": 1642,
            "end": 1752,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_49@13",
            "content": "Under these conditions, she annotated 46 pairs (event trigger, potential argument candidate) in 30 minutes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_49",
            "start": 1754,
            "end": 1860,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_49@14",
            "content": "Taking into account that ACE has 16.5000 such pairs, it would take approximately 180 hours to annotate ACE training part.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_49",
            "start": 1862,
            "end": 1982,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_49@15",
            "content": "Note that in practice, ACE requires much more time than our estimate to achieve the desired level of quality: the ACE annotation procedure involved double annotation and a second pass with a senior annotator (Doddington et al., 2004).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_49",
            "start": 1984,
            "end": 2217,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_49@16",
            "content": "For an analysis of the annotation procedure the interested reader is referred to Min and Grishman (2012).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_49",
            "start": 2219,
            "end": 2323,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_49@17",
            "content": "Based on our estimation, 9 hours would allow an annotator to annotate 5% of the dataset which yields a 37.5 F1 (Figure 5), while 5 hours of template building yields 40.6 F1-Score in the zero-shot setting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_49",
            "start": 2325,
            "end": 2528,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_49@18",
            "content": "With 18 hours 10% would be annotated and the F1-Score will be 50.9, while 5 hours of template building and 9 hours of annotations would yield 57.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_49",
            "start": 2530,
            "end": 2674,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_49@19",
            "content": "Figure 5 plots the performance according to manual hours on ACE, showing the huge gains provided by the initial 5 hours writing templates, plus the reuse of WikiEvents annotations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_49",
            "start": 2676,
            "end": 2855,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_49@20",
            "content": "According to our experience, more hours on template building does not necessarily lead to improvements (contrary to annotation), so a sweet spot for time investment seems to be to firstly create templates, and then spend the remaining budget on annotating examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_49",
            "start": 2857,
            "end": 3121,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_50@0",
            "content": "On another note, the linguist mentioned that writing templates is more natural and rewarding than annotating examples, which is more repetitive, stressful and tiresome.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_50",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_50@1",
            "content": "When writing templates, she was thinking in an abstract manner, trying to find generalizations, while she was paying attention to concrete cases when doing annotation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_50",
            "start": 169,
            "end": 335,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_51@0",
            "content": "Conclusions",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_51",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_52@0",
            "content": "This paper shows the entailment-based approach for event argument extraction is extremely effective in zero-shot, few-shot and full train scenarios both on ACE and WikiEvents, outperforming previous methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_52",
            "start": 0,
            "end": 206,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_52@1",
            "content": "First of all, recasting EAE as an entailment task allows it to reuse annotations from different event schemas, achieving large gains when transferring annotations between ACE and WikiEvents, and also some gains in the zero-shot performance when transferring annotations from a relation extraction model such as TACRED.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_52",
            "start": 208,
            "end": 525,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_52@2",
            "content": "Secondly, we show that using additional training entailment datasets improves results significantly over just using MNLI, not only on EAE but also on TA-CRED.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_52",
            "start": 527,
            "end": 684,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_52@3",
            "content": "Thirdly, we show that the relatively short time spent writing manual templates is much more effective than the time spent on doing annotations, with a sweet spot where the annotation effort is split between the two, with large savings in manual labour.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_52",
            "start": 686,
            "end": 937,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_52@4",
            "content": "Lastly, we show that an independent linguist is able to write templates with comparable performance without any special training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_52",
            "start": 939,
            "end": 1067,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_52@5",
            "content": "We think that our results and analysis support the potential of entailment models for other NLP tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_52",
            "start": 1069,
            "end": 1170,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_53@0",
            "content": "Our work paves the way for a new paradigm for IE, where the expert defines the schema using natural language and directly runs those specifications, annotating a handful of examples in the process, and allowing for quick trial-and-error iterations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_53",
            "start": 0,
            "end": 247,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_53@1",
            "content": "Sainz et al. (2022) propose a user interface alongside this paradigm.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_53",
            "start": 249,
            "end": 317,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_53@2",
            "content": "More generally, inference capability could be extended, acquired and applied from other tasks, in a research avenue where entailment and task performance improve in tandem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_53",
            "start": 319,
            "end": 490,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_54@0",
            "content": "On this section we describe the hyperparameters we have used on our experiments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_54",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_54@1",
            "content": "All the hyperparameters optimized on this work were optimized for the 100% split with the batch-size fixed to 32, and used on the rest.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_54",
            "start": 81,
            "end": 215,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_54@2",
            "content": "The Table 7 describes the hyperparameters used on EM, NLI and NLI MNLI only variants, for the NLI+ the same hyperparameters as NLI were used.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_54",
            "start": 217,
            "end": 357,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_54@3",
            "content": "We have found that the same exact hyperparameters were the best on ACE, WikiEvents and TACRED datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_54",
            "start": 359,
            "end": 461,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_54@4",
            "content": "For the future, we plan to test new hyperparameter sets that uses bigger batch-sizes, as recent works (Aribandi et al., 2022) suggest to be optimal for multi-task and -source learning experiments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_54",
            "start": 463,
            "end": 658,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_54@5",
            "content": "The pre-trained NLI models used on this work can be downloaded from the HuggingFace Models repository: NLI MNLI only (roberta-large-mnli) and NLI (ynie/roberta-large-snli_mnli_ fever_anli_R1_R2_R3-nli).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_54",
            "start": 660,
            "end": 861,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_55@0",
            "content": "The fine-tuned models derived from this work will be uploaded to HuggingFace Models repository.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_55",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_55@1",
            "content": "Check the GitHub repository for updated information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_55",
            "start": 96,
            "end": 147,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_56@0",
            "content": "The Figure 6 shows the per role absolute improvement obtained by training on different tasks over the 0% NLI system.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_56",
            "start": 0,
            "end": 115,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_56@1",
            "content": "Overall, we can see that training on ACE or WikiEvents improves almost all the roles and training on TACRED improves some and some others do not.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_56",
            "start": 117,
            "end": 261,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_56@2",
            "content": "A result that was unexpected is that there are few roles on WikiEvents that after training on WikiEvents become worse in contrary to training on ACE.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_56",
            "start": 263,
            "end": 411,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_56@3",
            "content": "This could be explained by the differences among the frequency distributions that the train, development and test sets of WikiEvents has.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_56",
            "start": 413,
            "end": 549,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_56@4",
            "content": "Moreover, there are some roles on WikiEvents that decreases in all training scenarios, this suggests us that sequential fine-tuning might be not the best option for this type of multi-source learning and therefore further ways should be explored.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_56",
            "start": 551,
            "end": 796,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_57@0",
            "content": "The next table contains the templates written by both developers for the ACE arguments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_57",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_57@1",
            "content": "We follow the notation introduced in Section 5.1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_57",
            "start": 88,
            "end": 136,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_57@2",
            "content": "In addition, we also consider information from the event, such as the type on different granularity levels, including {trg_type} for the trigger type (e.g. Movement from Movement.Transport) and {trg_subtype} for the subtype of the trigger, e.g. Transport from Movement.Transport).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_57",
            "start": 138,
            "end": 417,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_58@0",
            "content": "Vamsi Aribandi, Yi Tay, Tal Schuster, Jinfeng Rao, Huaixiu Steven Zheng, Sanket Vaibhav Mehta, Honglei Zhuang, Q Vinh, Dara Tran, Jianmo Bahri, Jai Ni, Kai Gupta, Sebastian Hui, Donald Ruder,  Metzler, Ext5: Towards extreme multi-task scaling for transfer learning, 2022, International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_58",
            "start": 0,
            "end": 326,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_59@0",
            "content": "Livio Baldini, Nicholas Soares, Jeffrey Fitzgerald, Tom Ling,  Kwiatkowski, Matching the blanks: Distributional similarity for relation learning, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_59",
            "start": 0,
            "end": 282,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_60@0",
            "content": "R Samuel, Gabor Bowman, Christopher Angeli, Christopher Potts,  Manning, A large annotated corpus for learning natural language inference, 2015, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_60",
            "start": 0,
            "end": 233,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_61@0",
            "content": "Yunmo Chen, Tongfei Chen, Seth Ebner, Aaron White, Benjamin Van Durme, Reading the manual: Event extraction as definition comprehension, 2020, Proceedings of the Fourth Workshop on Structured Prediction for NLP, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_61",
            "start": 0,
            "end": 261,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_62@0",
            "content": "Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettlemoyer, Veselin Stoyanov, Unsupervised cross-lingual representation learning at scale, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_62",
            "start": 0,
            "end": 322,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_63@0",
            "content": "Oren Ido Dagan, Bernardo Glickman,  Magnini, The pascal recognising textual entailment challenge, 2006, Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment, Springer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_63",
            "start": 0,
            "end": 242,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_64@0",
            "content": "UNKNOWN, None, 2018, Transforming question answering datasets into natural language inference datasets, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_64",
            "start": 0,
            "end": 104,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_65@0",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_65",
            "start": 0,
            "end": 335,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_66@0",
            "content": "Alexis George R Doddington,  Mitchell, A Mark,  Przybocki, A Lance, Stephanie Ramshaw, Ralph Strassel,  Weischedel, The Automatic Content Extraction (ACE) Program Tasks, Data, and Evaluation, 2004, Language Resources and Evaluation Conference (LREC), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_66",
            "start": 0,
            "end": 251,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_67@0",
            "content": "UNKNOWN, None, 2020, Document-level event role filler extraction using multi-granularity contextualized encoding, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_67",
            "start": 0,
            "end": 114,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_68@0",
            "content": "Xinya Du, Claire Cardie, Event extraction by answering (almost) natural questions, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_68",
            "start": 0,
            "end": 234,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_69@0",
            "content": "Xinya Du, Alexander Rush, Claire Cardie, GRIT: Generative role-filler transformers for document-level event entity extraction, 2021, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_69",
            "start": 0,
            "end": 304,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_70@0",
            "content": "Seth Ebner, Patrick Xia, Ryan Culkin, Kyle Rawlins, Benjamin Van Durme, Multi-sentence argument linking, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_70",
            "start": 0,
            "end": 249,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_71@0",
            "content": "UNKNOWN, None, 2020, Probing and fine-tuning reading comprehension models for few-shot event extraction, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_71",
            "start": 0,
            "end": 105,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_72@0",
            "content": "Tianyu Gao, Adam Fisch, Danqi Chen, Making pre-trained language models better few-shot learners, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_72",
            "start": 0,
            "end": 278,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_73@0",
            "content": "Mor Geva, Yoav Goldberg, Jonathan Berant, Are we modeling the task or the annotator? an investigation of annotator bias in natural language understanding datasets, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_73",
            "start": 0,
            "end": 388,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_74@0",
            "content": "Max Glockner, Vered Shwartz, Yoav Goldberg, Breaking NLI systems with sentences that require simple lexical inferences, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_74",
            "start": 0,
            "end": 256,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_75@0",
            "content": "Ralph Grishman, Beth Sundheim, Message Understanding Conference-6: A brief history, 1996, The 16th International Conference on Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_75",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_76@0",
            "content": "Swabha Suchin Gururangan, Omer Swayamdipta, Roy Levy, Samuel Schwartz, Noah Bowman,  Smith, Annotation artifacts in natural language inference data, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_76",
            "start": 0,
            "end": 299,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_77@0",
            "content": "UNKNOWN, None, 2021, Deberta: Decoding-enhanced bert with disentangled attention, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_77",
            "start": 0,
            "end": 82,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_78@0",
            "content": "UNKNOWN, None, 2003, Ontology mapping: the state of the art. The knowledge engineering review, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_78",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_79@0",
            "content": "Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut, Albert: A lite bert for self-supervised learning of language representations, 2020, International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_79",
            "start": 0,
            "end": 228,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_80@0",
            "content": "Le Teven, Alexander Scao,  Rush, How many data points is a prompt worth, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_80",
            "start": 0,
            "end": 272,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_81@0",
            "content": "Omer Levy, Minjoon Seo, Eunsol Choi, Luke Zettlemoyer, Zero-shot relation extraction via reading comprehension, 2017, Proceedings of the 21st Conference on Computational Natural Language Learning, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_81",
            "start": 0,
            "end": 238,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_82@0",
            "content": "Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, Luke Zettlemoyer, BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_82",
            "start": 0,
            "end": 337,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_83@0",
            "content": "Fayuan Li, Weihua Peng, Yuguang Chen, Quan Wang, Lu Pan, Yajuan Lyu, Yong Zhu, Event extraction as multi-turn question answering, 2020, Findings of the Association for Computational Linguistics: EMNLP 2020, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_83",
            "start": 0,
            "end": 256,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_84@0",
            "content": "Manling Li, Sha Li, Zhenhailong Wang, Lifu Huang, Kyunghyun Cho, Heng Ji, Jiawei Han, Clare Voss, The future is not one-dimensional: Complex event schema induction by graph modeling for event prediction, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_84",
            "start": 0,
            "end": 339,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_85@0",
            "content": "Sha Li, Ji Heng, Jiawei Han, Documentlevel event argument extraction by conditional generation, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_85",
            "start": 0,
            "end": 295,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_86@0",
            "content": "Ying Lin, Heng Ji, Fei Huang, Lingfei Wu, A joint neural model for information extraction with global features, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_86",
            "start": 0,
            "end": 256,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_87@0",
            "content": "Jian Liu, Yubo Chen, Kang Liu, Wei Bi, Xiaojiang Liu, Event extraction as machine reading comprehension, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_87",
            "start": 0,
            "end": 256,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_88@0",
            "content": "UNKNOWN, None, 2021, Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_88",
            "start": 0,
            "end": 125,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_89@0",
            "content": "UNKNOWN, None, , Zhilin Yang, and Jie Tang. 2021b. P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_89",
            "start": 0,
            "end": 148,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_90@0",
            "content": "UNKNOWN, None, 2019, Roberta: A robustly optimized bert pretraining approach, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_90",
            "start": 0,
            "end": 78,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_91@0",
            "content": "Qing Lyu, Hongming Zhang, Elior Sulem, Dan Roth, Zero-shot event extraction via transfer learning: Challenges and insights, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_91",
            "start": 0,
            "end": 343,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_92@0",
            "content": "UNKNOWN, None, 2018, The natural language decathlon: Multitask learning as question answering, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_92",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_93@0",
            "content": "Tom Mccoy, Ellie Pavlick, Tal Linzen, Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_93",
            "start": 0,
            "end": 266,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_94@0",
            "content": "Bonan Min, Ralph Grishman, Compensating for Annotation Errors in Training a Relation Extractor, 2012, Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_94",
            "start": 0,
            "end": 211,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_95@0",
            "content": "UNKNOWN, None, 2021, Recent advances in natural language processing via large pre-trained language models: A survey, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_95",
            "start": 0,
            "end": 117,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_96@0",
            "content": "Swaroop Mishra, Daniel Khashabi, Chitta Baral, Hannaneh Hajishirzi, Cross-task generalization via natural language crowdsourcing instructions, 2022, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_96",
            "start": 0,
            "end": 279,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_97@0",
            "content": "Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, Douwe Kiela, Adversarial NLI: A new benchmark for natural language understanding, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_97",
            "start": 0,
            "end": 245,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_98@0",
            "content": "UNKNOWN, None, 2018, Towards a unified natural language inference framework to evaluate sentence representations, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_98",
            "start": 0,
            "end": 118,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_99@0",
            "content": "Adam Poliak, Jason Naradowsky, Aparajita Haldar, Rachel Rudinger, Benjamin Van Durme, Hypothesis only baselines in natural language inference, 2018, Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_99",
            "start": 0,
            "end": 274,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_100@0",
            "content": "Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter Liu, Exploring the limits of transfer learning with a unified text-to-text transformer, 2020, Journal of Machine Learning Research, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_100",
            "start": 0,
            "end": 246,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_101@0",
            "content": "Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang, SQuAD: 100,000+ questions for machine comprehension of text, 2016, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_101",
            "start": 0,
            "end": 259,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_102@0",
            "content": "Oscar Sainz, Oier Lopez De Lacalle, Gorka Labaka, Ander Barrena, Eneko Agirre, Label verbalization and entailment for effective zero and fewshot relation extraction, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_102",
            "start": 0,
            "end": 301,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_103@0",
            "content": "Oscar Sainz, Haoling Qiu, Oier Lopez De Lacalle, Agirre Eneko, Bonan Min, ZS4IE: A toolkit for zero-shot information extraction with simple verbalizations, 2022, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations, Online and, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_103",
            "start": 0,
            "end": 375,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_104@0",
            "content": "Oscar Sainz, German Rigau, Ask2Transformers: Zero-shot domain labelling with pretrained language models, 2021, Proceedings of the 11th Global Wordnet Conference, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_104",
            "start": 0,
            "end": 162,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_105@0",
            "content": "Victor Sanh, Albert Webson, Colin Raffel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, Canwen Bari, Urmish Xu, Shanya Thakker, Eliza Sharma Sharma, Taewoon Szczechla, Gunjan Kim, Nihal Chhablani, Debajyoti Nayak, Jonathan Datta, Mike Chang,  Tian-Jian, Han Jiang, Matteo Wang, Sheng Manica,  Shen, Multitask prompted training enables zero-shot task generalization, 2022, International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_105",
            "start": 0,
            "end": 483,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_106@0",
            "content": "Timo Schick, Hinrich Sch\u00fctze, Exploiting cloze-questions for few-shot text classification and natural language inference, 2021, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_106",
            "start": 0,
            "end": 250,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_107@0",
            "content": "Timo Schick, Hinrich Sch\u00fctze, Few-shot text generation with natural language instructions, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_107",
            "start": 0,
            "end": 226,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_108@0",
            "content": "Timo Schick, Hinrich Sch\u00fctze, It's not just size that matters: Small language models are also fewshot learners, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_108",
            "start": 0,
            "end": 311,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_109@0",
            "content": "Sandeep Subramanian, Adam Trischler, Yoshua Bengio, Christopher Pal, Learning general purpose distributed sentence representations via large scale multi-task learning, 2018, International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_109",
            "start": 0,
            "end": 228,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_110@0",
            "content": "Elior Sulem, Jamaal Hay, Dan Roth, Yes, No or IDK: The challenge of unanswerable Yes/No questions, 2022, Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_110",
            "start": 0,
            "end": 290,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_111@0",
            "content": "James Thorne, Andreas Vlachos, Christos Christodoulopoulos, Arpit Mittal, FEVER: a large-scale dataset for fact extraction and VERification, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_111",
            "start": 0,
            "end": 332,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_112@0",
            "content": "Masatoshi Tsuchiya, Performance impact caused by hidden bias of training data for recognizing textual entailment, 2018, Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_112",
            "start": 0,
            "end": 223,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_113@0",
            "content": "David Wadden, Ulme Wennberg, Yi Luan, Hannaneh Hajishirzi, Entity, relation, and event extraction with contextualized span representations, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_113",
            "start": 0,
            "end": 323,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_114@0",
            "content": "UNKNOWN, None, 2006, Ace 2005 multilingual training corpus. Linguistic Data Consortium, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_114",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_115@0",
            "content": "UNKNOWN, None, 2021, , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_115",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_116@0",
            "content": "UNKNOWN, None, , , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_116",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_117@0",
            "content": "Kaiwen Wei, Xian Sun, Zequn Zhang, Jingyuan Zhang, Guo Zhi, Li Jin, Trigger is not sufficient: Exploiting frame-aware knowledge for implicit event argument extraction, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_117",
            "start": 0,
            "end": 349,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_118@0",
            "content": "Aaron Steven White, Pushpendre Rastogi, Kevin Duh, Benjamin Van Durme, Inference is everything: Recasting semantic resources into a unified evaluation framework, 2017, Proceedings of the Eighth International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_118",
            "start": 0,
            "end": 268,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_119@0",
            "content": "Adina Williams, Nikita Nangia, Samuel Bowman, A broad-coverage challenge corpus for sentence understanding through inference, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_119",
            "start": 0,
            "end": 287,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_120@0",
            "content": "Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Clara Patrick Von Platen, Yacine Ma, Julien Jernite, Canwen Plu, Teven Xu, Sylvain Scao, Mariama Gugger, Quentin Drame, Alexander Lhoest,  Rush, Transformers: State-of-the-art natural language processing, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_120",
            "start": 0,
            "end": 536,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_121@0",
            "content": "Wenpeng Yin, Jamaal Hay, Dan Roth, Benchmarking zero-shot text classification: Datasets, evaluation and entailment approach, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_121",
            "start": 0,
            "end": 349,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_122@0",
            "content": "Wenpeng Yin, Dragomir Nazneen Fatema Rajani, Richard Radev, Caiming Socher,  Xiong, Universal natural language processing with limited annotations: Try few-shot textual entailment as a start, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_122",
            "start": 0,
            "end": 343,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_123@0",
            "content": "Yuhao Zhang, Victor Zhong, Danqi Chen, Gabor Angeli, Christopher Manning, Position-aware attention and supervised data improve slot filling, 2017, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_123",
            "start": 0,
            "end": 235,
            "label": {}
        },
        {
            "ix": "103-ARR_v2_124@0",
            "content": "UNKNOWN, None, 2021, An improved baseline for sentence-level relation extraction, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "103-ARR_v2_124",
            "start": 0,
            "end": 82,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "103-ARR_v2_0",
            "tgt_ix": "103-ARR_v2_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_0",
            "tgt_ix": "103-ARR_v2_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_1",
            "tgt_ix": "103-ARR_v2_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_1",
            "tgt_ix": "103-ARR_v2_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_0",
            "tgt_ix": "103-ARR_v2_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_2",
            "tgt_ix": "103-ARR_v2_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_4",
            "tgt_ix": "103-ARR_v2_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_5",
            "tgt_ix": "103-ARR_v2_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_6",
            "tgt_ix": "103-ARR_v2_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_7",
            "tgt_ix": "103-ARR_v2_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_3",
            "tgt_ix": "103-ARR_v2_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_3",
            "tgt_ix": "103-ARR_v2_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_3",
            "tgt_ix": "103-ARR_v2_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_3",
            "tgt_ix": "103-ARR_v2_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_3",
            "tgt_ix": "103-ARR_v2_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_3",
            "tgt_ix": "103-ARR_v2_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_0",
            "tgt_ix": "103-ARR_v2_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_8",
            "tgt_ix": "103-ARR_v2_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_10",
            "tgt_ix": "103-ARR_v2_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_11",
            "tgt_ix": "103-ARR_v2_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_12",
            "tgt_ix": "103-ARR_v2_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_13",
            "tgt_ix": "103-ARR_v2_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_9",
            "tgt_ix": "103-ARR_v2_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_9",
            "tgt_ix": "103-ARR_v2_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_9",
            "tgt_ix": "103-ARR_v2_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_9",
            "tgt_ix": "103-ARR_v2_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_9",
            "tgt_ix": "103-ARR_v2_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_9",
            "tgt_ix": "103-ARR_v2_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_0",
            "tgt_ix": "103-ARR_v2_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_14",
            "tgt_ix": "103-ARR_v2_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_16",
            "tgt_ix": "103-ARR_v2_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_17",
            "tgt_ix": "103-ARR_v2_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_18",
            "tgt_ix": "103-ARR_v2_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_19",
            "tgt_ix": "103-ARR_v2_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_20",
            "tgt_ix": "103-ARR_v2_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_21",
            "tgt_ix": "103-ARR_v2_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_15",
            "tgt_ix": "103-ARR_v2_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_15",
            "tgt_ix": "103-ARR_v2_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_15",
            "tgt_ix": "103-ARR_v2_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_15",
            "tgt_ix": "103-ARR_v2_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_15",
            "tgt_ix": "103-ARR_v2_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_15",
            "tgt_ix": "103-ARR_v2_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_15",
            "tgt_ix": "103-ARR_v2_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_15",
            "tgt_ix": "103-ARR_v2_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_0",
            "tgt_ix": "103-ARR_v2_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_22",
            "tgt_ix": "103-ARR_v2_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_24",
            "tgt_ix": "103-ARR_v2_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_23",
            "tgt_ix": "103-ARR_v2_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_23",
            "tgt_ix": "103-ARR_v2_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_23",
            "tgt_ix": "103-ARR_v2_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_0",
            "tgt_ix": "103-ARR_v2_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_25",
            "tgt_ix": "103-ARR_v2_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_26",
            "tgt_ix": "103-ARR_v2_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_26",
            "tgt_ix": "103-ARR_v2_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_26",
            "tgt_ix": "103-ARR_v2_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_27",
            "tgt_ix": "103-ARR_v2_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_28",
            "tgt_ix": "103-ARR_v2_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_28",
            "tgt_ix": "103-ARR_v2_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_26",
            "tgt_ix": "103-ARR_v2_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_29",
            "tgt_ix": "103-ARR_v2_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_31",
            "tgt_ix": "103-ARR_v2_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_30",
            "tgt_ix": "103-ARR_v2_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_30",
            "tgt_ix": "103-ARR_v2_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_30",
            "tgt_ix": "103-ARR_v2_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_26",
            "tgt_ix": "103-ARR_v2_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_32",
            "tgt_ix": "103-ARR_v2_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_34",
            "tgt_ix": "103-ARR_v2_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_33",
            "tgt_ix": "103-ARR_v2_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_33",
            "tgt_ix": "103-ARR_v2_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_33",
            "tgt_ix": "103-ARR_v2_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_26",
            "tgt_ix": "103-ARR_v2_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_35",
            "tgt_ix": "103-ARR_v2_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_36",
            "tgt_ix": "103-ARR_v2_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_36",
            "tgt_ix": "103-ARR_v2_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_0",
            "tgt_ix": "103-ARR_v2_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_37",
            "tgt_ix": "103-ARR_v2_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_39",
            "tgt_ix": "103-ARR_v2_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_40",
            "tgt_ix": "103-ARR_v2_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_38",
            "tgt_ix": "103-ARR_v2_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_38",
            "tgt_ix": "103-ARR_v2_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_38",
            "tgt_ix": "103-ARR_v2_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_38",
            "tgt_ix": "103-ARR_v2_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_0",
            "tgt_ix": "103-ARR_v2_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_41",
            "tgt_ix": "103-ARR_v2_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_42",
            "tgt_ix": "103-ARR_v2_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_42",
            "tgt_ix": "103-ARR_v2_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_44",
            "tgt_ix": "103-ARR_v2_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_45",
            "tgt_ix": "103-ARR_v2_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_46",
            "tgt_ix": "103-ARR_v2_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_47",
            "tgt_ix": "103-ARR_v2_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_48",
            "tgt_ix": "103-ARR_v2_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_49",
            "tgt_ix": "103-ARR_v2_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_42",
            "tgt_ix": "103-ARR_v2_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_42",
            "tgt_ix": "103-ARR_v2_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_42",
            "tgt_ix": "103-ARR_v2_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_42",
            "tgt_ix": "103-ARR_v2_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_42",
            "tgt_ix": "103-ARR_v2_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_42",
            "tgt_ix": "103-ARR_v2_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_42",
            "tgt_ix": "103-ARR_v2_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_43",
            "tgt_ix": "103-ARR_v2_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_0",
            "tgt_ix": "103-ARR_v2_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_50",
            "tgt_ix": "103-ARR_v2_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_52",
            "tgt_ix": "103-ARR_v2_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_51",
            "tgt_ix": "103-ARR_v2_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_51",
            "tgt_ix": "103-ARR_v2_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_51",
            "tgt_ix": "103-ARR_v2_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_54",
            "tgt_ix": "103-ARR_v2_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_51",
            "tgt_ix": "103-ARR_v2_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_51",
            "tgt_ix": "103-ARR_v2_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_53",
            "tgt_ix": "103-ARR_v2_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_51",
            "tgt_ix": "103-ARR_v2_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_55",
            "tgt_ix": "103-ARR_v2_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_51",
            "tgt_ix": "103-ARR_v2_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_56",
            "tgt_ix": "103-ARR_v2_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "103-ARR_v2_0",
            "tgt_ix": "103-ARR_v2_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_1",
            "tgt_ix": "103-ARR_v2_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_2",
            "tgt_ix": "103-ARR_v2_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_2",
            "tgt_ix": "103-ARR_v2_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_2",
            "tgt_ix": "103-ARR_v2_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_2",
            "tgt_ix": "103-ARR_v2_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_2",
            "tgt_ix": "103-ARR_v2_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_2",
            "tgt_ix": "103-ARR_v2_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_2",
            "tgt_ix": "103-ARR_v2_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_3",
            "tgt_ix": "103-ARR_v2_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_4",
            "tgt_ix": "103-ARR_v2_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_4",
            "tgt_ix": "103-ARR_v2_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_5",
            "tgt_ix": "103-ARR_v2_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_5",
            "tgt_ix": "103-ARR_v2_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_5",
            "tgt_ix": "103-ARR_v2_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_5",
            "tgt_ix": "103-ARR_v2_5@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_6",
            "tgt_ix": "103-ARR_v2_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_6",
            "tgt_ix": "103-ARR_v2_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_6",
            "tgt_ix": "103-ARR_v2_6@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_7",
            "tgt_ix": "103-ARR_v2_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_7",
            "tgt_ix": "103-ARR_v2_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_8",
            "tgt_ix": "103-ARR_v2_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_8",
            "tgt_ix": "103-ARR_v2_8@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_8",
            "tgt_ix": "103-ARR_v2_8@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_9",
            "tgt_ix": "103-ARR_v2_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_10",
            "tgt_ix": "103-ARR_v2_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_10",
            "tgt_ix": "103-ARR_v2_10@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_10",
            "tgt_ix": "103-ARR_v2_10@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_11",
            "tgt_ix": "103-ARR_v2_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_11",
            "tgt_ix": "103-ARR_v2_11@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_11",
            "tgt_ix": "103-ARR_v2_11@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_11",
            "tgt_ix": "103-ARR_v2_11@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_11",
            "tgt_ix": "103-ARR_v2_11@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_12",
            "tgt_ix": "103-ARR_v2_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_12",
            "tgt_ix": "103-ARR_v2_12@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_12",
            "tgt_ix": "103-ARR_v2_12@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_12",
            "tgt_ix": "103-ARR_v2_12@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_12",
            "tgt_ix": "103-ARR_v2_12@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_12",
            "tgt_ix": "103-ARR_v2_12@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_13",
            "tgt_ix": "103-ARR_v2_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_13",
            "tgt_ix": "103-ARR_v2_13@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_13",
            "tgt_ix": "103-ARR_v2_13@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_13",
            "tgt_ix": "103-ARR_v2_13@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_13",
            "tgt_ix": "103-ARR_v2_13@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_13",
            "tgt_ix": "103-ARR_v2_13@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_14",
            "tgt_ix": "103-ARR_v2_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_14",
            "tgt_ix": "103-ARR_v2_14@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_14",
            "tgt_ix": "103-ARR_v2_14@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_15",
            "tgt_ix": "103-ARR_v2_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_16",
            "tgt_ix": "103-ARR_v2_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_16",
            "tgt_ix": "103-ARR_v2_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_16",
            "tgt_ix": "103-ARR_v2_16@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_16",
            "tgt_ix": "103-ARR_v2_16@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_17",
            "tgt_ix": "103-ARR_v2_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_17",
            "tgt_ix": "103-ARR_v2_17@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_17",
            "tgt_ix": "103-ARR_v2_17@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_17",
            "tgt_ix": "103-ARR_v2_17@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_17",
            "tgt_ix": "103-ARR_v2_17@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_17",
            "tgt_ix": "103-ARR_v2_17@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_17",
            "tgt_ix": "103-ARR_v2_17@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_18",
            "tgt_ix": "103-ARR_v2_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_18",
            "tgt_ix": "103-ARR_v2_18@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_18",
            "tgt_ix": "103-ARR_v2_18@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_18",
            "tgt_ix": "103-ARR_v2_18@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_18",
            "tgt_ix": "103-ARR_v2_18@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_19",
            "tgt_ix": "103-ARR_v2_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_19",
            "tgt_ix": "103-ARR_v2_19@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_19",
            "tgt_ix": "103-ARR_v2_19@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_20",
            "tgt_ix": "103-ARR_v2_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_20",
            "tgt_ix": "103-ARR_v2_20@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_20",
            "tgt_ix": "103-ARR_v2_20@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_21",
            "tgt_ix": "103-ARR_v2_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_21",
            "tgt_ix": "103-ARR_v2_21@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_21",
            "tgt_ix": "103-ARR_v2_21@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_21",
            "tgt_ix": "103-ARR_v2_21@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_21",
            "tgt_ix": "103-ARR_v2_21@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_21",
            "tgt_ix": "103-ARR_v2_21@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_21",
            "tgt_ix": "103-ARR_v2_21@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_21",
            "tgt_ix": "103-ARR_v2_21@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_21",
            "tgt_ix": "103-ARR_v2_21@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_22",
            "tgt_ix": "103-ARR_v2_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_23",
            "tgt_ix": "103-ARR_v2_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_24",
            "tgt_ix": "103-ARR_v2_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_24",
            "tgt_ix": "103-ARR_v2_24@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_24",
            "tgt_ix": "103-ARR_v2_24@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_24",
            "tgt_ix": "103-ARR_v2_24@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_24",
            "tgt_ix": "103-ARR_v2_24@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_25",
            "tgt_ix": "103-ARR_v2_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_25",
            "tgt_ix": "103-ARR_v2_25@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_26",
            "tgt_ix": "103-ARR_v2_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_27",
            "tgt_ix": "103-ARR_v2_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_28",
            "tgt_ix": "103-ARR_v2_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_29",
            "tgt_ix": "103-ARR_v2_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_29",
            "tgt_ix": "103-ARR_v2_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_29",
            "tgt_ix": "103-ARR_v2_29@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_30",
            "tgt_ix": "103-ARR_v2_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_31",
            "tgt_ix": "103-ARR_v2_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_31",
            "tgt_ix": "103-ARR_v2_31@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_31",
            "tgt_ix": "103-ARR_v2_31@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_31",
            "tgt_ix": "103-ARR_v2_31@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_31",
            "tgt_ix": "103-ARR_v2_31@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_31",
            "tgt_ix": "103-ARR_v2_31@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_31",
            "tgt_ix": "103-ARR_v2_31@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_31",
            "tgt_ix": "103-ARR_v2_31@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_32",
            "tgt_ix": "103-ARR_v2_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_32",
            "tgt_ix": "103-ARR_v2_32@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_32",
            "tgt_ix": "103-ARR_v2_32@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_32",
            "tgt_ix": "103-ARR_v2_32@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_33",
            "tgt_ix": "103-ARR_v2_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_34",
            "tgt_ix": "103-ARR_v2_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_34",
            "tgt_ix": "103-ARR_v2_34@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_34",
            "tgt_ix": "103-ARR_v2_34@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_34",
            "tgt_ix": "103-ARR_v2_34@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_34",
            "tgt_ix": "103-ARR_v2_34@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_34",
            "tgt_ix": "103-ARR_v2_34@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_34",
            "tgt_ix": "103-ARR_v2_34@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_35",
            "tgt_ix": "103-ARR_v2_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_35",
            "tgt_ix": "103-ARR_v2_35@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_36",
            "tgt_ix": "103-ARR_v2_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_37",
            "tgt_ix": "103-ARR_v2_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_37",
            "tgt_ix": "103-ARR_v2_37@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_37",
            "tgt_ix": "103-ARR_v2_37@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_38",
            "tgt_ix": "103-ARR_v2_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_39",
            "tgt_ix": "103-ARR_v2_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_39",
            "tgt_ix": "103-ARR_v2_39@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_39",
            "tgt_ix": "103-ARR_v2_39@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_40",
            "tgt_ix": "103-ARR_v2_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_40",
            "tgt_ix": "103-ARR_v2_40@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_40",
            "tgt_ix": "103-ARR_v2_40@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_41",
            "tgt_ix": "103-ARR_v2_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_41",
            "tgt_ix": "103-ARR_v2_41@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_42",
            "tgt_ix": "103-ARR_v2_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_43",
            "tgt_ix": "103-ARR_v2_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_44",
            "tgt_ix": "103-ARR_v2_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_44",
            "tgt_ix": "103-ARR_v2_44@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_44",
            "tgt_ix": "103-ARR_v2_44@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_44",
            "tgt_ix": "103-ARR_v2_44@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_45",
            "tgt_ix": "103-ARR_v2_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_45",
            "tgt_ix": "103-ARR_v2_45@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_45",
            "tgt_ix": "103-ARR_v2_45@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_45",
            "tgt_ix": "103-ARR_v2_45@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_45",
            "tgt_ix": "103-ARR_v2_45@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_45",
            "tgt_ix": "103-ARR_v2_45@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_45",
            "tgt_ix": "103-ARR_v2_45@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_45",
            "tgt_ix": "103-ARR_v2_45@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_46",
            "tgt_ix": "103-ARR_v2_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_47",
            "tgt_ix": "103-ARR_v2_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_48",
            "tgt_ix": "103-ARR_v2_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_48",
            "tgt_ix": "103-ARR_v2_48@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_49",
            "tgt_ix": "103-ARR_v2_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_49",
            "tgt_ix": "103-ARR_v2_49@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_49",
            "tgt_ix": "103-ARR_v2_49@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_49",
            "tgt_ix": "103-ARR_v2_49@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_49",
            "tgt_ix": "103-ARR_v2_49@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_49",
            "tgt_ix": "103-ARR_v2_49@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_49",
            "tgt_ix": "103-ARR_v2_49@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_49",
            "tgt_ix": "103-ARR_v2_49@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_49",
            "tgt_ix": "103-ARR_v2_49@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_49",
            "tgt_ix": "103-ARR_v2_49@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_49",
            "tgt_ix": "103-ARR_v2_49@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_49",
            "tgt_ix": "103-ARR_v2_49@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_49",
            "tgt_ix": "103-ARR_v2_49@12",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_49",
            "tgt_ix": "103-ARR_v2_49@13",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_49",
            "tgt_ix": "103-ARR_v2_49@14",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_49",
            "tgt_ix": "103-ARR_v2_49@15",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_49",
            "tgt_ix": "103-ARR_v2_49@16",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_49",
            "tgt_ix": "103-ARR_v2_49@17",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_49",
            "tgt_ix": "103-ARR_v2_49@18",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_49",
            "tgt_ix": "103-ARR_v2_49@19",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_49",
            "tgt_ix": "103-ARR_v2_49@20",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_50",
            "tgt_ix": "103-ARR_v2_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_50",
            "tgt_ix": "103-ARR_v2_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_51",
            "tgt_ix": "103-ARR_v2_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_52",
            "tgt_ix": "103-ARR_v2_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_52",
            "tgt_ix": "103-ARR_v2_52@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_52",
            "tgt_ix": "103-ARR_v2_52@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_52",
            "tgt_ix": "103-ARR_v2_52@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_52",
            "tgt_ix": "103-ARR_v2_52@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_52",
            "tgt_ix": "103-ARR_v2_52@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_53",
            "tgt_ix": "103-ARR_v2_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_53",
            "tgt_ix": "103-ARR_v2_53@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_53",
            "tgt_ix": "103-ARR_v2_53@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_54",
            "tgt_ix": "103-ARR_v2_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_54",
            "tgt_ix": "103-ARR_v2_54@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_54",
            "tgt_ix": "103-ARR_v2_54@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_54",
            "tgt_ix": "103-ARR_v2_54@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_54",
            "tgt_ix": "103-ARR_v2_54@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_54",
            "tgt_ix": "103-ARR_v2_54@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_55",
            "tgt_ix": "103-ARR_v2_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_55",
            "tgt_ix": "103-ARR_v2_55@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_56",
            "tgt_ix": "103-ARR_v2_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_56",
            "tgt_ix": "103-ARR_v2_56@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_56",
            "tgt_ix": "103-ARR_v2_56@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_56",
            "tgt_ix": "103-ARR_v2_56@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_56",
            "tgt_ix": "103-ARR_v2_56@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_57",
            "tgt_ix": "103-ARR_v2_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_57",
            "tgt_ix": "103-ARR_v2_57@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_57",
            "tgt_ix": "103-ARR_v2_57@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_58",
            "tgt_ix": "103-ARR_v2_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_59",
            "tgt_ix": "103-ARR_v2_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_60",
            "tgt_ix": "103-ARR_v2_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_61",
            "tgt_ix": "103-ARR_v2_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_62",
            "tgt_ix": "103-ARR_v2_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_63",
            "tgt_ix": "103-ARR_v2_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_64",
            "tgt_ix": "103-ARR_v2_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_65",
            "tgt_ix": "103-ARR_v2_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_66",
            "tgt_ix": "103-ARR_v2_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_67",
            "tgt_ix": "103-ARR_v2_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_68",
            "tgt_ix": "103-ARR_v2_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_69",
            "tgt_ix": "103-ARR_v2_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_70",
            "tgt_ix": "103-ARR_v2_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_71",
            "tgt_ix": "103-ARR_v2_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_72",
            "tgt_ix": "103-ARR_v2_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_73",
            "tgt_ix": "103-ARR_v2_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_74",
            "tgt_ix": "103-ARR_v2_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_75",
            "tgt_ix": "103-ARR_v2_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_76",
            "tgt_ix": "103-ARR_v2_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_77",
            "tgt_ix": "103-ARR_v2_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_78",
            "tgt_ix": "103-ARR_v2_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_79",
            "tgt_ix": "103-ARR_v2_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_80",
            "tgt_ix": "103-ARR_v2_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_81",
            "tgt_ix": "103-ARR_v2_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_82",
            "tgt_ix": "103-ARR_v2_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_83",
            "tgt_ix": "103-ARR_v2_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_84",
            "tgt_ix": "103-ARR_v2_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_85",
            "tgt_ix": "103-ARR_v2_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_86",
            "tgt_ix": "103-ARR_v2_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_87",
            "tgt_ix": "103-ARR_v2_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_88",
            "tgt_ix": "103-ARR_v2_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_89",
            "tgt_ix": "103-ARR_v2_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_90",
            "tgt_ix": "103-ARR_v2_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_91",
            "tgt_ix": "103-ARR_v2_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_92",
            "tgt_ix": "103-ARR_v2_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_93",
            "tgt_ix": "103-ARR_v2_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_94",
            "tgt_ix": "103-ARR_v2_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_95",
            "tgt_ix": "103-ARR_v2_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_96",
            "tgt_ix": "103-ARR_v2_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_97",
            "tgt_ix": "103-ARR_v2_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_98",
            "tgt_ix": "103-ARR_v2_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_99",
            "tgt_ix": "103-ARR_v2_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_100",
            "tgt_ix": "103-ARR_v2_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_101",
            "tgt_ix": "103-ARR_v2_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_102",
            "tgt_ix": "103-ARR_v2_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_103",
            "tgt_ix": "103-ARR_v2_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_104",
            "tgt_ix": "103-ARR_v2_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_105",
            "tgt_ix": "103-ARR_v2_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_106",
            "tgt_ix": "103-ARR_v2_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_107",
            "tgt_ix": "103-ARR_v2_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_108",
            "tgt_ix": "103-ARR_v2_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_109",
            "tgt_ix": "103-ARR_v2_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_110",
            "tgt_ix": "103-ARR_v2_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_111",
            "tgt_ix": "103-ARR_v2_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_112",
            "tgt_ix": "103-ARR_v2_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_113",
            "tgt_ix": "103-ARR_v2_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_114",
            "tgt_ix": "103-ARR_v2_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_115",
            "tgt_ix": "103-ARR_v2_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_116",
            "tgt_ix": "103-ARR_v2_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_117",
            "tgt_ix": "103-ARR_v2_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_118",
            "tgt_ix": "103-ARR_v2_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_119",
            "tgt_ix": "103-ARR_v2_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_120",
            "tgt_ix": "103-ARR_v2_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_121",
            "tgt_ix": "103-ARR_v2_121@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_122",
            "tgt_ix": "103-ARR_v2_122@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_123",
            "tgt_ix": "103-ARR_v2_123@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "103-ARR_v2_124",
            "tgt_ix": "103-ARR_v2_124@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 836,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "doc_id": "103-ARR",
        "version": 2
    }
}