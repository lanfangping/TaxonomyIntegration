{
    "nodes": [
        {
            "ix": "414-ARR_v1_0",
            "content": "On Synthetic Data for Back Translation",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_2",
            "content": "Back translation (BT) is one of the most significant technologies in NMT research fields. Existing attempts on BT share a common characteristic: they employ either beam search or random sampling to generate synthetic data with a backward model but seldom work studies the role of synthetic data in the performance of BT. This motivates us to ask a fundamental question: what kind of synthetic data contributes to BT performance? Through both theoretical and empirical studies, we identify two key factors on synthetic data controlling the back-translation NMT performance, which are quality and importance. Furthermore, based on our findings, we propose a simple yet effective method to generate synthetic data to better trade off both factors so as to yield the better performance for BT. We run extensive experiments on WMT14 DE-EN, EN-DE, and RU-EN benchmark tasks. By employing our proposed method to generate synthetic data, our BT model significantly outperforms the standard BT baselines (i.e., beam and sampling based methods for data generation), which proves the effectiveness of our proposed methods.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "414-ARR_v1_4",
            "content": "Since the birth of neural machine translation (NMT) (Bahdanau et al., 2014;Sutskever et al., 2014) back translation (BT) (Sennrich et al., 2016a) has quickly become one of the most significant technologies in natural language processing (NLP) research field. This is because 1) it provides a simple yet effective approach to advance the supervised NMT by leveraging monolingual data (Edunov et al., 2018) and it also serves as a key learning objective in unsupervised NMT (Artetxe et al., 2017;Lample et al., 2018); 2) back-translation even plays a significant role in other NLP research fields beyond translation such as paraphrasing (Mallinson et al., 2017) and style transfer (Prabhumoye et al., 2018;Zhang et al., 2018).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_5",
            "content": "Back translation consists of two steps, namely synthetic corpus generation with a backward model and parameter optimization for the forward model. Various contributions have been made on improving back translation, for instance, iterative backtranslation (Hoang et al., 2018), tagged backtranslation (Caswell et al., 2019), confidence weighting , data diversification (Nguyen et al., 2020). Although these efforts differ in some aspects, all of them share a common characteristic: they employ a default way to generate synthetic data in the first step of BT which is either beam search or random sampling with a backward model. Seldom work studies the consequences of synthetic corpus to back-translation and hence it is unclear how synthetic data influences the final performance of BT.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_6",
            "content": "The early study empirically suggests the quality of the synthetic corpus is vital for BT performance (Sennrich et al., 2016a). However, recent studies illustrate better test performance can be achieved by low quality synthetic corpus (Edunov et al., 2018). This contradictory observation indicates the quality of synthetic data is not the only element that affects the BT performance. Hence, this fact naturally raises a fundamental question: what kind of synthetic data contributes to backtranslation performance?",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_7",
            "content": "Consequently, we attempt to exploit such a fundamental question in this paper. To this end, we start from a marginal objective, which is critical to semi-supervised learning, and derive an approximate lower bound of the objective function. Corresponding to this lower bound, we theoretically find two related elements for maximizing such a lower bound: quality of synthetic bilingual data and importance weight of its source. Since both elements are mutually exclusive in essence, it may induce contradictory observation if one judges the BT performance according to a single element. In addition, such a theoretical explanation is supported by our empirical experiments. Furthermore, based on our findings, we propose a new heuristic approach to generate synthetic data whose both elements are better balanced so as to yield improvements over both sampling and beam search based methods. Extensive experiments on three WMT14 tasks show that our BT consistently outperforms the standard sampling and beam search based baselines with a significant margin.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_8",
            "content": "Our contributions are three folds:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_9",
            "content": "1. We point it out that importance weight and quality of synthetic candidates are two key factors that affect the NMT performance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_10",
            "content": "2. We propose a simple yet effective method for synthetic corpus generation, which could better balance the quality and importance of synthetic data.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_11",
            "content": "3. Our experiments prove the effectiveness of aforementioned strategy, it outperforms beam or sampling decoding methods on three benchmark tasks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_12",
            "content": "Revisiting Back Translation",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "414-ARR_v1_13",
            "content": "NMT builds a probabilistic model p(y|x; \u03b8) with neural networks parameterized by \u03b8, which is used to translate a sentence x in source language X to a sentence y in target language Y. The standard wisdom to train the model is to minimize the following objective function over a given bilingual corpus B = {(x i , y i )}:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_14",
            "content": "\u2113(B; \u03b8) = (x i ,y i )\u2208B log p(y i |x i ; \u03b8)(1)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_15",
            "content": "Recently Sennrich et al. (2016a) propose a remarkable method called Back Translation (BT) to improve NMT by using a monolingual corpus M in target language Y besides B and back translation becomes one of the most successful techniques in NMT (Fadaee and Monz, 2018;Edunov et al., 2018). At the high level, back translation can be considered as a semi-supervised method because it leverages both labeled and unlabeled data. Suppose p(x|y; \u03c0) is the backward translation model whose parameter \u03c0 is optimized over B, the key idea of back translation can be summarized as the following two steps:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_16",
            "content": "To make BT more efficient, the standard configuration is widely adopted: each sentence y is required to generate a single source x and both two steps are performed for a single pass. We follow this standard in this paper for generality but our idea in this paper is straightforward to apply to other configurations such as (Gra\u00e7a et al., 2019;Hoang et al., 2018;Nguyen et al., 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_17",
            "content": "In the first step, there are two main strategies to generate the synthetic corpus, i.e., deterministically decoding and randomly sampling with p(x|y; \u03c0). The first strategy aims to search the best candidate as follows, xb = arg max p(x|y; \u03c0)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_18",
            "content": "(3)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_19",
            "content": "The above optimization is achieved by the beam search decoding, which can be regarded as a degenerated shortest path problem with respect to the log p(x|y; \u03c0) with limited routing attempts. The alternative strategy is random sampling: it randomly samples a token with respect to the distribution estimated by back-translation model at each decoding step. Such a process can be modelled by,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_20",
            "content": "xs = rand{p(x|y; \u03c0)}(4)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_21",
            "content": "Research Question Prior work points out (Sennrich et al., 2016a) that the synthetic corpus with high quality is beneficial to the final performance of back translation. However, the recent studies (Edunov et al., 2018) find that NMT models with unsatisfactory BLEU score corpus, for instance the corpus generated by sampling based strategy, also establish the state-of-the-art (SOTA) achievement among back-translation NMT models. This contradictory fact indicates that the quality of synthetic corpus is not the sole element for back translation. This motivates us to study a fundamental question for back translation: what kind of synthetic corpus is beneficial to back translation?",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_22",
            "content": "Understanding Synthetic Data by Two Factors",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "414-ARR_v1_23",
            "content": "To answer the fundamental question presented in the previous section, we first start from the marginal likelihood objective defined on the target language Y, and then we theoretically explain two factors (i.e., quality and importance) that are highly related to the training objective of back translation. Finally, we empirically explain why synthetic corpus with low quality may lead to better performance than synthetic corpus with high quality by measuring both factors.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_24",
            "content": "Theoretical Explanation",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "414-ARR_v1_25",
            "content": "Maximizing marginal likelihood is an important principle to leverage unlabeled data. Therefore, we rethink back translation from this principle because it makes use of target monolingual corpus M. For each y \u2208 M, the marginal likelihood objective can be derived by the Bayesian Equation Total Probability formula (5), Jansen Inequality (6), and importance sampling (7) as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_26",
            "content": "log p(y; \u03b8) = log x p(x)p(y|x; \u03b8)(5)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_27",
            "content": "where p(x) is a language model on source language X , p(x|y) is a backward translation model from Y to X which serves as the proposal distribution for importance sampling, and x is sampled from p(x|y). If p(x|y) is set as the backward model p(x|y; \u03c0) optimized on B, the last term in Equation 7is the same as the second term in BT loss (i.e., log p(y|x) in Eq. 2), and the unique difference is the multiplicative term called importance weight:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_28",
            "content": "Imp(x; y) = p(x) p(x|y)(8)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_29",
            "content": "The denominator is the candidate conditional probability to target, and the numerator is the candidate distribution on source language distribution. Since Imp(x; y) is constant with respect to the parameter \u03b8, maximizing log p(y|x; \u03b8) in BT loss implicitly maximizes Imp(x; y) log p(y|x), which indicates that back translation aims to implicitly maximize the marginal likelihood objective. More importantly, according to Equation 7we can find that the following two factors are critical to influence the marginal likelihood log p(y; \u03b8):",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_30",
            "content": "\u2022 Factor 1: The quality of x as a translation of y corresponding to the log p(y|x; \u03b8) in Eq. 7. \u2022 Factor 2: The importance of x as a translation of y corresponding to Imp(x; y) in Eq. 7.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_31",
            "content": "Theoretically, if x is of higher quality and contains more semantic information in y, p(y|x; \u03b8) would be higher and thus it would lead to a higher log p(y; \u03b8), which is well acknowledged by prior work (Sennrich et al., 2016a;.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_32",
            "content": "In particular, if x is with higher importance weight, maximizing log p(y|x; \u03b8) is more helpful to maximize log p(y; \u03b8). On the contrary, if Imp(x; y) is very small, it needs to avoid such a sample x from p(x|y), which is essentially the rejection control strategy in importance sampling theory (Liu et al., 1998;Liu and Liu, 2001). Unfortunately, in practice, both factors are mutually exclusive: if x is with high quality, p(x|y; \u03b8) would be higher as well leading to lower importance weight. This fact can explain the contradictory observation in Sec 2 that BT with high-quality synthetic data sometimes leads to better testing performance, while it may deliver worse performance at other times, which will be later justified in Sec 3.2.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_33",
            "content": "Estimating Two Factors To measure the quality of x for each y, it is natural to use the evaluation metric such as BLEU if the reference translation x of y is available. Otherwise, as a surrogate, we use the log likelihood log p(x|y; \u03c0) of the backward translation model \u03c0 which is trained on the authentic data B. Similarly, in order to estimate the importance of x, we train an additional language model p(x; \u03c9) with GPT (Radford et al.) on a large monolingual corpus for X . In this way, the importance weight is estimated by Imp(x) \u2248 p(x; \u03c9) p(x|y; \u03c0)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_34",
            "content": "Empirical Justification",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "414-ARR_v1_35",
            "content": "In this subsection, we aim to justify the following statements: 1) encouraging quality of synthetic corpus may to some extent hurt the performance of BT due to the decrease of importance; 2) judging the testing performance in terms of quality only may be dangerous while it would be meaningful to judge the testing performance by taking into account both factors rather than either factor. To this end, we run some quick experiments on WMT14 datasets whose settings will be shown in Sec 5 later. We set up two back translation systems with two different options (i.e., beam search and sampling) to generate synthetic corpus by using the best checkpoint of p(x|y; \u03c0) tuned on the development set. Both beam search and sampling based BT systems are denoted by beam and sampling. In addition, we pick another checkpoint of p(x|y; \u03c0) which is trained for only 1 epoch, and we use this weak checkpoint to set up another beam search based BT system, which is denoted as beam*. Table 1 shows BLEU on test dataset, the quality and importance on dev dataset according to three systems on WMT14 DE-EN task.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_36",
            "content": "In Table 1, beam is better than sampling in the quality of synthetic corpus but its testing performance is worse. This is meaningful because the former relies on the synthetic corpus with lower importance weight according to our theoretical explanation. In addition, when comparing beam with beam*, we can find that beam delivers better testing performance because its quality is better meanwhile its importance weight is almost similar to that of beam*. Table 2 consistently demonstrates that it is meaningless to take into account quality only when evaluating BT. These facts justify our statements and provide an answer to the fundamental question in section 2.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_37",
            "content": "Improving Synthetic Data for BT",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "414-ARR_v1_38",
            "content": "As shown in the previous section, both importance and quality of synthetic corpus are beneficial to the overall testing performance of back translation. It is a natural idea to promote both factors when generating synthetic corpus such that running BT on such corpus leads to better testing performance. However, this is difficult because both factors are mutually exclusive. In this section, we instead propose two methods (namely data manipulation and gamma score) to trade off both factors in the hope to yield better BT performance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_39",
            "content": "Data Manipulation",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "414-ARR_v1_40",
            "content": "Since the synthetic data in sampling based BT is of high importance yet low quality whereas the case for the synthetic data in beam search based BT is opposite, we propose a data manipulation method to trade off importance and quality by combining both synthetic datasets. Through balancing the ratio between beam and sampling based synthetic corpora, we expect to find an optimized beam/sampling ratio to further improve NMT model performance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_41",
            "content": "Specifically, we randomly shuffle M and divide it into two parts with the first part accounting for \u03b3 (0 < \u03b3 < 1); then we generate translations for the first part with beam search while generating translations for the second part with sampling. Formally, we use the following corpus M c as the synthetic corpus for BT:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_42",
            "content": "M c = {(x b i , y i ) k i=0 } \u222a {(x s j , y j ) |M| j=k } k =\u230a\u03b3|M|\u230b",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_43",
            "content": "Where xb denotes a translation of y generated by p(x|y; \u03c0) with beam search and xs is a translation with sampling, | \u2022 | means the size of the corpus, and \u03b3 is the combination ratio of beam and sampling synthetic corpora. By tuning \u03b3 here, one can modify the weightage for the number of beam and sampling sentences, to improve back-translation performance by training models on a combined synthetic corpus.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_44",
            "content": "Although this method is easy to implement, its limitation is obvious. Since each x is either from beam search or from sampling, the quality of M c is generally worse than that of beam search and its importance weight is generally worse than that of sampling. Consequently, we propose an alternative method in the next part of this section.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_45",
            "content": "Gamma Score",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "414-ARR_v1_46",
            "content": "The key idea to the alternative method is that it employs a score that balances both quality and importance to generate a translation x for each y \u2208 M. A natural choice of such a score is defined by the interpolation score as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_47",
            "content": "\u03b3 log Imp(x; \u03c9, \u03c0) + (1 \u2212 \u03b3) log p(x|y; \u03c0)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_48",
            "content": "where \u03b3 is used to trade off both factors as in corpus manipulation. With the help of this score, one may optimize the x through beam search whose interpolation score is the best among all possible translations of y \u2208 M. Unfortunately, such an implementation leads to limited performance in our preliminary experiments, due to two major challenges.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_49",
            "content": "On one hand, the estimations of quality and importance weight of x are not well calibrated, and in particular, quality and importance are mutually exclusive as mentioned before. As a result, beam search with the interpolation score over the exponential space can not guarantee a desirable translation x for each y. On the other hand, quality and importance weight of x are not at the same scale for different y, it is difficult to balance both factors with a fixed \u03b3 in the interpolation score for different y.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_50",
            "content": "To alleviate these issues, we propose a simple method as follows. Specifically, firstly, instead of beam search with the interpolation score, we simply utilize the backward translation p(x|y; \u03c0) to randomly sample a set of candidate translations which is denoted by A(y) = {x i } N i (N = 50 in this paper). 1 Then we pick a xj among A(y) according to the balancing score. Secondly, for each x, we normalize the log values of importance and quality of each candidate by its sequence length, then normalize these values with respect to all N candidates as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_51",
            "content": "F(x i ) = log F(x i ) /len(x i ) \u2212 \u00b5 F \u03c3 F (9)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_52",
            "content": "1 N -best decoding strategy with p(x|y; \u03c0) to generate N candidates may be another solution which remains as future work.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_53",
            "content": "where F is either importance weight or quality estimations, and",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_54",
            "content": "\u00b5 F = 1 N i log F(x i ) and \u03c3 F = i (log F (x i )\u2212\u00b5 F ) 2 N \u22121",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_55",
            "content": "are mean and variance of N sampled candidates with length normalized. Finally, the Gamma score is defined on the normalized values of importance and quality as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_56",
            "content": "\u0393(x i ; \u03c9, \u03c0) = exp \u03b3 \u0128mp(x i ; \u03c9, \u03c0) + (1 \u2212 \u03b3)p(x i |y, \u03c0) j exp \u03b3 \u0128mp(x j ; \u03c9, \u03c0) + (1 \u2212 \u03b3)p(x j |y, \u03c0)(10)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_57",
            "content": "where \u0128mp and p are the normalized log value of importance weight and backward translation model p(x|y, \u03c0) as defined in Equation 9.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_58",
            "content": "Once the gamma score in Equation 10 is computed, there are two methods to select x from A(y), which are deterministic and stochastic methods. For deterministic selection, we simply select the candidates with maximum gamma score among N translation candidates; and for sampling, we sample a candidate according to its gamma score distribution. These two methods are called gamma selection and gamma sampling in our experiments.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_59",
            "content": "Experiments",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "414-ARR_v1_60",
            "content": "Settings",
            "ntype": "title",
            "meta": {
                "section": "5.1"
            }
        },
        {
            "ix": "414-ARR_v1_61",
            "content": "We run all the experiments using WMT14 datasets with fairseq (Ott et al., 2019) framework. For dataset settings, we use all available bitext of WMT14 corpus without any filtering on sentence length or source/target length ratio, this will result in a 4.5 million parallel corpus. For back translation experiment, we use equal scale monolingual corpus randomly sampled from Newscrawl 2020 (Barrault et al., 2019) comprising 4.5 million monolingual sentences, thus total 9 million sentences are used. We tokenize the parallel corpus using Mose tokenizer (Koehn et al., 2007), and learn a source and target shared Byte-Pair-Encoding (BPE; Sennrich et al., 2016) with 32K types. We develop on new-stest2013 and report the results on newstest2014.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_62",
            "content": "As for model architecture, we employ all the translation models using architecture transformer_wmt_en_de_big, which is a Big Transformer architecture with 6 blocks in the encoder and decoder, under the fairseq (Ott et al., 2019) feed-forward layers, and dropout is set to 0.3 for all the experiments. And for monolingual models, we apply transformer_lm_gpt architecture (Radford et al.) on each side of WMT14 corpus.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_63",
            "content": "For baseline models, we train them for 400K updating steps, and train the models with backtranslation data for 1.6M updating steps. We save the checkpoints every 100k updating intervals, and only select the checkpoints with highest develop set performance. As for the backtranslation data, we use baseline models' checkpoints at 400K updating steps to generate default beam5 decoding and sampling decoding synthetic corpus without any penalty. For monolingual models, we only select the checkpoints with the best develop set performance. When tuning \u03b3 on dev sets for data manipulation methods we select it from {0, 1/4, 1/2, 3/4, 1} and the optimal is \u03b3 = 1/2. For the Gamma Score method, \u03b3 is tuned among {0.1, 0.2, 0.3, 0.4, 0.5} and it is set \u03b3 = 0.2 for all three tasks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_64",
            "content": "All the experiments are conducted using 8 Nvidia V100-32GB graphic cards without any gradient accumulation or bitext upsampling, and the results in this paper are measured in case-sensitive detokenized BLEU with SacreBLEU 2 by Post (2018).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_65",
            "content": "Main Results",
            "ntype": "title",
            "meta": {
                "section": "5.2"
            }
        },
        {
            "ix": "414-ARR_v1_66",
            "content": "Results on DE-EN Data Manipulation",
            "ntype": "title",
            "meta": {
                "section": "5.2.1"
            }
        },
        {
            "ix": "414-ARR_v1_67",
            "content": "We conduct two experiments to study the data manipulation for backtranslation NMT model performance using aforementioned corpus with and without authentic corpus. Gamma criterion based method outperform beam search based and sampling based back-translation NMT models. The result marked with * denotes that it is significantly better than sampling BT with p < 0.0010.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_68",
            "content": "Table 3 show the data manipulation results compared with baseline. Firstly, for synthetic corpus experiment, we find that even if only monolingual corpus is used, the performance of back-translation NMT model can still be significantly improved to 31.3 from 29.2 by sampling or 27.6 by beam, and it is only 0.7 lower than bitext baseline by BLEU score measure. Secondly, for the experiments with bitext, the best performance by data manipulation only helps the back-translation NMT model achieves almost the same performance with sampling BT. This means data manipulation methods cannot achieve a higher BLEU score than sampling or beam.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_69",
            "content": "Gamma Score In this paragraph, we conduct the experiments based on gamma score method. We conduct both of the methods in this experiment: we select the candidate with highest gamma score for the deterministic method whereas sample the candidate by gamma score distribution for the stochastic method.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_70",
            "content": "Once again, we use synthetic gamma corpus combined with bitext to train the back-translation NMT models on each corpus, the results are listed in 4. From the table, we can see that our proposed gamma sampling significantly outperforms the sampling based and beam search based backtranslation baselines by 0.9 and 2.3 BLEU scores in terms of SacreBLEU. And our two proposed gamma score based methods outperform data manipulation method as well.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_71",
            "content": "In the rest of the experiments, we report results for both gamma selection and gamma sampling as the proposed methods and their hyperparameter \u03b3 for other tasks is fixed to 0.2.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_72",
            "content": "Results on other Datasets",
            "ntype": "title",
            "meta": {
                "section": "5.3"
            }
        },
        {
            "ix": "414-ARR_v1_73",
            "content": "We conduct the experiments on WMT14 EN-DE and RU-EN for both gamma selection and gamma sampling as well, and table 5 shows that our proposed gamma based methods significantly outperform beam and sampling based back-translation methods on both en-de and ru-en translation for almost 1 and 0.4 BLEU score respectively.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_74",
            "content": "Discussion on Efficiency Since our method requires to run sampling with size of 50 to generate synthetic data, its efficiency is about 10x slower than that of beam BT with size of 5 and 50x slower than that of sampling BT with size 1. Luckily, because the bottleneck of BT is not the synthetic data generation but the parameter optimization on both synthetic and authentic data, our overall overhead is less than 0.5x slower than sampling BT. In addition, since decoding is very easy to be parallelized on GPU or CPU machines, the cost of decoding is not a serious issue for our method, which makes it possible to run our method on a large scale dataset.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_75",
            "content": "Analysis on Synthetic Corpus",
            "ntype": "title",
            "meta": {
                "section": "5.4"
            }
        },
        {
            "ix": "414-ARR_v1_76",
            "content": "In this subsection, we analyze the synthetic corpus of proposed gamma score methods on both sentence level and token level.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_77",
            "content": "Sentence Level We evaluate the back-translation synthetic source sentences by their sentence representations. We use the baseline model to generate the hidden representations at the end-of-speech token as the sentence representation. Here, we compute the singular value spectrum of the representations for different back-translation corpora.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_78",
            "content": "3",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_79",
            "content": "The spectrum is shown in figure 1(a). From the spectrum, sampling has a more uniform distribution whereas beam has the worst variety. Our proposed methods have moderate variety between sampling and beam, and gamma sampling consists of higher linguistic information richness compared with gamma selection.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_80",
            "content": "Figure 1(b) shows the sequence length of the synthetic corpora of different generation methods. Beam generates the shortest synthetic sentences and gamma sampling generates the longest synthetic sentences on average. Between them, sampling and gamma selection generate almost the same sequence length, which means gamma selection candidates provide more learning signal than random sampling under the same length.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_81",
            "content": "3 Singular value spectrum analysis is a widely used method to measure the representation distribution. Gao et al. (2019) firstly introduces this method to measure the isotropy of representation, and directly employ spectrum control for better NMT performance. The idea is, representations of high linguistic variety usually are more isotropic, thus to have a relatively uniform singular value distribution. We employ this method here to measure the variety of sentence level information.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_82",
            "content": "Token Level Figure 1(c) is the token frequency histogram, which shows beam has higher probability to decode high frequency tokens while sampling prefers more low frequency tokens.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_83",
            "content": "We also measure the vocabulary size, finding that the proposed gamma sampling shares the same vocabulary size as sampling method. This could be the reason that gamma sampling is based on random sampling for candidates generation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_84",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "414-ARR_v1_85",
            "content": "This section describes prior arts in back-translation for NMT, data augmentation, and semi-supervised machine translation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_86",
            "content": "Back-translation NMT Bojar and Tamchyna (2011) firstly proposed back-translation, then Bertoldi and Federico (2009); Lambert et al. (2011) apply back translation to solve the domain adaptation problems in phrase-based NMT systems. Sennrich et al. (2016a) further extend the back translation for training NMT models integrally.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_87",
            "content": "For understanding the back-translation synthetic corpus, Currey et al. (2017) use a copy of target as a pseudo source , and find that NMT model performance can still be improved under the low resource settings. Caswell et al. (2019) propose tagged back-translation to indicate to the model that the given source is synthetic. To further find an optimum back-translation corpus decoding method, Imamura et al. (2018) firstly use sampling based synthetic corpus and find such a stochastic decoding method outperforms beam search on boosting NMT model performance, and Edunov et al. (2018) broaden the investigation of a number of backtranslation generation methods for synthetic source sentences. Their contribution shows that sampling or noisy synthetic data gives a much stronger training signal. Gra\u00e7a et al. (2019) reformulate backtranslation in the context of optimization and clarifying to improve sampling based decoding method search space, thus proposing N best list sampling. Recently, Nguyen et al. (2020) diversify the training data by multiple forward and backward models translations and combine them with the original datasets.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_88",
            "content": "Data Augmentation for NMT NMT researchers are the pioneers of data augmentation studies since back-translation is a natural type of data augmentation method. (Sennrich et al., 2016b;Norouzi et al., 2016;Zhang and Zong, 2016).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_89",
            "content": "To balance the token frequency in NMT corpus, Fadaee et al. (2017) create new sentences contain low-frequency words. However, as observed by , the improvement across different translation tasks is not consistent, and they invent SwitchOut data augmentation policy. Recht et al. (2018Recht et al. ( , 2019; Werpachowski et al. (2019) also observe such an inconsistency of variance between training corpus and testing set as well as in the generation tasks Recently, Li et al. (2019) try to understand data augmentation from input sensitivity and prediction margin, thus obtaining relatively low variance in generation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_90",
            "content": "Semi-supervised Machine Translation However, as high quality bitext is always limited and costly to collect, Gulcehre et al. (2015) study methods for effectively leveraging monolingual data in NMT systems. He et al. (2016) develop a duallearning mechanism, under such a learning objective, a NMT system is able to automatically learn from unlabeled data, thus improving NMT performance iteratively. Based on iterative learning, Lample et al. (2018) investigates how to learn NMT systems when only large monolingual corpora can be used in each language.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_91",
            "content": "For supervision of models, Gulcehre et al. (2017) employ the target language model hidden states into NMT decoder to further improve performance. Edunov et al. (2020) show that back-translation improves translation quality of both naturally occurring text and translationese according to professional human translators. For supervision of learning corpus, Wu et al. (2019) study both the source-side and target-side monolingual data for NMT.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_92",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "7"
            }
        },
        {
            "ix": "414-ARR_v1_93",
            "content": "In this work, we answer a fundamental question about synthetic data for back translation. We theoretically and empirically show two key factors namely quality and importance weight of synthetic data play an important role in back translation, and then we propose a new method to generate synthetic data which better balances both factors so as to boost the back-translation performance. For future work, we think it would be of significance to apply our synthetic data generation method to other BT methods or even to more broad NLP tasks such as paraphrasing and style transfer.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "414-ARR_v1_94",
            "content": "UNKNOWN, None, 2017, Unsupervised neural machine translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": "Unsupervised neural machine translation",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_95",
            "content": "UNKNOWN, None, 2014, Neural machine translation by jointly learning to align and translate, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": null,
                "title": null,
                "pub_date": "2014",
                "pub_title": "Neural machine translation by jointly learning to align and translate",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_96",
            "content": "Lo\u00efc Barrault, Ond\u0159ej Bojar, Marta Costa-Juss\u00e0, Christian Federmann, Mark Fishel, Yvette Graham, Barry Haddow, Matthias Huck, Philipp Koehn, Shervin Malmasi, Christof Monz, Mathias M\u00fcller, Findings of the 2019 conference on machine translation (WMT19), 2019, Proceedings of the Fourth Conference on Machine Translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "Lo\u00efc Barrault",
                    "Ond\u0159ej Bojar",
                    "Marta Costa-Juss\u00e0",
                    "Christian Federmann",
                    "Mark Fishel",
                    "Yvette Graham",
                    "Barry Haddow",
                    "Matthias Huck",
                    "Philipp Koehn",
                    "Shervin Malmasi",
                    "Christof Monz",
                    "Mathias M\u00fcller"
                ],
                "title": "Findings of the 2019 conference on machine translation (WMT19)",
                "pub_date": "2019",
                "pub_title": "Proceedings of the Fourth Conference on Machine Translation",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_97",
            "content": "Nicola Bertoldi, Marcello Federico, Domain adaptation for statistical machine translation with monolingual resources, 2009, Proceedings of the fourth workshop on statistical machine translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Nicola Bertoldi",
                    "Marcello Federico"
                ],
                "title": "Domain adaptation for statistical machine translation with monolingual resources",
                "pub_date": "2009",
                "pub_title": "Proceedings of the fourth workshop on statistical machine translation",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_98",
            "content": "Ond\u0159ej Bojar, Ale\u0161 Tamchyna, Improving translation model by monolingual data, 2011, Proceedings of the Sixth Workshop on Statistical Machine Translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Ond\u0159ej Bojar",
                    "Ale\u0161 Tamchyna"
                ],
                "title": "Improving translation model by monolingual data",
                "pub_date": "2011",
                "pub_title": "Proceedings of the Sixth Workshop on Statistical Machine Translation",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_99",
            "content": "Isaac Caswell, Ciprian Chelba, David Grangier, Tagged back-translation, 2019, Proceedings of the Fourth Conference on Machine Translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "Isaac Caswell",
                    "Ciprian Chelba",
                    "David Grangier"
                ],
                "title": "Tagged back-translation",
                "pub_date": "2019",
                "pub_title": "Proceedings of the Fourth Conference on Machine Translation",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_100",
            "content": "Anna Currey, Antonio Valerio Miceli-Barone, Kenneth Heafield, Copied monolingual data improves low-resource neural machine translation, 2017, Proceedings of the Second Conference on Machine Translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "Anna Currey",
                    "Antonio Valerio Miceli-Barone",
                    "Kenneth Heafield"
                ],
                "title": "Copied monolingual data improves low-resource neural machine translation",
                "pub_date": "2017",
                "pub_title": "Proceedings of the Second Conference on Machine Translation",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_101",
            "content": "Sergey Edunov, Myle Ott, Michael Auli, David Grangier, Understanding back-translation at scale, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Sergey Edunov",
                    "Myle Ott",
                    "Michael Auli",
                    "David Grangier"
                ],
                "title": "Understanding back-translation at scale",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_102",
            "content": "Sergey Edunov, Myle Ott, Marc'aurelio Ranzato, Michael Auli, On the evaluation of machine translation systems trained with back-translation, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Sergey Edunov",
                    "Myle Ott",
                    "Marc'aurelio Ranzato",
                    "Michael Auli"
                ],
                "title": "On the evaluation of machine translation systems trained with back-translation",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_103",
            "content": "Marzieh Fadaee, Arianna Bisazza, Christof Monz, Data augmentation for low-resource neural machine translation, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Short Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Marzieh Fadaee",
                    "Arianna Bisazza",
                    "Christof Monz"
                ],
                "title": "Data augmentation for low-resource neural machine translation",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Short Papers"
            }
        },
        {
            "ix": "414-ARR_v1_104",
            "content": "Marzieh Fadaee, Christof Monz, Backtranslation sampling by targeting difficult words in neural machine translation, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Marzieh Fadaee",
                    "Christof Monz"
                ],
                "title": "Backtranslation sampling by targeting difficult words in neural machine translation",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_105",
            "content": "Jun Gao, Di He, Xu Tan, Tao Qin, Liwei Wang, Tieyan Liu, Representation degeneration problem in training natural language generation models, 2019, International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Jun Gao",
                    "Di He",
                    "Xu Tan",
                    "Tao Qin",
                    "Liwei Wang",
                    "Tieyan Liu"
                ],
                "title": "Representation degeneration problem in training natural language generation models",
                "pub_date": "2019",
                "pub_title": "International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_106",
            "content": "Miguel Gra\u00e7a, Yunsu Kim, Julian Schamper, Shahram Khadivi, Hermann Ney, Generalizing back-translation in neural machine translation, 2019, Proceedings of the Fourth Conference on Machine Translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Miguel Gra\u00e7a",
                    "Yunsu Kim",
                    "Julian Schamper",
                    "Shahram Khadivi",
                    "Hermann Ney"
                ],
                "title": "Generalizing back-translation in neural machine translation",
                "pub_date": "2019",
                "pub_title": "Proceedings of the Fourth Conference on Machine Translation",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_107",
            "content": "UNKNOWN, None, 2015, On using monolingual corpora in neural machine translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": null,
                "title": null,
                "pub_date": "2015",
                "pub_title": "On using monolingual corpora in neural machine translation",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_108",
            "content": "Caglar Gulcehre, Orhan Firat, Kelvin Xu, Kyunghyun Cho, Yoshua Bengio, On integrating a language model into neural machine translation, 2017, Computer Speech & Language, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Caglar Gulcehre",
                    "Orhan Firat",
                    "Kelvin Xu",
                    "Kyunghyun Cho",
                    "Yoshua Bengio"
                ],
                "title": "On integrating a language model into neural machine translation",
                "pub_date": "2017",
                "pub_title": "Computer Speech & Language",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_109",
            "content": "Di He, Yingce Xia, Tao Qin, Liwei Wang, Nenghai Yu, Tie-Yan Liu, Wei-Ying Ma, Dual learning for machine translation, 2016, Advances in neural information processing systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Di He",
                    "Yingce Xia",
                    "Tao Qin",
                    "Liwei Wang",
                    "Nenghai Yu",
                    "Tie-Yan Liu",
                    "Wei-Ying Ma"
                ],
                "title": "Dual learning for machine translation",
                "pub_date": "2016",
                "pub_title": "Advances in neural information processing systems",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_110",
            "content": "Duy Vu Cong, Philipp Hoang, Gholamreza Koehn, Trevor Haffari,  Cohn, Iterative backtranslation for neural machine translation, 2018, Proceedings of the 2nd Workshop on Neural Machine Translation and Generation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "Duy Vu Cong",
                    "Philipp Hoang",
                    "Gholamreza Koehn",
                    "Trevor Haffari",
                    " Cohn"
                ],
                "title": "Iterative backtranslation for neural machine translation",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2nd Workshop on Neural Machine Translation and Generation",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_111",
            "content": "Kenji Imamura, Atsushi Fujita, Eiichiro Sumita, Enhancement of encoder and attention using target monolingual corpora in neural machine translation, 2018, Proceedings of the 2nd Workshop on Neural Machine Translation and Generation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Kenji Imamura",
                    "Atsushi Fujita",
                    "Eiichiro Sumita"
                ],
                "title": "Enhancement of encoder and attention using target monolingual corpora in neural machine translation",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2nd Workshop on Neural Machine Translation and Generation",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_112",
            "content": "P Diederik, Jimmy Kingma,  Ba, Adam: A method for stochastic optimization, 2015, ICLR (Poster), .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "P Diederik",
                    "Jimmy Kingma",
                    " Ba"
                ],
                "title": "Adam: A method for stochastic optimization",
                "pub_date": "2015",
                "pub_title": "ICLR (Poster)",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_113",
            "content": "Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ond\u0159ej Bojar, Alexandra Constantin, Evan Herbst, Moses: Open source toolkit for statistical machine translation, 2007, Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "Philipp Koehn",
                    "Hieu Hoang",
                    "Alexandra Birch",
                    "Chris Callison-Burch",
                    "Marcello Federico",
                    "Nicola Bertoldi",
                    "Brooke Cowan",
                    "Wade Shen",
                    "Christine Moran",
                    "Richard Zens",
                    "Chris Dyer",
                    "Ond\u0159ej Bojar",
                    "Alexandra Constantin",
                    "Evan Herbst"
                ],
                "title": "Moses: Open source toolkit for statistical machine translation",
                "pub_date": "2007",
                "pub_title": "Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "414-ARR_v1_114",
            "content": "Patrik Lambert, Holger Schwenk, Christophe Servan, Sadaf Abdul-Rauf, Investigations on translation model adaptation using monolingual data, 2011, Sixth Workshop on Statistical Machine Translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Patrik Lambert",
                    "Holger Schwenk",
                    "Christophe Servan",
                    "Sadaf Abdul-Rauf"
                ],
                "title": "Investigations on translation model adaptation using monolingual data",
                "pub_date": "2011",
                "pub_title": "Sixth Workshop on Statistical Machine Translation",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_115",
            "content": "UNKNOWN, None, 2018, Phrasebased & neural unsupervised machine translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Phrasebased & neural unsupervised machine translation",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_116",
            "content": "Guanlin Li, Lemao Liu, Guoping Huang, Conghui Zhu, Tiejun Zhao, Understanding data augmentation in neural machine translation: Two perspectives towards generalization, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Guanlin Li",
                    "Lemao Liu",
                    "Guoping Huang",
                    "Conghui Zhu",
                    "Tiejun Zhao"
                ],
                "title": "Understanding data augmentation in neural machine translation: Two perspectives towards generalization",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_117",
            "content": "S Jun, Rong Liu, Wing Hung Chen,  Wong, Rejection control and sequential importance sampling, 1998, Journal of the American Statistical Association, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "S Jun",
                    "Rong Liu",
                    "Wing Hung Chen",
                    " Wong"
                ],
                "title": "Rejection control and sequential importance sampling",
                "pub_date": "1998",
                "pub_title": "Journal of the American Statistical Association",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_118",
            "content": "UNKNOWN, None, 2001, Monte Carlo strategies in scientific computing, Springer.",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": null,
                "title": null,
                "pub_date": "2001",
                "pub_title": "Monte Carlo strategies in scientific computing",
                "pub": "Springer"
            }
        },
        {
            "ix": "414-ARR_v1_119",
            "content": "Jonathan Mallinson, Rico Sennrich, Mirella Lapata, Paraphrasing revisited with neural machine translation, 2017, Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Jonathan Mallinson",
                    "Rico Sennrich",
                    "Mirella Lapata"
                ],
                "title": "Paraphrasing revisited with neural machine translation",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_120",
            "content": "UNKNOWN, None, 2020, Data diversification: A simple strategy for neural machine translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Data diversification: A simple strategy for neural machine translation",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_121",
            "content": "Mohammad Norouzi, Samy Bengio, Navdeep Jaitly, Mike Schuster, Yonghui Wu, Dale Schuurmans, Reward augmented maximum likelihood for neural structured prediction, 2016, Advances In Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": [
                    "Mohammad Norouzi",
                    "Samy Bengio",
                    "Navdeep Jaitly",
                    "Mike Schuster",
                    "Yonghui Wu",
                    "Dale Schuurmans"
                ],
                "title": "Reward augmented maximum likelihood for neural structured prediction",
                "pub_date": "2016",
                "pub_title": "Advances In Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_122",
            "content": "Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, Michael Auli, fairseq: A fast, extensible toolkit for sequence modeling, 2019, Proceedings of NAACL-HLT 2019: Demonstrations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Myle Ott",
                    "Sergey Edunov",
                    "Alexei Baevski",
                    "Angela Fan",
                    "Sam Gross",
                    "Nathan Ng",
                    "David Grangier",
                    "Michael Auli"
                ],
                "title": "fairseq: A fast, extensible toolkit for sequence modeling",
                "pub_date": "2019",
                "pub_title": "Proceedings of NAACL-HLT 2019: Demonstrations",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_123",
            "content": "Matt Post, A call for clarity in reporting BLEU scores, 2018, Proceedings of the Third Conference on Machine Translation: Research Papers, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "Matt Post"
                ],
                "title": "A call for clarity in reporting BLEU scores",
                "pub_date": "2018",
                "pub_title": "Proceedings of the Third Conference on Machine Translation: Research Papers",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_124",
            "content": "UNKNOWN, None, 2018, Style transfer through back-translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Style transfer through back-translation",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_125",
            "content": "UNKNOWN, None, , , .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": null,
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_126",
            "content": "UNKNOWN, None, 2018, Do cifar-10 classifiers generalize to cifar-10? arXiv preprint, .",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Do cifar-10 classifiers generalize to cifar-10? arXiv preprint",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_127",
            "content": "Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, Vaishaal Shankar, Do imagenet classifiers generalize to imagenet, 2019, International Conference on Machine Learning, PMLR.",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": [
                    "Benjamin Recht",
                    "Rebecca Roelofs",
                    "Ludwig Schmidt",
                    "Vaishaal Shankar"
                ],
                "title": "Do imagenet classifiers generalize to imagenet",
                "pub_date": "2019",
                "pub_title": "International Conference on Machine Learning",
                "pub": "PMLR"
            }
        },
        {
            "ix": "414-ARR_v1_128",
            "content": "Rico Sennrich, Barry Haddow, Alexandra Birch, Improving neural machine translation models with monolingual data, 2016, Proceedings of the 54th, .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": [
                    "Rico Sennrich",
                    "Barry Haddow",
                    "Alexandra Birch"
                ],
                "title": "Improving neural machine translation models with monolingual data",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 54th",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_129",
            "content": "UNKNOWN, None, , Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_130",
            "content": "Rico Sennrich, Barry Haddow, Alexandra Birch, Improving neural machine translation models with monolingual data, 2016, Proceedings of the 54th, .",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "Rico Sennrich",
                    "Barry Haddow",
                    "Alexandra Birch"
                ],
                "title": "Improving neural machine translation models with monolingual data",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 54th",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_131",
            "content": "UNKNOWN, None, , Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Annual Meeting of the Association for Computational Linguistics",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "414-ARR_v1_132",
            "content": "Ilya Sutskever, Oriol Vinyals, Quoc V Le, Sequence to sequence learning with neural networks, 2014, Advances in neural information processing systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": [
                    "Ilya Sutskever",
                    "Oriol Vinyals",
                    "Quoc V Le"
                ],
                "title": "Sequence to sequence learning with neural networks",
                "pub_date": "2014",
                "pub_title": "Advances in neural information processing systems",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_133",
            "content": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Attention is all you need, 2017, Advances in neural information processing systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": [
                    "Ashish Vaswani",
                    "Noam Shazeer",
                    "Niki Parmar",
                    "Jakob Uszkoreit",
                    "Llion Jones",
                    "Aidan Gomez",
                    "\u0141ukasz Kaiser",
                    "Illia Polosukhin"
                ],
                "title": "Attention is all you need",
                "pub_date": "2017",
                "pub_title": "Advances in neural information processing systems",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_134",
            "content": "Shuo Wang, Yang Liu, Chao Wang, Huanbo Luan, Maosong Sun, Improving back-translation with uncertainty-based confidence estimation, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b40",
                "authors": [
                    "Shuo Wang",
                    "Yang Liu",
                    "Chao Wang",
                    "Huanbo Luan",
                    "Maosong Sun"
                ],
                "title": "Improving back-translation with uncertainty-based confidence estimation",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_135",
            "content": "Xinyi Wang, Hieu Pham, Zihang Dai, Graham Neubig, Switchout: an efficient data augmentation algorithm for neural machine translation, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b41",
                "authors": [
                    "Xinyi Wang",
                    "Hieu Pham",
                    "Zihang Dai",
                    "Graham Neubig"
                ],
                "title": "Switchout: an efficient data augmentation algorithm for neural machine translation",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_136",
            "content": "UNKNOWN, None, 2019, Detecting overfitting via adversarial examples, .",
            "ntype": "ref",
            "meta": {
                "xid": "b42",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Detecting overfitting via adversarial examples",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_137",
            "content": "Lijun Wu, Yiren Wang, Yingce Xia, Tao Qin, Jianhuang Lai, Tie-Yan Liu, Exploiting monolingual data at scale for neural machine translation, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b43",
                "authors": [
                    "Lijun Wu",
                    "Yiren Wang",
                    "Yingce Xia",
                    "Tao Qin",
                    "Jianhuang Lai",
                    "Tie-Yan Liu"
                ],
                "title": "Exploiting monolingual data at scale for neural machine translation",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_138",
            "content": "Jiajun Zhang, Chengqing Zong, Exploiting source-side monolingual data in neural machine translation, 2016, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b44",
                "authors": [
                    "Jiajun Zhang",
                    "Chengqing Zong"
                ],
                "title": "Exploiting source-side monolingual data in neural machine translation",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "414-ARR_v1_139",
            "content": "UNKNOWN, None, 2018, Style transfer as unsupervised machine translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b45",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Style transfer as unsupervised machine translation",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "414-ARR_v1_0@0",
            "content": "On Synthetic Data for Back Translation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_0",
            "start": 0,
            "end": 37,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_2@0",
            "content": "Back translation (BT) is one of the most significant technologies in NMT research fields.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_2",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_2@1",
            "content": "Existing attempts on BT share a common characteristic: they employ either beam search or random sampling to generate synthetic data with a backward model but seldom work studies the role of synthetic data in the performance of BT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_2",
            "start": 90,
            "end": 319,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_2@2",
            "content": "This motivates us to ask a fundamental question: what kind of synthetic data contributes to BT performance?",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_2",
            "start": 321,
            "end": 427,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_2@3",
            "content": "Through both theoretical and empirical studies, we identify two key factors on synthetic data controlling the back-translation NMT performance, which are quality and importance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_2",
            "start": 429,
            "end": 605,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_2@4",
            "content": "Furthermore, based on our findings, we propose a simple yet effective method to generate synthetic data to better trade off both factors so as to yield the better performance for BT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_2",
            "start": 607,
            "end": 788,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_2@5",
            "content": "We run extensive experiments on WMT14 DE-EN, EN-DE, and RU-EN benchmark tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_2",
            "start": 790,
            "end": 867,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_2@6",
            "content": "By employing our proposed method to generate synthetic data, our BT model significantly outperforms the standard BT baselines (i.e., beam and sampling based methods for data generation), which proves the effectiveness of our proposed methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_2",
            "start": 869,
            "end": 1110,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_4@0",
            "content": "Since the birth of neural machine translation (NMT) (Bahdanau et al., 2014;Sutskever et al., 2014) back translation (BT) (Sennrich et al., 2016a) has quickly become one of the most significant technologies in natural language processing (NLP) research field.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_4",
            "start": 0,
            "end": 257,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_4@1",
            "content": "This is because 1) it provides a simple yet effective approach to advance the supervised NMT by leveraging monolingual data (Edunov et al., 2018) and it also serves as a key learning objective in unsupervised NMT (Artetxe et al., 2017;Lample et al., 2018); 2) back-translation even plays a significant role in other NLP research fields beyond translation such as paraphrasing (Mallinson et al., 2017) and style transfer (Prabhumoye et al., 2018;Zhang et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_4",
            "start": 259,
            "end": 723,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_5@0",
            "content": "Back translation consists of two steps, namely synthetic corpus generation with a backward model and parameter optimization for the forward model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_5",
            "start": 0,
            "end": 145,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_5@1",
            "content": "Various contributions have been made on improving back translation, for instance, iterative backtranslation (Hoang et al., 2018), tagged backtranslation (Caswell et al., 2019), confidence weighting , data diversification (Nguyen et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_5",
            "start": 147,
            "end": 389,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_5@2",
            "content": "Although these efforts differ in some aspects, all of them share a common characteristic: they employ a default way to generate synthetic data in the first step of BT which is either beam search or random sampling with a backward model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_5",
            "start": 391,
            "end": 626,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_5@3",
            "content": "Seldom work studies the consequences of synthetic corpus to back-translation and hence it is unclear how synthetic data influences the final performance of BT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_5",
            "start": 628,
            "end": 786,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_6@0",
            "content": "The early study empirically suggests the quality of the synthetic corpus is vital for BT performance (Sennrich et al., 2016a).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_6",
            "start": 0,
            "end": 125,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_6@1",
            "content": "However, recent studies illustrate better test performance can be achieved by low quality synthetic corpus (Edunov et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_6",
            "start": 127,
            "end": 255,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_6@2",
            "content": "This contradictory observation indicates the quality of synthetic data is not the only element that affects the BT performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_6",
            "start": 257,
            "end": 383,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_6@3",
            "content": "Hence, this fact naturally raises a fundamental question: what kind of synthetic data contributes to backtranslation performance?",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_6",
            "start": 385,
            "end": 513,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_7@0",
            "content": "Consequently, we attempt to exploit such a fundamental question in this paper.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_7",
            "start": 0,
            "end": 77,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_7@1",
            "content": "To this end, we start from a marginal objective, which is critical to semi-supervised learning, and derive an approximate lower bound of the objective function.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_7",
            "start": 79,
            "end": 238,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_7@2",
            "content": "Corresponding to this lower bound, we theoretically find two related elements for maximizing such a lower bound: quality of synthetic bilingual data and importance weight of its source.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_7",
            "start": 240,
            "end": 424,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_7@3",
            "content": "Since both elements are mutually exclusive in essence, it may induce contradictory observation if one judges the BT performance according to a single element.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_7",
            "start": 426,
            "end": 583,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_7@4",
            "content": "In addition, such a theoretical explanation is supported by our empirical experiments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_7",
            "start": 585,
            "end": 670,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_7@5",
            "content": "Furthermore, based on our findings, we propose a new heuristic approach to generate synthetic data whose both elements are better balanced so as to yield improvements over both sampling and beam search based methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_7",
            "start": 672,
            "end": 887,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_7@6",
            "content": "Extensive experiments on three WMT14 tasks show that our BT consistently outperforms the standard sampling and beam search based baselines with a significant margin.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_7",
            "start": 889,
            "end": 1053,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_8@0",
            "content": "Our contributions are three folds:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_8",
            "start": 0,
            "end": 33,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_9@0",
            "content": "1. We point it out that importance weight and quality of synthetic candidates are two key factors that affect the NMT performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_9",
            "start": 0,
            "end": 129,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_10@0",
            "content": "2. We propose a simple yet effective method for synthetic corpus generation, which could better balance the quality and importance of synthetic data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_10",
            "start": 0,
            "end": 148,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_11@0",
            "content": "3. Our experiments prove the effectiveness of aforementioned strategy, it outperforms beam or sampling decoding methods on three benchmark tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_11",
            "start": 0,
            "end": 144,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_12@0",
            "content": "Revisiting Back Translation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_12",
            "start": 0,
            "end": 26,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_13@0",
            "content": "NMT builds a probabilistic model p(y|x; \u03b8) with neural networks parameterized by \u03b8, which is used to translate a sentence x in source language X to a sentence y in target language Y. The standard wisdom to train the model is to minimize the following objective function over a given bilingual corpus B = {(x i , y i )}:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_13",
            "start": 0,
            "end": 318,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_14@0",
            "content": "\u2113(B; \u03b8) = (x i ,y i )\u2208B log p(y i |x i ; \u03b8)(1)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_14",
            "start": 0,
            "end": 45,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_15@0",
            "content": "Recently Sennrich et al. (2016a) propose a remarkable method called Back Translation (BT) to improve NMT by using a monolingual corpus M in target language Y besides B and back translation becomes one of the most successful techniques in NMT (Fadaee and Monz, 2018;Edunov et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_15",
            "start": 0,
            "end": 285,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_15@1",
            "content": "At the high level, back translation can be considered as a semi-supervised method because it leverages both labeled and unlabeled data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_15",
            "start": 287,
            "end": 421,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_15@2",
            "content": "Suppose p(x|y; \u03c0) is the backward translation model whose parameter \u03c0 is optimized over B, the key idea of back translation can be summarized as the following two steps:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_15",
            "start": 423,
            "end": 591,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_16@0",
            "content": "To make BT more efficient, the standard configuration is widely adopted: each sentence y is required to generate a single source x and both two steps are performed for a single pass.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_16",
            "start": 0,
            "end": 181,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_16@1",
            "content": "We follow this standard in this paper for generality but our idea in this paper is straightforward to apply to other configurations such as (Gra\u00e7a et al., 2019;Hoang et al., 2018;Nguyen et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_16",
            "start": 183,
            "end": 382,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_17@0",
            "content": "In the first step, there are two main strategies to generate the synthetic corpus, i.e., deterministically decoding and randomly sampling with p(x|y; \u03c0).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_17",
            "start": 0,
            "end": 152,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_17@1",
            "content": "The first strategy aims to search the best candidate as follows, xb = arg max p(x|y; \u03c0)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_17",
            "start": 154,
            "end": 240,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_18@0",
            "content": "(3)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_18",
            "start": 0,
            "end": 2,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_19@0",
            "content": "The above optimization is achieved by the beam search decoding, which can be regarded as a degenerated shortest path problem with respect to the log p(x|y; \u03c0) with limited routing attempts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_19",
            "start": 0,
            "end": 188,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_19@1",
            "content": "The alternative strategy is random sampling: it randomly samples a token with respect to the distribution estimated by back-translation model at each decoding step.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_19",
            "start": 190,
            "end": 353,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_19@2",
            "content": "Such a process can be modelled by,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_19",
            "start": 355,
            "end": 388,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_20@0",
            "content": "xs = rand{p(x|y; \u03c0)}(4)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_20",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_21@0",
            "content": "Research Question Prior work points out (Sennrich et al., 2016a) that the synthetic corpus with high quality is beneficial to the final performance of back translation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_21",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_21@1",
            "content": "However, the recent studies (Edunov et al., 2018) find that NMT models with unsatisfactory BLEU score corpus, for instance the corpus generated by sampling based strategy, also establish the state-of-the-art (SOTA) achievement among back-translation NMT models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_21",
            "start": 169,
            "end": 429,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_21@2",
            "content": "This contradictory fact indicates that the quality of synthetic corpus is not the sole element for back translation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_21",
            "start": 431,
            "end": 546,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_21@3",
            "content": "This motivates us to study a fundamental question for back translation: what kind of synthetic corpus is beneficial to back translation?",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_21",
            "start": 548,
            "end": 683,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_22@0",
            "content": "Understanding Synthetic Data by Two Factors",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_22",
            "start": 0,
            "end": 42,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_23@0",
            "content": "To answer the fundamental question presented in the previous section, we first start from the marginal likelihood objective defined on the target language Y, and then we theoretically explain two factors (i.e., quality and importance) that are highly related to the training objective of back translation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_23",
            "start": 0,
            "end": 304,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_23@1",
            "content": "Finally, we empirically explain why synthetic corpus with low quality may lead to better performance than synthetic corpus with high quality by measuring both factors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_23",
            "start": 306,
            "end": 472,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_24@0",
            "content": "Theoretical Explanation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_24",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_25@0",
            "content": "Maximizing marginal likelihood is an important principle to leverage unlabeled data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_25",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_25@1",
            "content": "Therefore, we rethink back translation from this principle because it makes use of target monolingual corpus M. For each y \u2208 M, the marginal likelihood objective can be derived by the Bayesian Equation Total Probability formula (5), Jansen Inequality (6), and importance sampling (7) as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_25",
            "start": 85,
            "end": 379,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_26@0",
            "content": "log p(y; \u03b8) = log x p(x)p(y|x; \u03b8)(5)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_26",
            "start": 0,
            "end": 35,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_27@0",
            "content": "where p(x) is a language model on source language X , p(x|y) is a backward translation model from Y to X which serves as the proposal distribution for importance sampling, and x is sampled from p(x|y).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_27",
            "start": 0,
            "end": 200,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_27@1",
            "content": "If p(x|y) is set as the backward model p(x|y; \u03c0) optimized on B, the last term in Equation 7is the same as the second term in BT loss (i.e., log p(y|x) in Eq. 2), and the unique difference is the multiplicative term called importance weight:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_27",
            "start": 202,
            "end": 442,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_28@0",
            "content": "Imp(x; y) = p(x) p(x|y)(8)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_28",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_29@0",
            "content": "The denominator is the candidate conditional probability to target, and the numerator is the candidate distribution on source language distribution.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_29",
            "start": 0,
            "end": 147,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_29@1",
            "content": "Since Imp(x; y) is constant with respect to the parameter \u03b8, maximizing log p(y|x; \u03b8) in BT loss implicitly maximizes Imp(x; y) log p(y|x), which indicates that back translation aims to implicitly maximize the marginal likelihood objective.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_29",
            "start": 149,
            "end": 388,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_29@2",
            "content": "More importantly, according to Equation 7we can find that the following two factors are critical to influence the marginal likelihood log p(y; \u03b8):",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_29",
            "start": 390,
            "end": 535,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_30@0",
            "content": "\u2022 Factor 1: The quality of x as a translation of y corresponding to the log p(y|x; \u03b8) in Eq. 7. \u2022 Factor 2: The importance of x as a translation of y corresponding to Imp(x; y) in Eq. 7.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_30",
            "start": 0,
            "end": 185,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_31@0",
            "content": "Theoretically, if x is of higher quality and contains more semantic information in y, p(y|x; \u03b8) would be higher and thus it would lead to a higher log p(y; \u03b8), which is well acknowledged by prior work (Sennrich et al., 2016a;.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_31",
            "start": 0,
            "end": 225,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_32@0",
            "content": "In particular, if x is with higher importance weight, maximizing log p(y|x; \u03b8) is more helpful to maximize log p(y; \u03b8).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_32",
            "start": 0,
            "end": 118,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_32@1",
            "content": "On the contrary, if Imp(x; y) is very small, it needs to avoid such a sample x from p(x|y), which is essentially the rejection control strategy in importance sampling theory (Liu et al., 1998;Liu and Liu, 2001).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_32",
            "start": 120,
            "end": 330,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_32@2",
            "content": "Unfortunately, in practice, both factors are mutually exclusive: if x is with high quality, p(x|y; \u03b8) would be higher as well leading to lower importance weight.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_32",
            "start": 332,
            "end": 492,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_32@3",
            "content": "This fact can explain the contradictory observation in Sec 2 that BT with high-quality synthetic data sometimes leads to better testing performance, while it may deliver worse performance at other times, which will be later justified in Sec 3.2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_32",
            "start": 494,
            "end": 738,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_33@0",
            "content": "Estimating Two Factors To measure the quality of x for each y, it is natural to use the evaluation metric such as BLEU if the reference translation x of y is available.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_33",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_33@1",
            "content": "Otherwise, as a surrogate, we use the log likelihood log p(x|y; \u03c0) of the backward translation model \u03c0 which is trained on the authentic data B. Similarly, in order to estimate the importance of x, we train an additional language model p(x; \u03c9) with GPT (Radford et al.) on a large monolingual corpus for X .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_33",
            "start": 169,
            "end": 475,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_33@2",
            "content": "In this way, the importance weight is estimated by Imp(x) \u2248 p(x; \u03c9) p(x|y; \u03c0)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_33",
            "start": 477,
            "end": 553,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_34@0",
            "content": "Empirical Justification",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_34",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_35@0",
            "content": "In this subsection, we aim to justify the following statements: 1) encouraging quality of synthetic corpus may to some extent hurt the performance of BT due to the decrease of importance; 2) judging the testing performance in terms of quality only may be dangerous while it would be meaningful to judge the testing performance by taking into account both factors rather than either factor.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_35",
            "start": 0,
            "end": 388,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_35@1",
            "content": "To this end, we run some quick experiments on WMT14 datasets whose settings will be shown in Sec 5 later.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_35",
            "start": 390,
            "end": 494,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_35@2",
            "content": "We set up two back translation systems with two different options (i.e., beam search and sampling) to generate synthetic corpus by using the best checkpoint of p(x|y; \u03c0) tuned on the development set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_35",
            "start": 496,
            "end": 694,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_35@3",
            "content": "Both beam search and sampling based BT systems are denoted by beam and sampling.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_35",
            "start": 696,
            "end": 775,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_35@4",
            "content": "In addition, we pick another checkpoint of p(x|y; \u03c0) which is trained for only 1 epoch, and we use this weak checkpoint to set up another beam search based BT system, which is denoted as beam*. Table 1 shows BLEU on test dataset, the quality and importance on dev dataset according to three systems on WMT14 DE-EN task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_35",
            "start": 777,
            "end": 1095,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_36@0",
            "content": "In Table 1, beam is better than sampling in the quality of synthetic corpus but its testing performance is worse.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_36",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_36@1",
            "content": "This is meaningful because the former relies on the synthetic corpus with lower importance weight according to our theoretical explanation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_36",
            "start": 114,
            "end": 252,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_36@2",
            "content": "In addition, when comparing beam with beam*, we can find that beam delivers better testing performance because its quality is better meanwhile its importance weight is almost similar to that of beam*. Table 2 consistently demonstrates that it is meaningless to take into account quality only when evaluating BT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_36",
            "start": 254,
            "end": 564,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_36@3",
            "content": "These facts justify our statements and provide an answer to the fundamental question in section 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_36",
            "start": 566,
            "end": 663,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_37@0",
            "content": "Improving Synthetic Data for BT",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_37",
            "start": 0,
            "end": 30,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_38@0",
            "content": "As shown in the previous section, both importance and quality of synthetic corpus are beneficial to the overall testing performance of back translation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_38",
            "start": 0,
            "end": 151,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_38@1",
            "content": "It is a natural idea to promote both factors when generating synthetic corpus such that running BT on such corpus leads to better testing performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_38",
            "start": 153,
            "end": 302,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_38@2",
            "content": "However, this is difficult because both factors are mutually exclusive.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_38",
            "start": 304,
            "end": 374,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_38@3",
            "content": "In this section, we instead propose two methods (namely data manipulation and gamma score) to trade off both factors in the hope to yield better BT performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_38",
            "start": 376,
            "end": 535,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_39@0",
            "content": "Data Manipulation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_39",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_40@0",
            "content": "Since the synthetic data in sampling based BT is of high importance yet low quality whereas the case for the synthetic data in beam search based BT is opposite, we propose a data manipulation method to trade off importance and quality by combining both synthetic datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_40",
            "start": 0,
            "end": 271,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_40@1",
            "content": "Through balancing the ratio between beam and sampling based synthetic corpora, we expect to find an optimized beam/sampling ratio to further improve NMT model performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_40",
            "start": 273,
            "end": 443,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_41@0",
            "content": "Specifically, we randomly shuffle M and divide it into two parts with the first part accounting for \u03b3 (0 < \u03b3 < 1); then we generate translations for the first part with beam search while generating translations for the second part with sampling.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_41",
            "start": 0,
            "end": 244,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_41@1",
            "content": "Formally, we use the following corpus M c as the synthetic corpus for BT:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_41",
            "start": 246,
            "end": 318,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_42@0",
            "content": "M c = {(x b i , y i ) k i=0 } \u222a {(x s j , y j ) |M| j=k } k =\u230a\u03b3|M|\u230b",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_42",
            "start": 0,
            "end": 66,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_43@0",
            "content": "Where xb denotes a translation of y generated by p(x|y; \u03c0) with beam search and xs is a translation with sampling, | \u2022 | means the size of the corpus, and \u03b3 is the combination ratio of beam and sampling synthetic corpora.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_43",
            "start": 0,
            "end": 220,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_43@1",
            "content": "By tuning \u03b3 here, one can modify the weightage for the number of beam and sampling sentences, to improve back-translation performance by training models on a combined synthetic corpus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_43",
            "start": 222,
            "end": 405,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_44@0",
            "content": "Although this method is easy to implement, its limitation is obvious.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_44",
            "start": 0,
            "end": 68,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_44@1",
            "content": "Since each x is either from beam search or from sampling, the quality of M c is generally worse than that of beam search and its importance weight is generally worse than that of sampling.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_44",
            "start": 70,
            "end": 257,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_44@2",
            "content": "Consequently, we propose an alternative method in the next part of this section.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_44",
            "start": 259,
            "end": 338,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_45@0",
            "content": "Gamma Score",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_45",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_46@0",
            "content": "The key idea to the alternative method is that it employs a score that balances both quality and importance to generate a translation x for each y \u2208 M. A natural choice of such a score is defined by the interpolation score as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_46",
            "start": 0,
            "end": 233,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_47@0",
            "content": "\u03b3 log Imp(x; \u03c9, \u03c0) + (1 \u2212 \u03b3) log p(x|y; \u03c0)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_47",
            "start": 0,
            "end": 41,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_48@0",
            "content": "where \u03b3 is used to trade off both factors as in corpus manipulation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_48",
            "start": 0,
            "end": 67,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_48@1",
            "content": "With the help of this score, one may optimize the x through beam search whose interpolation score is the best among all possible translations of y \u2208 M. Unfortunately, such an implementation leads to limited performance in our preliminary experiments, due to two major challenges.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_48",
            "start": 69,
            "end": 347,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_49@0",
            "content": "On one hand, the estimations of quality and importance weight of x are not well calibrated, and in particular, quality and importance are mutually exclusive as mentioned before.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_49",
            "start": 0,
            "end": 176,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_49@1",
            "content": "As a result, beam search with the interpolation score over the exponential space can not guarantee a desirable translation x for each y. On the other hand, quality and importance weight of x are not at the same scale for different y, it is difficult to balance both factors with a fixed \u03b3 in the interpolation score for different y.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_49",
            "start": 178,
            "end": 509,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_50@0",
            "content": "To alleviate these issues, we propose a simple method as follows.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_50",
            "start": 0,
            "end": 64,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_50@1",
            "content": "Specifically, firstly, instead of beam search with the interpolation score, we simply utilize the backward translation p(x|y; \u03c0) to randomly sample a set of candidate translations which is denoted by A(y) = {x i } N i (N = 50 in this paper).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_50",
            "start": 66,
            "end": 306,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_50@2",
            "content": "1 Then we pick a xj among A(y) according to the balancing score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_50",
            "start": 308,
            "end": 371,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_50@3",
            "content": "Secondly, for each x, we normalize the log values of importance and quality of each candidate by its sequence length, then normalize these values with respect to all N candidates as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_50",
            "start": 373,
            "end": 562,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_51@0",
            "content": "F(x i ) = log F(x i ) /len(x i ) \u2212 \u00b5 F \u03c3 F (9)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_51",
            "start": 0,
            "end": 45,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_52@0",
            "content": "1 N -best decoding strategy with p(x|y; \u03c0) to generate N candidates may be another solution which remains as future work.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_52",
            "start": 0,
            "end": 120,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_53@0",
            "content": "where F is either importance weight or quality estimations, and",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_53",
            "start": 0,
            "end": 62,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_54@0",
            "content": "\u00b5 F = 1 N i log F(x i ) and \u03c3 F = i (log F (x i )\u2212\u00b5 F ) 2 N \u22121",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_54",
            "start": 0,
            "end": 61,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_55@0",
            "content": "are mean and variance of N sampled candidates with length normalized.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_55",
            "start": 0,
            "end": 68,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_55@1",
            "content": "Finally, the Gamma score is defined on the normalized values of importance and quality as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_55",
            "start": 70,
            "end": 167,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_56@0",
            "content": "\u0393(x i ; \u03c9, \u03c0) = exp \u03b3 \u0128mp(x i ; \u03c9, \u03c0) + (1 \u2212 \u03b3)p(x i |y, \u03c0) j exp \u03b3 \u0128mp(x j ; \u03c9, \u03c0) + (1 \u2212 \u03b3)p(x j |y, \u03c0)(10)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_56",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_57@0",
            "content": "where \u0128mp and p are the normalized log value of importance weight and backward translation model p(x|y, \u03c0) as defined in Equation 9.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_57",
            "start": 0,
            "end": 131,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_58@0",
            "content": "Once the gamma score in Equation 10 is computed, there are two methods to select x from A(y), which are deterministic and stochastic methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_58",
            "start": 0,
            "end": 140,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_58@1",
            "content": "For deterministic selection, we simply select the candidates with maximum gamma score among N translation candidates; and for sampling, we sample a candidate according to its gamma score distribution.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_58",
            "start": 142,
            "end": 341,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_58@2",
            "content": "These two methods are called gamma selection and gamma sampling in our experiments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_58",
            "start": 343,
            "end": 425,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_59@0",
            "content": "Experiments",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_59",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_60@0",
            "content": "Settings",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_60",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_61@0",
            "content": "We run all the experiments using WMT14 datasets with fairseq (Ott et al., 2019) framework.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_61",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_61@1",
            "content": "For dataset settings, we use all available bitext of WMT14 corpus without any filtering on sentence length or source/target length ratio, this will result in a 4.5 million parallel corpus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_61",
            "start": 91,
            "end": 278,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_61@2",
            "content": "For back translation experiment, we use equal scale monolingual corpus randomly sampled from Newscrawl 2020 (Barrault et al., 2019) comprising 4.5 million monolingual sentences, thus total 9 million sentences are used.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_61",
            "start": 280,
            "end": 497,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_61@3",
            "content": "We tokenize the parallel corpus using Mose tokenizer (Koehn et al., 2007), and learn a source and target shared Byte-Pair-Encoding (BPE; Sennrich et al., 2016) with 32K types.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_61",
            "start": 499,
            "end": 673,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_61@4",
            "content": "We develop on new-stest2013 and report the results on newstest2014.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_61",
            "start": 675,
            "end": 741,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_62@0",
            "content": "As for model architecture, we employ all the translation models using architecture transformer_wmt_en_de_big, which is a Big Transformer architecture with 6 blocks in the encoder and decoder, under the fairseq (Ott et al., 2019) feed-forward layers, and dropout is set to 0.3 for all the experiments. And for monolingual models, we apply transformer_lm_gpt architecture (Radford et al.) on each side of WMT14 corpus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_62",
            "start": 0,
            "end": 415,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_63@0",
            "content": "For baseline models, we train them for 400K updating steps, and train the models with backtranslation data for 1.6M updating steps.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_63",
            "start": 0,
            "end": 130,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_63@1",
            "content": "We save the checkpoints every 100k updating intervals, and only select the checkpoints with highest develop set performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_63",
            "start": 132,
            "end": 255,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_63@2",
            "content": "As for the backtranslation data, we use baseline models' checkpoints at 400K updating steps to generate default beam5 decoding and sampling decoding synthetic corpus without any penalty.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_63",
            "start": 257,
            "end": 442,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_63@3",
            "content": "For monolingual models, we only select the checkpoints with the best develop set performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_63",
            "start": 444,
            "end": 536,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_63@4",
            "content": "When tuning \u03b3 on dev sets for data manipulation methods we select it from {0, 1/4, 1/2, 3/4, 1} and the optimal is \u03b3 = 1/2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_63",
            "start": 538,
            "end": 660,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_63@5",
            "content": "For the Gamma Score method, \u03b3 is tuned among {0.1, 0.2, 0.3, 0.4, 0.5} and it is set \u03b3 = 0.2 for all three tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_63",
            "start": 662,
            "end": 774,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_64@0",
            "content": "All the experiments are conducted using 8 Nvidia V100-32GB graphic cards without any gradient accumulation or bitext upsampling, and the results in this paper are measured in case-sensitive detokenized BLEU with SacreBLEU 2 by Post (2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_64",
            "start": 0,
            "end": 238,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_65@0",
            "content": "Main Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_65",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_66@0",
            "content": "Results on DE-EN Data Manipulation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_66",
            "start": 0,
            "end": 33,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_67@0",
            "content": "We conduct two experiments to study the data manipulation for backtranslation NMT model performance using aforementioned corpus with and without authentic corpus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_67",
            "start": 0,
            "end": 161,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_67@1",
            "content": "Gamma criterion based method outperform beam search based and sampling based back-translation NMT models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_67",
            "start": 163,
            "end": 267,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_67@2",
            "content": "The result marked with * denotes that it is significantly better than sampling BT with p < 0.0010.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_67",
            "start": 269,
            "end": 366,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_68@0",
            "content": "Table 3 show the data manipulation results compared with baseline.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_68",
            "start": 0,
            "end": 65,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_68@1",
            "content": "Firstly, for synthetic corpus experiment, we find that even if only monolingual corpus is used, the performance of back-translation NMT model can still be significantly improved to 31.3 from 29.2 by sampling or 27.6 by beam, and it is only 0.7 lower than bitext baseline by BLEU score measure.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_68",
            "start": 67,
            "end": 359,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_68@2",
            "content": "Secondly, for the experiments with bitext, the best performance by data manipulation only helps the back-translation NMT model achieves almost the same performance with sampling BT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_68",
            "start": 361,
            "end": 541,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_68@3",
            "content": "This means data manipulation methods cannot achieve a higher BLEU score than sampling or beam.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_68",
            "start": 543,
            "end": 636,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_69@0",
            "content": "Gamma Score In this paragraph, we conduct the experiments based on gamma score method.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_69",
            "start": 0,
            "end": 85,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_69@1",
            "content": "We conduct both of the methods in this experiment: we select the candidate with highest gamma score for the deterministic method whereas sample the candidate by gamma score distribution for the stochastic method.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_69",
            "start": 87,
            "end": 298,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_70@0",
            "content": "Once again, we use synthetic gamma corpus combined with bitext to train the back-translation NMT models on each corpus, the results are listed in 4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_70",
            "start": 0,
            "end": 147,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_70@1",
            "content": "From the table, we can see that our proposed gamma sampling significantly outperforms the sampling based and beam search based backtranslation baselines by 0.9 and 2.3 BLEU scores in terms of SacreBLEU. And our two proposed gamma score based methods outperform data manipulation method as well.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_70",
            "start": 149,
            "end": 442,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_71@0",
            "content": "In the rest of the experiments, we report results for both gamma selection and gamma sampling as the proposed methods and their hyperparameter \u03b3 for other tasks is fixed to 0.2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_71",
            "start": 0,
            "end": 176,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_72@0",
            "content": "Results on other Datasets",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_72",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_73@0",
            "content": "We conduct the experiments on WMT14 EN-DE and RU-EN for both gamma selection and gamma sampling as well, and table 5 shows that our proposed gamma based methods significantly outperform beam and sampling based back-translation methods on both en-de and ru-en translation for almost 1 and 0.4 BLEU score respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_73",
            "start": 0,
            "end": 315,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_74@0",
            "content": "Discussion on Efficiency Since our method requires to run sampling with size of 50 to generate synthetic data, its efficiency is about 10x slower than that of beam BT with size of 5 and 50x slower than that of sampling BT with size 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_74",
            "start": 0,
            "end": 233,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_74@1",
            "content": "Luckily, because the bottleneck of BT is not the synthetic data generation but the parameter optimization on both synthetic and authentic data, our overall overhead is less than 0.5x slower than sampling BT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_74",
            "start": 235,
            "end": 441,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_74@2",
            "content": "In addition, since decoding is very easy to be parallelized on GPU or CPU machines, the cost of decoding is not a serious issue for our method, which makes it possible to run our method on a large scale dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_74",
            "start": 443,
            "end": 653,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_75@0",
            "content": "Analysis on Synthetic Corpus",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_75",
            "start": 0,
            "end": 27,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_76@0",
            "content": "In this subsection, we analyze the synthetic corpus of proposed gamma score methods on both sentence level and token level.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_76",
            "start": 0,
            "end": 122,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_77@0",
            "content": "Sentence Level We evaluate the back-translation synthetic source sentences by their sentence representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_77",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_77@1",
            "content": "We use the baseline model to generate the hidden representations at the end-of-speech token as the sentence representation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_77",
            "start": 110,
            "end": 232,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_77@2",
            "content": "Here, we compute the singular value spectrum of the representations for different back-translation corpora.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_77",
            "start": 234,
            "end": 340,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_78@0",
            "content": "3",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_78",
            "start": 0,
            "end": 0,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_79@0",
            "content": "The spectrum is shown in figure 1(a).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_79",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_79@1",
            "content": "From the spectrum, sampling has a more uniform distribution whereas beam has the worst variety.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_79",
            "start": 38,
            "end": 132,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_79@2",
            "content": "Our proposed methods have moderate variety between sampling and beam, and gamma sampling consists of higher linguistic information richness compared with gamma selection.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_79",
            "start": 134,
            "end": 303,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_80@0",
            "content": "Figure 1(b) shows the sequence length of the synthetic corpora of different generation methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_80",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_80@1",
            "content": "Beam generates the shortest synthetic sentences and gamma sampling generates the longest synthetic sentences on average.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_80",
            "start": 96,
            "end": 215,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_80@2",
            "content": "Between them, sampling and gamma selection generate almost the same sequence length, which means gamma selection candidates provide more learning signal than random sampling under the same length.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_80",
            "start": 217,
            "end": 412,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_81@0",
            "content": "3 Singular value spectrum analysis is a widely used method to measure the representation distribution.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_81",
            "start": 0,
            "end": 101,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_81@1",
            "content": "Gao et al. (2019) firstly introduces this method to measure the isotropy of representation, and directly employ spectrum control for better NMT performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_81",
            "start": 103,
            "end": 258,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_81@2",
            "content": "The idea is, representations of high linguistic variety usually are more isotropic, thus to have a relatively uniform singular value distribution.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_81",
            "start": 260,
            "end": 405,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_81@3",
            "content": "We employ this method here to measure the variety of sentence level information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_81",
            "start": 407,
            "end": 486,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_82@0",
            "content": "Token Level Figure 1(c) is the token frequency histogram, which shows beam has higher probability to decode high frequency tokens while sampling prefers more low frequency tokens.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_82",
            "start": 0,
            "end": 178,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_83@0",
            "content": "We also measure the vocabulary size, finding that the proposed gamma sampling shares the same vocabulary size as sampling method.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_83",
            "start": 0,
            "end": 128,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_83@1",
            "content": "This could be the reason that gamma sampling is based on random sampling for candidates generation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_83",
            "start": 130,
            "end": 228,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_84@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_84",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_85@0",
            "content": "This section describes prior arts in back-translation for NMT, data augmentation, and semi-supervised machine translation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_85",
            "start": 0,
            "end": 121,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_86@0",
            "content": "Back-translation NMT Bojar and Tamchyna (2011) firstly proposed back-translation, then Bertoldi and Federico (2009); Lambert et al. (2011) apply back translation to solve the domain adaptation problems in phrase-based NMT systems.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_86",
            "start": 0,
            "end": 229,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_86@1",
            "content": "Sennrich et al. (2016a) further extend the back translation for training NMT models integrally.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_86",
            "start": 231,
            "end": 325,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_87@0",
            "content": "For understanding the back-translation synthetic corpus, Currey et al. (2017) use a copy of target as a pseudo source , and find that NMT model performance can still be improved under the low resource settings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_87",
            "start": 0,
            "end": 209,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_87@1",
            "content": "Caswell et al. (2019) propose tagged back-translation to indicate to the model that the given source is synthetic.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_87",
            "start": 211,
            "end": 324,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_87@2",
            "content": "To further find an optimum back-translation corpus decoding method, Imamura et al. (2018) firstly use sampling based synthetic corpus and find such a stochastic decoding method outperforms beam search on boosting NMT model performance, and Edunov et al. (2018) broaden the investigation of a number of backtranslation generation methods for synthetic source sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_87",
            "start": 326,
            "end": 693,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_87@3",
            "content": "Their contribution shows that sampling or noisy synthetic data gives a much stronger training signal.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_87",
            "start": 695,
            "end": 795,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_87@4",
            "content": "Gra\u00e7a et al. (2019) reformulate backtranslation in the context of optimization and clarifying to improve sampling based decoding method search space, thus proposing N best list sampling.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_87",
            "start": 797,
            "end": 982,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_87@5",
            "content": "Recently, Nguyen et al. (2020) diversify the training data by multiple forward and backward models translations and combine them with the original datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_87",
            "start": 984,
            "end": 1139,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_88@0",
            "content": "Data Augmentation for NMT NMT researchers are the pioneers of data augmentation studies since back-translation is a natural type of data augmentation method.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_88",
            "start": 0,
            "end": 156,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_88@1",
            "content": "(Sennrich et al., 2016b;Norouzi et al., 2016;Zhang and Zong, 2016).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_88",
            "start": 158,
            "end": 224,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_89@0",
            "content": "To balance the token frequency in NMT corpus, Fadaee et al. (2017) create new sentences contain low-frequency words.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_89",
            "start": 0,
            "end": 115,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_89@1",
            "content": "However, as observed by , the improvement across different translation tasks is not consistent, and they invent SwitchOut data augmentation policy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_89",
            "start": 117,
            "end": 263,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_89@2",
            "content": "Recht et al. (2018Recht et al. ( , 2019; Werpachowski et al. (2019) also observe such an inconsistency of variance between training corpus and testing set as well as in the generation tasks Recently, Li et al. (2019) try to understand data augmentation from input sensitivity and prediction margin, thus obtaining relatively low variance in generation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_89",
            "start": 265,
            "end": 616,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_90@0",
            "content": "Semi-supervised Machine Translation However, as high quality bitext is always limited and costly to collect, Gulcehre et al. (2015) study methods for effectively leveraging monolingual data in NMT systems.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_90",
            "start": 0,
            "end": 204,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_90@1",
            "content": "He et al. (2016) develop a duallearning mechanism, under such a learning objective, a NMT system is able to automatically learn from unlabeled data, thus improving NMT performance iteratively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_90",
            "start": 206,
            "end": 397,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_90@2",
            "content": "Based on iterative learning, Lample et al. (2018) investigates how to learn NMT systems when only large monolingual corpora can be used in each language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_90",
            "start": 399,
            "end": 551,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_91@0",
            "content": "For supervision of models, Gulcehre et al. (2017) employ the target language model hidden states into NMT decoder to further improve performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_91",
            "start": 0,
            "end": 144,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_91@1",
            "content": "Edunov et al. (2020) show that back-translation improves translation quality of both naturally occurring text and translationese according to professional human translators.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_91",
            "start": 146,
            "end": 318,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_91@2",
            "content": "For supervision of learning corpus, Wu et al. (2019) study both the source-side and target-side monolingual data for NMT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_91",
            "start": 320,
            "end": 440,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_92@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_92",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_93@0",
            "content": "In this work, we answer a fundamental question about synthetic data for back translation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_93",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_93@1",
            "content": "We theoretically and empirically show two key factors namely quality and importance weight of synthetic data play an important role in back translation, and then we propose a new method to generate synthetic data which better balances both factors so as to boost the back-translation performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_93",
            "start": 90,
            "end": 385,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_93@2",
            "content": "For future work, we think it would be of significance to apply our synthetic data generation method to other BT methods or even to more broad NLP tasks such as paraphrasing and style transfer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_93",
            "start": 387,
            "end": 578,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_94@0",
            "content": "UNKNOWN, None, 2017, Unsupervised neural machine translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_94",
            "start": 0,
            "end": 62,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_95@0",
            "content": "UNKNOWN, None, 2014, Neural machine translation by jointly learning to align and translate, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_95",
            "start": 0,
            "end": 92,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_96@0",
            "content": "Lo\u00efc Barrault, Ond\u0159ej Bojar, Marta Costa-Juss\u00e0, Christian Federmann, Mark Fishel, Yvette Graham, Barry Haddow, Matthias Huck, Philipp Koehn, Shervin Malmasi, Christof Monz, Mathias M\u00fcller, Findings of the 2019 conference on machine translation (WMT19), 2019, Proceedings of the Fourth Conference on Machine Translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_96",
            "start": 0,
            "end": 320,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_97@0",
            "content": "Nicola Bertoldi, Marcello Federico, Domain adaptation for statistical machine translation with monolingual resources, 2009, Proceedings of the fourth workshop on statistical machine translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_97",
            "start": 0,
            "end": 195,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_98@0",
            "content": "Ond\u0159ej Bojar, Ale\u0161 Tamchyna, Improving translation model by monolingual data, 2011, Proceedings of the Sixth Workshop on Statistical Machine Translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_98",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_99@0",
            "content": "Isaac Caswell, Ciprian Chelba, David Grangier, Tagged back-translation, 2019, Proceedings of the Fourth Conference on Machine Translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_99",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_100@0",
            "content": "Anna Currey, Antonio Valerio Miceli-Barone, Kenneth Heafield, Copied monolingual data improves low-resource neural machine translation, 2017, Proceedings of the Second Conference on Machine Translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_100",
            "start": 0,
            "end": 203,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_101@0",
            "content": "Sergey Edunov, Myle Ott, Michael Auli, David Grangier, Understanding back-translation at scale, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_101",
            "start": 0,
            "end": 190,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_102@0",
            "content": "Sergey Edunov, Myle Ott, Marc'aurelio Ranzato, Michael Auli, On the evaluation of machine translation systems trained with back-translation, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_102",
            "start": 0,
            "end": 236,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_103@0",
            "content": "Marzieh Fadaee, Arianna Bisazza, Christof Monz, Data augmentation for low-resource neural machine translation, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Short Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_103",
            "start": 0,
            "end": 218,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_104@0",
            "content": "Marzieh Fadaee, Christof Monz, Backtranslation sampling by targeting difficult words in neural machine translation, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_104",
            "start": 0,
            "end": 210,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_105@0",
            "content": "Jun Gao, Di He, Xu Tan, Tao Qin, Liwei Wang, Tieyan Liu, Representation degeneration problem in training natural language generation models, 2019, International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_105",
            "start": 0,
            "end": 201,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_106@0",
            "content": "Miguel Gra\u00e7a, Yunsu Kim, Julian Schamper, Shahram Khadivi, Hermann Ney, Generalizing back-translation in neural machine translation, 2019, Proceedings of the Fourth Conference on Machine Translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_106",
            "start": 0,
            "end": 200,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_107@0",
            "content": "UNKNOWN, None, 2015, On using monolingual corpora in neural machine translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_107",
            "start": 0,
            "end": 81,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_108@0",
            "content": "Caglar Gulcehre, Orhan Firat, Kelvin Xu, Kyunghyun Cho, Yoshua Bengio, On integrating a language model into neural machine translation, 2017, Computer Speech & Language, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_108",
            "start": 0,
            "end": 170,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_109@0",
            "content": "Di He, Yingce Xia, Tao Qin, Liwei Wang, Nenghai Yu, Tie-Yan Liu, Wei-Ying Ma, Dual learning for machine translation, 2016, Advances in neural information processing systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_109",
            "start": 0,
            "end": 174,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_110@0",
            "content": "Duy Vu Cong, Philipp Hoang, Gholamreza Koehn, Trevor Haffari,  Cohn, Iterative backtranslation for neural machine translation, 2018, Proceedings of the 2nd Workshop on Neural Machine Translation and Generation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_110",
            "start": 0,
            "end": 211,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_111@0",
            "content": "Kenji Imamura, Atsushi Fujita, Eiichiro Sumita, Enhancement of encoder and attention using target monolingual corpora in neural machine translation, 2018, Proceedings of the 2nd Workshop on Neural Machine Translation and Generation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_111",
            "start": 0,
            "end": 233,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_112@0",
            "content": "P Diederik, Jimmy Kingma,  Ba, Adam: A method for stochastic optimization, 2015, ICLR (Poster), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_112",
            "start": 0,
            "end": 96,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_113@0",
            "content": "Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ond\u0159ej Bojar, Alexandra Constantin, Evan Herbst, Moses: Open source toolkit for statistical machine translation, 2007, Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_113",
            "start": 0,
            "end": 480,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_114@0",
            "content": "Patrik Lambert, Holger Schwenk, Christophe Servan, Sadaf Abdul-Rauf, Investigations on translation model adaptation using monolingual data, 2011, Sixth Workshop on Statistical Machine Translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_114",
            "start": 0,
            "end": 197,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_115@0",
            "content": "UNKNOWN, None, 2018, Phrasebased & neural unsupervised machine translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_115",
            "start": 0,
            "end": 76,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_116@0",
            "content": "Guanlin Li, Lemao Liu, Guoping Huang, Conghui Zhu, Tiejun Zhao, Understanding data augmentation in neural machine translation: Two perspectives towards generalization, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_116",
            "start": 0,
            "end": 351,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_117@0",
            "content": "S Jun, Rong Liu, Wing Hung Chen,  Wong, Rejection control and sequential importance sampling, 1998, Journal of the American Statistical Association, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_117",
            "start": 0,
            "end": 149,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_118@0",
            "content": "UNKNOWN, None, 2001, Monte Carlo strategies in scientific computing, Springer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_118",
            "start": 0,
            "end": 77,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_119@0",
            "content": "Jonathan Mallinson, Rico Sennrich, Mirella Lapata, Paraphrasing revisited with neural machine translation, 2017, Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_119",
            "start": 0,
            "end": 222,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_120@0",
            "content": "UNKNOWN, None, 2020, Data diversification: A simple strategy for neural machine translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_120",
            "start": 0,
            "end": 93,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_121@0",
            "content": "Mohammad Norouzi, Samy Bengio, Navdeep Jaitly, Mike Schuster, Yonghui Wu, Dale Schuurmans, Reward augmented maximum likelihood for neural structured prediction, 2016, Advances In Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_121",
            "start": 0,
            "end": 218,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_122@0",
            "content": "Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, Michael Auli, fairseq: A fast, extensible toolkit for sequence modeling, 2019, Proceedings of NAACL-HLT 2019: Demonstrations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_122",
            "start": 0,
            "end": 217,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_123@0",
            "content": "Matt Post, A call for clarity in reporting BLEU scores, 2018, Proceedings of the Third Conference on Machine Translation: Research Papers, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_123",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_124@0",
            "content": "UNKNOWN, None, 2018, Style transfer through back-translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_124",
            "start": 0,
            "end": 62,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_125@0",
            "content": "UNKNOWN, None, , , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_125",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_126@0",
            "content": "UNKNOWN, None, 2018, Do cifar-10 classifiers generalize to cifar-10? arXiv preprint, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_126",
            "start": 0,
            "end": 85,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_127@0",
            "content": "Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, Vaishaal Shankar, Do imagenet classifiers generalize to imagenet, 2019, International Conference on Machine Learning, PMLR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_127",
            "start": 0,
            "end": 171,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_128@0",
            "content": "Rico Sennrich, Barry Haddow, Alexandra Birch, Improving neural machine translation models with monolingual data, 2016, Proceedings of the 54th, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_128",
            "start": 0,
            "end": 144,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_129@0",
            "content": "UNKNOWN, None, , Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_129",
            "start": 0,
            "end": 82,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_130@0",
            "content": "Rico Sennrich, Barry Haddow, Alexandra Birch, Improving neural machine translation models with monolingual data, 2016, Proceedings of the 54th, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_130",
            "start": 0,
            "end": 144,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_131@0",
            "content": "UNKNOWN, None, , Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_131",
            "start": 0,
            "end": 93,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_132@0",
            "content": "Ilya Sutskever, Oriol Vinyals, Quoc V Le, Sequence to sequence learning with neural networks, 2014, Advances in neural information processing systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_132",
            "start": 0,
            "end": 151,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_133@0",
            "content": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Attention is all you need, 2017, Advances in neural information processing systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_133",
            "start": 0,
            "end": 203,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_134@0",
            "content": "Shuo Wang, Yang Liu, Chao Wang, Huanbo Luan, Maosong Sun, Improving back-translation with uncertainty-based confidence estimation, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_134",
            "start": 0,
            "end": 314,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_135@0",
            "content": "Xinyi Wang, Hieu Pham, Zihang Dai, Graham Neubig, Switchout: an efficient data augmentation algorithm for neural machine translation, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_135",
            "start": 0,
            "end": 228,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_136@0",
            "content": "UNKNOWN, None, 2019, Detecting overfitting via adversarial examples, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_136",
            "start": 0,
            "end": 69,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_137@0",
            "content": "Lijun Wu, Yiren Wang, Yingce Xia, Tao Qin, Jianhuang Lai, Tie-Yan Liu, Exploiting monolingual data at scale for neural machine translation, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_137",
            "start": 0,
            "end": 323,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_138@0",
            "content": "Jiajun Zhang, Chengqing Zong, Exploiting source-side monolingual data in neural machine translation, 2016, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_138",
            "start": 0,
            "end": 195,
            "label": {}
        },
        {
            "ix": "414-ARR_v1_139@0",
            "content": "UNKNOWN, None, 2018, Style transfer as unsupervised machine translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "414-ARR_v1_139",
            "start": 0,
            "end": 73,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "414-ARR_v1_0",
            "tgt_ix": "414-ARR_v1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_0",
            "tgt_ix": "414-ARR_v1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_1",
            "tgt_ix": "414-ARR_v1_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_1",
            "tgt_ix": "414-ARR_v1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_0",
            "tgt_ix": "414-ARR_v1_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_2",
            "tgt_ix": "414-ARR_v1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_4",
            "tgt_ix": "414-ARR_v1_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_5",
            "tgt_ix": "414-ARR_v1_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_6",
            "tgt_ix": "414-ARR_v1_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_7",
            "tgt_ix": "414-ARR_v1_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_8",
            "tgt_ix": "414-ARR_v1_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_9",
            "tgt_ix": "414-ARR_v1_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_10",
            "tgt_ix": "414-ARR_v1_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_3",
            "tgt_ix": "414-ARR_v1_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_3",
            "tgt_ix": "414-ARR_v1_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_3",
            "tgt_ix": "414-ARR_v1_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_3",
            "tgt_ix": "414-ARR_v1_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_3",
            "tgt_ix": "414-ARR_v1_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_3",
            "tgt_ix": "414-ARR_v1_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_3",
            "tgt_ix": "414-ARR_v1_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_3",
            "tgt_ix": "414-ARR_v1_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_3",
            "tgt_ix": "414-ARR_v1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_0",
            "tgt_ix": "414-ARR_v1_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_11",
            "tgt_ix": "414-ARR_v1_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_13",
            "tgt_ix": "414-ARR_v1_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_14",
            "tgt_ix": "414-ARR_v1_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_15",
            "tgt_ix": "414-ARR_v1_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_16",
            "tgt_ix": "414-ARR_v1_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_17",
            "tgt_ix": "414-ARR_v1_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_18",
            "tgt_ix": "414-ARR_v1_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_19",
            "tgt_ix": "414-ARR_v1_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_20",
            "tgt_ix": "414-ARR_v1_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_12",
            "tgt_ix": "414-ARR_v1_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_12",
            "tgt_ix": "414-ARR_v1_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_12",
            "tgt_ix": "414-ARR_v1_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_12",
            "tgt_ix": "414-ARR_v1_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_12",
            "tgt_ix": "414-ARR_v1_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_12",
            "tgt_ix": "414-ARR_v1_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_12",
            "tgt_ix": "414-ARR_v1_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_12",
            "tgt_ix": "414-ARR_v1_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_12",
            "tgt_ix": "414-ARR_v1_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_12",
            "tgt_ix": "414-ARR_v1_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_0",
            "tgt_ix": "414-ARR_v1_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_21",
            "tgt_ix": "414-ARR_v1_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_22",
            "tgt_ix": "414-ARR_v1_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_22",
            "tgt_ix": "414-ARR_v1_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_22",
            "tgt_ix": "414-ARR_v1_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_23",
            "tgt_ix": "414-ARR_v1_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_25",
            "tgt_ix": "414-ARR_v1_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_26",
            "tgt_ix": "414-ARR_v1_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_27",
            "tgt_ix": "414-ARR_v1_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_28",
            "tgt_ix": "414-ARR_v1_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_29",
            "tgt_ix": "414-ARR_v1_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_31",
            "tgt_ix": "414-ARR_v1_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_32",
            "tgt_ix": "414-ARR_v1_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_24",
            "tgt_ix": "414-ARR_v1_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_24",
            "tgt_ix": "414-ARR_v1_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_24",
            "tgt_ix": "414-ARR_v1_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_24",
            "tgt_ix": "414-ARR_v1_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_24",
            "tgt_ix": "414-ARR_v1_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_24",
            "tgt_ix": "414-ARR_v1_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_24",
            "tgt_ix": "414-ARR_v1_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_24",
            "tgt_ix": "414-ARR_v1_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_24",
            "tgt_ix": "414-ARR_v1_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_24",
            "tgt_ix": "414-ARR_v1_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_22",
            "tgt_ix": "414-ARR_v1_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_33",
            "tgt_ix": "414-ARR_v1_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_35",
            "tgt_ix": "414-ARR_v1_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_34",
            "tgt_ix": "414-ARR_v1_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_34",
            "tgt_ix": "414-ARR_v1_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_34",
            "tgt_ix": "414-ARR_v1_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_0",
            "tgt_ix": "414-ARR_v1_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_36",
            "tgt_ix": "414-ARR_v1_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_37",
            "tgt_ix": "414-ARR_v1_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_37",
            "tgt_ix": "414-ARR_v1_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_37",
            "tgt_ix": "414-ARR_v1_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_38",
            "tgt_ix": "414-ARR_v1_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_40",
            "tgt_ix": "414-ARR_v1_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_41",
            "tgt_ix": "414-ARR_v1_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_42",
            "tgt_ix": "414-ARR_v1_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_43",
            "tgt_ix": "414-ARR_v1_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_39",
            "tgt_ix": "414-ARR_v1_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_39",
            "tgt_ix": "414-ARR_v1_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_39",
            "tgt_ix": "414-ARR_v1_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_39",
            "tgt_ix": "414-ARR_v1_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_39",
            "tgt_ix": "414-ARR_v1_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_39",
            "tgt_ix": "414-ARR_v1_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_37",
            "tgt_ix": "414-ARR_v1_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_44",
            "tgt_ix": "414-ARR_v1_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_46",
            "tgt_ix": "414-ARR_v1_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_47",
            "tgt_ix": "414-ARR_v1_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_48",
            "tgt_ix": "414-ARR_v1_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_49",
            "tgt_ix": "414-ARR_v1_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_50",
            "tgt_ix": "414-ARR_v1_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_51",
            "tgt_ix": "414-ARR_v1_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_52",
            "tgt_ix": "414-ARR_v1_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_53",
            "tgt_ix": "414-ARR_v1_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_54",
            "tgt_ix": "414-ARR_v1_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_55",
            "tgt_ix": "414-ARR_v1_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_56",
            "tgt_ix": "414-ARR_v1_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_57",
            "tgt_ix": "414-ARR_v1_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_45",
            "tgt_ix": "414-ARR_v1_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_45",
            "tgt_ix": "414-ARR_v1_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_45",
            "tgt_ix": "414-ARR_v1_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_45",
            "tgt_ix": "414-ARR_v1_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_45",
            "tgt_ix": "414-ARR_v1_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_45",
            "tgt_ix": "414-ARR_v1_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_45",
            "tgt_ix": "414-ARR_v1_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_45",
            "tgt_ix": "414-ARR_v1_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_45",
            "tgt_ix": "414-ARR_v1_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_45",
            "tgt_ix": "414-ARR_v1_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_45",
            "tgt_ix": "414-ARR_v1_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_45",
            "tgt_ix": "414-ARR_v1_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_45",
            "tgt_ix": "414-ARR_v1_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_45",
            "tgt_ix": "414-ARR_v1_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_0",
            "tgt_ix": "414-ARR_v1_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_58",
            "tgt_ix": "414-ARR_v1_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_59",
            "tgt_ix": "414-ARR_v1_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_59",
            "tgt_ix": "414-ARR_v1_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_61",
            "tgt_ix": "414-ARR_v1_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_62",
            "tgt_ix": "414-ARR_v1_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_63",
            "tgt_ix": "414-ARR_v1_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_60",
            "tgt_ix": "414-ARR_v1_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_60",
            "tgt_ix": "414-ARR_v1_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_60",
            "tgt_ix": "414-ARR_v1_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_60",
            "tgt_ix": "414-ARR_v1_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_60",
            "tgt_ix": "414-ARR_v1_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_59",
            "tgt_ix": "414-ARR_v1_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_64",
            "tgt_ix": "414-ARR_v1_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_59",
            "tgt_ix": "414-ARR_v1_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_65",
            "tgt_ix": "414-ARR_v1_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_67",
            "tgt_ix": "414-ARR_v1_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_68",
            "tgt_ix": "414-ARR_v1_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_69",
            "tgt_ix": "414-ARR_v1_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_70",
            "tgt_ix": "414-ARR_v1_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_66",
            "tgt_ix": "414-ARR_v1_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_66",
            "tgt_ix": "414-ARR_v1_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_66",
            "tgt_ix": "414-ARR_v1_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_66",
            "tgt_ix": "414-ARR_v1_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_66",
            "tgt_ix": "414-ARR_v1_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_66",
            "tgt_ix": "414-ARR_v1_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_59",
            "tgt_ix": "414-ARR_v1_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_71",
            "tgt_ix": "414-ARR_v1_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_73",
            "tgt_ix": "414-ARR_v1_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_72",
            "tgt_ix": "414-ARR_v1_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_72",
            "tgt_ix": "414-ARR_v1_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_72",
            "tgt_ix": "414-ARR_v1_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_59",
            "tgt_ix": "414-ARR_v1_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_74",
            "tgt_ix": "414-ARR_v1_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_76",
            "tgt_ix": "414-ARR_v1_77",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_77",
            "tgt_ix": "414-ARR_v1_78",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_78",
            "tgt_ix": "414-ARR_v1_79",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_79",
            "tgt_ix": "414-ARR_v1_80",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_80",
            "tgt_ix": "414-ARR_v1_81",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_81",
            "tgt_ix": "414-ARR_v1_82",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_82",
            "tgt_ix": "414-ARR_v1_83",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_75",
            "tgt_ix": "414-ARR_v1_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_75",
            "tgt_ix": "414-ARR_v1_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_75",
            "tgt_ix": "414-ARR_v1_78",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_75",
            "tgt_ix": "414-ARR_v1_79",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_75",
            "tgt_ix": "414-ARR_v1_80",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_75",
            "tgt_ix": "414-ARR_v1_81",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_75",
            "tgt_ix": "414-ARR_v1_82",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_75",
            "tgt_ix": "414-ARR_v1_83",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_75",
            "tgt_ix": "414-ARR_v1_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_0",
            "tgt_ix": "414-ARR_v1_84",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_83",
            "tgt_ix": "414-ARR_v1_84",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_85",
            "tgt_ix": "414-ARR_v1_86",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_86",
            "tgt_ix": "414-ARR_v1_87",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_87",
            "tgt_ix": "414-ARR_v1_88",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_88",
            "tgt_ix": "414-ARR_v1_89",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_89",
            "tgt_ix": "414-ARR_v1_90",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_90",
            "tgt_ix": "414-ARR_v1_91",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_84",
            "tgt_ix": "414-ARR_v1_85",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_84",
            "tgt_ix": "414-ARR_v1_86",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_84",
            "tgt_ix": "414-ARR_v1_87",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_84",
            "tgt_ix": "414-ARR_v1_88",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_84",
            "tgt_ix": "414-ARR_v1_89",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_84",
            "tgt_ix": "414-ARR_v1_90",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_84",
            "tgt_ix": "414-ARR_v1_91",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_84",
            "tgt_ix": "414-ARR_v1_85",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_0",
            "tgt_ix": "414-ARR_v1_92",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_91",
            "tgt_ix": "414-ARR_v1_92",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_92",
            "tgt_ix": "414-ARR_v1_93",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_92",
            "tgt_ix": "414-ARR_v1_93",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "414-ARR_v1_0",
            "tgt_ix": "414-ARR_v1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_1",
            "tgt_ix": "414-ARR_v1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_2",
            "tgt_ix": "414-ARR_v1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_2",
            "tgt_ix": "414-ARR_v1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_2",
            "tgt_ix": "414-ARR_v1_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_2",
            "tgt_ix": "414-ARR_v1_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_2",
            "tgt_ix": "414-ARR_v1_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_2",
            "tgt_ix": "414-ARR_v1_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_2",
            "tgt_ix": "414-ARR_v1_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_3",
            "tgt_ix": "414-ARR_v1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_4",
            "tgt_ix": "414-ARR_v1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_4",
            "tgt_ix": "414-ARR_v1_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_5",
            "tgt_ix": "414-ARR_v1_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_5",
            "tgt_ix": "414-ARR_v1_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_5",
            "tgt_ix": "414-ARR_v1_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_5",
            "tgt_ix": "414-ARR_v1_5@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_6",
            "tgt_ix": "414-ARR_v1_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_6",
            "tgt_ix": "414-ARR_v1_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_6",
            "tgt_ix": "414-ARR_v1_6@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_6",
            "tgt_ix": "414-ARR_v1_6@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_7",
            "tgt_ix": "414-ARR_v1_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_7",
            "tgt_ix": "414-ARR_v1_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_7",
            "tgt_ix": "414-ARR_v1_7@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_7",
            "tgt_ix": "414-ARR_v1_7@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_7",
            "tgt_ix": "414-ARR_v1_7@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_7",
            "tgt_ix": "414-ARR_v1_7@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_7",
            "tgt_ix": "414-ARR_v1_7@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_8",
            "tgt_ix": "414-ARR_v1_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_9",
            "tgt_ix": "414-ARR_v1_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_10",
            "tgt_ix": "414-ARR_v1_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_11",
            "tgt_ix": "414-ARR_v1_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_12",
            "tgt_ix": "414-ARR_v1_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_13",
            "tgt_ix": "414-ARR_v1_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_14",
            "tgt_ix": "414-ARR_v1_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_15",
            "tgt_ix": "414-ARR_v1_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_15",
            "tgt_ix": "414-ARR_v1_15@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_15",
            "tgt_ix": "414-ARR_v1_15@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_16",
            "tgt_ix": "414-ARR_v1_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_16",
            "tgt_ix": "414-ARR_v1_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_17",
            "tgt_ix": "414-ARR_v1_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_17",
            "tgt_ix": "414-ARR_v1_17@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_18",
            "tgt_ix": "414-ARR_v1_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_19",
            "tgt_ix": "414-ARR_v1_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_19",
            "tgt_ix": "414-ARR_v1_19@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_19",
            "tgt_ix": "414-ARR_v1_19@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_20",
            "tgt_ix": "414-ARR_v1_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_21",
            "tgt_ix": "414-ARR_v1_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_21",
            "tgt_ix": "414-ARR_v1_21@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_21",
            "tgt_ix": "414-ARR_v1_21@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_21",
            "tgt_ix": "414-ARR_v1_21@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_22",
            "tgt_ix": "414-ARR_v1_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_23",
            "tgt_ix": "414-ARR_v1_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_23",
            "tgt_ix": "414-ARR_v1_23@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_24",
            "tgt_ix": "414-ARR_v1_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_25",
            "tgt_ix": "414-ARR_v1_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_25",
            "tgt_ix": "414-ARR_v1_25@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_26",
            "tgt_ix": "414-ARR_v1_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_27",
            "tgt_ix": "414-ARR_v1_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_27",
            "tgt_ix": "414-ARR_v1_27@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_28",
            "tgt_ix": "414-ARR_v1_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_29",
            "tgt_ix": "414-ARR_v1_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_29",
            "tgt_ix": "414-ARR_v1_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_29",
            "tgt_ix": "414-ARR_v1_29@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_30",
            "tgt_ix": "414-ARR_v1_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_31",
            "tgt_ix": "414-ARR_v1_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_32",
            "tgt_ix": "414-ARR_v1_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_32",
            "tgt_ix": "414-ARR_v1_32@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_32",
            "tgt_ix": "414-ARR_v1_32@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_32",
            "tgt_ix": "414-ARR_v1_32@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_33",
            "tgt_ix": "414-ARR_v1_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_33",
            "tgt_ix": "414-ARR_v1_33@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_33",
            "tgt_ix": "414-ARR_v1_33@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_34",
            "tgt_ix": "414-ARR_v1_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_35",
            "tgt_ix": "414-ARR_v1_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_35",
            "tgt_ix": "414-ARR_v1_35@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_35",
            "tgt_ix": "414-ARR_v1_35@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_35",
            "tgt_ix": "414-ARR_v1_35@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_35",
            "tgt_ix": "414-ARR_v1_35@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_36",
            "tgt_ix": "414-ARR_v1_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_36",
            "tgt_ix": "414-ARR_v1_36@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_36",
            "tgt_ix": "414-ARR_v1_36@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_36",
            "tgt_ix": "414-ARR_v1_36@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_37",
            "tgt_ix": "414-ARR_v1_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_38",
            "tgt_ix": "414-ARR_v1_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_38",
            "tgt_ix": "414-ARR_v1_38@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_38",
            "tgt_ix": "414-ARR_v1_38@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_38",
            "tgt_ix": "414-ARR_v1_38@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_39",
            "tgt_ix": "414-ARR_v1_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_40",
            "tgt_ix": "414-ARR_v1_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_40",
            "tgt_ix": "414-ARR_v1_40@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_41",
            "tgt_ix": "414-ARR_v1_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_41",
            "tgt_ix": "414-ARR_v1_41@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_42",
            "tgt_ix": "414-ARR_v1_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_43",
            "tgt_ix": "414-ARR_v1_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_43",
            "tgt_ix": "414-ARR_v1_43@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_44",
            "tgt_ix": "414-ARR_v1_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_44",
            "tgt_ix": "414-ARR_v1_44@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_44",
            "tgt_ix": "414-ARR_v1_44@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_45",
            "tgt_ix": "414-ARR_v1_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_46",
            "tgt_ix": "414-ARR_v1_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_47",
            "tgt_ix": "414-ARR_v1_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_48",
            "tgt_ix": "414-ARR_v1_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_48",
            "tgt_ix": "414-ARR_v1_48@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_49",
            "tgt_ix": "414-ARR_v1_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_49",
            "tgt_ix": "414-ARR_v1_49@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_50",
            "tgt_ix": "414-ARR_v1_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_50",
            "tgt_ix": "414-ARR_v1_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_50",
            "tgt_ix": "414-ARR_v1_50@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_50",
            "tgt_ix": "414-ARR_v1_50@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_51",
            "tgt_ix": "414-ARR_v1_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_52",
            "tgt_ix": "414-ARR_v1_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_53",
            "tgt_ix": "414-ARR_v1_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_54",
            "tgt_ix": "414-ARR_v1_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_55",
            "tgt_ix": "414-ARR_v1_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_55",
            "tgt_ix": "414-ARR_v1_55@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_56",
            "tgt_ix": "414-ARR_v1_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_57",
            "tgt_ix": "414-ARR_v1_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_58",
            "tgt_ix": "414-ARR_v1_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_58",
            "tgt_ix": "414-ARR_v1_58@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_58",
            "tgt_ix": "414-ARR_v1_58@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_59",
            "tgt_ix": "414-ARR_v1_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_60",
            "tgt_ix": "414-ARR_v1_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_61",
            "tgt_ix": "414-ARR_v1_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_61",
            "tgt_ix": "414-ARR_v1_61@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_61",
            "tgt_ix": "414-ARR_v1_61@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_61",
            "tgt_ix": "414-ARR_v1_61@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_61",
            "tgt_ix": "414-ARR_v1_61@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_62",
            "tgt_ix": "414-ARR_v1_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_63",
            "tgt_ix": "414-ARR_v1_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_63",
            "tgt_ix": "414-ARR_v1_63@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_63",
            "tgt_ix": "414-ARR_v1_63@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_63",
            "tgt_ix": "414-ARR_v1_63@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_63",
            "tgt_ix": "414-ARR_v1_63@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_63",
            "tgt_ix": "414-ARR_v1_63@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_64",
            "tgt_ix": "414-ARR_v1_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_65",
            "tgt_ix": "414-ARR_v1_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_66",
            "tgt_ix": "414-ARR_v1_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_67",
            "tgt_ix": "414-ARR_v1_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_67",
            "tgt_ix": "414-ARR_v1_67@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_67",
            "tgt_ix": "414-ARR_v1_67@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_68",
            "tgt_ix": "414-ARR_v1_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_68",
            "tgt_ix": "414-ARR_v1_68@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_68",
            "tgt_ix": "414-ARR_v1_68@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_68",
            "tgt_ix": "414-ARR_v1_68@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_69",
            "tgt_ix": "414-ARR_v1_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_69",
            "tgt_ix": "414-ARR_v1_69@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_70",
            "tgt_ix": "414-ARR_v1_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_70",
            "tgt_ix": "414-ARR_v1_70@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_71",
            "tgt_ix": "414-ARR_v1_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_72",
            "tgt_ix": "414-ARR_v1_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_73",
            "tgt_ix": "414-ARR_v1_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_74",
            "tgt_ix": "414-ARR_v1_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_74",
            "tgt_ix": "414-ARR_v1_74@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_74",
            "tgt_ix": "414-ARR_v1_74@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_75",
            "tgt_ix": "414-ARR_v1_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_76",
            "tgt_ix": "414-ARR_v1_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_77",
            "tgt_ix": "414-ARR_v1_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_77",
            "tgt_ix": "414-ARR_v1_77@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_77",
            "tgt_ix": "414-ARR_v1_77@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_78",
            "tgt_ix": "414-ARR_v1_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_79",
            "tgt_ix": "414-ARR_v1_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_79",
            "tgt_ix": "414-ARR_v1_79@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_79",
            "tgt_ix": "414-ARR_v1_79@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_80",
            "tgt_ix": "414-ARR_v1_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_80",
            "tgt_ix": "414-ARR_v1_80@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_80",
            "tgt_ix": "414-ARR_v1_80@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_81",
            "tgt_ix": "414-ARR_v1_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_81",
            "tgt_ix": "414-ARR_v1_81@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_81",
            "tgt_ix": "414-ARR_v1_81@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_81",
            "tgt_ix": "414-ARR_v1_81@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_82",
            "tgt_ix": "414-ARR_v1_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_83",
            "tgt_ix": "414-ARR_v1_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_83",
            "tgt_ix": "414-ARR_v1_83@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_84",
            "tgt_ix": "414-ARR_v1_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_85",
            "tgt_ix": "414-ARR_v1_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_86",
            "tgt_ix": "414-ARR_v1_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_86",
            "tgt_ix": "414-ARR_v1_86@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_87",
            "tgt_ix": "414-ARR_v1_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_87",
            "tgt_ix": "414-ARR_v1_87@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_87",
            "tgt_ix": "414-ARR_v1_87@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_87",
            "tgt_ix": "414-ARR_v1_87@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_87",
            "tgt_ix": "414-ARR_v1_87@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_87",
            "tgt_ix": "414-ARR_v1_87@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_88",
            "tgt_ix": "414-ARR_v1_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_88",
            "tgt_ix": "414-ARR_v1_88@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_89",
            "tgt_ix": "414-ARR_v1_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_89",
            "tgt_ix": "414-ARR_v1_89@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_89",
            "tgt_ix": "414-ARR_v1_89@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_90",
            "tgt_ix": "414-ARR_v1_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_90",
            "tgt_ix": "414-ARR_v1_90@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_90",
            "tgt_ix": "414-ARR_v1_90@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_91",
            "tgt_ix": "414-ARR_v1_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_91",
            "tgt_ix": "414-ARR_v1_91@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_91",
            "tgt_ix": "414-ARR_v1_91@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_92",
            "tgt_ix": "414-ARR_v1_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_93",
            "tgt_ix": "414-ARR_v1_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_93",
            "tgt_ix": "414-ARR_v1_93@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_93",
            "tgt_ix": "414-ARR_v1_93@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_94",
            "tgt_ix": "414-ARR_v1_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_95",
            "tgt_ix": "414-ARR_v1_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_96",
            "tgt_ix": "414-ARR_v1_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_97",
            "tgt_ix": "414-ARR_v1_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_98",
            "tgt_ix": "414-ARR_v1_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_99",
            "tgt_ix": "414-ARR_v1_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_100",
            "tgt_ix": "414-ARR_v1_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_101",
            "tgt_ix": "414-ARR_v1_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_102",
            "tgt_ix": "414-ARR_v1_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_103",
            "tgt_ix": "414-ARR_v1_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_104",
            "tgt_ix": "414-ARR_v1_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_105",
            "tgt_ix": "414-ARR_v1_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_106",
            "tgt_ix": "414-ARR_v1_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_107",
            "tgt_ix": "414-ARR_v1_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_108",
            "tgt_ix": "414-ARR_v1_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_109",
            "tgt_ix": "414-ARR_v1_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_110",
            "tgt_ix": "414-ARR_v1_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_111",
            "tgt_ix": "414-ARR_v1_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_112",
            "tgt_ix": "414-ARR_v1_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_113",
            "tgt_ix": "414-ARR_v1_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_114",
            "tgt_ix": "414-ARR_v1_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_115",
            "tgt_ix": "414-ARR_v1_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_116",
            "tgt_ix": "414-ARR_v1_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_117",
            "tgt_ix": "414-ARR_v1_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_118",
            "tgt_ix": "414-ARR_v1_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_119",
            "tgt_ix": "414-ARR_v1_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_120",
            "tgt_ix": "414-ARR_v1_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_121",
            "tgt_ix": "414-ARR_v1_121@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_122",
            "tgt_ix": "414-ARR_v1_122@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_123",
            "tgt_ix": "414-ARR_v1_123@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_124",
            "tgt_ix": "414-ARR_v1_124@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_125",
            "tgt_ix": "414-ARR_v1_125@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_126",
            "tgt_ix": "414-ARR_v1_126@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_127",
            "tgt_ix": "414-ARR_v1_127@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_128",
            "tgt_ix": "414-ARR_v1_128@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_129",
            "tgt_ix": "414-ARR_v1_129@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_130",
            "tgt_ix": "414-ARR_v1_130@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_131",
            "tgt_ix": "414-ARR_v1_131@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_132",
            "tgt_ix": "414-ARR_v1_132@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_133",
            "tgt_ix": "414-ARR_v1_133@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_134",
            "tgt_ix": "414-ARR_v1_134@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_135",
            "tgt_ix": "414-ARR_v1_135@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_136",
            "tgt_ix": "414-ARR_v1_136@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_137",
            "tgt_ix": "414-ARR_v1_137@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_138",
            "tgt_ix": "414-ARR_v1_138@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "414-ARR_v1_139",
            "tgt_ix": "414-ARR_v1_139@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 1320,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "position_tag_type": "from_draft",
        "doc_id": "414-ARR",
        "version": 1
    }
}