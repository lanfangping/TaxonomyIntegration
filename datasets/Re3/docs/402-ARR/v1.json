{
    "nodes": [
        {
            "ix": "402-ARR_v1_0",
            "content": "WatClaimCheck: A new Dataset for Claim Entailment and Inference",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_2",
            "content": "We contribute a new dataset for the task of automated fact checking and an evaluation of state of the art algorithms. The dataset includes claims (from speeches, interviews, social media and news articles), review articles published by professional fact checkers and premise articles used by those professional fact checkers to support their review and verify the veracity of the claims. An important challenge in the use of premise articles is the identification of relevant passages that will help to infer the veracity of a claim. We show that transferring a dense passage retrieval model trained with review articles improves the retrieval quality of passages in premise articles. We report results for the prediction of claim veracity by inference from premise articles.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "402-ARR_v1_4",
            "content": "The rise of social media has lead to a democratization of news, but it has also amplified issues related to fake news and misinformation. To that effect, many fact checking organizations (e.g., Politifact, Snopes, AFP Fact Check, Alt News, FactCheck.org, Africa Check, etc.) have emerged around the globe. They investigate debatable claims made by authorities, politicians, celebrities and the public. For each claim, they publish a review article with links to sources that support a verdict (e.g., true, partly true/false, false) about the veracity of the claim. Those reviews debunk false claims and mitigate the spread of misinformation. We consider a key NLP challenge in the context of automated fact checking: claim inference from premise articles. Note that determining the veracity of a claim without additional information is nearly impossible since claims are selected by professional fact checkers in part because their veracity is far from obvious and also because of their degree of controversy. To that effect, professional fact checkers invest a fair amount of time to research each claim by finding relevant sources and publishing a review article that explains their verdict of the claim. Hence there is a natural entailment problem, whereby anyone who reads a review article should be able to arrive at the same verdict as the professional fact checker regarding the claim. Unlike many entailment tasks that consist of short text (e.g., pairs of utterances) that may be artificially generated or extracted, this is a natural and challenging entailment task that involves an entire document (review article) with an utterance (claim) that requires a certain degree of reading comprehension. We note that this entailment problem has been tackled in some previous work (Augenstein et al., 2019;Shu et al., 2018;Nakov et al., 2021) and although it is a challenging NLP problem, it does not correspond to the problem that professional fact checkers need to solve.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_5",
            "content": "In this paper, we focus on the harder problem of claim inference from premise articles. This is part of the challenge that professional fact checkers face. They find premise articles that contain relevant facts and then infer the veracity of the claim based on those facts. Unlike many existing inference tasks where it is sufficient to use one or a few facts in a few sentences (Storks et al., 2019;Schlegel et al., 2020), information from a set of premise articles must be distilled and combined in non trivial ways to infer the veracity of a claim.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_6",
            "content": "We assembled a dataset of 33,697 claims made between December 1996 and July 2021 with associated review articles, premise articles and claim verdicts. While some other datasets include claims with associated verdicts and in some cases review articles as well as search engine results, this is the first dataset that includes premise articles, therefore enabling the inference task described above.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_7",
            "content": "Since there are several premise articles for a given claim and each premise article may be long, a simple two-stage approach to identify relevant passages would consist of a lightweight retrieval technique in a first stage, followed by a heavyweight inference technique applied to those passages. When the first stage fails to retrieve some key passages, then the inferred verdict will be negatively affected regardless of how good the second stage is. To that effect, several supervised dense passage retrieval techniques have been proposed in the past for question-answering (Karpukhin et al., 2020;. Unfortunately, we cannot directly apply those techniques since we do not have labels for the relevant passages in our inference task. Instead, we show how to use the review articles to train a supervised dense retrieval technique that is then transferred to premise articles.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_8",
            "content": "The contributions of the paper can be summarized as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_9",
            "content": "\u2022 New dataset of claims with review and premise articles for claim inference in automated fact checking; \u2022 Novel use of review articles to transfer a dense retrieval technique to premise articles; \u2022 Experiments establishing the state of the art for claim inference.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_10",
            "content": "The paper is organized as follows. Section 2 reviews previous work related to automated fact checking and claim verification. Section 3 describes the new dataset and summarizes the differences with previous datasets for claim verification. Section 4 describes a two-stage process to i) extract evidence sentences from premise articles and ii) infer the veracity of claims. This section also explains how to transfer a dense passage retrieval technique trained with review articles to premise articles. Section 5 reports the results for the claim veracity inference task. Finally, Section 6 concludes and discusses possible future work.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_11",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "402-ARR_v1_12",
            "content": "There is an important line of work that focuses on claim verification. This includes techniques that predict the veracity of a claim based on the text of the claim only (Rashkin et al., 2017), linguistic features (Popat et al., 2017), meta information about the claimant (e.g., name, job, party affiliation, veracity history) (Wang, 2017b), review articles (Augenstein et al., 2019;Shu et al., 2018;Nakov et al., 2021), as well as relevant articles returned by a search engine (Popat et al., 2018;Augenstein et al., 2019;Mishra and Setty, 2019). To the best of our knowledge, none of the existing work considers the problem of claim verification based on premise articles. There is an important distinction between articles returned by a search engine in previous work and the premise articles that we consider. The techniques that use a search engine to find articles related to a claim query the search engine after a fact checking website has published a review article and therefore end up retrieving articles that include the review article as well as other articles that summarize and/or discuss the verdict of the fact checking website. Hence they are tackling an entailment problem. In contrast, the premise articles that we consider are the source articles used by a fact checker before publishing a review article. Those articles contain relevant facts, but not a summary or discussion of the review article since they are published before the review article and in fact serve as premises for the review article.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_13",
            "content": "Closely related to claim verification is the problem of fake news detection. In this problem, the credibility of an entire news article is evaluated. The credibility of a news article can be estimated based on linguistic and textual features (Conroy et al., 2015;Reis et al., 2019;Li et al., 2019), discourse level structure (Karimi and Tang, 2019), network analysis (Conroy et al., 2015), knowledge graphs (Cui et al., 2020), inter-user behaviour dynamics (Gangireddy et al., 2020) or a combination of multiple modalities . Some techniques reorder the articles returned by a search engine based on their degree of credibility (Olteanu et al., 2013;Beylunioglu, 2020). An important task that can help the detection of fake news is the task of stance detection (Borges et al., 2019;Jwa et al., 2019), i.e., does the content of an article agree or disagree with the title of the article? The following surveys summarize existing work on fake news detection: (Kumar and Shah, 2018;Bondielli and Marcelloni, 2019).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_14",
            "content": "3 Fact Checking Dataset",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_15",
            "content": "Data Collection",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "402-ARR_v1_16",
            "content": "We collect fact checked claims, along with a review articles, premise articles, and claim metadata from the following eight fact checking services: Politifact, Snopes, AFP Fact Check, Alt News, FactCheck.org, Africa Check, USA Today, and Full Fact. We utilize Google's fact check tool APIs 1 to collect the claims' metadata for all previously listed fact checking services except Politifact and Snopes. The claims' metadata collected from Google's fact check tool APIs include the claim review article URL, which is used to retrieve the claim review article. The claim review articles published by some of the fact checking services provide the premise article URLs in a separate section while others provide the URLs as inline links in the review article body. We carefully parse the article body, retrieving the premise article URLs used in the claim review article to justify the claim veracity. Finally, the premise article URLs are used to retrieve the premise articles. We try to directly retrieve the article where possible, but also use archive.org's APIs in case the premise article URL is no longer available online. We follow the same general procedure for data collection from Politifact and Snopes except that instead of using Google's fact check tool APIs for collecting claims and associated metadata, we directly crawl the respective websites to collect the data.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_17",
            "content": "We only perform some basic cleanup to the collected data before inclusion in the dataset. This includes removing articles behind paywalls, removing claims with less than two premise articles, and removing non-textual premise sources. We obtain premise article text from their HTML pages by loading the HTML files into a text based web browser (Links browser) and then dumping the web page text into a text file. This allows us to bypass the CSS styling and JavaScript code included in the HTML pages and obtain only the text displayed to end users. Admittedly, this still does not eliminate the auxiliary text usually present in the web pages such as navigation links, footer text, recommended links, etc. We include both the HTML and text version of the premise articles. We perform minimal cleanup in order for our dataset to reflect the real life challenges present in the task of automated fact checking. We also map the numerous claim veracity labels used by the fact checking websites into three broad labels: True, Partially True/False, and False.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_18",
            "content": "WatClaimCheck Dataset",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "402-ARR_v1_19",
            "content": "The contributed dataset contains a total of 33,697 claims. We split those claims into the following three sets: training set containing 26,957 claims, validation set containing 3369 claims, and test set containing 3371 claims. For each claim in the dataset, we provide the following data: ID, Here Original Rating refers to the rating assigned by a fact checking organization and Rating corresponds to our mapping of the original rating to true, partly true/false and false. We provide both the HTML and extracted text files for the review and premise articles.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_20",
            "content": "Figure 1 shows the number of claims collected from each of the fact checking services. Figure 2 shows the claim rating distribution. We see that the claims in the Partially True/False and False categories significantly outnumber the claims in the True category. In reality, the number of true claims is much larger then the number of partially true/false and false claims, but fact checking services focus on debunking controversial claims and therefore the majority of the claims they investigate are false or partially true/false. This imbalance poses an important challenge for the models.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_21",
            "content": "Comparison with existing Datasets",
            "ntype": "title",
            "meta": {
                "section": "3.3"
            }
        },
        {
            "ix": "402-ARR_v1_22",
            "content": "We compare our proposed dataset with other publicly available fact checking related datasets in Table 1. We can broadly classify the fact checking datasets into two different categories: (1) veracity detection datasets based only on claim text and some metadata, but without supporting evidence documents (Wang, 2017a;P\u00e9rez-Rosas et al., 2018) and (2) datasets that provide claim text along with supporting evidence and/or context documents. We observe that the datasets that provide some evidence or context documents can be further subcategorized: (1) datasets that provide social media posts and comments related to the claim (Mitra and Gilbert, 2015;Nakamura et al., 2020;Shu et al., 2018), (2) datasets that retrieve supporting evidence for the claims by performing a web search using queries obtained from lexical and semantic features of the claim text (Baly et al., 2018;Augenstein et al., 2019), and (3) datasets that provide Wikipedia pages as supporting evidence (Thorne et al., 2018). Our proposed dataset provides the documents cited by the professional fact checkers in the claim review article to justify their claim rating. We argue that our dataset reflects the real world task of automated veracity detection more truthfully due to the availability of the premise articles cited by the professional fact checkers in claim review articles. Although, social media posts and comments can sometimes be helpful in claim veracity detection they are rarely treated as authoritative sources of information. Using a web search to retrieve evidence documents for a claim is problematic due to the fact that once a fact checking service has fact checked a claim, we observe that multiple other news agency also publish articles referencing the original fact checking review article. Retrieving top-k web search results, typically retrieves those articles as well. This can indirectly leak the veracity label in the retrieved documents.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_23",
            "content": "Models",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "402-ARR_v1_24",
            "content": "We develop a two-stage system to perform evidence based veracity detection. The first stage selects relevant sentence level evidence from the premise articles associated with a claim and the second stage performs claim veracity inference using the claim text and selected evidence sentences. For the first stage, we use and evaluate two different approaches. The first approach is the well-known and commonly used basic text retrieval technique called term frequency inverse document frequency (TF-IDF). For the second approach, we propose a novel way to adapt dense passage retrieval techniques using the review articles for evidence sentence selection. In our experiments, the aforementioned dense passage retrieval technique outperforms TF-IDF text retrieval and leads to overall system performance improvements. The second stage consists of training deep learning models to perform claim veracity inference using the claim text and selected evidence. We utilize multiple deep learning models to perform claim veracity inference ranging from basic bi-directional recurrent networks to state of the art transformers.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_25",
            "content": "Problem Formulation",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "402-ARR_v1_26",
            "content": "We represent a claim containing l tokens as C n = {c 1 , c 2 , . . . , c l }, where n \u2208 [1, N ] and N is the size of the dataset. Each claim is associated with multiple premise articles, we represent the k-th premise article associated with the n-th claim containing m sentences as A n,k = {s P n,1 , s P n,2 , . . . , s P n,m } where s n,i represents the i-th sentence. Similarly, we represent the review article associated with the claim",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_27",
            "content": "C n containing m sentences by R n = {s R n,1 , s R n,2 , . . . , s R n,m }.",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_28",
            "content": "For a given claim C n , we represent its ground truth veracity label by y n .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_29",
            "content": "We cast the problem as a textual inference problem. Given a claim C n and a set of associated premise articles A, our goal is to predict the ground truth veracity y n of the claim.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_30",
            "content": "Stage-1: Evidence Sentence Extraction",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "402-ARR_v1_31",
            "content": "One of the key steps in the fact checking process performed by human professional fact checkers is examining the premise articles associated with a claim and extracting useful evidence from them to establish claim veracity. Our first stage seeks to perform a similar task. Each claim in our dataset has multiple associated premise articles with each article containing a large amount of text. Our goal in the first stage is to rank the evidence available in the associated premise articles at the sentence level and extract the ones which are most useful and impactful for veracity detection in the second stage. Our experiments show that an improvement in this stage directly contributes to an overall improvement in the veracity detection performance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_32",
            "content": "TF-IDF",
            "ntype": "title",
            "meta": {
                "section": "4.2.1"
            }
        },
        {
            "ix": "402-ARR_v1_33",
            "content": "TF-IDF based similarity measure is commonly used in NLP tasks to retrieve texts similar to the target text from a large corpus. We use TF-IDF based similarity measure between the claim text and the premise article sentences to rank the sentence level evidence. Top ranked sentences are used in the second stage to perform veracity detection. This approach is similar to the one used by Thorne et al. (2018) to extract evidence sentences from Wikipedia articles for fact checking.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_34",
            "content": "Dense Passage Retrieval",
            "ntype": "title",
            "meta": {
                "section": "4.2.2"
            }
        },
        {
            "ix": "402-ARR_v1_35",
            "content": "We propose a novel way of adapting dense passage retrieval methods proposed by Karpukhin et al. (2020) for open domain question answering to the task of retrieving evidence sentences from premise articles. The dense passage retrieval method proposed by Karpukhin et al. (2020) uses a dual encoder architecture. Each encoder is implemented using BERT (Devlin et al., 2018). The question encoder E Q and the passage encoder E P embed a given question q and passage p into d-dimensional real-valued vectors. The similarity between the question and passage is defined as the dot product of their vectors:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_36",
            "content": "sim(q, p) = E Q (q) T E P (p) (1)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_37",
            "content": "The model is then trained to learn embedding functions such that the similarity score between relevant pairs of questions and passages will be higher than irrelevant ones.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_38",
            "content": "We adapt this method for our first stage by taking advantage of the fact that the review article published by fact checking websites along with a claim typically contains key evidence taken from the premise articles. The evidence taken from the premise articles is usually paraphrased in order to form a coherent argument in support of the claim veracity verdict.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_39",
            "content": "To train the dense passage retrieval model for stage-1, we use the claims and the associated review articles in the training set of our dataset. We form positive pairs using the claim and the sentences from the associated review article. The negative pairs are formed using a claim and a sentence from a review article not associated with that claim. Let",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_40",
            "content": "D = { C i , s R+ i,j , s R\u2212 i,1 , s R\u2212 i,2 , . . . , s R\u2212 i,n |R i | j=1 } N i=1",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_41",
            "content": "be the training data containing N i=1 |R i | instances where N is the number of claims in the training set, |R i | is the number of sentences in the review article associated with the i-th claim. Each instance is made up of a claim C i with one positive sentence from the associated review article s R+ i,j and n randomly chosen negative sentences s R\u2212 i,k . We train the model by optimizing the negative log likelihood of the positive sentences:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_42",
            "content": "L(C i , s R+ i,j , s R\u2212 i,1 , s R\u2212 i,2 , . . . , s R\u2212 i,n ) = \u2212log e sim(C i ,s R+ i,j ) e sim(C i ,s R+ i,j ) + n k=1 e sim(C i ,s R\u2212 i,k )(2)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_43",
            "content": "We evaluate the model using the claims and the associated review articles in the validation and test set. For model evaluation, we use the top-k recall rate for retrieving the review article sentences corresponding to the claims in the validation and test set using the similarity score. The review article sentences are retrieved from the corpus formed by all the sentences from every review article in the corresponding set.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_44",
            "content": "After training the model, we use the encoders to encode the claim text and the sentences of the associated premise articles. We compute the similarity score using the dot product between the encoded claim vector and the premise article sentences. We use the top scoring sentences as evidence sentences in the next stage to perform the claim veracity inference.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_45",
            "content": "Stage-2: Claim Veracity Inference",
            "ntype": "title",
            "meta": {
                "section": "4.3"
            }
        },
        {
            "ix": "402-ARR_v1_46",
            "content": "In this section, we describe how several popular sequence models are used to classify a claim as true, partly true/false or false based on the text of the claim, the claimant and the evidence sentences extracted in stage 1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_47",
            "content": "Bi-LSTM and Bi-GRU",
            "ntype": "title",
            "meta": {
                "section": "4.3.1"
            }
        },
        {
            "ix": "402-ARR_v1_48",
            "content": "We first consider bi-directional long short term memory (Bi-LSTM) networks and bi-directional gated recurrent units (Bi-GRUs). The evidence sentences of each premise article are concatenated with the claim and claimant, and then encoded by a Bi-LSTM or Bi-GRU into a latent vector. For N premise articles, the resulting N vectors are then averaged and passed through a softmax layer with 3 outputs corresponding to the predicted probabilities of true, partly true/false and false.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_49",
            "content": "HAN",
            "ntype": "title",
            "meta": {
                "section": "4.3.2"
            }
        },
        {
            "ix": "402-ARR_v1_50",
            "content": "Instead of concatenating the evidence sentences of each premise article into a long sequence, we can also use hierarchical attention networks (HANs) (Yang et al., 2016;Mishra and Setty, 2019) to compute sentence level embeddings that are then combined into article level embeddings. A HAN is used to embed each premise article with the claim as follows. At the bottom of a HAN, each sentence (claimant with claim text or each evidence sentence of the premise article) is embedded as a sequence of hidden vectors (one per word) by a bi-directional recurrent network (Bi-LSTM or Bi-GRU). Then, a word-level attention layer computes a sentence level embedding. Next, those embeddings are fed to another bi-directional recurrent network (Bi-LSTM or Bi-GRU) that computes a sequence of hidden vectors (one per sentence) and a sentence level attention layer computes an embedding for the document-claim pair. Finally, the embeddings of the document-claim pairs are averaged and passed through a softmax over the labels true, partly true/false and false.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_51",
            "content": "Transformer",
            "ntype": "title",
            "meta": {
                "section": "4.3.3"
            }
        },
        {
            "ix": "402-ARR_v1_52",
            "content": "We finetune a RoBERTa-base (Liu et al., 2019) model to perform claim veracity inference using the claim and the evidence sentences. We concatenate the claim text, the name of the claimant, and the evidence sentences extracted for that particular claim in the first stage to build a training data instance. The input sequence is encoded using the RoBERTa-base model and passed through a dense linear layer followed by a softmax layer to obtain the predicted claim veracity label distribution. We use the cross entropy loss function to train the model.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_53",
            "content": "Experiments",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "402-ARR_v1_54",
            "content": "We evaluate the two-stage process and the algorithms described in the previous section on the claim inference problem with our new dataset.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_55",
            "content": "Stage-1 Results",
            "ntype": "title",
            "meta": {
                "section": "5.1"
            }
        },
        {
            "ix": "402-ARR_v1_56",
            "content": "In order to reduce the computational resources and memory requirements, we implement the encoders in the dense passage retrieval model using Distil-RoBERTa (Dis). We use a batch size of 64 and the in-batch negatives technique as described in (Karpukhin et al., 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_57",
            "content": "We evaluate the stage-1 methods by comparing their performance using the top-k recall rate metric. The claim text is used to retrieve the ground truth review article sentences from the corpus containing all the sentences of all the review articles in the test set. We report the top-k recall rate for k = 10, 25, 50, 100 in Table 2. The results clearly show that the DPR (dense passage retrieval) method outperforms the TF-IDF similarity based method.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_58",
            "content": "Stage-2 Results",
            "ntype": "title",
            "meta": {
                "section": "5.2"
            }
        },
        {
            "ix": "402-ARR_v1_59",
            "content": "To evaluate whether the inference models in stage-2 can do better with the inclusion of additional evidence sentences, we perform the experiments in stage-2 in two settings: Pooled and Averaged.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_60",
            "content": "Pooled: In this setting, for each claim we pool all the sentences from every associated premise article and rank them using the similarity score. The sentences with top scores are then used to perform claim veracity inference. For each claim, we get exactly one data instance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_61",
            "content": "Averaged: This refers to the setting where we generate one data instance per claim and associated premise article. So, if a claim has m premise articles, we get m data instances. For each premise article associated with a claim, we score the sentences from that article and extract the top scoring sentences to form a data instance. During training, each data instance for a claim is used independently, but during inference, we compute the average of the claim veracity prediction distributions of the data instances associated with a single claim. We show in our reported results that the inclusion of additional evidence in the form of m data instances per claim (instead of 1 data instance for the pooled setting) does improve the performance when the retrieval method of stage 1 is not very effective. We use macro F1 as the evaluation metric. We report the results in Table 3. We report all the hyper parameters used in our experiments in the appendix. The best performance when doing the claim veracity inference is obtained by using the DPR model in the first stage and the RoBERTa-base model in the second stage. We also report results for claim entailment from the review articles as an upper bound on the accuracy that could be achieved for claim inference based on the premise articles.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_62",
            "content": "Prequential Results",
            "ntype": "title",
            "meta": {
                "section": "5.2.1"
            }
        },
        {
            "ix": "402-ARR_v1_63",
            "content": "We note that the traditional experimental setup of dividing a dataset at random into train, validation and test does not reflect the streaming nature of claims. When new topics arise (i.e., election, covid-19), the nature of the claims and the premise articles changes. Randomly splitting the dataset into train/validation/test ensures that all claim topics are well represented across the train/validation/test splits, which would not be the case in practice. In reality, when a new topic arises, the test split may have new types of claims that are not well represented in the train/validation splits. To evaluate the effect of this distribution shift over time, we performed a prequential evaluation (Bifet et al., 2015). More precisely, we divide the dataset into subsets corresponding to periods of 6 months. We repeatedly evaluate the performance for each 6-month period by treating the claims in that period as the test set and the claims in previous periods as the train/validation sets. This corresponds to a realistic setting where a claim verification algorithm may be re-trained every 6 months on the data seen so far to predict the veracity of the claims for the next 6 months. Naturally, the time period between each re-training iteration may be shorter than 6 months in practice. We chose 6 months simply to ensure that the size of the test set would be large enough to obtain reliable results.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_64",
            "content": "Figure 3 shows the number of claims investigated in each 6-month period in our dataset. We note two peaks. The first one in 2016 corresponds to a sudden surge of claims investigated by some fact checking websites regarding India politics. The second peak in 2020 corresponds to the 2020 US presidential election and the start of the covid-19 pandemic. Figure 4 shows the macro F1 results achieved by the top 4 algorithms with DPR evidence in each 6-month period. We note that the prequential results are significantly lower than the results in the DPR column of Table 3. This drop of accuracy is precisely due to the distribution shift of claims that naturally occurs over time. We also note a trend whereby the accuracy increases as time passes by. This is explained by the fact that more data is available for training in later time periods. We strongly recommend that future algorithms be evaluated in prequential mode since this evaluation setup is more realistic.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_65",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "402-ARR_v1_66",
            "content": "This paper introduces a new dataset for automated fact checking. It is the first dataset that includes premise articles used by professional fact checkers and therefore corresponds more closely to the task of claim veracity inference in automated fact checking. An important challenge is the extraction of relevant facts from the premise articles since it is not generally possible to apply heavyweight models on the entire content of all premise articles. To that effect, we described how to train the encoders of a dense passage retrieval technique with the review articles and then transfer the resulting retrieval technique to the premise articles. This increased the overall performance of the claim verification algorithms. We also performed a prequential evaluation that highlighted an important distribution shift that caused a significant drop in accuracy for all algorithms. We strongly recommend that future algorithms be evaluated in prequential mode. In fact, an important direction for future research would be to design algorithms based on transfer learning or domain generalization that can cope better with this distributional shift. We also note that the techniques that we evaluated are black boxes and therefore it is not clear how they do inference. Hence, another direction for future research would be to develop inference techniques that are explainable in the sense that they could provide explanations to the users to justify their veracity prediction for a claim.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "402-ARR_v1_67",
            "content": "UNKNOWN, None, , Distilroberta model, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Distilroberta model",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_68",
            "content": "Isabelle Augenstein, Christina Lioma, Dongsheng Wang, Lucas Lima, Casper Hansen, Christian Hansen, Jakob Simonsen, MultiFC: A real-world multi-domain dataset for evidence-based fact checking of claims, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Isabelle Augenstein",
                    "Christina Lioma",
                    "Dongsheng Wang",
                    "Lucas Lima",
                    "Casper Hansen",
                    "Christian Hansen",
                    "Jakob Simonsen"
                ],
                "title": "MultiFC: A real-world multi-domain dataset for evidence-based fact checking of claims",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_69",
            "content": "Joan Bachenko, Eileen Fitzpatrick, Michael Schonwetter, Verification and implementation of language-based deception indicators in civil and criminal narratives, 2008, Proceedings of the 22nd International Conference on Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "Joan Bachenko",
                    "Eileen Fitzpatrick",
                    "Michael Schonwetter"
                ],
                "title": "Verification and implementation of language-based deception indicators in civil and criminal narratives",
                "pub_date": "2008",
                "pub_title": "Proceedings of the 22nd International Conference on Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_70",
            "content": "Ramy Baly, Mitra Mohtarami, James Glass, Llu\u00eds M\u00e0rquez, Alessandro Moschitti, Preslav Nakov, Integrating stance detection and fact checking in a unified corpus, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Ramy Baly",
                    "Mitra Mohtarami",
                    "James Glass",
                    "Llu\u00eds M\u00e0rquez",
                    "Alessandro Moschitti",
                    "Preslav Nakov"
                ],
                "title": "Integrating stance detection and fact checking in a unified corpus",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "402-ARR_v1_71",
            "content": "UNKNOWN, None, 2020, Using a credibility classifier to improve health-related information retrieval, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Using a credibility classifier to improve health-related information retrieval",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_72",
            "content": "Albert Bifet, Gianmarco De Francisci, Jesse Morales, Geoff Read, Bernhard Holmes,  Pfahringer, Efficient online evaluation of big data stream classifiers, 2015, Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "Albert Bifet",
                    "Gianmarco De Francisci",
                    "Jesse Morales",
                    "Geoff Read",
                    "Bernhard Holmes",
                    " Pfahringer"
                ],
                "title": "Efficient online evaluation of big data stream classifiers",
                "pub_date": "2015",
                "pub_title": "Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_73",
            "content": "Alessandro Bondielli, Francesco Marcelloni, A survey on fake news and rumour detection techniques, 2019, Information Sciences, .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "Alessandro Bondielli",
                    "Francesco Marcelloni"
                ],
                "title": "A survey on fake news and rumour detection techniques",
                "pub_date": "2019",
                "pub_title": "Information Sciences",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_74",
            "content": "Lu\u00eds Borges, Bruno Martins, P\u00e1vel Calado, Combining similarity features and deep representation learning for stance detection in the context of checking fake news, 2019, Journal of Data and Information Quality (JDIQ), .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Lu\u00eds Borges",
                    "Bruno Martins",
                    "P\u00e1vel Calado"
                ],
                "title": "Combining similarity features and deep representation learning for stance detection in the context of checking fake news",
                "pub_date": "2019",
                "pub_title": "Journal of Data and Information Quality (JDIQ)",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_75",
            "content": "K Nadia, Victoria Conroy, Yimin Rubin,  Chen, Automatic deception detection: Methods for finding fake news, 2015, Proceedings of the Association for Information Science and Technology, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "K Nadia",
                    "Victoria Conroy",
                    "Yimin Rubin",
                    " Chen"
                ],
                "title": "Automatic deception detection: Methods for finding fake news",
                "pub_date": "2015",
                "pub_title": "Proceedings of the Association for Information Science and Technology",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_76",
            "content": "Limeng Cui, Haeseung Seo, Maryam Tabar, Fenglong Ma, Suhang Wang, Dongwon Lee, Deterrent: Knowledge guided graph attention network for detecting healthcare misinformation, 2020, Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Limeng Cui",
                    "Haeseung Seo",
                    "Maryam Tabar",
                    "Fenglong Ma",
                    "Suhang Wang",
                    "Dongwon Lee"
                ],
                "title": "Deterrent: Knowledge guided graph attention network for detecting healthcare misinformation",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_77",
            "content": "UNKNOWN, None, 2018, BERT: pre-training of deep bidirectional transformers for language understanding, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "BERT: pre-training of deep bidirectional transformers for language understanding",
                "pub": "CoRR"
            }
        },
        {
            "ix": "402-ARR_v1_78",
            "content": "Siva Charan Reddy, Cheng Gangireddy, Tanmoy Long,  Chakraborty, Unsupervised fake news detection: A graph-based approach, 2020, Proceedings of the 31st ACM Conference on Hypertext and Social Media, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    " Siva Charan Reddy",
                    "Cheng Gangireddy",
                    "Tanmoy Long",
                    " Chakraborty"
                ],
                "title": "Unsupervised fake news detection: A graph-based approach",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 31st ACM Conference on Hypertext and Social Media",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_79",
            "content": "UNKNOWN, None, 2019, SemEval-2019 task 7: RumourEval, determining rumour veracity and support for rumours, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "SemEval-2019 task 7: RumourEval, determining rumour veracity and support for rumours",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_80",
            "content": "UNKNOWN, None, 2019, exBAKE: Automatic fake news detection model based on bidirectional encoder representations from transformers (BERT). Applied Sciences, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "exBAKE: Automatic fake news detection model based on bidirectional encoder representations from transformers (BERT). Applied Sciences",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_81",
            "content": "UNKNOWN, None, 2019, Learning hierarchical discourse-level structure for fake news detection, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Learning hierarchical discourse-level structure for fake news detection",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_82",
            "content": "Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, Wen-Tau Yih, Dense passage retrieval for open-domain question answering, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Vladimir Karpukhin",
                    "Barlas Oguz",
                    "Sewon Min",
                    "Patrick Lewis",
                    "Ledell Wu",
                    "Sergey Edunov",
                    "Danqi Chen",
                    "Wen-Tau Yih"
                ],
                "title": "Dense passage retrieval for open-domain question answering",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_83",
            "content": "UNKNOWN, None, 2018, False information on web and social media: A survey, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "False information on web and social media: A survey",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_84",
            "content": "UNKNOWN, None, 2019, Multi-level word features based on CNN for fake news detection in cultural communication. Personal and Ubiquitous Computing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Multi-level word features based on CNN for fake news detection in cultural communication. Personal and Ubiquitous Computing",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_85",
            "content": "UNKNOWN, None, 1907, Roberta: A robustly optimized BERT pretraining approach, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": null,
                "title": null,
                "pub_date": "1907",
                "pub_title": "Roberta: A robustly optimized BERT pretraining approach",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_86",
            "content": "Rada Mihalcea, Carlo Strapparava, The lie detector: Explorations in the automatic recognition of deceptive language, 2009, Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "Rada Mihalcea",
                    "Carlo Strapparava"
                ],
                "title": "The lie detector: Explorations in the automatic recognition of deceptive language",
                "pub_date": "2009",
                "pub_title": "Proceedings of the ACL-IJCNLP 2009 Conference Short Papers",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_87",
            "content": "Rahul Mishra, Vinay Setty, Sadhan: Hierarchical attention networks to learn latent aspect embeddings for fake news detection, 2019, Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval, .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Rahul Mishra",
                    "Vinay Setty"
                ],
                "title": "Sadhan: Hierarchical attention networks to learn latent aspect embeddings for fake news detection",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_88",
            "content": "Tanushree Mitra, Eric Gilbert, Credbank: A large-scale social media corpus with associated credibility annotations, 2015, ICWSM, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "Tanushree Mitra",
                    "Eric Gilbert"
                ],
                "title": "Credbank: A large-scale social media corpus with associated credibility annotations",
                "pub_date": "2015",
                "pub_title": "ICWSM",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_89",
            "content": "Kai Nakamura, Sharon Levy, William Wang, Fakeddit: A new multimodal benchmark dataset for fine-grained fake news detection, 2020, Proceedings of the 12th Language Resources and Evaluation Conference, .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Kai Nakamura",
                    "Sharon Levy",
                    "William Wang"
                ],
                "title": "Fakeddit: A new multimodal benchmark dataset for fine-grained fake news detection",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 12th Language Resources and Evaluation Conference",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_90",
            "content": "Preslav Nakov, Giovanni Da San, Tamer Martino, Alberto Elsayed, Rub\u00e9n Barr\u00f3n-Cede\u00f1o, Shaden M\u00edguez, Firoj Shaar, Fatima Alam, Maram Haouari, Nikolay Hasanain, Alex Babulkov,  Nikolov, Julia Gautam Kishore Shahi, Thomas Stru\u00df,  Mandl, The clef-2021 checkthat! lab on detecting check-worthy claims, previously factchecked claims, and fake news, 2021, Advances in Information Retrieval, Springer International Publishing.",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Preslav Nakov",
                    "Giovanni Da San",
                    "Tamer Martino",
                    "Alberto Elsayed",
                    "Rub\u00e9n Barr\u00f3n-Cede\u00f1o",
                    "Shaden M\u00edguez",
                    "Firoj Shaar",
                    "Fatima Alam",
                    "Maram Haouari",
                    "Nikolay Hasanain",
                    "Alex Babulkov",
                    " Nikolov",
                    "Julia Gautam Kishore Shahi",
                    "Thomas Stru\u00df",
                    " Mandl"
                ],
                "title": "The clef-2021 checkthat! lab on detecting check-worthy claims, previously factchecked claims, and fake news",
                "pub_date": "2021",
                "pub_title": "Advances in Information Retrieval",
                "pub": "Springer International Publishing"
            }
        },
        {
            "ix": "402-ARR_v1_91",
            "content": "Alexandra Olteanu, Stanislav Peshterliev, Xin Liu, Karl Aberer, Web credibility: Features exploration and credibility prediction, 2013, European conference on information retrieval, Springer.",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Alexandra Olteanu",
                    "Stanislav Peshterliev",
                    "Xin Liu",
                    "Karl Aberer"
                ],
                "title": "Web credibility: Features exploration and credibility prediction",
                "pub_date": "2013",
                "pub_title": "European conference on information retrieval",
                "pub": "Springer"
            }
        },
        {
            "ix": "402-ARR_v1_92",
            "content": "Ver\u00f3nica P\u00e9rez-Rosas, Bennett Kleinberg, Alexandra Lefevre, Rada Mihalcea, Automatic detection of fake news, 2018, Proceedings of the 27th International Conference on Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Ver\u00f3nica P\u00e9rez-Rosas",
                    "Bennett Kleinberg",
                    "Alexandra Lefevre",
                    "Rada Mihalcea"
                ],
                "title": "Automatic detection of fake news",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 27th International Conference on Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "402-ARR_v1_93",
            "content": "Kashyap Popat, Subhabrata Mukherjee, Jannik Str\u00f6tgen, Gerhard Weikum, Credibility assessment of textual claims on the web, 2016, Proceedings of the 25th ACM International on Conference on Information and Knowledge Management, CIKM '16, Association for Computing Machinery.",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": [
                    "Kashyap Popat",
                    "Subhabrata Mukherjee",
                    "Jannik Str\u00f6tgen",
                    "Gerhard Weikum"
                ],
                "title": "Credibility assessment of textual claims on the web",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 25th ACM International on Conference on Information and Knowledge Management, CIKM '16",
                "pub": "Association for Computing Machinery"
            }
        },
        {
            "ix": "402-ARR_v1_94",
            "content": "Kashyap Popat, Subhabrata Mukherjee, Jannik Str\u00f6tgen, Gerhard Weikum, Where the truth lies: Explaining the credibility of emerging claims on the web and social media, 2017, Proceedings of the 26th International Conference on World Wide Web Companion, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": [
                    "Kashyap Popat",
                    "Subhabrata Mukherjee",
                    "Jannik Str\u00f6tgen",
                    "Gerhard Weikum"
                ],
                "title": "Where the truth lies: Explaining the credibility of emerging claims on the web and social media",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 26th International Conference on World Wide Web Companion",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_95",
            "content": "Kashyap Popat, Subhabrata Mukherjee, Andrew Yates, Gerhard Weikum, DeClarE: Debunking fake news and false claims using evidence-aware deep learning, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Kashyap Popat",
                    "Subhabrata Mukherjee",
                    "Andrew Yates",
                    "Gerhard Weikum"
                ],
                "title": "DeClarE: Debunking fake news and false claims using evidence-aware deep learning",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "402-ARR_v1_96",
            "content": "Yingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang Ren, Wayne Zhao, Daxiang Dong, Hua Wu, Haifeng Wang, Rocketqa: An optimized training approach to dense passage retrieval for opendomain question answering, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "Yingqi Qu",
                    "Yuchen Ding",
                    "Jing Liu",
                    "Kai Liu",
                    "Ruiyang Ren",
                    "Wayne Zhao",
                    "Daxiang Dong",
                    "Hua Wu",
                    "Haifeng Wang"
                ],
                "title": "Rocketqa: An optimized training approach to dense passage retrieval for opendomain question answering",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_97",
            "content": "Eunsol Hannah Rashkin, Jin Choi, Svitlana Jang, Yejin Volkova,  Choi, Truth of varying shades: Analyzing language in fake news and political fact-checking, 2017, Proceedings of the 2017 conference on empirical methods in natural language processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": [
                    "Eunsol Hannah Rashkin",
                    "Jin Choi",
                    "Svitlana Jang",
                    "Yejin Volkova",
                    " Choi"
                ],
                "title": "Truth of varying shades: Analyzing language in fake news and political fact-checking",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 2017 conference on empirical methods in natural language processing",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_98",
            "content": "C Julio, Andr\u00e9 Reis, Fabr\u00edcio Correia,  Murai, Explainable machine learning for fake news detection, 2019, Proceedings of the 10th ACM Conference on Web Science, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": [
                    "C Julio",
                    "Andr\u00e9 Reis",
                    "Fabr\u00edcio Correia",
                    " Murai"
                ],
                "title": "Explainable machine learning for fake news detection",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 10th ACM Conference on Web Science",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_99",
            "content": "Ruiyang Ren, Shangwen Lv, Yingqi Qu, Jing Liu, Wayne Zhao, Qiaoqiao She, Hua Wu, Haifeng Wang, Ji-Rong Wen, Pair: Leveraging passage-centric similarity relation for improving dense passage retrieval, 2021, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, .",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": [
                    "Ruiyang Ren",
                    "Shangwen Lv",
                    "Yingqi Qu",
                    "Jing Liu",
                    "Wayne Zhao",
                    "Qiaoqiao She",
                    "Hua Wu",
                    "Haifeng Wang",
                    "Ji-Rong Wen"
                ],
                "title": "Pair: Leveraging passage-centric similarity relation for improving dense passage retrieval",
                "pub_date": "2021",
                "pub_title": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_100",
            "content": "UNKNOWN, None, 2020, Beyond leaderboards: A survey of methods for revealing weaknesses in natural language inference data and models, .",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Beyond leaderboards: A survey of methods for revealing weaknesses in natural language inference data and models",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_101",
            "content": "UNKNOWN, None, 2018, Fakenewsnet: A data repository with news content, social context and dynamic information for studying fake news on social media, .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Fakenewsnet: A data repository with news content, social context and dynamic information for studying fake news on social media",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_102",
            "content": "UNKNOWN, None, 2019, Recent advances in natural language inference: A survey of benchmarks, resources, and approaches, .",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Recent advances in natural language inference: A survey of benchmarks, resources, and approaches",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_103",
            "content": "James Thorne, Andreas Vlachos, Christos Christodoulopoulos, Arpit Mittal, FEVER: a large-scale dataset for fact extraction and VERification, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "James Thorne",
                    "Andreas Vlachos",
                    "Christos Christodoulopoulos",
                    "Arpit Mittal"
                ],
                "title": "FEVER: a large-scale dataset for fact extraction and VERification",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "402-ARR_v1_104",
            "content": "Andreas Vlachos, Sebastian Riedel, Fact checking: Task definition and dataset construction, 2014, Proceedings of the ACL 2014 Workshop on Language Technologies and Computational Social Science, .",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": [
                    "Andreas Vlachos",
                    "Sebastian Riedel"
                ],
                "title": "Fact checking: Task definition and dataset construction",
                "pub_date": "2014",
                "pub_title": "Proceedings of the ACL 2014 Workshop on Language Technologies and Computational Social Science",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_105",
            "content": "William Yang, Wang , liar, liar pants on fire\": A new benchmark dataset for fake news detection, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": [
                    "William Yang",
                    "Wang "
                ],
                "title": "liar, liar pants on fire\": A new benchmark dataset for fake news detection",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "402-ARR_v1_106",
            "content": "William Yang, Wang , liar, liar pants on fire\": A new benchmark dataset for fake news detection, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Short Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": [
                    "William Yang",
                    "Wang "
                ],
                "title": "liar, liar pants on fire\": A new benchmark dataset for fake news detection",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Short Papers"
            }
        },
        {
            "ix": "402-ARR_v1_107",
            "content": "Youze Wang, Shengsheng Qian, Jun Hu, Quan Fang, Changsheng Xu, Fake news detection via knowledge-driven multimodal graph convolutional networks, 2020, Proceedings of the 2020 International Conference on Multimedia Retrieval, .",
            "ntype": "ref",
            "meta": {
                "xid": "b40",
                "authors": [
                    "Youze Wang",
                    "Shengsheng Qian",
                    "Jun Hu",
                    "Quan Fang",
                    "Changsheng Xu"
                ],
                "title": "Fake news detection via knowledge-driven multimodal graph convolutional networks",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 International Conference on Multimedia Retrieval",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_108",
            "content": "Zichao Yang, Diyi Yang, Chris Dyer, Xiaodong He, Alex Smola, Eduard Hovy, Hierarchical attention networks for document classification, 2016, Proceedings of the 2016 conference of the North American chapter of the association for computational linguistics: human language technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b41",
                "authors": [
                    "Zichao Yang",
                    "Diyi Yang",
                    "Chris Dyer",
                    "Xiaodong He",
                    "Alex Smola",
                    "Eduard Hovy"
                ],
                "title": "Hierarchical attention networks for document classification",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 2016 conference of the North American chapter of the association for computational linguistics: human language technologies",
                "pub": null
            }
        },
        {
            "ix": "402-ARR_v1_109",
            "content": "Arkaitz Zubiaga, Maria Liakata, Rob Procter, Geraldine Wong Sak, Peter Hoi,  Tolmie, Analysing how people orient to and spread rumours in social media by looking at conversational threads, 2016, PLOS ONE, .",
            "ntype": "ref",
            "meta": {
                "xid": "b42",
                "authors": [
                    "Arkaitz Zubiaga",
                    "Maria Liakata",
                    "Rob Procter",
                    "Geraldine Wong Sak",
                    "Peter Hoi",
                    " Tolmie"
                ],
                "title": "Analysing how people orient to and spread rumours in social media by looking at conversational threads",
                "pub_date": "2016",
                "pub_title": "PLOS ONE",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "402-ARR_v1_0@0",
            "content": "WatClaimCheck: A new Dataset for Claim Entailment and Inference",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_0",
            "start": 0,
            "end": 62,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_2@0",
            "content": "We contribute a new dataset for the task of automated fact checking and an evaluation of state of the art algorithms.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_2",
            "start": 0,
            "end": 116,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_2@1",
            "content": "The dataset includes claims (from speeches, interviews, social media and news articles), review articles published by professional fact checkers and premise articles used by those professional fact checkers to support their review and verify the veracity of the claims.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_2",
            "start": 118,
            "end": 386,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_2@2",
            "content": "An important challenge in the use of premise articles is the identification of relevant passages that will help to infer the veracity of a claim.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_2",
            "start": 388,
            "end": 532,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_2@3",
            "content": "We show that transferring a dense passage retrieval model trained with review articles improves the retrieval quality of passages in premise articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_2",
            "start": 534,
            "end": 683,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_2@4",
            "content": "We report results for the prediction of claim veracity by inference from premise articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_2",
            "start": 685,
            "end": 774,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_4@0",
            "content": "The rise of social media has lead to a democratization of news, but it has also amplified issues related to fake news and misinformation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_4",
            "start": 0,
            "end": 136,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_4@1",
            "content": "To that effect, many fact checking organizations (e.g., Politifact, Snopes, AFP Fact Check, Alt News, FactCheck.org, Africa Check, etc.) have emerged around the globe.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_4",
            "start": 138,
            "end": 304,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_4@2",
            "content": "They investigate debatable claims made by authorities, politicians, celebrities and the public.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_4",
            "start": 306,
            "end": 400,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_4@3",
            "content": "For each claim, they publish a review article with links to sources that support a verdict (e.g., true, partly true/false, false) about the veracity of the claim.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_4",
            "start": 402,
            "end": 563,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_4@4",
            "content": "Those reviews debunk false claims and mitigate the spread of misinformation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_4",
            "start": 565,
            "end": 640,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_4@5",
            "content": "We consider a key NLP challenge in the context of automated fact checking: claim inference from premise articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_4",
            "start": 642,
            "end": 754,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_4@6",
            "content": "Note that determining the veracity of a claim without additional information is nearly impossible since claims are selected by professional fact checkers in part because their veracity is far from obvious and also because of their degree of controversy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_4",
            "start": 756,
            "end": 1008,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_4@7",
            "content": "To that effect, professional fact checkers invest a fair amount of time to research each claim by finding relevant sources and publishing a review article that explains their verdict of the claim.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_4",
            "start": 1010,
            "end": 1205,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_4@8",
            "content": "Hence there is a natural entailment problem, whereby anyone who reads a review article should be able to arrive at the same verdict as the professional fact checker regarding the claim.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_4",
            "start": 1207,
            "end": 1391,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_4@9",
            "content": "Unlike many entailment tasks that consist of short text (e.g., pairs of utterances) that may be artificially generated or extracted, this is a natural and challenging entailment task that involves an entire document (review article) with an utterance (claim) that requires a certain degree of reading comprehension.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_4",
            "start": 1393,
            "end": 1707,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_4@10",
            "content": "We note that this entailment problem has been tackled in some previous work (Augenstein et al., 2019;Shu et al., 2018;Nakov et al., 2021) and although it is a challenging NLP problem, it does not correspond to the problem that professional fact checkers need to solve.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_4",
            "start": 1709,
            "end": 1976,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_5@0",
            "content": "In this paper, we focus on the harder problem of claim inference from premise articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_5",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_5@1",
            "content": "This is part of the challenge that professional fact checkers face.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_5",
            "start": 88,
            "end": 154,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_5@2",
            "content": "They find premise articles that contain relevant facts and then infer the veracity of the claim based on those facts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_5",
            "start": 156,
            "end": 272,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_5@3",
            "content": "Unlike many existing inference tasks where it is sufficient to use one or a few facts in a few sentences (Storks et al., 2019;Schlegel et al., 2020), information from a set of premise articles must be distilled and combined in non trivial ways to infer the veracity of a claim.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_5",
            "start": 274,
            "end": 550,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_6@0",
            "content": "We assembled a dataset of 33,697 claims made between December 1996 and July 2021 with associated review articles, premise articles and claim verdicts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_6",
            "start": 0,
            "end": 149,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_6@1",
            "content": "While some other datasets include claims with associated verdicts and in some cases review articles as well as search engine results, this is the first dataset that includes premise articles, therefore enabling the inference task described above.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_6",
            "start": 151,
            "end": 396,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_7@0",
            "content": "Since there are several premise articles for a given claim and each premise article may be long, a simple two-stage approach to identify relevant passages would consist of a lightweight retrieval technique in a first stage, followed by a heavyweight inference technique applied to those passages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_7",
            "start": 0,
            "end": 295,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_7@1",
            "content": "When the first stage fails to retrieve some key passages, then the inferred verdict will be negatively affected regardless of how good the second stage is.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_7",
            "start": 297,
            "end": 451,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_7@2",
            "content": "To that effect, several supervised dense passage retrieval techniques have been proposed in the past for question-answering (Karpukhin et al., 2020;. Unfortunately, we cannot directly apply those techniques since we do not have labels for the relevant passages in our inference task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_7",
            "start": 453,
            "end": 735,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_7@3",
            "content": "Instead, we show how to use the review articles to train a supervised dense retrieval technique that is then transferred to premise articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_7",
            "start": 737,
            "end": 877,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_8@0",
            "content": "The contributions of the paper can be summarized as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_8",
            "start": 0,
            "end": 59,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_9@0",
            "content": "\u2022 New dataset of claims with review and premise articles for claim inference in automated fact checking; \u2022 Novel use of review articles to transfer a dense retrieval technique to premise articles; \u2022 Experiments establishing the state of the art for claim inference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_9",
            "start": 0,
            "end": 264,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_10@0",
            "content": "The paper is organized as follows.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_10",
            "start": 0,
            "end": 33,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_10@1",
            "content": "Section 2 reviews previous work related to automated fact checking and claim verification.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_10",
            "start": 35,
            "end": 124,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_10@2",
            "content": "Section 3 describes the new dataset and summarizes the differences with previous datasets for claim verification.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_10",
            "start": 126,
            "end": 238,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_10@3",
            "content": "Section 4 describes a two-stage process to i) extract evidence sentences from premise articles and ii) infer the veracity of claims.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_10",
            "start": 240,
            "end": 371,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_10@4",
            "content": "This section also explains how to transfer a dense passage retrieval technique trained with review articles to premise articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_10",
            "start": 373,
            "end": 500,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_10@5",
            "content": "Section 5 reports the results for the claim veracity inference task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_10",
            "start": 502,
            "end": 569,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_10@6",
            "content": "Finally, Section 6 concludes and discusses possible future work.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_10",
            "start": 571,
            "end": 634,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_11@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_11",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_12@0",
            "content": "There is an important line of work that focuses on claim verification.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_12",
            "start": 0,
            "end": 69,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_12@1",
            "content": "This includes techniques that predict the veracity of a claim based on the text of the claim only (Rashkin et al., 2017), linguistic features (Popat et al., 2017), meta information about the claimant (e.g., name, job, party affiliation, veracity history) (Wang, 2017b), review articles (Augenstein et al., 2019;Shu et al., 2018;Nakov et al., 2021), as well as relevant articles returned by a search engine (Popat et al., 2018;Augenstein et al., 2019;Mishra and Setty, 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_12",
            "start": 71,
            "end": 544,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_12@2",
            "content": "To the best of our knowledge, none of the existing work considers the problem of claim verification based on premise articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_12",
            "start": 546,
            "end": 671,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_12@3",
            "content": "There is an important distinction between articles returned by a search engine in previous work and the premise articles that we consider.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_12",
            "start": 673,
            "end": 810,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_12@4",
            "content": "The techniques that use a search engine to find articles related to a claim query the search engine after a fact checking website has published a review article and therefore end up retrieving articles that include the review article as well as other articles that summarize and/or discuss the verdict of the fact checking website.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_12",
            "start": 812,
            "end": 1142,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_12@5",
            "content": "Hence they are tackling an entailment problem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_12",
            "start": 1144,
            "end": 1189,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_12@6",
            "content": "In contrast, the premise articles that we consider are the source articles used by a fact checker before publishing a review article.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_12",
            "start": 1191,
            "end": 1323,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_12@7",
            "content": "Those articles contain relevant facts, but not a summary or discussion of the review article since they are published before the review article and in fact serve as premises for the review article.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_12",
            "start": 1325,
            "end": 1521,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_13@0",
            "content": "Closely related to claim verification is the problem of fake news detection.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_13",
            "start": 0,
            "end": 75,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_13@1",
            "content": "In this problem, the credibility of an entire news article is evaluated.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_13",
            "start": 77,
            "end": 148,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_13@2",
            "content": "The credibility of a news article can be estimated based on linguistic and textual features (Conroy et al., 2015;Reis et al., 2019;Li et al., 2019), discourse level structure (Karimi and Tang, 2019), network analysis (Conroy et al., 2015), knowledge graphs (Cui et al., 2020), inter-user behaviour dynamics (Gangireddy et al., 2020) or a combination of multiple modalities .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_13",
            "start": 150,
            "end": 523,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_13@3",
            "content": "Some techniques reorder the articles returned by a search engine based on their degree of credibility (Olteanu et al., 2013;Beylunioglu, 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_13",
            "start": 525,
            "end": 667,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_13@4",
            "content": "An important task that can help the detection of fake news is the task of stance detection (Borges et al., 2019;Jwa et al., 2019), i.e., does the content of an article agree or disagree with the title of the article?",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_13",
            "start": 669,
            "end": 884,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_13@5",
            "content": "The following surveys summarize existing work on fake news detection: (Kumar and Shah, 2018;Bondielli and Marcelloni, 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_13",
            "start": 886,
            "end": 1009,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_14@0",
            "content": "3 Fact Checking Dataset",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_14",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_15@0",
            "content": "Data Collection",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_15",
            "start": 0,
            "end": 14,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_16@0",
            "content": "We collect fact checked claims, along with a review articles, premise articles, and claim metadata from the following eight fact checking services: Politifact, Snopes, AFP Fact Check, Alt News, FactCheck.org, Africa Check, USA Today, and Full Fact.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_16",
            "start": 0,
            "end": 247,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_16@1",
            "content": "We utilize Google's fact check tool APIs 1 to collect the claims' metadata for all previously listed fact checking services except Politifact and Snopes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_16",
            "start": 249,
            "end": 401,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_16@2",
            "content": "The claims' metadata collected from Google's fact check tool APIs include the claim review article URL, which is used to retrieve the claim review article.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_16",
            "start": 403,
            "end": 557,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_16@3",
            "content": "The claim review articles published by some of the fact checking services provide the premise article URLs in a separate section while others provide the URLs as inline links in the review article body.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_16",
            "start": 559,
            "end": 760,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_16@4",
            "content": "We carefully parse the article body, retrieving the premise article URLs used in the claim review article to justify the claim veracity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_16",
            "start": 762,
            "end": 897,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_16@5",
            "content": "Finally, the premise article URLs are used to retrieve the premise articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_16",
            "start": 899,
            "end": 974,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_16@6",
            "content": "We try to directly retrieve the article where possible, but also use archive.org's APIs in case the premise article URL is no longer available online.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_16",
            "start": 976,
            "end": 1125,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_16@7",
            "content": "We follow the same general procedure for data collection from Politifact and Snopes except that instead of using Google's fact check tool APIs for collecting claims and associated metadata, we directly crawl the respective websites to collect the data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_16",
            "start": 1127,
            "end": 1378,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_17@0",
            "content": "We only perform some basic cleanup to the collected data before inclusion in the dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_17",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_17@1",
            "content": "This includes removing articles behind paywalls, removing claims with less than two premise articles, and removing non-textual premise sources.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_17",
            "start": 90,
            "end": 232,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_17@2",
            "content": "We obtain premise article text from their HTML pages by loading the HTML files into a text based web browser (Links browser) and then dumping the web page text into a text file.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_17",
            "start": 234,
            "end": 410,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_17@3",
            "content": "This allows us to bypass the CSS styling and JavaScript code included in the HTML pages and obtain only the text displayed to end users.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_17",
            "start": 412,
            "end": 547,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_17@4",
            "content": "Admittedly, this still does not eliminate the auxiliary text usually present in the web pages such as navigation links, footer text, recommended links, etc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_17",
            "start": 549,
            "end": 704,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_17@5",
            "content": "We include both the HTML and text version of the premise articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_17",
            "start": 706,
            "end": 771,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_17@6",
            "content": "We perform minimal cleanup in order for our dataset to reflect the real life challenges present in the task of automated fact checking.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_17",
            "start": 773,
            "end": 907,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_17@7",
            "content": "We also map the numerous claim veracity labels used by the fact checking websites into three broad labels: True, Partially True/False, and False.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_17",
            "start": 909,
            "end": 1053,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_18@0",
            "content": "WatClaimCheck Dataset",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_18",
            "start": 0,
            "end": 20,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_19@0",
            "content": "The contributed dataset contains a total of 33,697 claims.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_19",
            "start": 0,
            "end": 57,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_19@1",
            "content": "We split those claims into the following three sets: training set containing 26,957 claims, validation set containing 3369 claims, and test set containing 3371 claims.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_19",
            "start": 59,
            "end": 225,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_19@2",
            "content": "For each claim in the dataset, we provide the following data: ID, Here Original Rating refers to the rating assigned by a fact checking organization and Rating corresponds to our mapping of the original rating to true, partly true/false and false.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_19",
            "start": 227,
            "end": 473,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_19@3",
            "content": "We provide both the HTML and extracted text files for the review and premise articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_19",
            "start": 475,
            "end": 560,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_20@0",
            "content": "Figure 1 shows the number of claims collected from each of the fact checking services.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_20",
            "start": 0,
            "end": 85,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_20@1",
            "content": "Figure 2 shows the claim rating distribution.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_20",
            "start": 87,
            "end": 131,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_20@2",
            "content": "We see that the claims in the Partially True/False and False categories significantly outnumber the claims in the True category.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_20",
            "start": 133,
            "end": 260,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_20@3",
            "content": "In reality, the number of true claims is much larger then the number of partially true/false and false claims, but fact checking services focus on debunking controversial claims and therefore the majority of the claims they investigate are false or partially true/false.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_20",
            "start": 262,
            "end": 531,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_20@4",
            "content": "This imbalance poses an important challenge for the models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_20",
            "start": 533,
            "end": 591,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_21@0",
            "content": "Comparison with existing Datasets",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_21",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_22@0",
            "content": "We compare our proposed dataset with other publicly available fact checking related datasets in Table 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_22",
            "start": 0,
            "end": 103,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_22@1",
            "content": "We can broadly classify the fact checking datasets into two different categories: (1) veracity detection datasets based only on claim text and some metadata, but without supporting evidence documents (Wang, 2017a;P\u00e9rez-Rosas et al., 2018) and (2) datasets that provide claim text along with supporting evidence and/or context documents.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_22",
            "start": 105,
            "end": 440,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_22@2",
            "content": "We observe that the datasets that provide some evidence or context documents can be further subcategorized: (1) datasets that provide social media posts and comments related to the claim (Mitra and Gilbert, 2015;Nakamura et al., 2020;Shu et al., 2018), (2) datasets that retrieve supporting evidence for the claims by performing a web search using queries obtained from lexical and semantic features of the claim text (Baly et al., 2018;Augenstein et al., 2019), and (3) datasets that provide Wikipedia pages as supporting evidence (Thorne et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_22",
            "start": 442,
            "end": 995,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_22@3",
            "content": "Our proposed dataset provides the documents cited by the professional fact checkers in the claim review article to justify their claim rating.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_22",
            "start": 997,
            "end": 1138,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_22@4",
            "content": "We argue that our dataset reflects the real world task of automated veracity detection more truthfully due to the availability of the premise articles cited by the professional fact checkers in claim review articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_22",
            "start": 1140,
            "end": 1355,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_22@5",
            "content": "Although, social media posts and comments can sometimes be helpful in claim veracity detection they are rarely treated as authoritative sources of information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_22",
            "start": 1357,
            "end": 1515,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_22@6",
            "content": "Using a web search to retrieve evidence documents for a claim is problematic due to the fact that once a fact checking service has fact checked a claim, we observe that multiple other news agency also publish articles referencing the original fact checking review article.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_22",
            "start": 1517,
            "end": 1788,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_22@7",
            "content": "Retrieving top-k web search results, typically retrieves those articles as well.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_22",
            "start": 1790,
            "end": 1869,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_22@8",
            "content": "This can indirectly leak the veracity label in the retrieved documents.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_22",
            "start": 1871,
            "end": 1941,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_23@0",
            "content": "Models",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_23",
            "start": 0,
            "end": 5,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_24@0",
            "content": "We develop a two-stage system to perform evidence based veracity detection.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_24",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_24@1",
            "content": "The first stage selects relevant sentence level evidence from the premise articles associated with a claim and the second stage performs claim veracity inference using the claim text and selected evidence sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_24",
            "start": 76,
            "end": 290,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_24@2",
            "content": "For the first stage, we use and evaluate two different approaches.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_24",
            "start": 292,
            "end": 357,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_24@3",
            "content": "The first approach is the well-known and commonly used basic text retrieval technique called term frequency inverse document frequency (TF-IDF).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_24",
            "start": 359,
            "end": 502,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_24@4",
            "content": "For the second approach, we propose a novel way to adapt dense passage retrieval techniques using the review articles for evidence sentence selection.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_24",
            "start": 504,
            "end": 653,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_24@5",
            "content": "In our experiments, the aforementioned dense passage retrieval technique outperforms TF-IDF text retrieval and leads to overall system performance improvements.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_24",
            "start": 655,
            "end": 814,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_24@6",
            "content": "The second stage consists of training deep learning models to perform claim veracity inference using the claim text and selected evidence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_24",
            "start": 816,
            "end": 953,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_24@7",
            "content": "We utilize multiple deep learning models to perform claim veracity inference ranging from basic bi-directional recurrent networks to state of the art transformers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_24",
            "start": 955,
            "end": 1117,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_25@0",
            "content": "Problem Formulation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_25",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_26@0",
            "content": "We represent a claim containing l tokens as C n = {c 1 , c 2 , . . . , c l }, where n \u2208 [1, N ] and N is the size of the dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_26",
            "start": 0,
            "end": 128,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_26@1",
            "content": "Each claim is associated with multiple premise articles, we represent the k-th premise article associated with the n-th claim containing m sentences as A n,k = {s P n,1 , s P n,2 , . . . , s P n,m } where s n,i represents the i-th sentence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_26",
            "start": 130,
            "end": 369,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_26@2",
            "content": "Similarly, we represent the review article associated with the claim",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_26",
            "start": 371,
            "end": 438,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_27@0",
            "content": "C n containing m sentences by R n = {s R n,1 , s R n,2 , . . . , s R n,m }.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_27",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_28@0",
            "content": "For a given claim C n , we represent its ground truth veracity label by y n .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_28",
            "start": 0,
            "end": 76,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_29@0",
            "content": "We cast the problem as a textual inference problem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_29",
            "start": 0,
            "end": 50,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_29@1",
            "content": "Given a claim C n and a set of associated premise articles A, our goal is to predict the ground truth veracity y n of the claim.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_29",
            "start": 52,
            "end": 179,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_30@0",
            "content": "Stage-1: Evidence Sentence Extraction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_30",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_31@0",
            "content": "One of the key steps in the fact checking process performed by human professional fact checkers is examining the premise articles associated with a claim and extracting useful evidence from them to establish claim veracity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_31",
            "start": 0,
            "end": 222,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_31@1",
            "content": "Our first stage seeks to perform a similar task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_31",
            "start": 224,
            "end": 271,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_31@2",
            "content": "Each claim in our dataset has multiple associated premise articles with each article containing a large amount of text.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_31",
            "start": 273,
            "end": 391,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_31@3",
            "content": "Our goal in the first stage is to rank the evidence available in the associated premise articles at the sentence level and extract the ones which are most useful and impactful for veracity detection in the second stage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_31",
            "start": 393,
            "end": 611,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_31@4",
            "content": "Our experiments show that an improvement in this stage directly contributes to an overall improvement in the veracity detection performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_31",
            "start": 613,
            "end": 752,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_32@0",
            "content": "TF-IDF",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_32",
            "start": 0,
            "end": 5,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_33@0",
            "content": "TF-IDF based similarity measure is commonly used in NLP tasks to retrieve texts similar to the target text from a large corpus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_33",
            "start": 0,
            "end": 126,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_33@1",
            "content": "We use TF-IDF based similarity measure between the claim text and the premise article sentences to rank the sentence level evidence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_33",
            "start": 128,
            "end": 259,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_33@2",
            "content": "Top ranked sentences are used in the second stage to perform veracity detection.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_33",
            "start": 261,
            "end": 340,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_33@3",
            "content": "This approach is similar to the one used by Thorne et al. (2018) to extract evidence sentences from Wikipedia articles for fact checking.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_33",
            "start": 342,
            "end": 478,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_34@0",
            "content": "Dense Passage Retrieval",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_34",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_35@0",
            "content": "We propose a novel way of adapting dense passage retrieval methods proposed by Karpukhin et al. (2020) for open domain question answering to the task of retrieving evidence sentences from premise articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_35",
            "start": 0,
            "end": 204,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_35@1",
            "content": "The dense passage retrieval method proposed by Karpukhin et al. (2020) uses a dual encoder architecture.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_35",
            "start": 206,
            "end": 309,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_35@2",
            "content": "Each encoder is implemented using BERT (Devlin et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_35",
            "start": 311,
            "end": 371,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_35@3",
            "content": "The question encoder E Q and the passage encoder E P embed a given question q and passage p into d-dimensional real-valued vectors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_35",
            "start": 373,
            "end": 503,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_35@4",
            "content": "The similarity between the question and passage is defined as the dot product of their vectors:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_35",
            "start": 505,
            "end": 599,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_36@0",
            "content": "sim(q, p) = E Q (q) T E P (p) (1)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_36",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_37@0",
            "content": "The model is then trained to learn embedding functions such that the similarity score between relevant pairs of questions and passages will be higher than irrelevant ones.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_37",
            "start": 0,
            "end": 170,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_38@0",
            "content": "We adapt this method for our first stage by taking advantage of the fact that the review article published by fact checking websites along with a claim typically contains key evidence taken from the premise articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_38",
            "start": 0,
            "end": 215,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_38@1",
            "content": "The evidence taken from the premise articles is usually paraphrased in order to form a coherent argument in support of the claim veracity verdict.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_38",
            "start": 217,
            "end": 362,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_39@0",
            "content": "To train the dense passage retrieval model for stage-1, we use the claims and the associated review articles in the training set of our dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_39",
            "start": 0,
            "end": 143,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_39@1",
            "content": "We form positive pairs using the claim and the sentences from the associated review article.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_39",
            "start": 145,
            "end": 236,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_39@2",
            "content": "The negative pairs are formed using a claim and a sentence from a review article not associated with that claim. Let",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_39",
            "start": 238,
            "end": 353,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_40@0",
            "content": "D = { C i , s R+ i,j , s R\u2212 i,1 , s R\u2212 i,2 , . . . , s R\u2212 i,n |R i | j=1 } N i=1",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_40",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_41@0",
            "content": "be the training data containing N i=1 |R i | instances where N is the number of claims in the training set, |R i | is the number of sentences in the review article associated with the i-th claim.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_41",
            "start": 0,
            "end": 194,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_41@1",
            "content": "Each instance is made up of a claim C i with one positive sentence from the associated review article s R+ i,j and n randomly chosen negative sentences s R\u2212 i,k .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_41",
            "start": 196,
            "end": 357,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_41@2",
            "content": "We train the model by optimizing the negative log likelihood of the positive sentences:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_41",
            "start": 359,
            "end": 445,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_42@0",
            "content": "L(C i , s R+ i,j , s R\u2212 i,1 , s R\u2212 i,2 , . . . , s R\u2212 i,n ) = \u2212log e sim(C i ,s R+ i,j ) e sim(C i ,s R+ i,j ) + n k=1 e sim(C i ,s R\u2212 i,k )(2)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_42",
            "start": 0,
            "end": 142,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_43@0",
            "content": "We evaluate the model using the claims and the associated review articles in the validation and test set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_43",
            "start": 0,
            "end": 104,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_43@1",
            "content": "For model evaluation, we use the top-k recall rate for retrieving the review article sentences corresponding to the claims in the validation and test set using the similarity score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_43",
            "start": 106,
            "end": 286,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_43@2",
            "content": "The review article sentences are retrieved from the corpus formed by all the sentences from every review article in the corresponding set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_43",
            "start": 288,
            "end": 425,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_44@0",
            "content": "After training the model, we use the encoders to encode the claim text and the sentences of the associated premise articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_44",
            "start": 0,
            "end": 123,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_44@1",
            "content": "We compute the similarity score using the dot product between the encoded claim vector and the premise article sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_44",
            "start": 125,
            "end": 245,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_44@2",
            "content": "We use the top scoring sentences as evidence sentences in the next stage to perform the claim veracity inference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_44",
            "start": 247,
            "end": 359,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_45@0",
            "content": "Stage-2: Claim Veracity Inference",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_45",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_46@0",
            "content": "In this section, we describe how several popular sequence models are used to classify a claim as true, partly true/false or false based on the text of the claim, the claimant and the evidence sentences extracted in stage 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_46",
            "start": 0,
            "end": 222,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_47@0",
            "content": "Bi-LSTM and Bi-GRU",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_47",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_48@0",
            "content": "We first consider bi-directional long short term memory (Bi-LSTM) networks and bi-directional gated recurrent units (Bi-GRUs).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_48",
            "start": 0,
            "end": 125,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_48@1",
            "content": "The evidence sentences of each premise article are concatenated with the claim and claimant, and then encoded by a Bi-LSTM or Bi-GRU into a latent vector.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_48",
            "start": 127,
            "end": 280,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_48@2",
            "content": "For N premise articles, the resulting N vectors are then averaged and passed through a softmax layer with 3 outputs corresponding to the predicted probabilities of true, partly true/false and false.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_48",
            "start": 282,
            "end": 479,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_49@0",
            "content": "HAN",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_49",
            "start": 0,
            "end": 2,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_50@0",
            "content": "Instead of concatenating the evidence sentences of each premise article into a long sequence, we can also use hierarchical attention networks (HANs) (Yang et al., 2016;Mishra and Setty, 2019) to compute sentence level embeddings that are then combined into article level embeddings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_50",
            "start": 0,
            "end": 281,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_50@1",
            "content": "A HAN is used to embed each premise article with the claim as follows.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_50",
            "start": 283,
            "end": 352,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_50@2",
            "content": "At the bottom of a HAN, each sentence (claimant with claim text or each evidence sentence of the premise article) is embedded as a sequence of hidden vectors (one per word) by a bi-directional recurrent network (Bi-LSTM or Bi-GRU).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_50",
            "start": 354,
            "end": 584,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_50@3",
            "content": "Then, a word-level attention layer computes a sentence level embedding.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_50",
            "start": 586,
            "end": 656,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_50@4",
            "content": "Next, those embeddings are fed to another bi-directional recurrent network (Bi-LSTM or Bi-GRU) that computes a sequence of hidden vectors (one per sentence) and a sentence level attention layer computes an embedding for the document-claim pair.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_50",
            "start": 658,
            "end": 901,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_50@5",
            "content": "Finally, the embeddings of the document-claim pairs are averaged and passed through a softmax over the labels true, partly true/false and false.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_50",
            "start": 903,
            "end": 1046,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_51@0",
            "content": "Transformer",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_51",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_52@0",
            "content": "We finetune a RoBERTa-base (Liu et al., 2019) model to perform claim veracity inference using the claim and the evidence sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_52",
            "start": 0,
            "end": 130,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_52@1",
            "content": "We concatenate the claim text, the name of the claimant, and the evidence sentences extracted for that particular claim in the first stage to build a training data instance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_52",
            "start": 132,
            "end": 304,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_52@2",
            "content": "The input sequence is encoded using the RoBERTa-base model and passed through a dense linear layer followed by a softmax layer to obtain the predicted claim veracity label distribution.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_52",
            "start": 306,
            "end": 490,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_52@3",
            "content": "We use the cross entropy loss function to train the model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_52",
            "start": 492,
            "end": 549,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_53@0",
            "content": "Experiments",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_53",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_54@0",
            "content": "We evaluate the two-stage process and the algorithms described in the previous section on the claim inference problem with our new dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_54",
            "start": 0,
            "end": 138,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_55@0",
            "content": "Stage-1 Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_55",
            "start": 0,
            "end": 14,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_56@0",
            "content": "In order to reduce the computational resources and memory requirements, we implement the encoders in the dense passage retrieval model using Distil-RoBERTa (Dis).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_56",
            "start": 0,
            "end": 161,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_56@1",
            "content": "We use a batch size of 64 and the in-batch negatives technique as described in (Karpukhin et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_56",
            "start": 163,
            "end": 266,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_57@0",
            "content": "We evaluate the stage-1 methods by comparing their performance using the top-k recall rate metric.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_57",
            "start": 0,
            "end": 97,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_57@1",
            "content": "The claim text is used to retrieve the ground truth review article sentences from the corpus containing all the sentences of all the review articles in the test set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_57",
            "start": 99,
            "end": 263,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_57@2",
            "content": "We report the top-k recall rate for k = 10, 25, 50, 100 in Table 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_57",
            "start": 265,
            "end": 331,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_57@3",
            "content": "The results clearly show that the DPR (dense passage retrieval) method outperforms the TF-IDF similarity based method.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_57",
            "start": 333,
            "end": 450,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_58@0",
            "content": "Stage-2 Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_58",
            "start": 0,
            "end": 14,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_59@0",
            "content": "To evaluate whether the inference models in stage-2 can do better with the inclusion of additional evidence sentences, we perform the experiments in stage-2 in two settings: Pooled and Averaged.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_59",
            "start": 0,
            "end": 193,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_60@0",
            "content": "Pooled: In this setting, for each claim we pool all the sentences from every associated premise article and rank them using the similarity score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_60",
            "start": 0,
            "end": 144,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_60@1",
            "content": "The sentences with top scores are then used to perform claim veracity inference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_60",
            "start": 146,
            "end": 225,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_60@2",
            "content": "For each claim, we get exactly one data instance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_60",
            "start": 227,
            "end": 275,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_61@0",
            "content": "Averaged: This refers to the setting where we generate one data instance per claim and associated premise article.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_61",
            "start": 0,
            "end": 113,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_61@1",
            "content": "So, if a claim has m premise articles, we get m data instances.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_61",
            "start": 115,
            "end": 177,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_61@2",
            "content": "For each premise article associated with a claim, we score the sentences from that article and extract the top scoring sentences to form a data instance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_61",
            "start": 179,
            "end": 331,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_61@3",
            "content": "During training, each data instance for a claim is used independently, but during inference, we compute the average of the claim veracity prediction distributions of the data instances associated with a single claim.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_61",
            "start": 333,
            "end": 548,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_61@4",
            "content": "We show in our reported results that the inclusion of additional evidence in the form of m data instances per claim (instead of 1 data instance for the pooled setting) does improve the performance when the retrieval method of stage 1 is not very effective.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_61",
            "start": 550,
            "end": 805,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_61@5",
            "content": "We use macro F1 as the evaluation metric.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_61",
            "start": 807,
            "end": 847,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_61@6",
            "content": "We report the results in Table 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_61",
            "start": 849,
            "end": 881,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_61@7",
            "content": "We report all the hyper parameters used in our experiments in the appendix.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_61",
            "start": 883,
            "end": 957,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_61@8",
            "content": "The best performance when doing the claim veracity inference is obtained by using the DPR model in the first stage and the RoBERTa-base model in the second stage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_61",
            "start": 959,
            "end": 1120,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_61@9",
            "content": "We also report results for claim entailment from the review articles as an upper bound on the accuracy that could be achieved for claim inference based on the premise articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_61",
            "start": 1122,
            "end": 1297,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_62@0",
            "content": "Prequential Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_62",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_63@0",
            "content": "We note that the traditional experimental setup of dividing a dataset at random into train, validation and test does not reflect the streaming nature of claims.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_63",
            "start": 0,
            "end": 159,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_63@1",
            "content": "When new topics arise (i.e., election, covid-19), the nature of the claims and the premise articles changes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_63",
            "start": 161,
            "end": 268,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_63@2",
            "content": "Randomly splitting the dataset into train/validation/test ensures that all claim topics are well represented across the train/validation/test splits, which would not be the case in practice.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_63",
            "start": 270,
            "end": 459,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_63@3",
            "content": "In reality, when a new topic arises, the test split may have new types of claims that are not well represented in the train/validation splits.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_63",
            "start": 461,
            "end": 602,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_63@4",
            "content": "To evaluate the effect of this distribution shift over time, we performed a prequential evaluation (Bifet et al., 2015).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_63",
            "start": 604,
            "end": 723,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_63@5",
            "content": "More precisely, we divide the dataset into subsets corresponding to periods of 6 months.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_63",
            "start": 725,
            "end": 812,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_63@6",
            "content": "We repeatedly evaluate the performance for each 6-month period by treating the claims in that period as the test set and the claims in previous periods as the train/validation sets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_63",
            "start": 814,
            "end": 994,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_63@7",
            "content": "This corresponds to a realistic setting where a claim verification algorithm may be re-trained every 6 months on the data seen so far to predict the veracity of the claims for the next 6 months.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_63",
            "start": 996,
            "end": 1189,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_63@8",
            "content": "Naturally, the time period between each re-training iteration may be shorter than 6 months in practice.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_63",
            "start": 1191,
            "end": 1293,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_63@9",
            "content": "We chose 6 months simply to ensure that the size of the test set would be large enough to obtain reliable results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_63",
            "start": 1295,
            "end": 1408,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_64@0",
            "content": "Figure 3 shows the number of claims investigated in each 6-month period in our dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_64",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_64@1",
            "content": "We note two peaks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_64",
            "start": 88,
            "end": 105,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_64@2",
            "content": "The first one in 2016 corresponds to a sudden surge of claims investigated by some fact checking websites regarding India politics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_64",
            "start": 107,
            "end": 237,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_64@3",
            "content": "The second peak in 2020 corresponds to the 2020 US presidential election and the start of the covid-19 pandemic.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_64",
            "start": 239,
            "end": 350,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_64@4",
            "content": "Figure 4 shows the macro F1 results achieved by the top 4 algorithms with DPR evidence in each 6-month period.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_64",
            "start": 352,
            "end": 461,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_64@5",
            "content": "We note that the prequential results are significantly lower than the results in the DPR column of Table 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_64",
            "start": 463,
            "end": 569,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_64@6",
            "content": "This drop of accuracy is precisely due to the distribution shift of claims that naturally occurs over time.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_64",
            "start": 571,
            "end": 677,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_64@7",
            "content": "We also note a trend whereby the accuracy increases as time passes by.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_64",
            "start": 679,
            "end": 748,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_64@8",
            "content": "This is explained by the fact that more data is available for training in later time periods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_64",
            "start": 750,
            "end": 842,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_64@9",
            "content": "We strongly recommend that future algorithms be evaluated in prequential mode since this evaluation setup is more realistic.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_64",
            "start": 844,
            "end": 967,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_65@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_65",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_66@0",
            "content": "This paper introduces a new dataset for automated fact checking.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_66",
            "start": 0,
            "end": 63,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_66@1",
            "content": "It is the first dataset that includes premise articles used by professional fact checkers and therefore corresponds more closely to the task of claim veracity inference in automated fact checking.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_66",
            "start": 65,
            "end": 260,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_66@2",
            "content": "An important challenge is the extraction of relevant facts from the premise articles since it is not generally possible to apply heavyweight models on the entire content of all premise articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_66",
            "start": 262,
            "end": 455,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_66@3",
            "content": "To that effect, we described how to train the encoders of a dense passage retrieval technique with the review articles and then transfer the resulting retrieval technique to the premise articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_66",
            "start": 457,
            "end": 651,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_66@4",
            "content": "This increased the overall performance of the claim verification algorithms.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_66",
            "start": 653,
            "end": 728,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_66@5",
            "content": "We also performed a prequential evaluation that highlighted an important distribution shift that caused a significant drop in accuracy for all algorithms.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_66",
            "start": 730,
            "end": 883,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_66@6",
            "content": "We strongly recommend that future algorithms be evaluated in prequential mode.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_66",
            "start": 885,
            "end": 962,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_66@7",
            "content": "In fact, an important direction for future research would be to design algorithms based on transfer learning or domain generalization that can cope better with this distributional shift.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_66",
            "start": 964,
            "end": 1149,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_66@8",
            "content": "We also note that the techniques that we evaluated are black boxes and therefore it is not clear how they do inference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_66",
            "start": 1151,
            "end": 1269,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_66@9",
            "content": "Hence, another direction for future research would be to develop inference techniques that are explainable in the sense that they could provide explanations to the users to justify their veracity prediction for a claim.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_66",
            "start": 1271,
            "end": 1489,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_67@0",
            "content": "UNKNOWN, None, , Distilroberta model, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_67",
            "start": 0,
            "end": 38,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_68@0",
            "content": "Isabelle Augenstein, Christina Lioma, Dongsheng Wang, Lucas Lima, Casper Hansen, Christian Hansen, Jakob Simonsen, MultiFC: A real-world multi-domain dataset for evidence-based fact checking of claims, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_68",
            "start": 0,
            "end": 385,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_69@0",
            "content": "Joan Bachenko, Eileen Fitzpatrick, Michael Schonwetter, Verification and implementation of language-based deception indicators in civil and criminal narratives, 2008, Proceedings of the 22nd International Conference on Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_69",
            "start": 0,
            "end": 246,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_70@0",
            "content": "Ramy Baly, Mitra Mohtarami, James Glass, Llu\u00eds M\u00e0rquez, Alessandro Moschitti, Preslav Nakov, Integrating stance detection and fact checking in a unified corpus, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_70",
            "start": 0,
            "end": 352,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_71@0",
            "content": "UNKNOWN, None, 2020, Using a credibility classifier to improve health-related information retrieval, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_71",
            "start": 0,
            "end": 101,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_72@0",
            "content": "Albert Bifet, Gianmarco De Francisci, Jesse Morales, Geoff Read, Bernhard Holmes,  Pfahringer, Efficient online evaluation of big data stream classifiers, 2015, Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_72",
            "start": 0,
            "end": 261,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_73@0",
            "content": "Alessandro Bondielli, Francesco Marcelloni, A survey on fake news and rumour detection techniques, 2019, Information Sciences, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_73",
            "start": 0,
            "end": 127,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_74@0",
            "content": "Lu\u00eds Borges, Bruno Martins, P\u00e1vel Calado, Combining similarity features and deep representation learning for stance detection in the context of checking fake news, 2019, Journal of Data and Information Quality (JDIQ), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_74",
            "start": 0,
            "end": 218,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_75@0",
            "content": "K Nadia, Victoria Conroy, Yimin Rubin,  Chen, Automatic deception detection: Methods for finding fake news, 2015, Proceedings of the Association for Information Science and Technology, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_75",
            "start": 0,
            "end": 185,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_76@0",
            "content": "Limeng Cui, Haeseung Seo, Maryam Tabar, Fenglong Ma, Suhang Wang, Dongwon Lee, Deterrent: Knowledge guided graph attention network for detecting healthcare misinformation, 2020, Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_76",
            "start": 0,
            "end": 276,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_77@0",
            "content": "UNKNOWN, None, 2018, BERT: pre-training of deep bidirectional transformers for language understanding, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_77",
            "start": 0,
            "end": 107,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_78@0",
            "content": "Siva Charan Reddy, Cheng Gangireddy, Tanmoy Long,  Chakraborty, Unsupervised fake news detection: A graph-based approach, 2020, Proceedings of the 31st ACM Conference on Hypertext and Social Media, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_78",
            "start": 0,
            "end": 198,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_79@0",
            "content": "UNKNOWN, None, 2019, SemEval-2019 task 7: RumourEval, determining rumour veracity and support for rumours, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_79",
            "start": 0,
            "end": 107,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_80@0",
            "content": "UNKNOWN, None, 2019, exBAKE: Automatic fake news detection model based on bidirectional encoder representations from transformers (BERT). Applied Sciences, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_80",
            "start": 0,
            "end": 156,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_81@0",
            "content": "UNKNOWN, None, 2019, Learning hierarchical discourse-level structure for fake news detection, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_81",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_82@0",
            "content": "Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, Wen-Tau Yih, Dense passage retrieval for open-domain question answering, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_82",
            "start": 0,
            "end": 272,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_83@0",
            "content": "UNKNOWN, None, 2018, False information on web and social media: A survey, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_83",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_84@0",
            "content": "UNKNOWN, None, 2019, Multi-level word features based on CNN for fake news detection in cultural communication. Personal and Ubiquitous Computing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_84",
            "start": 0,
            "end": 146,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_85@0",
            "content": "UNKNOWN, None, 1907, Roberta: A robustly optimized BERT pretraining approach, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_85",
            "start": 0,
            "end": 78,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_86@0",
            "content": "Rada Mihalcea, Carlo Strapparava, The lie detector: Explorations in the automatic recognition of deceptive language, 2009, Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_86",
            "start": 0,
            "end": 183,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_87@0",
            "content": "Rahul Mishra, Vinay Setty, Sadhan: Hierarchical attention networks to learn latent aspect embeddings for fake news detection, 2019, Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_87",
            "start": 0,
            "end": 227,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_88@0",
            "content": "Tanushree Mitra, Eric Gilbert, Credbank: A large-scale social media corpus with associated credibility annotations, 2015, ICWSM, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_88",
            "start": 0,
            "end": 129,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_89@0",
            "content": "Kai Nakamura, Sharon Levy, William Wang, Fakeddit: A new multimodal benchmark dataset for fine-grained fake news detection, 2020, Proceedings of the 12th Language Resources and Evaluation Conference, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_89",
            "start": 0,
            "end": 200,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_90@0",
            "content": "Preslav Nakov, Giovanni Da San, Tamer Martino, Alberto Elsayed, Rub\u00e9n Barr\u00f3n-Cede\u00f1o, Shaden M\u00edguez, Firoj Shaar, Fatima Alam, Maram Haouari, Nikolay Hasanain, Alex Babulkov,  Nikolov, Julia Gautam Kishore Shahi, Thomas Stru\u00df,  Mandl, The clef-2021 checkthat! lab on detecting check-worthy claims, previously factchecked claims, and fake news, 2021, Advances in Information Retrieval, Springer International Publishing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_90",
            "start": 0,
            "end": 417,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_91@0",
            "content": "Alexandra Olteanu, Stanislav Peshterliev, Xin Liu, Karl Aberer, Web credibility: Features exploration and credibility prediction, 2013, European conference on information retrieval, Springer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_91",
            "start": 0,
            "end": 190,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_92@0",
            "content": "Ver\u00f3nica P\u00e9rez-Rosas, Bennett Kleinberg, Alexandra Lefevre, Rada Mihalcea, Automatic detection of fake news, 2018, Proceedings of the 27th International Conference on Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_92",
            "start": 0,
            "end": 235,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_93@0",
            "content": "Kashyap Popat, Subhabrata Mukherjee, Jannik Str\u00f6tgen, Gerhard Weikum, Credibility assessment of textual claims on the web, 2016, Proceedings of the 25th ACM International on Conference on Information and Knowledge Management, CIKM '16, Association for Computing Machinery.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_93",
            "start": 0,
            "end": 271,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_94@0",
            "content": "Kashyap Popat, Subhabrata Mukherjee, Jannik Str\u00f6tgen, Gerhard Weikum, Where the truth lies: Explaining the credibility of emerging claims on the web and social media, 2017, Proceedings of the 26th International Conference on World Wide Web Companion, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_94",
            "start": 0,
            "end": 251,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_95@0",
            "content": "Kashyap Popat, Subhabrata Mukherjee, Andrew Yates, Gerhard Weikum, DeClarE: Debunking fake news and false claims using evidence-aware deep learning, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_95",
            "start": 0,
            "end": 284,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_96@0",
            "content": "Yingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang Ren, Wayne Zhao, Daxiang Dong, Hua Wu, Haifeng Wang, Rocketqa: An optimized training approach to dense passage retrieval for opendomain question answering, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_96",
            "start": 0,
            "end": 357,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_97@0",
            "content": "Eunsol Hannah Rashkin, Jin Choi, Svitlana Jang, Yejin Volkova,  Choi, Truth of varying shades: Analyzing language in fake news and political fact-checking, 2017, Proceedings of the 2017 conference on empirical methods in natural language processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_97",
            "start": 0,
            "end": 250,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_98@0",
            "content": "C Julio, Andr\u00e9 Reis, Fabr\u00edcio Correia,  Murai, Explainable machine learning for fake news detection, 2019, Proceedings of the 10th ACM Conference on Web Science, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_98",
            "start": 0,
            "end": 162,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_99@0",
            "content": "Ruiyang Ren, Shangwen Lv, Yingqi Qu, Jing Liu, Wayne Zhao, Qiaoqiao She, Hua Wu, Haifeng Wang, Ji-Rong Wen, Pair: Leveraging passage-centric similarity relation for improving dense passage retrieval, 2021, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_99",
            "start": 0,
            "end": 282,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_100@0",
            "content": "UNKNOWN, None, 2020, Beyond leaderboards: A survey of methods for revealing weaknesses in natural language inference data and models, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_100",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_101@0",
            "content": "UNKNOWN, None, 2018, Fakenewsnet: A data repository with news content, social context and dynamic information for studying fake news on social media, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_101",
            "start": 0,
            "end": 150,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_102@0",
            "content": "UNKNOWN, None, 2019, Recent advances in natural language inference: A survey of benchmarks, resources, and approaches, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_102",
            "start": 0,
            "end": 119,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_103@0",
            "content": "James Thorne, Andreas Vlachos, Christos Christodoulopoulos, Arpit Mittal, FEVER: a large-scale dataset for fact extraction and VERification, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_103",
            "start": 0,
            "end": 332,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_104@0",
            "content": "Andreas Vlachos, Sebastian Riedel, Fact checking: Task definition and dataset construction, 2014, Proceedings of the ACL 2014 Workshop on Language Technologies and Computational Social Science, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_104",
            "start": 0,
            "end": 194,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_105@0",
            "content": "William Yang, Wang , liar, liar pants on fire\": A new benchmark dataset for fake news detection, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_105",
            "start": 0,
            "end": 233,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_106@0",
            "content": "William Yang, Wang , liar, liar pants on fire\": A new benchmark dataset for fake news detection, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Short Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_106",
            "start": 0,
            "end": 204,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_107@0",
            "content": "Youze Wang, Shengsheng Qian, Jun Hu, Quan Fang, Changsheng Xu, Fake news detection via knowledge-driven multimodal graph convolutional networks, 2020, Proceedings of the 2020 International Conference on Multimedia Retrieval, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_107",
            "start": 0,
            "end": 225,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_108@0",
            "content": "Zichao Yang, Diyi Yang, Chris Dyer, Xiaodong He, Alex Smola, Eduard Hovy, Hierarchical attention networks for document classification, 2016, Proceedings of the 2016 conference of the North American chapter of the association for computational linguistics: human language technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_108",
            "start": 0,
            "end": 285,
            "label": {}
        },
        {
            "ix": "402-ARR_v1_109@0",
            "content": "Arkaitz Zubiaga, Maria Liakata, Rob Procter, Geraldine Wong Sak, Peter Hoi,  Tolmie, Analysing how people orient to and spread rumours in social media by looking at conversational threads, 2016, PLOS ONE, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "402-ARR_v1_109",
            "start": 0,
            "end": 205,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "402-ARR_v1_0",
            "tgt_ix": "402-ARR_v1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_0",
            "tgt_ix": "402-ARR_v1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_1",
            "tgt_ix": "402-ARR_v1_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_1",
            "tgt_ix": "402-ARR_v1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_0",
            "tgt_ix": "402-ARR_v1_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_2",
            "tgt_ix": "402-ARR_v1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_4",
            "tgt_ix": "402-ARR_v1_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_5",
            "tgt_ix": "402-ARR_v1_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_6",
            "tgt_ix": "402-ARR_v1_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_7",
            "tgt_ix": "402-ARR_v1_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_8",
            "tgt_ix": "402-ARR_v1_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_3",
            "tgt_ix": "402-ARR_v1_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_3",
            "tgt_ix": "402-ARR_v1_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_3",
            "tgt_ix": "402-ARR_v1_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_3",
            "tgt_ix": "402-ARR_v1_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_3",
            "tgt_ix": "402-ARR_v1_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_3",
            "tgt_ix": "402-ARR_v1_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_3",
            "tgt_ix": "402-ARR_v1_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_3",
            "tgt_ix": "402-ARR_v1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_0",
            "tgt_ix": "402-ARR_v1_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_10",
            "tgt_ix": "402-ARR_v1_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_12",
            "tgt_ix": "402-ARR_v1_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_13",
            "tgt_ix": "402-ARR_v1_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_11",
            "tgt_ix": "402-ARR_v1_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_11",
            "tgt_ix": "402-ARR_v1_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_11",
            "tgt_ix": "402-ARR_v1_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_11",
            "tgt_ix": "402-ARR_v1_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_0",
            "tgt_ix": "402-ARR_v1_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_14",
            "tgt_ix": "402-ARR_v1_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_16",
            "tgt_ix": "402-ARR_v1_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_15",
            "tgt_ix": "402-ARR_v1_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_15",
            "tgt_ix": "402-ARR_v1_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_15",
            "tgt_ix": "402-ARR_v1_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_0",
            "tgt_ix": "402-ARR_v1_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_17",
            "tgt_ix": "402-ARR_v1_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_19",
            "tgt_ix": "402-ARR_v1_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_18",
            "tgt_ix": "402-ARR_v1_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_18",
            "tgt_ix": "402-ARR_v1_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_18",
            "tgt_ix": "402-ARR_v1_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_0",
            "tgt_ix": "402-ARR_v1_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_20",
            "tgt_ix": "402-ARR_v1_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_21",
            "tgt_ix": "402-ARR_v1_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_21",
            "tgt_ix": "402-ARR_v1_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_0",
            "tgt_ix": "402-ARR_v1_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_22",
            "tgt_ix": "402-ARR_v1_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_23",
            "tgt_ix": "402-ARR_v1_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_23",
            "tgt_ix": "402-ARR_v1_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_23",
            "tgt_ix": "402-ARR_v1_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_24",
            "tgt_ix": "402-ARR_v1_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_26",
            "tgt_ix": "402-ARR_v1_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_27",
            "tgt_ix": "402-ARR_v1_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_28",
            "tgt_ix": "402-ARR_v1_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_25",
            "tgt_ix": "402-ARR_v1_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_25",
            "tgt_ix": "402-ARR_v1_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_25",
            "tgt_ix": "402-ARR_v1_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_25",
            "tgt_ix": "402-ARR_v1_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_25",
            "tgt_ix": "402-ARR_v1_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_23",
            "tgt_ix": "402-ARR_v1_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_29",
            "tgt_ix": "402-ARR_v1_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_30",
            "tgt_ix": "402-ARR_v1_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_30",
            "tgt_ix": "402-ARR_v1_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_23",
            "tgt_ix": "402-ARR_v1_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_31",
            "tgt_ix": "402-ARR_v1_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_32",
            "tgt_ix": "402-ARR_v1_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_32",
            "tgt_ix": "402-ARR_v1_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_23",
            "tgt_ix": "402-ARR_v1_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_33",
            "tgt_ix": "402-ARR_v1_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_35",
            "tgt_ix": "402-ARR_v1_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_36",
            "tgt_ix": "402-ARR_v1_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_37",
            "tgt_ix": "402-ARR_v1_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_38",
            "tgt_ix": "402-ARR_v1_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_39",
            "tgt_ix": "402-ARR_v1_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_40",
            "tgt_ix": "402-ARR_v1_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_41",
            "tgt_ix": "402-ARR_v1_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_42",
            "tgt_ix": "402-ARR_v1_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_43",
            "tgt_ix": "402-ARR_v1_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_34",
            "tgt_ix": "402-ARR_v1_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_34",
            "tgt_ix": "402-ARR_v1_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_34",
            "tgt_ix": "402-ARR_v1_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_34",
            "tgt_ix": "402-ARR_v1_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_34",
            "tgt_ix": "402-ARR_v1_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_34",
            "tgt_ix": "402-ARR_v1_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_34",
            "tgt_ix": "402-ARR_v1_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_34",
            "tgt_ix": "402-ARR_v1_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_34",
            "tgt_ix": "402-ARR_v1_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_34",
            "tgt_ix": "402-ARR_v1_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_34",
            "tgt_ix": "402-ARR_v1_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_23",
            "tgt_ix": "402-ARR_v1_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_44",
            "tgt_ix": "402-ARR_v1_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_45",
            "tgt_ix": "402-ARR_v1_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_45",
            "tgt_ix": "402-ARR_v1_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_23",
            "tgt_ix": "402-ARR_v1_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_46",
            "tgt_ix": "402-ARR_v1_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_47",
            "tgt_ix": "402-ARR_v1_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_47",
            "tgt_ix": "402-ARR_v1_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_23",
            "tgt_ix": "402-ARR_v1_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_48",
            "tgt_ix": "402-ARR_v1_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_49",
            "tgt_ix": "402-ARR_v1_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_49",
            "tgt_ix": "402-ARR_v1_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_23",
            "tgt_ix": "402-ARR_v1_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_50",
            "tgt_ix": "402-ARR_v1_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_51",
            "tgt_ix": "402-ARR_v1_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_51",
            "tgt_ix": "402-ARR_v1_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_0",
            "tgt_ix": "402-ARR_v1_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_52",
            "tgt_ix": "402-ARR_v1_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_53",
            "tgt_ix": "402-ARR_v1_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_53",
            "tgt_ix": "402-ARR_v1_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_53",
            "tgt_ix": "402-ARR_v1_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_54",
            "tgt_ix": "402-ARR_v1_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_56",
            "tgt_ix": "402-ARR_v1_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_55",
            "tgt_ix": "402-ARR_v1_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_55",
            "tgt_ix": "402-ARR_v1_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_55",
            "tgt_ix": "402-ARR_v1_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_53",
            "tgt_ix": "402-ARR_v1_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_57",
            "tgt_ix": "402-ARR_v1_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_59",
            "tgt_ix": "402-ARR_v1_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_60",
            "tgt_ix": "402-ARR_v1_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_58",
            "tgt_ix": "402-ARR_v1_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_58",
            "tgt_ix": "402-ARR_v1_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_58",
            "tgt_ix": "402-ARR_v1_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_58",
            "tgt_ix": "402-ARR_v1_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_53",
            "tgt_ix": "402-ARR_v1_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_61",
            "tgt_ix": "402-ARR_v1_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_63",
            "tgt_ix": "402-ARR_v1_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_62",
            "tgt_ix": "402-ARR_v1_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_62",
            "tgt_ix": "402-ARR_v1_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_62",
            "tgt_ix": "402-ARR_v1_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_0",
            "tgt_ix": "402-ARR_v1_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_64",
            "tgt_ix": "402-ARR_v1_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_65",
            "tgt_ix": "402-ARR_v1_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_65",
            "tgt_ix": "402-ARR_v1_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "402-ARR_v1_0",
            "tgt_ix": "402-ARR_v1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_1",
            "tgt_ix": "402-ARR_v1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_2",
            "tgt_ix": "402-ARR_v1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_2",
            "tgt_ix": "402-ARR_v1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_2",
            "tgt_ix": "402-ARR_v1_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_2",
            "tgt_ix": "402-ARR_v1_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_2",
            "tgt_ix": "402-ARR_v1_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_3",
            "tgt_ix": "402-ARR_v1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_4",
            "tgt_ix": "402-ARR_v1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_4",
            "tgt_ix": "402-ARR_v1_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_4",
            "tgt_ix": "402-ARR_v1_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_4",
            "tgt_ix": "402-ARR_v1_4@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_4",
            "tgt_ix": "402-ARR_v1_4@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_4",
            "tgt_ix": "402-ARR_v1_4@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_4",
            "tgt_ix": "402-ARR_v1_4@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_4",
            "tgt_ix": "402-ARR_v1_4@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_4",
            "tgt_ix": "402-ARR_v1_4@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_4",
            "tgt_ix": "402-ARR_v1_4@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_4",
            "tgt_ix": "402-ARR_v1_4@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_5",
            "tgt_ix": "402-ARR_v1_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_5",
            "tgt_ix": "402-ARR_v1_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_5",
            "tgt_ix": "402-ARR_v1_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_5",
            "tgt_ix": "402-ARR_v1_5@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_6",
            "tgt_ix": "402-ARR_v1_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_6",
            "tgt_ix": "402-ARR_v1_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_7",
            "tgt_ix": "402-ARR_v1_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_7",
            "tgt_ix": "402-ARR_v1_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_7",
            "tgt_ix": "402-ARR_v1_7@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_7",
            "tgt_ix": "402-ARR_v1_7@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_8",
            "tgt_ix": "402-ARR_v1_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_9",
            "tgt_ix": "402-ARR_v1_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_10",
            "tgt_ix": "402-ARR_v1_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_10",
            "tgt_ix": "402-ARR_v1_10@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_10",
            "tgt_ix": "402-ARR_v1_10@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_10",
            "tgt_ix": "402-ARR_v1_10@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_10",
            "tgt_ix": "402-ARR_v1_10@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_10",
            "tgt_ix": "402-ARR_v1_10@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_10",
            "tgt_ix": "402-ARR_v1_10@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_11",
            "tgt_ix": "402-ARR_v1_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_12",
            "tgt_ix": "402-ARR_v1_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_12",
            "tgt_ix": "402-ARR_v1_12@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_12",
            "tgt_ix": "402-ARR_v1_12@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_12",
            "tgt_ix": "402-ARR_v1_12@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_12",
            "tgt_ix": "402-ARR_v1_12@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_12",
            "tgt_ix": "402-ARR_v1_12@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_12",
            "tgt_ix": "402-ARR_v1_12@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_12",
            "tgt_ix": "402-ARR_v1_12@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_13",
            "tgt_ix": "402-ARR_v1_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_13",
            "tgt_ix": "402-ARR_v1_13@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_13",
            "tgt_ix": "402-ARR_v1_13@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_13",
            "tgt_ix": "402-ARR_v1_13@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_13",
            "tgt_ix": "402-ARR_v1_13@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_13",
            "tgt_ix": "402-ARR_v1_13@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_14",
            "tgt_ix": "402-ARR_v1_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_15",
            "tgt_ix": "402-ARR_v1_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_16",
            "tgt_ix": "402-ARR_v1_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_16",
            "tgt_ix": "402-ARR_v1_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_16",
            "tgt_ix": "402-ARR_v1_16@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_16",
            "tgt_ix": "402-ARR_v1_16@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_16",
            "tgt_ix": "402-ARR_v1_16@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_16",
            "tgt_ix": "402-ARR_v1_16@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_16",
            "tgt_ix": "402-ARR_v1_16@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_16",
            "tgt_ix": "402-ARR_v1_16@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_17",
            "tgt_ix": "402-ARR_v1_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_17",
            "tgt_ix": "402-ARR_v1_17@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_17",
            "tgt_ix": "402-ARR_v1_17@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_17",
            "tgt_ix": "402-ARR_v1_17@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_17",
            "tgt_ix": "402-ARR_v1_17@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_17",
            "tgt_ix": "402-ARR_v1_17@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_17",
            "tgt_ix": "402-ARR_v1_17@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_17",
            "tgt_ix": "402-ARR_v1_17@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_18",
            "tgt_ix": "402-ARR_v1_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_19",
            "tgt_ix": "402-ARR_v1_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_19",
            "tgt_ix": "402-ARR_v1_19@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_19",
            "tgt_ix": "402-ARR_v1_19@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_19",
            "tgt_ix": "402-ARR_v1_19@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_20",
            "tgt_ix": "402-ARR_v1_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_20",
            "tgt_ix": "402-ARR_v1_20@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_20",
            "tgt_ix": "402-ARR_v1_20@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_20",
            "tgt_ix": "402-ARR_v1_20@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_20",
            "tgt_ix": "402-ARR_v1_20@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_21",
            "tgt_ix": "402-ARR_v1_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_22",
            "tgt_ix": "402-ARR_v1_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_22",
            "tgt_ix": "402-ARR_v1_22@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_22",
            "tgt_ix": "402-ARR_v1_22@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_22",
            "tgt_ix": "402-ARR_v1_22@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_22",
            "tgt_ix": "402-ARR_v1_22@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_22",
            "tgt_ix": "402-ARR_v1_22@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_22",
            "tgt_ix": "402-ARR_v1_22@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_22",
            "tgt_ix": "402-ARR_v1_22@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_22",
            "tgt_ix": "402-ARR_v1_22@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_23",
            "tgt_ix": "402-ARR_v1_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_24",
            "tgt_ix": "402-ARR_v1_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_24",
            "tgt_ix": "402-ARR_v1_24@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_24",
            "tgt_ix": "402-ARR_v1_24@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_24",
            "tgt_ix": "402-ARR_v1_24@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_24",
            "tgt_ix": "402-ARR_v1_24@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_24",
            "tgt_ix": "402-ARR_v1_24@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_24",
            "tgt_ix": "402-ARR_v1_24@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_24",
            "tgt_ix": "402-ARR_v1_24@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_25",
            "tgt_ix": "402-ARR_v1_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_26",
            "tgt_ix": "402-ARR_v1_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_26",
            "tgt_ix": "402-ARR_v1_26@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_26",
            "tgt_ix": "402-ARR_v1_26@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_27",
            "tgt_ix": "402-ARR_v1_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_28",
            "tgt_ix": "402-ARR_v1_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_29",
            "tgt_ix": "402-ARR_v1_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_29",
            "tgt_ix": "402-ARR_v1_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_30",
            "tgt_ix": "402-ARR_v1_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_31",
            "tgt_ix": "402-ARR_v1_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_31",
            "tgt_ix": "402-ARR_v1_31@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_31",
            "tgt_ix": "402-ARR_v1_31@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_31",
            "tgt_ix": "402-ARR_v1_31@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_31",
            "tgt_ix": "402-ARR_v1_31@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_32",
            "tgt_ix": "402-ARR_v1_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_33",
            "tgt_ix": "402-ARR_v1_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_33",
            "tgt_ix": "402-ARR_v1_33@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_33",
            "tgt_ix": "402-ARR_v1_33@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_33",
            "tgt_ix": "402-ARR_v1_33@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_34",
            "tgt_ix": "402-ARR_v1_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_35",
            "tgt_ix": "402-ARR_v1_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_35",
            "tgt_ix": "402-ARR_v1_35@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_35",
            "tgt_ix": "402-ARR_v1_35@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_35",
            "tgt_ix": "402-ARR_v1_35@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_35",
            "tgt_ix": "402-ARR_v1_35@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_36",
            "tgt_ix": "402-ARR_v1_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_37",
            "tgt_ix": "402-ARR_v1_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_38",
            "tgt_ix": "402-ARR_v1_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_38",
            "tgt_ix": "402-ARR_v1_38@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_39",
            "tgt_ix": "402-ARR_v1_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_39",
            "tgt_ix": "402-ARR_v1_39@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_39",
            "tgt_ix": "402-ARR_v1_39@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_40",
            "tgt_ix": "402-ARR_v1_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_41",
            "tgt_ix": "402-ARR_v1_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_41",
            "tgt_ix": "402-ARR_v1_41@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_41",
            "tgt_ix": "402-ARR_v1_41@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_42",
            "tgt_ix": "402-ARR_v1_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_43",
            "tgt_ix": "402-ARR_v1_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_43",
            "tgt_ix": "402-ARR_v1_43@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_43",
            "tgt_ix": "402-ARR_v1_43@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_44",
            "tgt_ix": "402-ARR_v1_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_44",
            "tgt_ix": "402-ARR_v1_44@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_44",
            "tgt_ix": "402-ARR_v1_44@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_45",
            "tgt_ix": "402-ARR_v1_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_46",
            "tgt_ix": "402-ARR_v1_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_47",
            "tgt_ix": "402-ARR_v1_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_48",
            "tgt_ix": "402-ARR_v1_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_48",
            "tgt_ix": "402-ARR_v1_48@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_48",
            "tgt_ix": "402-ARR_v1_48@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_49",
            "tgt_ix": "402-ARR_v1_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_50",
            "tgt_ix": "402-ARR_v1_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_50",
            "tgt_ix": "402-ARR_v1_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_50",
            "tgt_ix": "402-ARR_v1_50@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_50",
            "tgt_ix": "402-ARR_v1_50@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_50",
            "tgt_ix": "402-ARR_v1_50@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_50",
            "tgt_ix": "402-ARR_v1_50@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_51",
            "tgt_ix": "402-ARR_v1_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_52",
            "tgt_ix": "402-ARR_v1_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_52",
            "tgt_ix": "402-ARR_v1_52@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_52",
            "tgt_ix": "402-ARR_v1_52@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_52",
            "tgt_ix": "402-ARR_v1_52@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_53",
            "tgt_ix": "402-ARR_v1_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_54",
            "tgt_ix": "402-ARR_v1_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_55",
            "tgt_ix": "402-ARR_v1_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_56",
            "tgt_ix": "402-ARR_v1_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_56",
            "tgt_ix": "402-ARR_v1_56@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_57",
            "tgt_ix": "402-ARR_v1_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_57",
            "tgt_ix": "402-ARR_v1_57@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_57",
            "tgt_ix": "402-ARR_v1_57@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_57",
            "tgt_ix": "402-ARR_v1_57@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_58",
            "tgt_ix": "402-ARR_v1_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_59",
            "tgt_ix": "402-ARR_v1_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_60",
            "tgt_ix": "402-ARR_v1_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_60",
            "tgt_ix": "402-ARR_v1_60@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_60",
            "tgt_ix": "402-ARR_v1_60@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_61",
            "tgt_ix": "402-ARR_v1_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_61",
            "tgt_ix": "402-ARR_v1_61@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_61",
            "tgt_ix": "402-ARR_v1_61@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_61",
            "tgt_ix": "402-ARR_v1_61@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_61",
            "tgt_ix": "402-ARR_v1_61@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_61",
            "tgt_ix": "402-ARR_v1_61@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_61",
            "tgt_ix": "402-ARR_v1_61@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_61",
            "tgt_ix": "402-ARR_v1_61@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_61",
            "tgt_ix": "402-ARR_v1_61@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_61",
            "tgt_ix": "402-ARR_v1_61@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_62",
            "tgt_ix": "402-ARR_v1_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_63",
            "tgt_ix": "402-ARR_v1_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_63",
            "tgt_ix": "402-ARR_v1_63@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_63",
            "tgt_ix": "402-ARR_v1_63@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_63",
            "tgt_ix": "402-ARR_v1_63@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_63",
            "tgt_ix": "402-ARR_v1_63@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_63",
            "tgt_ix": "402-ARR_v1_63@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_63",
            "tgt_ix": "402-ARR_v1_63@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_63",
            "tgt_ix": "402-ARR_v1_63@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_63",
            "tgt_ix": "402-ARR_v1_63@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_63",
            "tgt_ix": "402-ARR_v1_63@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_64",
            "tgt_ix": "402-ARR_v1_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_64",
            "tgt_ix": "402-ARR_v1_64@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_64",
            "tgt_ix": "402-ARR_v1_64@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_64",
            "tgt_ix": "402-ARR_v1_64@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_64",
            "tgt_ix": "402-ARR_v1_64@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_64",
            "tgt_ix": "402-ARR_v1_64@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_64",
            "tgt_ix": "402-ARR_v1_64@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_64",
            "tgt_ix": "402-ARR_v1_64@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_64",
            "tgt_ix": "402-ARR_v1_64@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_64",
            "tgt_ix": "402-ARR_v1_64@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_65",
            "tgt_ix": "402-ARR_v1_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_66",
            "tgt_ix": "402-ARR_v1_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_66",
            "tgt_ix": "402-ARR_v1_66@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_66",
            "tgt_ix": "402-ARR_v1_66@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_66",
            "tgt_ix": "402-ARR_v1_66@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_66",
            "tgt_ix": "402-ARR_v1_66@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_66",
            "tgt_ix": "402-ARR_v1_66@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_66",
            "tgt_ix": "402-ARR_v1_66@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_66",
            "tgt_ix": "402-ARR_v1_66@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_66",
            "tgt_ix": "402-ARR_v1_66@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_66",
            "tgt_ix": "402-ARR_v1_66@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_67",
            "tgt_ix": "402-ARR_v1_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_68",
            "tgt_ix": "402-ARR_v1_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_69",
            "tgt_ix": "402-ARR_v1_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_70",
            "tgt_ix": "402-ARR_v1_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_71",
            "tgt_ix": "402-ARR_v1_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_72",
            "tgt_ix": "402-ARR_v1_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_73",
            "tgt_ix": "402-ARR_v1_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_74",
            "tgt_ix": "402-ARR_v1_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_75",
            "tgt_ix": "402-ARR_v1_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_76",
            "tgt_ix": "402-ARR_v1_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_77",
            "tgt_ix": "402-ARR_v1_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_78",
            "tgt_ix": "402-ARR_v1_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_79",
            "tgt_ix": "402-ARR_v1_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_80",
            "tgt_ix": "402-ARR_v1_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_81",
            "tgt_ix": "402-ARR_v1_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_82",
            "tgt_ix": "402-ARR_v1_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_83",
            "tgt_ix": "402-ARR_v1_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_84",
            "tgt_ix": "402-ARR_v1_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_85",
            "tgt_ix": "402-ARR_v1_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_86",
            "tgt_ix": "402-ARR_v1_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_87",
            "tgt_ix": "402-ARR_v1_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_88",
            "tgt_ix": "402-ARR_v1_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_89",
            "tgt_ix": "402-ARR_v1_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_90",
            "tgt_ix": "402-ARR_v1_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_91",
            "tgt_ix": "402-ARR_v1_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_92",
            "tgt_ix": "402-ARR_v1_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_93",
            "tgt_ix": "402-ARR_v1_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_94",
            "tgt_ix": "402-ARR_v1_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_95",
            "tgt_ix": "402-ARR_v1_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_96",
            "tgt_ix": "402-ARR_v1_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_97",
            "tgt_ix": "402-ARR_v1_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_98",
            "tgt_ix": "402-ARR_v1_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_99",
            "tgt_ix": "402-ARR_v1_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_100",
            "tgt_ix": "402-ARR_v1_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_101",
            "tgt_ix": "402-ARR_v1_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_102",
            "tgt_ix": "402-ARR_v1_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_103",
            "tgt_ix": "402-ARR_v1_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_104",
            "tgt_ix": "402-ARR_v1_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_105",
            "tgt_ix": "402-ARR_v1_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_106",
            "tgt_ix": "402-ARR_v1_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_107",
            "tgt_ix": "402-ARR_v1_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_108",
            "tgt_ix": "402-ARR_v1_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "402-ARR_v1_109",
            "tgt_ix": "402-ARR_v1_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 1329,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "position_tag_type": "from_draft",
        "doc_id": "402-ARR",
        "version": 1
    }
}