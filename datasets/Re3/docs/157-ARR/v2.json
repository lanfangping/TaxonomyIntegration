{
    "nodes": [
        {
            "ix": "157-ARR_v2_0",
            "content": "DYNAMICTOC: Persona-based Table of Contents for Consumption of Long Documents",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_2",
            "content": "Long documents like contracts, financial documents, etc., are often tedious to read through. Linearly consuming (via scrolling or navigation through default table of content) these documents is time-consuming and challenging. These documents are also authored to be consumed by varied entities (referred to as persona in the paper) interested in only certain parts of the document. In this work, we describe DYNAMICTOC, a dynamic table of contentbased navigator, to aid in the task of non-linear, persona-based document consumption. DY-NAMICTOC highlights sections of interest in the document as per the aspects relevant to different personas. DYNAMICTOC is augmented with short questions to assist the users in understanding underlying content. This uses a novel deep-reinforcement learning technique to generate questions on these persona-clustered paragraphs. Human and automatic evaluations suggest the efficacy of both end-to-end pipeline and different components of DYNAMICTOC.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "157-ARR_v2_4",
            "content": "Documents such as financial statements, reports and contracts are often long and comprehensive, replete with domain-specific description and information. They are meant to be consumed by several entities or personas, e.g. legal department of companies, customers or financial organizations such as banks. As these documents contain vital information about the business, the business personas are often required to read through and analyze the documents in details. These personas are often interested in different sections of the document, based on the business requirements. For example, employees might be interested in the stock programs of the company, whereas the lenders and investors would like to read through profit statements. The traditional technology to navigate long documents is through a Table of Contents (ToC) populated with the heading of each section and chapters. However, the Table of Contents does not show the information present in the underlying paragraphs of a section, and there is no way to highlight information relevant to different personas.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_5",
            "content": "To this effect, we propose DYNAMICTOC, an intelligent table of contents-based navigator. DY-NAMICTOC provides user the flexibility to choose the persona and read the document from its lens. For the current work, we focus on the finance and legal domain, and hence, personas are taken as commonplace entities like investors, lenders, financial bodies, etc. DYNAMICTOC highlights the relevant sections of the document as per the persona. For this, the input finance or contract document is segmented at the paragraph level and a cluster of \"aspects or topics\" is inferred for each para. These are then mapped to the interest topics of the personas. Further, DYNAMICTOC has a novel question-based guided experience, to enhance the visibility of underlying information. Studies have shown that questions are more intuitive and informative than headings and hence can provide a better understanding of what the paragraph talks about. The overall interface is shown in Figure 1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_6",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "157-ARR_v2_7",
            "content": "Document understanding is a critical and challenging task in information processing. There have been many related research works in this direction. Keyword detection (Liu et al., 2009;Tixier et al., 2016) & topic modeling (Blei et al., 2001) works aim is to describe the document by a few important words or topics for concise representation. The first step is to acquire a list of keyword candidates (e.g., n-grams or chunks) with heuristic methods (Hulth, 2003;Shang et al., 2018), then rank them in accordance with their importance to the document (Wu et al., 2005;Gollapalli and Caragea, 2014;Bougouin et al., 2013). Another task is compact and informative headline generation from a document (Dorr et al., 2003;Lopyrev, 2015). Text summarization is the process of generating natural language summaries from an input document retaining the most important information (Rush et al., 2015;See et al., 2017). Recently, an Outline Generation task was introduced by as a hierarchical structured prediction problem. Given a document, their aim is to first predict a sequence of section boundaries and then a sequence of section headings accordingly to come up with a Table of Contents for the same.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_8",
            "content": "A related direction of work to ours is of aspect detection, which has been explored in the literature largely using user reviews for products. Early works focused on rule-based approaches using lexicons and dependency relations, and utilize manually defined rules to identify patterns and extract aspects (Qiu et al., 2011;Liu et al., 2016), which require domain-specific knowledge and human expertise. Supervised approaches formulate aspect extraction as a sequence labelling problem that can be solved by hidden Markov models (HMM) (Jin et al., 2009), conditional random fields (CRF) (Li et al., 2010;Mitchell et al., 2013;Yang and Cardie, 2012), and recurrent neural networks (RNN) (Wang et al., 2016;Liu et al., 2015). These approaches have shown better performance compared to the rule-based ones, but require large amounts of labelled data for training. Early unsupervised systems are dominated by Latent Dirichlet Allocation (LDA)-based topic models (Garc\u00eda-Pablos et al., 2018;Shi et al., 2018;\u00c1lvarez-L\u00f3pez et al., 2016). Recently, deep learning based topic models (Srivastava and Sutton, 2017;Luo et al., 2019;He et al., 2017;Shi et al., 2021) have shown strong performance in extracting coherent aspects in an unsupervised manner. None of the prior works on aspect detection have worked with contracts or financial documents that are quite long (50-100 pages) in comparison to user reviews. Even if we break the document at paragraph level, it can still go over tens of lines. Hence, the importance of word frequency is much more in our case. We bridge the gap between directly using the unsupervised aspect detection frameworks for the financial documents by adding a TF-IDF based weighing parameter while training. Moreover, there are no gold standards for aspect detection for contract or finance domain, hence, we use unsupervised clustering based metrics for validating the output detection.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_9",
            "content": "Further, it has been shown that question-answers play a critical role in scientific inquiry, informationseeking dialogue, and knowledge acquisition (Hintikka and Saarinen, 1979;Stede and Schlangen, 2004). In a dialogue system, question generation is used to obtain specific information from the user or make the conversation more pleasant (Shukla et al., 2019;Saeidi et al., 2018). Hence, we hypothesize that augmenting the default ToC with Questions that give a high level overview of the paragraphs can enhance the reading experience of the users. Question generation can also be seen as a summarization or seq2seq task. Various pre-trained language models like BART (Lewis et al., 2020), PEGASUS (Zhang et al., 2020), etc., have shown excellent results for these tasks. Researchers have worked on top of these language models & proposed various rewards for QGen to optimize these models. (Kumar et al., 2019) has employed BLEUbased rewards, (Zhang and Bansal, 2019) have used answerability rewards, whereas (Xie et al., 2020) has used a combination of fluency, relevance, and answerability rewards.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_10",
            "content": "Previous question generation literature has focused on generating questions based on an entity, phrase, or sentence. In this work, we explore longform question generation, i.e., question-based long text. We explore deep reinforcement learning techniques for the same. as they have shown competitive results in various natural language generation tasks such as summarization (Pasunuru and Bansal, 2018), style transfer (Liu et al., 2021;Goyal et al., 2021), question generation (Hosking and Riedel, 2019;Xie et al., 2020) etc. Motivated by this we use BART as our base model. As there is a lack of labeled question datasets in financial domain, to overcome the domain shift problem, we train the model with additional rewards in a reinforcement learning setup to make more suitable for a general domain.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_11",
            "content": "There are several commercial products for reading documents across devices, but all of them have a fixed document navigation, based on chapters and headings. To the best of our knowledge, there is no prior art looking into providing an end-to-end persona-based navigation. The mentioned technologies address only part of the required solutions. Following are the key contributions of our work:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_12",
            "content": "1. We propose a novel DYNAMICTOC technology to enable persona-based non-linear navigation for efficient consumption of long documents.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_13",
            "content": "2. We extend the unsupervised aspect detection to long domain-specific documents by combining TF-IDF with aspect detection process to make it more robust and show the improvements experimentally.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_14",
            "content": "3. We propose a method to generate questions based on the content of the paragraph maximizing the information coverage, entity correctness & answerability of the question.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_15",
            "content": "4. We showcase the viability of our pipeline and evaluate it using metric-based and a human survey-based evaluation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_16",
            "content": "3 Datasets SEC Filing: The SEC filing is a financial statement document submitted to the U.S. Securities and Exchange Commission. Public companies, certain insiders, and broker-dealers are required to make regular SEC filings. There are many types of documents available on the EDGAR website (Eg. 10-K, 10-Q, Form 4, etc.). For our work, we focused on the SEC 10-K documents available on the EDGAR website 1 . For a given company, the 10-k documents are available in HTML, XBRL and XML format. The complete submission text file for a 10-k document (XML) was used for parsing.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_17",
            "content": "We split the document content into different items ranging from item 1 to item 16. These 10-K documents range from 50 to 120 pages and contain multiple tables along with text paragraphs. ELI5: We use the ELI5 dataset ) to train the question generation model. ELI5 or Explain Like I'm 5, is a question-answer dataset scraped from the subreddit r/explainlikeimfive/. The subreddit rules encourage people to ask a question about any topic and get an answer for it. To maintain the dataset's quality, we only select those question-answer pairs with more than two upvotes. Note that no dataset for such question generation task exists for contractual and financial documents. Hence, we resort to use the ELI5 dataset for supervised training and use that model for inferencing on documents from a different domain. To test the model's performance on the domainspecific dataset, we also scrape question-answer pairs from two different subreddits -r/AskLegal and r/AskEconomics. As the name suggests, they contain questions (and answers) from the legal and economics domain respectively. Table 1 includes the statistics of the three datasets.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_18",
            "content": "Methodology",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "157-ARR_v2_19",
            "content": "In this section, different components of the DY-NAMICTOC are described in details.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_20",
            "content": "Aspect Detection",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "157-ARR_v2_21",
            "content": "Aspect detection has been popularly used with analysing user reviews to understand their preferences. We leverage an unsupervised technique for aspect detection and extend it to a new use case -for the modelling of user profiles from a given document and using this info for segregating the document text based on the determined aspects. Data Pre-processing: For the input SEC filings, text corresponding to each paragraph is obtained and considered as a separate data point. Extra information such as headings, sub-headings, blank lines, signature fields etc. are discarded. Along with this, any paragraph with less than 10 words are discarded. The text is pre-processed before training the model for aspect detection. We require three formatting styles for each paragraph which is consolidated in a single dictionary. (1) Tokenized words converted to lowercase characters. (2) The word stems of the text which has been lower-cased and tokenised. (3) The content words (meaningful words, like nouns, verbs, adjectives and adverbs) of the paragraph.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_22",
            "content": "Proposed Asp-SSCL Method: Aspect detection aims at extracting interpretable aspects from the textual documents without human supervision. We propose an approach, Asp-SSCL based on selfsupervised contrastive learning framework by (Shi et al., 2021) for aspect detection. We use the following steps for aspect detection from the contractual and financial documents:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_23",
            "content": "1. Vocabulary formation and IDF indexing: First, we obtain a vocabulary for the whole corpus. This is sorted alphabetically and each word is given an index, so that corresponding IDF/word vectors can be easily referenced. 128-dimensional word vectors are generated on the corpus by a skip-gram model with an n-gram size of 5.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_24",
            "content": "2. Weak Mapping: Prior aspect detection methods require a gold set labels for validating aspect model training, either through human supervision or rules-based mapping to gold set keywords. However, as no such gold aspect labels exist for our case, we first use text embedding via sentence transformers 2 . These are then clustered using K-means to obtain 20 clusters comprising of 10 keywords each, which are used for aspect mapping.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_25",
            "content": "3. Contrastive Learning: The mapping and generated word vectors are then used for training the self-supervised contrastive learning method, (Shi et al., 2021), which outputs the final aspect clusters and keywords.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_26",
            "content": "4. TF-IDF Weighing: Further, since these documents are text-heavy, we introduce a modification, Asp-SSCL-TFIDF which includes TF-IDF weighing term in the original implementation, to ensure rare but relevant words are considered as important as opposed to more frequently occurring words. Each word representation is modified by multiplying it with the TF-IDF score so that the algorithm can adapt to the financial corpus better.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_27",
            "content": "Persona Mapping",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "157-ARR_v2_28",
            "content": "The aspects generated on the corpus are used as dimensions that define the document. Each persona is expected to be interested in one or more of these dimensions. We call the mapping between multiple personas and multiple aspects as the persona space.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_29",
            "content": "We consulted a domain expert (financial domain; specifically for SEC 10-K filings) to create a matrix of personas, who read such documents, and what kind of information they are interested in. Figure 2 lists out the various stakeholders of a general 10-K filing against the different sections of the document each stakeholder is interested in. The stakeholders are grouped together to form the personas used in DYNAMICTOC, viz. employees, business partners, investors and lendors, financial bodies and advisory and regulatory firms. Similarly, the columns (headings) are grouped together according to similarity to create a mapping of topics of interest for each persona.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_30",
            "content": "We can map these columns to the aspects we get from the Aspect Detection Module and determine if a particular persona is interested in that paragraph or not. For this, the aspects obtained from the unsupervised technique are compared against the simplified column values from the constructed matrix. The columns with the greatest similarity (above a threshold) are associated with each persona. For getting the personas interested in each paragraph, the paragraphs are first tagged for aspect. From the resultant vector (which represents the confidence score of the text for each aspect), the combined score for each persona is calculated using the scores of its constituent aspects. This Similar column topics have also been grouped for aspect mapping.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_31",
            "content": "is used to segregate the paragraphs for enhanced document consumption. Note that for financial documents, we were able to gather domain knowledge and leverage it to obtain the persona space. But the proposed technique is generalizable to other domains as well. In the absence of domain-specific knowledge, each aspect is a sufficiently distinct topic and can be treated as a proxy to personas. Hence, modelling of interests can be done directly on the basis of aspects in such cases.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_32",
            "content": "Intelligent Navigation via Question Generation",
            "ntype": "title",
            "meta": {
                "section": "4.3"
            }
        },
        {
            "ix": "157-ARR_v2_33",
            "content": "It has been shown that question-answers play a critical role in scientific inquiry, information-seeking dialogue, and knowledge acquisition (Hintikka and Saarinen, 1979;Stede and Schlangen, 2004). Additionally, unstructured lists of \"Frequently Asked Questions (FAQs)\" are regularly deployed at scale to present information. On top, questions can provide a meaningful understanding of the document at a paragraph or section level which cannot be directly captured by a heading (or sub-heading). Therefore, to aid in document consumption, we generate long-form questions (i.e., questions based on paragraphs instead of entities) to enhance the navigation experience.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_34",
            "content": "Model Architecture: We use an encoderdecoder architecture for the task of generating questions given the paragraph as context which essentially is a sequence-to-sequence task. Large pretrained language models like BART (Lewis et al., 2020), PEGASUS (Zhang et al., 2020), etc., have shown excellent results in summarization tasks. Motivated by this, we employ BART as our under-lying language model. The task is to generate questions covering the entire paragraph and summarize it capturing the most-salient information in form of a question. The BART model has shown promising results in abstractive summarization tasks, making it a natural choice. We use ELI5 dataset for training the model. The answer is provided as the input to the encoder-decoder model which is trained to generate the corresponding question and minimize the cross-entropy loss with respect to the ground truth. Although such supervised training is straight-forward, due to the domain shift from ELI5 to financial language, qualitative evaluations showed that the model produced some irrelevant questions, some entities were artificially induced (that it might have seen during the training time) and sometimes, it could not cover the entire paragraph. Hence, we augmented the vanilla BART with three additional rewards targeting the qualities we seek in the final generated questions. We call the resulting model Variant BART. Figure 3 shows the proposed pipeline. The following sections explain these rewards in detail: \u2022 Answerability Classifier Reward: Qualitative evaluations showed some of the questions generated were not answerable by the paragraph, making them unsuitable for the task of understanding the paragraph easily. To address this, we trained a classifier to judge the answerability of the question given the paragraph. Basically, the paragraph and the generated question would be fed as input to the classifier and the classifier predicts \"1\" if the question is answerable by the para, otherwise \"0\". The classifier is a fine-tuned Roberta model. We create data with both positive and negative samples to fine tune the Roberta model. We use the following strategy to create the training data for the binary classifier: (a) We select 10,000 random question-answer pairs from the ELI5 dataset. Note that in ELI5 data, some questions have multiple answer paras too. All these forms our positive samples. To create negative samples for a question Q', we take its corresponding answer para, A', and a random set of 100 question-answer pairs. We compare the similarity of the answer para (A') with all the 100 answers. Top 3 most similar answers are taken as the negative samples for the question Q'. (b) Given that style of ELI5 answers and Wikipedia paragraphs are very similar 3 , we create negative samples in another way as well to introduce diversity. Wikipedia articles are chosen based on their similarity with ELI5 data and for each question, we compute the similarity score with each para in the wiki articles. The topmost similar paras are of interest, and we sample 10 most similar paras out of top 20 and call them our negative samples. \u2022 Entity Correctness Reward: The vanilla BART model can generated questions with hallucinated entities and names like Microsoft, Apple etc. even when there was no mention of them in the corresponding paragraph. To tackle this, we identify the named entities present in the generated question. If those entities appear in the passage, we give a reward of 1 else 0. If there is no entity in the generated question, a reward of 0.5 is given to the model. Mathematically, reward is given by:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_35",
            "content": "R entity = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 1, if e(Q) \u0338 = \u03d5, e(Q) \u2286 e(P ) 0, if e(Q) \u0338 = \u03d5, e(Q) \u0338 \u2286 e(P ) 0.5, if e(Q) = \u03d5",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_36",
            "content": "where, e(.) denotes the entities in the question or paragraph.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_37",
            "content": "\u2022 Coverage Reward: We observe that the output question did not cover the entire information present in the paragraph and instead focused on certain segments of it. We introduce this reward to improve information coverage.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_38",
            "content": "The idea is similar to the entity correctness reward. We first identify keywords from the paragraph using YAKE algorithm (Campos et al., 2018). Then we calculate the similarity of the generated question with these keywords. We use the Extended String Subsequence Kernel (ESSK) introduced in (Hirao et al., 2003) to calculate this similarity score. The idea is that YAKE would generate keywords from different parts of the paragraph. When we calculate the similarity of this keyword list with the generated question, we are encouraging the model to cover the entire paragraph. Thus, given a passage P and the generated question Q, the reward R is defined as follows: et al., 2021) shows how to use rewards on top of language models for policy learning. We adopt the same setup. The policy gradient, \u2207 \u03d5 J(\u03d5) is given by:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_39",
            "content": "R coverage = ESSK(Y AKE(P ), Q) (Lai",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_40",
            "content": "\u2207 \u03d5 J(\u03d5) = E[R \u2022 \u2207 \u03d5 log(P (y s |x, \u03d5))](1)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_41",
            "content": "where, R denotes reward value, \u03d5 represents the model parameters, x is the input paragraph and y s is obtained by greedily maximizing the distribution of BART outputs at each timestep. Hence, the overall loss term for training the proposed Variant BART model becomes:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_42",
            "content": "L total = \u03bb CE \u2022 L CE + \u03bb reward \u2022 L reward (2)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_43",
            "content": "Results & Discussion",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "157-ARR_v2_44",
            "content": "In order to evaluate the different parts of the pipeline, we employ metric based evaluation schemes. Since there is no off-the-shelf criterion to evaluate all the stages of the pipeline together, we have provided independent evaluations for each of the sub-modules. However, the intended goal of our pipeline is to facilitate the readers in consuming long documents through the lens they deem most suitable for them. To facilitate an end-to-end evaluation and to understand whether the persona-based document segmentation with enhanced Table of Content is informative or not, we have conducted a small scale human evaluation. Both metric-based and human-based evaluations are discussed in the following subsections.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_45",
            "content": "Metric-Based Evaluation",
            "ntype": "title",
            "meta": {
                "section": "5.1"
            }
        },
        {
            "ix": "157-ARR_v2_46",
            "content": "Aspect Detection: Figure 4 shows the t-SNE 4 clustering of the outputs of Asp-SSCL, Asp-SSCL-TFIDF, that are determined from the SEC-10K filing corpus. For a baseline comparison, we also plot the output for LDA (10 clusters) for the corpus. Essentially, each cluster is a bag of words indicating some vital theme that is mentioned in the corpus.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_47",
            "content": "We would want the clusters to be as independent from each other as possible as that would mean different kinds of information is captured by different clusters with minimal overlap. We observe that adding TF-IDF scores to the aspect detection module helps as the clusters' separation gets better as shown in the Figure 4. Further, for the baseline using LDA, the separation is not clear. Some of the examples of cluster keywords are shown in Figure 5.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_48",
            "content": "Question Generation: Since no ground truth questions are available for the SEC-10K Filing dataset, we report the following evaluations for the question generation module. First, we report the \"type\" of questions that are generated using the Vanilla BART model and the Variant BART model that is trained with a combination of the rewards we added on top of it (Table 3) .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_49",
            "content": "On analysing this table, we see that \"What\" questions are heavily generated on the 10K filing data. This suggests that the nature of 10K filing is such that the question asked about them is \"What\" type. We also observe that biases of training data are not creeping in the model, as the percentage of the \"What\" questions in the training dataset is four times less than the model's output. Similarly, the percentage of other questions is significant in the ELI5 dataset but is very small in our model's output. Thus, we can safely say that the model learns to generate questions and not mimic the ELI5 dataset. Although we don't have the gold corpus for SEC filing dataset, we evaluate the performance of question generation model on the AskLegal and AskEconomics subreddits since we have the ground truth questions for them. We report the BLEU and ROUGE scores that are standard metrics in Natural Language Processing literature and are a measure of overlap or common n-grams between the generated text and the ground truth. We also report the answerability score by feeding the generated question and input para to the classifier we trained (as mentioned in Reward 1 -Question Generation Section). Table 4 shows the corresponding results. On closely analysing the paragraph, reference question, and the generated question, we observe the following three things: (i) There is more than one way to ask the same question and there could be multiple questions around the same topic. (ii) Input paragraphs may have more than one prominent topics. The generated question might be focused on one such topic, and the reference question is focused on another. (iii) Some answers/passages are unrelated to the question or require some background, and thus, the generated questions are very different from the actual question.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_50",
            "content": "The above reasons explain the fluctuation in scores for Vanilla and Variant BART, and thus the answerability of the generated question becomes an important metric. The variant model trained with additional rewards has the highest answerability score across all the datasets. This suggests that including a coverage-based loss not only helps cover the information of the entire paragraph but also helps increase the generated question's answerability as different themes of the passages are covered.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_51",
            "content": "Human Evaluation",
            "ntype": "title",
            "meta": {
                "section": "5.2"
            }
        },
        {
            "ix": "157-ARR_v2_52",
            "content": "We conducted a small human evaluation involving 8 participants (age -27.8 \u00b1 6.7, 2 females). The participants were technology workers internal to our organization. They were asked to play around with a web demo to experience the DYNAMICTOC, for different SEC filings. They were first shown the default section heading-based reading experience and then they choose the type of persona as whom they wish to consume the document. After this, they filled a questionnaire about their experience. The results of the survey are summarized in Table 5.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_53",
            "content": "Some relevant comments from the survey are as follows -(i) How do we ensure that all the relevant information will be covered by the sections highlighted as important for a particular \"persona\"? (ii) Although questions generated are relevant, some of the why questions are not answered by the paragraphs they point to. (iii) Interesting experiment with possibly multiple use-cases. The first comment is actually true for all summarization tasks, hence, DYNAMICTOC does not disrupt the linear flow. The second feedback indicates scope for further research in the question generation space. The overall response is immensely positive and the scores of 4.50, 4.16 and 4.40 in Table 5 reflect the same.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_54",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "157-ARR_v2_55",
            "content": "In this work, we have proposed a novel DYNAM-ICTOC framework for consumption of long documents. Financial documents are high value documents for businesses, and are often long and complex. The default ToC-based reading experience is quite limited and document consumption can be enhanced using intelligent technologies. DY-NAMICTOC is one of the first works to pursue this exciting research direction. DYNAMICTOC would benefit from in-domain learning of aspect keywords and questions. Evaluation of paragraph segmentation and mapping of personas to the aspects are future directions. A better understanding of personas would generalize the work to different domains.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "157-ARR_v2_56",
            "content": "Tamara \u00c1lvarez-L\u00f3pez, Jonathan Juncal-Mart\u00ednez, Milagros Fern\u00e1ndez-Gavilanes, Enrique Costa-Montenegro, Francisco Gonz\u00e1lez-Casta\u00f1o, GTI at SemEval-2016 task 5: SVM and CRF for aspect detection and unsupervised aspectbased sentiment analysis, 2016, Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016), Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "Tamara \u00c1lvarez-L\u00f3pez",
                    "Jonathan Juncal-Mart\u00ednez",
                    "Milagros Fern\u00e1ndez-Gavilanes",
                    "Enrique Costa-Montenegro",
                    "Francisco Gonz\u00e1lez-Casta\u00f1o"
                ],
                "title": "GTI at SemEval-2016 task 5: SVM and CRF for aspect detection and unsupervised aspectbased sentiment analysis",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "157-ARR_v2_57",
            "content": "David Blei, Andrew Ng, Michael Jordan, Latent dirichlet allocation, 2001-12-03, Advances in Neural Information Processing Systems 14 [Neural Information Processing Systems: Natural and Synthetic, MIT Press.",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "David Blei",
                    "Andrew Ng",
                    "Michael Jordan"
                ],
                "title": "Latent dirichlet allocation",
                "pub_date": "2001-12-03",
                "pub_title": "Advances in Neural Information Processing Systems 14 [Neural Information Processing Systems: Natural and Synthetic",
                "pub": "MIT Press"
            }
        },
        {
            "ix": "157-ARR_v2_58",
            "content": "Adrien Bougouin, Florian Boudin, B\u00e9atrice Daille, TopicRank: Graph-based topic ranking for keyphrase extraction, 2013, Proceedings of the Sixth International Joint Conference on Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "Adrien Bougouin",
                    "Florian Boudin",
                    "B\u00e9atrice Daille"
                ],
                "title": "TopicRank: Graph-based topic ranking for keyphrase extraction",
                "pub_date": "2013",
                "pub_title": "Proceedings of the Sixth International Joint Conference on Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "157-ARR_v2_59",
            "content": "Ricardo Campos, V\u00edtor Mangaravite, Arian Pasquali, Al\u00edpio M\u00e1rio Jorge, C\u00e9lia Nunes, Adam Jatowt, Yake! collection-independent automatic keyword extractor, 2018, European Conference on Information Retrieval, Springer.",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Ricardo Campos",
                    "V\u00edtor Mangaravite",
                    "Arian Pasquali",
                    "Al\u00edpio M\u00e1rio Jorge",
                    "C\u00e9lia Nunes",
                    "Adam Jatowt"
                ],
                "title": "Yake! collection-independent automatic keyword extractor",
                "pub_date": "2018",
                "pub_title": "European Conference on Information Retrieval",
                "pub": "Springer"
            }
        },
        {
            "ix": "157-ARR_v2_60",
            "content": "Bonnie Dorr, David Zajic, Richard Schwartz, Hedge trimmer: A parse-and-trim approach to headline generation, 2003, Proceedings of the HLT-NAACL 03 Text Summarization Workshop, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Bonnie Dorr",
                    "David Zajic",
                    "Richard Schwartz"
                ],
                "title": "Hedge trimmer: A parse-and-trim approach to headline generation",
                "pub_date": "2003",
                "pub_title": "Proceedings of the HLT-NAACL 03 Text Summarization Workshop",
                "pub": null
            }
        },
        {
            "ix": "157-ARR_v2_61",
            "content": "Angela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, Michael Auli, ELI5: Long form question answering, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "Angela Fan",
                    "Yacine Jernite",
                    "Ethan Perez",
                    "David Grangier",
                    "Jason Weston",
                    "Michael Auli"
                ],
                "title": "ELI5: Long form question answering",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "157-ARR_v2_62",
            "content": "Aitor Garc\u00eda-Pablos, Montse Cuadros, German Rigau, W2vlda: almost unsupervised system for aspect based sentiment analysis, 2018, Expert Systems with Applications, .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "Aitor Garc\u00eda-Pablos",
                    "Montse Cuadros",
                    "German Rigau"
                ],
                "title": "W2vlda: almost unsupervised system for aspect based sentiment analysis",
                "pub_date": "2018",
                "pub_title": "Expert Systems with Applications",
                "pub": null
            }
        },
        {
            "ix": "157-ARR_v2_63",
            "content": "Cornelia Sujatha Das Gollapalli,  Caragea, Extracting keyphrases from research papers using citation networks, 2014-07-27, Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, AAAI Press.",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Cornelia Sujatha Das Gollapalli",
                    " Caragea"
                ],
                "title": "Extracting keyphrases from research papers using citation networks",
                "pub_date": "2014-07-27",
                "pub_title": "Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence",
                "pub": "AAAI Press"
            }
        },
        {
            "ix": "157-ARR_v2_64",
            "content": "Navita Goyal,  Balaji Vasan Srinivasan, N Anandhavelu, Abhilasha Sancheti, Multi-style transfer with discriminative feedback on disjoint corpus, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Navita Goyal",
                    " Balaji Vasan Srinivasan",
                    "N Anandhavelu",
                    "Abhilasha Sancheti"
                ],
                "title": "Multi-style transfer with discriminative feedback on disjoint corpus",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "157-ARR_v2_65",
            "content": "Ruidan He, Hwee Tou Wee Sun Lee, Daniel Ng,  Dahlmeier, An unsupervised neural attention model for aspect extraction, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Ruidan He",
                    "Hwee Tou Wee Sun Lee",
                    "Daniel Ng",
                    " Dahlmeier"
                ],
                "title": "An unsupervised neural attention model for aspect extraction",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "157-ARR_v2_66",
            "content": "Jaakko Hintikka, Esa Saarinen, Informationseeking dialogues: Some of their logical properties, 1979, Studia Logica, .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Jaakko Hintikka",
                    "Esa Saarinen"
                ],
                "title": "Informationseeking dialogues: Some of their logical properties",
                "pub_date": "1979",
                "pub_title": "Studia Logica",
                "pub": null
            }
        },
        {
            "ix": "157-ARR_v2_67",
            "content": "Tsutomu Hirao, Jun Suzuki, Hideki Isozaki, Eisaku Maeda, Ntt's multiple document summarization system for duc2003, 2003, Proc. DUC, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Tsutomu Hirao",
                    "Jun Suzuki",
                    "Hideki Isozaki",
                    "Eisaku Maeda"
                ],
                "title": "Ntt's multiple document summarization system for duc2003",
                "pub_date": "2003",
                "pub_title": "Proc. DUC",
                "pub": null
            }
        },
        {
            "ix": "157-ARR_v2_68",
            "content": "Tom Hosking, Sebastian Riedel, Evaluating rewards for question generation models, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Tom Hosking",
                    "Sebastian Riedel"
                ],
                "title": "Evaluating rewards for question generation models",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "157-ARR_v2_69",
            "content": "Anette Hulth, Improved automatic keyword extraction given more linguistic knowledge, 2003, Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    "Anette Hulth"
                ],
                "title": "Improved automatic keyword extraction given more linguistic knowledge",
                "pub_date": "2003",
                "pub_title": "Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "157-ARR_v2_70",
            "content": "Wei Jin, Hung Ho, Rohini K Srihari, Opinionminer: a novel machine learning system for web opinion mining and extraction, 2009, Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Wei Jin",
                    "Hung Ho",
                    "Rohini K Srihari"
                ],
                "title": "Opinionminer: a novel machine learning system for web opinion mining and extraction",
                "pub_date": "2009",
                "pub_title": "Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining",
                "pub": null
            }
        },
        {
            "ix": "157-ARR_v2_71",
            "content": "Vishwajeet Kumar, Ganesh Ramakrishnan, Yuan-Fang Li, Putting the horse before the cart: A generator-evaluator framework for question generation from text, 2019, Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL), Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Vishwajeet Kumar",
                    "Ganesh Ramakrishnan",
                    "Yuan-Fang Li"
                ],
                "title": "Putting the horse before the cart: A generator-evaluator framework for question generation from text",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "157-ARR_v2_72",
            "content": "Huiyuan Lai, Antonio Toral, Malvina Nissim, Thank you BART! rewarding pre-trained models improves formality style transfer, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Short Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "Huiyuan Lai",
                    "Antonio Toral",
                    "Malvina Nissim"
                ],
                "title": "Thank you BART! rewarding pre-trained models improves formality style transfer",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
                "pub": "Short Papers"
            }
        },
        {
            "ix": "157-ARR_v2_73",
            "content": "Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, Luke Zettlemoyer, BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Mike Lewis",
                    "Yinhan Liu",
                    "Naman Goyal",
                    "Marjan Ghazvininejad",
                    "Abdelrahman Mohamed",
                    "Omer Levy",
                    "Veselin Stoyanov",
                    "Luke Zettlemoyer"
                ],
                "title": "BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "157-ARR_v2_74",
            "content": "Fangtao Li, Chao Han, Minlie Huang, Xiaoyan Zhu, Ying-Ju Xia, Shu Zhang, Hao Yu, Structure-aware review mining and summarization, 2010, Proceedings of the 23rd International Conference on Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Fangtao Li",
                    "Chao Han",
                    "Minlie Huang",
                    "Xiaoyan Zhu",
                    "Ying-Ju Xia",
                    "Shu Zhang",
                    "Hao Yu"
                ],
                "title": "Structure-aware review mining and summarization",
                "pub_date": "2010",
                "pub_title": "Proceedings of the 23rd International Conference on Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "157-ARR_v2_75",
            "content": "Feifan Liu, Deana Pennell, Fei Liu, Yang Liu, Unsupervised approaches for automatic keyword extraction using meeting transcripts, 2009, Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "Feifan Liu",
                    "Deana Pennell",
                    "Fei Liu",
                    "Yang Liu"
                ],
                "title": "Unsupervised approaches for automatic keyword extraction using meeting transcripts",
                "pub_date": "2009",
                "pub_title": "Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "157-ARR_v2_76",
            "content": "Pengfei Liu, Shafiq Joty, Helen Meng, Finegrained opinion mining with recurrent neural networks and word embeddings, 2015, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Pengfei Liu",
                    "Shafiq Joty",
                    "Helen Meng"
                ],
                "title": "Finegrained opinion mining with recurrent neural networks and word embeddings",
                "pub_date": "2015",
                "pub_title": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "157-ARR_v2_77",
            "content": "Qian Liu, Bing Liu, Yuanlin Zhang, Doo Kim, Zhiqiang Gao, Improving opinion aspect extraction using semantic similarity and aspect associations, 2016-02-12, Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, AAAI Press.",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "Qian Liu",
                    "Bing Liu",
                    "Yuanlin Zhang",
                    "Doo Kim",
                    "Zhiqiang Gao"
                ],
                "title": "Improving opinion aspect extraction using semantic similarity and aspect associations",
                "pub_date": "2016-02-12",
                "pub_title": "Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence",
                "pub": "AAAI Press"
            }
        },
        {
            "ix": "157-ARR_v2_78",
            "content": "Yixin Liu, Graham Neubig, John Wieting, On learning text style transfer with direct rewards, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Yixin Liu",
                    "Graham Neubig",
                    "John Wieting"
                ],
                "title": "On learning text style transfer with direct rewards",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "157-ARR_v2_79",
            "content": "UNKNOWN, None, 2015, Generating news headlines with recurrent neural networks, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": null,
                "title": null,
                "pub_date": "2015",
                "pub_title": "Generating news headlines with recurrent neural networks",
                "pub": null
            }
        },
        {
            "ix": "157-ARR_v2_80",
            "content": "Ling Luo, Xiang Ao, Yan Song, Jinyao Li, Xiaopeng Yang, Qing He, Dong Yu, Unsupervised neural aspect extraction with sememes, 2019-08-10, Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Ling Luo",
                    "Xiang Ao",
                    "Yan Song",
                    "Jinyao Li",
                    "Xiaopeng Yang",
                    "Qing He",
                    "Dong Yu"
                ],
                "title": "Unsupervised neural aspect extraction with sememes",
                "pub_date": "2019-08-10",
                "pub_title": "Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019",
                "pub": null
            }
        },
        {
            "ix": "157-ARR_v2_81",
            "content": "Margaret Mitchell, Jacqui Aguilar, Theresa Wilson, Benjamin Van Durme, Open domain targeted sentiment, 2013, Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Margaret Mitchell",
                    "Jacqui Aguilar",
                    "Theresa Wilson",
                    "Benjamin Van Durme"
                ],
                "title": "Open domain targeted sentiment",
                "pub_date": "2013",
                "pub_title": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "157-ARR_v2_82",
            "content": "Ramakanth Pasunuru, Mohit Bansal, Multireward reinforced summarization with saliency and entailment, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": [
                    "Ramakanth Pasunuru",
                    "Mohit Bansal"
                ],
                "title": "Multireward reinforced summarization with saliency and entailment",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "157-ARR_v2_83",
            "content": "Guang Qiu, Bing Liu, Jiajun Bu, Chun Chen, Opinion word expansion and target extraction through double propagation, 2011, Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": [
                    "Guang Qiu",
                    "Bing Liu",
                    "Jiajun Bu",
                    "Chun Chen"
                ],
                "title": "Opinion word expansion and target extraction through double propagation",
                "pub_date": "2011",
                "pub_title": "Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "157-ARR_v2_84",
            "content": "Alexander Rush, Sumit Chopra, Jason Weston, A neural attention model for abstractive sentence summarization, 2015, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Alexander Rush",
                    "Sumit Chopra",
                    "Jason Weston"
                ],
                "title": "A neural attention model for abstractive sentence summarization",
                "pub_date": "2015",
                "pub_title": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "157-ARR_v2_85",
            "content": "Marzieh Saeidi, Max Bartolo, Patrick Lewis, Sameer Singh, Tim Rockt\u00e4schel, Mike Sheldon, Guillaume Bouchard, Sebastian Riedel, Interpretation of natural language rules in conversational machine reading, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "Marzieh Saeidi",
                    "Max Bartolo",
                    "Patrick Lewis",
                    "Sameer Singh",
                    "Tim Rockt\u00e4schel",
                    "Mike Sheldon",
                    "Guillaume Bouchard",
                    "Sebastian Riedel"
                ],
                "title": "Interpretation of natural language rules in conversational machine reading",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "157-ARR_v2_86",
            "content": "Abigail See, J Peter, Christopher Liu,  Manning, Get to the point: Summarization with pointergenerator networks, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": [
                    "Abigail See",
                    "J Peter",
                    "Christopher Liu",
                    " Manning"
                ],
                "title": "Get to the point: Summarization with pointergenerator networks",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "157-ARR_v2_87",
            "content": "Jingbo Shang, Jialu Liu, Meng Jiang, Xiang Ren, Clare Voss, Jiawei Han, Automated phrase mining from massive text corpora, 2018, IEEE Transactions on Knowledge and Data Engineering, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": [
                    "Jingbo Shang",
                    "Jialu Liu",
                    "Meng Jiang",
                    "Xiang Ren",
                    "Clare Voss",
                    "Jiawei Han"
                ],
                "title": "Automated phrase mining from massive text corpora",
                "pub_date": "2018",
                "pub_title": "IEEE Transactions on Knowledge and Data Engineering",
                "pub": null
            }
        },
        {
            "ix": "157-ARR_v2_88",
            "content": "Tian Shi, Kyeongpil Kang, Jaegul Choo, Chandan Reddy, Short-text topic modeling via non-negative matrix factorization enriched with local word-context correlations, 2018-04-23, Proceedings of the 2018 World Wide Web Conference on World Wide Web, ACM.",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": [
                    "Tian Shi",
                    "Kyeongpil Kang",
                    "Jaegul Choo",
                    "Chandan Reddy"
                ],
                "title": "Short-text topic modeling via non-negative matrix factorization enriched with local word-context correlations",
                "pub_date": "2018-04-23",
                "pub_title": "Proceedings of the 2018 World Wide Web Conference on World Wide Web",
                "pub": "ACM"
            }
        },
        {
            "ix": "157-ARR_v2_89",
            "content": "Tian Shi, Liuqing Li, Ping Wang, Chandan K Reddy, A simple and effective self-supervised contrastive learning framework for aspect detection, 2021, Proceedings of the AAAI Conference on Artificial Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": [
                    "Tian Shi",
                    "Liuqing Li",
                    "Ping Wang",
                    "Chandan K Reddy"
                ],
                "title": "A simple and effective self-supervised contrastive learning framework for aspect detection",
                "pub_date": "2021",
                "pub_title": "Proceedings of the AAAI Conference on Artificial Intelligence",
                "pub": null
            }
        },
        {
            "ix": "157-ARR_v2_90",
            "content": "Pushkar Shukla, Carlos Elmadjian, Richika Sharan, Vivek Kulkarni, Matthew Turk, William Wang, What should I ask? using conversationally informative rewards for goal-oriented visual dialog, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": [
                    "Pushkar Shukla",
                    "Carlos Elmadjian",
                    "Richika Sharan",
                    "Vivek Kulkarni",
                    "Matthew Turk",
                    "William Wang"
                ],
                "title": "What should I ask? using conversationally informative rewards for goal-oriented visual dialog",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "157-ARR_v2_91",
            "content": "Akash Srivastava, Charles Sutton, Autoencoding variational inference for topic models, 2017-04-24, 5th International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": [
                    "Akash Srivastava",
                    "Charles Sutton"
                ],
                "title": "Autoencoding variational inference for topic models",
                "pub_date": "2017-04-24",
                "pub_title": "5th International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "157-ARR_v2_92",
            "content": "Manfred Stede, David Schlangen, Information-seeking chat: Dialogues driven by topic-structure, 2004, Proceedings of Catalog (the 8th workshop on the semantics and pragmatics of dialogue; SemDial04), Citeseer.",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "Manfred Stede",
                    "David Schlangen"
                ],
                "title": "Information-seeking chat: Dialogues driven by topic-structure",
                "pub_date": "2004",
                "pub_title": "Proceedings of Catalog (the 8th workshop on the semantics and pragmatics of dialogue; SemDial04)",
                "pub": "Citeseer"
            }
        },
        {
            "ix": "157-ARR_v2_93",
            "content": "Antoine Tixier, Fragkiskos Malliaros, Michalis Vazirgiannis, A graph degeneracy-based approach to keyword extraction, 2016, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": [
                    "Antoine Tixier",
                    "Fragkiskos Malliaros",
                    "Michalis Vazirgiannis"
                ],
                "title": "A graph degeneracy-based approach to keyword extraction",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "157-ARR_v2_94",
            "content": "Wenya Wang, Daniel Sinno Jialin Pan, Xiaokui Dahlmeier,  Xiao, Recursive neural conditional random fields for aspect-based sentiment analysis, 2016, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": [
                    "Wenya Wang",
                    "Daniel Sinno Jialin Pan",
                    "Xiaokui Dahlmeier",
                    " Xiao"
                ],
                "title": "Recursive neural conditional random fields for aspect-based sentiment analysis",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "157-ARR_v2_95",
            "content": "Yi-Fang Brook Wu, Quanzhi Li, Razvan Bot, Xin Chen, Domain-specific keyphrase extraction, 2005, Proceedings of the 14th ACM international conference on Information and knowledge management, .",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": [
                    "Yi-Fang Brook Wu",
                    "Quanzhi Li",
                    "Razvan Bot",
                    "Xin Chen"
                ],
                "title": "Domain-specific keyphrase extraction",
                "pub_date": "2005",
                "pub_title": "Proceedings of the 14th ACM international conference on Information and knowledge management",
                "pub": null
            }
        },
        {
            "ix": "157-ARR_v2_96",
            "content": "Yuxi Xie, Liangming Pan, Dongzhe Wang, Min-Yen Kan, Yansong Feng, Exploring questionspecific rewards for generating deep questions, 2020, Proceedings of the 28th International Conference on Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b40",
                "authors": [
                    "Yuxi Xie",
                    "Liangming Pan",
                    "Dongzhe Wang",
                    "Min-Yen Kan",
                    "Yansong Feng"
                ],
                "title": "Exploring questionspecific rewards for generating deep questions",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 28th International Conference on Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "157-ARR_v2_97",
            "content": "Bishan Yang, Claire Cardie, Extracting opinion expressions with semi-Markov conditional random fields, 2012, Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b41",
                "authors": [
                    "Bishan Yang",
                    "Claire Cardie"
                ],
                "title": "Extracting opinion expressions with semi-Markov conditional random fields",
                "pub_date": "2012",
                "pub_title": "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning",
                "pub": null
            }
        },
        {
            "ix": "157-ARR_v2_98",
            "content": "Jingqing Zhang, Yao Zhao, Mohammad Saleh, Peter Liu, Pegasus: Pre-training with extracted gap-sentences for abstractive summarization, 2020, International Conference on Machine Learning, PMLR.",
            "ntype": "ref",
            "meta": {
                "xid": "b42",
                "authors": [
                    "Jingqing Zhang",
                    "Yao Zhao",
                    "Mohammad Saleh",
                    "Peter Liu"
                ],
                "title": "Pegasus: Pre-training with extracted gap-sentences for abstractive summarization",
                "pub_date": "2020",
                "pub_title": "International Conference on Machine Learning",
                "pub": "PMLR"
            }
        },
        {
            "ix": "157-ARR_v2_99",
            "content": "Ruqing Zhang, Jiafeng Guo, Yixing Fan, Yanyan Lan, Xueqi Cheng, Outline generation: Understanding the inherent content structure of documents, 2019-07-21, Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2019, ACM.",
            "ntype": "ref",
            "meta": {
                "xid": "b43",
                "authors": [
                    "Ruqing Zhang",
                    "Jiafeng Guo",
                    "Yixing Fan",
                    "Yanyan Lan",
                    "Xueqi Cheng"
                ],
                "title": "Outline generation: Understanding the inherent content structure of documents",
                "pub_date": "2019-07-21",
                "pub_title": "Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2019",
                "pub": "ACM"
            }
        },
        {
            "ix": "157-ARR_v2_100",
            "content": "Shiyue Zhang, Mohit Bansal, Addressing semantic drift in question generation for semisupervised question answering, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b44",
                "authors": [
                    "Shiyue Zhang",
                    "Mohit Bansal"
                ],
                "title": "Addressing semantic drift in question generation for semisupervised question answering",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": "Association for Computational Linguistics"
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "157-ARR_v2_0@0",
            "content": "DYNAMICTOC: Persona-based Table of Contents for Consumption of Long Documents",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_0",
            "start": 0,
            "end": 76,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_2@0",
            "content": "Long documents like contracts, financial documents, etc., are often tedious to read through.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_2",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_2@1",
            "content": "Linearly consuming (via scrolling or navigation through default table of content) these documents is time-consuming and challenging.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_2",
            "start": 93,
            "end": 224,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_2@2",
            "content": "These documents are also authored to be consumed by varied entities (referred to as persona in the paper) interested in only certain parts of the document.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_2",
            "start": 226,
            "end": 380,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_2@3",
            "content": "In this work, we describe DYNAMICTOC, a dynamic table of contentbased navigator, to aid in the task of non-linear, persona-based document consumption.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_2",
            "start": 382,
            "end": 531,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_2@4",
            "content": "DY-NAMICTOC highlights sections of interest in the document as per the aspects relevant to different personas.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_2",
            "start": 533,
            "end": 642,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_2@5",
            "content": "DYNAMICTOC is augmented with short questions to assist the users in understanding underlying content.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_2",
            "start": 644,
            "end": 744,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_2@6",
            "content": "This uses a novel deep-reinforcement learning technique to generate questions on these persona-clustered paragraphs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_2",
            "start": 746,
            "end": 861,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_2@7",
            "content": "Human and automatic evaluations suggest the efficacy of both end-to-end pipeline and different components of DYNAMICTOC.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_2",
            "start": 863,
            "end": 982,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_4@0",
            "content": "Documents such as financial statements, reports and contracts are often long and comprehensive, replete with domain-specific description and information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_4",
            "start": 0,
            "end": 152,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_4@1",
            "content": "They are meant to be consumed by several entities or personas, e.g. legal department of companies, customers or financial organizations such as banks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_4",
            "start": 154,
            "end": 303,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_4@2",
            "content": "As these documents contain vital information about the business, the business personas are often required to read through and analyze the documents in details.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_4",
            "start": 305,
            "end": 463,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_4@3",
            "content": "These personas are often interested in different sections of the document, based on the business requirements.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_4",
            "start": 465,
            "end": 574,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_4@4",
            "content": "For example, employees might be interested in the stock programs of the company, whereas the lenders and investors would like to read through profit statements.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_4",
            "start": 576,
            "end": 735,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_4@5",
            "content": "The traditional technology to navigate long documents is through a Table of Contents (ToC) populated with the heading of each section and chapters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_4",
            "start": 737,
            "end": 883,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_4@6",
            "content": "However, the Table of Contents does not show the information present in the underlying paragraphs of a section, and there is no way to highlight information relevant to different personas.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_4",
            "start": 885,
            "end": 1072,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_5@0",
            "content": "To this effect, we propose DYNAMICTOC, an intelligent table of contents-based navigator.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_5",
            "start": 0,
            "end": 87,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_5@1",
            "content": "DY-NAMICTOC provides user the flexibility to choose the persona and read the document from its lens.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_5",
            "start": 89,
            "end": 188,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_5@2",
            "content": "For the current work, we focus on the finance and legal domain, and hence, personas are taken as commonplace entities like investors, lenders, financial bodies, etc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_5",
            "start": 190,
            "end": 354,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_5@3",
            "content": "DYNAMICTOC highlights the relevant sections of the document as per the persona.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_5",
            "start": 356,
            "end": 434,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_5@4",
            "content": "For this, the input finance or contract document is segmented at the paragraph level and a cluster of \"aspects or topics\" is inferred for each para.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_5",
            "start": 436,
            "end": 583,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_5@5",
            "content": "These are then mapped to the interest topics of the personas.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_5",
            "start": 585,
            "end": 645,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_5@6",
            "content": "Further, DYNAMICTOC has a novel question-based guided experience, to enhance the visibility of underlying information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_5",
            "start": 647,
            "end": 764,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_5@7",
            "content": "Studies have shown that questions are more intuitive and informative than headings and hence can provide a better understanding of what the paragraph talks about.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_5",
            "start": 766,
            "end": 927,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_5@8",
            "content": "The overall interface is shown in Figure 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_5",
            "start": 929,
            "end": 971,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_6@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_6",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_7@0",
            "content": "Document understanding is a critical and challenging task in information processing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_7",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_7@1",
            "content": "There have been many related research works in this direction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_7",
            "start": 85,
            "end": 146,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_7@2",
            "content": "Keyword detection (Liu et al., 2009;Tixier et al., 2016) & topic modeling (Blei et al., 2001) works aim is to describe the document by a few important words or topics for concise representation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_7",
            "start": 148,
            "end": 341,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_7@3",
            "content": "The first step is to acquire a list of keyword candidates (e.g., n-grams or chunks) with heuristic methods (Hulth, 2003;Shang et al., 2018), then rank them in accordance with their importance to the document (Wu et al., 2005;Gollapalli and Caragea, 2014;Bougouin et al., 2013).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_7",
            "start": 343,
            "end": 619,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_7@4",
            "content": "Another task is compact and informative headline generation from a document (Dorr et al., 2003;Lopyrev, 2015).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_7",
            "start": 621,
            "end": 730,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_7@5",
            "content": "Text summarization is the process of generating natural language summaries from an input document retaining the most important information (Rush et al., 2015;See et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_7",
            "start": 732,
            "end": 907,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_7@6",
            "content": "Recently, an Outline Generation task was introduced by as a hierarchical structured prediction problem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_7",
            "start": 909,
            "end": 1011,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_7@7",
            "content": "Given a document, their aim is to first predict a sequence of section boundaries and then a sequence of section headings accordingly to come up with a Table of Contents for the same.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_7",
            "start": 1013,
            "end": 1194,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_8@0",
            "content": "A related direction of work to ours is of aspect detection, which has been explored in the literature largely using user reviews for products.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_8",
            "start": 0,
            "end": 141,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_8@1",
            "content": "Early works focused on rule-based approaches using lexicons and dependency relations, and utilize manually defined rules to identify patterns and extract aspects (Qiu et al., 2011;Liu et al., 2016), which require domain-specific knowledge and human expertise.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_8",
            "start": 143,
            "end": 401,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_8@2",
            "content": "Supervised approaches formulate aspect extraction as a sequence labelling problem that can be solved by hidden Markov models (HMM) (Jin et al., 2009), conditional random fields (CRF) (Li et al., 2010;Mitchell et al., 2013;Yang and Cardie, 2012), and recurrent neural networks (RNN) (Wang et al., 2016;Liu et al., 2015).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_8",
            "start": 403,
            "end": 721,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_8@3",
            "content": "These approaches have shown better performance compared to the rule-based ones, but require large amounts of labelled data for training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_8",
            "start": 723,
            "end": 858,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_8@4",
            "content": "Early unsupervised systems are dominated by Latent Dirichlet Allocation (LDA)-based topic models (Garc\u00eda-Pablos et al., 2018;Shi et al., 2018;\u00c1lvarez-L\u00f3pez et al., 2016).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_8",
            "start": 860,
            "end": 1029,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_8@5",
            "content": "Recently, deep learning based topic models (Srivastava and Sutton, 2017;Luo et al., 2019;He et al., 2017;Shi et al., 2021) have shown strong performance in extracting coherent aspects in an unsupervised manner.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_8",
            "start": 1031,
            "end": 1240,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_8@6",
            "content": "None of the prior works on aspect detection have worked with contracts or financial documents that are quite long (50-100 pages) in comparison to user reviews.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_8",
            "start": 1242,
            "end": 1400,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_8@7",
            "content": "Even if we break the document at paragraph level, it can still go over tens of lines.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_8",
            "start": 1402,
            "end": 1486,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_8@8",
            "content": "Hence, the importance of word frequency is much more in our case.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_8",
            "start": 1488,
            "end": 1552,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_8@9",
            "content": "We bridge the gap between directly using the unsupervised aspect detection frameworks for the financial documents by adding a TF-IDF based weighing parameter while training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_8",
            "start": 1554,
            "end": 1726,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_8@10",
            "content": "Moreover, there are no gold standards for aspect detection for contract or finance domain, hence, we use unsupervised clustering based metrics for validating the output detection.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_8",
            "start": 1728,
            "end": 1906,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_9@0",
            "content": "Further, it has been shown that question-answers play a critical role in scientific inquiry, informationseeking dialogue, and knowledge acquisition (Hintikka and Saarinen, 1979;Stede and Schlangen, 2004).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_9",
            "start": 0,
            "end": 203,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_9@1",
            "content": "In a dialogue system, question generation is used to obtain specific information from the user or make the conversation more pleasant (Shukla et al., 2019;Saeidi et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_9",
            "start": 205,
            "end": 380,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_9@2",
            "content": "Hence, we hypothesize that augmenting the default ToC with Questions that give a high level overview of the paragraphs can enhance the reading experience of the users.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_9",
            "start": 382,
            "end": 548,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_9@3",
            "content": "Question generation can also be seen as a summarization or seq2seq task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_9",
            "start": 550,
            "end": 621,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_9@4",
            "content": "Various pre-trained language models like BART (Lewis et al., 2020), PEGASUS (Zhang et al., 2020), etc., have shown excellent results for these tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_9",
            "start": 623,
            "end": 771,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_9@5",
            "content": "Researchers have worked on top of these language models & proposed various rewards for QGen to optimize these models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_9",
            "start": 773,
            "end": 889,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_9@6",
            "content": "(Kumar et al., 2019) has employed BLEUbased rewards, (Zhang and Bansal, 2019) have used answerability rewards, whereas (Xie et al., 2020) has used a combination of fluency, relevance, and answerability rewards.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_9",
            "start": 891,
            "end": 1100,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_10@0",
            "content": "Previous question generation literature has focused on generating questions based on an entity, phrase, or sentence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_10",
            "start": 0,
            "end": 115,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_10@1",
            "content": "In this work, we explore longform question generation, i.e., question-based long text.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_10",
            "start": 117,
            "end": 202,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_10@2",
            "content": "We explore deep reinforcement learning techniques for the same.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_10",
            "start": 204,
            "end": 266,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_10@3",
            "content": "as they have shown competitive results in various natural language generation tasks such as summarization (Pasunuru and Bansal, 2018), style transfer (Liu et al., 2021;Goyal et al., 2021), question generation (Hosking and Riedel, 2019;Xie et al., 2020) etc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_10",
            "start": 268,
            "end": 524,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_10@4",
            "content": "Motivated by this we use BART as our base model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_10",
            "start": 526,
            "end": 573,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_10@5",
            "content": "As there is a lack of labeled question datasets in financial domain, to overcome the domain shift problem, we train the model with additional rewards in a reinforcement learning setup to make more suitable for a general domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_10",
            "start": 575,
            "end": 801,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_11@0",
            "content": "There are several commercial products for reading documents across devices, but all of them have a fixed document navigation, based on chapters and headings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_11",
            "start": 0,
            "end": 156,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_11@1",
            "content": "To the best of our knowledge, there is no prior art looking into providing an end-to-end persona-based navigation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_11",
            "start": 158,
            "end": 271,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_11@2",
            "content": "The mentioned technologies address only part of the required solutions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_11",
            "start": 273,
            "end": 343,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_11@3",
            "content": "Following are the key contributions of our work:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_11",
            "start": 345,
            "end": 392,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_12@0",
            "content": "1. We propose a novel DYNAMICTOC technology to enable persona-based non-linear navigation for efficient consumption of long documents.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_12",
            "start": 0,
            "end": 133,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_13@0",
            "content": "2. We extend the unsupervised aspect detection to long domain-specific documents by combining TF-IDF with aspect detection process to make it more robust and show the improvements experimentally.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_13",
            "start": 0,
            "end": 194,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_14@0",
            "content": "3. We propose a method to generate questions based on the content of the paragraph maximizing the information coverage, entity correctness & answerability of the question.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_14",
            "start": 0,
            "end": 170,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_15@0",
            "content": "4. We showcase the viability of our pipeline and evaluate it using metric-based and a human survey-based evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_15",
            "start": 0,
            "end": 115,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_16@0",
            "content": "3 Datasets SEC Filing: The SEC filing is a financial statement document submitted to the U.S. Securities and Exchange Commission.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_16",
            "start": 0,
            "end": 128,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_16@1",
            "content": "Public companies, certain insiders, and broker-dealers are required to make regular SEC filings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_16",
            "start": 130,
            "end": 225,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_16@2",
            "content": "There are many types of documents available on the EDGAR website (Eg. 10-K, 10-Q, Form 4, etc.).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_16",
            "start": 227,
            "end": 322,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_16@3",
            "content": "For our work, we focused on the SEC 10-K documents available on the EDGAR website 1 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_16",
            "start": 324,
            "end": 408,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_16@4",
            "content": "For a given company, the 10-k documents are available in HTML, XBRL and XML format.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_16",
            "start": 410,
            "end": 492,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_16@5",
            "content": "The complete submission text file for a 10-k document (XML) was used for parsing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_16",
            "start": 494,
            "end": 574,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_17@0",
            "content": "We split the document content into different items ranging from item 1 to item 16.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_17",
            "start": 0,
            "end": 81,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_17@1",
            "content": "These 10-K documents range from 50 to 120 pages and contain multiple tables along with text paragraphs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_17",
            "start": 83,
            "end": 185,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_17@2",
            "content": "ELI5: We use the ELI5 dataset ) to train the question generation model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_17",
            "start": 187,
            "end": 257,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_17@3",
            "content": "ELI5 or Explain Like I'm 5, is a question-answer dataset scraped from the subreddit r/explainlikeimfive/. The subreddit rules encourage people to ask a question about any topic and get an answer for it.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_17",
            "start": 259,
            "end": 460,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_17@4",
            "content": "To maintain the dataset's quality, we only select those question-answer pairs with more than two upvotes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_17",
            "start": 462,
            "end": 566,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_17@5",
            "content": "Note that no dataset for such question generation task exists for contractual and financial documents.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_17",
            "start": 568,
            "end": 669,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_17@6",
            "content": "Hence, we resort to use the ELI5 dataset for supervised training and use that model for inferencing on documents from a different domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_17",
            "start": 671,
            "end": 807,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_17@7",
            "content": "To test the model's performance on the domainspecific dataset, we also scrape question-answer pairs from two different subreddits -r/AskLegal and r/AskEconomics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_17",
            "start": 809,
            "end": 969,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_17@8",
            "content": "As the name suggests, they contain questions (and answers) from the legal and economics domain respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_17",
            "start": 971,
            "end": 1078,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_17@9",
            "content": "Table 1 includes the statistics of the three datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_17",
            "start": 1080,
            "end": 1133,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_18@0",
            "content": "Methodology",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_18",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_19@0",
            "content": "In this section, different components of the DY-NAMICTOC are described in details.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_19",
            "start": 0,
            "end": 81,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_20@0",
            "content": "Aspect Detection",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_20",
            "start": 0,
            "end": 15,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_21@0",
            "content": "Aspect detection has been popularly used with analysing user reviews to understand their preferences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_21",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_21@1",
            "content": "We leverage an unsupervised technique for aspect detection and extend it to a new use case -for the modelling of user profiles from a given document and using this info for segregating the document text based on the determined aspects.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_21",
            "start": 102,
            "end": 336,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_21@2",
            "content": "Data Pre-processing: For the input SEC filings, text corresponding to each paragraph is obtained and considered as a separate data point.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_21",
            "start": 338,
            "end": 474,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_21@3",
            "content": "Extra information such as headings, sub-headings, blank lines, signature fields etc. are discarded.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_21",
            "start": 476,
            "end": 574,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_21@4",
            "content": "Along with this, any paragraph with less than 10 words are discarded.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_21",
            "start": 576,
            "end": 644,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_21@5",
            "content": "The text is pre-processed before training the model for aspect detection.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_21",
            "start": 646,
            "end": 718,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_21@6",
            "content": "We require three formatting styles for each paragraph which is consolidated in a single dictionary.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_21",
            "start": 720,
            "end": 818,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_21@7",
            "content": "(1) Tokenized words converted to lowercase characters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_21",
            "start": 820,
            "end": 873,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_21@8",
            "content": "(2) The word stems of the text which has been lower-cased and tokenised.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_21",
            "start": 875,
            "end": 946,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_21@9",
            "content": "(3) The content words (meaningful words, like nouns, verbs, adjectives and adverbs) of the paragraph.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_21",
            "start": 948,
            "end": 1048,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_22@0",
            "content": "Proposed Asp-SSCL Method: Aspect detection aims at extracting interpretable aspects from the textual documents without human supervision.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_22",
            "start": 0,
            "end": 136,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_22@1",
            "content": "We propose an approach, Asp-SSCL based on selfsupervised contrastive learning framework by (Shi et al., 2021) for aspect detection.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_22",
            "start": 138,
            "end": 268,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_22@2",
            "content": "We use the following steps for aspect detection from the contractual and financial documents:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_22",
            "start": 270,
            "end": 362,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_23@0",
            "content": "1. Vocabulary formation and IDF indexing: First, we obtain a vocabulary for the whole corpus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_23",
            "start": 0,
            "end": 92,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_23@1",
            "content": "This is sorted alphabetically and each word is given an index, so that corresponding IDF/word vectors can be easily referenced.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_23",
            "start": 94,
            "end": 220,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_23@2",
            "content": "128-dimensional word vectors are generated on the corpus by a skip-gram model with an n-gram size of 5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_23",
            "start": 222,
            "end": 324,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_24@0",
            "content": "2. Weak Mapping: Prior aspect detection methods require a gold set labels for validating aspect model training, either through human supervision or rules-based mapping to gold set keywords.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_24",
            "start": 0,
            "end": 188,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_24@1",
            "content": "However, as no such gold aspect labels exist for our case, we first use text embedding via sentence transformers 2 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_24",
            "start": 190,
            "end": 305,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_24@2",
            "content": "These are then clustered using K-means to obtain 20 clusters comprising of 10 keywords each, which are used for aspect mapping.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_24",
            "start": 307,
            "end": 433,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_25@0",
            "content": "3. Contrastive Learning: The mapping and generated word vectors are then used for training the self-supervised contrastive learning method, (Shi et al., 2021), which outputs the final aspect clusters and keywords.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_25",
            "start": 0,
            "end": 212,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_26@0",
            "content": "4. TF-IDF Weighing: Further, since these documents are text-heavy, we introduce a modification, Asp-SSCL-TFIDF which includes TF-IDF weighing term in the original implementation, to ensure rare but relevant words are considered as important as opposed to more frequently occurring words.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_26",
            "start": 0,
            "end": 286,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_26@1",
            "content": "Each word representation is modified by multiplying it with the TF-IDF score so that the algorithm can adapt to the financial corpus better.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_26",
            "start": 288,
            "end": 427,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_27@0",
            "content": "Persona Mapping",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_27",
            "start": 0,
            "end": 14,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_28@0",
            "content": "The aspects generated on the corpus are used as dimensions that define the document.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_28",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_28@1",
            "content": "Each persona is expected to be interested in one or more of these dimensions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_28",
            "start": 85,
            "end": 161,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_28@2",
            "content": "We call the mapping between multiple personas and multiple aspects as the persona space.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_28",
            "start": 163,
            "end": 250,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_29@0",
            "content": "We consulted a domain expert (financial domain; specifically for SEC 10-K filings) to create a matrix of personas, who read such documents, and what kind of information they are interested in.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_29",
            "start": 0,
            "end": 191,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_29@1",
            "content": "Figure 2 lists out the various stakeholders of a general 10-K filing against the different sections of the document each stakeholder is interested in.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_29",
            "start": 193,
            "end": 342,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_29@2",
            "content": "The stakeholders are grouped together to form the personas used in DYNAMICTOC, viz. employees, business partners, investors and lendors, financial bodies and advisory and regulatory firms.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_29",
            "start": 344,
            "end": 531,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_29@3",
            "content": "Similarly, the columns (headings) are grouped together according to similarity to create a mapping of topics of interest for each persona.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_29",
            "start": 533,
            "end": 670,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_30@0",
            "content": "We can map these columns to the aspects we get from the Aspect Detection Module and determine if a particular persona is interested in that paragraph or not.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_30",
            "start": 0,
            "end": 156,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_30@1",
            "content": "For this, the aspects obtained from the unsupervised technique are compared against the simplified column values from the constructed matrix.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_30",
            "start": 158,
            "end": 298,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_30@2",
            "content": "The columns with the greatest similarity (above a threshold) are associated with each persona.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_30",
            "start": 300,
            "end": 393,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_30@3",
            "content": "For getting the personas interested in each paragraph, the paragraphs are first tagged for aspect.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_30",
            "start": 395,
            "end": 492,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_30@4",
            "content": "From the resultant vector (which represents the confidence score of the text for each aspect), the combined score for each persona is calculated using the scores of its constituent aspects.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_30",
            "start": 494,
            "end": 682,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_30@5",
            "content": "This Similar column topics have also been grouped for aspect mapping.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_30",
            "start": 684,
            "end": 752,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_31@0",
            "content": "is used to segregate the paragraphs for enhanced document consumption.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_31",
            "start": 0,
            "end": 69,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_31@1",
            "content": "Note that for financial documents, we were able to gather domain knowledge and leverage it to obtain the persona space.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_31",
            "start": 71,
            "end": 189,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_31@2",
            "content": "But the proposed technique is generalizable to other domains as well.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_31",
            "start": 191,
            "end": 259,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_31@3",
            "content": "In the absence of domain-specific knowledge, each aspect is a sufficiently distinct topic and can be treated as a proxy to personas.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_31",
            "start": 261,
            "end": 392,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_31@4",
            "content": "Hence, modelling of interests can be done directly on the basis of aspects in such cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_31",
            "start": 394,
            "end": 482,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_32@0",
            "content": "Intelligent Navigation via Question Generation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_32",
            "start": 0,
            "end": 45,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_33@0",
            "content": "It has been shown that question-answers play a critical role in scientific inquiry, information-seeking dialogue, and knowledge acquisition (Hintikka and Saarinen, 1979;Stede and Schlangen, 2004).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_33",
            "start": 0,
            "end": 195,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_33@1",
            "content": "Additionally, unstructured lists of \"Frequently Asked Questions (FAQs)\" are regularly deployed at scale to present information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_33",
            "start": 197,
            "end": 323,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_33@2",
            "content": "On top, questions can provide a meaningful understanding of the document at a paragraph or section level which cannot be directly captured by a heading (or sub-heading).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_33",
            "start": 325,
            "end": 493,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_33@3",
            "content": "Therefore, to aid in document consumption, we generate long-form questions (i.e., questions based on paragraphs instead of entities) to enhance the navigation experience.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_33",
            "start": 495,
            "end": 664,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@0",
            "content": "Model Architecture: We use an encoderdecoder architecture for the task of generating questions given the paragraph as context which essentially is a sequence-to-sequence task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 0,
            "end": 174,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@1",
            "content": "Large pretrained language models like BART (Lewis et al., 2020), PEGASUS (Zhang et al., 2020), etc., have shown excellent results in summarization tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 176,
            "end": 328,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@2",
            "content": "Motivated by this, we employ BART as our under-lying language model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 330,
            "end": 397,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@3",
            "content": "The task is to generate questions covering the entire paragraph and summarize it capturing the most-salient information in form of a question.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 399,
            "end": 540,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@4",
            "content": "The BART model has shown promising results in abstractive summarization tasks, making it a natural choice.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 542,
            "end": 647,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@5",
            "content": "We use ELI5 dataset for training the model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 649,
            "end": 691,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@6",
            "content": "The answer is provided as the input to the encoder-decoder model which is trained to generate the corresponding question and minimize the cross-entropy loss with respect to the ground truth.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 693,
            "end": 882,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@7",
            "content": "Although such supervised training is straight-forward, due to the domain shift from ELI5 to financial language, qualitative evaluations showed that the model produced some irrelevant questions, some entities were artificially induced (that it might have seen during the training time) and sometimes, it could not cover the entire paragraph.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 884,
            "end": 1223,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@8",
            "content": "Hence, we augmented the vanilla BART with three additional rewards targeting the qualities we seek in the final generated questions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 1225,
            "end": 1356,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@9",
            "content": "We call the resulting model Variant BART.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 1358,
            "end": 1398,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@10",
            "content": "Figure 3 shows the proposed pipeline.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 1400,
            "end": 1436,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@11",
            "content": "The following sections explain these rewards in detail: \u2022 Answerability Classifier Reward: Qualitative evaluations showed some of the questions generated were not answerable by the paragraph, making them unsuitable for the task of understanding the paragraph easily.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 1438,
            "end": 1703,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@12",
            "content": "To address this, we trained a classifier to judge the answerability of the question given the paragraph.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 1705,
            "end": 1808,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@13",
            "content": "Basically, the paragraph and the generated question would be fed as input to the classifier and the classifier predicts \"1\" if the question is answerable by the para, otherwise \"0\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 1810,
            "end": 1990,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@14",
            "content": "The classifier is a fine-tuned Roberta model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 1992,
            "end": 2036,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@15",
            "content": "We create data with both positive and negative samples to fine tune the Roberta model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 2038,
            "end": 2123,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@16",
            "content": "We use the following strategy to create the training data for the binary classifier: (a) We select 10,000 random question-answer pairs from the ELI5 dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 2125,
            "end": 2281,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@17",
            "content": "Note that in ELI5 data, some questions have multiple answer paras too.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 2283,
            "end": 2352,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@18",
            "content": "All these forms our positive samples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 2354,
            "end": 2390,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@19",
            "content": "To create negative samples for a question Q', we take its corresponding answer para, A', and a random set of 100 question-answer pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 2392,
            "end": 2526,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@20",
            "content": "We compare the similarity of the answer para (A') with all the 100 answers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 2528,
            "end": 2602,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@21",
            "content": "Top 3 most similar answers are taken as the negative samples for the question Q'. (b) Given that style of ELI5 answers and Wikipedia paragraphs are very similar 3 , we create negative samples in another way as well to introduce diversity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 2604,
            "end": 2841,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@22",
            "content": "Wikipedia articles are chosen based on their similarity with ELI5 data and for each question, we compute the similarity score with each para in the wiki articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 2843,
            "end": 3004,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@23",
            "content": "The topmost similar paras are of interest, and we sample 10 most similar paras out of top 20 and call them our negative samples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 3006,
            "end": 3133,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@24",
            "content": "\u2022 Entity Correctness Reward: The vanilla BART model can generated questions with hallucinated entities and names like Microsoft, Apple etc. even when there was no mention of them in the corresponding paragraph.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 3135,
            "end": 3344,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@25",
            "content": "To tackle this, we identify the named entities present in the generated question.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 3346,
            "end": 3426,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@26",
            "content": "If those entities appear in the passage, we give a reward of 1 else 0.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 3428,
            "end": 3497,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@27",
            "content": "If there is no entity in the generated question, a reward of 0.5 is given to the model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 3499,
            "end": 3585,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_34@28",
            "content": "Mathematically, reward is given by:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_34",
            "start": 3587,
            "end": 3621,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_35@0",
            "content": "R entity = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 1, if e(Q) \u0338 = \u03d5, e(Q) \u2286 e(P ) 0, if e(Q) \u0338 = \u03d5, e(Q) \u0338 \u2286 e(P ) 0.5, if e(Q) = \u03d5",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_35",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_36@0",
            "content": "where, e(.) denotes the entities in the question or paragraph.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_36",
            "start": 0,
            "end": 61,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_37@0",
            "content": "\u2022 Coverage Reward: We observe that the output question did not cover the entire information present in the paragraph and instead focused on certain segments of it. We introduce this reward to improve information coverage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_37",
            "start": 0,
            "end": 220,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_38@0",
            "content": "The idea is similar to the entity correctness reward.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_38",
            "start": 0,
            "end": 52,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_38@1",
            "content": "We first identify keywords from the paragraph using YAKE algorithm (Campos et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_38",
            "start": 54,
            "end": 142,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_38@2",
            "content": "Then we calculate the similarity of the generated question with these keywords.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_38",
            "start": 144,
            "end": 222,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_38@3",
            "content": "We use the Extended String Subsequence Kernel (ESSK) introduced in (Hirao et al., 2003) to calculate this similarity score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_38",
            "start": 224,
            "end": 346,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_38@4",
            "content": "The idea is that YAKE would generate keywords from different parts of the paragraph.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_38",
            "start": 348,
            "end": 431,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_38@5",
            "content": "When we calculate the similarity of this keyword list with the generated question, we are encouraging the model to cover the entire paragraph.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_38",
            "start": 433,
            "end": 574,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_38@6",
            "content": "Thus, given a passage P and the generated question Q, the reward R is defined as follows: et al., 2021) shows how to use rewards on top of language models for policy learning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_38",
            "start": 576,
            "end": 750,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_38@7",
            "content": "We adopt the same setup.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_38",
            "start": 752,
            "end": 775,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_38@8",
            "content": "The policy gradient, \u2207 \u03d5 J(\u03d5) is given by:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_38",
            "start": 777,
            "end": 818,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_39@0",
            "content": "R coverage = ESSK(Y AKE(P ), Q) (Lai",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_39",
            "start": 0,
            "end": 35,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_40@0",
            "content": "\u2207 \u03d5 J(\u03d5) = E[R \u2022 \u2207 \u03d5 log(P (y s |x, \u03d5))](1)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_40",
            "start": 0,
            "end": 42,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_41@0",
            "content": "where, R denotes reward value, \u03d5 represents the model parameters, x is the input paragraph and y s is obtained by greedily maximizing the distribution of BART outputs at each timestep.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_41",
            "start": 0,
            "end": 183,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_41@1",
            "content": "Hence, the overall loss term for training the proposed Variant BART model becomes:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_41",
            "start": 185,
            "end": 266,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_42@0",
            "content": "L total = \u03bb CE \u2022 L CE + \u03bb reward \u2022 L reward (2)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_42",
            "start": 0,
            "end": 46,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_43@0",
            "content": "Results & Discussion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_43",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_44@0",
            "content": "In order to evaluate the different parts of the pipeline, we employ metric based evaluation schemes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_44",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_44@1",
            "content": "Since there is no off-the-shelf criterion to evaluate all the stages of the pipeline together, we have provided independent evaluations for each of the sub-modules.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_44",
            "start": 101,
            "end": 264,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_44@2",
            "content": "However, the intended goal of our pipeline is to facilitate the readers in consuming long documents through the lens they deem most suitable for them.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_44",
            "start": 266,
            "end": 415,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_44@3",
            "content": "To facilitate an end-to-end evaluation and to understand whether the persona-based document segmentation with enhanced Table of Content is informative or not, we have conducted a small scale human evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_44",
            "start": 417,
            "end": 624,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_44@4",
            "content": "Both metric-based and human-based evaluations are discussed in the following subsections.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_44",
            "start": 626,
            "end": 714,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_45@0",
            "content": "Metric-Based Evaluation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_45",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_46@0",
            "content": "Aspect Detection: Figure 4 shows the t-SNE 4 clustering of the outputs of Asp-SSCL, Asp-SSCL-TFIDF, that are determined from the SEC-10K filing corpus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_46",
            "start": 0,
            "end": 150,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_46@1",
            "content": "For a baseline comparison, we also plot the output for LDA (10 clusters) for the corpus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_46",
            "start": 152,
            "end": 239,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_46@2",
            "content": "Essentially, each cluster is a bag of words indicating some vital theme that is mentioned in the corpus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_46",
            "start": 241,
            "end": 344,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_47@0",
            "content": "We would want the clusters to be as independent from each other as possible as that would mean different kinds of information is captured by different clusters with minimal overlap.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_47",
            "start": 0,
            "end": 180,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_47@1",
            "content": "We observe that adding TF-IDF scores to the aspect detection module helps as the clusters' separation gets better as shown in the Figure 4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_47",
            "start": 182,
            "end": 320,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_47@2",
            "content": "Further, for the baseline using LDA, the separation is not clear.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_47",
            "start": 322,
            "end": 386,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_47@3",
            "content": "Some of the examples of cluster keywords are shown in Figure 5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_47",
            "start": 388,
            "end": 450,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_48@0",
            "content": "Question Generation: Since no ground truth questions are available for the SEC-10K Filing dataset, we report the following evaluations for the question generation module.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_48",
            "start": 0,
            "end": 169,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_48@1",
            "content": "First, we report the \"type\" of questions that are generated using the Vanilla BART model and the Variant BART model that is trained with a combination of the rewards we added on top of it (Table 3) .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_48",
            "start": 171,
            "end": 369,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_49@0",
            "content": "On analysing this table, we see that \"What\" questions are heavily generated on the 10K filing data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_49",
            "start": 0,
            "end": 98,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_49@1",
            "content": "This suggests that the nature of 10K filing is such that the question asked about them is \"What\" type.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_49",
            "start": 100,
            "end": 201,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_49@2",
            "content": "We also observe that biases of training data are not creeping in the model, as the percentage of the \"What\" questions in the training dataset is four times less than the model's output.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_49",
            "start": 203,
            "end": 387,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_49@3",
            "content": "Similarly, the percentage of other questions is significant in the ELI5 dataset but is very small in our model's output.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_49",
            "start": 389,
            "end": 508,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_49@4",
            "content": "Thus, we can safely say that the model learns to generate questions and not mimic the ELI5 dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_49",
            "start": 510,
            "end": 608,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_49@5",
            "content": "Although we don't have the gold corpus for SEC filing dataset, we evaluate the performance of question generation model on the AskLegal and AskEconomics subreddits since we have the ground truth questions for them.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_49",
            "start": 610,
            "end": 823,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_49@6",
            "content": "We report the BLEU and ROUGE scores that are standard metrics in Natural Language Processing literature and are a measure of overlap or common n-grams between the generated text and the ground truth.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_49",
            "start": 825,
            "end": 1023,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_49@7",
            "content": "We also report the answerability score by feeding the generated question and input para to the classifier we trained (as mentioned in Reward 1 -Question Generation Section).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_49",
            "start": 1025,
            "end": 1197,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_49@8",
            "content": "Table 4 shows the corresponding results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_49",
            "start": 1199,
            "end": 1238,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_49@9",
            "content": "On closely analysing the paragraph, reference question, and the generated question, we observe the following three things:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_49",
            "start": 1240,
            "end": 1361,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_49@10",
            "content": "(i) There is more than one way to ask the same question and there could be multiple questions around the same topic.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_49",
            "start": 1363,
            "end": 1478,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_49@11",
            "content": "(ii) Input paragraphs may have more than one prominent topics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_49",
            "start": 1480,
            "end": 1541,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_49@12",
            "content": "The generated question might be focused on one such topic, and the reference question is focused on another.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_49",
            "start": 1543,
            "end": 1650,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_49@13",
            "content": "(iii) Some answers/passages are unrelated to the question or require some background, and thus, the generated questions are very different from the actual question.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_49",
            "start": 1652,
            "end": 1815,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_50@0",
            "content": "The above reasons explain the fluctuation in scores for Vanilla and Variant BART, and thus the answerability of the generated question becomes an important metric.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_50",
            "start": 0,
            "end": 162,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_50@1",
            "content": "The variant model trained with additional rewards has the highest answerability score across all the datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_50",
            "start": 164,
            "end": 273,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_50@2",
            "content": "This suggests that including a coverage-based loss not only helps cover the information of the entire paragraph but also helps increase the generated question's answerability as different themes of the passages are covered.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_50",
            "start": 275,
            "end": 497,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_51@0",
            "content": "Human Evaluation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_51",
            "start": 0,
            "end": 15,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_52@0",
            "content": "We conducted a small human evaluation involving 8 participants (age -27.8 \u00b1 6.7, 2 females).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_52",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_52@1",
            "content": "The participants were technology workers internal to our organization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_52",
            "start": 93,
            "end": 162,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_52@2",
            "content": "They were asked to play around with a web demo to experience the DYNAMICTOC, for different SEC filings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_52",
            "start": 164,
            "end": 266,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_52@3",
            "content": "They were first shown the default section heading-based reading experience and then they choose the type of persona as whom they wish to consume the document.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_52",
            "start": 268,
            "end": 425,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_52@4",
            "content": "After this, they filled a questionnaire about their experience.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_52",
            "start": 427,
            "end": 489,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_52@5",
            "content": "The results of the survey are summarized in Table 5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_52",
            "start": 491,
            "end": 542,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_53@0",
            "content": "Some relevant comments from the survey are as follows -(i) How do we ensure that all the relevant information will be covered by the sections highlighted as important for a particular \"persona\"? (ii) Although questions generated are relevant, some of the why questions are not answered by the paragraphs they point to. (iii) Interesting experiment with possibly multiple use-cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_53",
            "start": 0,
            "end": 380,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_53@1",
            "content": "The first comment is actually true for all summarization tasks, hence, DYNAMICTOC does not disrupt the linear flow.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_53",
            "start": 382,
            "end": 496,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_53@2",
            "content": "The second feedback indicates scope for further research in the question generation space.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_53",
            "start": 498,
            "end": 587,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_53@3",
            "content": "The overall response is immensely positive and the scores of 4.50, 4.16 and 4.40 in Table 5 reflect the same.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_53",
            "start": 589,
            "end": 697,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_54@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_54",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_55@0",
            "content": "In this work, we have proposed a novel DYNAM-ICTOC framework for consumption of long documents.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_55",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_55@1",
            "content": "Financial documents are high value documents for businesses, and are often long and complex.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_55",
            "start": 96,
            "end": 187,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_55@2",
            "content": "The default ToC-based reading experience is quite limited and document consumption can be enhanced using intelligent technologies.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_55",
            "start": 189,
            "end": 318,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_55@3",
            "content": "DY-NAMICTOC is one of the first works to pursue this exciting research direction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_55",
            "start": 320,
            "end": 400,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_55@4",
            "content": "DYNAMICTOC would benefit from in-domain learning of aspect keywords and questions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_55",
            "start": 402,
            "end": 483,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_55@5",
            "content": "Evaluation of paragraph segmentation and mapping of personas to the aspects are future directions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_55",
            "start": 485,
            "end": 582,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_55@6",
            "content": "A better understanding of personas would generalize the work to different domains.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_55",
            "start": 584,
            "end": 665,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_56@0",
            "content": "Tamara \u00c1lvarez-L\u00f3pez, Jonathan Juncal-Mart\u00ednez, Milagros Fern\u00e1ndez-Gavilanes, Enrique Costa-Montenegro, Francisco Gonz\u00e1lez-Casta\u00f1o, GTI at SemEval-2016 task 5: SVM and CRF for aspect detection and unsupervised aspectbased sentiment analysis, 2016, Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016), Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_56",
            "start": 0,
            "end": 375,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_57@0",
            "content": "David Blei, Andrew Ng, Michael Jordan, Latent dirichlet allocation, 2001-12-03, Advances in Neural Information Processing Systems 14 [Neural Information Processing Systems: Natural and Synthetic, MIT Press.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_57",
            "start": 0,
            "end": 205,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_58@0",
            "content": "Adrien Bougouin, Florian Boudin, B\u00e9atrice Daille, TopicRank: Graph-based topic ranking for keyphrase extraction, 2013, Proceedings of the Sixth International Joint Conference on Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_58",
            "start": 0,
            "end": 207,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_59@0",
            "content": "Ricardo Campos, V\u00edtor Mangaravite, Arian Pasquali, Al\u00edpio M\u00e1rio Jorge, C\u00e9lia Nunes, Adam Jatowt, Yake! collection-independent automatic keyword extractor, 2018, European Conference on Information Retrieval, Springer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_59",
            "start": 0,
            "end": 215,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_60@0",
            "content": "Bonnie Dorr, David Zajic, Richard Schwartz, Hedge trimmer: A parse-and-trim approach to headline generation, 2003, Proceedings of the HLT-NAACL 03 Text Summarization Workshop, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_60",
            "start": 0,
            "end": 176,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_61@0",
            "content": "Angela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, Michael Auli, ELI5: Long form question answering, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_61",
            "start": 0,
            "end": 257,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_62@0",
            "content": "Aitor Garc\u00eda-Pablos, Montse Cuadros, German Rigau, W2vlda: almost unsupervised system for aspect based sentiment analysis, 2018, Expert Systems with Applications, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_62",
            "start": 0,
            "end": 163,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_63@0",
            "content": "Cornelia Sujatha Das Gollapalli,  Caragea, Extracting keyphrases from research papers using citation networks, 2014-07-27, Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, AAAI Press.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_63",
            "start": 0,
            "end": 210,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_64@0",
            "content": "Navita Goyal,  Balaji Vasan Srinivasan, N Anandhavelu, Abhilasha Sancheti, Multi-style transfer with discriminative feedback on disjoint corpus, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_64",
            "start": 0,
            "end": 295,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_65@0",
            "content": "Ruidan He, Hwee Tou Wee Sun Lee, Daniel Ng,  Dahlmeier, An unsupervised neural attention model for aspect extraction, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_65",
            "start": 0,
            "end": 224,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_66@0",
            "content": "Jaakko Hintikka, Esa Saarinen, Informationseeking dialogues: Some of their logical properties, 1979, Studia Logica, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_66",
            "start": 0,
            "end": 116,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_67@0",
            "content": "Tsutomu Hirao, Jun Suzuki, Hideki Isozaki, Eisaku Maeda, Ntt's multiple document summarization system for duc2003, 2003, Proc. DUC, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_67",
            "start": 0,
            "end": 132,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_68@0",
            "content": "Tom Hosking, Sebastian Riedel, Evaluating rewards for question generation models, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_68",
            "start": 0,
            "end": 273,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_69@0",
            "content": "Anette Hulth, Improved automatic keyword extraction given more linguistic knowledge, 2003, Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_69",
            "start": 0,
            "end": 179,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_70@0",
            "content": "Wei Jin, Hung Ho, Rohini K Srihari, Opinionminer: a novel machine learning system for web opinion mining and extraction, 2009, Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_70",
            "start": 0,
            "end": 227,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_71@0",
            "content": "Vishwajeet Kumar, Ganesh Ramakrishnan, Yuan-Fang Li, Putting the horse before the cart: A generator-evaluator framework for question generation from text, 2019, Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL), Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_71",
            "start": 0,
            "end": 289,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_72@0",
            "content": "Huiyuan Lai, Antonio Toral, Malvina Nissim, Thank you BART! rewarding pre-trained models improves formality style transfer, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Short Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_72",
            "start": 0,
            "end": 306,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_73@0",
            "content": "Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, Luke Zettlemoyer, BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_73",
            "start": 0,
            "end": 337,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_74@0",
            "content": "Fangtao Li, Chao Han, Minlie Huang, Xiaoyan Zhu, Ying-Ju Xia, Shu Zhang, Hao Yu, Structure-aware review mining and summarization, 2010, Proceedings of the 23rd International Conference on Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_74",
            "start": 0,
            "end": 215,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_75@0",
            "content": "Feifan Liu, Deana Pennell, Fei Liu, Yang Liu, Unsupervised approaches for automatic keyword extraction using meeting transcripts, 2009, Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_75",
            "start": 0,
            "end": 287,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_76@0",
            "content": "Pengfei Liu, Shafiq Joty, Helen Meng, Finegrained opinion mining with recurrent neural networks and word embeddings, 2015, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_76",
            "start": 0,
            "end": 252,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_77@0",
            "content": "Qian Liu, Bing Liu, Yuanlin Zhang, Doo Kim, Zhiqiang Gao, Improving opinion aspect extraction using semantic similarity and aspect associations, 2016-02-12, Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, AAAI Press.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_77",
            "start": 0,
            "end": 240,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_78@0",
            "content": "Yixin Liu, Graham Neubig, John Wieting, On learning text style transfer with direct rewards, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_78",
            "start": 0,
            "end": 243,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_79@0",
            "content": "UNKNOWN, None, 2015, Generating news headlines with recurrent neural networks, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_79",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_80@0",
            "content": "Ling Luo, Xiang Ao, Yan Song, Jinyao Li, Xiaopeng Yang, Qing He, Dong Yu, Unsupervised neural aspect extraction with sememes, 2019-08-10, Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_80",
            "start": 0,
            "end": 242,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_81@0",
            "content": "Margaret Mitchell, Jacqui Aguilar, Theresa Wilson, Benjamin Van Durme, Open domain targeted sentiment, 2013, Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_81",
            "start": 0,
            "end": 238,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_82@0",
            "content": "Ramakanth Pasunuru, Mohit Bansal, Multireward reinforced summarization with saliency and entailment, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_82",
            "start": 0,
            "end": 251,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_83@0",
            "content": "Guang Qiu, Bing Liu, Jiajun Bu, Chun Chen, Opinion word expansion and target extraction through double propagation, 2011, Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_83",
            "start": 0,
            "end": 149,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_84@0",
            "content": "Alexander Rush, Sumit Chopra, Jason Weston, A neural attention model for abstractive sentence summarization, 2015, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_84",
            "start": 0,
            "end": 244,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_85@0",
            "content": "Marzieh Saeidi, Max Bartolo, Patrick Lewis, Sameer Singh, Tim Rockt\u00e4schel, Mike Sheldon, Guillaume Bouchard, Sebastian Riedel, Interpretation of natural language rules in conversational machine reading, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_85",
            "start": 0,
            "end": 338,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_86@0",
            "content": "Abigail See, J Peter, Christopher Liu,  Manning, Get to the point: Summarization with pointergenerator networks, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_86",
            "start": 0,
            "end": 219,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_87@0",
            "content": "Jingbo Shang, Jialu Liu, Meng Jiang, Xiang Ren, Clare Voss, Jiawei Han, Automated phrase mining from massive text corpora, 2018, IEEE Transactions on Knowledge and Data Engineering, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_87",
            "start": 0,
            "end": 182,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_88@0",
            "content": "Tian Shi, Kyeongpil Kang, Jaegul Choo, Chandan Reddy, Short-text topic modeling via non-negative matrix factorization enriched with local word-context correlations, 2018-04-23, Proceedings of the 2018 World Wide Web Conference on World Wide Web, ACM.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_88",
            "start": 0,
            "end": 249,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_89@0",
            "content": "Tian Shi, Liuqing Li, Ping Wang, Chandan K Reddy, A simple and effective self-supervised contrastive learning framework for aspect detection, 2021, Proceedings of the AAAI Conference on Artificial Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_89",
            "start": 0,
            "end": 211,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_90@0",
            "content": "Pushkar Shukla, Carlos Elmadjian, Richika Sharan, Vivek Kulkarni, Matthew Turk, William Wang, What should I ask? using conversationally informative rewards for goal-oriented visual dialog, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_90",
            "start": 0,
            "end": 284,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_91@0",
            "content": "Akash Srivastava, Charles Sutton, Autoencoding variational inference for topic models, 2017-04-24, 5th International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_91",
            "start": 0,
            "end": 157,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_92@0",
            "content": "Manfred Stede, David Schlangen, Information-seeking chat: Dialogues driven by topic-structure, 2004, Proceedings of Catalog (the 8th workshop on the semantics and pragmatics of dialogue; SemDial04), Citeseer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_92",
            "start": 0,
            "end": 207,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_93@0",
            "content": "Antoine Tixier, Fragkiskos Malliaros, Michalis Vazirgiannis, A graph degeneracy-based approach to keyword extraction, 2016, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_93",
            "start": 0,
            "end": 253,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_94@0",
            "content": "Wenya Wang, Daniel Sinno Jialin Pan, Xiaokui Dahlmeier,  Xiao, Recursive neural conditional random fields for aspect-based sentiment analysis, 2016, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_94",
            "start": 0,
            "end": 278,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_95@0",
            "content": "Yi-Fang Brook Wu, Quanzhi Li, Razvan Bot, Xin Chen, Domain-specific keyphrase extraction, 2005, Proceedings of the 14th ACM international conference on Information and knowledge management, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_95",
            "start": 0,
            "end": 190,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_96@0",
            "content": "Yuxi Xie, Liangming Pan, Dongzhe Wang, Min-Yen Kan, Yansong Feng, Exploring questionspecific rewards for generating deep questions, 2020, Proceedings of the 28th International Conference on Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_96",
            "start": 0,
            "end": 217,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_97@0",
            "content": "Bishan Yang, Claire Cardie, Extracting opinion expressions with semi-Markov conditional random fields, 2012, Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_97",
            "start": 0,
            "end": 247,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_98@0",
            "content": "Jingqing Zhang, Yao Zhao, Mohammad Saleh, Peter Liu, Pegasus: Pre-training with extracted gap-sentences for abstractive summarization, 2020, International Conference on Machine Learning, PMLR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_98",
            "start": 0,
            "end": 191,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_99@0",
            "content": "Ruqing Zhang, Jiafeng Guo, Yixing Fan, Yanyan Lan, Xueqi Cheng, Outline generation: Understanding the inherent content structure of documents, 2019-07-21, Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2019, ACM.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_99",
            "start": 0,
            "end": 283,
            "label": {}
        },
        {
            "ix": "157-ARR_v2_100@0",
            "content": "Shiyue Zhang, Mohit Bansal, Addressing semantic drift in question generation for semisupervised question answering, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "157-ARR_v2_100",
            "start": 0,
            "end": 340,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "157-ARR_v2_0",
            "tgt_ix": "157-ARR_v2_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_0",
            "tgt_ix": "157-ARR_v2_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_1",
            "tgt_ix": "157-ARR_v2_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_1",
            "tgt_ix": "157-ARR_v2_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_0",
            "tgt_ix": "157-ARR_v2_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_2",
            "tgt_ix": "157-ARR_v2_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_4",
            "tgt_ix": "157-ARR_v2_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_3",
            "tgt_ix": "157-ARR_v2_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_3",
            "tgt_ix": "157-ARR_v2_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_3",
            "tgt_ix": "157-ARR_v2_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_0",
            "tgt_ix": "157-ARR_v2_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_5",
            "tgt_ix": "157-ARR_v2_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_7",
            "tgt_ix": "157-ARR_v2_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_8",
            "tgt_ix": "157-ARR_v2_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_9",
            "tgt_ix": "157-ARR_v2_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_10",
            "tgt_ix": "157-ARR_v2_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_11",
            "tgt_ix": "157-ARR_v2_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_12",
            "tgt_ix": "157-ARR_v2_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_13",
            "tgt_ix": "157-ARR_v2_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_14",
            "tgt_ix": "157-ARR_v2_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_15",
            "tgt_ix": "157-ARR_v2_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_16",
            "tgt_ix": "157-ARR_v2_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_6",
            "tgt_ix": "157-ARR_v2_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_6",
            "tgt_ix": "157-ARR_v2_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_6",
            "tgt_ix": "157-ARR_v2_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_6",
            "tgt_ix": "157-ARR_v2_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_6",
            "tgt_ix": "157-ARR_v2_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_6",
            "tgt_ix": "157-ARR_v2_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_6",
            "tgt_ix": "157-ARR_v2_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_6",
            "tgt_ix": "157-ARR_v2_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_6",
            "tgt_ix": "157-ARR_v2_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_6",
            "tgt_ix": "157-ARR_v2_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_6",
            "tgt_ix": "157-ARR_v2_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_6",
            "tgt_ix": "157-ARR_v2_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_0",
            "tgt_ix": "157-ARR_v2_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_17",
            "tgt_ix": "157-ARR_v2_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_18",
            "tgt_ix": "157-ARR_v2_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_18",
            "tgt_ix": "157-ARR_v2_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_18",
            "tgt_ix": "157-ARR_v2_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_19",
            "tgt_ix": "157-ARR_v2_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_21",
            "tgt_ix": "157-ARR_v2_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_22",
            "tgt_ix": "157-ARR_v2_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_23",
            "tgt_ix": "157-ARR_v2_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_24",
            "tgt_ix": "157-ARR_v2_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_25",
            "tgt_ix": "157-ARR_v2_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_20",
            "tgt_ix": "157-ARR_v2_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_20",
            "tgt_ix": "157-ARR_v2_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_20",
            "tgt_ix": "157-ARR_v2_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_20",
            "tgt_ix": "157-ARR_v2_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_20",
            "tgt_ix": "157-ARR_v2_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_20",
            "tgt_ix": "157-ARR_v2_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_20",
            "tgt_ix": "157-ARR_v2_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_18",
            "tgt_ix": "157-ARR_v2_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_26",
            "tgt_ix": "157-ARR_v2_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_28",
            "tgt_ix": "157-ARR_v2_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_29",
            "tgt_ix": "157-ARR_v2_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_30",
            "tgt_ix": "157-ARR_v2_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_27",
            "tgt_ix": "157-ARR_v2_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_27",
            "tgt_ix": "157-ARR_v2_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_27",
            "tgt_ix": "157-ARR_v2_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_27",
            "tgt_ix": "157-ARR_v2_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_27",
            "tgt_ix": "157-ARR_v2_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_18",
            "tgt_ix": "157-ARR_v2_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_31",
            "tgt_ix": "157-ARR_v2_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_33",
            "tgt_ix": "157-ARR_v2_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_35",
            "tgt_ix": "157-ARR_v2_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_36",
            "tgt_ix": "157-ARR_v2_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_38",
            "tgt_ix": "157-ARR_v2_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_39",
            "tgt_ix": "157-ARR_v2_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_40",
            "tgt_ix": "157-ARR_v2_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_41",
            "tgt_ix": "157-ARR_v2_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_32",
            "tgt_ix": "157-ARR_v2_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_32",
            "tgt_ix": "157-ARR_v2_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_32",
            "tgt_ix": "157-ARR_v2_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_32",
            "tgt_ix": "157-ARR_v2_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_32",
            "tgt_ix": "157-ARR_v2_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_32",
            "tgt_ix": "157-ARR_v2_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_32",
            "tgt_ix": "157-ARR_v2_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_32",
            "tgt_ix": "157-ARR_v2_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_32",
            "tgt_ix": "157-ARR_v2_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_32",
            "tgt_ix": "157-ARR_v2_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_32",
            "tgt_ix": "157-ARR_v2_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_0",
            "tgt_ix": "157-ARR_v2_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_42",
            "tgt_ix": "157-ARR_v2_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_43",
            "tgt_ix": "157-ARR_v2_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_43",
            "tgt_ix": "157-ARR_v2_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_43",
            "tgt_ix": "157-ARR_v2_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_44",
            "tgt_ix": "157-ARR_v2_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_46",
            "tgt_ix": "157-ARR_v2_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_47",
            "tgt_ix": "157-ARR_v2_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_48",
            "tgt_ix": "157-ARR_v2_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_49",
            "tgt_ix": "157-ARR_v2_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_45",
            "tgt_ix": "157-ARR_v2_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_45",
            "tgt_ix": "157-ARR_v2_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_45",
            "tgt_ix": "157-ARR_v2_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_45",
            "tgt_ix": "157-ARR_v2_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_45",
            "tgt_ix": "157-ARR_v2_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_45",
            "tgt_ix": "157-ARR_v2_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_43",
            "tgt_ix": "157-ARR_v2_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_50",
            "tgt_ix": "157-ARR_v2_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_52",
            "tgt_ix": "157-ARR_v2_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_51",
            "tgt_ix": "157-ARR_v2_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_51",
            "tgt_ix": "157-ARR_v2_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_51",
            "tgt_ix": "157-ARR_v2_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_0",
            "tgt_ix": "157-ARR_v2_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_53",
            "tgt_ix": "157-ARR_v2_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_54",
            "tgt_ix": "157-ARR_v2_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_54",
            "tgt_ix": "157-ARR_v2_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "157-ARR_v2_0",
            "tgt_ix": "157-ARR_v2_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_1",
            "tgt_ix": "157-ARR_v2_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_2",
            "tgt_ix": "157-ARR_v2_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_2",
            "tgt_ix": "157-ARR_v2_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_2",
            "tgt_ix": "157-ARR_v2_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_2",
            "tgt_ix": "157-ARR_v2_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_2",
            "tgt_ix": "157-ARR_v2_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_2",
            "tgt_ix": "157-ARR_v2_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_2",
            "tgt_ix": "157-ARR_v2_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_2",
            "tgt_ix": "157-ARR_v2_2@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_3",
            "tgt_ix": "157-ARR_v2_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_4",
            "tgt_ix": "157-ARR_v2_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_4",
            "tgt_ix": "157-ARR_v2_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_4",
            "tgt_ix": "157-ARR_v2_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_4",
            "tgt_ix": "157-ARR_v2_4@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_4",
            "tgt_ix": "157-ARR_v2_4@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_4",
            "tgt_ix": "157-ARR_v2_4@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_4",
            "tgt_ix": "157-ARR_v2_4@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_5",
            "tgt_ix": "157-ARR_v2_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_5",
            "tgt_ix": "157-ARR_v2_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_5",
            "tgt_ix": "157-ARR_v2_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_5",
            "tgt_ix": "157-ARR_v2_5@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_5",
            "tgt_ix": "157-ARR_v2_5@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_5",
            "tgt_ix": "157-ARR_v2_5@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_5",
            "tgt_ix": "157-ARR_v2_5@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_5",
            "tgt_ix": "157-ARR_v2_5@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_5",
            "tgt_ix": "157-ARR_v2_5@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_6",
            "tgt_ix": "157-ARR_v2_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_7",
            "tgt_ix": "157-ARR_v2_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_7",
            "tgt_ix": "157-ARR_v2_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_7",
            "tgt_ix": "157-ARR_v2_7@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_7",
            "tgt_ix": "157-ARR_v2_7@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_7",
            "tgt_ix": "157-ARR_v2_7@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_7",
            "tgt_ix": "157-ARR_v2_7@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_7",
            "tgt_ix": "157-ARR_v2_7@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_7",
            "tgt_ix": "157-ARR_v2_7@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_8",
            "tgt_ix": "157-ARR_v2_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_8",
            "tgt_ix": "157-ARR_v2_8@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_8",
            "tgt_ix": "157-ARR_v2_8@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_8",
            "tgt_ix": "157-ARR_v2_8@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_8",
            "tgt_ix": "157-ARR_v2_8@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_8",
            "tgt_ix": "157-ARR_v2_8@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_8",
            "tgt_ix": "157-ARR_v2_8@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_8",
            "tgt_ix": "157-ARR_v2_8@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_8",
            "tgt_ix": "157-ARR_v2_8@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_8",
            "tgt_ix": "157-ARR_v2_8@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_8",
            "tgt_ix": "157-ARR_v2_8@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_9",
            "tgt_ix": "157-ARR_v2_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_9",
            "tgt_ix": "157-ARR_v2_9@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_9",
            "tgt_ix": "157-ARR_v2_9@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_9",
            "tgt_ix": "157-ARR_v2_9@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_9",
            "tgt_ix": "157-ARR_v2_9@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_9",
            "tgt_ix": "157-ARR_v2_9@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_9",
            "tgt_ix": "157-ARR_v2_9@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_10",
            "tgt_ix": "157-ARR_v2_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_10",
            "tgt_ix": "157-ARR_v2_10@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_10",
            "tgt_ix": "157-ARR_v2_10@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_10",
            "tgt_ix": "157-ARR_v2_10@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_10",
            "tgt_ix": "157-ARR_v2_10@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_10",
            "tgt_ix": "157-ARR_v2_10@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_11",
            "tgt_ix": "157-ARR_v2_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_11",
            "tgt_ix": "157-ARR_v2_11@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_11",
            "tgt_ix": "157-ARR_v2_11@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_11",
            "tgt_ix": "157-ARR_v2_11@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_12",
            "tgt_ix": "157-ARR_v2_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_13",
            "tgt_ix": "157-ARR_v2_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_14",
            "tgt_ix": "157-ARR_v2_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_15",
            "tgt_ix": "157-ARR_v2_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_16",
            "tgt_ix": "157-ARR_v2_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_16",
            "tgt_ix": "157-ARR_v2_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_16",
            "tgt_ix": "157-ARR_v2_16@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_16",
            "tgt_ix": "157-ARR_v2_16@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_16",
            "tgt_ix": "157-ARR_v2_16@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_16",
            "tgt_ix": "157-ARR_v2_16@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_17",
            "tgt_ix": "157-ARR_v2_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_17",
            "tgt_ix": "157-ARR_v2_17@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_17",
            "tgt_ix": "157-ARR_v2_17@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_17",
            "tgt_ix": "157-ARR_v2_17@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_17",
            "tgt_ix": "157-ARR_v2_17@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_17",
            "tgt_ix": "157-ARR_v2_17@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_17",
            "tgt_ix": "157-ARR_v2_17@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_17",
            "tgt_ix": "157-ARR_v2_17@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_17",
            "tgt_ix": "157-ARR_v2_17@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_17",
            "tgt_ix": "157-ARR_v2_17@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_18",
            "tgt_ix": "157-ARR_v2_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_19",
            "tgt_ix": "157-ARR_v2_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_20",
            "tgt_ix": "157-ARR_v2_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_21",
            "tgt_ix": "157-ARR_v2_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_21",
            "tgt_ix": "157-ARR_v2_21@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_21",
            "tgt_ix": "157-ARR_v2_21@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_21",
            "tgt_ix": "157-ARR_v2_21@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_21",
            "tgt_ix": "157-ARR_v2_21@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_21",
            "tgt_ix": "157-ARR_v2_21@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_21",
            "tgt_ix": "157-ARR_v2_21@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_21",
            "tgt_ix": "157-ARR_v2_21@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_21",
            "tgt_ix": "157-ARR_v2_21@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_21",
            "tgt_ix": "157-ARR_v2_21@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_22",
            "tgt_ix": "157-ARR_v2_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_22",
            "tgt_ix": "157-ARR_v2_22@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_22",
            "tgt_ix": "157-ARR_v2_22@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_23",
            "tgt_ix": "157-ARR_v2_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_23",
            "tgt_ix": "157-ARR_v2_23@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_23",
            "tgt_ix": "157-ARR_v2_23@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_24",
            "tgt_ix": "157-ARR_v2_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_24",
            "tgt_ix": "157-ARR_v2_24@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_24",
            "tgt_ix": "157-ARR_v2_24@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_25",
            "tgt_ix": "157-ARR_v2_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_26",
            "tgt_ix": "157-ARR_v2_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_26",
            "tgt_ix": "157-ARR_v2_26@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_27",
            "tgt_ix": "157-ARR_v2_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_28",
            "tgt_ix": "157-ARR_v2_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_28",
            "tgt_ix": "157-ARR_v2_28@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_28",
            "tgt_ix": "157-ARR_v2_28@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_29",
            "tgt_ix": "157-ARR_v2_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_29",
            "tgt_ix": "157-ARR_v2_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_29",
            "tgt_ix": "157-ARR_v2_29@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_29",
            "tgt_ix": "157-ARR_v2_29@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_30",
            "tgt_ix": "157-ARR_v2_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_30",
            "tgt_ix": "157-ARR_v2_30@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_30",
            "tgt_ix": "157-ARR_v2_30@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_30",
            "tgt_ix": "157-ARR_v2_30@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_30",
            "tgt_ix": "157-ARR_v2_30@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_30",
            "tgt_ix": "157-ARR_v2_30@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_31",
            "tgt_ix": "157-ARR_v2_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_31",
            "tgt_ix": "157-ARR_v2_31@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_31",
            "tgt_ix": "157-ARR_v2_31@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_31",
            "tgt_ix": "157-ARR_v2_31@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_31",
            "tgt_ix": "157-ARR_v2_31@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_32",
            "tgt_ix": "157-ARR_v2_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_33",
            "tgt_ix": "157-ARR_v2_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_33",
            "tgt_ix": "157-ARR_v2_33@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_33",
            "tgt_ix": "157-ARR_v2_33@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_33",
            "tgt_ix": "157-ARR_v2_33@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@12",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@13",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@14",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@15",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@16",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@17",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@18",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@19",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@20",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@21",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@22",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@23",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@24",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@25",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@26",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@27",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_34",
            "tgt_ix": "157-ARR_v2_34@28",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_35",
            "tgt_ix": "157-ARR_v2_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_36",
            "tgt_ix": "157-ARR_v2_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_37",
            "tgt_ix": "157-ARR_v2_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_38",
            "tgt_ix": "157-ARR_v2_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_38",
            "tgt_ix": "157-ARR_v2_38@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_38",
            "tgt_ix": "157-ARR_v2_38@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_38",
            "tgt_ix": "157-ARR_v2_38@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_38",
            "tgt_ix": "157-ARR_v2_38@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_38",
            "tgt_ix": "157-ARR_v2_38@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_38",
            "tgt_ix": "157-ARR_v2_38@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_38",
            "tgt_ix": "157-ARR_v2_38@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_38",
            "tgt_ix": "157-ARR_v2_38@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_39",
            "tgt_ix": "157-ARR_v2_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_40",
            "tgt_ix": "157-ARR_v2_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_41",
            "tgt_ix": "157-ARR_v2_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_41",
            "tgt_ix": "157-ARR_v2_41@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_42",
            "tgt_ix": "157-ARR_v2_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_43",
            "tgt_ix": "157-ARR_v2_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_44",
            "tgt_ix": "157-ARR_v2_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_44",
            "tgt_ix": "157-ARR_v2_44@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_44",
            "tgt_ix": "157-ARR_v2_44@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_44",
            "tgt_ix": "157-ARR_v2_44@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_44",
            "tgt_ix": "157-ARR_v2_44@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_45",
            "tgt_ix": "157-ARR_v2_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_46",
            "tgt_ix": "157-ARR_v2_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_46",
            "tgt_ix": "157-ARR_v2_46@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_46",
            "tgt_ix": "157-ARR_v2_46@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_47",
            "tgt_ix": "157-ARR_v2_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_47",
            "tgt_ix": "157-ARR_v2_47@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_47",
            "tgt_ix": "157-ARR_v2_47@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_47",
            "tgt_ix": "157-ARR_v2_47@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_48",
            "tgt_ix": "157-ARR_v2_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_48",
            "tgt_ix": "157-ARR_v2_48@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_49",
            "tgt_ix": "157-ARR_v2_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_49",
            "tgt_ix": "157-ARR_v2_49@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_49",
            "tgt_ix": "157-ARR_v2_49@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_49",
            "tgt_ix": "157-ARR_v2_49@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_49",
            "tgt_ix": "157-ARR_v2_49@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_49",
            "tgt_ix": "157-ARR_v2_49@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_49",
            "tgt_ix": "157-ARR_v2_49@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_49",
            "tgt_ix": "157-ARR_v2_49@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_49",
            "tgt_ix": "157-ARR_v2_49@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_49",
            "tgt_ix": "157-ARR_v2_49@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_49",
            "tgt_ix": "157-ARR_v2_49@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_49",
            "tgt_ix": "157-ARR_v2_49@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_49",
            "tgt_ix": "157-ARR_v2_49@12",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_49",
            "tgt_ix": "157-ARR_v2_49@13",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_50",
            "tgt_ix": "157-ARR_v2_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_50",
            "tgt_ix": "157-ARR_v2_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_50",
            "tgt_ix": "157-ARR_v2_50@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_51",
            "tgt_ix": "157-ARR_v2_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_52",
            "tgt_ix": "157-ARR_v2_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_52",
            "tgt_ix": "157-ARR_v2_52@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_52",
            "tgt_ix": "157-ARR_v2_52@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_52",
            "tgt_ix": "157-ARR_v2_52@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_52",
            "tgt_ix": "157-ARR_v2_52@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_52",
            "tgt_ix": "157-ARR_v2_52@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_53",
            "tgt_ix": "157-ARR_v2_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_53",
            "tgt_ix": "157-ARR_v2_53@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_53",
            "tgt_ix": "157-ARR_v2_53@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_53",
            "tgt_ix": "157-ARR_v2_53@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_54",
            "tgt_ix": "157-ARR_v2_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_55",
            "tgt_ix": "157-ARR_v2_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_55",
            "tgt_ix": "157-ARR_v2_55@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_55",
            "tgt_ix": "157-ARR_v2_55@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_55",
            "tgt_ix": "157-ARR_v2_55@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_55",
            "tgt_ix": "157-ARR_v2_55@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_55",
            "tgt_ix": "157-ARR_v2_55@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_55",
            "tgt_ix": "157-ARR_v2_55@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_56",
            "tgt_ix": "157-ARR_v2_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_57",
            "tgt_ix": "157-ARR_v2_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_58",
            "tgt_ix": "157-ARR_v2_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_59",
            "tgt_ix": "157-ARR_v2_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_60",
            "tgt_ix": "157-ARR_v2_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_61",
            "tgt_ix": "157-ARR_v2_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_62",
            "tgt_ix": "157-ARR_v2_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_63",
            "tgt_ix": "157-ARR_v2_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_64",
            "tgt_ix": "157-ARR_v2_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_65",
            "tgt_ix": "157-ARR_v2_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_66",
            "tgt_ix": "157-ARR_v2_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_67",
            "tgt_ix": "157-ARR_v2_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_68",
            "tgt_ix": "157-ARR_v2_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_69",
            "tgt_ix": "157-ARR_v2_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_70",
            "tgt_ix": "157-ARR_v2_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_71",
            "tgt_ix": "157-ARR_v2_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_72",
            "tgt_ix": "157-ARR_v2_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_73",
            "tgt_ix": "157-ARR_v2_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_74",
            "tgt_ix": "157-ARR_v2_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_75",
            "tgt_ix": "157-ARR_v2_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_76",
            "tgt_ix": "157-ARR_v2_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_77",
            "tgt_ix": "157-ARR_v2_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_78",
            "tgt_ix": "157-ARR_v2_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_79",
            "tgt_ix": "157-ARR_v2_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_80",
            "tgt_ix": "157-ARR_v2_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_81",
            "tgt_ix": "157-ARR_v2_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_82",
            "tgt_ix": "157-ARR_v2_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_83",
            "tgt_ix": "157-ARR_v2_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_84",
            "tgt_ix": "157-ARR_v2_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_85",
            "tgt_ix": "157-ARR_v2_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_86",
            "tgt_ix": "157-ARR_v2_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_87",
            "tgt_ix": "157-ARR_v2_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_88",
            "tgt_ix": "157-ARR_v2_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_89",
            "tgt_ix": "157-ARR_v2_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_90",
            "tgt_ix": "157-ARR_v2_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_91",
            "tgt_ix": "157-ARR_v2_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_92",
            "tgt_ix": "157-ARR_v2_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_93",
            "tgt_ix": "157-ARR_v2_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_94",
            "tgt_ix": "157-ARR_v2_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_95",
            "tgt_ix": "157-ARR_v2_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_96",
            "tgt_ix": "157-ARR_v2_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_97",
            "tgt_ix": "157-ARR_v2_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_98",
            "tgt_ix": "157-ARR_v2_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_99",
            "tgt_ix": "157-ARR_v2_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "157-ARR_v2_100",
            "tgt_ix": "157-ARR_v2_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 800,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "doc_id": "157-ARR",
        "version": 2
    }
}