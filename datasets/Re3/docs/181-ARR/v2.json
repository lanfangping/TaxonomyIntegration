{
    "nodes": [
        {
            "ix": "181-ARR_v2_0",
            "content": "Generalized Quantifiers as a Source of Error in Multilingual NLU Benchmarks",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_2",
            "content": "Logical approaches to representing language have developed and evaluated computational models of quantifier words since the 19th century, but today's NLU models still struggle to capture their semantics. We rely on Generalized Quantifier Theory for languageindependent representations of the semantics of quantifier words, to quantify their contribution to the errors of NLU models. We find that quantifiers are pervasive in NLU benchmarks, and their occurrence at test time is associated with performance drops. Multilingual models also exhibit unsatisfying quantifier reasoning abilities, but not necessarily worse for non-English languages. To facilitate directlytargeted probing, we present an adversarial generalized quantifier NLI task (GQNLI) and show that pre-trained language models have a clear lack of robustness in generalized quantifier reasoning.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "181-ARR_v2_4",
            "content": "Quantifier words-such as each or most or more than three-have been extensively studied, both in logic and in linguistics (Westerst\u00e5hl, 1989;Peters and Westerst\u00e5hl, 2006), going all the way back to Frege (1879). In this paper, we examine the extent to which they present a challenge to modern NLU systems. Our analysis is motivated by three observations:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_5",
            "content": "Quantifier words are abstract Unlike nouns, verbs and adjectives, quantifier words do not have referents out in the world. Rather, quantifier words specify relationships between sets of entities, events and properties. To provide intuitions about the semantics of quantifier words, and to be able to refer to quantifiers in a language-independent way, we rely on the notion of generalized quantifiers (Mostowski, 1957), as described in \u00a72.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_6",
            "content": "Quantifier words vary across languages Quantifier word inventories differ across languages.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_7",
            "content": "CONTEXT: A piece of paper was later found on which he had written his last statements in two languages, Latin and German. Only one statement was in Latin and the rest in German.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_8",
            "content": "In what language were most statements written? ANSWER: German PREDICTED AN-SWER: Latin and German NLI_Spanish PREMISE: M\u00e1s de tres personas resultaron heridas en un accidente de dos veh\u00edculos el lunes por la noche.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_9",
            "content": "(translation: More than three people were injured in a two-vehicle crash Monday evening.) HYPOTHESIS: Hab\u00eda 4 personas involucradas. (translation: There were 4 people involved. LABEL: Neutral PREDICTED LABEL: Entailment Table 1: Examples of quantifiers (marked in bold texts) in NLP tasks, with RoBERTa's prediction for QA and XLM-R's prediction for NLI after fine-tuning.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_10",
            "content": "Often what is considered rough translation equivalents also differ in syntax, fine-grained semantics or pragmatics. Stateva et al. (2019) show, e.g., that perceptions of the numerical bounds of existential quantifiers differ across speakers of English, French, Slovenian, and German. Other papers showing discrepancies between quantifier systems include comparisons of Salish to English (Matthewson, 2001), Adyghe to English (Nikolaeva, 2012), or of Dutch, Hebrew and Bengali (Gil, 1982). The cross-linguistic differences in how generalized quantifiers are expressed motivates a cross-lingual error analysis, since quantifiers may contribute more to error when processing some languages rather than others.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_11",
            "content": "Quantifier words are important Quantifier words are extremely important for tasks that require inference, including natural language inference, question answering, fact-checking, etc. Datasets have, for example, been developed for numerical reasoning in English (Dua et al., 2019). Several researchers have identified quantifier words as important sources of errors for natural language processing systems (Joshi et al., 2020); see Table 1 for examples of such errors. Unfortunately, most efforts have concentrated on subsets of quantifier words and on English.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_12",
            "content": "Contributions We analyze how quantifiers are represented in NLU benchmarks, and how their occurrence at test time contributes to errors by neural language models (LMs). We derive a linguistically motivated 11-way categorization set for generalized quantifiers and look into their distribution in three steps: (a) monolingual NLI; (b) cross-lingual NLI; (c) cross-lingual question answering. We also propose GQNLI 1 , an adversarial generalized quantifier NLI challenge dataset. Our work shows that (i) generalized quantifiers are pervasive and cause overall performance drops in NLU benchmarks; (ii) the contribution of quantifier words to system error varies across languages; and (iii) generalized quantifiers are particularly difficult for LMs in interaction with negation and subsumption.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_13",
            "content": "Background",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "181-ARR_v2_14",
            "content": "Generalized quantifiers (GQs) are developed upon first-order predicate logic, denoting relations between sets (Mostowski, 1957). Given a universe E, a quantifier Q would be treated as a mapping Q E from the Cartesian product of powersets P(E) \u00d7 P(E) to the set {false,true} or, as a binary relation on subsets of E (Dvo\u0159\u00e1k and Hol\u010dapek, 2015). GQs are generalizations of the \u2200,\u2203 quantifiers from first-order predicate logic (Mostowski, 1957;Lindstr\u00f6m, 1966;Montague, 1973;Bach et al., 1995;Keenan and Paperno, 2012). A generalized quantifier is, abstractly, a relation between sets. Generalized quantifier theory, while developed by logicians, is used by formal linguists to analyze the meaning of quantifier words in combination with referential expressions (Barwise and Cooper, 1981;Higginbotham and May, 1981).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_15",
            "content": "Most human languages contain ways of expressing generalized quantifiers, and their semantics exhibit striking similarities across languages (Matthewson, 2004;Fintel and Matthewson, 2008;Steinert-Threlkeld, 2019). At the same time, generalized quantifiers can be instantiated very differently across languages due to pragmatic considerations (Grice, 1989) or cognitive economy and costbenefit optimisation in the exchange of information (Levinson et al., 2000;Steinert-Threlkeld, 2021;Uegaki, 2022). Quantifier words also exhibit syntactic differences, e.g., with some languages having specialized words to express quantity, while others rely on metaphorical usage of common nouns (Katsos et al., 2012). In English, most is a determiner, but Spanish and French express the same concept through common nouns, la mayor\u00eda and la majorit\u00e9. The relative stability of the core semantics of quantifiers makes a cross-linguistic comparison possible, but the syntactic and pragmatic variation associated with the expression of generalized quantifiers poses a challenge for multilingual NLU. We consult quantifier taxonomy studies (Keenan and Westerst\u00e5hl, 1997;Peters and Westerst\u00e5hl, 2006;Szymanik and Thorne, 2015;Szymanik, 2016) and derive a categorization set for quantifier analysis in NLU benchmarks. In Table 2, we list the 11way quantifier categorization set and their logical denotation based on set theory.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_16",
            "content": "While other foci of formal linguistics have attracted the attention of NLP researchers-including coreference (Ogrodniczuk et al., 2019(Ogrodniczuk et al., , 2020 tion (Hossain et al., 2020;Hartmann et al., 2021), and consistency (Li et al., 2019;Ribeiro et al., 2019;Asai and Hajishirzi, 2020;Geva et al., 2022)-there has been little work on generalized quantifiers as a source of error in NLU, let alone in multilingual NLU. It remains an open problem whether LMs represent the semantics of quantifiers words adequately, or if they provide a basis for resolving scopal ambiguities. 2",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_17",
            "content": "NLU Benchmarks",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "181-ARR_v2_18",
            "content": "We conduct an error analysis focusing on the role of generalized quantifiers in two NLU tasks, Natural Language Inference (NLI) and Question Answering (QA), which generally require understanding of quantifiers. For each type of task, both monolingual and cross-lingual evaluation are conducted. We focus on generalized quantifiers in the hypotheses in NLI examples-and on generalized quantifiers in the question fields in question answering. To this end, we identify quantifiers by the lemma and the universal dependency relation (Nivre et al., 2020) of a quantifier after preprocessing the sentences using Stanza (Qi et al., 2020). Take the sentence \"The Yiddish culture has survived for more than a thousand years.\", we annotate it as \"The/det Yiddish/amod culture/nsubj have/aux survive/root for/case more/advmod than/fixed a/det thousand/nummod year/obl ./punct\". By matching the regex pattern of the quantifier \"more than k\", in this case \"((more|great)\\/advmod than\\/(fixed|case)|at\\/case least\\/nmod) .+\\/nummod .+\\/(nsubj|obj|obl)\", we approximate the surface form of the type \"more than k\".Through matching quantifier patterns, we are able to find entries in which quantifiers are instantiated. See Appendix A for the list of regex patterns we write to identify GQs. In Table 3 and Table 6, we present the statistics of the quantifier distributions in NLI and QA tasks, respectively. As can be seen, quantifiers are indeed widespread in NLU tasks, accounting for roughly 10% in NLI tasks and 5% in QA tasks. We will further discuss the statistics and experiments in the following section.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_19",
            "content": "Quantifiers in English NLI Benchmarks",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "181-ARR_v2_20",
            "content": "NLI is commonly framed as a three-way classification task with labels entailment, contradiction and neutral (Bowman et al., 2015a). While SOTA models exhibit low error rates on NLI benchmarks, it is unclear when they succeed or fail in their underlying reasoning. We are interested in whether generalized quantifers challenge modern NLI models. In our error analysis, we initially focus on three English NLI datasets, MultiNLI (MNLI; , SNLI (Bowman et al., 2015a) and ANLI (Nie et al., 2020) as testbeds. across, about 10% of all hypotheses contain quantifier words, indicating the pervasiveness of quantification. We also plot the frequency of quantifiers in NLI in Figure 1 and find the quantifier word distribution follows Zipf's law (Zipf, 1949). Note the top three most common quantifiers account for more than 90% of all.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_21",
            "content": "In order to investigate whether NLU systems can solve quantifiers in NLI, we experiment with two pretrained LMs: BERT 3 (Devlin et al., 2019) and RoBERTa 4 (Liu et al., 2019). We use the codebase by Nie et al. (2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_22",
            "content": "The training data combines SNLI, MNLI, FEVER-NLI (Nie et al., 2019) and ANLI.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_23",
            "content": "In Table 4, we report the test set performance on SNLI and ANLI, and the dev set performance on MLNI matched and mismatched sections. We can observe that SOTA models suffer from performance drops across almost all quantification phenomena in every task. When it comes to performance over all quantifiers, the improvement from RoBERTa to BERT (2.2%) is less prominent than that over full datasets (2.9%), suggesting RoBERTa is particularly challenged.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_24",
            "content": "Taking a closer look at error by category, proportional quantifiers seem harder to solve than Aristotelian/counting quantifiers. Except for k%, all proportional quantifiers-p/k, most, and few-are about 10% lower than the five counting quantifiers (except less than k) with BERT; and about 5% lower with RoBERTa. RoBERTa is not generally superior to BERT; e.g., for k%, BERT outperforms it by 22%. We show a pairwise analysis of how GQs affect performance when they appear in both the premises and hypotheses in the Appendix B. Generally, our results attest to the difficulty of resolving GQs in NLI benchmarks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_25",
            "content": "Quantifiers in Cross-lingual NLU Benchmarks",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "181-ARR_v2_26",
            "content": "Quantifiers are acquired in similar orders across languages (Katsos et al., 2016), although languages express quantifiers in different ways. For example, there are eight different universal quantifiers with different level of distributivity in Malagasy (Matthewson, 2008). This poses challenges to training multilingual LMs and transfer learning. We are interested in whether quantifiers are universally and evenly challenging for all languages.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_27",
            "content": "Quantifiers in Cross-lingual NLI We choose XNLI (Conneau et al., 2018), a manual translation of the development and test set of MNLI into 15 languages, for this multilingual error analysis. We should clarify that for XNLI, the authors annotate entailment labels for the English data only and apply them to the other languages. We do not assume label changes due to translation in this study, but it is worth investigate in the future. We choose five languages belonging to different language families, namely Arabic, Chinese, German, Spanish and Vietnamese as targets. The last column in Table 3 shows the numbers of quantifiers in XNLI. The distribution rate is 10%. Note that the universal quantifier is the most common quantifier in XNLI. We fine-tune mBERT 5 (Devlin et al., 2019) and XLM 6 (Lample and Conneau, 2019) on the MNLI training set and evaluate them on XNLI. We report the results in Table 5. We find that performance varies across languages. For Chinese and Vietnamese, we see significant drops in performance for examples with GQs, whereas for Arabic and German, we see improvements. The results per quantifier are more homogeneous, however.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_28",
            "content": "Similar to our results for English, we can see that the lowest accuracies in XNLI are with proportional quantifiers, such as most and few. But the gap in non-English languages is wider for these two categories, especially for Chinese, the difference reaches 30%. Other hard quantifiers include all, > k, < k, and each other.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_29",
            "content": "Quantifiers in Cross-lingual QA Cross-lingual question answering (XQA) is another important NLU task that evaluates the cross-lingual transferability of LMs. We evaluate the effect of quantifiers on system errors across two XQA datasets, namely XQuAD (Artetxe et al., 2020) and MLQA (Lewis et al., 2020). As demonstrated in Figure 1, quantifier word distributions in XQA tasks also follow Zipf's law, as in NLI tasks, but k is more frequent (perhaps because of a traditional emphasis on numerical reasoning), and we see less variance across languages. This is probably because question answering is targeting quantification less directly. To evaluate cross-lingual QA performance on GQs, we fine-tune mBERT and XLM-R 7 (Conneau et al., 2020) using Hu et al. (2020)'s architecture. We present results for mBERT in Table 7; for XLM-R results, please refer to Appendix D.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_30",
            "content": "Just as with XNLI, LMs suffer from performance drops across all languages for almost all GQ phenomena with significant, cross-lingual variation. The most distinguished is that Exact Match (EM) suffers from a greater deterioration than F1 scores for all languages. For example, the weighted EM difference for mBERT on MLQA is 2.9% while the weighted F1 is 1%. As one example in Table 1, we observe that the plausible answers selected by models, while being incorrect, result in a sharper decrease of EMs comparing to F1s. Questions containing GQs also tend to have less verbal answers comparing to those without GQs, and therefore require higher precision.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_31",
            "content": "Regarding cross-lingual comparisons, Chinese and Arabic are the two languages that do not have lower performance over GQs compared to the performance over the complete dataset. Despite the overall trends, subtle differences from XNLI performance still exist. For example, XLM-R is worse than mBERT on quantifier reasoning on XQuAD Chinese, especially at proportional quantifiers, but this is not the case on MLQA Chinese.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_32",
            "content": "GQNLI",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "181-ARR_v2_33",
            "content": "We have seen how quantifiers present challenges to NLI and QA models. Using an approach similar to ANLI (Nie et al., 2020) and DynaBench (Kiela et al., 2021), we use model difficulty (RoBERTa's) as a heuristic to select hard examples for a challenge dataset that can hopefully be used to evaluate any future progress on this. We propose GQNLI, a generalized quantifier NLI challenge dataset, consisting of 30 premises and 300 hypotheses. The average sentence lengths of hypothesis and premises are 15.97 and 7.35, respectively. Both numbers are comparable to those of MNLI, but lower than ANLI's . It should be noted that GQNLI is designed for evaluating future models; obviously not for benchmarking RoBERTa.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_34",
            "content": "Dataset Creation Firstly, we manually create 100 premise-hypothesis pairs, in which various types of GQs appear. For each premise and hypothesis, the number of GQs varies from one to three. To choose the premises, we randomly sampled 100 premises with GQs from SNLI and ANLI test sets, respectively, and selected 10 premises in total, that we consider are semantically adequate for adding GQs and making simple hypotheses.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_35",
            "content": "To construct the hypotheses, we rely on RoBERTa fine-tuned on MNLI and manually select examples about which the model is unsure or incorrect. To focus on GQs, we keep the challenge examples otherwise simple (Ribeiro et al., 2020), and avoid lexical variations in the hypotheses. Hard examples were found to be characterized by (i) mixing generalized quantifiers with other logical operators, such as subsumption or negation, and (ii) combining multiple different generalized quantifiers. We discuss these observations in Section 7.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_36",
            "content": "Two of the authors annotated the examples. The inter-annotator agreement (Fleiss' kappa) was 0.895, substantially higher than ANLI's (0.672-0.740). It is worth noting that the level of semantic or pragmatic interpretation difference of GQs is reflected in the measurement.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_37",
            "content": "We augmented the examples by substituting non-quantifier words (e.g., replacing \"dogs\" with \"cats\") while keeping the labels, to exclude the effect of specific lexical items. The resulting labels are uniformly distributed. Table 8 presents GQNLI statistics. Since the dataset is curated to probe the ability to reason with quantifiers, the distribution of generalized quantifiers does not follow Zipf's law; see \u00a74. A list of GQNLI examples per category is shown in Appendix E.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_38",
            "content": "We evaluate seven types of models on GQNLI, fine-tuned with different combinations of NLI datasets. As data creation only relied on RoBERTa and MNLI, nothing prevents that models with different architectures and training data will perform well. They do not, however. The results are shown in Table 8.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_39",
            "content": "We see that all models have great difficulty with GQNLI. With more training data, models improve, but the best performance is 48%, less than 15 points above chance level. In general, the counting quantifiers, especially the existential and universal quantifiers, are easier than proportional quantifiers. Particularly, most models struggle with less than k and between. This is in some contrast with the NLU tasks studied above, where these quantifiers were among the easiest.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_40",
            "content": "We also observe unstable GQ reasoning ability in simple word substitution cases. For instance, it happens for DeBERTa fine-tuned with M, F, Ling, DocNLI that it predicted correctly the contradiction relation between \"There are six children standing on top of a yellow mountain. Two thirds wear red tops and one third wear green.\" and \"Between 80% and 90% children do not wear red tops.\", but incorrectly when \"red\" is substituted with \"beige\" and \"green\" with \"cyan\". We are yet to study what kind of cues lead to the instability. Our experiments suggest a lack of testing proportionality reasoning and robustness in existing benchmarks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_41",
            "content": "Discussion",
            "ntype": "title",
            "meta": {
                "section": "7"
            }
        },
        {
            "ix": "181-ARR_v2_42",
            "content": "Negation The interaction between negation words and quantifiers increases semantic complexity (Partee, 1970;Horn, 2010). We investigate whether this holds for NLI tasks, using negation cue detection to find all cases where a negation word and a quantifier appear in the hypotheses.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_43",
            "content": "We break down the performances on negation of the seven models in Appendix F. As indicated, LMs overall have polarized results for negation cases comparing to the entire dataset. We can see a majority of the models even predicted opposite labels for some GQ categories, with 0% accuracy. BART is no longer the second best model, replaced by RoBERTa. The improvement by training with more data is overall consistent for reasoning over GQs with negation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_44",
            "content": "For a cross-lingual investigation of the interaction of GQs and negation, we find that in XNLI, the number of cases combining both phenomena is insufficient: we identified four such cases, involving only the quantifiers \"all\" and \"more than.\" For English, mBERT predicted two cases successfully. For Chinese, German, Vietnamese and Arabic, one is correct. For Spanish, all are wrongly predicted.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_45",
            "content": "It is evident that NLU models suffer from reasoning difficulties in certain cases when negation interacts with GQs, especially in cross-lingual evaluation. In future work, we are interested in expanding GQNLI to more instances and more languages to facilitate qualitative investigations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_46",
            "content": "Subsumption In generalized term subsumption languages (TSLs; Yen, 1991;Ali and Shapiro, 1993), a term a subsumes another term b if and only if the extension of a is a superset of the extension of b . Rather than surface number comparison, subsumption reasoning requires knowledge of the relations between supersets and subsets. For example, to decide whether \"There are six dogs. Three brown dogs, a black dog and a white dog run along the green grass\" entails \"One dog sits\", LMs should be aware that \"six dogs\" is a superset of the extension of the \"brown dogs\", \"black dog\" and \"white dog\". Another example in GQNLI is to infer whether \"There are twelve singers on a stage, less than half from Argentina and one from Cape Verde\" entails \"Several singers do not come from Chile\".",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_47",
            "content": "We annotate 63 cases out of the first 100 in GQNLI requiring subsumption reasoning. We show the statistics and results regarding subsumption in Appendix G. It can be seen that more training data leads to higher accuracies. Especially, DeBERTa fine-tuned with DocNLI, which unifies the two classes \"neutral\" and \"contradict\" into a new class \"not entail\", has a significant improvement on subsumption cases with neutral label. The training bias give an advantage to the model on the subsumption subset, half cases of which are labelled neutral. But such bias has a negative effect on non-subsumption cases; the accuracy drops by 20.2% comparing to the model without training with DocNLI. It is worth investigating whether DocNLI is truly helping subsumption reasoning in future work. Subsumption is a key concept in the study of knowledge representation (Woods, 1991), but is neglected in current NLP research. The fact that LMs struggle to perform subsumption reasoning asserts the necessity to explicit tackle the problem.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_48",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "8"
            }
        },
        {
            "ix": "181-ARR_v2_49",
            "content": "We examine the sensitivity of NLU models to generalized quantifiers. These models are designed to induce correlations from large volumes of data, not to reason symbolically with logical quantifiers. Such models have, nevertheless, been probed for logical knowledge. Mul and Zuidema (2019), for example, show neural networks encode fragments of first-order logic and exhibit zero-shot generalization ability. Evans et al. (2018) present a neural architecture that improves performance on propositional logical inference. Bowman et al. (2015b) also suggest neural networks learn semantic representations for logical inference in natural languages. However, on the same task, Veldhoen and Zuidema (2017) find neural networks fail to do so on a more stringent test. Geiger et al. ( 2019) also show that neural networks fail to exhibit robust logical inference. Srivastava et al. (2018) use semantic parsers to encode quantifiers and improve zero-shot learning in classification tasks. Haruta et al. (2020) present a system that computes logical inference over GQs and see improvements on two specialized datasets, FraCaS (Cooper et al., 1994) and MED (Yanaka et al., 2019). None of these papers explicitly discussed generalized quantifiers, and all were limited to studying the ability of neural networks to capture the logical semantics of English.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_50",
            "content": "Many studies have instead focused on LMs' ability to capture negation (Gururangan et al., 2018;Naik et al., 2018;Hossain et al., 2020;Ettinger, 2020;Hartmann et al., 2021) or coreference (Ye et al., 2020;Varkel and Globerson, 2020;Abdou et al., 2020). Others have focused on LMs' ability to reason with numbers . DROP (Dua et al., 2019), for example, is a question answering dataset designed specifically to probe LMs' ability to count, add and subtract for answering factoid questions. Models have also been tailored for numerical reasoning (Geva et al., 2020;. Cobbe et al. (2021) proposes to use a verification task during pretraining of LMs to improve their ability to solve math word problems. Others have studied monotonicity inference (Hu et al., 2019;Yanaka et al., 2019Yanaka et al., , 2020, and Fang and Lou (2021) recently focused on the two quantifier words part and whole in an error analysis for named entity recognition.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_51",
            "content": "Many NLU benchmarks contain quantifier words, but their influence on performance has not been studied systematically. One exception to this is that generalized quantifiers have been used to generate adversarial examples in the context of numerical reasoning (Naik et al., 2018;Nie et al., 2020). TaxiNLI (Joshi et al., 2020), which categorizes 15 types of reasoning abilities, is a dataset drawn from MNLI. In their taxonomy, the Quantifier category only refers to universal and existential quantifiers, not to generalized quantifiers, and ditto for Kim et al. (2019). All of the above focused on English, but in an extension to TaxiNLI, K et al. ( 2021) incorporated quantifiers into the Logic class and found a large cross-lingual transfer gap on LMs.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_52",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "9"
            }
        },
        {
            "ix": "181-ARR_v2_53",
            "content": "Quantifiers lie in the intersection of logic, linguistics and NLP research. It is essential for NLU systems to learn quantifier reasoning. We examined generalized quantifiers in multilingual NLU tasks with regards to their expressiveness and logical reasoning requirement. Our survey and experiments indicate quantifiers are neglected to a degree and cause significant performance drops for neural LMs. To better understand LMs' reasoning abilities, we release GQNLI, a novel generalized quantifier NLI challenge dataset. With the pervasiveness of generalized quantifiers, we stress that more efforts are necessary to investigate: (1) when and why models systematically fail when quantifiers interact with other operators; (2) how to improve cross-lingual transferability of quantifiers; (3) how we can exploit the theoretical results about generalized quantifiers from logic and linguistic studies, so as to improve the logical inference ability of neural LMs.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_54",
            "content": "A Regular Expressions for Generalized Quantifiers",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_55",
            "content": "Table 9 lists the regex we use to parse generalized quntifiers in sentences augmented with universal dependency tags. The approach does not find all the generalized quantifiers exhuastively but rather approximates the common distributions.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_56",
            "content": "While the analysis in Section 4 is based on quantifiers in hypotheses, next we consider the interaction of quantifiers in hypotheses and quantifiers in premises. To this end, we calculate the difference between overall performance and performance for premise-hypothesis pairs of GQs. In Figure 2, we visualize the results as heatmaps (see Table 10 for exact numbers of occurences and accuracies). Surprisingly, whenever quantifiers appear in both the premise and the hypothesis, LMs largely fail to predict the entailment. Percentage quantifiers, supposed to be semantically more complex than counting quantifiers, are not de facto harder in NLI. We studied all 27 cases of percentage quantifiers in the English NLI datasets, and found that in most cases, percentage quantifiers occurrences are identical across premises and hypotheses, i.e., triggering little or no inference. The other two proportional quantifiers, most and few, are hard for Figure 2: Fine-grained analysis of RoBERTa performance on 6 English NLI subtasks. Each heatmap represents hypotheses with a type of quantifier. The rows stand for premises with the quantifier of that label. The numbers are calculated as the accuracy over the whole dataset minus the fine-grained accuracy given a specific premise and hypothesis (the higher the number, the worse the performance). For each heatmap, the last column represents the accuracy gap weighted by all 6 tasks. \"UN\" stands for an entry where no explicit quantifier is identified.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_57",
            "content": "LMs to resolve, e.g., in some quantifier pairs, models yield 0% accuracy. Although each other is supposed to be hardest to resolve due to the complex semantics of reciprocals (Szymanik and Thorne, 2015), it is not reflected in NLI tasks as such. The reason is similar to percentage quantifiers, while annotators intend to alter counting quantifiers when writing hypotheses, reciprocality is seldomly considered a linguistic ability that needs testing for NLU systems. And the annotation for Ramsey quantifier is simply a knockoff, making reciprocal relation identification unwarranted through shallow correlations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_58",
            "content": "C Fine-grained NLI Analysis D XQA Result: mBERT and XLM-R",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_59",
            "content": "We present the results of seven models' performance on cases with negation cues in GQNLI in Table 13.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_60",
            "content": "See Table 14 for models 'performance on cases requiring subsumption reasoning in GQNLI. We also break down subsumption results by entailment labels into two categories: neutral and non-neutral.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "181-ARR_v2_61",
            "content": "Mostafa Abdou, Vinit Ravishankar, Maria Barrett, Yonatan Belinkov, Desmond Elliott, Anders S\u00f8gaard, The sensitivity of language models and humans to Winograd schema perturbations, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "Mostafa Abdou",
                    "Vinit Ravishankar",
                    "Maria Barrett",
                    "Yonatan Belinkov",
                    "Desmond Elliott",
                    "Anders S\u00f8gaard"
                ],
                "title": "The sensitivity of language models and humans to Winograd schema perturbations",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_62",
            "content": "UNKNOWN, None, 1993, Natural language processing using a propositional semantic network with structured variables. Minds and machines, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": null,
                "title": null,
                "pub_date": "1993",
                "pub_title": "Natural language processing using a propositional semantic network with structured variables. Minds and machines",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_63",
            "content": "Mikel Artetxe, Sebastian Ruder, Dani Yogatama, On the cross-lingual transferability of monolingual representations, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "Mikel Artetxe",
                    "Sebastian Ruder",
                    "Dani Yogatama"
                ],
                "title": "On the cross-lingual transferability of monolingual representations",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_64",
            "content": "Akari Asai, Hannaneh Hajishirzi, Logicguided data augmentation and regularization for consistent question answering, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Akari Asai",
                    "Hannaneh Hajishirzi"
                ],
                "title": "Logicguided data augmentation and regularization for consistent question answering",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_65",
            "content": "UNKNOWN, None, 1995, , .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": null,
                "title": null,
                "pub_date": "1995",
                "pub_title": null,
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_66",
            "content": "Jon Barwise, Robin Cooper, Generalized quantifiers and natural language, 1981, Philosophy, language, and artificial intelligence, Springer.",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "Jon Barwise",
                    "Robin Cooper"
                ],
                "title": "Generalized quantifiers and natural language",
                "pub_date": "1981",
                "pub_title": "Philosophy, language, and artificial intelligence",
                "pub": "Springer"
            }
        },
        {
            "ix": "181-ARR_v2_67",
            "content": "R Samuel, Gabor Bowman, Christopher Angeli, Christopher Potts,  Manning, A large annotated corpus for learning natural language inference, 2015, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "R Samuel",
                    "Gabor Bowman",
                    "Christopher Angeli",
                    "Christopher Potts",
                    " Manning"
                ],
                "title": "A large annotated corpus for learning natural language inference",
                "pub_date": "2015",
                "pub_title": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_68",
            "content": "R Samuel, Christopher Bowman, Christopher Potts,  Manning, Recursive neural networks can learn logical semantics, 2015, Proceedings of the 3rd Workshop on Continuous Vector Space Models and their Compositionality, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "R Samuel",
                    "Christopher Bowman",
                    "Christopher Potts",
                    " Manning"
                ],
                "title": "Recursive neural networks can learn logical semantics",
                "pub_date": "2015",
                "pub_title": "Proceedings of the 3rd Workshop on Continuous Vector Space Models and their Compositionality",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "181-ARR_v2_69",
            "content": "Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, John Schulman, Training verifiers to solve math word problems, 2021, ArXiv, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Karl Cobbe",
                    "Vineet Kosaraju",
                    "Mohammad Bavarian",
                    "Jacob Hilton",
                    "Reiichiro Nakano",
                    "Christopher Hesse",
                    "John Schulman"
                ],
                "title": "Training verifiers to solve math word problems",
                "pub_date": "2021",
                "pub_title": "ArXiv",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_70",
            "content": "Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettlemoyer, Veselin Stoyanov, Unsupervised cross-lingual representation learning at scale, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Alexis Conneau",
                    "Kartikay Khandelwal",
                    "Naman Goyal",
                    "Vishrav Chaudhary",
                    "Guillaume Wenzek",
                    "Francisco Guzm\u00e1n",
                    "Edouard Grave",
                    "Myle Ott",
                    "Luke Zettlemoyer",
                    "Veselin Stoyanov"
                ],
                "title": "Unsupervised cross-lingual representation learning at scale",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_71",
            "content": "Alexis Conneau, Ruty Rinott, Guillaume Lample, Adina Williams, Samuel Bowman, Holger Schwenk, Veselin Stoyanov, XNLI: Evaluating cross-lingual sentence representations, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Alexis Conneau",
                    "Ruty Rinott",
                    "Guillaume Lample",
                    "Adina Williams",
                    "Samuel Bowman",
                    "Holger Schwenk",
                    "Veselin Stoyanov"
                ],
                "title": "XNLI: Evaluating cross-lingual sentence representations",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "181-ARR_v2_72",
            "content": "UNKNOWN, None, 1994, Fracas: A framework for computational semantics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": null,
                "title": null,
                "pub_date": "1994",
                "pub_title": "Fracas: A framework for computational semantics",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_73",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long and Short Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Jacob Devlin",
                    "Ming-Wei Chang",
                    "Kenton Lee",
                    "Kristina Toutanova"
                ],
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Long and Short Papers"
            }
        },
        {
            "ix": "181-ARR_v2_74",
            "content": "Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, Matt Gardner, DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    "Dheeru Dua",
                    "Yizhong Wang",
                    "Pradeep Dasigi",
                    "Gabriel Stanovsky",
                    "Sameer Singh",
                    "Matt Gardner"
                ],
                "title": "DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "181-ARR_v2_75",
            "content": "Anton\u00edn Dvo\u0159\u00e1k, Michal Hol\u010dapek, Type 1 , 1 fuzzy quantifiers determined by fuzzy measures on residuated lattices. part iii. extension, conservativity and extensionality, 2015, Fuzzy Sets Syst, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Anton\u00edn Dvo\u0159\u00e1k",
                    "Michal Hol\u010dapek"
                ],
                "title": "Type 1 , 1 fuzzy quantifiers determined by fuzzy measures on residuated lattices. part iii. extension, conservativity and extensionality",
                "pub_date": "2015",
                "pub_title": "Fuzzy Sets Syst",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_76",
            "content": "Allyson Ettinger, What BERT is not: Lessons from a new suite of psycholinguistic diagnostics for language models, 2020, Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Allyson Ettinger"
                ],
                "title": "What BERT is not: Lessons from a new suite of psycholinguistic diagnostics for language models",
                "pub_date": "2020",
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_77",
            "content": "UNKNOWN, None, 2018, Can neural networks understand logical entailment? arXiv preprint, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Can neural networks understand logical entailment? arXiv preprint",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_78",
            "content": "Izumi Haruta, Koji Mineshima, Daisuke Bekki, Logical inferences with comparatives and generalized quantifiers, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Izumi Haruta",
                    "Koji Mineshima",
                    "Daisuke Bekki"
                ],
                "title": "Logical inferences with comparatives and generalized quantifiers",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_79",
            "content": "UNKNOWN, None, 1981-05, Questions, quantifiers and crossing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": null,
                "title": null,
                "pub_date": "1981-05",
                "pub_title": "Questions, quantifiers and crossing",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_80",
            "content": "UNKNOWN, None, 2010, The expression of negation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": null,
                "title": null,
                "pub_date": "2010",
                "pub_title": "The expression of negation",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_81",
            "content": "Venelin Md Mosharaf Hossain, Pranoy Kovatchev, Tiffany Dutta, Elizabeth Kao, Eduardo Wei,  Blanco, An analysis of natural language inference benchmarks through the lens of negation, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Venelin Md Mosharaf Hossain",
                    "Pranoy Kovatchev",
                    "Tiffany Dutta",
                    "Elizabeth Kao",
                    "Eduardo Wei",
                    " Blanco"
                ],
                "title": "An analysis of natural language inference benchmarks through the lens of negation",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_82",
            "content": "Hai Hu, Qi Chen, Larry Moss, Natural language inference with monotonicity, 2019, Proceedings of the 13th International Conference on Computational Semantics -Short Papers, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "Hai Hu",
                    "Qi Chen",
                    "Larry Moss"
                ],
                "title": "Natural language inference with monotonicity",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 13th International Conference on Computational Semantics -Short Papers",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_83",
            "content": "Junjie Hu, Sebastian Ruder, Aditya Siddhant, Graham Neubig, Orhan Firat, Melvin Johnson, Xtreme: A massively multilingual multitask benchmark for evaluating cross-lingual generalisation, 2020, International Conference on Machine Learning, PMLR.",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Junjie Hu",
                    "Sebastian Ruder",
                    "Aditya Siddhant",
                    "Graham Neubig",
                    "Orhan Firat",
                    "Melvin Johnson"
                ],
                "title": "Xtreme: A massively multilingual multitask benchmark for evaluating cross-lingual generalisation",
                "pub_date": "2020",
                "pub_title": "International Conference on Machine Learning",
                "pub": "PMLR"
            }
        },
        {
            "ix": "181-ARR_v2_84",
            "content": "Devin Johnson, Denise Mak, Andrew Barker, Lexi Loessberg-Zahl, Probing for multilingual numerical understanding in transformer-based language models, 2020, Proceedings of the Third Black-boxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Devin Johnson",
                    "Denise Mak",
                    "Andrew Barker",
                    "Lexi Loessberg-Zahl"
                ],
                "title": "Probing for multilingual numerical understanding in transformer-based language models",
                "pub_date": "2020",
                "pub_title": "Proceedings of the Third Black-boxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "181-ARR_v2_85",
            "content": "Pratik Joshi, Somak Aditya, Aalok Sathe, Monojit Choudhury, TaxiNLI: Taking a ride up the NLU hill, 2020, Proceedings of the 24th Conference on Computational Natural Language Learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Pratik Joshi",
                    "Somak Aditya",
                    "Aalok Sathe",
                    "Monojit Choudhury"
                ],
                "title": "TaxiNLI: Taking a ride up the NLU hill",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 24th Conference on Computational Natural Language Learning",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_86",
            "content": "K Karthikeyan, Aalok Sathe, Somak Aditya, Monojit Choudhury, Analyzing the effects of reasoning types on cross-lingual transfer performance, 2021, Proceedings of the 1st Workshop on Multilingual Representation Learning, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "K Karthikeyan",
                    "Aalok Sathe",
                    "Somak Aditya",
                    "Monojit Choudhury"
                ],
                "title": "Analyzing the effects of reasoning types on cross-lingual transfer performance",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 1st Workshop on Multilingual Representation Learning",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "181-ARR_v2_87",
            "content": "Napoleon Katsos, Chris Cummins, Maria-Jos\u00e9 Ezeizabarrena, Anna Gavarr\u00f3, Jelena Kuva\u010d Kraljevi\u0107, Gordana Hrzica, Athina Kleanthes K Grohmann, Kristine Jensen De Skordi, Lone L\u00f3pez,  Sundahl, Cross-linguistic patterns in the acquisition of quantifiers, 2016, Proceedings of the National Academy of Sciences, .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": [
                    "Napoleon Katsos",
                    "Chris Cummins",
                    "Maria-Jos\u00e9 Ezeizabarrena",
                    "Anna Gavarr\u00f3",
                    "Jelena Kuva\u010d Kraljevi\u0107",
                    "Gordana Hrzica",
                    "Athina Kleanthes K Grohmann",
                    "Kristine Jensen De Skordi",
                    "Lone L\u00f3pez",
                    " Sundahl"
                ],
                "title": "Cross-linguistic patterns in the acquisition of quantifiers",
                "pub_date": "2016",
                "pub_title": "Proceedings of the National Academy of Sciences",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_88",
            "content": "UNKNOWN, None, , , Angeliek Van Hout.",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": null,
                "pub": "Angeliek Van Hout"
            }
        },
        {
            "ix": "181-ARR_v2_89",
            "content": "UNKNOWN, None, 2012, Handbook of quantifiers in natural language, .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": null,
                "title": null,
                "pub_date": "2012",
                "pub_title": "Handbook of quantifiers in natural language",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_90",
            "content": "L Edward, Dag Keenan,  Westerst\u00e5hl, Generalized quantifiers in linguistics and logic, 1997, Handbook of Logic and Language, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "L Edward",
                    "Dag Keenan",
                    " Westerst\u00e5hl"
                ],
                "title": "Generalized quantifiers in linguistics and logic",
                "pub_date": "1997",
                "pub_title": "Handbook of Logic and Language",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_91",
            "content": "Douwe Kiela, Max Bartolo, Yixin Nie, Divyansh Kaushik, Atticus Geiger, Zhengxuan Wu, Bertie Vidgen, Grusha Prasad, Amanpreet Singh, Pratik Ringshia, Zhiyi Ma, Tristan Thrush, Sebastian Riedel, Zeerak Waseem, Pontus Stenetorp, Robin Jia, Mohit Bansal, Christopher Potts, Adina Williams, Dynabench: Rethinking benchmarking in NLP, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": [
                    "Douwe Kiela",
                    "Max Bartolo",
                    "Yixin Nie",
                    "Divyansh Kaushik",
                    "Atticus Geiger",
                    "Zhengxuan Wu",
                    "Bertie Vidgen",
                    "Grusha Prasad",
                    "Amanpreet Singh",
                    "Pratik Ringshia",
                    "Zhiyi Ma",
                    "Tristan Thrush",
                    "Sebastian Riedel",
                    "Zeerak Waseem",
                    "Pontus Stenetorp",
                    "Robin Jia",
                    "Mohit Bansal",
                    "Christopher Potts",
                    "Adina Williams"
                ],
                "title": "Dynabench: Rethinking benchmarking in NLP",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "181-ARR_v2_92",
            "content": "Najoung Kim, Roma Patel, Adam Poliak, Patrick Xia, Alex Wang, Tom Mccoy, Ian Tenney, Alexis Ross, Tal Linzen, Benjamin Van Durme, Samuel Bowman, Ellie Pavlick, Probing what different NLP tasks teach machines about function word comprehension, 2019, Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*SEM 2019), .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": [
                    "Najoung Kim",
                    "Roma Patel",
                    "Adam Poliak",
                    "Patrick Xia",
                    "Alex Wang",
                    "Tom Mccoy",
                    "Ian Tenney",
                    "Alexis Ross",
                    "Tal Linzen",
                    "Benjamin Van Durme",
                    "Samuel Bowman",
                    "Ellie Pavlick"
                ],
                "title": "Probing what different NLP tasks teach machines about function word comprehension",
                "pub_date": "2019",
                "pub_title": "Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*SEM 2019)",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_93",
            "content": "UNKNOWN, None, 2019, Crosslingual language model pretraining, .",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Crosslingual language model pretraining",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_94",
            "content": "UNKNOWN, None, 2000, Presumptive meanings: The theory of generalized conversational implicature, MIT press.",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": null,
                "title": null,
                "pub_date": "2000",
                "pub_title": "Presumptive meanings: The theory of generalized conversational implicature",
                "pub": "MIT press"
            }
        },
        {
            "ix": "181-ARR_v2_95",
            "content": "Patrick Lewis, Barlas Oguz, Ruty Rinott, Sebastian Riedel, Holger Schwenk, MLQA: Evaluating cross-lingual extractive question answering, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": [
                    "Patrick Lewis",
                    "Barlas Oguz",
                    "Ruty Rinott",
                    "Sebastian Riedel",
                    "Holger Schwenk"
                ],
                "title": "MLQA: Evaluating cross-lingual extractive question answering",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_96",
            "content": "Tao Li, Vivek Gupta, Maitrey Mehta, Vivek , A logic-driven framework for consistency of neural models, 2019-03, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": [
                    "Tao Li",
                    "Vivek Gupta",
                    "Maitrey Mehta",
                    "Vivek "
                ],
                "title": "A logic-driven framework for consistency of neural models",
                "pub_date": "2019-03",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "181-ARR_v2_97",
            "content": "Per Lindstr\u00f6m, First order predicate logic with generalized quantifiers, 1966, Theoria, .",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "Per Lindstr\u00f6m"
                ],
                "title": "First order predicate logic with generalized quantifiers",
                "pub_date": "1966",
                "pub_title": "Theoria",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_98",
            "content": "UNKNOWN, None, 1907, Roberta: A robustly optimized bert pretraining approach. ArXiv, abs, .",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": null,
                "title": null,
                "pub_date": "1907",
                "pub_title": "Roberta: A robustly optimized bert pretraining approach. ArXiv, abs",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_99",
            "content": "Lisa Matthewson, Quantification and the nature of crosslinguistic variation, 2001, Natural Language Semantics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": [
                    "Lisa Matthewson"
                ],
                "title": "Quantification and the nature of crosslinguistic variation",
                "pub_date": "2001",
                "pub_title": "Natural Language Semantics",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_100",
            "content": "Lisa Matthewson, On the methodology of semantic fieldwork, 2004, International journal of American linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": [
                    "Lisa Matthewson"
                ],
                "title": "On the methodology of semantic fieldwork",
                "pub_date": "2004",
                "pub_title": "International journal of American linguistics",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_101",
            "content": "UNKNOWN, None, 2008, Quantification: A crosslinguistic perspective, .",
            "ntype": "ref",
            "meta": {
                "xid": "b40",
                "authors": null,
                "title": null,
                "pub_date": "2008",
                "pub_title": "Quantification: A crosslinguistic perspective",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_102",
            "content": "Richard Montague, The proper treatment of quantification in ordinary english, 1973, Approaches to natural language, Springer.",
            "ntype": "ref",
            "meta": {
                "xid": "b41",
                "authors": [
                    "Richard Montague"
                ],
                "title": "The proper treatment of quantification in ordinary english",
                "pub_date": "1973",
                "pub_title": "Approaches to natural language",
                "pub": "Springer"
            }
        },
        {
            "ix": "181-ARR_v2_103",
            "content": "Andrzej Mostowski, On a generalization of quantifiers, 1957, Fundamenta Mathematicae, .",
            "ntype": "ref",
            "meta": {
                "xid": "b42",
                "authors": [
                    "Andrzej Mostowski"
                ],
                "title": "On a generalization of quantifiers",
                "pub_date": "1957",
                "pub_title": "Fundamenta Mathematicae",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_104",
            "content": "UNKNOWN, None, 2019, Siamese recurrent networks learn first-order logic reasoning and exhibit zero-shot compositional generalization, .",
            "ntype": "ref",
            "meta": {
                "xid": "b43",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Siamese recurrent networks learn first-order logic reasoning and exhibit zero-shot compositional generalization",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_105",
            "content": "Aakanksha Naik, Abhilasha Ravichander, Norman Sadeh, Carolyn Rose, Graham Neubig, Stress test evaluation for natural language inference, 2018, Proceedings of the 27th International Conference on Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b44",
                "authors": [
                    "Aakanksha Naik",
                    "Abhilasha Ravichander",
                    "Norman Sadeh",
                    "Carolyn Rose",
                    "Graham Neubig"
                ],
                "title": "Stress test evaluation for natural language inference",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 27th International Conference on Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_106",
            "content": "Yixin Nie, Haonan Chen, Mohit Bansal, Combining fact extraction and verification with neural semantic matching networks, 2019, Association for the Advancement of Artificial Intelligence (AAAI), .",
            "ntype": "ref",
            "meta": {
                "xid": "b45",
                "authors": [
                    "Yixin Nie",
                    "Haonan Chen",
                    "Mohit Bansal"
                ],
                "title": "Combining fact extraction and verification with neural semantic matching networks",
                "pub_date": "2019",
                "pub_title": "Association for the Advancement of Artificial Intelligence (AAAI)",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_107",
            "content": "Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, Douwe Kiela, Adversarial NLI: A new benchmark for natural language understanding, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b46",
                "authors": [
                    "Yixin Nie",
                    "Adina Williams",
                    "Emily Dinan",
                    "Mohit Bansal",
                    "Jason Weston",
                    "Douwe Kiela"
                ],
                "title": "Adversarial NLI: A new benchmark for natural language understanding",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "181-ARR_v2_108",
            "content": "UNKNOWN, None, 2012, Quantifiers in Adyghe, Springer.",
            "ntype": "ref",
            "meta": {
                "xid": "b47",
                "authors": null,
                "title": null,
                "pub_date": "2012",
                "pub_title": "Quantifiers in Adyghe",
                "pub": "Springer"
            }
        },
        {
            "ix": "181-ARR_v2_109",
            "content": "Joakim Nivre, Marie-Catherine De Marneffe, Filip Ginter, Jan Haji\u010d, Christopher Manning, Sampo Pyysalo, Sebastian Schuster, Francis Tyers, Daniel Zeman, Universal Dependencies v2: An evergrowing multilingual treebank collection, 2020, Proceedings of the 12th Language Resources and Evaluation Conference, .",
            "ntype": "ref",
            "meta": {
                "xid": "b48",
                "authors": [
                    "Joakim Nivre",
                    "Marie-Catherine De Marneffe",
                    "Filip Ginter",
                    "Jan Haji\u010d",
                    "Christopher Manning",
                    "Sampo Pyysalo",
                    "Sebastian Schuster",
                    "Francis Tyers",
                    "Daniel Zeman"
                ],
                "title": "Universal Dependencies v2: An evergrowing multilingual treebank collection",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 12th Language Resources and Evaluation Conference",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_110",
            "content": "UNKNOWN, None, , 2020. Proceedings of the Third Workshop on Computational Models of Reference, Anaphora and Coreference, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b49",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "2020. Proceedings of the Third Workshop on Computational Models of Reference, Anaphora and Coreference",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "181-ARR_v2_111",
            "content": "UNKNOWN, None, 2019, Proceedings of the Second Workshop on Computational Models of Reference, Anaphora and Coreference, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b50",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Proceedings of the Second Workshop on Computational Models of Reference, Anaphora and Coreference",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "181-ARR_v2_112",
            "content": "Alicia Parrish, William Huang, Omar Agha, Soo-Hwan Lee, Nikita Nangia, Alexia Warstadt, Karmanya Aggarwal, Emily Allaway, Tal Linzen, Samuel Bowman, Does putting a linguist in the loop improve NLU data collection?, 2021, Findings of the Association for Computational Linguistics: EMNLP 2021, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b51",
                "authors": [
                    "Alicia Parrish",
                    "William Huang",
                    "Omar Agha",
                    "Soo-Hwan Lee",
                    "Nikita Nangia",
                    "Alexia Warstadt",
                    "Karmanya Aggarwal",
                    "Emily Allaway",
                    "Tal Linzen",
                    "Samuel Bowman"
                ],
                "title": "Does putting a linguist in the loop improve NLU data collection?",
                "pub_date": "2021",
                "pub_title": "Findings of the Association for Computational Linguistics: EMNLP 2021",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "181-ARR_v2_113",
            "content": "UNKNOWN, None, 1970, Negation, conjunction, and quantifiers: Syntax vs. semantics. Foundations of Language, .",
            "ntype": "ref",
            "meta": {
                "xid": "b52",
                "authors": null,
                "title": null,
                "pub_date": "1970",
                "pub_title": "Negation, conjunction, and quantifiers: Syntax vs. semantics. Foundations of Language",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_114",
            "content": "UNKNOWN, None, 2006, Quantifiers in language and logic, Oxford University Press.",
            "ntype": "ref",
            "meta": {
                "xid": "b53",
                "authors": null,
                "title": null,
                "pub_date": "2006",
                "pub_title": "Quantifiers in language and logic",
                "pub": "Oxford University Press"
            }
        },
        {
            "ix": "181-ARR_v2_115",
            "content": "Peng Qi, Yuhao Zhang, Yuhui Zhang, Jason Bolton, Christopher Manning, Stanza: A python natural language processing toolkit for many human languages, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b54",
                "authors": [
                    "Peng Qi",
                    "Yuhao Zhang",
                    "Yuhui Zhang",
                    "Jason Bolton",
                    "Christopher Manning"
                ],
                "title": "Stanza: A python natural language processing toolkit for many human languages",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_116",
            "content": "Carlos Marco Tulio Ribeiro, Sameer Guestrin,  Singh, Are red roses red? evaluating consistency of question-answering models, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b55",
                "authors": [
                    "Carlos Marco Tulio Ribeiro",
                    "Sameer Guestrin",
                    " Singh"
                ],
                "title": "Are red roses red? evaluating consistency of question-answering models",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_117",
            "content": "Tongshuang Marco Tulio Ribeiro, Carlos Wu, Sameer Guestrin,  Singh, Beyond accuracy: Behavioral testing of NLP models with CheckList, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b56",
                "authors": [
                    "Tongshuang Marco Tulio Ribeiro",
                    "Carlos Wu",
                    "Sameer Guestrin",
                    " Singh"
                ],
                "title": "Beyond accuracy: Behavioral testing of NLP models with CheckList",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_118",
            "content": "H James, Stephen Schmerl,  Simpson, On the role of ramsey quantifiers in first order arithmetic, 1982, J. Symb. Log, .",
            "ntype": "ref",
            "meta": {
                "xid": "b57",
                "authors": [
                    "H James",
                    "Stephen Schmerl",
                    " Simpson"
                ],
                "title": "On the role of ramsey quantifiers in first order arithmetic",
                "pub_date": "1982",
                "pub_title": "J. Symb. Log",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_119",
            "content": "Shashank Srivastava, Igor Labutov, Tom Mitchell, Zero-shot learning of classifiers from natural language quantification, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b58",
                "authors": [
                    "Shashank Srivastava",
                    "Igor Labutov",
                    "Tom Mitchell"
                ],
                "title": "Zero-shot learning of classifiers from natural language quantification",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "181-ARR_v2_120",
            "content": "Penka Stateva, Arthur Stepanov, Viviane D\u00e9prez, Ludivine Dupuy, Anne Reboul, Cross-linguistic variation in the meaning of quantifiers: Implications for pragmatic enrichment, 2019, Frontiers in Psychology, .",
            "ntype": "ref",
            "meta": {
                "xid": "b59",
                "authors": [
                    "Penka Stateva",
                    "Arthur Stepanov",
                    "Viviane D\u00e9prez",
                    "Ludivine Dupuy",
                    "Anne Reboul"
                ],
                "title": "Cross-linguistic variation in the meaning of quantifiers: Implications for pragmatic enrichment",
                "pub_date": "2019",
                "pub_title": "Frontiers in Psychology",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_121",
            "content": "Shane Steinert-Threlkeld, Learnability and semantic universals, 2019, Semantics and Pragmatics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b60",
                "authors": [
                    "Shane Steinert-Threlkeld"
                ],
                "title": "Learnability and semantic universals",
                "pub_date": "2019",
                "pub_title": "Semantics and Pragmatics",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_122",
            "content": "Shane Steinert-Threlkeld, Quantifiers in natural language: Efficient communication and degrees of semantic universals, 2021, Entropy, .",
            "ntype": "ref",
            "meta": {
                "xid": "b61",
                "authors": [
                    "Shane Steinert-Threlkeld"
                ],
                "title": "Quantifiers in natural language: Efficient communication and degrees of semantic universals",
                "pub_date": "2021",
                "pub_title": "Entropy",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_123",
            "content": "UNKNOWN, None, 2016, Cognitive Processing of Quantifiers, Springer International Publishing.",
            "ntype": "ref",
            "meta": {
                "xid": "b62",
                "authors": null,
                "title": null,
                "pub_date": "2016",
                "pub_title": "Cognitive Processing of Quantifiers",
                "pub": "Springer International Publishing"
            }
        },
        {
            "ix": "181-ARR_v2_124",
            "content": "Jakub Szymanik, Camilo Thorne, Semantic complexity of quantifiers and their distribution in corpora, 2015, Proceedings of the 11th International Conference on Computational Semantics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b63",
                "authors": [
                    "Jakub Szymanik",
                    "Camilo Thorne"
                ],
                "title": "Semantic complexity of quantifiers and their distribution in corpora",
                "pub_date": "2015",
                "pub_title": "Proceedings of the 11th International Conference on Computational Semantics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "181-ARR_v2_125",
            "content": "Wataru Uegaki, The Informativeness/Complexity Trade-Off in the Domain of Boolean Connectives, 2022, Linguistic Inquiry, .",
            "ntype": "ref",
            "meta": {
                "xid": "b64",
                "authors": [
                    "Wataru Uegaki"
                ],
                "title": "The Informativeness/Complexity Trade-Off in the Domain of Boolean Connectives",
                "pub_date": "2022",
                "pub_title": "Linguistic Inquiry",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_126",
            "content": "Yuval Varkel, Amir Globerson, Pre-training mention representations in coreference models, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b65",
                "authors": [
                    "Yuval Varkel",
                    "Amir Globerson"
                ],
                "title": "Pre-training mention representations in coreference models",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_127",
            "content": "UNKNOWN, None, 2017, Can neural networks learn logical reasoning? CLASP Papers in Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b66",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": "Can neural networks learn logical reasoning? CLASP Papers in Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_128",
            "content": "Dag Westerst\u00e5hl, Quantifiers in formal and natural languages, 1989, Handbook of philosophical logic, Springer.",
            "ntype": "ref",
            "meta": {
                "xid": "b67",
                "authors": [
                    "Dag Westerst\u00e5hl"
                ],
                "title": "Quantifiers in formal and natural languages",
                "pub_date": "1989",
                "pub_title": "Handbook of philosophical logic",
                "pub": "Springer"
            }
        },
        {
            "ix": "181-ARR_v2_129",
            "content": "Adina Williams, Nikita Nangia, Samuel Bowman, A broad-coverage challenge corpus for sentence understanding through inference, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b68",
                "authors": [
                    "Adina Williams",
                    "Nikita Nangia",
                    "Samuel Bowman"
                ],
                "title": "A broad-coverage challenge corpus for sentence understanding through inference",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "181-ARR_v2_130",
            "content": "UNKNOWN, None, 2020, Anlizing the adversarial natural language inference dataset, .",
            "ntype": "ref",
            "meta": {
                "xid": "b69",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Anlizing the adversarial natural language inference dataset",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_131",
            "content": "William Woods, Understanding subsumption and taxonomy: A framework for progress, 1991, Principles of Semantic Networks, .",
            "ntype": "ref",
            "meta": {
                "xid": "b70",
                "authors": [
                    "William Woods"
                ],
                "title": "Understanding subsumption and taxonomy: A framework for progress",
                "pub_date": "1991",
                "pub_title": "Principles of Semantic Networks",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_132",
            "content": "Hitomi Yanaka, Koji Mineshima, Daisuke Bekki, Kentaro Inui, Do neural models learn systematicity of monotonicity inference in natural language?, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b71",
                "authors": [
                    "Hitomi Yanaka",
                    "Koji Mineshima",
                    "Daisuke Bekki",
                    "Kentaro Inui"
                ],
                "title": "Do neural models learn systematicity of monotonicity inference in natural language?",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_133",
            "content": "Hitomi Yanaka, Koji Mineshima, Daisuke Bekki, Kentaro Inui, Satoshi Sekine, Lasha Abzianidze, Johan Bos, Can neural networks understand monotonicity reasoning?, 2019, Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b72",
                "authors": [
                    "Hitomi Yanaka",
                    "Koji Mineshima",
                    "Daisuke Bekki",
                    "Kentaro Inui",
                    "Satoshi Sekine",
                    "Lasha Abzianidze",
                    "Johan Bos"
                ],
                "title": "Can neural networks understand monotonicity reasoning?",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_134",
            "content": "Deming Ye, Yankai Lin, Jiaju Du, Zhenghao Liu, Peng Li, Maosong Sun, Zhiyuan Liu, Coreferential Reasoning Learning for Language Representation, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b73",
                "authors": [
                    "Deming Ye",
                    "Yankai Lin",
                    "Jiaju Du",
                    "Zhenghao Liu",
                    "Peng Li",
                    "Maosong Sun",
                    "Zhiyuan Liu"
                ],
                "title": "Coreferential Reasoning Learning for Language Representation",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_135",
            "content": "John Yen, Generalizing term subsumption languages to fuzzy logic, 1991, IJCAI, .",
            "ntype": "ref",
            "meta": {
                "xid": "b74",
                "authors": [
                    "John Yen"
                ],
                "title": "Generalizing term subsumption languages to fuzzy logic",
                "pub_date": "1991",
                "pub_title": "IJCAI",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_136",
            "content": "Wenpeng Yin, Dragomir Radev, Caiming Xiong, DocNLI: A large-scale dataset for documentlevel natural language inference, 2021, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, .",
            "ntype": "ref",
            "meta": {
                "xid": "b75",
                "authors": [
                    "Wenpeng Yin",
                    "Dragomir Radev",
                    "Caiming Xiong"
                ],
                "title": "DocNLI: A large-scale dataset for documentlevel natural language inference",
                "pub_date": "2021",
                "pub_title": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_137",
            "content": "A Lotfi,  Zadeh, A computational approach to fuzzy quantifiers in natural languages, 1983, Computational linguistics, Elsevier.",
            "ntype": "ref",
            "meta": {
                "xid": "b76",
                "authors": [
                    "A Lotfi",
                    " Zadeh"
                ],
                "title": "A computational approach to fuzzy quantifiers in natural languages",
                "pub_date": "1983",
                "pub_title": "Computational linguistics",
                "pub": "Elsevier"
            }
        },
        {
            "ix": "181-ARR_v2_138",
            "content": "Xikun Zhang, Deepak Ramachandran, Ian Tenney, Yanai Elazar, Dan Roth, Do language embeddings capture scales?, 2020, Findings of the Association for Computational Linguistics: EMNLP 2020, .",
            "ntype": "ref",
            "meta": {
                "xid": "b77",
                "authors": [
                    "Xikun Zhang",
                    "Deepak Ramachandran",
                    "Ian Tenney",
                    "Yanai Elazar",
                    "Dan Roth"
                ],
                "title": "Do language embeddings capture scales?",
                "pub_date": "2020",
                "pub_title": "Findings of the Association for Computational Linguistics: EMNLP 2020",
                "pub": null
            }
        },
        {
            "ix": "181-ARR_v2_139",
            "content": "UNKNOWN, None, 1949, Human behavior and the principle of least effort, .",
            "ntype": "ref",
            "meta": {
                "xid": "b78",
                "authors": null,
                "title": null,
                "pub_date": "1949",
                "pub_title": "Human behavior and the principle of least effort",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "181-ARR_v2_0@0",
            "content": "Generalized Quantifiers as a Source of Error in Multilingual NLU Benchmarks",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_0",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_2@0",
            "content": "Logical approaches to representing language have developed and evaluated computational models of quantifier words since the 19th century, but today's NLU models still struggle to capture their semantics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_2",
            "start": 0,
            "end": 202,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_2@1",
            "content": "We rely on Generalized Quantifier Theory for languageindependent representations of the semantics of quantifier words, to quantify their contribution to the errors of NLU models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_2",
            "start": 204,
            "end": 381,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_2@2",
            "content": "We find that quantifiers are pervasive in NLU benchmarks, and their occurrence at test time is associated with performance drops.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_2",
            "start": 383,
            "end": 511,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_2@3",
            "content": "Multilingual models also exhibit unsatisfying quantifier reasoning abilities, but not necessarily worse for non-English languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_2",
            "start": 513,
            "end": 642,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_2@4",
            "content": "To facilitate directlytargeted probing, we present an adversarial generalized quantifier NLI task (GQNLI) and show that pre-trained language models have a clear lack of robustness in generalized quantifier reasoning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_2",
            "start": 644,
            "end": 859,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_4@0",
            "content": "Quantifier words-such as each or most or more than three-have been extensively studied, both in logic and in linguistics (Westerst\u00e5hl, 1989;Peters and Westerst\u00e5hl, 2006), going all the way back to Frege (1879).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_4",
            "start": 0,
            "end": 209,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_4@1",
            "content": "In this paper, we examine the extent to which they present a challenge to modern NLU systems.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_4",
            "start": 211,
            "end": 303,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_4@2",
            "content": "Our analysis is motivated by three observations:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_4",
            "start": 305,
            "end": 352,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_5@0",
            "content": "Quantifier words are abstract Unlike nouns, verbs and adjectives, quantifier words do not have referents out in the world.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_5",
            "start": 0,
            "end": 121,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_5@1",
            "content": "Rather, quantifier words specify relationships between sets of entities, events and properties.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_5",
            "start": 123,
            "end": 217,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_5@2",
            "content": "To provide intuitions about the semantics of quantifier words, and to be able to refer to quantifiers in a language-independent way, we rely on the notion of generalized quantifiers (Mostowski, 1957), as described in \u00a72.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_5",
            "start": 219,
            "end": 438,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_6@0",
            "content": "Quantifier words vary across languages Quantifier word inventories differ across languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_6",
            "start": 0,
            "end": 90,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_7@0",
            "content": "CONTEXT: A piece of paper was later found on which he had written his last statements in two languages, Latin and German.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_7",
            "start": 0,
            "end": 120,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_7@1",
            "content": "Only one statement was in Latin and the rest in German.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_7",
            "start": 122,
            "end": 176,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_8@0",
            "content": "In what language were most statements written?",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_8",
            "start": 0,
            "end": 45,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_8@1",
            "content": "ANSWER: German PREDICTED AN-SWER: Latin and German NLI_Spanish PREMISE: M\u00e1s de tres personas resultaron heridas en un accidente de dos veh\u00edculos el lunes por la noche.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_8",
            "start": 47,
            "end": 213,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_9@0",
            "content": "(translation: More than three people were injured in a two-vehicle crash Monday evening.)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_9",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_9@1",
            "content": "HYPOTHESIS: Hab\u00eda 4 personas involucradas.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_9",
            "start": 90,
            "end": 131,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_9@2",
            "content": "(translation: There were 4 people involved.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_9",
            "start": 133,
            "end": 175,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_9@3",
            "content": "LABEL: Neutral PREDICTED LABEL: Entailment Table 1: Examples of quantifiers (marked in bold texts) in NLP tasks, with RoBERTa's prediction for QA and XLM-R's prediction for NLI after fine-tuning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_9",
            "start": 177,
            "end": 371,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_10@0",
            "content": "Often what is considered rough translation equivalents also differ in syntax, fine-grained semantics or pragmatics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_10",
            "start": 0,
            "end": 114,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_10@1",
            "content": "Stateva et al. (2019) show, e.g., that perceptions of the numerical bounds of existential quantifiers differ across speakers of English, French, Slovenian, and German.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_10",
            "start": 116,
            "end": 282,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_10@2",
            "content": "Other papers showing discrepancies between quantifier systems include comparisons of Salish to English (Matthewson, 2001), Adyghe to English (Nikolaeva, 2012), or of Dutch, Hebrew and Bengali (Gil, 1982).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_10",
            "start": 284,
            "end": 487,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_10@3",
            "content": "The cross-linguistic differences in how generalized quantifiers are expressed motivates a cross-lingual error analysis, since quantifiers may contribute more to error when processing some languages rather than others.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_10",
            "start": 489,
            "end": 705,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_11@0",
            "content": "Quantifier words are important Quantifier words are extremely important for tasks that require inference, including natural language inference, question answering, fact-checking, etc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_11",
            "start": 0,
            "end": 182,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_11@1",
            "content": "Datasets have, for example, been developed for numerical reasoning in English (Dua et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_11",
            "start": 184,
            "end": 280,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_11@2",
            "content": "Several researchers have identified quantifier words as important sources of errors for natural language processing systems (Joshi et al., 2020); see Table 1 for examples of such errors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_11",
            "start": 282,
            "end": 467,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_11@3",
            "content": "Unfortunately, most efforts have concentrated on subsets of quantifier words and on English.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_11",
            "start": 469,
            "end": 560,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_12@0",
            "content": "Contributions We analyze how quantifiers are represented in NLU benchmarks, and how their occurrence at test time contributes to errors by neural language models (LMs).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_12",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_12@1",
            "content": "We derive a linguistically motivated 11-way categorization set for generalized quantifiers and look into their distribution in three steps: (a) monolingual NLI; (b) cross-lingual NLI; (c) cross-lingual question answering.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_12",
            "start": 169,
            "end": 389,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_12@2",
            "content": "We also propose GQNLI 1 , an adversarial generalized quantifier NLI challenge dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_12",
            "start": 391,
            "end": 476,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_12@3",
            "content": "Our work shows that (i) generalized quantifiers are pervasive and cause overall performance drops in NLU benchmarks; (ii) the contribution of quantifier words to system error varies across languages; and (iii) generalized quantifiers are particularly difficult for LMs in interaction with negation and subsumption.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_12",
            "start": 478,
            "end": 791,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_13@0",
            "content": "Background",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_13",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_14@0",
            "content": "Generalized quantifiers (GQs) are developed upon first-order predicate logic, denoting relations between sets (Mostowski, 1957).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_14",
            "start": 0,
            "end": 127,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_14@1",
            "content": "Given a universe E, a quantifier Q would be treated as a mapping Q E from the Cartesian product of powersets P(E) \u00d7 P(E) to the set {false,true} or, as a binary relation on subsets of E (Dvo\u0159\u00e1k and Hol\u010dapek, 2015).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_14",
            "start": 129,
            "end": 342,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_14@2",
            "content": "GQs are generalizations of the \u2200,\u2203 quantifiers from first-order predicate logic (Mostowski, 1957;Lindstr\u00f6m, 1966;Montague, 1973;Bach et al., 1995;Keenan and Paperno, 2012).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_14",
            "start": 344,
            "end": 515,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_14@3",
            "content": "A generalized quantifier is, abstractly, a relation between sets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_14",
            "start": 517,
            "end": 581,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_14@4",
            "content": "Generalized quantifier theory, while developed by logicians, is used by formal linguists to analyze the meaning of quantifier words in combination with referential expressions (Barwise and Cooper, 1981;Higginbotham and May, 1981).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_14",
            "start": 583,
            "end": 812,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_15@0",
            "content": "Most human languages contain ways of expressing generalized quantifiers, and their semantics exhibit striking similarities across languages (Matthewson, 2004;Fintel and Matthewson, 2008;Steinert-Threlkeld, 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_15",
            "start": 0,
            "end": 211,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_15@1",
            "content": "At the same time, generalized quantifiers can be instantiated very differently across languages due to pragmatic considerations (Grice, 1989) or cognitive economy and costbenefit optimisation in the exchange of information (Levinson et al., 2000;Steinert-Threlkeld, 2021;Uegaki, 2022).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_15",
            "start": 213,
            "end": 497,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_15@2",
            "content": "Quantifier words also exhibit syntactic differences, e.g., with some languages having specialized words to express quantity, while others rely on metaphorical usage of common nouns (Katsos et al., 2012).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_15",
            "start": 499,
            "end": 701,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_15@3",
            "content": "In English, most is a determiner, but Spanish and French express the same concept through common nouns, la mayor\u00eda and la majorit\u00e9.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_15",
            "start": 703,
            "end": 833,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_15@4",
            "content": "The relative stability of the core semantics of quantifiers makes a cross-linguistic comparison possible, but the syntactic and pragmatic variation associated with the expression of generalized quantifiers poses a challenge for multilingual NLU.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_15",
            "start": 835,
            "end": 1079,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_15@5",
            "content": "We consult quantifier taxonomy studies (Keenan and Westerst\u00e5hl, 1997;Peters and Westerst\u00e5hl, 2006;Szymanik and Thorne, 2015;Szymanik, 2016) and derive a categorization set for quantifier analysis in NLU benchmarks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_15",
            "start": 1081,
            "end": 1294,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_15@6",
            "content": "In Table 2, we list the 11way quantifier categorization set and their logical denotation based on set theory.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_15",
            "start": 1296,
            "end": 1404,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_16@0",
            "content": "While other foci of formal linguistics have attracted the attention of NLP researchers-including coreference (Ogrodniczuk et al., 2019(Ogrodniczuk et al., , 2020 tion (Hossain et al., 2020;Hartmann et al., 2021), and consistency (Li et al., 2019;Ribeiro et al., 2019;Asai and Hajishirzi, 2020;Geva et al., 2022)-there has been little work on generalized quantifiers as a source of error in NLU, let alone in multilingual NLU.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_16",
            "start": 0,
            "end": 424,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_16@1",
            "content": "It remains an open problem whether LMs represent the semantics of quantifiers words adequately, or if they provide a basis for resolving scopal ambiguities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_16",
            "start": 426,
            "end": 581,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_16@2",
            "content": "2",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_16",
            "start": 583,
            "end": 583,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_17@0",
            "content": "NLU Benchmarks",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_17",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_18@0",
            "content": "We conduct an error analysis focusing on the role of generalized quantifiers in two NLU tasks, Natural Language Inference (NLI) and Question Answering (QA), which generally require understanding of quantifiers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_18",
            "start": 0,
            "end": 209,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_18@1",
            "content": "For each type of task, both monolingual and cross-lingual evaluation are conducted.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_18",
            "start": 211,
            "end": 293,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_18@2",
            "content": "We focus on generalized quantifiers in the hypotheses in NLI examples-and on generalized quantifiers in the question fields in question answering.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_18",
            "start": 295,
            "end": 440,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_18@3",
            "content": "To this end, we identify quantifiers by the lemma and the universal dependency relation (Nivre et al., 2020) of a quantifier after preprocessing the sentences using Stanza (Qi et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_18",
            "start": 442,
            "end": 631,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_18@4",
            "content": "Take the sentence \"The Yiddish culture has survived for more than a thousand years.\", we annotate it as \"The/det Yiddish/amod culture/nsubj have/aux survive/root for/case more/advmod than/fixed a/det thousand/nummod year/obl ./punct\". By matching the regex pattern of the quantifier \"more than k\", in this case \"((more|great)\\/advmod than\\/(fixed|case)|at\\/case least\\/nmod) .+\\/nummod .+\\/(nsubj|obj|obl)\", we approximate the surface form of the type \"more than k\".Through matching quantifier patterns, we are able to find entries in which quantifiers are instantiated.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_18",
            "start": 633,
            "end": 1202,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_18@5",
            "content": "See Appendix A for the list of regex patterns we write to identify GQs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_18",
            "start": 1204,
            "end": 1274,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_18@6",
            "content": "In Table 3 and Table 6, we present the statistics of the quantifier distributions in NLI and QA tasks, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_18",
            "start": 1276,
            "end": 1391,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_18@7",
            "content": "As can be seen, quantifiers are indeed widespread in NLU tasks, accounting for roughly 10% in NLI tasks and 5% in QA tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_18",
            "start": 1393,
            "end": 1515,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_18@8",
            "content": "We will further discuss the statistics and experiments in the following section.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_18",
            "start": 1517,
            "end": 1596,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_19@0",
            "content": "Quantifiers in English NLI Benchmarks",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_19",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_20@0",
            "content": "NLI is commonly framed as a three-way classification task with labels entailment, contradiction and neutral (Bowman et al., 2015a).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_20",
            "start": 0,
            "end": 130,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_20@1",
            "content": "While SOTA models exhibit low error rates on NLI benchmarks, it is unclear when they succeed or fail in their underlying reasoning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_20",
            "start": 132,
            "end": 262,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_20@2",
            "content": "We are interested in whether generalized quantifers challenge modern NLI models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_20",
            "start": 264,
            "end": 343,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_20@3",
            "content": "In our error analysis, we initially focus on three English NLI datasets, MultiNLI (MNLI; , SNLI (Bowman et al., 2015a) and ANLI (Nie et al., 2020) as testbeds.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_20",
            "start": 345,
            "end": 503,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_20@4",
            "content": "across, about 10% of all hypotheses contain quantifier words, indicating the pervasiveness of quantification.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_20",
            "start": 505,
            "end": 613,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_20@5",
            "content": "We also plot the frequency of quantifiers in NLI in Figure 1 and find the quantifier word distribution follows Zipf's law (Zipf, 1949).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_20",
            "start": 615,
            "end": 749,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_20@6",
            "content": "Note the top three most common quantifiers account for more than 90% of all.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_20",
            "start": 751,
            "end": 826,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_21@0",
            "content": "In order to investigate whether NLU systems can solve quantifiers in NLI, we experiment with two pretrained LMs: BERT 3 (Devlin et al., 2019) and RoBERTa 4 (Liu et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_21",
            "start": 0,
            "end": 174,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_21@1",
            "content": "We use the codebase by Nie et al. (2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_21",
            "start": 176,
            "end": 216,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_22@0",
            "content": "The training data combines SNLI, MNLI, FEVER-NLI (Nie et al., 2019) and ANLI.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_22",
            "start": 0,
            "end": 76,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_23@0",
            "content": "In Table 4, we report the test set performance on SNLI and ANLI, and the dev set performance on MLNI matched and mismatched sections.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_23",
            "start": 0,
            "end": 132,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_23@1",
            "content": "We can observe that SOTA models suffer from performance drops across almost all quantification phenomena in every task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_23",
            "start": 134,
            "end": 252,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_23@2",
            "content": "When it comes to performance over all quantifiers, the improvement from RoBERTa to BERT (2.2%) is less prominent than that over full datasets (2.9%), suggesting RoBERTa is particularly challenged.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_23",
            "start": 254,
            "end": 449,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_24@0",
            "content": "Taking a closer look at error by category, proportional quantifiers seem harder to solve than Aristotelian/counting quantifiers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_24",
            "start": 0,
            "end": 127,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_24@1",
            "content": "Except for k%, all proportional quantifiers-p/k, most, and few-are about 10% lower than the five counting quantifiers (except less than k) with BERT; and about 5% lower with RoBERTa.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_24",
            "start": 129,
            "end": 310,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_24@2",
            "content": "RoBERTa is not generally superior to BERT; e.g., for k%, BERT outperforms it by 22%.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_24",
            "start": 312,
            "end": 395,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_24@3",
            "content": "We show a pairwise analysis of how GQs affect performance when they appear in both the premises and hypotheses in the Appendix B. Generally, our results attest to the difficulty of resolving GQs in NLI benchmarks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_24",
            "start": 397,
            "end": 609,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_25@0",
            "content": "Quantifiers in Cross-lingual NLU Benchmarks",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_25",
            "start": 0,
            "end": 42,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_26@0",
            "content": "Quantifiers are acquired in similar orders across languages (Katsos et al., 2016), although languages express quantifiers in different ways.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_26",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_26@1",
            "content": "For example, there are eight different universal quantifiers with different level of distributivity in Malagasy (Matthewson, 2008).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_26",
            "start": 141,
            "end": 271,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_26@2",
            "content": "This poses challenges to training multilingual LMs and transfer learning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_26",
            "start": 273,
            "end": 345,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_26@3",
            "content": "We are interested in whether quantifiers are universally and evenly challenging for all languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_26",
            "start": 347,
            "end": 444,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_27@0",
            "content": "Quantifiers in Cross-lingual NLI We choose XNLI (Conneau et al., 2018), a manual translation of the development and test set of MNLI into 15 languages, for this multilingual error analysis.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_27",
            "start": 0,
            "end": 188,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_27@1",
            "content": "We should clarify that for XNLI, the authors annotate entailment labels for the English data only and apply them to the other languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_27",
            "start": 190,
            "end": 325,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_27@2",
            "content": "We do not assume label changes due to translation in this study, but it is worth investigate in the future.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_27",
            "start": 327,
            "end": 433,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_27@3",
            "content": "We choose five languages belonging to different language families, namely Arabic, Chinese, German, Spanish and Vietnamese as targets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_27",
            "start": 435,
            "end": 567,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_27@4",
            "content": "The last column in Table 3 shows the numbers of quantifiers in XNLI.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_27",
            "start": 569,
            "end": 636,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_27@5",
            "content": "The distribution rate is 10%.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_27",
            "start": 638,
            "end": 666,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_27@6",
            "content": "Note that the universal quantifier is the most common quantifier in XNLI.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_27",
            "start": 668,
            "end": 740,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_27@7",
            "content": "We fine-tune mBERT 5 (Devlin et al., 2019) and XLM 6 (Lample and Conneau, 2019) on the MNLI training set and evaluate them on XNLI.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_27",
            "start": 742,
            "end": 872,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_27@8",
            "content": "We report the results in Table 5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_27",
            "start": 874,
            "end": 906,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_27@9",
            "content": "We find that performance varies across languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_27",
            "start": 908,
            "end": 956,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_27@10",
            "content": "For Chinese and Vietnamese, we see significant drops in performance for examples with GQs, whereas for Arabic and German, we see improvements.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_27",
            "start": 958,
            "end": 1099,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_27@11",
            "content": "The results per quantifier are more homogeneous, however.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_27",
            "start": 1101,
            "end": 1157,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_28@0",
            "content": "Similar to our results for English, we can see that the lowest accuracies in XNLI are with proportional quantifiers, such as most and few. But the gap in non-English languages is wider for these two categories, especially for Chinese, the difference reaches 30%.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_28",
            "start": 0,
            "end": 261,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_28@1",
            "content": "Other hard quantifiers include all, > k, < k, and each other.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_28",
            "start": 263,
            "end": 323,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_29@0",
            "content": "Quantifiers in Cross-lingual QA Cross-lingual question answering (XQA) is another important NLU task that evaluates the cross-lingual transferability of LMs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_29",
            "start": 0,
            "end": 156,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_29@1",
            "content": "We evaluate the effect of quantifiers on system errors across two XQA datasets, namely XQuAD (Artetxe et al., 2020) and MLQA (Lewis et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_29",
            "start": 158,
            "end": 303,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_29@2",
            "content": "As demonstrated in Figure 1, quantifier word distributions in XQA tasks also follow Zipf's law, as in NLI tasks, but k is more frequent (perhaps because of a traditional emphasis on numerical reasoning), and we see less variance across languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_29",
            "start": 305,
            "end": 550,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_29@3",
            "content": "This is probably because question answering is targeting quantification less directly.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_29",
            "start": 552,
            "end": 637,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_29@4",
            "content": "To evaluate cross-lingual QA performance on GQs, we fine-tune mBERT and XLM-R 7 (Conneau et al., 2020) using Hu et al. (2020)'s architecture.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_29",
            "start": 639,
            "end": 779,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_29@5",
            "content": "We present results for mBERT in Table 7; for XLM-R results, please refer to Appendix D.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_29",
            "start": 781,
            "end": 867,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_30@0",
            "content": "Just as with XNLI, LMs suffer from performance drops across all languages for almost all GQ phenomena with significant, cross-lingual variation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_30",
            "start": 0,
            "end": 143,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_30@1",
            "content": "The most distinguished is that Exact Match (EM) suffers from a greater deterioration than F1 scores for all languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_30",
            "start": 145,
            "end": 262,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_30@2",
            "content": "For example, the weighted EM difference for mBERT on MLQA is 2.9% while the weighted F1 is 1%.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_30",
            "start": 264,
            "end": 357,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_30@3",
            "content": "As one example in Table 1, we observe that the plausible answers selected by models, while being incorrect, result in a sharper decrease of EMs comparing to F1s.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_30",
            "start": 359,
            "end": 519,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_30@4",
            "content": "Questions containing GQs also tend to have less verbal answers comparing to those without GQs, and therefore require higher precision.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_30",
            "start": 521,
            "end": 654,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_31@0",
            "content": "Regarding cross-lingual comparisons, Chinese and Arabic are the two languages that do not have lower performance over GQs compared to the performance over the complete dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_31",
            "start": 0,
            "end": 175,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_31@1",
            "content": "Despite the overall trends, subtle differences from XNLI performance still exist.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_31",
            "start": 177,
            "end": 257,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_31@2",
            "content": "For example, XLM-R is worse than mBERT on quantifier reasoning on XQuAD Chinese, especially at proportional quantifiers, but this is not the case on MLQA Chinese.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_31",
            "start": 259,
            "end": 420,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_32@0",
            "content": "GQNLI",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_32",
            "start": 0,
            "end": 4,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_33@0",
            "content": "We have seen how quantifiers present challenges to NLI and QA models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_33",
            "start": 0,
            "end": 68,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_33@1",
            "content": "Using an approach similar to ANLI (Nie et al., 2020) and DynaBench (Kiela et al., 2021), we use model difficulty (RoBERTa's) as a heuristic to select hard examples for a challenge dataset that can hopefully be used to evaluate any future progress on this.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_33",
            "start": 70,
            "end": 324,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_33@2",
            "content": "We propose GQNLI, a generalized quantifier NLI challenge dataset, consisting of 30 premises and 300 hypotheses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_33",
            "start": 326,
            "end": 436,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_33@3",
            "content": "The average sentence lengths of hypothesis and premises are 15.97 and 7.35, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_33",
            "start": 438,
            "end": 526,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_33@4",
            "content": "Both numbers are comparable to those of MNLI, but lower than ANLI's .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_33",
            "start": 528,
            "end": 596,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_33@5",
            "content": "It should be noted that GQNLI is designed for evaluating future models; obviously not for benchmarking RoBERTa.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_33",
            "start": 598,
            "end": 708,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_34@0",
            "content": "Dataset Creation Firstly, we manually create 100 premise-hypothesis pairs, in which various types of GQs appear.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_34",
            "start": 0,
            "end": 111,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_34@1",
            "content": "For each premise and hypothesis, the number of GQs varies from one to three.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_34",
            "start": 113,
            "end": 188,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_34@2",
            "content": "To choose the premises, we randomly sampled 100 premises with GQs from SNLI and ANLI test sets, respectively, and selected 10 premises in total, that we consider are semantically adequate for adding GQs and making simple hypotheses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_34",
            "start": 190,
            "end": 421,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_35@0",
            "content": "To construct the hypotheses, we rely on RoBERTa fine-tuned on MNLI and manually select examples about which the model is unsure or incorrect.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_35",
            "start": 0,
            "end": 140,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_35@1",
            "content": "To focus on GQs, we keep the challenge examples otherwise simple (Ribeiro et al., 2020), and avoid lexical variations in the hypotheses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_35",
            "start": 142,
            "end": 277,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_35@2",
            "content": "Hard examples were found to be characterized by (i) mixing generalized quantifiers with other logical operators, such as subsumption or negation, and (ii) combining multiple different generalized quantifiers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_35",
            "start": 279,
            "end": 486,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_35@3",
            "content": "We discuss these observations in Section 7.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_35",
            "start": 488,
            "end": 530,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_36@0",
            "content": "Two of the authors annotated the examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_36",
            "start": 0,
            "end": 41,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_36@1",
            "content": "The inter-annotator agreement (Fleiss' kappa) was 0.895, substantially higher than ANLI's (0.672-0.740).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_36",
            "start": 43,
            "end": 146,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_36@2",
            "content": "It is worth noting that the level of semantic or pragmatic interpretation difference of GQs is reflected in the measurement.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_36",
            "start": 148,
            "end": 271,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_37@0",
            "content": "We augmented the examples by substituting non-quantifier words (e.g., replacing \"dogs\" with \"cats\") while keeping the labels, to exclude the effect of specific lexical items.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_37",
            "start": 0,
            "end": 173,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_37@1",
            "content": "The resulting labels are uniformly distributed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_37",
            "start": 175,
            "end": 221,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_37@2",
            "content": "Table 8 presents GQNLI statistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_37",
            "start": 223,
            "end": 256,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_37@3",
            "content": "Since the dataset is curated to probe the ability to reason with quantifiers, the distribution of generalized quantifiers does not follow Zipf's law; see \u00a74.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_37",
            "start": 258,
            "end": 414,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_37@4",
            "content": "A list of GQNLI examples per category is shown in Appendix E.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_37",
            "start": 416,
            "end": 476,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_38@0",
            "content": "We evaluate seven types of models on GQNLI, fine-tuned with different combinations of NLI datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_38",
            "start": 0,
            "end": 98,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_38@1",
            "content": "As data creation only relied on RoBERTa and MNLI, nothing prevents that models with different architectures and training data will perform well.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_38",
            "start": 100,
            "end": 243,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_38@2",
            "content": "They do not, however.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_38",
            "start": 245,
            "end": 265,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_38@3",
            "content": "The results are shown in Table 8.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_38",
            "start": 267,
            "end": 299,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_39@0",
            "content": "We see that all models have great difficulty with GQNLI.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_39",
            "start": 0,
            "end": 55,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_39@1",
            "content": "With more training data, models improve, but the best performance is 48%, less than 15 points above chance level.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_39",
            "start": 57,
            "end": 169,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_39@2",
            "content": "In general, the counting quantifiers, especially the existential and universal quantifiers, are easier than proportional quantifiers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_39",
            "start": 171,
            "end": 303,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_39@3",
            "content": "Particularly, most models struggle with less than k and between.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_39",
            "start": 305,
            "end": 368,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_39@4",
            "content": "This is in some contrast with the NLU tasks studied above, where these quantifiers were among the easiest.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_39",
            "start": 370,
            "end": 475,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_40@0",
            "content": "We also observe unstable GQ reasoning ability in simple word substitution cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_40",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_40@1",
            "content": "For instance, it happens for DeBERTa fine-tuned with M, F, Ling, DocNLI that it predicted correctly the contradiction relation between \"There are six children standing on top of a yellow mountain. Two thirds wear red tops and one third wear green.\" and \"Between 80% and 90% children do not wear red tops.\", but incorrectly when \"red\" is substituted with \"beige\" and \"green\" with \"cyan\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_40",
            "start": 81,
            "end": 466,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_40@2",
            "content": "We are yet to study what kind of cues lead to the instability.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_40",
            "start": 468,
            "end": 529,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_40@3",
            "content": "Our experiments suggest a lack of testing proportionality reasoning and robustness in existing benchmarks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_40",
            "start": 531,
            "end": 636,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_41@0",
            "content": "Discussion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_41",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_42@0",
            "content": "Negation The interaction between negation words and quantifiers increases semantic complexity (Partee, 1970;Horn, 2010).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_42",
            "start": 0,
            "end": 119,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_42@1",
            "content": "We investigate whether this holds for NLI tasks, using negation cue detection to find all cases where a negation word and a quantifier appear in the hypotheses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_42",
            "start": 121,
            "end": 280,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_43@0",
            "content": "We break down the performances on negation of the seven models in Appendix F. As indicated, LMs overall have polarized results for negation cases comparing to the entire dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_43",
            "start": 0,
            "end": 177,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_43@1",
            "content": "We can see a majority of the models even predicted opposite labels for some GQ categories, with 0% accuracy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_43",
            "start": 179,
            "end": 286,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_43@2",
            "content": "BART is no longer the second best model, replaced by RoBERTa.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_43",
            "start": 288,
            "end": 348,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_43@3",
            "content": "The improvement by training with more data is overall consistent for reasoning over GQs with negation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_43",
            "start": 350,
            "end": 451,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_44@0",
            "content": "For a cross-lingual investigation of the interaction of GQs and negation, we find that in XNLI, the number of cases combining both phenomena is insufficient: we identified four such cases, involving only the quantifiers \"all\" and \"more than.\" For English, mBERT predicted two cases successfully.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_44",
            "start": 0,
            "end": 294,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_44@1",
            "content": "For Chinese, German, Vietnamese and Arabic, one is correct.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_44",
            "start": 296,
            "end": 354,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_44@2",
            "content": "For Spanish, all are wrongly predicted.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_44",
            "start": 356,
            "end": 394,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_45@0",
            "content": "It is evident that NLU models suffer from reasoning difficulties in certain cases when negation interacts with GQs, especially in cross-lingual evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_45",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_45@1",
            "content": "In future work, we are interested in expanding GQNLI to more instances and more languages to facilitate qualitative investigations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_45",
            "start": 156,
            "end": 286,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_46@0",
            "content": "Subsumption In generalized term subsumption languages (TSLs; Yen, 1991;Ali and Shapiro, 1993), a term a subsumes another term b if and only if the extension of a is a superset of the extension of b .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_46",
            "start": 0,
            "end": 198,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_46@1",
            "content": "Rather than surface number comparison, subsumption reasoning requires knowledge of the relations between supersets and subsets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_46",
            "start": 200,
            "end": 326,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_46@2",
            "content": "For example, to decide whether \"There are six dogs. Three brown dogs, a black dog and a white dog run along the green grass\" entails \"One dog sits\", LMs should be aware that \"six dogs\" is a superset of the extension of the \"brown dogs\", \"black dog\" and \"white dog\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_46",
            "start": 328,
            "end": 592,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_46@3",
            "content": "Another example in GQNLI is to infer whether \"There are twelve singers on a stage, less than half from Argentina and one from Cape Verde\" entails \"Several singers do not come from Chile\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_46",
            "start": 594,
            "end": 780,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_47@0",
            "content": "We annotate 63 cases out of the first 100 in GQNLI requiring subsumption reasoning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_47",
            "start": 0,
            "end": 82,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_47@1",
            "content": "We show the statistics and results regarding subsumption in Appendix G. It can be seen that more training data leads to higher accuracies.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_47",
            "start": 84,
            "end": 221,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_47@2",
            "content": "Especially, DeBERTa fine-tuned with DocNLI, which unifies the two classes \"neutral\" and \"contradict\" into a new class \"not entail\", has a significant improvement on subsumption cases with neutral label.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_47",
            "start": 223,
            "end": 424,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_47@3",
            "content": "The training bias give an advantage to the model on the subsumption subset, half cases of which are labelled neutral. But such bias has a negative effect on non-subsumption cases; the accuracy drops by 20.2% comparing to the model without training with DocNLI.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_47",
            "start": 426,
            "end": 685,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_47@4",
            "content": "It is worth investigating whether DocNLI is truly helping subsumption reasoning in future work.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_47",
            "start": 687,
            "end": 781,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_47@5",
            "content": "Subsumption is a key concept in the study of knowledge representation (Woods, 1991), but is neglected in current NLP research.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_47",
            "start": 783,
            "end": 908,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_47@6",
            "content": "The fact that LMs struggle to perform subsumption reasoning asserts the necessity to explicit tackle the problem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_47",
            "start": 910,
            "end": 1022,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_48@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_48",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_49@0",
            "content": "We examine the sensitivity of NLU models to generalized quantifiers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_49",
            "start": 0,
            "end": 67,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_49@1",
            "content": "These models are designed to induce correlations from large volumes of data, not to reason symbolically with logical quantifiers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_49",
            "start": 69,
            "end": 197,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_49@2",
            "content": "Such models have, nevertheless, been probed for logical knowledge.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_49",
            "start": 199,
            "end": 264,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_49@3",
            "content": "Mul and Zuidema (2019), for example, show neural networks encode fragments of first-order logic and exhibit zero-shot generalization ability.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_49",
            "start": 266,
            "end": 406,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_49@4",
            "content": "Evans et al. (2018) present a neural architecture that improves performance on propositional logical inference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_49",
            "start": 408,
            "end": 518,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_49@5",
            "content": "Bowman et al. (2015b) also suggest neural networks learn semantic representations for logical inference in natural languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_49",
            "start": 520,
            "end": 644,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_49@6",
            "content": "However, on the same task, Veldhoen and Zuidema (2017) find neural networks fail to do so on a more stringent test.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_49",
            "start": 646,
            "end": 760,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_49@7",
            "content": "Geiger et al. ( 2019) also show that neural networks fail to exhibit robust logical inference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_49",
            "start": 762,
            "end": 855,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_49@8",
            "content": "Srivastava et al. (2018) use semantic parsers to encode quantifiers and improve zero-shot learning in classification tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_49",
            "start": 857,
            "end": 979,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_49@9",
            "content": "Haruta et al. (2020) present a system that computes logical inference over GQs and see improvements on two specialized datasets, FraCaS (Cooper et al., 1994) and MED (Yanaka et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_49",
            "start": 981,
            "end": 1168,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_49@10",
            "content": "None of these papers explicitly discussed generalized quantifiers, and all were limited to studying the ability of neural networks to capture the logical semantics of English.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_49",
            "start": 1170,
            "end": 1344,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_50@0",
            "content": "Many studies have instead focused on LMs' ability to capture negation (Gururangan et al., 2018;Naik et al., 2018;Hossain et al., 2020;Ettinger, 2020;Hartmann et al., 2021) or coreference (Ye et al., 2020;Varkel and Globerson, 2020;Abdou et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_50",
            "start": 0,
            "end": 250,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_50@1",
            "content": "Others have focused on LMs' ability to reason with numbers .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_50",
            "start": 252,
            "end": 311,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_50@2",
            "content": "DROP (Dua et al., 2019), for example, is a question answering dataset designed specifically to probe LMs' ability to count, add and subtract for answering factoid questions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_50",
            "start": 313,
            "end": 485,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_50@3",
            "content": "Models have also been tailored for numerical reasoning (Geva et al., 2020;. Cobbe et al. (2021) proposes to use a verification task during pretraining of LMs to improve their ability to solve math word problems.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_50",
            "start": 487,
            "end": 697,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_50@4",
            "content": "Others have studied monotonicity inference (Hu et al., 2019;Yanaka et al., 2019Yanaka et al., , 2020, and Fang and Lou (2021) recently focused on the two quantifier words part and whole in an error analysis for named entity recognition.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_50",
            "start": 699,
            "end": 934,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_51@0",
            "content": "Many NLU benchmarks contain quantifier words, but their influence on performance has not been studied systematically.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_51",
            "start": 0,
            "end": 116,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_51@1",
            "content": "One exception to this is that generalized quantifiers have been used to generate adversarial examples in the context of numerical reasoning (Naik et al., 2018;Nie et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_51",
            "start": 118,
            "end": 294,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_51@2",
            "content": "TaxiNLI (Joshi et al., 2020), which categorizes 15 types of reasoning abilities, is a dataset drawn from MNLI.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_51",
            "start": 296,
            "end": 405,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_51@3",
            "content": "In their taxonomy, the Quantifier category only refers to universal and existential quantifiers, not to generalized quantifiers, and ditto for Kim et al. (2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_51",
            "start": 407,
            "end": 567,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_51@4",
            "content": "All of the above focused on English, but in an extension to TaxiNLI, K et al. ( 2021) incorporated quantifiers into the Logic class and found a large cross-lingual transfer gap on LMs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_51",
            "start": 569,
            "end": 752,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_52@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_52",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_53@0",
            "content": "Quantifiers lie in the intersection of logic, linguistics and NLP research.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_53",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_53@1",
            "content": "It is essential for NLU systems to learn quantifier reasoning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_53",
            "start": 76,
            "end": 137,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_53@2",
            "content": "We examined generalized quantifiers in multilingual NLU tasks with regards to their expressiveness and logical reasoning requirement.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_53",
            "start": 139,
            "end": 271,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_53@3",
            "content": "Our survey and experiments indicate quantifiers are neglected to a degree and cause significant performance drops for neural LMs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_53",
            "start": 273,
            "end": 401,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_53@4",
            "content": "To better understand LMs' reasoning abilities, we release GQNLI, a novel generalized quantifier NLI challenge dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_53",
            "start": 403,
            "end": 520,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_53@5",
            "content": "With the pervasiveness of generalized quantifiers, we stress that more efforts are necessary to investigate: (1) when and why models systematically fail when quantifiers interact with other operators; (2) how to improve cross-lingual transferability of quantifiers; (3) how we can exploit the theoretical results about generalized quantifiers from logic and linguistic studies, so as to improve the logical inference ability of neural LMs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_53",
            "start": 522,
            "end": 960,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_54@0",
            "content": "A Regular Expressions for Generalized Quantifiers",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_54",
            "start": 0,
            "end": 48,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_55@0",
            "content": "Table 9 lists the regex we use to parse generalized quntifiers in sentences augmented with universal dependency tags.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_55",
            "start": 0,
            "end": 116,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_55@1",
            "content": "The approach does not find all the generalized quantifiers exhuastively but rather approximates the common distributions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_55",
            "start": 118,
            "end": 238,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_56@0",
            "content": "While the analysis in Section 4 is based on quantifiers in hypotheses, next we consider the interaction of quantifiers in hypotheses and quantifiers in premises.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_56",
            "start": 0,
            "end": 160,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_56@1",
            "content": "To this end, we calculate the difference between overall performance and performance for premise-hypothesis pairs of GQs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_56",
            "start": 162,
            "end": 282,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_56@2",
            "content": "In Figure 2, we visualize the results as heatmaps (see Table 10 for exact numbers of occurences and accuracies).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_56",
            "start": 284,
            "end": 395,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_56@3",
            "content": "Surprisingly, whenever quantifiers appear in both the premise and the hypothesis, LMs largely fail to predict the entailment.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_56",
            "start": 397,
            "end": 521,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_56@4",
            "content": "Percentage quantifiers, supposed to be semantically more complex than counting quantifiers, are not de facto harder in NLI.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_56",
            "start": 523,
            "end": 645,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_56@5",
            "content": "We studied all 27 cases of percentage quantifiers in the English NLI datasets, and found that in most cases, percentage quantifiers occurrences are identical across premises and hypotheses, i.e., triggering little or no inference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_56",
            "start": 647,
            "end": 876,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_56@6",
            "content": "The other two proportional quantifiers, most and few, are hard for Figure 2: Fine-grained analysis of RoBERTa performance on 6 English NLI subtasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_56",
            "start": 878,
            "end": 1025,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_56@7",
            "content": "Each heatmap represents hypotheses with a type of quantifier.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_56",
            "start": 1027,
            "end": 1087,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_56@8",
            "content": "The rows stand for premises with the quantifier of that label.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_56",
            "start": 1089,
            "end": 1150,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_56@9",
            "content": "The numbers are calculated as the accuracy over the whole dataset minus the fine-grained accuracy given a specific premise and hypothesis (the higher the number, the worse the performance).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_56",
            "start": 1152,
            "end": 1340,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_56@10",
            "content": "For each heatmap, the last column represents the accuracy gap weighted by all 6 tasks. \"UN\" stands for an entry where no explicit quantifier is identified.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_56",
            "start": 1342,
            "end": 1496,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_57@0",
            "content": "LMs to resolve, e.g., in some quantifier pairs, models yield 0% accuracy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_57",
            "start": 0,
            "end": 72,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_57@1",
            "content": "Although each other is supposed to be hardest to resolve due to the complex semantics of reciprocals (Szymanik and Thorne, 2015), it is not reflected in NLI tasks as such.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_57",
            "start": 74,
            "end": 244,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_57@2",
            "content": "The reason is similar to percentage quantifiers, while annotators intend to alter counting quantifiers when writing hypotheses, reciprocality is seldomly considered a linguistic ability that needs testing for NLU systems. And the annotation for Ramsey quantifier is simply a knockoff, making reciprocal relation identification unwarranted through shallow correlations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_57",
            "start": 246,
            "end": 613,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_58@0",
            "content": "C Fine-grained NLI Analysis D XQA Result: mBERT and XLM-R",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_58",
            "start": 0,
            "end": 56,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_59@0",
            "content": "We present the results of seven models' performance on cases with negation cues in GQNLI in Table 13.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_59",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_60@0",
            "content": "See Table 14 for models 'performance on cases requiring subsumption reasoning in GQNLI.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_60",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_60@1",
            "content": "We also break down subsumption results by entailment labels into two categories: neutral and non-neutral.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_60",
            "start": 88,
            "end": 192,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_61@0",
            "content": "Mostafa Abdou, Vinit Ravishankar, Maria Barrett, Yonatan Belinkov, Desmond Elliott, Anders S\u00f8gaard, The sensitivity of language models and humans to Winograd schema perturbations, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_61",
            "start": 0,
            "end": 275,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_62@0",
            "content": "UNKNOWN, None, 1993, Natural language processing using a propositional semantic network with structured variables. Minds and machines, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_62",
            "start": 0,
            "end": 135,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_63@0",
            "content": "Mikel Artetxe, Sebastian Ruder, Dani Yogatama, On the cross-lingual transferability of monolingual representations, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_63",
            "start": 0,
            "end": 211,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_64@0",
            "content": "Akari Asai, Hannaneh Hajishirzi, Logicguided data augmentation and regularization for consistent question answering, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_64",
            "start": 0,
            "end": 212,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_65@0",
            "content": "UNKNOWN, None, 1995, , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_65",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_66@0",
            "content": "Jon Barwise, Robin Cooper, Generalized quantifiers and natural language, 1981, Philosophy, language, and artificial intelligence, Springer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_66",
            "start": 0,
            "end": 138,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_67@0",
            "content": "R Samuel, Gabor Bowman, Christopher Angeli, Christopher Potts,  Manning, A large annotated corpus for learning natural language inference, 2015, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_67",
            "start": 0,
            "end": 233,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_68@0",
            "content": "R Samuel, Christopher Bowman, Christopher Potts,  Manning, Recursive neural networks can learn logical semantics, 2015, Proceedings of the 3rd Workshop on Continuous Vector Space Models and their Compositionality, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_68",
            "start": 0,
            "end": 255,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_69@0",
            "content": "Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, John Schulman, Training verifiers to solve math word problems, 2021, ArXiv, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_69",
            "start": 0,
            "end": 175,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_70@0",
            "content": "Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettlemoyer, Veselin Stoyanov, Unsupervised cross-lingual representation learning at scale, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_70",
            "start": 0,
            "end": 322,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_71@0",
            "content": "Alexis Conneau, Ruty Rinott, Guillaume Lample, Adina Williams, Samuel Bowman, Holger Schwenk, Veselin Stoyanov, XNLI: Evaluating cross-lingual sentence representations, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_71",
            "start": 0,
            "end": 304,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_72@0",
            "content": "UNKNOWN, None, 1994, Fracas: A framework for computational semantics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_72",
            "start": 0,
            "end": 70,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_73@0",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long and Short Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_73",
            "start": 0,
            "end": 315,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_74@0",
            "content": "Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, Matt Gardner, DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_74",
            "start": 0,
            "end": 366,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_75@0",
            "content": "Anton\u00edn Dvo\u0159\u00e1k, Michal Hol\u010dapek, Type 1 , 1 fuzzy quantifiers determined by fuzzy measures on residuated lattices. part iii. extension, conservativity and extensionality, 2015, Fuzzy Sets Syst, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_75",
            "start": 0,
            "end": 194,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_76@0",
            "content": "Allyson Ettinger, What BERT is not: Lessons from a new suite of psycholinguistic diagnostics for language models, 2020, Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_76",
            "start": 0,
            "end": 183,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_77@0",
            "content": "UNKNOWN, None, 2018, Can neural networks understand logical entailment? arXiv preprint, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_77",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_78@0",
            "content": "Izumi Haruta, Koji Mineshima, Daisuke Bekki, Logical inferences with comparatives and generalized quantifiers, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_78",
            "start": 0,
            "end": 233,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_79@0",
            "content": "UNKNOWN, None, 1981-05, Questions, quantifiers and crossing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_79",
            "start": 0,
            "end": 61,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_80@0",
            "content": "UNKNOWN, None, 2010, The expression of negation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_80",
            "start": 0,
            "end": 49,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_81@0",
            "content": "Venelin Md Mosharaf Hossain, Pranoy Kovatchev, Tiffany Dutta, Elizabeth Kao, Eduardo Wei,  Blanco, An analysis of natural language inference benchmarks through the lens of negation, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_81",
            "start": 0,
            "end": 284,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_82@0",
            "content": "Hai Hu, Qi Chen, Larry Moss, Natural language inference with monotonicity, 2019, Proceedings of the 13th International Conference on Computational Semantics -Short Papers, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_82",
            "start": 0,
            "end": 172,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_83@0",
            "content": "Junjie Hu, Sebastian Ruder, Aditya Siddhant, Graham Neubig, Orhan Firat, Melvin Johnson, Xtreme: A massively multilingual multitask benchmark for evaluating cross-lingual generalisation, 2020, International Conference on Machine Learning, PMLR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_83",
            "start": 0,
            "end": 243,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_84@0",
            "content": "Devin Johnson, Denise Mak, Andrew Barker, Lexi Loessberg-Zahl, Probing for multilingual numerical understanding in transformer-based language models, 2020, Proceedings of the Third Black-boxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_84",
            "start": 0,
            "end": 307,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_85@0",
            "content": "Pratik Joshi, Somak Aditya, Aalok Sathe, Monojit Choudhury, TaxiNLI: Taking a ride up the NLU hill, 2020, Proceedings of the 24th Conference on Computational Natural Language Learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_85",
            "start": 0,
            "end": 185,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_86@0",
            "content": "K Karthikeyan, Aalok Sathe, Somak Aditya, Monojit Choudhury, Analyzing the effects of reasoning types on cross-lingual transfer performance, 2021, Proceedings of the 1st Workshop on Multilingual Representation Learning, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_86",
            "start": 0,
            "end": 261,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_87@0",
            "content": "Napoleon Katsos, Chris Cummins, Maria-Jos\u00e9 Ezeizabarrena, Anna Gavarr\u00f3, Jelena Kuva\u010d Kraljevi\u0107, Gordana Hrzica, Athina Kleanthes K Grohmann, Kristine Jensen De Skordi, Lone L\u00f3pez,  Sundahl, Cross-linguistic patterns in the acquisition of quantifiers, 2016, Proceedings of the National Academy of Sciences, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_87",
            "start": 0,
            "end": 306,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_88@0",
            "content": "UNKNOWN, None, , , Angeliek Van Hout.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_88",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_89@0",
            "content": "UNKNOWN, None, 2012, Handbook of quantifiers in natural language, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_89",
            "start": 0,
            "end": 66,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_90@0",
            "content": "L Edward, Dag Keenan,  Westerst\u00e5hl, Generalized quantifiers in linguistics and logic, 1997, Handbook of Logic and Language, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_90",
            "start": 0,
            "end": 124,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_91@0",
            "content": "Douwe Kiela, Max Bartolo, Yixin Nie, Divyansh Kaushik, Atticus Geiger, Zhengxuan Wu, Bertie Vidgen, Grusha Prasad, Amanpreet Singh, Pratik Ringshia, Zhiyi Ma, Tristan Thrush, Sebastian Riedel, Zeerak Waseem, Pontus Stenetorp, Robin Jia, Mohit Bansal, Christopher Potts, Adina Williams, Dynabench: Rethinking benchmarking in NLP, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_91",
            "start": 0,
            "end": 520,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_92@0",
            "content": "Najoung Kim, Roma Patel, Adam Poliak, Patrick Xia, Alex Wang, Tom Mccoy, Ian Tenney, Alexis Ross, Tal Linzen, Benjamin Van Durme, Samuel Bowman, Ellie Pavlick, Probing what different NLP tasks teach machines about function word comprehension, 2019, Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*SEM 2019), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_92",
            "start": 0,
            "end": 344,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_93@0",
            "content": "UNKNOWN, None, 2019, Crosslingual language model pretraining, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_93",
            "start": 0,
            "end": 62,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_94@0",
            "content": "UNKNOWN, None, 2000, Presumptive meanings: The theory of generalized conversational implicature, MIT press.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_94",
            "start": 0,
            "end": 106,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_95@0",
            "content": "Patrick Lewis, Barlas Oguz, Ruty Rinott, Sebastian Riedel, Holger Schwenk, MLQA: Evaluating cross-lingual extractive question answering, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_95",
            "start": 0,
            "end": 232,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_96@0",
            "content": "Tao Li, Vivek Gupta, Maitrey Mehta, Vivek , A logic-driven framework for consistency of neural models, 2019-03, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_96",
            "start": 0,
            "end": 330,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_97@0",
            "content": "Per Lindstr\u00f6m, First order predicate logic with generalized quantifiers, 1966, Theoria, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_97",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_98@0",
            "content": "UNKNOWN, None, 1907, Roberta: A robustly optimized bert pretraining approach. ArXiv, abs, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_98",
            "start": 0,
            "end": 90,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_99@0",
            "content": "Lisa Matthewson, Quantification and the nature of crosslinguistic variation, 2001, Natural Language Semantics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_99",
            "start": 0,
            "end": 111,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_100@0",
            "content": "Lisa Matthewson, On the methodology of semantic fieldwork, 2004, International journal of American linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_100",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_101@0",
            "content": "UNKNOWN, None, 2008, Quantification: A crosslinguistic perspective, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_101",
            "start": 0,
            "end": 68,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_102@0",
            "content": "Richard Montague, The proper treatment of quantification in ordinary english, 1973, Approaches to natural language, Springer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_102",
            "start": 0,
            "end": 124,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_103@0",
            "content": "Andrzej Mostowski, On a generalization of quantifiers, 1957, Fundamenta Mathematicae, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_103",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_104@0",
            "content": "UNKNOWN, None, 2019, Siamese recurrent networks learn first-order logic reasoning and exhibit zero-shot compositional generalization, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_104",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_105@0",
            "content": "Aakanksha Naik, Abhilasha Ravichander, Norman Sadeh, Carolyn Rose, Graham Neubig, Stress test evaluation for natural language inference, 2018, Proceedings of the 27th International Conference on Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_105",
            "start": 0,
            "end": 222,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_106@0",
            "content": "Yixin Nie, Haonan Chen, Mohit Bansal, Combining fact extraction and verification with neural semantic matching networks, 2019, Association for the Advancement of Artificial Intelligence (AAAI), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_106",
            "start": 0,
            "end": 194,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_107@0",
            "content": "Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, Douwe Kiela, Adversarial NLI: A new benchmark for natural language understanding, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_107",
            "start": 0,
            "end": 294,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_108@0",
            "content": "UNKNOWN, None, 2012, Quantifiers in Adyghe, Springer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_108",
            "start": 0,
            "end": 52,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_109@0",
            "content": "Joakim Nivre, Marie-Catherine De Marneffe, Filip Ginter, Jan Haji\u010d, Christopher Manning, Sampo Pyysalo, Sebastian Schuster, Francis Tyers, Daniel Zeman, Universal Dependencies v2: An evergrowing multilingual treebank collection, 2020, Proceedings of the 12th Language Resources and Evaluation Conference, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_109",
            "start": 0,
            "end": 305,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_110@0",
            "content": "UNKNOWN, None, , 2020. Proceedings of the Third Workshop on Computational Models of Reference, Anaphora and Coreference, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_110",
            "start": 0,
            "end": 162,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_111@0",
            "content": "UNKNOWN, None, 2019, Proceedings of the Second Workshop on Computational Models of Reference, Anaphora and Coreference, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_111",
            "start": 0,
            "end": 161,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_112@0",
            "content": "Alicia Parrish, William Huang, Omar Agha, Soo-Hwan Lee, Nikita Nangia, Alexia Warstadt, Karmanya Aggarwal, Emily Allaway, Tal Linzen, Samuel Bowman, Does putting a linguist in the loop improve NLU data collection?, 2021, Findings of the Association for Computational Linguistics: EMNLP 2021, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_112",
            "start": 0,
            "end": 333,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_113@0",
            "content": "UNKNOWN, None, 1970, Negation, conjunction, and quantifiers: Syntax vs. semantics. Foundations of Language, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_113",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_114@0",
            "content": "UNKNOWN, None, 2006, Quantifiers in language and logic, Oxford University Press.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_114",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_115@0",
            "content": "Peng Qi, Yuhao Zhang, Yuhui Zhang, Jason Bolton, Christopher Manning, Stanza: A python natural language processing toolkit for many human languages, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_115",
            "start": 0,
            "end": 267,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_116@0",
            "content": "Carlos Marco Tulio Ribeiro, Sameer Guestrin,  Singh, Are red roses red? evaluating consistency of question-answering models, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_116",
            "start": 0,
            "end": 220,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_117@0",
            "content": "Tongshuang Marco Tulio Ribeiro, Carlos Wu, Sameer Guestrin,  Singh, Beyond accuracy: Behavioral testing of NLP models with CheckList, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_117",
            "start": 0,
            "end": 229,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_118@0",
            "content": "H James, Stephen Schmerl,  Simpson, On the role of ramsey quantifiers in first order arithmetic, 1982, J. Symb. Log, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_118",
            "start": 0,
            "end": 117,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_119@0",
            "content": "Shashank Srivastava, Igor Labutov, Tom Mitchell, Zero-shot learning of classifiers from natural language quantification, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_119",
            "start": 0,
            "end": 257,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_120@0",
            "content": "Penka Stateva, Arthur Stepanov, Viviane D\u00e9prez, Ludivine Dupuy, Anne Reboul, Cross-linguistic variation in the meaning of quantifiers: Implications for pragmatic enrichment, 2019, Frontiers in Psychology, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_120",
            "start": 0,
            "end": 205,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_121@0",
            "content": "Shane Steinert-Threlkeld, Learnability and semantic universals, 2019, Semantics and Pragmatics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_121",
            "start": 0,
            "end": 96,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_122@0",
            "content": "Shane Steinert-Threlkeld, Quantifiers in natural language: Efficient communication and degrees of semantic universals, 2021, Entropy, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_122",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_123@0",
            "content": "UNKNOWN, None, 2016, Cognitive Processing of Quantifiers, Springer International Publishing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_123",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_124@0",
            "content": "Jakub Szymanik, Camilo Thorne, Semantic complexity of quantifiers and their distribution in corpora, 2015, Proceedings of the 11th International Conference on Computational Semantics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_124",
            "start": 0,
            "end": 225,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_125@0",
            "content": "Wataru Uegaki, The Informativeness/Complexity Trade-Off in the Domain of Boolean Connectives, 2022, Linguistic Inquiry, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_125",
            "start": 0,
            "end": 120,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_126@0",
            "content": "Yuval Varkel, Amir Globerson, Pre-training mention representations in coreference models, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_126",
            "start": 0,
            "end": 192,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_127@0",
            "content": "UNKNOWN, None, 2017, Can neural networks learn logical reasoning? CLASP Papers in Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_127",
            "start": 0,
            "end": 109,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_128@0",
            "content": "Dag Westerst\u00e5hl, Quantifiers in formal and natural languages, 1989, Handbook of philosophical logic, Springer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_128",
            "start": 0,
            "end": 109,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_129@0",
            "content": "Adina Williams, Nikita Nangia, Samuel Bowman, A broad-coverage challenge corpus for sentence understanding through inference, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_129",
            "start": 0,
            "end": 287,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_130@0",
            "content": "UNKNOWN, None, 2020, Anlizing the adversarial natural language inference dataset, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_130",
            "start": 0,
            "end": 82,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_131@0",
            "content": "William Woods, Understanding subsumption and taxonomy: A framework for progress, 1991, Principles of Semantic Networks, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_131",
            "start": 0,
            "end": 120,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_132@0",
            "content": "Hitomi Yanaka, Koji Mineshima, Daisuke Bekki, Kentaro Inui, Do neural models learn systematicity of monotonicity inference in natural language?, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_132",
            "start": 0,
            "end": 240,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_133@0",
            "content": "Hitomi Yanaka, Koji Mineshima, Daisuke Bekki, Kentaro Inui, Satoshi Sekine, Lasha Abzianidze, Johan Bos, Can neural networks understand monotonicity reasoning?, 2019, Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_133",
            "start": 0,
            "end": 269,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_134@0",
            "content": "Deming Ye, Yankai Lin, Jiaju Du, Zhenghao Liu, Peng Li, Maosong Sun, Zhiyuan Liu, Coreferential Reasoning Learning for Language Representation, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_134",
            "start": 0,
            "end": 246,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_135@0",
            "content": "John Yen, Generalizing term subsumption languages to fuzzy logic, 1991, IJCAI, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_135",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_136@0",
            "content": "Wenpeng Yin, Dragomir Radev, Caiming Xiong, DocNLI: A large-scale dataset for documentlevel natural language inference, 2021, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_136",
            "start": 0,
            "end": 202,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_137@0",
            "content": "A Lotfi,  Zadeh, A computational approach to fuzzy quantifiers in natural languages, 1983, Computational linguistics, Elsevier.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_137",
            "start": 0,
            "end": 126,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_138@0",
            "content": "Xikun Zhang, Deepak Ramachandran, Ian Tenney, Yanai Elazar, Dan Roth, Do language embeddings capture scales?, 2020, Findings of the Association for Computational Linguistics: EMNLP 2020, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_138",
            "start": 0,
            "end": 187,
            "label": {}
        },
        {
            "ix": "181-ARR_v2_139@0",
            "content": "UNKNOWN, None, 1949, Human behavior and the principle of least effort, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "181-ARR_v2_139",
            "start": 0,
            "end": 71,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "181-ARR_v2_0",
            "tgt_ix": "181-ARR_v2_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_0",
            "tgt_ix": "181-ARR_v2_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_1",
            "tgt_ix": "181-ARR_v2_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_1",
            "tgt_ix": "181-ARR_v2_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_0",
            "tgt_ix": "181-ARR_v2_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_2",
            "tgt_ix": "181-ARR_v2_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_4",
            "tgt_ix": "181-ARR_v2_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_5",
            "tgt_ix": "181-ARR_v2_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_3",
            "tgt_ix": "181-ARR_v2_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_3",
            "tgt_ix": "181-ARR_v2_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_3",
            "tgt_ix": "181-ARR_v2_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_3",
            "tgt_ix": "181-ARR_v2_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_3",
            "tgt_ix": "181-ARR_v2_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_6",
            "tgt_ix": "181-ARR_v2_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_8",
            "tgt_ix": "181-ARR_v2_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_9",
            "tgt_ix": "181-ARR_v2_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_10",
            "tgt_ix": "181-ARR_v2_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_11",
            "tgt_ix": "181-ARR_v2_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_3",
            "tgt_ix": "181-ARR_v2_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_3",
            "tgt_ix": "181-ARR_v2_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_3",
            "tgt_ix": "181-ARR_v2_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_3",
            "tgt_ix": "181-ARR_v2_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_3",
            "tgt_ix": "181-ARR_v2_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_7",
            "tgt_ix": "181-ARR_v2_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_0",
            "tgt_ix": "181-ARR_v2_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_12",
            "tgt_ix": "181-ARR_v2_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_14",
            "tgt_ix": "181-ARR_v2_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_15",
            "tgt_ix": "181-ARR_v2_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_13",
            "tgt_ix": "181-ARR_v2_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_13",
            "tgt_ix": "181-ARR_v2_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_13",
            "tgt_ix": "181-ARR_v2_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_13",
            "tgt_ix": "181-ARR_v2_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_0",
            "tgt_ix": "181-ARR_v2_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_16",
            "tgt_ix": "181-ARR_v2_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_17",
            "tgt_ix": "181-ARR_v2_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_17",
            "tgt_ix": "181-ARR_v2_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_0",
            "tgt_ix": "181-ARR_v2_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_18",
            "tgt_ix": "181-ARR_v2_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_19",
            "tgt_ix": "181-ARR_v2_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_19",
            "tgt_ix": "181-ARR_v2_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_21",
            "tgt_ix": "181-ARR_v2_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_22",
            "tgt_ix": "181-ARR_v2_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_23",
            "tgt_ix": "181-ARR_v2_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_19",
            "tgt_ix": "181-ARR_v2_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_19",
            "tgt_ix": "181-ARR_v2_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_19",
            "tgt_ix": "181-ARR_v2_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_19",
            "tgt_ix": "181-ARR_v2_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_20",
            "tgt_ix": "181-ARR_v2_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_0",
            "tgt_ix": "181-ARR_v2_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_24",
            "tgt_ix": "181-ARR_v2_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_26",
            "tgt_ix": "181-ARR_v2_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_27",
            "tgt_ix": "181-ARR_v2_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_28",
            "tgt_ix": "181-ARR_v2_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_29",
            "tgt_ix": "181-ARR_v2_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_30",
            "tgt_ix": "181-ARR_v2_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_25",
            "tgt_ix": "181-ARR_v2_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_25",
            "tgt_ix": "181-ARR_v2_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_25",
            "tgt_ix": "181-ARR_v2_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_25",
            "tgt_ix": "181-ARR_v2_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_25",
            "tgt_ix": "181-ARR_v2_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_25",
            "tgt_ix": "181-ARR_v2_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_25",
            "tgt_ix": "181-ARR_v2_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_0",
            "tgt_ix": "181-ARR_v2_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_31",
            "tgt_ix": "181-ARR_v2_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_33",
            "tgt_ix": "181-ARR_v2_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_34",
            "tgt_ix": "181-ARR_v2_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_35",
            "tgt_ix": "181-ARR_v2_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_36",
            "tgt_ix": "181-ARR_v2_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_32",
            "tgt_ix": "181-ARR_v2_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_32",
            "tgt_ix": "181-ARR_v2_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_32",
            "tgt_ix": "181-ARR_v2_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_32",
            "tgt_ix": "181-ARR_v2_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_32",
            "tgt_ix": "181-ARR_v2_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_32",
            "tgt_ix": "181-ARR_v2_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_38",
            "tgt_ix": "181-ARR_v2_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_39",
            "tgt_ix": "181-ARR_v2_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_32",
            "tgt_ix": "181-ARR_v2_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_32",
            "tgt_ix": "181-ARR_v2_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_32",
            "tgt_ix": "181-ARR_v2_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_37",
            "tgt_ix": "181-ARR_v2_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_0",
            "tgt_ix": "181-ARR_v2_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_40",
            "tgt_ix": "181-ARR_v2_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_42",
            "tgt_ix": "181-ARR_v2_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_43",
            "tgt_ix": "181-ARR_v2_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_44",
            "tgt_ix": "181-ARR_v2_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_45",
            "tgt_ix": "181-ARR_v2_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_46",
            "tgt_ix": "181-ARR_v2_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_41",
            "tgt_ix": "181-ARR_v2_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_41",
            "tgt_ix": "181-ARR_v2_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_41",
            "tgt_ix": "181-ARR_v2_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_41",
            "tgt_ix": "181-ARR_v2_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_41",
            "tgt_ix": "181-ARR_v2_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_41",
            "tgt_ix": "181-ARR_v2_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_41",
            "tgt_ix": "181-ARR_v2_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_0",
            "tgt_ix": "181-ARR_v2_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_47",
            "tgt_ix": "181-ARR_v2_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_49",
            "tgt_ix": "181-ARR_v2_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_50",
            "tgt_ix": "181-ARR_v2_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_48",
            "tgt_ix": "181-ARR_v2_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_48",
            "tgt_ix": "181-ARR_v2_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_48",
            "tgt_ix": "181-ARR_v2_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_48",
            "tgt_ix": "181-ARR_v2_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_0",
            "tgt_ix": "181-ARR_v2_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_51",
            "tgt_ix": "181-ARR_v2_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_52",
            "tgt_ix": "181-ARR_v2_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_52",
            "tgt_ix": "181-ARR_v2_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_54",
            "tgt_ix": "181-ARR_v2_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_52",
            "tgt_ix": "181-ARR_v2_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_52",
            "tgt_ix": "181-ARR_v2_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_53",
            "tgt_ix": "181-ARR_v2_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_56",
            "tgt_ix": "181-ARR_v2_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_57",
            "tgt_ix": "181-ARR_v2_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_52",
            "tgt_ix": "181-ARR_v2_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_52",
            "tgt_ix": "181-ARR_v2_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_52",
            "tgt_ix": "181-ARR_v2_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_55",
            "tgt_ix": "181-ARR_v2_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_52",
            "tgt_ix": "181-ARR_v2_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_58",
            "tgt_ix": "181-ARR_v2_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_52",
            "tgt_ix": "181-ARR_v2_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_59",
            "tgt_ix": "181-ARR_v2_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "181-ARR_v2_0",
            "tgt_ix": "181-ARR_v2_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_1",
            "tgt_ix": "181-ARR_v2_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_2",
            "tgt_ix": "181-ARR_v2_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_2",
            "tgt_ix": "181-ARR_v2_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_2",
            "tgt_ix": "181-ARR_v2_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_2",
            "tgt_ix": "181-ARR_v2_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_2",
            "tgt_ix": "181-ARR_v2_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_3",
            "tgt_ix": "181-ARR_v2_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_4",
            "tgt_ix": "181-ARR_v2_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_4",
            "tgt_ix": "181-ARR_v2_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_4",
            "tgt_ix": "181-ARR_v2_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_5",
            "tgt_ix": "181-ARR_v2_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_5",
            "tgt_ix": "181-ARR_v2_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_5",
            "tgt_ix": "181-ARR_v2_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_6",
            "tgt_ix": "181-ARR_v2_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_7",
            "tgt_ix": "181-ARR_v2_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_7",
            "tgt_ix": "181-ARR_v2_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_8",
            "tgt_ix": "181-ARR_v2_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_8",
            "tgt_ix": "181-ARR_v2_8@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_9",
            "tgt_ix": "181-ARR_v2_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_9",
            "tgt_ix": "181-ARR_v2_9@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_9",
            "tgt_ix": "181-ARR_v2_9@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_9",
            "tgt_ix": "181-ARR_v2_9@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_10",
            "tgt_ix": "181-ARR_v2_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_10",
            "tgt_ix": "181-ARR_v2_10@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_10",
            "tgt_ix": "181-ARR_v2_10@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_10",
            "tgt_ix": "181-ARR_v2_10@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_11",
            "tgt_ix": "181-ARR_v2_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_11",
            "tgt_ix": "181-ARR_v2_11@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_11",
            "tgt_ix": "181-ARR_v2_11@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_11",
            "tgt_ix": "181-ARR_v2_11@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_12",
            "tgt_ix": "181-ARR_v2_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_12",
            "tgt_ix": "181-ARR_v2_12@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_12",
            "tgt_ix": "181-ARR_v2_12@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_12",
            "tgt_ix": "181-ARR_v2_12@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_13",
            "tgt_ix": "181-ARR_v2_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_14",
            "tgt_ix": "181-ARR_v2_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_14",
            "tgt_ix": "181-ARR_v2_14@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_14",
            "tgt_ix": "181-ARR_v2_14@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_14",
            "tgt_ix": "181-ARR_v2_14@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_14",
            "tgt_ix": "181-ARR_v2_14@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_15",
            "tgt_ix": "181-ARR_v2_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_15",
            "tgt_ix": "181-ARR_v2_15@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_15",
            "tgt_ix": "181-ARR_v2_15@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_15",
            "tgt_ix": "181-ARR_v2_15@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_15",
            "tgt_ix": "181-ARR_v2_15@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_15",
            "tgt_ix": "181-ARR_v2_15@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_15",
            "tgt_ix": "181-ARR_v2_15@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_16",
            "tgt_ix": "181-ARR_v2_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_16",
            "tgt_ix": "181-ARR_v2_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_16",
            "tgt_ix": "181-ARR_v2_16@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_17",
            "tgt_ix": "181-ARR_v2_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_18",
            "tgt_ix": "181-ARR_v2_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_18",
            "tgt_ix": "181-ARR_v2_18@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_18",
            "tgt_ix": "181-ARR_v2_18@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_18",
            "tgt_ix": "181-ARR_v2_18@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_18",
            "tgt_ix": "181-ARR_v2_18@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_18",
            "tgt_ix": "181-ARR_v2_18@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_18",
            "tgt_ix": "181-ARR_v2_18@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_18",
            "tgt_ix": "181-ARR_v2_18@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_18",
            "tgt_ix": "181-ARR_v2_18@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_19",
            "tgt_ix": "181-ARR_v2_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_20",
            "tgt_ix": "181-ARR_v2_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_20",
            "tgt_ix": "181-ARR_v2_20@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_20",
            "tgt_ix": "181-ARR_v2_20@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_20",
            "tgt_ix": "181-ARR_v2_20@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_20",
            "tgt_ix": "181-ARR_v2_20@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_20",
            "tgt_ix": "181-ARR_v2_20@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_20",
            "tgt_ix": "181-ARR_v2_20@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_21",
            "tgt_ix": "181-ARR_v2_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_21",
            "tgt_ix": "181-ARR_v2_21@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_22",
            "tgt_ix": "181-ARR_v2_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_23",
            "tgt_ix": "181-ARR_v2_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_23",
            "tgt_ix": "181-ARR_v2_23@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_23",
            "tgt_ix": "181-ARR_v2_23@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_24",
            "tgt_ix": "181-ARR_v2_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_24",
            "tgt_ix": "181-ARR_v2_24@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_24",
            "tgt_ix": "181-ARR_v2_24@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_24",
            "tgt_ix": "181-ARR_v2_24@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_25",
            "tgt_ix": "181-ARR_v2_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_26",
            "tgt_ix": "181-ARR_v2_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_26",
            "tgt_ix": "181-ARR_v2_26@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_26",
            "tgt_ix": "181-ARR_v2_26@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_26",
            "tgt_ix": "181-ARR_v2_26@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_27",
            "tgt_ix": "181-ARR_v2_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_27",
            "tgt_ix": "181-ARR_v2_27@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_27",
            "tgt_ix": "181-ARR_v2_27@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_27",
            "tgt_ix": "181-ARR_v2_27@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_27",
            "tgt_ix": "181-ARR_v2_27@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_27",
            "tgt_ix": "181-ARR_v2_27@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_27",
            "tgt_ix": "181-ARR_v2_27@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_27",
            "tgt_ix": "181-ARR_v2_27@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_27",
            "tgt_ix": "181-ARR_v2_27@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_27",
            "tgt_ix": "181-ARR_v2_27@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_27",
            "tgt_ix": "181-ARR_v2_27@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_27",
            "tgt_ix": "181-ARR_v2_27@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_28",
            "tgt_ix": "181-ARR_v2_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_28",
            "tgt_ix": "181-ARR_v2_28@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_29",
            "tgt_ix": "181-ARR_v2_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_29",
            "tgt_ix": "181-ARR_v2_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_29",
            "tgt_ix": "181-ARR_v2_29@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_29",
            "tgt_ix": "181-ARR_v2_29@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_29",
            "tgt_ix": "181-ARR_v2_29@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_29",
            "tgt_ix": "181-ARR_v2_29@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_30",
            "tgt_ix": "181-ARR_v2_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_30",
            "tgt_ix": "181-ARR_v2_30@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_30",
            "tgt_ix": "181-ARR_v2_30@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_30",
            "tgt_ix": "181-ARR_v2_30@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_30",
            "tgt_ix": "181-ARR_v2_30@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_31",
            "tgt_ix": "181-ARR_v2_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_31",
            "tgt_ix": "181-ARR_v2_31@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_31",
            "tgt_ix": "181-ARR_v2_31@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_32",
            "tgt_ix": "181-ARR_v2_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_33",
            "tgt_ix": "181-ARR_v2_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_33",
            "tgt_ix": "181-ARR_v2_33@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_33",
            "tgt_ix": "181-ARR_v2_33@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_33",
            "tgt_ix": "181-ARR_v2_33@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_33",
            "tgt_ix": "181-ARR_v2_33@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_33",
            "tgt_ix": "181-ARR_v2_33@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_34",
            "tgt_ix": "181-ARR_v2_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_34",
            "tgt_ix": "181-ARR_v2_34@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_34",
            "tgt_ix": "181-ARR_v2_34@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_35",
            "tgt_ix": "181-ARR_v2_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_35",
            "tgt_ix": "181-ARR_v2_35@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_35",
            "tgt_ix": "181-ARR_v2_35@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_35",
            "tgt_ix": "181-ARR_v2_35@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_36",
            "tgt_ix": "181-ARR_v2_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_36",
            "tgt_ix": "181-ARR_v2_36@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_36",
            "tgt_ix": "181-ARR_v2_36@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_37",
            "tgt_ix": "181-ARR_v2_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_37",
            "tgt_ix": "181-ARR_v2_37@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_37",
            "tgt_ix": "181-ARR_v2_37@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_37",
            "tgt_ix": "181-ARR_v2_37@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_37",
            "tgt_ix": "181-ARR_v2_37@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_38",
            "tgt_ix": "181-ARR_v2_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_38",
            "tgt_ix": "181-ARR_v2_38@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_38",
            "tgt_ix": "181-ARR_v2_38@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_38",
            "tgt_ix": "181-ARR_v2_38@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_39",
            "tgt_ix": "181-ARR_v2_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_39",
            "tgt_ix": "181-ARR_v2_39@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_39",
            "tgt_ix": "181-ARR_v2_39@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_39",
            "tgt_ix": "181-ARR_v2_39@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_39",
            "tgt_ix": "181-ARR_v2_39@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_40",
            "tgt_ix": "181-ARR_v2_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_40",
            "tgt_ix": "181-ARR_v2_40@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_40",
            "tgt_ix": "181-ARR_v2_40@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_40",
            "tgt_ix": "181-ARR_v2_40@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_41",
            "tgt_ix": "181-ARR_v2_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_42",
            "tgt_ix": "181-ARR_v2_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_42",
            "tgt_ix": "181-ARR_v2_42@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_43",
            "tgt_ix": "181-ARR_v2_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_43",
            "tgt_ix": "181-ARR_v2_43@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_43",
            "tgt_ix": "181-ARR_v2_43@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_43",
            "tgt_ix": "181-ARR_v2_43@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_44",
            "tgt_ix": "181-ARR_v2_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_44",
            "tgt_ix": "181-ARR_v2_44@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_44",
            "tgt_ix": "181-ARR_v2_44@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_45",
            "tgt_ix": "181-ARR_v2_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_45",
            "tgt_ix": "181-ARR_v2_45@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_46",
            "tgt_ix": "181-ARR_v2_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_46",
            "tgt_ix": "181-ARR_v2_46@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_46",
            "tgt_ix": "181-ARR_v2_46@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_46",
            "tgt_ix": "181-ARR_v2_46@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_47",
            "tgt_ix": "181-ARR_v2_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_47",
            "tgt_ix": "181-ARR_v2_47@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_47",
            "tgt_ix": "181-ARR_v2_47@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_47",
            "tgt_ix": "181-ARR_v2_47@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_47",
            "tgt_ix": "181-ARR_v2_47@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_47",
            "tgt_ix": "181-ARR_v2_47@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_47",
            "tgt_ix": "181-ARR_v2_47@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_48",
            "tgt_ix": "181-ARR_v2_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_49",
            "tgt_ix": "181-ARR_v2_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_49",
            "tgt_ix": "181-ARR_v2_49@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_49",
            "tgt_ix": "181-ARR_v2_49@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_49",
            "tgt_ix": "181-ARR_v2_49@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_49",
            "tgt_ix": "181-ARR_v2_49@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_49",
            "tgt_ix": "181-ARR_v2_49@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_49",
            "tgt_ix": "181-ARR_v2_49@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_49",
            "tgt_ix": "181-ARR_v2_49@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_49",
            "tgt_ix": "181-ARR_v2_49@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_49",
            "tgt_ix": "181-ARR_v2_49@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_49",
            "tgt_ix": "181-ARR_v2_49@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_50",
            "tgt_ix": "181-ARR_v2_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_50",
            "tgt_ix": "181-ARR_v2_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_50",
            "tgt_ix": "181-ARR_v2_50@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_50",
            "tgt_ix": "181-ARR_v2_50@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_50",
            "tgt_ix": "181-ARR_v2_50@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_51",
            "tgt_ix": "181-ARR_v2_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_51",
            "tgt_ix": "181-ARR_v2_51@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_51",
            "tgt_ix": "181-ARR_v2_51@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_51",
            "tgt_ix": "181-ARR_v2_51@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_51",
            "tgt_ix": "181-ARR_v2_51@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_52",
            "tgt_ix": "181-ARR_v2_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_53",
            "tgt_ix": "181-ARR_v2_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_53",
            "tgt_ix": "181-ARR_v2_53@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_53",
            "tgt_ix": "181-ARR_v2_53@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_53",
            "tgt_ix": "181-ARR_v2_53@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_53",
            "tgt_ix": "181-ARR_v2_53@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_53",
            "tgt_ix": "181-ARR_v2_53@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_54",
            "tgt_ix": "181-ARR_v2_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_55",
            "tgt_ix": "181-ARR_v2_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_55",
            "tgt_ix": "181-ARR_v2_55@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_56",
            "tgt_ix": "181-ARR_v2_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_56",
            "tgt_ix": "181-ARR_v2_56@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_56",
            "tgt_ix": "181-ARR_v2_56@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_56",
            "tgt_ix": "181-ARR_v2_56@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_56",
            "tgt_ix": "181-ARR_v2_56@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_56",
            "tgt_ix": "181-ARR_v2_56@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_56",
            "tgt_ix": "181-ARR_v2_56@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_56",
            "tgt_ix": "181-ARR_v2_56@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_56",
            "tgt_ix": "181-ARR_v2_56@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_56",
            "tgt_ix": "181-ARR_v2_56@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_56",
            "tgt_ix": "181-ARR_v2_56@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_57",
            "tgt_ix": "181-ARR_v2_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_57",
            "tgt_ix": "181-ARR_v2_57@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_57",
            "tgt_ix": "181-ARR_v2_57@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_58",
            "tgt_ix": "181-ARR_v2_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_59",
            "tgt_ix": "181-ARR_v2_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_60",
            "tgt_ix": "181-ARR_v2_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_60",
            "tgt_ix": "181-ARR_v2_60@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_61",
            "tgt_ix": "181-ARR_v2_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_62",
            "tgt_ix": "181-ARR_v2_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_63",
            "tgt_ix": "181-ARR_v2_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_64",
            "tgt_ix": "181-ARR_v2_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_65",
            "tgt_ix": "181-ARR_v2_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_66",
            "tgt_ix": "181-ARR_v2_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_67",
            "tgt_ix": "181-ARR_v2_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_68",
            "tgt_ix": "181-ARR_v2_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_69",
            "tgt_ix": "181-ARR_v2_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_70",
            "tgt_ix": "181-ARR_v2_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_71",
            "tgt_ix": "181-ARR_v2_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_72",
            "tgt_ix": "181-ARR_v2_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_73",
            "tgt_ix": "181-ARR_v2_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_74",
            "tgt_ix": "181-ARR_v2_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_75",
            "tgt_ix": "181-ARR_v2_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_76",
            "tgt_ix": "181-ARR_v2_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_77",
            "tgt_ix": "181-ARR_v2_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_78",
            "tgt_ix": "181-ARR_v2_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_79",
            "tgt_ix": "181-ARR_v2_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_80",
            "tgt_ix": "181-ARR_v2_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_81",
            "tgt_ix": "181-ARR_v2_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_82",
            "tgt_ix": "181-ARR_v2_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_83",
            "tgt_ix": "181-ARR_v2_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_84",
            "tgt_ix": "181-ARR_v2_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_85",
            "tgt_ix": "181-ARR_v2_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_86",
            "tgt_ix": "181-ARR_v2_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_87",
            "tgt_ix": "181-ARR_v2_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_88",
            "tgt_ix": "181-ARR_v2_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_89",
            "tgt_ix": "181-ARR_v2_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_90",
            "tgt_ix": "181-ARR_v2_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_91",
            "tgt_ix": "181-ARR_v2_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_92",
            "tgt_ix": "181-ARR_v2_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_93",
            "tgt_ix": "181-ARR_v2_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_94",
            "tgt_ix": "181-ARR_v2_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_95",
            "tgt_ix": "181-ARR_v2_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_96",
            "tgt_ix": "181-ARR_v2_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_97",
            "tgt_ix": "181-ARR_v2_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_98",
            "tgt_ix": "181-ARR_v2_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_99",
            "tgt_ix": "181-ARR_v2_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_100",
            "tgt_ix": "181-ARR_v2_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_101",
            "tgt_ix": "181-ARR_v2_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_102",
            "tgt_ix": "181-ARR_v2_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_103",
            "tgt_ix": "181-ARR_v2_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_104",
            "tgt_ix": "181-ARR_v2_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_105",
            "tgt_ix": "181-ARR_v2_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_106",
            "tgt_ix": "181-ARR_v2_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_107",
            "tgt_ix": "181-ARR_v2_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_108",
            "tgt_ix": "181-ARR_v2_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_109",
            "tgt_ix": "181-ARR_v2_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_110",
            "tgt_ix": "181-ARR_v2_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_111",
            "tgt_ix": "181-ARR_v2_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_112",
            "tgt_ix": "181-ARR_v2_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_113",
            "tgt_ix": "181-ARR_v2_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_114",
            "tgt_ix": "181-ARR_v2_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_115",
            "tgt_ix": "181-ARR_v2_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_116",
            "tgt_ix": "181-ARR_v2_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_117",
            "tgt_ix": "181-ARR_v2_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_118",
            "tgt_ix": "181-ARR_v2_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_119",
            "tgt_ix": "181-ARR_v2_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_120",
            "tgt_ix": "181-ARR_v2_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_121",
            "tgt_ix": "181-ARR_v2_121@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_122",
            "tgt_ix": "181-ARR_v2_122@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_123",
            "tgt_ix": "181-ARR_v2_123@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_124",
            "tgt_ix": "181-ARR_v2_124@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_125",
            "tgt_ix": "181-ARR_v2_125@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_126",
            "tgt_ix": "181-ARR_v2_126@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_127",
            "tgt_ix": "181-ARR_v2_127@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_128",
            "tgt_ix": "181-ARR_v2_128@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_129",
            "tgt_ix": "181-ARR_v2_129@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_130",
            "tgt_ix": "181-ARR_v2_130@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_131",
            "tgt_ix": "181-ARR_v2_131@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_132",
            "tgt_ix": "181-ARR_v2_132@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_133",
            "tgt_ix": "181-ARR_v2_133@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_134",
            "tgt_ix": "181-ARR_v2_134@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_135",
            "tgt_ix": "181-ARR_v2_135@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_136",
            "tgt_ix": "181-ARR_v2_136@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_137",
            "tgt_ix": "181-ARR_v2_137@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_138",
            "tgt_ix": "181-ARR_v2_138@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "181-ARR_v2_139",
            "tgt_ix": "181-ARR_v2_139@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 947,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "doc_id": "181-ARR",
        "version": 2
    }
}