{
    "nodes": [
        {
            "ix": "394-ARR_v2_0",
            "content": "Neural Language Taskonomy: Which NLP Tasks are the most Predictive of fMRI Brain Activity?",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_2",
            "content": "Several popular Transformer based language models have been found to be successful for text-driven brain encoding. However, existing literature leverages only pretrained text Transformer models and has not explored the efficacy of task-specific learned Transformer representations. In this work, we explore transfer learning from representations learned for ten popular natural language processing tasks (two syntactic and eight semantic) for predicting brain responses from two diverse datasets: Pereira (subjects reading sentences from paragraphs) and Narratives (subjects listening to the spoken stories). Encoding models based on task features are used to predict activity in different regions across the whole brain. Features from coreference resolution, NER, and shallow syntax parsing explain greater variance for the reading activity. On the other hand, for the listening activity, tasks such as paraphrase generation, summarization, and natural language inference show better encoding performance. Experiments across all 10 task representations provide the following cognitive insights: (i) language left hemisphere has higher predictive brain activity versus language right hemisphere, (ii) posterior medial cortex, temporoparieto-occipital junction, dorsal frontal lobe have higher correlation versus early auditory and auditory association cortex, (iii) syntactic and semantic tasks display a good predictive performance across brain regions for reading and listening stimuli resp.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "394-ARR_v2_4",
            "content": "Brain encoding aims at constructing neural brain activity given an input stimulus. Since the discovery of the relationship between language stimuli and functions of brain networks using fMRI [for ex., (Constable et al., 2004)], researchers have been interested in understanding how the neural encoding models predict the fMRI brain activity. Several brain encoding models have been developed to (i) understand the ventral stream in biological vision (Yamins et al., 2014;Kietzmann et al., 2019;Bao et al., 2020), and (ii) to study the higher-level cognition like language processing (Gauthier and Levy, 2019;Schrimpf et al., 2021;Schwartz et al., 2019). Some recent studies (Nishida et al., 2015;Huth et al., 2016) have been able to identify brain ROIs (Region of Interest) that respond to words that have a similar meaning and have thus built a \"semantic atlas\" of how the human brain organizes language. Further, several studies (Oota et al., 2018;Jain and Huth, 2018;Hollenstein et al., 2019) have used a wide variety of word embeddings where words represented as vectors in an embedding space are mapped to brain activation for improved neural coding.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_5",
            "content": "Recently, Transformer (Vaswani et al., 2017) based models like BERT (Devlin et al., 2019) have been found to be very effective across a large number of natural language processing (NLP) tasks. These Transformer based models have been pretrained on millions of text instances in an unsupervised manner and further finetuned to specialize for various NLP tasks. Natural language understanding requires integrating several cognitive skills like syntactic parsing of the language structure, identifying the named entities, capturing the word meaning in the context, coreference resolution, etc. Learning from massive corpora enables these models to excel at cognitive skills required for language understanding. Interestingly, such Transformer-based neural representations have been found to be very effective for brain encoding as well (Schrimpf et al., 2021).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_6",
            "content": "Despite the recent advances in mapping between language Transformers and the brain activity recorded with reading (Schrimpf et al., 2021), the Transformer features themselves are notoriously difficult to interpret. In recent works, Caucheteux et al. (2021a); Antonello et al. (2021) address this issue by disentangling the high-dimensional Transformer representations of language models into four combinatorial classes: lexical, compositional, syntactic, and semantic representations to explore which class is highly associated with language cortical ROIs. Representations do not exist in a vacuum but become meaningful only when they accomplish a task. Therefore, the next logical step is to see which of these Transformer representations most effectively drive the linear mapping between language models and the brain in the context of NLP tasks. Gauthier and Levy (2019) fine-tune a pretrained BERT model on multiple tasks to find tasks best correlated with high decoding performance. In this study, we investigate the correlation between brain activation and feature representations learned by different task-specific networks, and ask which tasks lead to improvements in brainencoding performance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_7",
            "content": "Recently, a study using multiple computer vision tasks has shown that 3D vision task models predict better fMRI brain activity than 2D vision task models for visual stimuli. Inspired by the success of correlations in the vision field , and brain encoding study of a variety of language Transformer models (Schrimpf et al., 2021;Caucheteux et al., 2021b,a), we build neural language taskonomy models for brain encoding and aim to find NLP tasks that are most explanatory of brain activations for reading and listening tasks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_8",
            "content": "In this paper, we uncover insights about the association between fMRI voxel activations and representations of diverse NLP tasks representations. The predictive power of task-specific representations with brain activation is ascertained by (1) using ridge regression on such representations and predicting activations and (2) computing popular metrics like 2V2 accuracy and Pearson correlation between actual and predicted activations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_9",
            "content": "Specifically, we make the following contributions in this paper.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_10",
            "content": "\u2022 Given Transformer models finetuned for various NLP tasks, we propose the problem of finding which of these are the most predictive of fMRI brain activity for reading and listening tasks. \u2022 Our language taskonomy results reveal that Coreference Resolution, Named Entity Recognition, and Shallow Syntax Parsing tasks have higher predictive performance while reading the text. On the other hand, paraphrase detection, summarization, and Natural Language Inference tasks display better correlation during listening. \u2022 We also perform similarity analysis between task representations from transfer learning and neural taskonomy and derive interesting cognitive insights from brain maps.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_11",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "394-ARR_v2_12",
            "content": "Older methods for text-based stimulus representation include text corpus co-occurrence counts (Mitchell et al., 2008;Pereira et al., 2013;Huth et al., 2016), syntactic and discourse features (Wehbe et al., 2014). In recent times, both semantic and experiential attribute models have been explored for text-based stimuli. Semantic representation models include distributed word embeddings (Pereira et al., 2016;Anderson et al., 2017a;Pereira et al., 2018;Hollenstein et al., 2019;Wang et al., 2020), sentence representation models (Sun et al., 2019;Sun et al., 2020), recurrent neural networks (Jain and Huth, 2018;Oota et al., 2019), and Transformer-based language models (Gauthier and Levy, 2019;Schwartz et al., 2019;Oota et al., 2022a,b). Experiential attribute models represent words in terms of human ratings of their degree of association with different attributes of experience, typically on a scale of 0-6 (Anderson et al., 2019(Anderson et al., , 2020Berezutskaya et al., 2020;Jat et al., 2020;Caucheteux et al., 2021a;Antonello et al., 2021) or binary (Handjaras et al., 2016;Wang et al., 2017). Fine-grained details such as lexical, compositional, syntactic, and semantic representations of narratives are factorized from Transformer-based models and utilized for training encoding models. The resulting models are better able to disentangle the corresponding brain responses in fMRI (Caucheteux et al., 2021a).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_13",
            "content": "In this paper, we focus on Transformer-based linguistic stimuli representations since they have been found to be most effective. Unlike previous studies which directly used existing task-agnostic pretrained models, we train task-specific Transformer models and aim to find which model leads to the best encoding accuracy given reading and listening language stimuli.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_14",
            "content": "Brain Imaging Datasets",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "394-ARR_v2_15",
            "content": "We work with two datasets: Pereira and Narratives-Pieman. Results on Narratives-Lucy and Narratives-SlumLord show similar trends. Hence, we also show results on Narratives-Lucy and Narratives-SlumLord in the appendix. Pereira Dataset (Reading Sentences from Passages) For the Pereira dataset, similar to earlier work (Sun et al., 2019(Sun et al., , 2020, we combine the data from sentence-based experiments (experiments-2 and 3) from Pereira et al. (2018). Five subjects were presented a total of 627 sentences from 48 broad topics, spanning over 168 passages, where each passage consists of 3-4 sentences. As in (Pereira et al., 2018), we focused on nine brain ROIs (regions of interest) corresponding to four brain networks: (i) Default Mode Network (DMN) (linked to the functionality of semantic processing), (ii) Language Network (related to language processing, understanding, word meaning, and sentence comprehension), (iii) Task Positive Network (TP) (related to attention, salience information), and (iv) Visual Network (related to the processing of visual objects, object recognition). We briefly summarize the details of the dataset and the number of voxels corresponding to each ROI in Table 1 Narratives-Pieman (Listening to Stories) The \"Narratives\" collection aggregates a variety of fMRI datasets collected while human subjects listened to naturalistic spoken stories. The Narratives dataset that includes 345 subjects, 891 functional scans, and 27 diverse stories of varying duration totaling \u223c4.6 hours of unique stimuli (\u223c43,000 words) was proposed in (Nastase et al., 2021). Similar to earlier works (Caucheteux et al., 2021b), we analyze data from 82 subjects listening to the story titled 'PieMan' with 259 TRs (repetition time -fMRI recorded every 1.5 sec.). We list number of voxels per ROI in this dataset in Table 2. We use the multimodal parcellation of the human cerebral cortex (Glassar Atlas: consists of 180 ROIs in each hemisphere) to display the brain maps (Glasser et al., 2016), since Narratives dataset contains annotations tied to this atlas. The data covers ten brain ROIs in the human brain, i.e., Left hemisphere (L), and Right hemisphere (R) for each of the following: (i) early auditory cortex (EAC: A1, LBelt, MBelt, PBelt, and R1) which plays a key role for sound perception since it represents one of the first cortical processing stations for sounds; (ii) auditory association cortex (AAC: A4, A5, STSdp, STSda, STSvp, STSva, STGa, and TA2) which is concerned with the memory and classification of sounds; (iii) posterior medial cortex (PMC: POS1, POS2, v23ab, d23ab, 31pv, 31pd, 7m); (iv) the temporo parieto occipital junction (TPOJ: TPOJ1, TPOJ2, TPOJ3, STV, PSL) which is a complex brain territory heavily involved in several high-level neurological functions, such as language, visuo-spatial recognition, writing, reading, symbol processing, calculation, self-processing, working memory, musical memory, and face and object recognition; and (v) the dorsal frontal lobe (DFL: L_55b, SFL, L_44, L_45, IFJA, IFSP) which covers the aspects of pragmatic processing such as discourse management, integration of prosody, interpretation of nonliteral meanings, inference making, ambiguity resolution, and error repair.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_16",
            "content": "Encoding Model",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "394-ARR_v2_17",
            "content": "To explore how and where contextual language features are represented in the brain when reading sentences and listening to stories, we extract different features spaces describing each stimulus sentence and use them in an encoding model to predict brain responses. Our reasoning is as follows. If a feature is a good predictor of a specific brain region, information about that feature is likely encoded in that region. In this paper, for both datasets, we train fMRI encoding models using Ridge regression on stimuli representations obtained using a variety of NLP tasks. The main goal of each fMRI encoder model is to predict brain responses associated with each brain region given a stimuli. In all cases, we train a model per subject separately. Following literature on brain encoding (Caucheteux et al., 2021b;Toneva et al., 2020), we choose to use a ridge regression model instead of more complicated models. We plan to explore more such models as part of future work. We follow K-fold (K=10) cross-validation. All the data samples from K-1 folds were used for training, and the model was tested on samples of the left-out fold. We used sklearn's ridge-regression with default parameters, 10-fold cross-validation, Stochastic-Average-Gradient Descent Optimizer, Huggingface for Transformer models, MSE loss function, and L2-decay (\u03bb) as 1.0. We used BERT Word-Piece tokenizer for the linguistic Transformer input. All experiments were conducted on a machine with 1 NVIDIA GEFORCE-GTX GPU with 16GB GPU RAM. We make the code publicly available 1 .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_18",
            "content": "Feature Spaces",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "394-ARR_v2_19",
            "content": "To simultaneously test representations from multiple NLP tasks, we used the latent space features from each of the following ten popular NLP tasks: coreference resolution (CR), named entity recognition (NER), natural language inference (NLI), paraphrase detection (PD), question answering (QA), sentiment analysis (SA), semantic role labeling (SRL), shallow syntax parsing (SS), summarization (Sum) and word sense disambiguation (WSD). All of these are discriminative NLP tasks, and thus we use models obtained by task-specific finetuning of the same pretrained Transformer encoder model (BERT-base-cased with dimension-ality=768). Given an input sentence, each task Transformer outputs token representations at the final layer. We use the #tokens \u00d7 768 dimension vector obtained from the last hidden layer to obtain latent features for the stimuli. We then build individual ridge regression models with the extracted latent features to predict brain responses and measure the correlation between the prediction and the true response. Pereira: Since individual sentences were presented to the subjects while modeling, sentences were passed one by one to the task Transformer model, and average-pooled representations were used to encode the sentence stimuli. Narratives-Pieman: Due to the constraint on input sequence length for BERT (512), we considered a window size of 10 sentences with the last two sentences of one window overlapping with the next to be given as input to the BERT model. We use the average-pooled representation from BERT to encode text stimuli. To get the representation for a TR, we pooled the representations of only those words of the sentences in that TR.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_20",
            "content": "Task Descriptions",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "394-ARR_v2_21",
            "content": "Here we describe the functionality of each NLP task that we used for fMRI encoding. CR: involves finding all expressions that refer to the same entity in a text. PD: involves taking a passage -either spoken or written -and rewording it in shorter or own words. Summarization (Sum): involves selecting a few important sentences from a document or paragraph. NER: involves detection of the named entities such as person names, location names, company names from a given text. NLI: investigates the entailment relationship between two texts: premise and hypothesis. QA: aims to select an answer given a passage, a question, and a set of candidate answers. SA: involves determining whether a piece of text is positive, negative, or neutral. SRL: assigns labels to words or phrases in a sentence that indicates their semantic role in the sentence, such as that of an agent, goal, or result. SS: provides an approximation of phrase-syntactic structure of sentences. WSD: involves determining which sense (meaning) of a word is activated by the use of the word in a particular context.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_22",
            "content": "Syntactic reasoning is rather shallow compared to deep semantic reasoning. Syntactic reasoning follows somewhat objective grammar rules. Comparatively semantic reasoning is often subjective in nature and complex. The emerging evidence from fMRI studies (Fedorenko et al., 2020(Fedorenko et al., , 2012 also points out that processing of both syntax and semantics is distributed in the brain and it is only when violations of these processes are probed, we see localization of function (Friederici et al., 2003). Thus, in this work, we explore syntactic and semantic tasks separately. Of the above mentioned tasks, NER and SS are syntactic, while the others involve semantic reasoning.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_23",
            "content": "Our selection of these tasks was based on the following design principles: (1) We wanted to select a set of tasks covering diverse cognitive-linguistic skills. (2) We wanted to select tasks that are a part of popular NLP benchmarks like GLUE (Wang et al., 2018). (3) We selected tasks for which BERT-base-cased finetuned models were available. Note that we did not finetune any of these models ourselves but leveraged the state-of-the-art finetuned models available on Huggingface. Details of the specific finetuned model checkpoints are mentioned in Table 3 in the Appendix.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_24",
            "content": "Evaluation Metrics",
            "ntype": "title",
            "meta": {
                "section": "4.3"
            }
        },
        {
            "ix": "394-ARR_v2_25",
            "content": "We evaluate our models using popular brain encoding evaluation metrics described in the following. Given a subject and a brain region, let N be the number of samples. Let {Y i } N i=1 and { \u0176i } N i=1 denote the actual and predicted voxel value vectors for the i th sample. Thus, Y \u2208 R N \u00d7V and \u0176 \u2208 R N \u00d7V where V is the number of voxels in that region.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_26",
            "content": "Accuracy",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_27",
            "content": "is computed as 2V2Acc= 1 N C 2 N \u22121 i=1 N j=i+1 I[cosD(Y i , \u0176i ) + cosD(Y j , \u0176j ) < cosD(Y i , \u0176j ) + cosD(Y j , \u0176i )]",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_28",
            "content": "where cosD is the cosine distance function. I[c] is an indicator function such that I[c] = 1 if c is true, else it is 0. The higher the 2V2 accuracy, the better. \u0176i ] where corr is the correlation function. Mean Absolute Error (MAE) is computed as",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_29",
            "content": "Pearson Correlation (PC) is computed as PC= 1 N n i=1 corr[Y i ,",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_30",
            "content": "MAE= 1 N n i=1 |[Y i \u2212 \u0176i ]|.",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_31",
            "content": "Statistical Significance: In order to estimate the statistical significance of the performance differences (across all results), we performed one-way ANOVA on the mean values for the subjects. In all such cases we report p-values corrected using Bonferroni correction.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_32",
            "content": "Neural Language Tasks Similarity Computation",
            "ntype": "title",
            "meta": {
                "section": "4.4"
            }
        },
        {
            "ix": "394-ARR_v2_33",
            "content": "To estimate the similarity between 10 language tasks, we took the prediction performance scores across all the voxels in Pereira (97,539) and Narratives-Pieman datasets (10,732). To analyze the relationship between tasks based on neural representations, we calculated the Pearson correlation between predicted voxels of each task with the remaining tasks. These Pearson correlation values were used to construct heatmaps and the task similarity trees(dendograms) using hierarchical clustering for Pereira and Narratives-Pieman datasets.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_34",
            "content": "Results",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "394-ARR_v2_35",
            "content": "In order to assess the performance of the fMRI encoder models learned using the representations from a variety of NLP tasks, we computed the 2V2 accuracy and Pearson correlation coefficient between the predicted and true responses across various ROIs for both the reading (Pereira) dataset (Fig. 1) as well as the listening (Narratives-Pieman) dataset (Fig. 2).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_36",
            "content": "Encoding performance of Language Task models for reading vs listening tasks",
            "ntype": "title",
            "meta": {
                "section": "5.1"
            }
        },
        {
            "ix": "394-ARR_v2_37",
            "content": "Reading Sentences (Pereira): From Fig. 1, we observe that tasks such as CR, NER, SRL, and SS appear to have a better correlation to the brain responses compared to the other tasks. In order to estimate the statistical significance of the performance differences, we performed one-way ANOVA on the mean correlation values for the subjects across the ten language tasks for the nine brain ROIs. The main effect of the ANOVA test was significant for all the ROIs with p\u2264 10 \u22122 with confidence 95% (see Appendix for detailed ANOVA results). Further, post hoc pairwise comparisons (Ruxton and Beauchamp, 2008) confirmed the visual observations that on both 2V2 accuracy and Pearson correlation measures, tasks such as CR, NER, SRL, and SS performed significantly better compared to other tasks (see Appendix for pairwise comparison results). These results demonstrate that when reading a sentence, information processing operations related to recognizing named entities, labeling semantic roles to the constituents of a sentence, identifying the references from a sentence to the given topic (concept), and syntactic processing may be engaged. Further, we observe that the ROI corresponding to language processing in the left hemisphere (Lan-guage_LH) has higher encoding performance than that of the right hemisphere (Language_RH). This is in line with the left hemisphere dominance for language processing (Binder et al., 2009). Also, lateral visual ROIs such as Vision_Object, Vi-sion_Body, Vision_Face, and Vision ROIs display higher correlation with the language tasks associated with named entities (NER), relating the entities (CR), and syntax processing (SS). Higher correlations with all the visual brain regions point to the possible alignment of visual and language regions for semantic understanding (Popham et al., 2021) in a reading task. Finally, across all regions, pretrained BERT model has worse correlation compared to at least 5 other task models. Listening Stories (Narratives-Pieman): From Fig. 2, we observe that the profiles of performance show low scores in the early auditory cortex (EAC), auditory association cortex (AAC); average scores in TPOJ and DFL; and superior scores in PMC. This aligns with the known language hierarchy for spoken language understanding (Nastase et al., 2020). Tasks such as PD, Summarization, and NLI seem to yield better performance in predicting the brain responses than the other NLP tasks across all the ROIs. These Pearson correlation (\u03c4 ) results are comparatively much higher compared to those obtained using pretrained (task-agnostic) GPT2 model in (Caucheteux et al., 2021a) (\u03c4 ranging from 0.02 \u2212 0.06). As shown in Fig. 2, our method obtains much higher correlations (\u03c4 ranging from 0.02 \u2212 0.229). Similar to the Pereira dataset, we estimate the statistical significance of the performance differences using the one-way ANOVA test. The main effect of task was significant for all the ROIs with p\u2264 10 \u22123 with confidence 95% (see Appendix for detailed ANOVA results). Also, Post hoc pairwise comparisons (Ruxton and Beauchamp, 2008) revealed that on both 2V2 accuracy and Pearson correlation measures, tasks such as PD, Sum, and NLI performed significantly better compared to other tasks (see Appendix for pairwise comparison results).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_38",
            "content": "Further, from Fig. 2, we see that the bilateral posterior medial cortex (PMC) associated with higher language function exhibits a higher correlation among all the brain ROIs. ROIs, including bilateral TPOJ and bilateral DFL, yield higher correlations with the five NLP tasks, which is in line with the language processing hierarchy in the human brain. Finally, across all regions, pretrained BERT model has worse correlation compared to at least 5 other task models.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_39",
            "content": "In summary, different and distinct language Taskonomy features seem to be related to the encoding performance in reading versus listening tasks. CR, NER, SRL, and SS perform better for reading. PD, Sum, and NLI perform better for listening. While listening the subject is cognitively more involved in the activity compared to reading (Buchweitz et al., 2009). Thus, it makes sense that shallow tasks like NER and SS are useful for reading while more complex NLP tasks like PD, Sum and NLI are effective for encoding listening stimuli.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_40",
            "content": "Language Task Similarity Computation",
            "ntype": "title",
            "meta": {
                "section": "5.2"
            }
        },
        {
            "ix": "394-ARR_v2_41",
            "content": "Pearson correlation values between predicted responses for each pair of tasks were used to construct the similarity matrix with heatmap for both Pereira and Narratives-Pieman datasets, as shown in Figs. 3 and 4. We observe that the following task pairs are highly correlated for the Pereira dataset: (NER and CR), (SS and CR) and (PD and Sum). Also these task pairs are highly correlated for the Narratives-Pieman dataset: (CR and NLI), (NLI and SA) and (PD and Sum). Similarities are relatively higher for Narratives-Pieman compared to the Pereira dataset. Surprisingly, the (NLI, SA) pair has lowest similarity for Pereira (reading) and close to highest in Narratives-Pieman (listening). We hypothesize that this is because sentiment is best conveyed while the subject is listening. Reading sentences (Pereira): The stimulus sentences from the Pereira dataset were fed as input to each of the 10 task Transformers. The similarity among the resulting representations was analyzed using hierarchical clustering, and the clusters are visualized as dendrograms in Fig. 5 (left). We observe that the tasks are clustered into three groups denoted using red, green, and blue colors. Next, we wished to check if similar task grouping is observed on brain activations predicted by ridge regression trained on task-specific representations. Hence, similar clustering analysis was conducted on the neural space representations, and the clusters are visualized as dendrograms in Fig. 5 (right) across all subjects. Interestingly, the tree derived from brain representation also shows a similar distribution of tasks across the three groups. Similar dendrograms for individual subjects are illustrated in Appendix-Fig. 11. Listening Stories (Narratives-Pieman): Fig. 6 compares the task similarity tree based on the patterns from the pretrained task Transformers, with the task similarity tree generated based on similarity in brain response prediction performance averaged across all subjects. We observe that the tasks are clustered into three groups denoted using red, green, and blue colors. Again, the tree derived from brain representation also shows a similar distribution of tasks across the three groups. Dendrograms for individual subjects are in the Appendix-Fig. 12.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_42",
            "content": "Brain maps for whole brain predictions",
            "ntype": "title",
            "meta": {
                "section": "5.3"
            }
        },
        {
            "ix": "394-ARR_v2_43",
            "content": "The mean absolute error (MAE) between predictive and actual responses is obtained using individual task features from the taskonomy. MAE values are obtained for all the voxels in the brain for both the reading (Fig. 7) and listening datasets (Fig. 8).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_44",
            "content": "In the reading task, we observe from Fig. 7 that CR has lower MAE compared to PD which in turn has lower MAE compared to the NLI task (brain maps for the other tasks are reported in Fig. 17 in the Appendix). Overall, for the reading stimuli, tasks such as NLI, QA, and SA display higher MAE values. To further investigate which sub ROIs (LPTG, LMTG, LATG, LFus, Lpar, Lang, LIFGorb, LIFG, LaMFG, LpMFG, and LmMFG) of the Language network are related to the predictive task features, we train encoding models for all the sub ROIs for the best encoding task, i.e., for the CR task (see Fig. 14 in Appendix). We notice that both LMTG (middle temporal gyrus) and LPTG (posterior temporal gyrus) are more accurately predicted than the other sub ROIs. On the other hand, LIFG-orb displays a lower Pearson correlation for the CR task. The presence of superior encoding information in the ROIs in the temporal gyrus as compared to those in the inferior frontal gyrus seems to mirror similar observations seen in decoder performance (Anderson et al., 2017b).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_45",
            "content": "On the other hand, in the listening task, we observe from Fig. 8 that Paraphrase and WSD display lower MAE values compared to QA task (brain maps for the other tasks are reported in Fig. 18 in the Appendix). Taken together, for listening stimuli, tasks such as NER, QA, SA, CR, and SS display higher MAE values. From Fig. 8, we see that ROIs such as EAC and AAC have higher MAE compared to PMC and TPOJ brain ROIs.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_46",
            "content": "We further demonstrate the prediction performance of the encoder model trained on sub ROIs for the paraphrase task in Fig. 15 in the Appendix. It can be observed that sub ROIs such as Pos1 and Pos2 have a higher Pearson correlation than other sub ROIs of the PMC region. Both sfl and l55b display a higher correlation among all the sub ROIs for the DFL ROI. However, all the sub ROIs in the TPOJ yield higher correlation, as shown in Fig. 15. The control and attention ROIs in the posterior cingulate cortex (for ex., POS1 in PMC), together with the superior frontal language region (sfl in DFL) and TPOJ, are part of the well-known language network associated with narrative comprehension (Nastase et al., 2020), and it is heartening to see that task features from PD task also relate to semantic analysis of the ongoing narrative.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_47",
            "content": "Discussion",
            "ntype": "title",
            "meta": {
                "section": "5.4"
            }
        },
        {
            "ix": "394-ARR_v2_48",
            "content": "(1) We used a ridge regression model instead of more complicated models for encoding. We believe that more complex models can lead to further exciting insights. (2) We experimented with 10 NLP tasks. Models can be pretrained for more such tasks to check if other tasks are better predictive of voxel activations. tasks. While a fair comparison of dataset sizes across tasks is impossible, we understand that this could have resulted in some bias in our results.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_49",
            "content": "(4) We used a different dataset for reading vs listening. While we believe that the differences in task-specific model performances across reading and listening are mainly due to the learned stimulus representations, but they could also arise from other factors such as experimental conditions, the text domain of the stimuli or number of voxels, etc. (5) On Natural Language Understanding tasks such as NLI, SA, QA and PD, Gauthier and Levy (2019) observed that scrambled sentence representations gave better decoding performance. But encoding models (especially for the listening task), scrambled order would be detrimental to making sense of what is being heard. It is an interesting future task to see if the opposite result is seen in the case of brain encoding models. It is plausible that brain uses encoding models in a flexible way when it comes to decoding (Kriegeskorte and Douglas, 2019). Kriegeskorte and Douglas (2019) mention that \"Decoding models can help reveal whether particular information is present in a brain region in a format the decoder can exploit. Encoding models make comprehensive predictions about representational spaces.\" In this sense, results of current work are not directly comparable to those of Gauthier and Levy (2019).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_50",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "394-ARR_v2_51",
            "content": "In this paper, we studied the effectiveness of task specific NLP models for brain encoding. We observe that building individual encoding models and exploiting existing relationships among models can provide a more in-depth understanding of the neural representation of language information. Our experiments on Pereira and Narrative datasets lead to interesting cognitive insights.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_52",
            "content": "A Details of the Finetuned Models",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_53",
            "content": "We selected tasks for which BERT-base-cased finetuned models were available. Note that we did not finetune any of these models ourselves but leveraged the state-of-the-art finetuned models available on Huggingface. Details of the specific finetuned model checkpoints are mentioned in Table 3.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_54",
            "content": "B ANOVA test results",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_55",
            "content": "The main effect of model was significant for the ROIs with 95% confidence with these statistics:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_56",
            "content": "\u2022 The main effect of model was significant for the ROIs with 95% confidence with these statistics: \u2022 EAC_L [F(9,810)=3.88, p=.00009] \u2022 EAC_R [F(9,810)=3.34, p=.00055] \u2022 AAC_L [F(9,810)=5.37, p=.0000007] \u2022 AAC_R [F(9,810)=6.955, p=.00000] \u2022 PMC_L [F(9,810)=37.21, p=.00000] \u2022 PMC_R [F(9,810)=31.62, p=.00000] \u2022 TPOJ_L [F(9,810)=9.166, p=.00000] \u2022 TPOJ_R [F(9,810)=7.797, p=.00000] \u2022 DFL_L [F(9,810)=12.445, p=.00000] \u2022 DFL_R [F(9,810)=12.27, p=.00000]",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "394-ARR_v2_57",
            "content": "F Nick,  Ramsey, 2020. Cortical network responses map onto data-driven features that capture visual semantics of movie fragments, , Scientific reports, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "F Nick",
                    " Ramsey"
                ],
                "title": "2020. Cortical network responses map onto data-driven features that capture visual semantics of movie fragments",
                "pub_date": null,
                "pub_title": "Scientific reports",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_58",
            "content": "R Jeffrey,  Binder, H Rutvik, William Desai, Lisa Graves,  Conant, Where is the semantic system? a critical review and meta-analysis of 120 functional neuroimaging studies, 2009, Cerebral cortex, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "R Jeffrey",
                    " Binder",
                    "H Rutvik",
                    "William Desai",
                    "Lisa Graves",
                    " Conant"
                ],
                "title": "Where is the semantic system? a critical review and meta-analysis of 120 functional neuroimaging studies",
                "pub_date": "2009",
                "pub_title": "Cerebral cortex",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_59",
            "content": "Augusto Buchweitz, A Robert, L\u00eada Mason, Marcel Tomitch,  Just, Brain activation for reading and listening comprehension: An fmri study of modality effects and individual differences in language comprehension, 2009, Psychology & neuroscience, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "Augusto Buchweitz",
                    "A Robert",
                    "L\u00eada Mason",
                    "Marcel Tomitch",
                    " Just"
                ],
                "title": "Brain activation for reading and listening comprehension: An fmri study of modality effects and individual differences in language comprehension",
                "pub_date": "2009",
                "pub_title": "Psychology & neuroscience",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_60",
            "content": "Charlotte Caucheteux, Alexandre Gramfort, Jean-Remi King, Disentangling syntax and semantics in the brain with deep networks, 2021, International Conference on Machine Learning, PMLR.",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Charlotte Caucheteux",
                    "Alexandre Gramfort",
                    "Jean-Remi King"
                ],
                "title": "Disentangling syntax and semantics in the brain with deep networks",
                "pub_date": "2021",
                "pub_title": "International Conference on Machine Learning",
                "pub": "PMLR"
            }
        },
        {
            "ix": "394-ARR_v2_61",
            "content": "UNKNOWN, None, 2021, Model-based analysis of brain activity reveals the hierarchy of language in 305 subjects, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Model-based analysis of brain activity reveals the hierarchy of language in 305 subjects",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_62",
            "content": "Todd Constable, R Kenneth, Ella Pugh, Einar Berroya, Michael Mencl, Weijia Westerveld, Donald Ni,  Shankweiler, Sentence complexity and input modality effects in sentence comprehension: an fmri study, 2004, NeuroImage, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "Todd Constable",
                    "R Kenneth",
                    "Ella Pugh",
                    "Einar Berroya",
                    "Michael Mencl",
                    "Weijia Westerveld",
                    "Donald Ni",
                    " Shankweiler"
                ],
                "title": "Sentence complexity and input modality effects in sentence comprehension: an fmri study",
                "pub_date": "2004",
                "pub_title": "NeuroImage",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_63",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, Bert: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "Jacob Devlin",
                    "Ming-Wei Chang",
                    "Kenton Lee",
                    "Kristina Toutanova"
                ],
                "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_64",
            "content": "Evelina Fedorenko, Asher Idan, Matthew Blank, Zachary Siegelman,  Mineroff, Lack of selectivity for syntax relative to word meanings throughout the language network, 2020, Cognition, .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Evelina Fedorenko",
                    "Asher Idan",
                    "Matthew Blank",
                    "Zachary Siegelman",
                    " Mineroff"
                ],
                "title": "Lack of selectivity for syntax relative to word meanings throughout the language network",
                "pub_date": "2020",
                "pub_title": "Cognition",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_65",
            "content": "Evelina Fedorenko, Alfonso Nieto-Castanon, Nancy Kanwisher, Lexical and syntactic representations in the brain: an fmri investigation with multivoxel pattern analyses, 2012, Neuropsychologia, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Evelina Fedorenko",
                    "Alfonso Nieto-Castanon",
                    "Nancy Kanwisher"
                ],
                "title": "Lexical and syntactic representations in the brain: an fmri investigation with multivoxel pattern analyses",
                "pub_date": "2012",
                "pub_title": "Neuropsychologia",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_66",
            "content": "D Angela, Shirley-Ann Friederici, Anja R\u00fcschemeyer, Christian Hahne,  Fiebach, The role of left inferior frontal and superior temporal cortex in sentence comprehension: localizing syntactic and semantic processes, 2003, Cerebral cortex, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "D Angela",
                    "Shirley-Ann Friederici",
                    "Anja R\u00fcschemeyer",
                    "Christian Hahne",
                    " Fiebach"
                ],
                "title": "The role of left inferior frontal and superior temporal cortex in sentence comprehension: localizing syntactic and semantic processes",
                "pub_date": "2003",
                "pub_title": "Cerebral cortex",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_67",
            "content": "Jon Gauthier, Roger Levy, Linking artificial and human neural representations of language, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Jon Gauthier",
                    "Roger Levy"
                ],
                "title": "Linking artificial and human neural representations of language",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_68",
            "content": "F Matthew, Timothy Glasser, Emma Coalson, Carl Robinson, John Hacker, Essa Harwell, Kamil Yacoub, Jesper Ugurbil,  Andersson, F Christian, Mark Beckmann,  Jenkinson, A multimodal parcellation of human cerebral cortex, 2016, Nature, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "F Matthew",
                    "Timothy Glasser",
                    "Emma Coalson",
                    "Carl Robinson",
                    "John Hacker",
                    "Essa Harwell",
                    "Kamil Yacoub",
                    "Jesper Ugurbil",
                    " Andersson",
                    "F Christian",
                    "Mark Beckmann",
                    " Jenkinson"
                ],
                "title": "A multimodal parcellation of human cerebral cortex",
                "pub_date": "2016",
                "pub_title": "Nature",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_69",
            "content": "Giacomo Handjaras, Emiliano Ricciardi, Andrea Leo, Alessandro Lenci, Luca Cecchetti, Mirco Cosottini, Giovanna Marotta, Pietro Pietrini, How concepts are encoded in the human brain: a modality independent, category-based cortical organization of semantic knowledge, 2016, Neuroimage, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Giacomo Handjaras",
                    "Emiliano Ricciardi",
                    "Andrea Leo",
                    "Alessandro Lenci",
                    "Luca Cecchetti",
                    "Mirco Cosottini",
                    "Giovanna Marotta",
                    "Pietro Pietrini"
                ],
                "title": "How concepts are encoded in the human brain: a modality independent, category-based cortical organization of semantic knowledge",
                "pub_date": "2016",
                "pub_title": "Neuroimage",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_70",
            "content": "Nora Hollenstein, Antonio De La Torre, Nicolas Langer, Ce Zhang, Cognival: A framework for cognitive word embedding evaluation, 2019, Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL), .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    "Nora Hollenstein",
                    "Antonio De La Torre",
                    "Nicolas Langer",
                    "Ce Zhang"
                ],
                "title": "Cognival: A framework for cognitive word embedding evaluation",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_71",
            "content": "G Alexander, Wendy A De Huth,  Heer, L Thomas,  Griffiths, Jack Fr\u00e9d\u00e9ric E Theunissen,  Gallant, Natural speech reveals the semantic maps that tile human cerebral cortex, 2016, Nature, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "G Alexander",
                    "Wendy A De Huth",
                    " Heer",
                    "L Thomas",
                    " Griffiths",
                    "Jack Fr\u00e9d\u00e9ric E Theunissen",
                    " Gallant"
                ],
                "title": "Natural speech reveals the semantic maps that tile human cerebral cortex",
                "pub_date": "2016",
                "pub_title": "Nature",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_72",
            "content": "Shailee Jain, Alexander Huth, Incorporating context into language encoding models for fmri, 2018, Proceedings of the 32nd International Conference on Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Shailee Jain",
                    "Alexander Huth"
                ],
                "title": "Incorporating context into language encoding models for fmri",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 32nd International Conference on Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_73",
            "content": "S Jat,  Tang, T Talukdar,  Mitchel, Relating simple sentence representations in deep neural networks and the brain, 2020, ACL 2019-57th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "S Jat",
                    " Tang",
                    "T Talukdar",
                    " Mitchel"
                ],
                "title": "Relating simple sentence representations in deep neural networks and the brain",
                "pub_date": "2020",
                "pub_title": "ACL 2019-57th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_74",
            "content": "Courtney Tim C Kietzmann,  Spoerer, K Lynn,  S\u00f6rensen, M Radoslaw, Olaf Cichy, Nikolaus Hauk,  Kriegeskorte, Recurrence is required to capture the representational dynamics of the human visual system, 2019, Proceedings of the National Academy of Sciences, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Courtney Tim C Kietzmann",
                    " Spoerer",
                    "K Lynn",
                    " S\u00f6rensen",
                    "M Radoslaw",
                    "Olaf Cichy",
                    "Nikolaus Hauk",
                    " Kriegeskorte"
                ],
                "title": "Recurrence is required to capture the representational dynamics of the human visual system",
                "pub_date": "2019",
                "pub_title": "Proceedings of the National Academy of Sciences",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_75",
            "content": "Nikolaus Kriegeskorte, Pamela Douglas, Interpreting encoding and decoding models, 2019, Current opinion in neurobiology, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Nikolaus Kriegeskorte",
                    "Pamela Douglas"
                ],
                "title": "Interpreting encoding and decoding models",
                "pub_date": "2019",
                "pub_title": "Current opinion in neurobiology",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_76",
            "content": "M Tom, Svetlana Mitchell, Andrew Shinkareva, Kai-Min Carlson, Vicente Chang, Robert Malave, Marcel Mason,  Just, Predicting human brain activity associated with the meanings of nouns, 2008, science, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "M Tom",
                    "Svetlana Mitchell",
                    "Andrew Shinkareva",
                    "Kai-Min Carlson",
                    "Vicente Chang",
                    "Robert Malave",
                    "Marcel Mason",
                    " Just"
                ],
                "title": "Predicting human brain activity associated with the meanings of nouns",
                "pub_date": "2008",
                "pub_title": "science",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_77",
            "content": "Yun-Fei Samuel A Nastase, Hanna Liu,  Hillman, A Kenneth, Uri Norman,  Hasson, Leveraging shared connectivity to aggregate heterogeneous datasets into a common response space, 2020, NeuroImage, .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Yun-Fei Samuel A Nastase",
                    "Hanna Liu",
                    " Hillman",
                    "A Kenneth",
                    "Uri Norman",
                    " Hasson"
                ],
                "title": "Leveraging shared connectivity to aggregate heterogeneous datasets into a common response space",
                "pub_date": "2020",
                "pub_title": "NeuroImage",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_78",
            "content": "Yun-Fei Samuel A Nastase, Hanna Liu, Asieh Hillman, Liat Zadbood, Neggin Hasenfratz, Janice Keshavarzian,  Chen, J Christopher, Yaara Honey,  Yeshurun, Narratives: fmri data for evaluating models of naturalistic language comprehension, , bioRxiv, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "Yun-Fei Samuel A Nastase",
                    "Hanna Liu",
                    "Asieh Hillman",
                    "Liat Zadbood",
                    "Neggin Hasenfratz",
                    "Janice Keshavarzian",
                    " Chen",
                    "J Christopher",
                    "Yaara Honey",
                    " Yeshurun"
                ],
                "title": "Narratives: fmri data for evaluating models of naturalistic language comprehension",
                "pub_date": null,
                "pub_title": "bioRxiv",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_79",
            "content": "Satoshi Nishida, Alexander Huth, L Jack, Shinji Gallant,  Nishimoto, Word statistics in large-scale texts explain the human cortical semantic representation of objects, actions, and impressions, 2015, Society for Neuroscience Annual Meeting, .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Satoshi Nishida",
                    "Alexander Huth",
                    "L Jack",
                    "Shinji Gallant",
                    " Nishimoto"
                ],
                "title": "Word statistics in large-scale texts explain the human cortical semantic representation of objects, actions, and impressions",
                "pub_date": "2015",
                "pub_title": "Society for Neuroscience Annual Meeting",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_80",
            "content": "UNKNOWN, None, 2022, Cross-view brain decoding, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": null,
                "title": null,
                "pub_date": "2022",
                "pub_title": "Cross-view brain decoding",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_81",
            "content": "UNKNOWN, None, 2022, Visio-linguistic brain encoding, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": null,
                "title": null,
                "pub_date": "2022",
                "pub_title": "Visio-linguistic brain encoding",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_82",
            "content": "Naresh Subba Reddy Oota, Raju S Manwani,  Bapi, fmri semantic category decoding using linguistic encoding of word embeddings, 2018, International Conference on Neural Information Processing, Springer.",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Naresh Subba Reddy Oota",
                    "Raju S Manwani",
                    " Bapi"
                ],
                "title": "fmri semantic category decoding using linguistic encoding of word embeddings",
                "pub_date": "2018",
                "pub_title": "International Conference on Neural Information Processing",
                "pub": "Springer"
            }
        },
        {
            "ix": "394-ARR_v2_83",
            "content": "Vijay Subba Reddy Oota, Manish Rowtula, Raju S Gupta,  Bapi, Stepencog: A convolutional lstm autoencoder for near-perfect fmri encoding, 2019, 2019 International Joint Conference on Neural Networks (IJCNN), IEEE.",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": [
                    "Vijay Subba Reddy Oota",
                    "Manish Rowtula",
                    "Raju S Gupta",
                    " Bapi"
                ],
                "title": "Stepencog: A convolutional lstm autoencoder for near-perfect fmri encoding",
                "pub_date": "2019",
                "pub_title": "2019 International Joint Conference on Neural Networks (IJCNN)",
                "pub": "IEEE"
            }
        },
        {
            "ix": "394-ARR_v2_84",
            "content": "Francisco Pereira, Matthew Botvinick, Greg Detre, Using wikipedia to learn semantic feature representations of concrete concepts in neuroimaging experiments, 2013, Artificial intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": [
                    "Francisco Pereira",
                    "Matthew Botvinick",
                    "Greg Detre"
                ],
                "title": "Using wikipedia to learn semantic feature representations of concrete concepts in neuroimaging experiments",
                "pub_date": "2013",
                "pub_title": "Artificial intelligence",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_85",
            "content": "Francisco Pereira, Bin Lou, Brianna Pritchett, Nancy Kanwisher, Matthew Botvinick, Evelina Fedorenko, Decoding of generic mental representations from functional mri data using word embeddings, 2016, bioRxiv, .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Francisco Pereira",
                    "Bin Lou",
                    "Brianna Pritchett",
                    "Nancy Kanwisher",
                    "Matthew Botvinick",
                    "Evelina Fedorenko"
                ],
                "title": "Decoding of generic mental representations from functional mri data using word embeddings",
                "pub_date": "2016",
                "pub_title": "bioRxiv",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_86",
            "content": "Francisco Pereira, Bin Lou, Brianna Pritchett, Samuel Ritter, J Samuel, Nancy Gershman, Matthew Kanwisher, Evelina Botvinick,  Fedorenko, Toward a universal decoder of linguistic meaning from brain activation, 2018, Nature communications, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "Francisco Pereira",
                    "Bin Lou",
                    "Brianna Pritchett",
                    "Samuel Ritter",
                    "J Samuel",
                    "Nancy Gershman",
                    "Matthew Kanwisher",
                    "Evelina Botvinick",
                    " Fedorenko"
                ],
                "title": "Toward a universal decoder of linguistic meaning from brain activation",
                "pub_date": "2018",
                "pub_title": "Nature communications",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_87",
            "content": "F Sara, Alexander Popham, Natalia Huth, Fatma Bilenko,  Deniz, S James,  Gao, O Anwar, Jack Nunez-Elizalde,  Gallant, Visual and linguistic semantic representations are aligned at the border of human visual cortex, 2021, Nature Neuroscience, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": [
                    "F Sara",
                    "Alexander Popham",
                    "Natalia Huth",
                    "Fatma Bilenko",
                    " Deniz",
                    "S James",
                    " Gao",
                    "O Anwar",
                    "Jack Nunez-Elizalde",
                    " Gallant"
                ],
                "title": "Visual and linguistic semantic representations are aligned at the border of human visual cortex",
                "pub_date": "2021",
                "pub_title": "Nature Neuroscience",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_88",
            "content": "D Graeme, Guy Ruxton,  Beauchamp, Time for some a priori thinking about post hoc testing, 2008, Behavioral ecology, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": [
                    "D Graeme",
                    "Guy Ruxton",
                    " Beauchamp"
                ],
                "title": "Time for some a priori thinking about post hoc testing",
                "pub_date": "2008",
                "pub_title": "Behavioral ecology",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_89",
            "content": "UNKNOWN, None, 2021, The neural architecture of language: Integrative reverseengineering converges on a model for predictive processing, PNAS.",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "The neural architecture of language: Integrative reverseengineering converges on a model for predictive processing",
                "pub": "PNAS"
            }
        },
        {
            "ix": "394-ARR_v2_90",
            "content": "Dan Schwartz, Mariya Toneva, Leila Wehbe, Inducing brain-relevant bias in natural language processing models, 2019, Advances in Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": [
                    "Dan Schwartz",
                    "Mariya Toneva",
                    "Leila Wehbe"
                ],
                "title": "Inducing brain-relevant bias in natural language processing models",
                "pub_date": "2019",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_91",
            "content": "Jingyuan Sun, Shaonan Wang, Jiajun Zhang, Chengqing Zong, Towards sentence-level brain decoding with distributed representations, 2019, Proceedings of the AAAI Conference on Artificial Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": [
                    "Jingyuan Sun",
                    "Shaonan Wang",
                    "Jiajun Zhang",
                    "Chengqing Zong"
                ],
                "title": "Towards sentence-level brain decoding with distributed representations",
                "pub_date": "2019",
                "pub_title": "Proceedings of the AAAI Conference on Artificial Intelligence",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_92",
            "content": "Jingyuan Sun, Shaonan Wang, Jiajun Zhang, Chengqing Zong, Neural encoding and decoding with distributed sentence representations, 2020, IEEE Transactions on Neural Networks and Learning Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": [
                    "Jingyuan Sun",
                    "Shaonan Wang",
                    "Jiajun Zhang",
                    "Chengqing Zong"
                ],
                "title": "Neural encoding and decoding with distributed sentence representations",
                "pub_date": "2020",
                "pub_title": "IEEE Transactions on Neural Networks and Learning Systems",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_93",
            "content": "Mariya Toneva, Otilia Stretcu, Barnab\u00e1s P\u00f3czos, Leila Wehbe, Tom M Mitchell, Modeling task effects on meaning representation in the brain via zero-shot meg prediction, 2020, Advances in Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "Mariya Toneva",
                    "Otilia Stretcu",
                    "Barnab\u00e1s P\u00f3czos",
                    "Leila Wehbe",
                    "Tom M Mitchell"
                ],
                "title": "Modeling task effects on meaning representation in the brain via zero-shot meg prediction",
                "pub_date": "2020",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_94",
            "content": "Mariya Toneva, Leila Wehbe, Interpreting and improving processing (in machines) with natural language-processing, 2019, the brain), .",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": [
                    "Mariya Toneva",
                    "Leila Wehbe"
                ],
                "title": "Interpreting and improving processing (in machines) with natural language-processing",
                "pub_date": "2019",
                "pub_title": "the brain)",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_95",
            "content": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Attention is all you need, 2017, Advances in neural information processing systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": [
                    "Ashish Vaswani",
                    "Noam Shazeer",
                    "Niki Parmar",
                    "Jakob Uszkoreit",
                    "Llion Jones",
                    "Aidan Gomez",
                    "\u0141ukasz Kaiser",
                    "Illia Polosukhin"
                ],
                "title": "Attention is all you need",
                "pub_date": "2017",
                "pub_title": "Advances in neural information processing systems",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_96",
            "content": "Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, Samuel Bowman, Glue: A multi-task benchmark and analysis platform for natural language understanding, 2018, Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": [
                    "Alex Wang",
                    "Amanpreet Singh",
                    "Julian Michael",
                    "Felix Hill",
                    "Omer Levy",
                    "Samuel Bowman"
                ],
                "title": "Glue: A multi-task benchmark and analysis platform for natural language understanding",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_97",
            "content": "UNKNOWN, None, 2019, Neural taskonomy: Inferring the similarity of taskderived representations from brain activity. Advances in Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b40",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Neural taskonomy: Inferring the similarity of taskderived representations from brain activity. Advances in Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_98",
            "content": "Jing Wang, L Vladimir, Marcel Cherkassky,  Just, Predicting the brain activation pattern associated with the propositional content of a sentence: Modeling neural representations of events and states, 2017, Human brain mapping, .",
            "ntype": "ref",
            "meta": {
                "xid": "b41",
                "authors": [
                    "Jing Wang",
                    "L Vladimir",
                    "Marcel Cherkassky",
                    " Just"
                ],
                "title": "Predicting the brain activation pattern associated with the propositional content of a sentence: Modeling neural representations of events and states",
                "pub_date": "2017",
                "pub_title": "Human brain mapping",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_99",
            "content": "Shaonan Wang, Jiajun Zhang, Haiyan Wang, Nan Lin, and Chengqing Zong. 2020. Fine-grained neural decoding with distributed word representations, , formation Sciences, .",
            "ntype": "ref",
            "meta": {
                "xid": "b42",
                "authors": [
                    "Shaonan Wang",
                    "Jiajun Zhang",
                    "Haiyan Wang"
                ],
                "title": "Nan Lin, and Chengqing Zong. 2020. Fine-grained neural decoding with distributed word representations",
                "pub_date": null,
                "pub_title": "formation Sciences",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_100",
            "content": "UNKNOWN, None, 2014, Simultaneously uncovering the patterns of brain regions involved in different story reading subprocesses, .",
            "ntype": "ref",
            "meta": {
                "xid": "b43",
                "authors": null,
                "title": null,
                "pub_date": "2014",
                "pub_title": "Simultaneously uncovering the patterns of brain regions involved in different story reading subprocesses",
                "pub": null
            }
        },
        {
            "ix": "394-ARR_v2_101",
            "content": "L Daniel, Ha Yamins,  Hong, F Charles, Ethan Cadieu, Darren Solomon, James J Di-Carlo Seibert, Performance-optimized hierarchical models predict neural responses in higher visual cortex, 2014, Proceedings of the national academy of sciences, .",
            "ntype": "ref",
            "meta": {
                "xid": "b44",
                "authors": [
                    "L Daniel",
                    "Ha Yamins",
                    " Hong",
                    "F Charles",
                    "Ethan Cadieu",
                    "Darren Solomon",
                    "James J Di-Carlo Seibert"
                ],
                "title": "Performance-optimized hierarchical models predict neural responses in higher visual cortex",
                "pub_date": "2014",
                "pub_title": "Proceedings of the national academy of sciences",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "394-ARR_v2_0@0",
            "content": "Neural Language Taskonomy: Which NLP Tasks are the most Predictive of fMRI Brain Activity?",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_0",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_2@0",
            "content": "Several popular Transformer based language models have been found to be successful for text-driven brain encoding.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_2",
            "start": 0,
            "end": 113,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_2@1",
            "content": "However, existing literature leverages only pretrained text Transformer models and has not explored the efficacy of task-specific learned Transformer representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_2",
            "start": 115,
            "end": 280,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_2@2",
            "content": "In this work, we explore transfer learning from representations learned for ten popular natural language processing tasks (two syntactic and eight semantic) for predicting brain responses from two diverse datasets: Pereira (subjects reading sentences from paragraphs) and Narratives (subjects listening to the spoken stories).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_2",
            "start": 282,
            "end": 607,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_2@3",
            "content": "Encoding models based on task features are used to predict activity in different regions across the whole brain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_2",
            "start": 609,
            "end": 720,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_2@4",
            "content": "Features from coreference resolution, NER, and shallow syntax parsing explain greater variance for the reading activity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_2",
            "start": 722,
            "end": 841,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_2@5",
            "content": "On the other hand, for the listening activity, tasks such as paraphrase generation, summarization, and natural language inference show better encoding performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_2",
            "start": 843,
            "end": 1005,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_2@6",
            "content": "Experiments across all 10 task representations provide the following cognitive insights: (i) language left hemisphere has higher predictive brain activity versus language right hemisphere, (ii) posterior medial cortex, temporoparieto-occipital junction, dorsal frontal lobe have higher correlation versus early auditory and auditory association cortex, (iii) syntactic and semantic tasks display a good predictive performance across brain regions for reading and listening stimuli resp.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_2",
            "start": 1007,
            "end": 1492,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_4@0",
            "content": "Brain encoding aims at constructing neural brain activity given an input stimulus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_4",
            "start": 0,
            "end": 81,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_4@1",
            "content": "Since the discovery of the relationship between language stimuli and functions of brain networks using fMRI [for ex., (Constable et al., 2004)], researchers have been interested in understanding how the neural encoding models predict the fMRI brain activity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_4",
            "start": 83,
            "end": 340,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_4@2",
            "content": "Several brain encoding models have been developed to (i) understand the ventral stream in biological vision (Yamins et al., 2014;Kietzmann et al., 2019;Bao et al., 2020), and (ii) to study the higher-level cognition like language processing (Gauthier and Levy, 2019;Schrimpf et al., 2021;Schwartz et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_4",
            "start": 342,
            "end": 652,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_4@3",
            "content": "Some recent studies (Nishida et al., 2015;Huth et al., 2016) have been able to identify brain ROIs (Region of Interest) that respond to words that have a similar meaning and have thus built a \"semantic atlas\" of how the human brain organizes language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_4",
            "start": 654,
            "end": 904,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_4@4",
            "content": "Further, several studies (Oota et al., 2018;Jain and Huth, 2018;Hollenstein et al., 2019) have used a wide variety of word embeddings where words represented as vectors in an embedding space are mapped to brain activation for improved neural coding.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_4",
            "start": 906,
            "end": 1154,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_5@0",
            "content": "Recently, Transformer (Vaswani et al., 2017) based models like BERT (Devlin et al., 2019) have been found to be very effective across a large number of natural language processing (NLP) tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_5",
            "start": 0,
            "end": 191,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_5@1",
            "content": "These Transformer based models have been pretrained on millions of text instances in an unsupervised manner and further finetuned to specialize for various NLP tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_5",
            "start": 193,
            "end": 358,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_5@2",
            "content": "Natural language understanding requires integrating several cognitive skills like syntactic parsing of the language structure, identifying the named entities, capturing the word meaning in the context, coreference resolution, etc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_5",
            "start": 360,
            "end": 589,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_5@3",
            "content": "Learning from massive corpora enables these models to excel at cognitive skills required for language understanding.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_5",
            "start": 591,
            "end": 706,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_5@4",
            "content": "Interestingly, such Transformer-based neural representations have been found to be very effective for brain encoding as well (Schrimpf et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_5",
            "start": 708,
            "end": 856,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_6@0",
            "content": "Despite the recent advances in mapping between language Transformers and the brain activity recorded with reading (Schrimpf et al., 2021), the Transformer features themselves are notoriously difficult to interpret.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_6",
            "start": 0,
            "end": 213,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_6@1",
            "content": "In recent works, Caucheteux et al. (2021a); Antonello et al. (2021) address this issue by disentangling the high-dimensional Transformer representations of language models into four combinatorial classes: lexical, compositional, syntactic, and semantic representations to explore which class is highly associated with language cortical ROIs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_6",
            "start": 215,
            "end": 555,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_6@2",
            "content": "Representations do not exist in a vacuum but become meaningful only when they accomplish a task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_6",
            "start": 557,
            "end": 652,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_6@3",
            "content": "Therefore, the next logical step is to see which of these Transformer representations most effectively drive the linear mapping between language models and the brain in the context of NLP tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_6",
            "start": 654,
            "end": 847,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_6@4",
            "content": "Gauthier and Levy (2019) fine-tune a pretrained BERT model on multiple tasks to find tasks best correlated with high decoding performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_6",
            "start": 849,
            "end": 986,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_6@5",
            "content": "In this study, we investigate the correlation between brain activation and feature representations learned by different task-specific networks, and ask which tasks lead to improvements in brainencoding performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_6",
            "start": 988,
            "end": 1201,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_7@0",
            "content": "Recently, a study using multiple computer vision tasks has shown that 3D vision task models predict better fMRI brain activity than 2D vision task models for visual stimuli.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_7",
            "start": 0,
            "end": 172,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_7@1",
            "content": "Inspired by the success of correlations in the vision field , and brain encoding study of a variety of language Transformer models (Schrimpf et al., 2021;Caucheteux et al., 2021b,a), we build neural language taskonomy models for brain encoding and aim to find NLP tasks that are most explanatory of brain activations for reading and listening tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_7",
            "start": 174,
            "end": 522,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_8@0",
            "content": "In this paper, we uncover insights about the association between fMRI voxel activations and representations of diverse NLP tasks representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_8",
            "start": 0,
            "end": 144,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_8@1",
            "content": "The predictive power of task-specific representations with brain activation is ascertained by (1) using ridge regression on such representations and predicting activations and (2) computing popular metrics like 2V2 accuracy and Pearson correlation between actual and predicted activations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_8",
            "start": 146,
            "end": 434,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_9@0",
            "content": "Specifically, we make the following contributions in this paper.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_9",
            "start": 0,
            "end": 63,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_10@0",
            "content": "\u2022 Given Transformer models finetuned for various NLP tasks, we propose the problem of finding which of these are the most predictive of fMRI brain activity for reading and listening tasks. \u2022 Our language taskonomy results reveal that Coreference Resolution, Named Entity Recognition, and Shallow Syntax Parsing tasks have higher predictive performance while reading the text. On the other hand, paraphrase detection, summarization, and Natural Language Inference tasks display better correlation during listening. \u2022 We also perform similarity analysis between task representations from transfer learning and neural taskonomy and derive interesting cognitive insights from brain maps.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_10",
            "start": 0,
            "end": 682,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_11@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_11",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_12@0",
            "content": "Older methods for text-based stimulus representation include text corpus co-occurrence counts (Mitchell et al., 2008;Pereira et al., 2013;Huth et al., 2016), syntactic and discourse features (Wehbe et al., 2014).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_12",
            "start": 0,
            "end": 211,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_12@1",
            "content": "In recent times, both semantic and experiential attribute models have been explored for text-based stimuli.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_12",
            "start": 213,
            "end": 319,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_12@2",
            "content": "Semantic representation models include distributed word embeddings (Pereira et al., 2016;Anderson et al., 2017a;Pereira et al., 2018;Hollenstein et al., 2019;Wang et al., 2020), sentence representation models (Sun et al., 2019;Sun et al., 2020), recurrent neural networks (Jain and Huth, 2018;Oota et al., 2019), and Transformer-based language models (Gauthier and Levy, 2019;Schwartz et al., 2019;Oota et al., 2022a,b).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_12",
            "start": 321,
            "end": 740,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_12@3",
            "content": "Experiential attribute models represent words in terms of human ratings of their degree of association with different attributes of experience, typically on a scale of 0-6 (Anderson et al., 2019(Anderson et al., , 2020Berezutskaya et al., 2020;Jat et al., 2020;Caucheteux et al., 2021a;Antonello et al., 2021) or binary (Handjaras et al., 2016;Wang et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_12",
            "start": 742,
            "end": 1104,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_12@4",
            "content": "Fine-grained details such as lexical, compositional, syntactic, and semantic representations of narratives are factorized from Transformer-based models and utilized for training encoding models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_12",
            "start": 1106,
            "end": 1299,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_12@5",
            "content": "The resulting models are better able to disentangle the corresponding brain responses in fMRI (Caucheteux et al., 2021a).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_12",
            "start": 1301,
            "end": 1421,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_13@0",
            "content": "In this paper, we focus on Transformer-based linguistic stimuli representations since they have been found to be most effective.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_13",
            "start": 0,
            "end": 127,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_13@1",
            "content": "Unlike previous studies which directly used existing task-agnostic pretrained models, we train task-specific Transformer models and aim to find which model leads to the best encoding accuracy given reading and listening language stimuli.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_13",
            "start": 129,
            "end": 365,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_14@0",
            "content": "Brain Imaging Datasets",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_14",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_15@0",
            "content": "We work with two datasets: Pereira and Narratives-Pieman.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_15",
            "start": 0,
            "end": 56,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_15@1",
            "content": "Results on Narratives-Lucy and Narratives-SlumLord show similar trends.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_15",
            "start": 58,
            "end": 128,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_15@2",
            "content": "Hence, we also show results on Narratives-Lucy and Narratives-SlumLord in the appendix.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_15",
            "start": 130,
            "end": 216,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_15@3",
            "content": "Pereira Dataset (Reading Sentences from Passages) For the Pereira dataset, similar to earlier work (Sun et al., 2019(Sun et al., , 2020, we combine the data from sentence-based experiments (experiments-2 and 3) from Pereira et al. (2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_15",
            "start": 218,
            "end": 455,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_15@4",
            "content": "Five subjects were presented a total of 627 sentences from 48 broad topics, spanning over 168 passages, where each passage consists of 3-4 sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_15",
            "start": 457,
            "end": 605,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_15@5",
            "content": "As in (Pereira et al., 2018)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_15",
            "start": 607,
            "end": 634,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_15@6",
            "content": ", we focused on nine brain ROIs (regions of interest) corresponding to four brain networks: (i) Default Mode Network (DMN) (linked to the functionality of semantic processing), (ii) Language Network (related to language processing, understanding, word meaning, and sentence comprehension), (iii) Task Positive Network (TP) (related to attention, salience information), and (iv) Visual Network (related to the processing of visual objects, object recognition).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_15",
            "start": 635,
            "end": 1093,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_15@7",
            "content": "We briefly summarize the details of the dataset and the number of voxels corresponding to each ROI in Table 1 Narratives-Pieman (Listening to Stories) The \"Narratives\" collection aggregates a variety of fMRI datasets collected while human subjects listened to naturalistic spoken stories.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_15",
            "start": 1095,
            "end": 1382,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_15@8",
            "content": "The Narratives dataset that includes 345 subjects, 891 functional scans, and 27 diverse stories of varying duration totaling \u223c4.6 hours of unique stimuli (\u223c43,000 words) was proposed in (Nastase et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_15",
            "start": 1384,
            "end": 1592,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_15@9",
            "content": "Similar to earlier works (Caucheteux et al., 2021b), we analyze data from 82 subjects listening to the story titled 'PieMan' with 259 TRs (repetition time -fMRI recorded every 1.5 sec.).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_15",
            "start": 1594,
            "end": 1779,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_15@10",
            "content": "We list number of voxels per ROI in this dataset in Table 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_15",
            "start": 1781,
            "end": 1840,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_15@11",
            "content": "We use the multimodal parcellation of the human cerebral cortex (Glassar Atlas: consists of 180 ROIs in each hemisphere) to display the brain maps (Glasser et al., 2016), since Narratives dataset contains annotations tied to this atlas.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_15",
            "start": 1842,
            "end": 2077,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_15@12",
            "content": "The data covers ten brain ROIs in the human brain, i.e., Left hemisphere (L), and Right hemisphere (R) for each of the following: (i) early auditory cortex (EAC: A1, LBelt, MBelt, PBelt, and R1) which plays a key role for sound perception since it represents one of the first cortical processing stations for sounds; (ii) auditory association cortex (AAC: A4, A5, STSdp, STSda, STSvp, STSva, STGa, and TA2) which is concerned with the memory and classification of sounds; (iii) posterior medial cortex (PMC: POS1, POS2, v23ab, d23ab, 31pv, 31pd, 7m); (iv) the temporo parieto occipital junction (TPOJ: TPOJ1, TPOJ2, TPOJ3, STV, PSL) which is a complex brain territory heavily involved in several high-level neurological functions, such as language, visuo-spatial recognition, writing, reading, symbol processing, calculation, self-processing, working memory, musical memory, and face and object recognition; and (v) the dorsal frontal lobe (DFL: L_55b, SFL, L_44, L_45, IFJA, IFSP) which covers the aspects of pragmatic processing such as discourse management, integration of prosody, interpretation of nonliteral meanings, inference making, ambiguity resolution, and error repair.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_15",
            "start": 2079,
            "end": 3259,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_16@0",
            "content": "Encoding Model",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_16",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_17@0",
            "content": "To explore how and where contextual language features are represented in the brain when reading sentences and listening to stories, we extract different features spaces describing each stimulus sentence and use them in an encoding model to predict brain responses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_17",
            "start": 0,
            "end": 263,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_17@1",
            "content": "Our reasoning is as follows.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_17",
            "start": 265,
            "end": 292,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_17@2",
            "content": "If a feature is a good predictor of a specific brain region, information about that feature is likely encoded in that region.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_17",
            "start": 294,
            "end": 418,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_17@3",
            "content": "In this paper, for both datasets, we train fMRI encoding models using Ridge regression on stimuli representations obtained using a variety of NLP tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_17",
            "start": 420,
            "end": 571,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_17@4",
            "content": "The main goal of each fMRI encoder model is to predict brain responses associated with each brain region given a stimuli.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_17",
            "start": 573,
            "end": 693,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_17@5",
            "content": "In all cases, we train a model per subject separately.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_17",
            "start": 695,
            "end": 748,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_17@6",
            "content": "Following literature on brain encoding (Caucheteux et al., 2021b;Toneva et al., 2020), we choose to use a ridge regression model instead of more complicated models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_17",
            "start": 750,
            "end": 913,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_17@7",
            "content": "We plan to explore more such models as part of future work.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_17",
            "start": 915,
            "end": 973,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_17@8",
            "content": "We follow K-fold (K=10) cross-validation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_17",
            "start": 975,
            "end": 1015,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_17@9",
            "content": "All the data samples from K-1 folds were used for training, and the model was tested on samples of the left-out fold.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_17",
            "start": 1017,
            "end": 1133,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_17@10",
            "content": "We used sklearn's ridge-regression with default parameters, 10-fold cross-validation, Stochastic-Average-Gradient Descent Optimizer, Huggingface for Transformer models, MSE loss function, and L2-decay (\u03bb) as 1.0.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_17",
            "start": 1135,
            "end": 1346,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_17@11",
            "content": "We used BERT Word-Piece tokenizer for the linguistic Transformer input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_17",
            "start": 1348,
            "end": 1418,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_17@12",
            "content": "All experiments were conducted on a machine with 1 NVIDIA GEFORCE-GTX GPU with 16GB GPU RAM.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_17",
            "start": 1420,
            "end": 1511,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_17@13",
            "content": "We make the code publicly available 1 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_17",
            "start": 1513,
            "end": 1551,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_18@0",
            "content": "Feature Spaces",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_18",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_19@0",
            "content": "To simultaneously test representations from multiple NLP tasks, we used the latent space features from each of the following ten popular NLP tasks: coreference resolution (CR), named entity recognition (NER), natural language inference (NLI), paraphrase detection (PD), question answering (QA), sentiment analysis (SA), semantic role labeling (SRL), shallow syntax parsing (SS), summarization (Sum) and word sense disambiguation (WSD).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_19",
            "start": 0,
            "end": 434,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_19@1",
            "content": "All of these are discriminative NLP tasks, and thus we use models obtained by task-specific finetuning of the same pretrained Transformer encoder model (BERT-base-cased with dimension-ality=768).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_19",
            "start": 436,
            "end": 630,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_19@2",
            "content": "Given an input sentence, each task Transformer outputs token representations at the final layer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_19",
            "start": 632,
            "end": 727,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_19@3",
            "content": "We use the #tokens \u00d7 768 dimension vector obtained from the last hidden layer to obtain latent features for the stimuli.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_19",
            "start": 729,
            "end": 848,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_19@4",
            "content": "We then build individual ridge regression models with the extracted latent features to predict brain responses and measure the correlation between the prediction and the true response.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_19",
            "start": 850,
            "end": 1033,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_19@5",
            "content": "Pereira: Since individual sentences were presented to the subjects while modeling, sentences were passed one by one to the task Transformer model, and average-pooled representations were used to encode the sentence stimuli.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_19",
            "start": 1035,
            "end": 1257,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_19@6",
            "content": "Narratives-Pieman: Due to the constraint on input sequence length for BERT (512), we considered a window size of 10 sentences with the last two sentences of one window overlapping with the next to be given as input to the BERT model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_19",
            "start": 1259,
            "end": 1491,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_19@7",
            "content": "We use the average-pooled representation from BERT to encode text stimuli.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_19",
            "start": 1493,
            "end": 1566,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_19@8",
            "content": "To get the representation for a TR, we pooled the representations of only those words of the sentences in that TR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_19",
            "start": 1568,
            "end": 1681,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_20@0",
            "content": "Task Descriptions",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_20",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_21@0",
            "content": "Here we describe the functionality of each NLP task that we used for fMRI encoding.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_21",
            "start": 0,
            "end": 82,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_21@1",
            "content": "CR: involves finding all expressions that refer to the same entity in a text.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_21",
            "start": 84,
            "end": 160,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_21@2",
            "content": "PD: involves taking a passage -either spoken or written -and rewording it in shorter or own words.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_21",
            "start": 162,
            "end": 259,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_21@3",
            "content": "Summarization (Sum): involves selecting a few important sentences from a document or paragraph.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_21",
            "start": 261,
            "end": 355,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_21@4",
            "content": "NER: involves detection of the named entities such as person names, location names, company names from a given text.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_21",
            "start": 357,
            "end": 472,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_21@5",
            "content": "NLI: investigates the entailment relationship between two texts: premise and hypothesis.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_21",
            "start": 474,
            "end": 561,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_21@6",
            "content": "QA: aims to select an answer given a passage, a question, and a set of candidate answers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_21",
            "start": 563,
            "end": 651,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_21@7",
            "content": "SA: involves determining whether a piece of text is positive, negative, or neutral.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_21",
            "start": 653,
            "end": 735,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_21@8",
            "content": "SRL: assigns labels to words or phrases in a sentence that indicates their semantic role in the sentence, such as that of an agent, goal, or result.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_21",
            "start": 737,
            "end": 884,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_21@9",
            "content": "SS: provides an approximation of phrase-syntactic structure of sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_21",
            "start": 886,
            "end": 958,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_21@10",
            "content": "WSD: involves determining which sense (meaning) of a word is activated by the use of the word in a particular context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_21",
            "start": 960,
            "end": 1077,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_22@0",
            "content": "Syntactic reasoning is rather shallow compared to deep semantic reasoning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_22",
            "start": 0,
            "end": 73,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_22@1",
            "content": "Syntactic reasoning follows somewhat objective grammar rules.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_22",
            "start": 75,
            "end": 135,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_22@2",
            "content": "Comparatively semantic reasoning is often subjective in nature and complex.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_22",
            "start": 137,
            "end": 211,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_22@3",
            "content": "The emerging evidence from fMRI studies (Fedorenko et al., 2020(Fedorenko et al., , 2012 also points out that processing of both syntax and semantics is distributed in the brain and it is only when violations of these processes are probed, we see localization of function (Friederici et al., 2003).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_22",
            "start": 213,
            "end": 510,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_22@4",
            "content": "Thus, in this work, we explore syntactic and semantic tasks separately.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_22",
            "start": 512,
            "end": 582,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_22@5",
            "content": "Of the above mentioned tasks, NER and SS are syntactic, while the others involve semantic reasoning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_22",
            "start": 584,
            "end": 683,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_23@0",
            "content": "Our selection of these tasks was based on the following design principles: (1) We wanted to select a set of tasks covering diverse cognitive-linguistic skills.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_23",
            "start": 0,
            "end": 158,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_23@1",
            "content": "(2) We wanted to select tasks that are a part of popular NLP benchmarks like GLUE (Wang et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_23",
            "start": 160,
            "end": 261,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_23@2",
            "content": "(3) We selected tasks for which BERT-base-cased finetuned models were available.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_23",
            "start": 263,
            "end": 342,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_23@3",
            "content": "Note that we did not finetune any of these models ourselves but leveraged the state-of-the-art finetuned models available on Huggingface.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_23",
            "start": 344,
            "end": 480,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_23@4",
            "content": "Details of the specific finetuned model checkpoints are mentioned in Table 3 in the Appendix.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_23",
            "start": 482,
            "end": 574,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_24@0",
            "content": "Evaluation Metrics",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_24",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_25@0",
            "content": "We evaluate our models using popular brain encoding evaluation metrics described in the following.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_25",
            "start": 0,
            "end": 97,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_25@1",
            "content": "Given a subject and a brain region, let N be the number of samples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_25",
            "start": 99,
            "end": 165,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_25@2",
            "content": "Let {Y i } N i=1 and { \u0176i } N i=1 denote the actual and predicted voxel value vectors for the i th sample.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_25",
            "start": 167,
            "end": 272,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_25@3",
            "content": "Thus, Y \u2208 R N \u00d7V and \u0176 \u2208 R N \u00d7V where V is the number of voxels in that region.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_25",
            "start": 274,
            "end": 352,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_26@0",
            "content": "Accuracy",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_26",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_27@0",
            "content": "is computed as 2V2Acc= 1 N C 2 N \u22121 i=1 N j=i+1 I[cosD(Y i , \u0176i ) + cosD(Y j , \u0176j ) < cosD(Y i , \u0176j ) + cosD(Y j , \u0176i )]",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_27",
            "start": 0,
            "end": 119,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_28@0",
            "content": "where cosD is the cosine distance function.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_28",
            "start": 0,
            "end": 42,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_28@1",
            "content": "I[c] is an indicator function such that I[c] = 1 if c is true, else it is 0.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_28",
            "start": 44,
            "end": 119,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_28@2",
            "content": "The higher the 2V2 accuracy, the better.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_28",
            "start": 121,
            "end": 160,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_28@3",
            "content": "\u0176i ] where corr is the correlation function.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_28",
            "start": 162,
            "end": 205,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_28@4",
            "content": "Mean Absolute Error (MAE) is computed as",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_28",
            "start": 207,
            "end": 246,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_29@0",
            "content": "Pearson Correlation (PC) is computed as PC= 1 N n i=1 corr[Y i ,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_29",
            "start": 0,
            "end": 63,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_30@0",
            "content": "MAE= 1 N n i=1 |[Y i \u2212 \u0176i ]|.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_30",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_31@0",
            "content": "Statistical Significance: In order to estimate the statistical significance of the performance differences (across all results), we performed one-way ANOVA on the mean values for the subjects.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_31",
            "start": 0,
            "end": 191,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_31@1",
            "content": "In all such cases we report p-values corrected using Bonferroni correction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_31",
            "start": 193,
            "end": 267,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_32@0",
            "content": "Neural Language Tasks Similarity Computation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_32",
            "start": 0,
            "end": 43,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_33@0",
            "content": "To estimate the similarity between 10 language tasks, we took the prediction performance scores across all the voxels in Pereira (97,539) and Narratives-Pieman datasets (10,732).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_33",
            "start": 0,
            "end": 177,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_33@1",
            "content": "To analyze the relationship between tasks based on neural representations, we calculated the Pearson correlation between predicted voxels of each task with the remaining tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_33",
            "start": 179,
            "end": 354,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_33@2",
            "content": "These Pearson correlation values were used to construct heatmaps and the task similarity trees(dendograms) using hierarchical clustering for Pereira and Narratives-Pieman datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_33",
            "start": 356,
            "end": 535,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_34@0",
            "content": "Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_34",
            "start": 0,
            "end": 6,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_35@0",
            "content": "In order to assess the performance of the fMRI encoder models learned using the representations from a variety of NLP tasks, we computed the 2V2 accuracy and Pearson correlation coefficient between the predicted and true responses across various ROIs for both the reading (Pereira) dataset (Fig. 1) as well as the listening (Narratives-Pieman) dataset (Fig. 2).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_35",
            "start": 0,
            "end": 360,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_36@0",
            "content": "Encoding performance of Language Task models for reading vs listening tasks",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_36",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_37@0",
            "content": "Reading Sentences (Pereira): From Fig. 1, we observe that tasks such as CR, NER, SRL, and SS appear to have a better correlation to the brain responses compared to the other tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_37",
            "start": 0,
            "end": 179,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_37@1",
            "content": "In order to estimate the statistical significance of the performance differences, we performed one-way ANOVA on the mean correlation values for the subjects across the ten language tasks for the nine brain ROIs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_37",
            "start": 181,
            "end": 391,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_37@2",
            "content": "The main effect of the ANOVA test was significant for all the ROIs with p\u2264 10 \u22122 with confidence 95% (see Appendix for detailed ANOVA results).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_37",
            "start": 393,
            "end": 535,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_37@3",
            "content": "Further, post hoc pairwise comparisons (Ruxton and Beauchamp, 2008) confirmed the visual observations that on both 2V2 accuracy and Pearson correlation measures, tasks such as CR, NER, SRL, and SS performed significantly better compared to other tasks (see Appendix for pairwise comparison results).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_37",
            "start": 537,
            "end": 835,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_37@4",
            "content": "These results demonstrate that when reading a sentence, information processing operations related to recognizing named entities, labeling semantic roles to the constituents of a sentence, identifying the references from a sentence to the given topic (concept), and syntactic processing may be engaged.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_37",
            "start": 837,
            "end": 1137,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_37@5",
            "content": "Further, we observe that the ROI corresponding to language processing in the left hemisphere (Lan-guage_LH) has higher encoding performance than that of the right hemisphere (Language_RH).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_37",
            "start": 1139,
            "end": 1326,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_37@6",
            "content": "This is in line with the left hemisphere dominance for language processing (Binder et al., 2009).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_37",
            "start": 1328,
            "end": 1424,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_37@7",
            "content": "Also, lateral visual ROIs such as Vision_Object, Vi-sion_Body, Vision_Face, and Vision ROIs display higher correlation with the language tasks associated with named entities (NER), relating the entities (CR), and syntax processing (SS).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_37",
            "start": 1426,
            "end": 1661,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_37@8",
            "content": "Higher correlations with all the visual brain regions point to the possible alignment of visual and language regions for semantic understanding (Popham et al., 2021) in a reading task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_37",
            "start": 1663,
            "end": 1846,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_37@9",
            "content": "Finally, across all regions, pretrained BERT model has worse correlation compared to at least 5 other task models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_37",
            "start": 1848,
            "end": 1961,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_37@10",
            "content": "Listening Stories (Narratives-Pieman): From Fig. 2, we observe that the profiles of performance show low scores in the early auditory cortex (EAC), auditory association cortex (AAC); average scores in TPOJ and DFL; and superior scores in PMC.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_37",
            "start": 1963,
            "end": 2204,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_37@11",
            "content": "This aligns with the known language hierarchy for spoken language understanding (Nastase et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_37",
            "start": 2206,
            "end": 2308,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_37@12",
            "content": "Tasks such as PD, Summarization, and NLI seem to yield better performance in predicting the brain responses than the other NLP tasks across all the ROIs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_37",
            "start": 2310,
            "end": 2462,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_37@13",
            "content": "These Pearson correlation (\u03c4 ) results are comparatively much higher compared to those obtained using pretrained (task-agnostic) GPT2 model in (Caucheteux et al., 2021a) (\u03c4 ranging from 0.02 \u2212 0.06).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_37",
            "start": 2464,
            "end": 2662,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_37@14",
            "content": "As shown in Fig. 2, our method obtains much higher correlations (\u03c4 ranging from 0.02 \u2212 0.229).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_37",
            "start": 2664,
            "end": 2757,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_37@15",
            "content": "Similar to the Pereira dataset, we estimate the statistical significance of the performance differences using the one-way ANOVA test.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_37",
            "start": 2759,
            "end": 2891,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_37@16",
            "content": "The main effect of task was significant for all the ROIs with p\u2264 10 \u22123 with confidence 95% (see Appendix for detailed ANOVA results).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_37",
            "start": 2893,
            "end": 3025,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_37@17",
            "content": "Also, Post hoc pairwise comparisons (Ruxton and Beauchamp, 2008) revealed that on both 2V2 accuracy and Pearson correlation measures, tasks such as PD, Sum, and NLI performed significantly better compared to other tasks (see Appendix for pairwise comparison results).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_37",
            "start": 3027,
            "end": 3293,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_38@0",
            "content": "Further, from Fig. 2, we see that the bilateral posterior medial cortex (PMC) associated with higher language function exhibits a higher correlation among all the brain ROIs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_38",
            "start": 0,
            "end": 173,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_38@1",
            "content": "ROIs, including bilateral TPOJ and bilateral DFL, yield higher correlations with the five NLP tasks, which is in line with the language processing hierarchy in the human brain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_38",
            "start": 175,
            "end": 350,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_38@2",
            "content": "Finally, across all regions, pretrained BERT model has worse correlation compared to at least 5 other task models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_38",
            "start": 352,
            "end": 465,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_39@0",
            "content": "In summary, different and distinct language Taskonomy features seem to be related to the encoding performance in reading versus listening tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_39",
            "start": 0,
            "end": 143,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_39@1",
            "content": "CR, NER, SRL, and SS perform better for reading.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_39",
            "start": 145,
            "end": 192,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_39@2",
            "content": "PD, Sum, and NLI perform better for listening.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_39",
            "start": 194,
            "end": 239,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_39@3",
            "content": "While listening the subject is cognitively more involved in the activity compared to reading (Buchweitz et al., 2009).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_39",
            "start": 241,
            "end": 358,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_39@4",
            "content": "Thus, it makes sense that shallow tasks like NER and SS are useful for reading while more complex NLP tasks like PD, Sum and NLI are effective for encoding listening stimuli.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_39",
            "start": 360,
            "end": 533,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_40@0",
            "content": "Language Task Similarity Computation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_40",
            "start": 0,
            "end": 35,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_41@0",
            "content": "Pearson correlation values between predicted responses for each pair of tasks were used to construct the similarity matrix with heatmap for both Pereira and Narratives-Pieman datasets, as shown in Figs. 3 and 4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_41",
            "start": 0,
            "end": 210,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_41@1",
            "content": "We observe that the following task pairs are highly correlated for the Pereira dataset: (NER and CR), (SS and CR) and (PD and Sum).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_41",
            "start": 212,
            "end": 342,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_41@2",
            "content": "Also these task pairs are highly correlated for the Narratives-Pieman dataset: (CR and NLI), (NLI and SA) and (PD and Sum).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_41",
            "start": 344,
            "end": 466,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_41@3",
            "content": "Similarities are relatively higher for Narratives-Pieman compared to the Pereira dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_41",
            "start": 468,
            "end": 556,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_41@4",
            "content": "Surprisingly, the (NLI, SA) pair has lowest similarity for Pereira (reading) and close to highest in Narratives-Pieman (listening).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_41",
            "start": 558,
            "end": 688,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_41@5",
            "content": "We hypothesize that this is because sentiment is best conveyed while the subject is listening.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_41",
            "start": 690,
            "end": 783,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_41@6",
            "content": "Reading sentences (Pereira): The stimulus sentences from the Pereira dataset were fed as input to each of the 10 task Transformers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_41",
            "start": 785,
            "end": 915,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_41@7",
            "content": "The similarity among the resulting representations was analyzed using hierarchical clustering, and the clusters are visualized as dendrograms in Fig. 5 (left).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_41",
            "start": 917,
            "end": 1075,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_41@8",
            "content": "We observe that the tasks are clustered into three groups denoted using red, green, and blue colors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_41",
            "start": 1077,
            "end": 1176,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_41@9",
            "content": "Next, we wished to check if similar task grouping is observed on brain activations predicted by ridge regression trained on task-specific representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_41",
            "start": 1178,
            "end": 1331,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_41@10",
            "content": "Hence, similar clustering analysis was conducted on the neural space representations, and the clusters are visualized as dendrograms in Fig. 5 (right) across all subjects.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_41",
            "start": 1333,
            "end": 1503,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_41@11",
            "content": "Interestingly, the tree derived from brain representation also shows a similar distribution of tasks across the three groups.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_41",
            "start": 1505,
            "end": 1629,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_41@12",
            "content": "Similar dendrograms for individual subjects are illustrated in Appendix-Fig.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_41",
            "start": 1631,
            "end": 1706,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_41@13",
            "content": "11.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_41",
            "start": 1708,
            "end": 1710,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_41@14",
            "content": "Listening Stories (Narratives-Pieman): Fig. 6 compares the task similarity tree based on the patterns from the pretrained task Transformers, with the task similarity tree generated based on similarity in brain response prediction performance averaged across all subjects.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_41",
            "start": 1712,
            "end": 1982,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_41@15",
            "content": "We observe that the tasks are clustered into three groups denoted using red, green, and blue colors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_41",
            "start": 1984,
            "end": 2083,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_41@16",
            "content": "Again, the tree derived from brain representation also shows a similar distribution of tasks across the three groups.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_41",
            "start": 2085,
            "end": 2201,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_41@17",
            "content": "Dendrograms for individual subjects are in the Appendix-Fig.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_41",
            "start": 2203,
            "end": 2262,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_41@18",
            "content": "12.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_41",
            "start": 2264,
            "end": 2266,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_42@0",
            "content": "Brain maps for whole brain predictions",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_42",
            "start": 0,
            "end": 37,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_43@0",
            "content": "The mean absolute error (MAE) between predictive and actual responses is obtained using individual task features from the taskonomy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_43",
            "start": 0,
            "end": 131,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_43@1",
            "content": "MAE values are obtained for all the voxels in the brain for both the reading (Fig. 7) and listening datasets (Fig. 8).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_43",
            "start": 133,
            "end": 250,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_44@0",
            "content": "In the reading task, we observe from Fig. 7 that CR has lower MAE compared to PD which in turn has lower MAE compared to the NLI task (brain maps for the other tasks are reported in Fig. 17 in the Appendix).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_44",
            "start": 0,
            "end": 206,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_44@1",
            "content": "Overall, for the reading stimuli, tasks such as NLI, QA, and SA display higher MAE values.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_44",
            "start": 208,
            "end": 297,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_44@2",
            "content": "To further investigate which sub ROIs (LPTG, LMTG, LATG, LFus, Lpar, Lang, LIFGorb, LIFG, LaMFG, LpMFG, and LmMFG) of the Language network are related to the predictive task features, we train encoding models for all the sub ROIs for the best encoding task, i.e., for the CR task (see Fig. 14 in Appendix).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_44",
            "start": 299,
            "end": 604,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_44@3",
            "content": "We notice that both LMTG (middle temporal gyrus) and LPTG (posterior temporal gyrus) are more accurately predicted than the other sub ROIs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_44",
            "start": 606,
            "end": 744,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_44@4",
            "content": "On the other hand, LIFG-orb displays a lower Pearson correlation for the CR task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_44",
            "start": 746,
            "end": 826,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_44@5",
            "content": "The presence of superior encoding information in the ROIs in the temporal gyrus as compared to those in the inferior frontal gyrus seems to mirror similar observations seen in decoder performance (Anderson et al., 2017b).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_44",
            "start": 828,
            "end": 1048,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_45@0",
            "content": "On the other hand, in the listening task, we observe from Fig. 8 that Paraphrase and WSD display lower MAE values compared to QA task (brain maps for the other tasks are reported in Fig. 18 in the Appendix).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_45",
            "start": 0,
            "end": 206,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_45@1",
            "content": "Taken together, for listening stimuli, tasks such as NER, QA, SA, CR, and SS display higher MAE values.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_45",
            "start": 208,
            "end": 310,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_45@2",
            "content": "From Fig. 8, we see that ROIs such as EAC and AAC have higher MAE compared to PMC and TPOJ brain ROIs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_45",
            "start": 312,
            "end": 413,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_46@0",
            "content": "We further demonstrate the prediction performance of the encoder model trained on sub ROIs for the paraphrase task in Fig. 15 in the Appendix. It can be observed that sub ROIs such as Pos1 and Pos2 have a higher Pearson correlation than other sub ROIs of the PMC region.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_46",
            "start": 0,
            "end": 269,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_46@1",
            "content": "Both sfl and l55b display a higher correlation among all the sub ROIs for the DFL ROI.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_46",
            "start": 271,
            "end": 356,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_46@2",
            "content": "However, all the sub ROIs in the TPOJ yield higher correlation, as shown in Fig. 15.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_46",
            "start": 358,
            "end": 441,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_46@3",
            "content": "The control and attention ROIs in the posterior cingulate cortex (for ex., POS1 in PMC), together with the superior frontal language region (sfl in DFL) and TPOJ, are part of the well-known language network associated with narrative comprehension (Nastase et al., 2020), and it is heartening to see that task features from PD task also relate to semantic analysis of the ongoing narrative.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_46",
            "start": 443,
            "end": 831,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_47@0",
            "content": "Discussion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_47",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_48@0",
            "content": "(1) We used a ridge regression model instead of more complicated models for encoding.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_48",
            "start": 0,
            "end": 84,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_48@1",
            "content": "We believe that more complex models can lead to further exciting insights.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_48",
            "start": 86,
            "end": 159,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_48@2",
            "content": "(2) We experimented with 10 NLP tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_48",
            "start": 161,
            "end": 198,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_48@3",
            "content": "Models can be pretrained for more such tasks to check if other tasks are better predictive of voxel activations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_48",
            "start": 200,
            "end": 311,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_48@4",
            "content": "tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_48",
            "start": 313,
            "end": 318,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_48@5",
            "content": "While a fair comparison of dataset sizes across tasks is impossible, we understand that this could have resulted in some bias in our results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_48",
            "start": 320,
            "end": 460,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_49@0",
            "content": "(4) We used a different dataset for reading vs listening.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_49",
            "start": 0,
            "end": 56,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_49@1",
            "content": "While we believe that the differences in task-specific model performances across reading and listening are mainly due to the learned stimulus representations, but they could also arise from other factors such as experimental conditions, the text domain of the stimuli or number of voxels, etc. (5) On Natural Language Understanding tasks such as NLI, SA, QA and PD, Gauthier and Levy (2019) observed that scrambled sentence representations gave better decoding performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_49",
            "start": 58,
            "end": 530,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_49@2",
            "content": "But encoding models (especially for the listening task), scrambled order would be detrimental to making sense of what is being heard.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_49",
            "start": 532,
            "end": 664,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_49@3",
            "content": "It is an interesting future task to see if the opposite result is seen in the case of brain encoding models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_49",
            "start": 666,
            "end": 773,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_49@4",
            "content": "It is plausible that brain uses encoding models in a flexible way when it comes to decoding (Kriegeskorte and Douglas, 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_49",
            "start": 775,
            "end": 899,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_49@5",
            "content": "Kriegeskorte and Douglas (2019) mention that \"Decoding models can help reveal whether particular information is present in a brain region in a format the decoder can exploit. Encoding models make comprehensive predictions about representational spaces.\"",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_49",
            "start": 901,
            "end": 1153,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_49@6",
            "content": "In this sense, results of current work are not directly comparable to those of Gauthier and Levy (2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_49",
            "start": 1155,
            "end": 1258,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_50@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_50",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_51@0",
            "content": "In this paper, we studied the effectiveness of task specific NLP models for brain encoding.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_51",
            "start": 0,
            "end": 90,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_51@1",
            "content": "We observe that building individual encoding models and exploiting existing relationships among models can provide a more in-depth understanding of the neural representation of language information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_51",
            "start": 92,
            "end": 289,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_51@2",
            "content": "Our experiments on Pereira and Narrative datasets lead to interesting cognitive insights.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_51",
            "start": 291,
            "end": 379,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_52@0",
            "content": "A Details of the Finetuned Models",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_52",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_53@0",
            "content": "We selected tasks for which BERT-base-cased finetuned models were available.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_53",
            "start": 0,
            "end": 75,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_53@1",
            "content": "Note that we did not finetune any of these models ourselves but leveraged the state-of-the-art finetuned models available on Huggingface.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_53",
            "start": 77,
            "end": 213,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_53@2",
            "content": "Details of the specific finetuned model checkpoints are mentioned in Table 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_53",
            "start": 215,
            "end": 291,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_54@0",
            "content": "B ANOVA test results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_54",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_55@0",
            "content": "The main effect of model was significant for the ROIs with 95% confidence with these statistics:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_55",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_56@0",
            "content": "\u2022 The main effect of model was significant for the ROIs with 95% confidence with these statistics: \u2022 EAC_L [F(9,810)=3.88, p=.00009] \u2022 EAC_R [F(9,810)=3.34, p=.00055] \u2022 AAC_L [F(9,810)=5.37, p=.0000007] \u2022 AAC_R [F(9,810)=6.955, p=.00000] \u2022 PMC_L [F(9,810)=37.21, p=.00000] \u2022 PMC_R [F(9,810)=31.62, p=.00000] \u2022 TPOJ_L [F(9,810)=9.166, p=.00000] \u2022 TPOJ_R [F(9,810)=7.797, p=.00000] \u2022 DFL_L [F(9,810)=12.445, p=.00000] \u2022 DFL_R [F(9,810)=12.27, p=.00000]",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_56",
            "start": 0,
            "end": 449,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_57@0",
            "content": "F Nick,  Ramsey, 2020. Cortical network responses map onto data-driven features that capture visual semantics of movie fragments, , Scientific reports, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_57",
            "start": 0,
            "end": 152,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_58@0",
            "content": "R Jeffrey,  Binder, H Rutvik, William Desai, Lisa Graves,  Conant, Where is the semantic system? a critical review and meta-analysis of 120 functional neuroimaging studies, 2009, Cerebral cortex, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_58",
            "start": 0,
            "end": 196,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_59@0",
            "content": "Augusto Buchweitz, A Robert, L\u00eada Mason, Marcel Tomitch,  Just, Brain activation for reading and listening comprehension: An fmri study of modality effects and individual differences in language comprehension, 2009, Psychology & neuroscience, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_59",
            "start": 0,
            "end": 243,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_60@0",
            "content": "Charlotte Caucheteux, Alexandre Gramfort, Jean-Remi King, Disentangling syntax and semantics in the brain with deep networks, 2021, International Conference on Machine Learning, PMLR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_60",
            "start": 0,
            "end": 182,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_61@0",
            "content": "UNKNOWN, None, 2021, Model-based analysis of brain activity reveals the hierarchy of language in 305 subjects, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_61",
            "start": 0,
            "end": 111,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_62@0",
            "content": "Todd Constable, R Kenneth, Ella Pugh, Einar Berroya, Michael Mencl, Weijia Westerveld, Donald Ni,  Shankweiler, Sentence complexity and input modality effects in sentence comprehension: an fmri study, 2004, NeuroImage, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_62",
            "start": 0,
            "end": 219,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_63@0",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, Bert: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_63",
            "start": 0,
            "end": 294,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_64@0",
            "content": "Evelina Fedorenko, Asher Idan, Matthew Blank, Zachary Siegelman,  Mineroff, Lack of selectivity for syntax relative to word meanings throughout the language network, 2020, Cognition, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_64",
            "start": 0,
            "end": 183,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_65@0",
            "content": "Evelina Fedorenko, Alfonso Nieto-Castanon, Nancy Kanwisher, Lexical and syntactic representations in the brain: an fmri investigation with multivoxel pattern analyses, 2012, Neuropsychologia, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_65",
            "start": 0,
            "end": 192,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_66@0",
            "content": "D Angela, Shirley-Ann Friederici, Anja R\u00fcschemeyer, Christian Hahne,  Fiebach, The role of left inferior frontal and superior temporal cortex in sentence comprehension: localizing syntactic and semantic processes, 2003, Cerebral cortex, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_66",
            "start": 0,
            "end": 237,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_67@0",
            "content": "Jon Gauthier, Roger Levy, Linking artificial and human neural representations of language, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_67",
            "start": 0,
            "end": 274,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_68@0",
            "content": "F Matthew, Timothy Glasser, Emma Coalson, Carl Robinson, John Hacker, Essa Harwell, Kamil Yacoub, Jesper Ugurbil,  Andersson, F Christian, Mark Beckmann,  Jenkinson, A multimodal parcellation of human cerebral cortex, 2016, Nature, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_68",
            "start": 0,
            "end": 232,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_69@0",
            "content": "Giacomo Handjaras, Emiliano Ricciardi, Andrea Leo, Alessandro Lenci, Luca Cecchetti, Mirco Cosottini, Giovanna Marotta, Pietro Pietrini, How concepts are encoded in the human brain: a modality independent, category-based cortical organization of semantic knowledge, 2016, Neuroimage, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_69",
            "start": 0,
            "end": 284,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_70@0",
            "content": "Nora Hollenstein, Antonio De La Torre, Nicolas Langer, Ce Zhang, Cognival: A framework for cognitive word embedding evaluation, 2019, Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_70",
            "start": 0,
            "end": 221,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_71@0",
            "content": "G Alexander, Wendy A De Huth,  Heer, L Thomas,  Griffiths, Jack Fr\u00e9d\u00e9ric E Theunissen,  Gallant, Natural speech reveals the semantic maps that tile human cerebral cortex, 2016, Nature, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_71",
            "start": 0,
            "end": 185,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_72@0",
            "content": "Shailee Jain, Alexander Huth, Incorporating context into language encoding models for fmri, 2018, Proceedings of the 32nd International Conference on Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_72",
            "start": 0,
            "end": 189,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_73@0",
            "content": "S Jat,  Tang, T Talukdar,  Mitchel, Relating simple sentence representations in deep neural networks and the brain, 2020, ACL 2019-57th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_73",
            "start": 0,
            "end": 232,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_74@0",
            "content": "Courtney Tim C Kietzmann,  Spoerer, K Lynn,  S\u00f6rensen, M Radoslaw, Olaf Cichy, Nikolaus Hauk,  Kriegeskorte, Recurrence is required to capture the representational dynamics of the human visual system, 2019, Proceedings of the National Academy of Sciences, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_74",
            "start": 0,
            "end": 256,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_75@0",
            "content": "Nikolaus Kriegeskorte, Pamela Douglas, Interpreting encoding and decoding models, 2019, Current opinion in neurobiology, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_75",
            "start": 0,
            "end": 121,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_76@0",
            "content": "M Tom, Svetlana Mitchell, Andrew Shinkareva, Kai-Min Carlson, Vicente Chang, Robert Malave, Marcel Mason,  Just, Predicting human brain activity associated with the meanings of nouns, 2008, science, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_76",
            "start": 0,
            "end": 199,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_77@0",
            "content": "Yun-Fei Samuel A Nastase, Hanna Liu,  Hillman, A Kenneth, Uri Norman,  Hasson, Leveraging shared connectivity to aggregate heterogeneous datasets into a common response space, 2020, NeuroImage, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_77",
            "start": 0,
            "end": 194,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_78@0",
            "content": "Yun-Fei Samuel A Nastase, Hanna Liu, Asieh Hillman, Liat Zadbood, Neggin Hasenfratz, Janice Keshavarzian,  Chen, J Christopher, Yaara Honey,  Yeshurun, Narratives: fmri data for evaluating models of naturalistic language comprehension, , bioRxiv, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_78",
            "start": 0,
            "end": 247,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_79@0",
            "content": "Satoshi Nishida, Alexander Huth, L Jack, Shinji Gallant,  Nishimoto, Word statistics in large-scale texts explain the human cortical semantic representation of objects, actions, and impressions, 2015, Society for Neuroscience Annual Meeting, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_79",
            "start": 0,
            "end": 242,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_80@0",
            "content": "UNKNOWN, None, 2022, Cross-view brain decoding, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_80",
            "start": 0,
            "end": 48,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_81@0",
            "content": "UNKNOWN, None, 2022, Visio-linguistic brain encoding, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_81",
            "start": 0,
            "end": 54,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_82@0",
            "content": "Naresh Subba Reddy Oota, Raju S Manwani,  Bapi, fmri semantic category decoding using linguistic encoding of word embeddings, 2018, International Conference on Neural Information Processing, Springer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_82",
            "start": 0,
            "end": 199,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_83@0",
            "content": "Vijay Subba Reddy Oota, Manish Rowtula, Raju S Gupta,  Bapi, Stepencog: A convolutional lstm autoencoder for near-perfect fmri encoding, 2019, 2019 International Joint Conference on Neural Networks (IJCNN), IEEE.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_83",
            "start": 0,
            "end": 211,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_84@0",
            "content": "Francisco Pereira, Matthew Botvinick, Greg Detre, Using wikipedia to learn semantic feature representations of concrete concepts in neuroimaging experiments, 2013, Artificial intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_84",
            "start": 0,
            "end": 189,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_85@0",
            "content": "Francisco Pereira, Bin Lou, Brianna Pritchett, Nancy Kanwisher, Matthew Botvinick, Evelina Fedorenko, Decoding of generic mental representations from functional mri data using word embeddings, 2016, bioRxiv, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_85",
            "start": 0,
            "end": 208,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_86@0",
            "content": "Francisco Pereira, Bin Lou, Brianna Pritchett, Samuel Ritter, J Samuel, Nancy Gershman, Matthew Kanwisher, Evelina Botvinick,  Fedorenko, Toward a universal decoder of linguistic meaning from brain activation, 2018, Nature communications, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_86",
            "start": 0,
            "end": 239,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_87@0",
            "content": "F Sara, Alexander Popham, Natalia Huth, Fatma Bilenko,  Deniz, S James,  Gao, O Anwar, Jack Nunez-Elizalde,  Gallant, Visual and linguistic semantic representations are aligned at the border of human visual cortex, 2021, Nature Neuroscience, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_87",
            "start": 0,
            "end": 242,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_88@0",
            "content": "D Graeme, Guy Ruxton,  Beauchamp, Time for some a priori thinking about post hoc testing, 2008, Behavioral ecology, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_88",
            "start": 0,
            "end": 116,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_89@0",
            "content": "UNKNOWN, None, 2021, The neural architecture of language: Integrative reverseengineering converges on a model for predictive processing, PNAS.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_89",
            "start": 0,
            "end": 141,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_90@0",
            "content": "Dan Schwartz, Mariya Toneva, Leila Wehbe, Inducing brain-relevant bias in natural language processing models, 2019, Advances in Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_90",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_91@0",
            "content": "Jingyuan Sun, Shaonan Wang, Jiajun Zhang, Chengqing Zong, Towards sentence-level brain decoding with distributed representations, 2019, Proceedings of the AAAI Conference on Artificial Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_91",
            "start": 0,
            "end": 199,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_92@0",
            "content": "Jingyuan Sun, Shaonan Wang, Jiajun Zhang, Chengqing Zong, Neural encoding and decoding with distributed sentence representations, 2020, IEEE Transactions on Neural Networks and Learning Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_92",
            "start": 0,
            "end": 195,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_93@0",
            "content": "Mariya Toneva, Otilia Stretcu, Barnab\u00e1s P\u00f3czos, Leila Wehbe, Tom M Mitchell, Modeling task effects on meaning representation in the brain via zero-shot meg prediction, 2020, Advances in Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_93",
            "start": 0,
            "end": 225,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_94@0",
            "content": "Mariya Toneva, Leila Wehbe, Interpreting and improving processing (in machines) with natural language-processing, 2019, the brain), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_94",
            "start": 0,
            "end": 132,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_95@0",
            "content": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Attention is all you need, 2017, Advances in neural information processing systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_95",
            "start": 0,
            "end": 203,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_96@0",
            "content": "Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, Samuel Bowman, Glue: A multi-task benchmark and analysis platform for natural language understanding, 2018, Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_96",
            "start": 0,
            "end": 279,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_97@0",
            "content": "UNKNOWN, None, 2019, Neural taskonomy: Inferring the similarity of taskderived representations from brain activity. Advances in Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_97",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_98@0",
            "content": "Jing Wang, L Vladimir, Marcel Cherkassky,  Just, Predicting the brain activation pattern associated with the propositional content of a sentence: Modeling neural representations of events and states, 2017, Human brain mapping, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_98",
            "start": 0,
            "end": 227,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_99@0",
            "content": "Shaonan Wang, Jiajun Zhang, Haiyan Wang, Nan Lin, and Chengqing Zong. 2020. Fine-grained neural decoding with distributed word representations, , formation Sciences, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_99",
            "start": 0,
            "end": 166,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_100@0",
            "content": "UNKNOWN, None, 2014, Simultaneously uncovering the patterns of brain regions involved in different story reading subprocesses, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_100",
            "start": 0,
            "end": 127,
            "label": {}
        },
        {
            "ix": "394-ARR_v2_101@0",
            "content": "L Daniel, Ha Yamins,  Hong, F Charles, Ethan Cadieu, Darren Solomon, James J Di-Carlo Seibert, Performance-optimized hierarchical models predict neural responses in higher visual cortex, 2014, Proceedings of the national academy of sciences, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "394-ARR_v2_101",
            "start": 0,
            "end": 242,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "394-ARR_v2_0",
            "tgt_ix": "394-ARR_v2_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_0",
            "tgt_ix": "394-ARR_v2_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_1",
            "tgt_ix": "394-ARR_v2_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_1",
            "tgt_ix": "394-ARR_v2_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_0",
            "tgt_ix": "394-ARR_v2_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_2",
            "tgt_ix": "394-ARR_v2_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_4",
            "tgt_ix": "394-ARR_v2_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_5",
            "tgt_ix": "394-ARR_v2_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_6",
            "tgt_ix": "394-ARR_v2_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_7",
            "tgt_ix": "394-ARR_v2_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_8",
            "tgt_ix": "394-ARR_v2_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_9",
            "tgt_ix": "394-ARR_v2_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_3",
            "tgt_ix": "394-ARR_v2_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_3",
            "tgt_ix": "394-ARR_v2_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_3",
            "tgt_ix": "394-ARR_v2_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_3",
            "tgt_ix": "394-ARR_v2_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_3",
            "tgt_ix": "394-ARR_v2_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_3",
            "tgt_ix": "394-ARR_v2_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_3",
            "tgt_ix": "394-ARR_v2_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_3",
            "tgt_ix": "394-ARR_v2_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_0",
            "tgt_ix": "394-ARR_v2_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_12",
            "tgt_ix": "394-ARR_v2_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_11",
            "tgt_ix": "394-ARR_v2_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_11",
            "tgt_ix": "394-ARR_v2_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_11",
            "tgt_ix": "394-ARR_v2_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_0",
            "tgt_ix": "394-ARR_v2_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_13",
            "tgt_ix": "394-ARR_v2_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_14",
            "tgt_ix": "394-ARR_v2_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_14",
            "tgt_ix": "394-ARR_v2_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_0",
            "tgt_ix": "394-ARR_v2_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_15",
            "tgt_ix": "394-ARR_v2_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_16",
            "tgt_ix": "394-ARR_v2_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_16",
            "tgt_ix": "394-ARR_v2_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_16",
            "tgt_ix": "394-ARR_v2_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_17",
            "tgt_ix": "394-ARR_v2_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_18",
            "tgt_ix": "394-ARR_v2_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_18",
            "tgt_ix": "394-ARR_v2_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_16",
            "tgt_ix": "394-ARR_v2_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_19",
            "tgt_ix": "394-ARR_v2_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_21",
            "tgt_ix": "394-ARR_v2_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_22",
            "tgt_ix": "394-ARR_v2_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_20",
            "tgt_ix": "394-ARR_v2_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_20",
            "tgt_ix": "394-ARR_v2_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_20",
            "tgt_ix": "394-ARR_v2_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_20",
            "tgt_ix": "394-ARR_v2_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_16",
            "tgt_ix": "394-ARR_v2_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_23",
            "tgt_ix": "394-ARR_v2_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_24",
            "tgt_ix": "394-ARR_v2_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_24",
            "tgt_ix": "394-ARR_v2_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_26",
            "tgt_ix": "394-ARR_v2_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_27",
            "tgt_ix": "394-ARR_v2_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_28",
            "tgt_ix": "394-ARR_v2_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_29",
            "tgt_ix": "394-ARR_v2_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_30",
            "tgt_ix": "394-ARR_v2_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_24",
            "tgt_ix": "394-ARR_v2_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_24",
            "tgt_ix": "394-ARR_v2_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_24",
            "tgt_ix": "394-ARR_v2_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_24",
            "tgt_ix": "394-ARR_v2_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_24",
            "tgt_ix": "394-ARR_v2_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_24",
            "tgt_ix": "394-ARR_v2_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_25",
            "tgt_ix": "394-ARR_v2_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_16",
            "tgt_ix": "394-ARR_v2_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_31",
            "tgt_ix": "394-ARR_v2_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_32",
            "tgt_ix": "394-ARR_v2_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_32",
            "tgt_ix": "394-ARR_v2_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_0",
            "tgt_ix": "394-ARR_v2_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_33",
            "tgt_ix": "394-ARR_v2_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_34",
            "tgt_ix": "394-ARR_v2_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_34",
            "tgt_ix": "394-ARR_v2_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_34",
            "tgt_ix": "394-ARR_v2_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_35",
            "tgt_ix": "394-ARR_v2_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_37",
            "tgt_ix": "394-ARR_v2_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_38",
            "tgt_ix": "394-ARR_v2_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_36",
            "tgt_ix": "394-ARR_v2_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_36",
            "tgt_ix": "394-ARR_v2_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_36",
            "tgt_ix": "394-ARR_v2_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_36",
            "tgt_ix": "394-ARR_v2_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_34",
            "tgt_ix": "394-ARR_v2_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_39",
            "tgt_ix": "394-ARR_v2_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_40",
            "tgt_ix": "394-ARR_v2_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_40",
            "tgt_ix": "394-ARR_v2_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_34",
            "tgt_ix": "394-ARR_v2_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_41",
            "tgt_ix": "394-ARR_v2_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_43",
            "tgt_ix": "394-ARR_v2_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_44",
            "tgt_ix": "394-ARR_v2_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_45",
            "tgt_ix": "394-ARR_v2_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_42",
            "tgt_ix": "394-ARR_v2_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_42",
            "tgt_ix": "394-ARR_v2_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_42",
            "tgt_ix": "394-ARR_v2_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_42",
            "tgt_ix": "394-ARR_v2_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_42",
            "tgt_ix": "394-ARR_v2_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_34",
            "tgt_ix": "394-ARR_v2_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_46",
            "tgt_ix": "394-ARR_v2_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_48",
            "tgt_ix": "394-ARR_v2_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_47",
            "tgt_ix": "394-ARR_v2_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_47",
            "tgt_ix": "394-ARR_v2_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_47",
            "tgt_ix": "394-ARR_v2_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_0",
            "tgt_ix": "394-ARR_v2_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_49",
            "tgt_ix": "394-ARR_v2_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_51",
            "tgt_ix": "394-ARR_v2_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_52",
            "tgt_ix": "394-ARR_v2_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_53",
            "tgt_ix": "394-ARR_v2_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_50",
            "tgt_ix": "394-ARR_v2_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_50",
            "tgt_ix": "394-ARR_v2_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_50",
            "tgt_ix": "394-ARR_v2_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_50",
            "tgt_ix": "394-ARR_v2_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_50",
            "tgt_ix": "394-ARR_v2_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_55",
            "tgt_ix": "394-ARR_v2_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_50",
            "tgt_ix": "394-ARR_v2_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_50",
            "tgt_ix": "394-ARR_v2_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_54",
            "tgt_ix": "394-ARR_v2_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "394-ARR_v2_0",
            "tgt_ix": "394-ARR_v2_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_1",
            "tgt_ix": "394-ARR_v2_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_2",
            "tgt_ix": "394-ARR_v2_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_2",
            "tgt_ix": "394-ARR_v2_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_2",
            "tgt_ix": "394-ARR_v2_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_2",
            "tgt_ix": "394-ARR_v2_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_2",
            "tgt_ix": "394-ARR_v2_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_2",
            "tgt_ix": "394-ARR_v2_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_2",
            "tgt_ix": "394-ARR_v2_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_3",
            "tgt_ix": "394-ARR_v2_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_4",
            "tgt_ix": "394-ARR_v2_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_4",
            "tgt_ix": "394-ARR_v2_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_4",
            "tgt_ix": "394-ARR_v2_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_4",
            "tgt_ix": "394-ARR_v2_4@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_4",
            "tgt_ix": "394-ARR_v2_4@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_5",
            "tgt_ix": "394-ARR_v2_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_5",
            "tgt_ix": "394-ARR_v2_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_5",
            "tgt_ix": "394-ARR_v2_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_5",
            "tgt_ix": "394-ARR_v2_5@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_5",
            "tgt_ix": "394-ARR_v2_5@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_6",
            "tgt_ix": "394-ARR_v2_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_6",
            "tgt_ix": "394-ARR_v2_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_6",
            "tgt_ix": "394-ARR_v2_6@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_6",
            "tgt_ix": "394-ARR_v2_6@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_6",
            "tgt_ix": "394-ARR_v2_6@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_6",
            "tgt_ix": "394-ARR_v2_6@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_7",
            "tgt_ix": "394-ARR_v2_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_7",
            "tgt_ix": "394-ARR_v2_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_8",
            "tgt_ix": "394-ARR_v2_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_8",
            "tgt_ix": "394-ARR_v2_8@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_9",
            "tgt_ix": "394-ARR_v2_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_10",
            "tgt_ix": "394-ARR_v2_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_11",
            "tgt_ix": "394-ARR_v2_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_12",
            "tgt_ix": "394-ARR_v2_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_12",
            "tgt_ix": "394-ARR_v2_12@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_12",
            "tgt_ix": "394-ARR_v2_12@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_12",
            "tgt_ix": "394-ARR_v2_12@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_12",
            "tgt_ix": "394-ARR_v2_12@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_12",
            "tgt_ix": "394-ARR_v2_12@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_13",
            "tgt_ix": "394-ARR_v2_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_13",
            "tgt_ix": "394-ARR_v2_13@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_14",
            "tgt_ix": "394-ARR_v2_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_15",
            "tgt_ix": "394-ARR_v2_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_15",
            "tgt_ix": "394-ARR_v2_15@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_15",
            "tgt_ix": "394-ARR_v2_15@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_15",
            "tgt_ix": "394-ARR_v2_15@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_15",
            "tgt_ix": "394-ARR_v2_15@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_15",
            "tgt_ix": "394-ARR_v2_15@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_15",
            "tgt_ix": "394-ARR_v2_15@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_15",
            "tgt_ix": "394-ARR_v2_15@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_15",
            "tgt_ix": "394-ARR_v2_15@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_15",
            "tgt_ix": "394-ARR_v2_15@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_15",
            "tgt_ix": "394-ARR_v2_15@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_15",
            "tgt_ix": "394-ARR_v2_15@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_15",
            "tgt_ix": "394-ARR_v2_15@12",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_16",
            "tgt_ix": "394-ARR_v2_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_17",
            "tgt_ix": "394-ARR_v2_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_17",
            "tgt_ix": "394-ARR_v2_17@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_17",
            "tgt_ix": "394-ARR_v2_17@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_17",
            "tgt_ix": "394-ARR_v2_17@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_17",
            "tgt_ix": "394-ARR_v2_17@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_17",
            "tgt_ix": "394-ARR_v2_17@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_17",
            "tgt_ix": "394-ARR_v2_17@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_17",
            "tgt_ix": "394-ARR_v2_17@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_17",
            "tgt_ix": "394-ARR_v2_17@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_17",
            "tgt_ix": "394-ARR_v2_17@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_17",
            "tgt_ix": "394-ARR_v2_17@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_17",
            "tgt_ix": "394-ARR_v2_17@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_17",
            "tgt_ix": "394-ARR_v2_17@12",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_17",
            "tgt_ix": "394-ARR_v2_17@13",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_18",
            "tgt_ix": "394-ARR_v2_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_19",
            "tgt_ix": "394-ARR_v2_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_19",
            "tgt_ix": "394-ARR_v2_19@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_19",
            "tgt_ix": "394-ARR_v2_19@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_19",
            "tgt_ix": "394-ARR_v2_19@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_19",
            "tgt_ix": "394-ARR_v2_19@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_19",
            "tgt_ix": "394-ARR_v2_19@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_19",
            "tgt_ix": "394-ARR_v2_19@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_19",
            "tgt_ix": "394-ARR_v2_19@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_19",
            "tgt_ix": "394-ARR_v2_19@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_20",
            "tgt_ix": "394-ARR_v2_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_21",
            "tgt_ix": "394-ARR_v2_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_21",
            "tgt_ix": "394-ARR_v2_21@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_21",
            "tgt_ix": "394-ARR_v2_21@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_21",
            "tgt_ix": "394-ARR_v2_21@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_21",
            "tgt_ix": "394-ARR_v2_21@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_21",
            "tgt_ix": "394-ARR_v2_21@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_21",
            "tgt_ix": "394-ARR_v2_21@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_21",
            "tgt_ix": "394-ARR_v2_21@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_21",
            "tgt_ix": "394-ARR_v2_21@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_21",
            "tgt_ix": "394-ARR_v2_21@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_21",
            "tgt_ix": "394-ARR_v2_21@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_22",
            "tgt_ix": "394-ARR_v2_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_22",
            "tgt_ix": "394-ARR_v2_22@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_22",
            "tgt_ix": "394-ARR_v2_22@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_22",
            "tgt_ix": "394-ARR_v2_22@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_22",
            "tgt_ix": "394-ARR_v2_22@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_22",
            "tgt_ix": "394-ARR_v2_22@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_23",
            "tgt_ix": "394-ARR_v2_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_23",
            "tgt_ix": "394-ARR_v2_23@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_23",
            "tgt_ix": "394-ARR_v2_23@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_23",
            "tgt_ix": "394-ARR_v2_23@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_23",
            "tgt_ix": "394-ARR_v2_23@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_24",
            "tgt_ix": "394-ARR_v2_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_25",
            "tgt_ix": "394-ARR_v2_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_25",
            "tgt_ix": "394-ARR_v2_25@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_25",
            "tgt_ix": "394-ARR_v2_25@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_25",
            "tgt_ix": "394-ARR_v2_25@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_26",
            "tgt_ix": "394-ARR_v2_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_27",
            "tgt_ix": "394-ARR_v2_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_28",
            "tgt_ix": "394-ARR_v2_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_28",
            "tgt_ix": "394-ARR_v2_28@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_28",
            "tgt_ix": "394-ARR_v2_28@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_28",
            "tgt_ix": "394-ARR_v2_28@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_28",
            "tgt_ix": "394-ARR_v2_28@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_29",
            "tgt_ix": "394-ARR_v2_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_30",
            "tgt_ix": "394-ARR_v2_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_31",
            "tgt_ix": "394-ARR_v2_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_31",
            "tgt_ix": "394-ARR_v2_31@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_32",
            "tgt_ix": "394-ARR_v2_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_33",
            "tgt_ix": "394-ARR_v2_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_33",
            "tgt_ix": "394-ARR_v2_33@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_33",
            "tgt_ix": "394-ARR_v2_33@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_34",
            "tgt_ix": "394-ARR_v2_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_35",
            "tgt_ix": "394-ARR_v2_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_36",
            "tgt_ix": "394-ARR_v2_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_37",
            "tgt_ix": "394-ARR_v2_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_37",
            "tgt_ix": "394-ARR_v2_37@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_37",
            "tgt_ix": "394-ARR_v2_37@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_37",
            "tgt_ix": "394-ARR_v2_37@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_37",
            "tgt_ix": "394-ARR_v2_37@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_37",
            "tgt_ix": "394-ARR_v2_37@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_37",
            "tgt_ix": "394-ARR_v2_37@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_37",
            "tgt_ix": "394-ARR_v2_37@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_37",
            "tgt_ix": "394-ARR_v2_37@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_37",
            "tgt_ix": "394-ARR_v2_37@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_37",
            "tgt_ix": "394-ARR_v2_37@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_37",
            "tgt_ix": "394-ARR_v2_37@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_37",
            "tgt_ix": "394-ARR_v2_37@12",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_37",
            "tgt_ix": "394-ARR_v2_37@13",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_37",
            "tgt_ix": "394-ARR_v2_37@14",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_37",
            "tgt_ix": "394-ARR_v2_37@15",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_37",
            "tgt_ix": "394-ARR_v2_37@16",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_37",
            "tgt_ix": "394-ARR_v2_37@17",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_38",
            "tgt_ix": "394-ARR_v2_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_38",
            "tgt_ix": "394-ARR_v2_38@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_38",
            "tgt_ix": "394-ARR_v2_38@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_39",
            "tgt_ix": "394-ARR_v2_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_39",
            "tgt_ix": "394-ARR_v2_39@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_39",
            "tgt_ix": "394-ARR_v2_39@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_39",
            "tgt_ix": "394-ARR_v2_39@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_39",
            "tgt_ix": "394-ARR_v2_39@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_40",
            "tgt_ix": "394-ARR_v2_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_41",
            "tgt_ix": "394-ARR_v2_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_41",
            "tgt_ix": "394-ARR_v2_41@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_41",
            "tgt_ix": "394-ARR_v2_41@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_41",
            "tgt_ix": "394-ARR_v2_41@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_41",
            "tgt_ix": "394-ARR_v2_41@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_41",
            "tgt_ix": "394-ARR_v2_41@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_41",
            "tgt_ix": "394-ARR_v2_41@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_41",
            "tgt_ix": "394-ARR_v2_41@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_41",
            "tgt_ix": "394-ARR_v2_41@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_41",
            "tgt_ix": "394-ARR_v2_41@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_41",
            "tgt_ix": "394-ARR_v2_41@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_41",
            "tgt_ix": "394-ARR_v2_41@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_41",
            "tgt_ix": "394-ARR_v2_41@12",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_41",
            "tgt_ix": "394-ARR_v2_41@13",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_41",
            "tgt_ix": "394-ARR_v2_41@14",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_41",
            "tgt_ix": "394-ARR_v2_41@15",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_41",
            "tgt_ix": "394-ARR_v2_41@16",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_41",
            "tgt_ix": "394-ARR_v2_41@17",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_41",
            "tgt_ix": "394-ARR_v2_41@18",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_42",
            "tgt_ix": "394-ARR_v2_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_43",
            "tgt_ix": "394-ARR_v2_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_43",
            "tgt_ix": "394-ARR_v2_43@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_44",
            "tgt_ix": "394-ARR_v2_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_44",
            "tgt_ix": "394-ARR_v2_44@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_44",
            "tgt_ix": "394-ARR_v2_44@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_44",
            "tgt_ix": "394-ARR_v2_44@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_44",
            "tgt_ix": "394-ARR_v2_44@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_44",
            "tgt_ix": "394-ARR_v2_44@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_45",
            "tgt_ix": "394-ARR_v2_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_45",
            "tgt_ix": "394-ARR_v2_45@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_45",
            "tgt_ix": "394-ARR_v2_45@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_46",
            "tgt_ix": "394-ARR_v2_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_46",
            "tgt_ix": "394-ARR_v2_46@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_46",
            "tgt_ix": "394-ARR_v2_46@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_46",
            "tgt_ix": "394-ARR_v2_46@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_47",
            "tgt_ix": "394-ARR_v2_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_48",
            "tgt_ix": "394-ARR_v2_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_48",
            "tgt_ix": "394-ARR_v2_48@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_48",
            "tgt_ix": "394-ARR_v2_48@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_48",
            "tgt_ix": "394-ARR_v2_48@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_48",
            "tgt_ix": "394-ARR_v2_48@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_48",
            "tgt_ix": "394-ARR_v2_48@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_49",
            "tgt_ix": "394-ARR_v2_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_49",
            "tgt_ix": "394-ARR_v2_49@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_49",
            "tgt_ix": "394-ARR_v2_49@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_49",
            "tgt_ix": "394-ARR_v2_49@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_49",
            "tgt_ix": "394-ARR_v2_49@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_49",
            "tgt_ix": "394-ARR_v2_49@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_49",
            "tgt_ix": "394-ARR_v2_49@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_50",
            "tgt_ix": "394-ARR_v2_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_51",
            "tgt_ix": "394-ARR_v2_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_51",
            "tgt_ix": "394-ARR_v2_51@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_51",
            "tgt_ix": "394-ARR_v2_51@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_52",
            "tgt_ix": "394-ARR_v2_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_53",
            "tgt_ix": "394-ARR_v2_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_53",
            "tgt_ix": "394-ARR_v2_53@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_53",
            "tgt_ix": "394-ARR_v2_53@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_54",
            "tgt_ix": "394-ARR_v2_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_55",
            "tgt_ix": "394-ARR_v2_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_56",
            "tgt_ix": "394-ARR_v2_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_57",
            "tgt_ix": "394-ARR_v2_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_58",
            "tgt_ix": "394-ARR_v2_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_59",
            "tgt_ix": "394-ARR_v2_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_60",
            "tgt_ix": "394-ARR_v2_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_61",
            "tgt_ix": "394-ARR_v2_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_62",
            "tgt_ix": "394-ARR_v2_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_63",
            "tgt_ix": "394-ARR_v2_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_64",
            "tgt_ix": "394-ARR_v2_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_65",
            "tgt_ix": "394-ARR_v2_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_66",
            "tgt_ix": "394-ARR_v2_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_67",
            "tgt_ix": "394-ARR_v2_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_68",
            "tgt_ix": "394-ARR_v2_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_69",
            "tgt_ix": "394-ARR_v2_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_70",
            "tgt_ix": "394-ARR_v2_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_71",
            "tgt_ix": "394-ARR_v2_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_72",
            "tgt_ix": "394-ARR_v2_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_73",
            "tgt_ix": "394-ARR_v2_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_74",
            "tgt_ix": "394-ARR_v2_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_75",
            "tgt_ix": "394-ARR_v2_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_76",
            "tgt_ix": "394-ARR_v2_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_77",
            "tgt_ix": "394-ARR_v2_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_78",
            "tgt_ix": "394-ARR_v2_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_79",
            "tgt_ix": "394-ARR_v2_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_80",
            "tgt_ix": "394-ARR_v2_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_81",
            "tgt_ix": "394-ARR_v2_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_82",
            "tgt_ix": "394-ARR_v2_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_83",
            "tgt_ix": "394-ARR_v2_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_84",
            "tgt_ix": "394-ARR_v2_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_85",
            "tgt_ix": "394-ARR_v2_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_86",
            "tgt_ix": "394-ARR_v2_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_87",
            "tgt_ix": "394-ARR_v2_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_88",
            "tgt_ix": "394-ARR_v2_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_89",
            "tgt_ix": "394-ARR_v2_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_90",
            "tgt_ix": "394-ARR_v2_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_91",
            "tgt_ix": "394-ARR_v2_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_92",
            "tgt_ix": "394-ARR_v2_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_93",
            "tgt_ix": "394-ARR_v2_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_94",
            "tgt_ix": "394-ARR_v2_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_95",
            "tgt_ix": "394-ARR_v2_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_96",
            "tgt_ix": "394-ARR_v2_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_97",
            "tgt_ix": "394-ARR_v2_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_98",
            "tgt_ix": "394-ARR_v2_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_99",
            "tgt_ix": "394-ARR_v2_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_100",
            "tgt_ix": "394-ARR_v2_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "394-ARR_v2_101",
            "tgt_ix": "394-ARR_v2_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 845,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "doc_id": "394-ARR",
        "version": 2
    }
}