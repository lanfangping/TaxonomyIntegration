{
    "nodes": [
        {
            "ix": "419-ARR_v1_0",
            "content": "Is Attention Explanation? An Introduction to the Debate",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_2",
            "content": "The performance of deep learning models in NLP and other fields of machine learning has led to a rise in their popularity, and so the need for explanations of these models becomes paramount. Attention has been seen as a solution to increase performance, while providing some explanations. However, a debate has started to cast doubt on the explanatory power of attention in neural networks. Although the debate has created a vast literature thanks to contributions from various areas, the lack of communication is becoming more and more tangible. In this paper, we provide a clear overview of the insights on the debate by critically confronting works from these different areas. This holistic vision can be of great interest for future works in all the communities concerned by this debate. We sum up the main challenges spotted in these areas, and we conclude by discussing the most promising future avenues on attention as an explanation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "419-ARR_v1_4",
            "content": "Attention mechanisms have been widely used in various tasks of Natural Language Processing (NLP) as well as in other fields of machine learning (e.g., Computer Vision (Mnih et al., 2014;Li et al., 2019)). These mechanisms draw insight from the intuition that humans build the representation of a whole scene by dynamically focusing on relevant parts at different times (Rensink, 2000).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_5",
            "content": "The general form of attention has been named differently according to authors (alignment model (Bahdanau et al., 2015) and attention mechanism (Vaswani et al., 2017)). In essence, the attention function maps a query Q and keys K to scalar scores (Vaswani et al., 2017). These scores are fed to a softmax function, in turn producing a set of attention weights that are then applied to values V. Different kinds of attention are thus possible according to how many keys are attended to (global vs. local attention, according to Luong et al. (2015)) and where the query is generated (cross vs. self-attention as in the works of Bahdanau et al. (2015) and Vaswani et al. (2017)). In this paper, we focus on attention regardless of these technical differences. There are mainly two ways of computing the attention weights \u03b1: Bahdanau et al. (2015) introduced additive attention \u03b1 = softmax(w 3 T tanh(W 1 K + W 2 Q)), where w 3 , W 1 , W 2 model parameters to be learned, and Vaswani et al. (2017) introduced scaled dot-product attention \u03b1 = softmax KQ \u221a m , where m represents the dimension of K. These two forms are theoretically similar (Vaswani et al., 2017) and generally give the same results (Jain and Wallace, 2019), the dot-product form being faster on certain tasks from a practical point of view.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_6",
            "content": "Since the introduction of attention mechanisms in the literature, many have seen the opportunity to use the weights for explaining neural networks (e.g., Xu et al. (2015); Martins and Astudillo (2016); Choi et al. (2016); Xie et al. (2017); Mullenbach et al. (2018)). Explainability in machine learning and NLP is defined as the capacity to explain a non-interpretable (Bibal and Fr\u00e9nay, 2016), i.e. black-box, model (Guidotti et al., 2018). The two major ways to explain black-box models are global explanations, providing clues about the behavior of the model as a whole, and local explanations, explaining particular decisions. Using attention to explain neural networks mainly pertains to the latter, even if some authors study attention for global explanation (e.g., Clark et al. (2019)).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_7",
            "content": "Explanations can also be faithful (how close the explanation is to the inner workings of the model) (Rudin, 2019;Jacovi and Goldberg, 2020), or plausible (does the user consider the explanation of the model plausible?) (Riedl, 2019;Jacovi and Goldberg, 2020). It should be noted that explanation presupposes some degree of transparency to the user, whether it is faithful or plausible. Indeed, disregarding this aspect would entail that the most faithful explanation is the black-box model itself.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_8",
            "content": "Recently, a debate fundamentally questioned whether attention can be used as explanation (Jain and Wallace, 2019). An immediate response by Wiegreffe and Pinter (2019) challenged some of the arguments of Jain and Wallace (2019). To this day, the debate about \"is attention explanation?\" continues and is the source of a rich and diverse literature. Researchers from different areas have mostly contributed to this debate without referring to works outside, and sometimes even inside, their area. These insights include theoretical analyses of attention, the necessity to bring users in the loop, questioning the evaluation methodology for model explanation, and more.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_9",
            "content": "This paper aims at bringing together the papers from these different areas in order to provide an outline of the quickly growing and vast literature on the subject. Moreover, we discuss the lessons learned and highlight the main issues and perspectives. To accurately reflect the debate, we only focus on papers that are posterior to the works of Jain and Wallace (2019) and Wiegreffe and Pinter (2019), and that explicitly rely on these two papers to contribute to the debate. This paper proposes the first introduction to the debate about \"is attention explanation?\". The main contributions of this work are as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_10",
            "content": "\u2022 a summary and a discussion of the actual state of the debate by identifying convergences and disagreements in the literature; \u2022 an extraction and structure of the main insights from papers of different areas that generally do not interact; and \u2022 the bases for developing research on attention as explanation, with a more integrated state-ofthe-art built upon a multitude of perspectives.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_11",
            "content": "In order to present the different insights on the debate, we briefly summarize the two seminal papers (Section 2), describing the arguments of the two original papers that represent the source of the ongoing debate. We also present survey papers that mention the debate within a broader context (Section 3). We then investigate the different research perspectives we extracted from the literature (Sections 4 to 9). Finally, we analyze the insights offered by those works and offer foundations to build upon for future research related to attention as explanation (Section 10).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_12",
            "content": "Starting Point of the Debate",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "419-ARR_v1_13",
            "content": "Jain and Wallace (2019) make a set of observations on attention weights in a battery of experiments: (i) an analysis of the correlations between attention weights and feature importance methods (gradientbased and leave-one-out) and (ii) a study of the impact of counterfactual attention weight distributions on the final prediction by randomly shuffling the attention weights, and by shuffling them adversarially (i.e., by creating distributions that correspond to a focus on a different set of features than the one in the original attention distribution). The experiments are performed on three tasks: binary text classification, question answering and natural language inference. When commenting upon the results of their experiments, the authors' observations are: (i) there are poor correlations between attention weights and gradient-based or leave-oneout methods for explanation and (ii) shuffling the attention weights in a neural model does not affect the final prediction, except for some rare cases where the prediction relies on a few high precision tokens. The conclusion they draw from the poor correlations with other explanation methods and the lack of exclusive explanation is that attention cannot be used as a means of explanation. Wiegreffe and Pinter (2019) agree on the importance of the questions raised by Jain and Wallace (2019) and reply to their claims. They agree with the first observation and the corresponding experimental setup. However, they object to the second claim, stating that only modifying the attention weights in the model does not produce a real attention-based model. Indeed, if the attention weights should be modified for experimental purposes, then the model should be retrained to correspond to a real trained model with those modified attention weights. In addition, they also object to the exclusive explanation argument that attention is \"an explanation, not the explanation\" (Wiegreffe and Pinter, 2019, p. 13). Indeed, several plausible explanations can co-exist for a similar degree of faithfulness.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_14",
            "content": "The clash between the initial use of attention as explanation and the 2019 studies showing that attention might not be explanation started a vast literature on the subject. The following section presents survey papers that are mentioning the debate within a broader perspective.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_15",
            "content": "Survey Papers Mentioning the Debate",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "419-ARR_v1_16",
            "content": "Usually, when exploring a question, survey papers are a good starting point, as they have the advantage of covering a broader scope. However, there is no in-depth introduction to the debate, as survey papers only briefly mention the debate and sometimes do not really add something significant for the discussion (e.g., Chaudhari et al. (2019) and Lindsay (2020)). Please note that we only discuss surveys that add significant elements to the discussion. Galassi et al. (2020) propose a survey on attention. They recall the results of Jain and Wallace (2019) on the fact that attention may not be explanation, but also refer to the fact that only faithful explanations (and not plausible ones; see Section 7) are considered. The \"explanation\" perspective of the survey is focused on the work of , which discusses how well attention captures the importance of abstract features in multilayer neural networks when dealing with images. Galassi et al. (2020) argue that an answer to the question \"is attention explanation?\" with image data may not generalize to text, and should be verified, as human understanding mechanisms strongly differ between images and texts.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_17",
            "content": "de Santana Correia and Colombini (2021) introduce the debate in broad terms in Section 5.7 of their survey, but point out that, based on the work of Vashishth et al. (2019), the answer to the question \"is attention explanation?\" can take different shapes based on the NLP task that is studied (see our Section 6 for more details on this point of the debate). Later in their paper, they also mention, like Galassi et al. (2020), that some works show that attention in transformers focuses on syntactical structures (Voita et al., 2018;Vig and Belinkov, 2019;Tenney et al., 2019;Clark et al., 2019). This indicates that global explanations based on attention can be provided, but do not answer the need for the local, decision-based, explanation that is mainly discussed in the debate. Ras et al. (2021) also stress that the debate has been extended to several NLP tasks in the work of Vashishth et al. (2019). They add the information that mixed results have been obtained in the debate (Serrano and Smith, 2019;Baan et al., 2019).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_18",
            "content": "Contrary to the short introductions to the debate in these survey papers, we aim at providing a clear and rather exhaustive view of the different ways the debate is tackled in the literature. The different insights on the debate, which are unfortunately not regrouped and discussed in these surveys (because the debate is not their main focus), are numerous: some papers add arguments about the fact that attention is not explanation (Section 4), provide analyses to explain why attention is not explanation (Section 5), analyze the debate on different NLP tasks (Section 6), discuss the methodological issues at the heart of the debate (Section 7), evaluate the explanatory power of attention with humans (Section 8), or propose solutions to make attention become explanation (based on technical developments or on user-in-the-loop strategies) (Section 9).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_19",
            "content": "Additional Arguments about Attention is not Explanation",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "419-ARR_v1_20",
            "content": "Some works may be considered as the direct continuation of the arguments of Jain and Wallace ( 2019) by adding experiments that corroborate their findings, e.g., by showing that the comparison of attention with other explainable methods different from the gradient-based one leads to similar conclusions. Serrano and Smith (2019) show that removing features considered as important by attention less often leads to a decision flip than removing features considered important by gradient-based methods. This means that the features deemed important by attention for a decision are not so important for the model. This, therefore, adds to the first argument of Jain and Wallace (2019) against the relevance of attention as an indicator of feature importance. Thorne et al. (2019) demonstrate that applying LIME (Ribeiro et al., 2016) on an attention-based neural network can provide good explanations that the attention itself cannot provide. They conclude on this subject that their experimental results are aligned with the ones of Jain and Wallace (2019).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_21",
            "content": "Mohankumar et al. ( 2020) investigate attention on top of LSTMs (attention-LSTMs). Their study focuses on why attention in such models neither provides plausible, nor faithful, explanations. They use a variety of NLP tasks (sentiment analysis, natural language inference, question answering and paraphrase detection) and randomly permute attention weights as Jain and Wallace (2019). They find that attention-LSTM's outputs do not change much after the permutation and conclude that attention weights are not faithful explanations in attention-LSTMs. The authors propose changes to attention-LSTMs to make attention a faithful explanation (see Section 9.1). Moreover, by analyzing the attention given to part-of-speech tags, they find that the model cannot provide a plausible explanation either, since, for several datasets, a significant amount of attention is given to punctuation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_22",
            "content": "Finally, Ethayarajh and Jurafsky (2021) show that attention weights are not Shapley values (i.e. a method for feature importance) (Lundberg and Lee, 2017). This result is in line with Jain and Wallace (2019) on the fact that the attention weights do not correlate with other explanation techniques (saliency maps or Shapley values). The authors however note that attention flows (i.e. an extension of attention weights obtained after postprocessing) (Abnar and Zuidema, 2020) are Shapley values, which may indicate that using attention in another way could lead to explanation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_23",
            "content": "Analyses of Why Attention is not Explanation",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "419-ARR_v1_24",
            "content": "In addition to the arguments in the literature on the fact that attention is not explanation, another part of the literature focuses on understanding the reasons why it is not explanation. Bai et al. (2021) show that attention can be put on uninteresting tokens because of an effect they call \"combinatorial shortcuts\". The key idea is that attention is calculated on the basis of a biased input: \"the attention mechanism will try to select biased features to adapt the biased estimations to minimize the overall loss functions\" (Bai et al., 2021, p. 27). For instance, if one adds random tokens (such as A, B, and C) to all documents in a corpus, one might find that some of these tokens are considered as important for the positive (or negative) class because their representation ends up being similar to the representation of \"good\" (or \"bad\"), even if their information content for the task is negligible, as they are present in all documents. Brunner et al. (2020) theoretically show that attention weights in transformers can be decomposed into two parts, from which the \"effective attention\" part corresponds to the attention that really affects the output. Effective attention focuses on the effective input needed by the model for the task and is not biased by the representation of the input. Kobayashi et al. (2020) extend the work of Brunner et al. (2020), but focus on describing the effective attention part in more detail instead of using it to improve the model. Likewise, Sun and Marasovi\u0107 (2021) also extend the work of Brunner et al. (2020) and delve deeper into the explanation of effective attention and its use for explaining the model. Sun and Lu (2020) study attention through two specific scores: attention and polarization. The attention score corresponds to the absolute value associated with each input token before the transformation into an attention weight. The polarization score is a global score (not instance-specific) for each input token, indicating its importance for predicting the positive or negative class. The authors show through these two scores why attentionbased models are stable in their prediction, even when attention weights differ. They also show that the match between attention and polarizing scores strongly depends on the hyperparameter values.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_25",
            "content": "By analyzing the effect of regularization on attention, Tutek and \u0160najder (2020) show that one of the reasons why attention cannot be used as a faithful explanation is due to the fact that all input tokens roughly have the same influence on the prediction. The authors show that regularizing attention-based models so that embedded tokens e t better correspond to their hidden representation rnn(e t ) produces explanations that are more faithful to the model. However, Meister et al. (2021) show that regularizing generally decreases the correlation between attention and explanation techniques, if the regularization is directed towards sparse attention weights. The authors conclude that sparsity, which is often viewed as increasing interpretability of models in the literature, in this case reduces the faithfulness of explanations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_26",
            "content": "Another way to analyze the problem is to study the change in the representation of the meaning of a sentence when (i) an attention layer is added, and when (ii) the type of RNN encoding the input is changed . The authors show that, in addition to an increase in accuracy, the use of attention also makes the model more stable in terms of representation of sentence meanings.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_27",
            "content": "Is Attention Explanation on Different",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "419-ARR_v1_28",
            "content": "Tasks?",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_29",
            "content": "In this section, we introduce arguments from the literature that claim that, despite some proofs that attention is not always explanation, attention can be explanation on certain NLP tasks. In general, attention mechanisms seem to provide faithful explanations in syntax-related tasks such as part-ofspeech tagging and syntactic annotation. Clark et al. (2019) thus investigate the attention heads in BERT. They explore syntactic dependency tagging and co-reference resolution. They find that attention heads at different layers attend to different kinds of information (e.g., direct objects of verbs, determiners of nouns or referential antecedents), with earlier layers having a broader attention span. Furthermore, attention heads in the same layer tend to show similar distributions, which is a counter to the argument of Li et al. (2018) on the fact that encouraging attention heads to learn different distributions within layers can improve performance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_30",
            "content": "Overall, knowledge of syntax seems to be encoded by a variety of attention heads in different layers, and thus attention can be used as a global explanation for the tasks under investigation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_31",
            "content": "Similarly, Vig and Belinkov (2019) investigate attention in GPT-2, in particular for two tasks: partof-speech and syntactic tagging. They find that each part-of-speech is attended to by a specific subset of attention heads, and that attention heads in adjacent layers attend to similar part-of-speech tags. In general, attention shows which tokens were attended to for the tasks at hand and can thus be used as a global explanation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_32",
            "content": "In a different vein, Vashishth et al. (2019) investigate the role of attention across a variety of NLP tasks. They show that, when the input consists of a single sequence (e.g., in sentiment classification), the attention mechanism is comparable to a gating unit and, as such, the learned weights cannot be interpreted as attention. Therefore, in this context, attention does not provide an explanation of the model's reasoning. The reduction of attention to gating units however does not hold true for selfattention networks nor for tasks depending on an additional text sequence, as for example in neural machine translation or natural language inference (pair-wise tasks and text generation tasks). In such cases, altering learned attention weights significantly degrades performance and attention appears to be an explanation of the model and to correlate with feature importance measures.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_33",
            "content": "Evaluation Methodology for Explanation",
            "ntype": "title",
            "meta": {
                "section": "7"
            }
        },
        {
            "ix": "419-ARR_v1_34",
            "content": "This section focuses on critics of the methodology when evaluating explanations via attention. The critics mainly focus on two points in the evaluation setup of Jain and Wallace (2019). First, Jain and Wallace (2019) claim that there should be a consistency between attention weights and other explanation methods -which Wiegreffe and Pinter (2019) agree with -and find none. Second, they state that the fact that attention could offer different explanations (which they show by shuffling the attention weights) is an issue, which is a strong point of disagreement with Wiegreffe and Pinter (2019).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_35",
            "content": "Regarding the first point, Neely et al. (2021) compare explanation methods from the literature (LIME, Integrated Gradients, DeepLIFT, Grad-SHAP and Deep-SHAP) with attention-based explanations. The comparison is performed on two types of classification: single-sequence classification (sentiment classification) and pair-sequence classification (language inference and understanding, and question answering). The authors find small agreement between the different explanation methods, including attention-based explanations. They conclude that checking for consistency between explanation methods should not be a criterion for evaluation, which goes against the agreement between the two seminal papers.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_36",
            "content": "The second point on shuffling the attention weights is a subject of more discussion. Ju et al. (2021) propose a general discussion about logic traps in evaluating interpretation. Their take on this point of the debate is that a model with its manipulated attention weights in the work of Jain and Wallace ( 2019) \"cannot even be regarded as a trained model, which makes their manipulation meaningless\" (Ju et al., 2021, p. 4), which adds to the point made by Wiegreffe and Pinter (2019). argue that it is too early for the debate to take place because there are no good definition and evaluation of explanations. The authors propose a Definition Driven Pipeline (DDP) to evaluate explanations based on the definition of faithfulness. They show that following this DDP can produce an evaluation of explanations that is less biased and can even drive the development of new faithful explanations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_37",
            "content": "Calling for more clearly differentiating between faithfulness and plausibility when evaluating explanation, Jacovi and Goldberg (2020) define five guidelines for evaluating faithfulness, building upon the common pitfalls and sub-optimal practices they observed in the literature. They propose an organization of the literature into three types: model assumption, prediction assumption, and linearity assumption. They state that the distinction between Jain and Wallace (2019) and Wiegreffe and Pinter (2019) is the underlying assumptions they use for evaluating attention heat-maps as explanations. The former attempts to provide different explanations of similar decisions per instance (therefore linked to prediction assumption). The latter critiques the former and is more anchored in the model assumption type of work.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_38",
            "content": "Evaluating Explanations with Humans",
            "ntype": "title",
            "meta": {
                "section": "8"
            }
        },
        {
            "ix": "419-ARR_v1_39",
            "content": "The notion of plausibility of attention-based explanations implies asking humans to evaluate whether attention provides a plausible explanation for the model's decisions. A first issue is whether human judges can agree on what plausible explanations of a decision (e.g., a prediction) are. In an experiment involving predictions for sentiment analysis and reading comprehension, Vashishth et al. (2019) ask humans to decide whether the top 3 highest weighted words in 200 samples are relevant for the model's prediction. They reported a very high agreement among judges (i.e. Cohen's \u03ba over 0.8), which leads to think that words receiving the highest attention can form a plausible explanation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_40",
            "content": "A second interesting issue is the type of human annotations that should be captured in order to assess model's plausibility. The most common approach is to ask humans to assess attention heatmaps produced by a model. In Vashishth et al. (2019), users assess the relevance of the top 3 highest weighted words, whereas Mohankumar et al.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_41",
            "content": "(2020) ask evaluators to decide which of two attention heatmaps better explains the model's prediction as regards to three dimensions: overall prediction, completeness (which heatmap highlights all the words required for the prediction) and correctness (highlights only the important words and not unnecessary words). Another way to assess the difference between human and machine attention, in Sen et al. (2020), consists in asking humans to highlight important words for a classification task. The authors report an agreement percentage around 70% for this task and show that attention weights on top of bi-RNNs align pretty well with human attention. This finding is especially true for words for which annotators agree on the importance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_42",
            "content": "A third line of research (Sood et al., 2020) uses eye tracking measures to investigate whether machine attention match human attention. The authors hypothesize that machine attention distributions should correlate with human attention strategies for a given task (e.g., question answering). They found that human and machine attention distributions are more similar on easier tasks, which may mean that, for difficult tasks, humans required more varied strategies. For LSTMs and CNNs, diverging more from human attention leads to a drop in performance, which is not the case for XLNets.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_43",
            "content": "However, the fact that humans could reliably assess model's plausibility does not ensure that the model is faithful (Jacovi and Goldberg, 2020). In fact, Pruthi et al. (2020) cast serious doubts on using attention maps as a way for users to audit explanations in the context of fairness. More precisely, the authors train various architectures of neural network models on datasets that are all gender-biased and whose predictions heavily rely on \"impermissible\" tokens (e.g., pronouns). An adapted loss function is used to penalize the attention values of these impermissible tokens. The authors conclude that, although the problematic tokens are still used by the models, they do not appear in the attention map, which wrongly leads users to believe that the models are unbiased. In other words, the authors proved that a plausible explanation does not always imply that the explanation is faithful.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_44",
            "content": "Solutions to Make Attention Explanation",
            "ntype": "title",
            "meta": {
                "section": "9"
            }
        },
        {
            "ix": "419-ARR_v1_45",
            "content": "This section proposes an overview of the different solutions that have been developed to tackle the various challenges raised by the debate. We identify two types of solutions: the first type, presented in Section 9.1, concerns purely technical solutions that are often based on the theoretical and empirical analyses presented in Section 5. The second type of solutions, presented in Section 9.2, leverages user-in-the-loop strategies to align machine attention with human attention.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_46",
            "content": "Technical Solutions",
            "ntype": "title",
            "meta": {
                "section": "9.1"
            }
        },
        {
            "ix": "419-ARR_v1_47",
            "content": "The technical solutions developed to make attention an explanation differ by whether they use attention values directly or indirectly. Within a recurrent network, the representation of an input element contains a summary of the components of its context. As such, the attention weight computed for that element is imprecise because it indirectly focuses on the context. In order to avoid this dispersion, some researchers seek to reinforce the link between attention weights and input elements. Chrysostomou and Aletras (2021) produce a weighted representation of input elements using the attention weights and a score that is specific to the elements themselves. They propose three learning strategies for that score and compare their solutions to three baseline explanations methods. Their results show that their solutions are an improvement over the baselines. Mohankumar et al. (2020) propose the introduction of more diversity in the hidden states learned by LSTMs, allowing to observe elements separately from their context. They evaluate two different strategies and show that the resulting attention values offer explanations that are not only more faithful but also more plausible.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_48",
            "content": "Tutek and \u0160najder (2020) explore different hidden state regularization methods in order to preserve a strong link with the corresponding input elements. They propose a regularization scheme that positively impacts the attention weights by reinforcing their link with the model prediction, which, in turn, leads to more faithful explanations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_49",
            "content": "The above approaches rely on a property of recurrent networks and seek to work on the attention by modifying the representation of the input elements within the network. In parallel, some researchers focus directly on the attention weights with no constraints regarding the network architecture. Moradi et al. (2021) modify the loss function by adding a term that penalizes non-faithful attention. In order to quantify faithfulness, they propose a measure that combines up to three different stress tests. They show that their method optimizes faithfulness, while improving the model's performance. Bai et al. (2021) propose to weight the elements of the input X to counter the effect of combinatorial shortcuts. The weighting scheme is based on the fact that the estimation of E(Y|X M) in attention, where M are masks applied ( ) to the elements of the input X, is not the same for all elements of X.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_50",
            "content": "Attention can be Explanation When",
            "ntype": "title",
            "meta": {
                "section": "9.2"
            }
        },
        {
            "ix": "419-ARR_v1_51",
            "content": "Users are in the Loop",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_52",
            "content": "Another way to make attention become explanation is to bring users into the loop. This approach is sometimes called supervised attention, as the user attention is used by the model during training. Strout et al. (2019) show that using human rationale to supervise attention can produce explanations that are better accepted by users, but can also lead to better results in terms of performance. Zhong et al. (2019) modify an attention-based LSTM to make it match user provided attention. In order to do that, they compare the distributions of machine and user attention and use a Kullback-Leibler divergence between the two distributions to penalize the attention of the model.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_53",
            "content": "In the same idea of supervised attention, Heo et al. (2020) extend the meta-learning technique called neural processes to include attention. Their Neural Attention Processes (NAP) are designed to consider user-provided attention in an active learning fashion through the use of context points. Kanchinadam et al. (2020) also extend the training of attention to obtain a supervised version of attention. Their approach consists in the addition of a term in the objective function of their model to penalize the difference between the machine and the user attention. As in Heo et al. (2020), the authors make use of active learning in their method called Rationale-based Active Learning with Supervised Attention (RALSA) to collect user attention.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_54",
            "content": "Finally, Arous et al. (2021) introduce MApping human Rationales To Attention (MARTA), a Bayesian framework to include human rationale in order to adapt machine attention. As for all other works in this section, the method improves the performance of the model while providing humanunderstandable explanations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_55",
            "content": "Discussion",
            "ntype": "title",
            "meta": {
                "section": "10"
            }
        },
        {
            "ix": "419-ARR_v1_56",
            "content": "As stated earlier in this paper, one of the difficulties in this debate is that the insights are brought from paper of different areas that do not always cite each other. In fact, even inside a particular area, papers do not always refer to each other. In this section, we aim at bridging the gap between the different papers and their area in order to extract the main conclusions and some points of tension.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_57",
            "content": "First of all, like Thorne et al. (2019) who state that LIME can be used for explanation, thus questioning the need for attention, Bastings and Filippova (2020) state that saliency methods can be used for explanation, and so the attention is not needed in that role. Therefore, according to Bastings and Filippova (2020), if explanation tools already exist to do the job, why is the debate about attention useful? Two answers can be provided to this question. First, attention is something that is learned for performance purposes, so it would be useful if it could be used as explanation also, instead of using additional post-hoc tools. Second, the existence of the debate kick-started solutions that are now moving towards explanation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_58",
            "content": "Current solutions for making attention an explanation have to consider the two sides of explanation: faithfulness and plausibility. This subject is at the very heart of the debate, as Wiegreffe and Pinter (2019) already mentioned the focus of Jain and Wallace (2019) on faithful explanations only. However, users may not be satisfied by explanations that are only faithful to the model, as they need to be plausible for them too. Therefore, focusing on the correlation between attention and other faithful techniques may not be enough to evaluate whether attention is explanation in real conditions. The right balance between plausibility and faithfulness may lie in human-based evaluations (Section 8) and supervised attention (Section 9.2).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_59",
            "content": "That being said, faithfulness should also be evaluated on its own right, without any consideration of plausibility, to check if the explanation matches the model behavior. However, as explained by Jacovi and Goldberg (2020), faithfulness should not be evaluated in a binary fashion: the level of faithfulness needed for attention to be accepted as an explanation should be measured.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_60",
            "content": "Still the subject evaluation, we noted that the different contributions to the debate are often based on different setups. Indeed, except for the analysis of attention on different tasks (Section 6), the contributions often base their claims on one or two tasks of their choice. We claim that a common ground must be found to properly analyze attention and its relation to explanation. The same issue has been observed with the use of different input embeddings and different architectures surrounding the attention layer(s). Likewise, stress that the lack of a common ground when discussing faithfulness, plausibility and explanations is not conducive to finding answers to the debate.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_61",
            "content": "On the side of solutions, the common intuitive solution in interpretability and explanation that regularizing a model to be sparse improves our understanding of the model is not well supported in the literature for attention. In fact, some authors like Meister et al. (2021) note that inducing sparsity may in fact reduce the faithfulness of attention.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_62",
            "content": "Another perspective that is better suited for obtaining faithful explanations is effective attention (Brunner et al., 2020;Kobayashi et al., 2020;Sun and Marasovi\u0107, 2021). Indeed, while attention per se may not be explanation, further studies and uses of effective attention as a sub-part of attention may prove useful to learn a faithful explanation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_63",
            "content": "If plausible explanations, alongside faithfulness, are needed, supervised attention is a good perspective. The argument for supervised attention is well-founded: if attention is not explanation and if faithfulness is not enough, then making machine attention match human attention may be a solution. While one can argue that attention has originally been introduced for performance purposes and that supervised attention may work against this advantage, several studies show that, in fact, guiding attention increases performance (e.g., Strout et al. (2019)). Supervised attention is therefore a solution that both optimizes performance and explainability. The main cost of this solution is that it requires the participation of users, but solutions using few-shot user annotations have already been introduced in the literature (e.g., Heo et al. (2020)).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_64",
            "content": "In a complementary point of view, Grimsley et al. ( 2020) offer a philosophical perspective on the debate. The authors show that works studying attention as explanation attempt to do so in a causal framework. They argue that it is an issue because the object of study does not fit in that type of framework. The reason is that the link between the attention layer and a model's output cannot be isolated from the other components of the model. They conclude that \"attention weights alone cannot be used as causal explanation for model behavior\" (Grimsley et al., 2020(Grimsley et al., , p. 1786. This entails that assuming causality when evaluating the explanatory power of attention is doomed to fail by design. The authors offer other, non-causal, explanation paradigms to explore the issue, such as mathematical, structural modal, and minimal-model explanations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_65",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "11"
            }
        },
        {
            "ix": "419-ARR_v1_66",
            "content": "We have shown that the debate about the question \"is attention explanation?\" already produced a vast and diverse literature. Throughout our analysis of the existing works, we have stressed various insights that could help advance the debate: theoretically refining concepts around the notion of explanation (in particular plausibility and faithfulness), developing a common ground in the evaluation setup (e.g., similar input embeddings and architectures), extending the studies and uses of effective attention, and improving the integration of users for a supervised attention. We intend that our work provides a solid ground for further research, calling for more integration to answer the question \"is attention explanation?\". In particular, combining the findings from the different areas (e.g., to produce a supervised effective attention) seems to be among the most promising avenues.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "419-ARR_v1_67",
            "content": "Samira Abnar, Willem Zuidema, Quantifying attention flow in transformers, 2020, Proceedings of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "Samira Abnar",
                    "Willem Zuidema"
                ],
                "title": "Quantifying attention flow in transformers",
                "pub_date": "2020",
                "pub_title": "Proceedings of ACL",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_68",
            "content": "Ines Arous, Ljiljana Dolamic, Jie Yang, Akansha Bhardwaj, Giuseppe Cuccu, Philippe Cudr\u00e9-Mauroux, MARTA: Leveraging human rationales for explainable text classification, 2021, Proceedings of AAAI, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Ines Arous",
                    "Ljiljana Dolamic",
                    "Jie Yang",
                    "Akansha Bhardwaj",
                    "Giuseppe Cuccu",
                    "Philippe Cudr\u00e9-Mauroux"
                ],
                "title": "MARTA: Leveraging human rationales for explainable text classification",
                "pub_date": "2021",
                "pub_title": "Proceedings of AAAI",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_69",
            "content": "Joris Baan, Marlies Maartje Ter Hoeve, Anne Van Der Wees, Maarten Schuth,  De Rijke, Do transformer attention heads provide transparency in abstractive summarization?, 2019, Proceedings of the SI-GIR Workshop FACTS-IR, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "Joris Baan",
                    "Marlies Maartje Ter Hoeve",
                    "Anne Van Der Wees",
                    "Maarten Schuth",
                    " De Rijke"
                ],
                "title": "Do transformer attention heads provide transparency in abstractive summarization?",
                "pub_date": "2019",
                "pub_title": "Proceedings of the SI-GIR Workshop FACTS-IR",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_70",
            "content": "Dzmitry Bahdanau, Kyung Cho, Yoshua Bengio, Neural machine translation by jointly learning to align and translate, 2015, Proceedings of ICLR, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Dzmitry Bahdanau",
                    "Kyung Cho",
                    "Yoshua Bengio"
                ],
                "title": "Neural machine translation by jointly learning to align and translate",
                "pub_date": "2015",
                "pub_title": "Proceedings of ICLR",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_71",
            "content": "Bing Bai, Jian Liang, Guanhua Zhang, Hao Li, Kun Bai, Fei Wang, Why attentions may not be interpretable?, 2021, Proceedings of the ACM SIGKDD Conference, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Bing Bai",
                    "Jian Liang",
                    "Guanhua Zhang",
                    "Hao Li",
                    "Kun Bai",
                    "Fei Wang"
                ],
                "title": "Why attentions may not be interpretable?",
                "pub_date": "2021",
                "pub_title": "Proceedings of the ACM SIGKDD Conference",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_72",
            "content": "Jasmijn Bastings, Katja Filippova, The elephant in the interpretability room: Why use attention as explanation when we have saliency methods?, 2020, Proceedings of the EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "Jasmijn Bastings",
                    "Katja Filippova"
                ],
                "title": "The elephant in the interpretability room: Why use attention as explanation when we have saliency methods?",
                "pub_date": "2020",
                "pub_title": "Proceedings of the EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_73",
            "content": "Adrien Bibal, Beno\u00eet Fr\u00e9nay, Interpretability of machine learning models and representations: An introduction, 2016, Proceedings of ESANN, .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "Adrien Bibal",
                    "Beno\u00eet Fr\u00e9nay"
                ],
                "title": "Interpretability of machine learning models and representations: An introduction",
                "pub_date": "2016",
                "pub_title": "Proceedings of ESANN",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_74",
            "content": "Gino Brunner, Yang Liu, Dami\u00e1n Pascual, Oliver Richter, Massimiliano Ciaramita, Roger Wattenhofer, On identifiability in transformers, 2020, Proceedings of ICLR, .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Gino Brunner",
                    "Yang Liu",
                    "Dami\u00e1n Pascual",
                    "Oliver Richter",
                    "Massimiliano Ciaramita",
                    "Roger Wattenhofer"
                ],
                "title": "On identifiability in transformers",
                "pub_date": "2020",
                "pub_title": "Proceedings of ICLR",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_75",
            "content": "UNKNOWN, None, 2019, An attentive survey of attention models, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "An attentive survey of attention models",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_76",
            "content": "Edward Choi, Mohammad Bahadori, Joshua Kulas, Andy Schuetz, F Walter, Jimeng Stewart,  Sun, RETAIN: an interpretable predictive model for healthcare using reverse time attention mechanism, 2016, Proceedings of NeurIPS, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Edward Choi",
                    "Mohammad Bahadori",
                    "Joshua Kulas",
                    "Andy Schuetz",
                    "F Walter",
                    "Jimeng Stewart",
                    " Sun"
                ],
                "title": "RETAIN: an interpretable predictive model for healthcare using reverse time attention mechanism",
                "pub_date": "2016",
                "pub_title": "Proceedings of NeurIPS",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_77",
            "content": "George Chrysostomou, Nikolaos Aletras, Improving the faithfulness of attention-based explanations with task-specific information for text classification, 2021, Proceedings of ACL-IJCNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "George Chrysostomou",
                    "Nikolaos Aletras"
                ],
                "title": "Improving the faithfulness of attention-based explanations with task-specific information for text classification",
                "pub_date": "2021",
                "pub_title": "Proceedings of ACL-IJCNLP",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_78",
            "content": "Kevin Clark, Urvashi Khandelwal, Omer Levy, Christopher D Manning, What does BERT look at? An analysis of BERT's attention, 2019, Proceedings of the ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Kevin Clark",
                    "Urvashi Khandelwal",
                    "Omer Levy",
                    "Christopher D Manning"
                ],
                "title": "What does BERT look at? An analysis of BERT's attention",
                "pub_date": "2019",
                "pub_title": "Proceedings of the ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_79",
            "content": "UNKNOWN, None, 2021, Attention, please! A survey of neural attention models in deep learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Attention, please! A survey of neural attention models in deep learning",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_80",
            "content": "Kawin Ethayarajh, Dan Jurafsky, Attention flows are shapley value explanations, 2021, Proceedings of ACL-IJCNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    "Kawin Ethayarajh",
                    "Dan Jurafsky"
                ],
                "title": "Attention flows are shapley value explanations",
                "pub_date": "2021",
                "pub_title": "Proceedings of ACL-IJCNLP",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_81",
            "content": "Andrea Galassi, Marco Lippi, Paolo Torroni, Attention in natural language processing, 2020, IEEE Transactions on Neural Networks and Learning Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Andrea Galassi",
                    "Marco Lippi",
                    "Paolo Torroni"
                ],
                "title": "Attention in natural language processing",
                "pub_date": "2020",
                "pub_title": "IEEE Transactions on Neural Networks and Learning Systems",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_82",
            "content": "Christopher Grimsley, Elijah Mayfield, Julia Rs Bursten, Why attention is not explanation: Surgical intervention and causal reasoning about neural models, 2020, Proceedings of LREC, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Christopher Grimsley",
                    "Elijah Mayfield",
                    "Julia Rs Bursten"
                ],
                "title": "Why attention is not explanation: Surgical intervention and causal reasoning about neural models",
                "pub_date": "2020",
                "pub_title": "Proceedings of LREC",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_83",
            "content": "Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Franco Turini, Fosca Giannotti, Dino Pedreschi, A survey of methods for explaining black box models, 2018, ACM Computing Surveys, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "Riccardo Guidotti",
                    "Anna Monreale",
                    "Salvatore Ruggieri",
                    "Franco Turini",
                    "Fosca Giannotti",
                    "Dino Pedreschi"
                ],
                "title": "A survey of methods for explaining black box models",
                "pub_date": "2018",
                "pub_title": "ACM Computing Surveys",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_84",
            "content": "Jay Heo, Junhyeon Park, Hyewon Jeong, Kwang Joon Kim, Juho Lee, Eunho Yang, Sung Hwang, Cost-effective interactive attention learning with neural attention processes, 2020, Proceedings of ICML, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Jay Heo",
                    "Junhyeon Park",
                    "Hyewon Jeong",
                    "Kwang Joon Kim",
                    "Juho Lee",
                    "Eunho Yang",
                    "Sung Hwang"
                ],
                "title": "Cost-effective interactive attention learning with neural attention processes",
                "pub_date": "2020",
                "pub_title": "Proceedings of ICML",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_85",
            "content": "Alon Jacovi, Yoav Goldberg, Towards faithfully interpretable NLP systems: How should we define and evaluate faithfulness?, 2020, Proceedings of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Alon Jacovi",
                    "Yoav Goldberg"
                ],
                "title": "Towards faithfully interpretable NLP systems: How should we define and evaluate faithfulness?",
                "pub_date": "2020",
                "pub_title": "Proceedings of ACL",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_86",
            "content": "Sarthak Jain, C Byron,  Wallace, Attention is not explanation, 2019, Proceedings of NAACL-HLT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "Sarthak Jain",
                    "C Byron",
                    " Wallace"
                ],
                "title": "Attention is not explanation",
                "pub_date": "2019",
                "pub_title": "Proceedings of NAACL-HLT",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_87",
            "content": "UNKNOWN, None, 2021, The logic traps in evaluating post-hoc interpretations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "The logic traps in evaluating post-hoc interpretations",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_88",
            "content": "Teja Kanchinadam, Keith Westpfahl, Qian You, Glenn Fung, Rationale-based human-in-theloop via supervised attention, 2020, Proceedings of the KDD workshop DaSH, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "Teja Kanchinadam",
                    "Keith Westpfahl",
                    "Qian You",
                    "Glenn Fung"
                ],
                "title": "Rationale-based human-in-theloop via supervised attention",
                "pub_date": "2020",
                "pub_title": "Proceedings of the KDD workshop DaSH",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_89",
            "content": "Goro Kobayashi, Tatsuki Kuribayashi, Sho Yokoi, Kentaro Inui, Attention is not only a weight: Analyzing transformers with vector norms, 2020, Proceedings of EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Goro Kobayashi",
                    "Tatsuki Kuribayashi",
                    "Sho Yokoi",
                    "Kentaro Inui"
                ],
                "title": "Attention is not only a weight: Analyzing transformers with vector norms",
                "pub_date": "2020",
                "pub_title": "Proceedings of EMNLP",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_90",
            "content": "Jian Li, Zhaopeng Tu, Baosong Yang, Tong Michael R Lyu,  Zhang, Multi-head attention with disagreement regularization, 2018, Proceedings of EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Jian Li",
                    "Zhaopeng Tu",
                    "Baosong Yang",
                    "Tong Michael R Lyu",
                    " Zhang"
                ],
                "title": "Multi-head attention with disagreement regularization",
                "pub_date": "2018",
                "pub_title": "Proceedings of EMNLP",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_91",
            "content": "Xiang Li, Wenhai Wang, Xiaolin Hu, Jian Yang, Selective kernel networks, 2019, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Xiang Li",
                    "Wenhai Wang",
                    "Xiaolin Hu",
                    "Jian Yang"
                ],
                "title": "Selective kernel networks",
                "pub_date": "2019",
                "pub_title": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_92",
            "content": "W Grace,  Lindsay, Attention in psychology, neuroscience, and machine learning, 2020, Frontiers in Computational Neuroscience, .",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "W Grace",
                    " Lindsay"
                ],
                "title": "Attention in psychology, neuroscience, and machine learning",
                "pub_date": "2020",
                "pub_title": "Frontiers in Computational Neuroscience",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_93",
            "content": "UNKNOWN, None, 2020, Are interpretations fairly evaluated? a definition driven pipeline for post-hoc interpretability, .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Are interpretations fairly evaluated? a definition driven pipeline for post-hoc interpretability",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_94",
            "content": "M Scott, Su-In Lundberg,  Lee, A unified approach to interpreting model predictions, 2017, Proceedings of NeurIPS, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": [
                    "M Scott",
                    "Su-In Lundberg",
                    " Lee"
                ],
                "title": "A unified approach to interpreting model predictions",
                "pub_date": "2017",
                "pub_title": "Proceedings of NeurIPS",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_95",
            "content": "Minh-Thang Luong, Hieu Pham, Christopher Manning, Effective approaches to attentionbased neural machine translation, 2015, Proceedings of EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Minh-Thang Luong",
                    "Hieu Pham",
                    "Christopher Manning"
                ],
                "title": "Effective approaches to attentionbased neural machine translation",
                "pub_date": "2015",
                "pub_title": "Proceedings of EMNLP",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_96",
            "content": "Andre Martins, Ramon Astudillo, From softmax to sparsemax: A sparse model of attention and multi-label classification, 2016, Proceedings of ICML, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "Andre Martins",
                    "Ramon Astudillo"
                ],
                "title": "From softmax to sparsemax: A sparse model of attention and multi-label classification",
                "pub_date": "2016",
                "pub_title": "Proceedings of ICML",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_97",
            "content": "Clara Meister, Stefan Lazov, Isabelle Augenstein, Ryan Cotterell, Is sparse attention more interpretable?, 2021, Proceedings of ACL-IJCNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": [
                    "Clara Meister",
                    "Stefan Lazov",
                    "Isabelle Augenstein",
                    "Ryan Cotterell"
                ],
                "title": "Is sparse attention more interpretable?",
                "pub_date": "2021",
                "pub_title": "Proceedings of ACL-IJCNLP",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_98",
            "content": "Volodymyr Mnih, Nicolas Heess, Alex Graves, Recurrent models of visual attention, 2014, Proceedings of NeurIPS, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": [
                    "Volodymyr Mnih",
                    "Nicolas Heess",
                    "Alex Graves"
                ],
                "title": "Recurrent models of visual attention",
                "pub_date": "2014",
                "pub_title": "Proceedings of NeurIPS",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_99",
            "content": "Akash Kumar Mohankumar, Preksha Nema, Sharan Narasimhan, M Mitesh,  Khapra, Balaraman Balaji Vasan Srinivasan,  Ravindran, Towards transparent and explainable attention models, 2020, Proceedings of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": [
                    "Akash Kumar Mohankumar",
                    "Preksha Nema",
                    "Sharan Narasimhan",
                    "M Mitesh",
                    " Khapra",
                    "Balaraman Balaji Vasan Srinivasan",
                    " Ravindran"
                ],
                "title": "Towards transparent and explainable attention models",
                "pub_date": "2020",
                "pub_title": "Proceedings of ACL",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_100",
            "content": "Pooya Moradi, Nishant Kambhatla, Anoop Sarkar, Measuring and improving faithfulness of attention in neural machine translation, 2021, Proceedings of EACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": [
                    "Pooya Moradi",
                    "Nishant Kambhatla",
                    "Anoop Sarkar"
                ],
                "title": "Measuring and improving faithfulness of attention in neural machine translation",
                "pub_date": "2021",
                "pub_title": "Proceedings of EACL",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_101",
            "content": "James Mullenbach, Sarah Wiegreffe, Jon Duke, Jimeng Sun, Jacob Eisenstein, Explainable prediction of medical codes from clinical text, 2018, Proceedings of NAACL-HLT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": [
                    "James Mullenbach",
                    "Sarah Wiegreffe",
                    "Jon Duke",
                    "Jimeng Sun",
                    "Jacob Eisenstein"
                ],
                "title": "Explainable prediction of medical codes from clinical text",
                "pub_date": "2018",
                "pub_title": "Proceedings of NAACL-HLT",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_102",
            "content": "Michael Neely, F Stefan,  Schouten, J Maurits, Ana Bleeker,  Lucic, Order in the court: Explainable AI methods prone to disagreement, 2021, Proceedings of the ICML Workshop on Theoretic Foundation, Criticism, and Application Trend of Explainable AI, .",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": [
                    "Michael Neely",
                    "F Stefan",
                    " Schouten",
                    "J Maurits",
                    "Ana Bleeker",
                    " Lucic"
                ],
                "title": "Order in the court: Explainable AI methods prone to disagreement",
                "pub_date": "2021",
                "pub_title": "Proceedings of the ICML Workshop on Theoretic Foundation, Criticism, and Application Trend of Explainable AI",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_103",
            "content": "Danish Pruthi, Mansi Gupta, Bhuwan Dhingra, Graham Neubig, Zachary Lipton, Learning to deceive with attention-based explanations, 2020, Proceedings of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "Danish Pruthi",
                    "Mansi Gupta",
                    "Bhuwan Dhingra",
                    "Graham Neubig",
                    "Zachary Lipton"
                ],
                "title": "Learning to deceive with attention-based explanations",
                "pub_date": "2020",
                "pub_title": "Proceedings of ACL",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_104",
            "content": "UNKNOWN, None, 2021, Explainable deep learning: A field guide for the uninitiated, .",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Explainable deep learning: A field guide for the uninitiated",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_105",
            "content": "A Ronald,  Rensink, The dynamic representation of scenes, 2000, Visual cognition, .",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": [
                    "A Ronald",
                    " Rensink"
                ],
                "title": "The dynamic representation of scenes",
                "pub_date": "2000",
                "pub_title": "Visual cognition",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_106",
            "content": "Sameer Marco Tulio Ribeiro, Carlos Singh,  Guestrin, Explaining the predictions of any classifier, 2016, Proceedings of the ACM SIGKDD Conference, .",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": [
                    "Sameer Marco Tulio Ribeiro",
                    "Carlos Singh",
                    " Guestrin"
                ],
                "title": "Explaining the predictions of any classifier",
                "pub_date": "2016",
                "pub_title": "Proceedings of the ACM SIGKDD Conference",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_107",
            "content": "O Mark,  Riedl, Human-centered artificial intelligence and machine learning, 2019, Human Behavior and Emerging Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b40",
                "authors": [
                    "O Mark",
                    " Riedl"
                ],
                "title": "Human-centered artificial intelligence and machine learning",
                "pub_date": "2019",
                "pub_title": "Human Behavior and Emerging Technologies",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_108",
            "content": "Cynthia Rudin, Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead, 2019, Nature Machine Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b41",
                "authors": [
                    "Cynthia Rudin"
                ],
                "title": "Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead",
                "pub_date": "2019",
                "pub_title": "Nature Machine Intelligence",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_109",
            "content": "Cansu Sen, Thomas Hartvigsen, Biao Yin, Xiangnan Kong, Elke Rundensteiner, Human attention maps for text classification: Do humans and neural networks focus on the same words?, 2020, Proceedings of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b42",
                "authors": [
                    "Cansu Sen",
                    "Thomas Hartvigsen",
                    "Biao Yin",
                    "Xiangnan Kong",
                    "Elke Rundensteiner"
                ],
                "title": "Human attention maps for text classification: Do humans and neural networks focus on the same words?",
                "pub_date": "2020",
                "pub_title": "Proceedings of ACL",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_110",
            "content": "Sofia Serrano, A Noah,  Smith, Is attention interpretable?, 2019, Proceedings of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b43",
                "authors": [
                    "Sofia Serrano",
                    "A Noah",
                    " Smith"
                ],
                "title": "Is attention interpretable?",
                "pub_date": "2019",
                "pub_title": "Proceedings of ACL",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_111",
            "content": "Ekta Sood, Simon Tannert, Diego Frassinelli, Andreas Bulling, Ngoc Vu, Interpreting attention models with human visual attention in machine reading comprehension, 2020, Proceedings of CoNLL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b44",
                "authors": [
                    "Ekta Sood",
                    "Simon Tannert",
                    "Diego Frassinelli",
                    "Andreas Bulling",
                    "Ngoc Vu"
                ],
                "title": "Interpreting attention models with human visual attention in machine reading comprehension",
                "pub_date": "2020",
                "pub_title": "Proceedings of CoNLL",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_112",
            "content": "Julia Strout, Ye Zhang, Raymond Mooney, Do human rationales improve machine explanations?, 2019, Proceedings of the ACL Workshop Black-boxNLP: Analyzing and Interpreting Neural Networks for NLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b45",
                "authors": [
                    "Julia Strout",
                    "Ye Zhang",
                    "Raymond Mooney"
                ],
                "title": "Do human rationales improve machine explanations?",
                "pub_date": "2019",
                "pub_title": "Proceedings of the ACL Workshop Black-boxNLP: Analyzing and Interpreting Neural Networks for NLP",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_113",
            "content": "Kaiser Sun, Ana Marasovi\u0107, Effective attention sheds light on interpretability, 2021, Findings of ACL-IJCNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b46",
                "authors": [
                    "Kaiser Sun",
                    "Ana Marasovi\u0107"
                ],
                "title": "Effective attention sheds light on interpretability",
                "pub_date": "2021",
                "pub_title": "Findings of ACL-IJCNLP",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_114",
            "content": "Xiaobing Sun, Wei Lu, Understanding attention for text classification, 2020, Proceedings of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b47",
                "authors": [
                    "Xiaobing Sun",
                    "Wei Lu"
                ],
                "title": "Understanding attention for text classification",
                "pub_date": "2020",
                "pub_title": "Proceedings of ACL",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_115",
            "content": "Ian Tenney, Dipanjan Das, Ellie Pavlick, BERT rediscovers the classical NLP pipeline, 2019, Proceedings of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b48",
                "authors": [
                    "Ian Tenney",
                    "Dipanjan Das",
                    "Ellie Pavlick"
                ],
                "title": "BERT rediscovers the classical NLP pipeline",
                "pub_date": "2019",
                "pub_title": "Proceedings of ACL",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_116",
            "content": "James Thorne, Andreas Vlachos, Generating token-level explanations for natural language inference, 2019, Proceedings of NAACL-HLT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b49",
                "authors": [
                    "James Thorne",
                    "Andreas Vlachos"
                ],
                "title": "Generating token-level explanations for natural language inference",
                "pub_date": "2019",
                "pub_title": "Proceedings of NAACL-HLT",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_117",
            "content": "Martin Tutek, Staying true to your word:(how) can attention become explanation?, 2020, Proceedings of the ACL Workshop on Representation Learning for NLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b50",
                "authors": [
                    "Martin Tutek"
                ],
                "title": "Staying true to your word:(how) can attention become explanation?",
                "pub_date": "2020",
                "pub_title": "Proceedings of the ACL Workshop on Representation Learning for NLP",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_118",
            "content": "UNKNOWN, None, 2019, Attention interpretability across NLP tasks, .",
            "ntype": "ref",
            "meta": {
                "xid": "b51",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Attention interpretability across NLP tasks",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_119",
            "content": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Attention is all you need, 2017, Proceedings of NeurIPS, .",
            "ntype": "ref",
            "meta": {
                "xid": "b52",
                "authors": [
                    "Ashish Vaswani",
                    "Noam Shazeer",
                    "Niki Parmar",
                    "Jakob Uszkoreit",
                    "Llion Jones",
                    "Aidan Gomez",
                    "\u0141ukasz Kaiser",
                    "Illia Polosukhin"
                ],
                "title": "Attention is all you need",
                "pub_date": "2017",
                "pub_title": "Proceedings of NeurIPS",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_120",
            "content": "Jesse Vig, Yonatan Belinkov, Analyzing the structure of attention in a transformer language model, 2019, Proceedings of the ACL Workshop Black-boxNLP: Analyzing and Interpreting Neural Networks for NLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b53",
                "authors": [
                    "Jesse Vig",
                    "Yonatan Belinkov"
                ],
                "title": "Analyzing the structure of attention in a transformer language model",
                "pub_date": "2019",
                "pub_title": "Proceedings of the ACL Workshop Black-boxNLP: Analyzing and Interpreting Neural Networks for NLP",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_121",
            "content": "Elena Voita, Pavel Serdyukov, Rico Sennrich, Ivan Titov, Context-aware neural machine translation learns anaphora resolution, 2018, Proceedings of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b54",
                "authors": [
                    "Elena Voita",
                    "Pavel Serdyukov",
                    "Rico Sennrich",
                    "Ivan Titov"
                ],
                "title": "Context-aware neural machine translation learns anaphora resolution",
                "pub_date": "2018",
                "pub_title": "Proceedings of ACL",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_122",
            "content": "Sarah Wiegreffe, Yuval Pinter, Attention is not not explanation, 2019, Proceedings of EMNLP-IJCNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b55",
                "authors": [
                    "Sarah Wiegreffe",
                    "Yuval Pinter"
                ],
                "title": "Attention is not not explanation",
                "pub_date": "2019",
                "pub_title": "Proceedings of EMNLP-IJCNLP",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_123",
            "content": "Qizhe Xie, Xuezhe Ma, Zihang Dai, Eduard Hovy, An interpretable knowledge transfer model for knowledge base completion, 2017, Proceedings of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b56",
                "authors": [
                    "Qizhe Xie",
                    "Xuezhe Ma",
                    "Zihang Dai",
                    "Eduard Hovy"
                ],
                "title": "An interpretable knowledge transfer model for knowledge base completion",
                "pub_date": "2017",
                "pub_title": "Proceedings of ACL",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_124",
            "content": "Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhudinov, Rich Zemel, Yoshua Bengio, Show, attend and tell: Neural image caption generation with visual attention, 2015, Proceedings of ICML, .",
            "ntype": "ref",
            "meta": {
                "xid": "b57",
                "authors": [
                    "Kelvin Xu",
                    "Jimmy Ba",
                    "Ryan Kiros",
                    "Kyunghyun Cho",
                    "Aaron Courville",
                    "Ruslan Salakhudinov",
                    "Rich Zemel",
                    "Yoshua Bengio"
                ],
                "title": "Show, attend and tell: Neural image caption generation with visual attention",
                "pub_date": "2015",
                "pub_title": "Proceedings of ICML",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_125",
            "content": "Cheng Zhang, Qiuchi Lingyu Hua, Dawei Song, How does attention affect the model?, 2021, Findings of ACL-IJCNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b58",
                "authors": [
                    "Cheng Zhang",
                    "Qiuchi Lingyu Hua",
                    "Dawei Song"
                ],
                "title": "How does attention affect the model?",
                "pub_date": "2021",
                "pub_title": "Findings of ACL-IJCNLP",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_126",
            "content": "Han Zhang, Ian Goodfellow, Dimitris Metaxas, Augustus Odena, Self-attention generative adversarial networks, 2019, Proceedings of ICML, .",
            "ntype": "ref",
            "meta": {
                "xid": "b59",
                "authors": [
                    "Han Zhang",
                    "Ian Goodfellow",
                    "Dimitris Metaxas",
                    "Augustus Odena"
                ],
                "title": "Self-attention generative adversarial networks",
                "pub_date": "2019",
                "pub_title": "Proceedings of ICML",
                "pub": null
            }
        },
        {
            "ix": "419-ARR_v1_127",
            "content": "UNKNOWN, None, 2019, Fine-grained sentiment analysis with faithful attention, .",
            "ntype": "ref",
            "meta": {
                "xid": "b60",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Fine-grained sentiment analysis with faithful attention",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "419-ARR_v1_0@0",
            "content": "Is Attention Explanation? An Introduction to the Debate",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_0",
            "start": 0,
            "end": 54,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_2@0",
            "content": "The performance of deep learning models in NLP and other fields of machine learning has led to a rise in their popularity, and so the need for explanations of these models becomes paramount.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_2",
            "start": 0,
            "end": 189,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_2@1",
            "content": "Attention has been seen as a solution to increase performance, while providing some explanations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_2",
            "start": 191,
            "end": 287,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_2@2",
            "content": "However, a debate has started to cast doubt on the explanatory power of attention in neural networks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_2",
            "start": 289,
            "end": 389,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_2@3",
            "content": "Although the debate has created a vast literature thanks to contributions from various areas, the lack of communication is becoming more and more tangible.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_2",
            "start": 391,
            "end": 545,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_2@4",
            "content": "In this paper, we provide a clear overview of the insights on the debate by critically confronting works from these different areas.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_2",
            "start": 547,
            "end": 678,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_2@5",
            "content": "This holistic vision can be of great interest for future works in all the communities concerned by this debate.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_2",
            "start": 680,
            "end": 790,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_2@6",
            "content": "We sum up the main challenges spotted in these areas, and we conclude by discussing the most promising future avenues on attention as an explanation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_2",
            "start": 792,
            "end": 940,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_4@0",
            "content": "Attention mechanisms have been widely used in various tasks of Natural Language Processing (NLP) as well as in other fields of machine learning (e.g., Computer Vision (Mnih et al., 2014;Li et al., 2019)).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_4",
            "start": 0,
            "end": 203,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_4@1",
            "content": "These mechanisms draw insight from the intuition that humans build the representation of a whole scene by dynamically focusing on relevant parts at different times (Rensink, 2000).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_4",
            "start": 205,
            "end": 384,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_5@0",
            "content": "The general form of attention has been named differently according to authors (alignment model (Bahdanau et al., 2015) and attention mechanism (Vaswani et al., 2017)).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_5",
            "start": 0,
            "end": 166,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_5@1",
            "content": "In essence, the attention function maps a query Q and keys K to scalar scores (Vaswani et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_5",
            "start": 168,
            "end": 268,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_5@2",
            "content": "These scores are fed to a softmax function, in turn producing a set of attention weights that are then applied to values V. Different kinds of attention are thus possible according to how many keys are attended to (global vs. local attention, according to Luong et al. (2015)) and where the query is generated (cross vs. self-attention as in the works of Bahdanau et al. (2015) and Vaswani et al. (2017)).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_5",
            "start": 270,
            "end": 674,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_5@3",
            "content": "In this paper, we focus on attention regardless of these technical differences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_5",
            "start": 676,
            "end": 754,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_5@4",
            "content": "There are mainly two ways of computing the attention weights \u03b1: Bahdanau et al. (2015) introduced additive attention \u03b1 = softmax(w 3 T tanh(W 1 K + W 2 Q)), where w 3 , W 1 , W 2 model parameters to be learned, and Vaswani et al. (2017) introduced scaled dot-product attention \u03b1 = softmax KQ \u221a m , where m represents the dimension of K. These two forms are theoretically similar (Vaswani et al., 2017) and generally give the same results (Jain and Wallace, 2019), the dot-product form being faster on certain tasks from a practical point of view.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_5",
            "start": 756,
            "end": 1301,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_6@0",
            "content": "Since the introduction of attention mechanisms in the literature, many have seen the opportunity to use the weights for explaining neural networks (e.g., Xu et al. (2015); Martins and Astudillo (2016); Choi et al. (2016); Xie et al. (2017); Mullenbach et al. (2018)).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_6",
            "start": 0,
            "end": 266,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_6@1",
            "content": "Explainability in machine learning and NLP is defined as the capacity to explain a non-interpretable (Bibal and Fr\u00e9nay, 2016), i.e. black-box, model (Guidotti et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_6",
            "start": 268,
            "end": 440,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_6@2",
            "content": "The two major ways to explain black-box models are global explanations, providing clues about the behavior of the model as a whole, and local explanations, explaining particular decisions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_6",
            "start": 442,
            "end": 629,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_6@3",
            "content": "Using attention to explain neural networks mainly pertains to the latter, even if some authors study attention for global explanation (e.g., Clark et al. (2019)).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_6",
            "start": 631,
            "end": 792,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_7@0",
            "content": "Explanations can also be faithful (how close the explanation is to the inner workings of the model) (Rudin, 2019;Jacovi and Goldberg, 2020), or plausible (does the user consider the explanation of the model plausible?) (Riedl, 2019;Jacovi and Goldberg, 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_7",
            "start": 0,
            "end": 258,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_7@1",
            "content": "It should be noted that explanation presupposes some degree of transparency to the user, whether it is faithful or plausible.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_7",
            "start": 260,
            "end": 384,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_7@2",
            "content": "Indeed, disregarding this aspect would entail that the most faithful explanation is the black-box model itself.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_7",
            "start": 386,
            "end": 496,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_8@0",
            "content": "Recently, a debate fundamentally questioned whether attention can be used as explanation (Jain and Wallace, 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_8",
            "start": 0,
            "end": 113,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_8@1",
            "content": "An immediate response by Wiegreffe and Pinter (2019) challenged some of the arguments of Jain and Wallace (2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_8",
            "start": 115,
            "end": 227,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_8@2",
            "content": "To this day, the debate about \"is attention explanation?\" continues and is the source of a rich and diverse literature.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_8",
            "start": 229,
            "end": 347,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_8@3",
            "content": "Researchers from different areas have mostly contributed to this debate without referring to works outside, and sometimes even inside, their area.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_8",
            "start": 349,
            "end": 494,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_8@4",
            "content": "These insights include theoretical analyses of attention, the necessity to bring users in the loop, questioning the evaluation methodology for model explanation, and more.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_8",
            "start": 496,
            "end": 666,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_9@0",
            "content": "This paper aims at bringing together the papers from these different areas in order to provide an outline of the quickly growing and vast literature on the subject.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_9",
            "start": 0,
            "end": 163,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_9@1",
            "content": "Moreover, we discuss the lessons learned and highlight the main issues and perspectives.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_9",
            "start": 165,
            "end": 252,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_9@2",
            "content": "To accurately reflect the debate, we only focus on papers that are posterior to the works of Jain and Wallace (2019) and Wiegreffe and Pinter (2019), and that explicitly rely on these two papers to contribute to the debate.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_9",
            "start": 254,
            "end": 476,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_9@3",
            "content": "This paper proposes the first introduction to the debate about \"is attention explanation?\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_9",
            "start": 478,
            "end": 568,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_9@4",
            "content": "The main contributions of this work are as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_9",
            "start": 570,
            "end": 620,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_10@0",
            "content": "\u2022 a summary and a discussion of the actual state of the debate by identifying convergences and disagreements in the literature; \u2022 an extraction and structure of the main insights from papers of different areas that generally do not interact; and \u2022 the bases for developing research on attention as explanation, with a more integrated state-ofthe-art built upon a multitude of perspectives.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_10",
            "start": 0,
            "end": 388,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_11@0",
            "content": "In order to present the different insights on the debate, we briefly summarize the two seminal papers (Section 2), describing the arguments of the two original papers that represent the source of the ongoing debate.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_11",
            "start": 0,
            "end": 214,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_11@1",
            "content": "We also present survey papers that mention the debate within a broader context (Section 3).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_11",
            "start": 216,
            "end": 306,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_11@2",
            "content": "We then investigate the different research perspectives we extracted from the literature (Sections 4 to 9).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_11",
            "start": 308,
            "end": 414,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_11@3",
            "content": "Finally, we analyze the insights offered by those works and offer foundations to build upon for future research related to attention as explanation (Section 10).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_11",
            "start": 416,
            "end": 576,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_12@0",
            "content": "Starting Point of the Debate",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_12",
            "start": 0,
            "end": 27,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_13@0",
            "content": "Jain and Wallace (2019) make a set of observations on attention weights in a battery of experiments: (i) an analysis of the correlations between attention weights and feature importance methods (gradientbased and leave-one-out) and (ii) a study of the impact of counterfactual attention weight distributions on the final prediction by randomly shuffling the attention weights, and by shuffling them adversarially (i.e., by creating distributions that correspond to a focus on a different set of features than the one in the original attention distribution).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_13",
            "start": 0,
            "end": 556,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_13@1",
            "content": "The experiments are performed on three tasks: binary text classification, question answering and natural language inference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_13",
            "start": 558,
            "end": 681,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_13@2",
            "content": "When commenting upon the results of their experiments, the authors' observations are: (i) there are poor correlations between attention weights and gradient-based or leave-oneout methods for explanation and (ii) shuffling the attention weights in a neural model does not affect the final prediction, except for some rare cases where the prediction relies on a few high precision tokens.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_13",
            "start": 683,
            "end": 1068,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_13@3",
            "content": "The conclusion they draw from the poor correlations with other explanation methods and the lack of exclusive explanation is that attention cannot be used as a means of explanation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_13",
            "start": 1070,
            "end": 1249,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_13@4",
            "content": "Wiegreffe and Pinter (2019) agree on the importance of the questions raised by Jain and Wallace (2019) and reply to their claims.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_13",
            "start": 1251,
            "end": 1379,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_13@5",
            "content": "They agree with the first observation and the corresponding experimental setup.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_13",
            "start": 1381,
            "end": 1459,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_13@6",
            "content": "However, they object to the second claim, stating that only modifying the attention weights in the model does not produce a real attention-based model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_13",
            "start": 1461,
            "end": 1611,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_13@7",
            "content": "Indeed, if the attention weights should be modified for experimental purposes, then the model should be retrained to correspond to a real trained model with those modified attention weights.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_13",
            "start": 1613,
            "end": 1802,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_13@8",
            "content": "In addition, they also object to the exclusive explanation argument that attention is \"an explanation, not the explanation\" (Wiegreffe and Pinter, 2019, p. 13).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_13",
            "start": 1804,
            "end": 1963,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_13@9",
            "content": "Indeed, several plausible explanations can co-exist for a similar degree of faithfulness.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_13",
            "start": 1965,
            "end": 2053,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_14@0",
            "content": "The clash between the initial use of attention as explanation and the 2019 studies showing that attention might not be explanation started a vast literature on the subject.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_14",
            "start": 0,
            "end": 171,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_14@1",
            "content": "The following section presents survey papers that are mentioning the debate within a broader perspective.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_14",
            "start": 173,
            "end": 277,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_15@0",
            "content": "Survey Papers Mentioning the Debate",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_15",
            "start": 0,
            "end": 34,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_16@0",
            "content": "Usually, when exploring a question, survey papers are a good starting point, as they have the advantage of covering a broader scope.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_16",
            "start": 0,
            "end": 131,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_16@1",
            "content": "However, there is no in-depth introduction to the debate, as survey papers only briefly mention the debate and sometimes do not really add something significant for the discussion (e.g., Chaudhari et al. (2019) and Lindsay (2020)).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_16",
            "start": 133,
            "end": 363,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_16@2",
            "content": "Please note that we only discuss surveys that add significant elements to the discussion.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_16",
            "start": 365,
            "end": 453,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_16@3",
            "content": "Galassi et al. (2020) propose a survey on attention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_16",
            "start": 455,
            "end": 506,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_16@4",
            "content": "They recall the results of Jain and Wallace (2019) on the fact that attention may not be explanation, but also refer to the fact that only faithful explanations (and not plausible ones; see Section 7) are considered.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_16",
            "start": 508,
            "end": 723,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_16@5",
            "content": "The \"explanation\" perspective of the survey is focused on the work of , which discusses how well attention captures the importance of abstract features in multilayer neural networks when dealing with images.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_16",
            "start": 725,
            "end": 931,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_16@6",
            "content": "Galassi et al. (2020) argue that an answer to the question \"is attention explanation?\" with image data may not generalize to text, and should be verified, as human understanding mechanisms strongly differ between images and texts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_16",
            "start": 933,
            "end": 1162,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_17@0",
            "content": "de Santana Correia and Colombini (2021) introduce the debate in broad terms in Section 5.7 of their survey, but point out that, based on the work of Vashishth et al. (2019), the answer to the question \"is attention explanation?\" can take different shapes based on the NLP task that is studied (see our Section 6 for more details on this point of the debate).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_17",
            "start": 0,
            "end": 357,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_17@1",
            "content": "Later in their paper, they also mention, like Galassi et al. (2020), that some works show that attention in transformers focuses on syntactical structures (Voita et al., 2018;Vig and Belinkov, 2019;Tenney et al., 2019;Clark et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_17",
            "start": 359,
            "end": 596,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_17@2",
            "content": "This indicates that global explanations based on attention can be provided, but do not answer the need for the local, decision-based, explanation that is mainly discussed in the debate.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_17",
            "start": 598,
            "end": 782,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_17@3",
            "content": "Ras et al. (2021) also stress that the debate has been extended to several NLP tasks in the work of Vashishth et al. (2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_17",
            "start": 784,
            "end": 907,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_17@4",
            "content": "They add the information that mixed results have been obtained in the debate (Serrano and Smith, 2019;Baan et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_17",
            "start": 909,
            "end": 1029,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_18@0",
            "content": "Contrary to the short introductions to the debate in these survey papers, we aim at providing a clear and rather exhaustive view of the different ways the debate is tackled in the literature.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_18",
            "start": 0,
            "end": 190,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_18@1",
            "content": "The different insights on the debate, which are unfortunately not regrouped and discussed in these surveys (because the debate is not their main focus), are numerous: some papers add arguments about the fact that attention is not explanation (Section 4), provide analyses to explain why attention is not explanation (Section 5), analyze the debate on different NLP tasks (Section 6), discuss the methodological issues at the heart of the debate (Section 7), evaluate the explanatory power of attention with humans (Section 8), or propose solutions to make attention become explanation (based on technical developments or on user-in-the-loop strategies) (Section 9).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_18",
            "start": 192,
            "end": 856,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_19@0",
            "content": "Additional Arguments about Attention is not Explanation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_19",
            "start": 0,
            "end": 54,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_20@0",
            "content": "Some works may be considered as the direct continuation of the arguments of Jain and Wallace ( 2019) by adding experiments that corroborate their findings, e.g., by showing that the comparison of attention with other explainable methods different from the gradient-based one leads to similar conclusions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_20",
            "start": 0,
            "end": 303,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_20@1",
            "content": "Serrano and Smith (2019) show that removing features considered as important by attention less often leads to a decision flip than removing features considered important by gradient-based methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_20",
            "start": 305,
            "end": 500,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_20@2",
            "content": "This means that the features deemed important by attention for a decision are not so important for the model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_20",
            "start": 502,
            "end": 610,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_20@3",
            "content": "This, therefore, adds to the first argument of Jain and Wallace (2019) against the relevance of attention as an indicator of feature importance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_20",
            "start": 612,
            "end": 755,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_20@4",
            "content": "Thorne et al. (2019) demonstrate that applying LIME (Ribeiro et al., 2016) on an attention-based neural network can provide good explanations that the attention itself cannot provide.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_20",
            "start": 757,
            "end": 939,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_20@5",
            "content": "They conclude on this subject that their experimental results are aligned with the ones of Jain and Wallace (2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_20",
            "start": 941,
            "end": 1055,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_21@0",
            "content": "Mohankumar et al. ( 2020) investigate attention on top of LSTMs (attention-LSTMs).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_21",
            "start": 0,
            "end": 81,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_21@1",
            "content": "Their study focuses on why attention in such models neither provides plausible, nor faithful, explanations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_21",
            "start": 83,
            "end": 189,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_21@2",
            "content": "They use a variety of NLP tasks (sentiment analysis, natural language inference, question answering and paraphrase detection) and randomly permute attention weights as Jain and Wallace (2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_21",
            "start": 191,
            "end": 382,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_21@3",
            "content": "They find that attention-LSTM's outputs do not change much after the permutation and conclude that attention weights are not faithful explanations in attention-LSTMs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_21",
            "start": 384,
            "end": 549,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_21@4",
            "content": "The authors propose changes to attention-LSTMs to make attention a faithful explanation (see Section 9.1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_21",
            "start": 551,
            "end": 656,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_21@5",
            "content": "Moreover, by analyzing the attention given to part-of-speech tags, they find that the model cannot provide a plausible explanation either, since, for several datasets, a significant amount of attention is given to punctuation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_21",
            "start": 658,
            "end": 883,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_22@0",
            "content": "Finally, Ethayarajh and Jurafsky (2021) show that attention weights are not Shapley values (i.e. a method for feature importance) (Lundberg and Lee, 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_22",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_22@1",
            "content": "This result is in line with Jain and Wallace (2019) on the fact that the attention weights do not correlate with other explanation techniques (saliency maps or Shapley values).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_22",
            "start": 156,
            "end": 331,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_22@2",
            "content": "The authors however note that attention flows (i.e. an extension of attention weights obtained after postprocessing) (Abnar and Zuidema, 2020) are Shapley values, which may indicate that using attention in another way could lead to explanation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_22",
            "start": 333,
            "end": 576,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_23@0",
            "content": "Analyses of Why Attention is not Explanation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_23",
            "start": 0,
            "end": 43,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_24@0",
            "content": "In addition to the arguments in the literature on the fact that attention is not explanation, another part of the literature focuses on understanding the reasons why it is not explanation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_24",
            "start": 0,
            "end": 187,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_24@1",
            "content": "Bai et al. (2021) show that attention can be put on uninteresting tokens because of an effect they call \"combinatorial shortcuts\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_24",
            "start": 189,
            "end": 318,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_24@2",
            "content": "The key idea is that attention is calculated on the basis of a biased input: \"the attention mechanism will try to select biased features to adapt the biased estimations to minimize the overall loss functions\" (Bai et al., 2021, p. 27).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_24",
            "start": 320,
            "end": 554,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_24@3",
            "content": "For instance, if one adds random tokens (such as A, B, and C) to all documents in a corpus, one might find that some of these tokens are considered as important for the positive (or negative) class because their representation ends up being similar to the representation of \"good\" (or \"bad\"), even if their information content for the task is negligible, as they are present in all documents.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_24",
            "start": 556,
            "end": 947,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_24@4",
            "content": "Brunner et al. (2020) theoretically show that attention weights in transformers can be decomposed into two parts, from which the \"effective attention\" part corresponds to the attention that really affects the output.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_24",
            "start": 949,
            "end": 1164,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_24@5",
            "content": "Effective attention focuses on the effective input needed by the model for the task and is not biased by the representation of the input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_24",
            "start": 1166,
            "end": 1302,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_24@6",
            "content": "Kobayashi et al. (2020) extend the work of Brunner et al. (2020), but focus on describing the effective attention part in more detail instead of using it to improve the model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_24",
            "start": 1304,
            "end": 1478,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_24@7",
            "content": "Likewise, Sun and Marasovi\u0107 (2021) also extend the work of Brunner et al. (2020) and delve deeper into the explanation of effective attention and its use for explaining the model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_24",
            "start": 1480,
            "end": 1658,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_24@8",
            "content": "Sun and Lu (2020) study attention through two specific scores: attention and polarization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_24",
            "start": 1660,
            "end": 1749,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_24@9",
            "content": "The attention score corresponds to the absolute value associated with each input token before the transformation into an attention weight.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_24",
            "start": 1751,
            "end": 1888,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_24@10",
            "content": "The polarization score is a global score (not instance-specific) for each input token, indicating its importance for predicting the positive or negative class.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_24",
            "start": 1890,
            "end": 2048,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_24@11",
            "content": "The authors show through these two scores why attentionbased models are stable in their prediction, even when attention weights differ.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_24",
            "start": 2050,
            "end": 2184,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_24@12",
            "content": "They also show that the match between attention and polarizing scores strongly depends on the hyperparameter values.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_24",
            "start": 2186,
            "end": 2301,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_25@0",
            "content": "By analyzing the effect of regularization on attention, Tutek and \u0160najder (2020) show that one of the reasons why attention cannot be used as a faithful explanation is due to the fact that all input tokens roughly have the same influence on the prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_25",
            "start": 0,
            "end": 255,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_25@1",
            "content": "The authors show that regularizing attention-based models so that embedded tokens e t better correspond to their hidden representation rnn(e t ) produces explanations that are more faithful to the model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_25",
            "start": 257,
            "end": 459,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_25@2",
            "content": "However, Meister et al. (2021) show that regularizing generally decreases the correlation between attention and explanation techniques, if the regularization is directed towards sparse attention weights.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_25",
            "start": 461,
            "end": 663,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_25@3",
            "content": "The authors conclude that sparsity, which is often viewed as increasing interpretability of models in the literature, in this case reduces the faithfulness of explanations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_25",
            "start": 665,
            "end": 836,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_26@0",
            "content": "Another way to analyze the problem is to study the change in the representation of the meaning of a sentence when (i) an attention layer is added, and when (ii) the type of RNN encoding the input is changed .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_26",
            "start": 0,
            "end": 207,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_26@1",
            "content": "The authors show that, in addition to an increase in accuracy, the use of attention also makes the model more stable in terms of representation of sentence meanings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_26",
            "start": 209,
            "end": 373,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_27@0",
            "content": "Is Attention Explanation on Different",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_27",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_28@0",
            "content": "Tasks?",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_28",
            "start": 0,
            "end": 5,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_29@0",
            "content": "In this section, we introduce arguments from the literature that claim that, despite some proofs that attention is not always explanation, attention can be explanation on certain NLP tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_29",
            "start": 0,
            "end": 188,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_29@1",
            "content": "In general, attention mechanisms seem to provide faithful explanations in syntax-related tasks such as part-ofspeech tagging and syntactic annotation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_29",
            "start": 190,
            "end": 339,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_29@2",
            "content": "Clark et al. (2019) thus investigate the attention heads in BERT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_29",
            "start": 341,
            "end": 405,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_29@3",
            "content": "They explore syntactic dependency tagging and co-reference resolution.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_29",
            "start": 407,
            "end": 476,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_29@4",
            "content": "They find that attention heads at different layers attend to different kinds of information (e.g., direct objects of verbs, determiners of nouns or referential antecedents), with earlier layers having a broader attention span.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_29",
            "start": 478,
            "end": 703,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_29@5",
            "content": "Furthermore, attention heads in the same layer tend to show similar distributions, which is a counter to the argument of Li et al. (2018) on the fact that encouraging attention heads to learn different distributions within layers can improve performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_29",
            "start": 705,
            "end": 958,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_30@0",
            "content": "Overall, knowledge of syntax seems to be encoded by a variety of attention heads in different layers, and thus attention can be used as a global explanation for the tasks under investigation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_30",
            "start": 0,
            "end": 190,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_31@0",
            "content": "Similarly, Vig and Belinkov (2019) investigate attention in GPT-2, in particular for two tasks: partof-speech and syntactic tagging.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_31",
            "start": 0,
            "end": 131,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_31@1",
            "content": "They find that each part-of-speech is attended to by a specific subset of attention heads, and that attention heads in adjacent layers attend to similar part-of-speech tags.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_31",
            "start": 133,
            "end": 305,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_31@2",
            "content": "In general, attention shows which tokens were attended to for the tasks at hand and can thus be used as a global explanation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_31",
            "start": 307,
            "end": 431,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_32@0",
            "content": "In a different vein, Vashishth et al. (2019) investigate the role of attention across a variety of NLP tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_32",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_32@1",
            "content": "They show that, when the input consists of a single sequence (e.g., in sentiment classification), the attention mechanism is comparable to a gating unit and, as such, the learned weights cannot be interpreted as attention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_32",
            "start": 110,
            "end": 331,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_32@2",
            "content": "Therefore, in this context, attention does not provide an explanation of the model's reasoning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_32",
            "start": 333,
            "end": 427,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_32@3",
            "content": "The reduction of attention to gating units however does not hold true for selfattention networks nor for tasks depending on an additional text sequence, as for example in neural machine translation or natural language inference (pair-wise tasks and text generation tasks).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_32",
            "start": 429,
            "end": 700,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_32@4",
            "content": "In such cases, altering learned attention weights significantly degrades performance and attention appears to be an explanation of the model and to correlate with feature importance measures.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_32",
            "start": 702,
            "end": 892,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_33@0",
            "content": "Evaluation Methodology for Explanation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_33",
            "start": 0,
            "end": 37,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_34@0",
            "content": "This section focuses on critics of the methodology when evaluating explanations via attention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_34",
            "start": 0,
            "end": 93,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_34@1",
            "content": "The critics mainly focus on two points in the evaluation setup of Jain and Wallace (2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_34",
            "start": 95,
            "end": 184,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_34@2",
            "content": "First, Jain and Wallace (2019) claim that there should be a consistency between attention weights and other explanation methods -which Wiegreffe and Pinter (2019) agree with -and find none.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_34",
            "start": 186,
            "end": 374,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_34@3",
            "content": "Second, they state that the fact that attention could offer different explanations (which they show by shuffling the attention weights) is an issue, which is a strong point of disagreement with Wiegreffe and Pinter (2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_34",
            "start": 376,
            "end": 597,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_35@0",
            "content": "Regarding the first point, Neely et al. (2021) compare explanation methods from the literature (LIME, Integrated Gradients, DeepLIFT, Grad-SHAP and Deep-SHAP) with attention-based explanations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_35",
            "start": 0,
            "end": 192,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_35@1",
            "content": "The comparison is performed on two types of classification: single-sequence classification (sentiment classification) and pair-sequence classification (language inference and understanding, and question answering).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_35",
            "start": 194,
            "end": 407,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_35@2",
            "content": "The authors find small agreement between the different explanation methods, including attention-based explanations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_35",
            "start": 409,
            "end": 523,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_35@3",
            "content": "They conclude that checking for consistency between explanation methods should not be a criterion for evaluation, which goes against the agreement between the two seminal papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_35",
            "start": 525,
            "end": 702,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_36@0",
            "content": "The second point on shuffling the attention weights is a subject of more discussion.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_36",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_36@1",
            "content": "Ju et al. (2021) propose a general discussion about logic traps in evaluating interpretation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_36",
            "start": 85,
            "end": 177,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_36@2",
            "content": "Their take on this point of the debate is that a model with its manipulated attention weights in the work of Jain and Wallace ( 2019) \"cannot even be regarded as a trained model, which makes their manipulation meaningless\" (Ju et al., 2021, p. 4), which adds to the point made by Wiegreffe and Pinter (2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_36",
            "start": 179,
            "end": 486,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_36@3",
            "content": "argue that it is too early for the debate to take place because there are no good definition and evaluation of explanations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_36",
            "start": 488,
            "end": 611,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_36@4",
            "content": "The authors propose a Definition Driven Pipeline (DDP) to evaluate explanations based on the definition of faithfulness.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_36",
            "start": 613,
            "end": 732,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_36@5",
            "content": "They show that following this DDP can produce an evaluation of explanations that is less biased and can even drive the development of new faithful explanations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_36",
            "start": 734,
            "end": 893,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_37@0",
            "content": "Calling for more clearly differentiating between faithfulness and plausibility when evaluating explanation, Jacovi and Goldberg (2020) define five guidelines for evaluating faithfulness, building upon the common pitfalls and sub-optimal practices they observed in the literature.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_37",
            "start": 0,
            "end": 278,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_37@1",
            "content": "They propose an organization of the literature into three types: model assumption, prediction assumption, and linearity assumption.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_37",
            "start": 280,
            "end": 410,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_37@2",
            "content": "They state that the distinction between Jain and Wallace (2019) and Wiegreffe and Pinter (2019) is the underlying assumptions they use for evaluating attention heat-maps as explanations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_37",
            "start": 412,
            "end": 597,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_37@3",
            "content": "The former attempts to provide different explanations of similar decisions per instance (therefore linked to prediction assumption).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_37",
            "start": 599,
            "end": 730,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_37@4",
            "content": "The latter critiques the former and is more anchored in the model assumption type of work.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_37",
            "start": 732,
            "end": 821,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_38@0",
            "content": "Evaluating Explanations with Humans",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_38",
            "start": 0,
            "end": 34,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_39@0",
            "content": "The notion of plausibility of attention-based explanations implies asking humans to evaluate whether attention provides a plausible explanation for the model's decisions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_39",
            "start": 0,
            "end": 169,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_39@1",
            "content": "A first issue is whether human judges can agree on what plausible explanations of a decision (e.g., a prediction) are.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_39",
            "start": 171,
            "end": 288,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_39@2",
            "content": "In an experiment involving predictions for sentiment analysis and reading comprehension, Vashishth et al. (2019) ask humans to decide whether the top 3 highest weighted words in 200 samples are relevant for the model's prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_39",
            "start": 290,
            "end": 519,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_39@3",
            "content": "They reported a very high agreement among judges (i.e. Cohen's \u03ba over 0.8), which leads to think that words receiving the highest attention can form a plausible explanation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_39",
            "start": 521,
            "end": 693,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_40@0",
            "content": "A second interesting issue is the type of human annotations that should be captured in order to assess model's plausibility.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_40",
            "start": 0,
            "end": 123,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_40@1",
            "content": "The most common approach is to ask humans to assess attention heatmaps produced by a model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_40",
            "start": 125,
            "end": 215,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_40@2",
            "content": "In Vashishth et al. (2019), users assess the relevance of the top 3 highest weighted words, whereas Mohankumar et al.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_40",
            "start": 217,
            "end": 333,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_41@0",
            "content": "(2020) ask evaluators to decide which of two attention heatmaps better explains the model's prediction as regards to three dimensions: overall prediction, completeness (which heatmap highlights all the words required for the prediction) and correctness (highlights only the important words and not unnecessary words).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_41",
            "start": 0,
            "end": 316,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_41@1",
            "content": "Another way to assess the difference between human and machine attention, in Sen et al. (2020), consists in asking humans to highlight important words for a classification task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_41",
            "start": 318,
            "end": 494,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_41@2",
            "content": "The authors report an agreement percentage around 70% for this task and show that attention weights on top of bi-RNNs align pretty well with human attention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_41",
            "start": 496,
            "end": 652,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_41@3",
            "content": "This finding is especially true for words for which annotators agree on the importance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_41",
            "start": 654,
            "end": 740,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_42@0",
            "content": "A third line of research (Sood et al., 2020) uses eye tracking measures to investigate whether machine attention match human attention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_42",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_42@1",
            "content": "The authors hypothesize that machine attention distributions should correlate with human attention strategies for a given task (e.g., question answering).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_42",
            "start": 136,
            "end": 289,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_42@2",
            "content": "They found that human and machine attention distributions are more similar on easier tasks, which may mean that, for difficult tasks, humans required more varied strategies.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_42",
            "start": 291,
            "end": 463,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_42@3",
            "content": "For LSTMs and CNNs, diverging more from human attention leads to a drop in performance, which is not the case for XLNets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_42",
            "start": 465,
            "end": 585,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_43@0",
            "content": "However, the fact that humans could reliably assess model's plausibility does not ensure that the model is faithful (Jacovi and Goldberg, 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_43",
            "start": 0,
            "end": 143,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_43@1",
            "content": "In fact, Pruthi et al. (2020) cast serious doubts on using attention maps as a way for users to audit explanations in the context of fairness.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_43",
            "start": 145,
            "end": 286,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_43@2",
            "content": "More precisely, the authors train various architectures of neural network models on datasets that are all gender-biased and whose predictions heavily rely on \"impermissible\" tokens (e.g., pronouns).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_43",
            "start": 288,
            "end": 485,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_43@3",
            "content": "An adapted loss function is used to penalize the attention values of these impermissible tokens.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_43",
            "start": 487,
            "end": 582,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_43@4",
            "content": "The authors conclude that, although the problematic tokens are still used by the models, they do not appear in the attention map, which wrongly leads users to believe that the models are unbiased.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_43",
            "start": 584,
            "end": 779,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_43@5",
            "content": "In other words, the authors proved that a plausible explanation does not always imply that the explanation is faithful.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_43",
            "start": 781,
            "end": 899,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_44@0",
            "content": "Solutions to Make Attention Explanation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_44",
            "start": 0,
            "end": 38,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_45@0",
            "content": "This section proposes an overview of the different solutions that have been developed to tackle the various challenges raised by the debate.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_45",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_45@1",
            "content": "We identify two types of solutions: the first type, presented in Section 9.1, concerns purely technical solutions that are often based on the theoretical and empirical analyses presented in Section 5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_45",
            "start": 141,
            "end": 340,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_45@2",
            "content": "The second type of solutions, presented in Section 9.2, leverages user-in-the-loop strategies to align machine attention with human attention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_45",
            "start": 342,
            "end": 483,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_46@0",
            "content": "Technical Solutions",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_46",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_47@0",
            "content": "The technical solutions developed to make attention an explanation differ by whether they use attention values directly or indirectly.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_47",
            "start": 0,
            "end": 133,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_47@1",
            "content": "Within a recurrent network, the representation of an input element contains a summary of the components of its context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_47",
            "start": 135,
            "end": 253,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_47@2",
            "content": "As such, the attention weight computed for that element is imprecise because it indirectly focuses on the context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_47",
            "start": 255,
            "end": 368,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_47@3",
            "content": "In order to avoid this dispersion, some researchers seek to reinforce the link between attention weights and input elements.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_47",
            "start": 370,
            "end": 493,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_47@4",
            "content": "Chrysostomou and Aletras (2021) produce a weighted representation of input elements using the attention weights and a score that is specific to the elements themselves.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_47",
            "start": 495,
            "end": 662,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_47@5",
            "content": "They propose three learning strategies for that score and compare their solutions to three baseline explanations methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_47",
            "start": 664,
            "end": 784,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_47@6",
            "content": "Their results show that their solutions are an improvement over the baselines.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_47",
            "start": 786,
            "end": 863,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_47@7",
            "content": "Mohankumar et al. (2020) propose the introduction of more diversity in the hidden states learned by LSTMs, allowing to observe elements separately from their context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_47",
            "start": 865,
            "end": 1030,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_47@8",
            "content": "They evaluate two different strategies and show that the resulting attention values offer explanations that are not only more faithful but also more plausible.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_47",
            "start": 1032,
            "end": 1190,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_48@0",
            "content": "Tutek and \u0160najder (2020) explore different hidden state regularization methods in order to preserve a strong link with the corresponding input elements.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_48",
            "start": 0,
            "end": 151,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_48@1",
            "content": "They propose a regularization scheme that positively impacts the attention weights by reinforcing their link with the model prediction, which, in turn, leads to more faithful explanations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_48",
            "start": 153,
            "end": 340,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_49@0",
            "content": "The above approaches rely on a property of recurrent networks and seek to work on the attention by modifying the representation of the input elements within the network.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_49",
            "start": 0,
            "end": 168,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_49@1",
            "content": "In parallel, some researchers focus directly on the attention weights with no constraints regarding the network architecture.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_49",
            "start": 170,
            "end": 294,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_49@2",
            "content": "Moradi et al. (2021) modify the loss function by adding a term that penalizes non-faithful attention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_49",
            "start": 296,
            "end": 396,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_49@3",
            "content": "In order to quantify faithfulness, they propose a measure that combines up to three different stress tests.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_49",
            "start": 398,
            "end": 504,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_49@4",
            "content": "They show that their method optimizes faithfulness, while improving the model's performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_49",
            "start": 506,
            "end": 597,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_49@5",
            "content": "Bai et al. (2021) propose to weight the elements of the input X to counter the effect of combinatorial shortcuts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_49",
            "start": 599,
            "end": 711,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_49@6",
            "content": "The weighting scheme is based on the fact that the estimation of E(Y|X M) in attention, where M are masks applied ( ) to the elements of the input X, is not the same for all elements of X.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_49",
            "start": 713,
            "end": 900,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_50@0",
            "content": "Attention can be Explanation When",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_50",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_51@0",
            "content": "Users are in the Loop",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_51",
            "start": 0,
            "end": 20,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_52@0",
            "content": "Another way to make attention become explanation is to bring users into the loop.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_52",
            "start": 0,
            "end": 80,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_52@1",
            "content": "This approach is sometimes called supervised attention, as the user attention is used by the model during training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_52",
            "start": 82,
            "end": 196,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_52@2",
            "content": "Strout et al. (2019) show that using human rationale to supervise attention can produce explanations that are better accepted by users, but can also lead to better results in terms of performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_52",
            "start": 198,
            "end": 393,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_52@3",
            "content": "Zhong et al. (2019) modify an attention-based LSTM to make it match user provided attention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_52",
            "start": 395,
            "end": 486,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_52@4",
            "content": "In order to do that, they compare the distributions of machine and user attention and use a Kullback-Leibler divergence between the two distributions to penalize the attention of the model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_52",
            "start": 488,
            "end": 676,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_53@0",
            "content": "In the same idea of supervised attention, Heo et al. (2020) extend the meta-learning technique called neural processes to include attention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_53",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_53@1",
            "content": "Their Neural Attention Processes (NAP) are designed to consider user-provided attention in an active learning fashion through the use of context points.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_53",
            "start": 141,
            "end": 292,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_53@2",
            "content": "Kanchinadam et al. (2020) also extend the training of attention to obtain a supervised version of attention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_53",
            "start": 294,
            "end": 401,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_53@3",
            "content": "Their approach consists in the addition of a term in the objective function of their model to penalize the difference between the machine and the user attention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_53",
            "start": 403,
            "end": 563,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_53@4",
            "content": "As in Heo et al. (2020), the authors make use of active learning in their method called Rationale-based Active Learning with Supervised Attention (RALSA) to collect user attention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_53",
            "start": 565,
            "end": 744,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_54@0",
            "content": "Finally, Arous et al. (2021) introduce MApping human Rationales To Attention (MARTA), a Bayesian framework to include human rationale in order to adapt machine attention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_54",
            "start": 0,
            "end": 169,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_54@1",
            "content": "As for all other works in this section, the method improves the performance of the model while providing humanunderstandable explanations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_54",
            "start": 171,
            "end": 308,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_55@0",
            "content": "Discussion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_55",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_56@0",
            "content": "As stated earlier in this paper, one of the difficulties in this debate is that the insights are brought from paper of different areas that do not always cite each other.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_56",
            "start": 0,
            "end": 169,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_56@1",
            "content": "In fact, even inside a particular area, papers do not always refer to each other.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_56",
            "start": 171,
            "end": 251,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_56@2",
            "content": "In this section, we aim at bridging the gap between the different papers and their area in order to extract the main conclusions and some points of tension.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_56",
            "start": 253,
            "end": 408,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_57@0",
            "content": "First of all, like Thorne et al. (2019) who state that LIME can be used for explanation, thus questioning the need for attention, Bastings and Filippova (2020) state that saliency methods can be used for explanation, and so the attention is not needed in that role.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_57",
            "start": 0,
            "end": 264,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_57@1",
            "content": "Therefore, according to Bastings and Filippova (2020), if explanation tools already exist to do the job, why is the debate about attention useful?",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_57",
            "start": 266,
            "end": 411,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_57@2",
            "content": "Two answers can be provided to this question.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_57",
            "start": 413,
            "end": 457,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_57@3",
            "content": "First, attention is something that is learned for performance purposes, so it would be useful if it could be used as explanation also, instead of using additional post-hoc tools.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_57",
            "start": 459,
            "end": 636,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_57@4",
            "content": "Second, the existence of the debate kick-started solutions that are now moving towards explanation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_57",
            "start": 638,
            "end": 736,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_58@0",
            "content": "Current solutions for making attention an explanation have to consider the two sides of explanation: faithfulness and plausibility.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_58",
            "start": 0,
            "end": 130,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_58@1",
            "content": "This subject is at the very heart of the debate, as Wiegreffe and Pinter (2019) already mentioned the focus of Jain and Wallace (2019) on faithful explanations only.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_58",
            "start": 132,
            "end": 296,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_58@2",
            "content": "However, users may not be satisfied by explanations that are only faithful to the model, as they need to be plausible for them too.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_58",
            "start": 298,
            "end": 428,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_58@3",
            "content": "Therefore, focusing on the correlation between attention and other faithful techniques may not be enough to evaluate whether attention is explanation in real conditions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_58",
            "start": 430,
            "end": 598,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_58@4",
            "content": "The right balance between plausibility and faithfulness may lie in human-based evaluations (Section 8) and supervised attention (Section 9.2).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_58",
            "start": 600,
            "end": 741,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_59@0",
            "content": "That being said, faithfulness should also be evaluated on its own right, without any consideration of plausibility, to check if the explanation matches the model behavior.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_59",
            "start": 0,
            "end": 170,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_59@1",
            "content": "However, as explained by Jacovi and Goldberg (2020), faithfulness should not be evaluated in a binary fashion: the level of faithfulness needed for attention to be accepted as an explanation should be measured.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_59",
            "start": 172,
            "end": 381,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_60@0",
            "content": "Still the subject evaluation, we noted that the different contributions to the debate are often based on different setups.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_60",
            "start": 0,
            "end": 121,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_60@1",
            "content": "Indeed, except for the analysis of attention on different tasks (Section 6), the contributions often base their claims on one or two tasks of their choice.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_60",
            "start": 123,
            "end": 277,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_60@2",
            "content": "We claim that a common ground must be found to properly analyze attention and its relation to explanation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_60",
            "start": 279,
            "end": 384,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_60@3",
            "content": "The same issue has been observed with the use of different input embeddings and different architectures surrounding the attention layer(s).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_60",
            "start": 386,
            "end": 524,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_60@4",
            "content": "Likewise, stress that the lack of a common ground when discussing faithfulness, plausibility and explanations is not conducive to finding answers to the debate.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_60",
            "start": 526,
            "end": 685,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_61@0",
            "content": "On the side of solutions, the common intuitive solution in interpretability and explanation that regularizing a model to be sparse improves our understanding of the model is not well supported in the literature for attention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_61",
            "start": 0,
            "end": 224,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_61@1",
            "content": "In fact, some authors like Meister et al. (2021) note that inducing sparsity may in fact reduce the faithfulness of attention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_61",
            "start": 226,
            "end": 351,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_62@0",
            "content": "Another perspective that is better suited for obtaining faithful explanations is effective attention (Brunner et al., 2020;Kobayashi et al., 2020;Sun and Marasovi\u0107, 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_62",
            "start": 0,
            "end": 170,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_62@1",
            "content": "Indeed, while attention per se may not be explanation, further studies and uses of effective attention as a sub-part of attention may prove useful to learn a faithful explanation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_62",
            "start": 172,
            "end": 350,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_63@0",
            "content": "If plausible explanations, alongside faithfulness, are needed, supervised attention is a good perspective.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_63",
            "start": 0,
            "end": 105,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_63@1",
            "content": "The argument for supervised attention is well-founded: if attention is not explanation and if faithfulness is not enough, then making machine attention match human attention may be a solution.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_63",
            "start": 107,
            "end": 298,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_63@2",
            "content": "While one can argue that attention has originally been introduced for performance purposes and that supervised attention may work against this advantage, several studies show that, in fact, guiding attention increases performance (e.g., Strout et al. (2019)).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_63",
            "start": 300,
            "end": 558,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_63@3",
            "content": "Supervised attention is therefore a solution that both optimizes performance and explainability.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_63",
            "start": 560,
            "end": 655,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_63@4",
            "content": "The main cost of this solution is that it requires the participation of users, but solutions using few-shot user annotations have already been introduced in the literature (e.g., Heo et al. (2020)).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_63",
            "start": 657,
            "end": 854,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_64@0",
            "content": "In a complementary point of view, Grimsley et al. ( 2020) offer a philosophical perspective on the debate.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_64",
            "start": 0,
            "end": 105,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_64@1",
            "content": "The authors show that works studying attention as explanation attempt to do so in a causal framework.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_64",
            "start": 107,
            "end": 207,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_64@2",
            "content": "They argue that it is an issue because the object of study does not fit in that type of framework.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_64",
            "start": 209,
            "end": 306,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_64@3",
            "content": "The reason is that the link between the attention layer and a model's output cannot be isolated from the other components of the model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_64",
            "start": 308,
            "end": 442,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_64@4",
            "content": "They conclude that \"attention weights alone cannot be used as causal explanation for model behavior\" (Grimsley et al., 2020(Grimsley et al., , p. 1786.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_64",
            "start": 444,
            "end": 594,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_64@5",
            "content": "This entails that assuming causality when evaluating the explanatory power of attention is doomed to fail by design.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_64",
            "start": 596,
            "end": 711,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_64@6",
            "content": "The authors offer other, non-causal, explanation paradigms to explore the issue, such as mathematical, structural modal, and minimal-model explanations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_64",
            "start": 713,
            "end": 864,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_65@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_65",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_66@0",
            "content": "We have shown that the debate about the question \"is attention explanation?\" already produced a vast and diverse literature.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_66",
            "start": 0,
            "end": 123,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_66@1",
            "content": "Throughout our analysis of the existing works, we have stressed various insights that could help advance the debate: theoretically refining concepts around the notion of explanation (in particular plausibility and faithfulness), developing a common ground in the evaluation setup (e.g., similar input embeddings and architectures), extending the studies and uses of effective attention, and improving the integration of users for a supervised attention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_66",
            "start": 125,
            "end": 577,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_66@2",
            "content": "We intend that our work provides a solid ground for further research, calling for more integration to answer the question \"is attention explanation?\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_66",
            "start": 579,
            "end": 728,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_66@3",
            "content": "In particular, combining the findings from the different areas (e.g., to produce a supervised effective attention) seems to be among the most promising avenues.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_66",
            "start": 730,
            "end": 889,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_67@0",
            "content": "Samira Abnar, Willem Zuidema, Quantifying attention flow in transformers, 2020, Proceedings of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_67",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_68@0",
            "content": "Ines Arous, Ljiljana Dolamic, Jie Yang, Akansha Bhardwaj, Giuseppe Cuccu, Philippe Cudr\u00e9-Mauroux, MARTA: Leveraging human rationales for explainable text classification, 2021, Proceedings of AAAI, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_68",
            "start": 0,
            "end": 197,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_69@0",
            "content": "Joris Baan, Marlies Maartje Ter Hoeve, Anne Van Der Wees, Maarten Schuth,  De Rijke, Do transformer attention heads provide transparency in abstractive summarization?, 2019, Proceedings of the SI-GIR Workshop FACTS-IR, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_69",
            "start": 0,
            "end": 219,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_70@0",
            "content": "Dzmitry Bahdanau, Kyung Cho, Yoshua Bengio, Neural machine translation by jointly learning to align and translate, 2015, Proceedings of ICLR, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_70",
            "start": 0,
            "end": 142,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_71@0",
            "content": "Bing Bai, Jian Liang, Guanhua Zhang, Hao Li, Kun Bai, Fei Wang, Why attentions may not be interpretable?, 2021, Proceedings of the ACM SIGKDD Conference, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_71",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_72@0",
            "content": "Jasmijn Bastings, Katja Filippova, The elephant in the interpretability room: Why use attention as explanation when we have saliency methods?, 2020, Proceedings of the EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_72",
            "start": 0,
            "end": 248,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_73@0",
            "content": "Adrien Bibal, Beno\u00eet Fr\u00e9nay, Interpretability of machine learning models and representations: An introduction, 2016, Proceedings of ESANN, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_73",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_74@0",
            "content": "Gino Brunner, Yang Liu, Dami\u00e1n Pascual, Oliver Richter, Massimiliano Ciaramita, Roger Wattenhofer, On identifiability in transformers, 2020, Proceedings of ICLR, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_74",
            "start": 0,
            "end": 162,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_75@0",
            "content": "UNKNOWN, None, 2019, An attentive survey of attention models, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_75",
            "start": 0,
            "end": 62,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_76@0",
            "content": "Edward Choi, Mohammad Bahadori, Joshua Kulas, Andy Schuetz, F Walter, Jimeng Stewart,  Sun, RETAIN: an interpretable predictive model for healthcare using reverse time attention mechanism, 2016, Proceedings of NeurIPS, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_76",
            "start": 0,
            "end": 219,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_77@0",
            "content": "George Chrysostomou, Nikolaos Aletras, Improving the faithfulness of attention-based explanations with task-specific information for text classification, 2021, Proceedings of ACL-IJCNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_77",
            "start": 0,
            "end": 187,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_78@0",
            "content": "Kevin Clark, Urvashi Khandelwal, Omer Levy, Christopher D Manning, What does BERT look at? An analysis of BERT's attention, 2019, Proceedings of the ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_78",
            "start": 0,
            "end": 227,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_79@0",
            "content": "UNKNOWN, None, 2021, Attention, please! A survey of neural attention models in deep learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_79",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_80@0",
            "content": "Kawin Ethayarajh, Dan Jurafsky, Attention flows are shapley value explanations, 2021, Proceedings of ACL-IJCNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_80",
            "start": 0,
            "end": 113,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_81@0",
            "content": "Andrea Galassi, Marco Lippi, Paolo Torroni, Attention in natural language processing, 2020, IEEE Transactions on Neural Networks and Learning Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_81",
            "start": 0,
            "end": 151,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_82@0",
            "content": "Christopher Grimsley, Elijah Mayfield, Julia Rs Bursten, Why attention is not explanation: Surgical intervention and causal reasoning about neural models, 2020, Proceedings of LREC, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_82",
            "start": 0,
            "end": 182,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_83@0",
            "content": "Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Franco Turini, Fosca Giannotti, Dino Pedreschi, A survey of methods for explaining black box models, 2018, ACM Computing Surveys, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_83",
            "start": 0,
            "end": 184,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_84@0",
            "content": "Jay Heo, Junhyeon Park, Hyewon Jeong, Kwang Joon Kim, Juho Lee, Eunho Yang, Sung Hwang, Cost-effective interactive attention learning with neural attention processes, 2020, Proceedings of ICML, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_84",
            "start": 0,
            "end": 194,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_85@0",
            "content": "Alon Jacovi, Yoav Goldberg, Towards faithfully interpretable NLP systems: How should we define and evaluate faithfulness?, 2020, Proceedings of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_85",
            "start": 0,
            "end": 149,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_86@0",
            "content": "Sarthak Jain, C Byron,  Wallace, Attention is not explanation, 2019, Proceedings of NAACL-HLT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_86",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_87@0",
            "content": "UNKNOWN, None, 2021, The logic traps in evaluating post-hoc interpretations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_87",
            "start": 0,
            "end": 77,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_88@0",
            "content": "Teja Kanchinadam, Keith Westpfahl, Qian You, Glenn Fung, Rationale-based human-in-theloop via supervised attention, 2020, Proceedings of the KDD workshop DaSH, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_88",
            "start": 0,
            "end": 160,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_89@0",
            "content": "Goro Kobayashi, Tatsuki Kuribayashi, Sho Yokoi, Kentaro Inui, Attention is not only a weight: Analyzing transformers with vector norms, 2020, Proceedings of EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_89",
            "start": 0,
            "end": 164,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_90@0",
            "content": "Jian Li, Zhaopeng Tu, Baosong Yang, Tong Michael R Lyu,  Zhang, Multi-head attention with disagreement regularization, 2018, Proceedings of EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_90",
            "start": 0,
            "end": 147,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_91@0",
            "content": "Xiang Li, Wenhai Wang, Xiaolin Hu, Jian Yang, Selective kernel networks, 2019, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_91",
            "start": 0,
            "end": 162,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_92@0",
            "content": "W Grace,  Lindsay, Attention in psychology, neuroscience, and machine learning, 2020, Frontiers in Computational Neuroscience, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_92",
            "start": 0,
            "end": 127,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_93@0",
            "content": "UNKNOWN, None, 2020, Are interpretations fairly evaluated? a definition driven pipeline for post-hoc interpretability, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_93",
            "start": 0,
            "end": 119,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_94@0",
            "content": "M Scott, Su-In Lundberg,  Lee, A unified approach to interpreting model predictions, 2017, Proceedings of NeurIPS, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_94",
            "start": 0,
            "end": 115,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_95@0",
            "content": "Minh-Thang Luong, Hieu Pham, Christopher Manning, Effective approaches to attentionbased neural machine translation, 2015, Proceedings of EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_95",
            "start": 0,
            "end": 145,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_96@0",
            "content": "Andre Martins, Ramon Astudillo, From softmax to sparsemax: A sparse model of attention and multi-label classification, 2016, Proceedings of ICML, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_96",
            "start": 0,
            "end": 146,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_97@0",
            "content": "Clara Meister, Stefan Lazov, Isabelle Augenstein, Ryan Cotterell, Is sparse attention more interpretable?, 2021, Proceedings of ACL-IJCNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_97",
            "start": 0,
            "end": 140,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_98@0",
            "content": "Volodymyr Mnih, Nicolas Heess, Alex Graves, Recurrent models of visual attention, 2014, Proceedings of NeurIPS, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_98",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_99@0",
            "content": "Akash Kumar Mohankumar, Preksha Nema, Sharan Narasimhan, M Mitesh,  Khapra, Balaraman Balaji Vasan Srinivasan,  Ravindran, Towards transparent and explainable attention models, 2020, Proceedings of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_99",
            "start": 0,
            "end": 203,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_100@0",
            "content": "Pooya Moradi, Nishant Kambhatla, Anoop Sarkar, Measuring and improving faithfulness of attention in neural machine translation, 2021, Proceedings of EACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_100",
            "start": 0,
            "end": 155,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_101@0",
            "content": "James Mullenbach, Sarah Wiegreffe, Jon Duke, Jimeng Sun, Jacob Eisenstein, Explainable prediction of medical codes from clinical text, 2018, Proceedings of NAACL-HLT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_101",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_102@0",
            "content": "Michael Neely, F Stefan,  Schouten, J Maurits, Ana Bleeker,  Lucic, Order in the court: Explainable AI methods prone to disagreement, 2021, Proceedings of the ICML Workshop on Theoretic Foundation, Criticism, and Application Trend of Explainable AI, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_102",
            "start": 0,
            "end": 250,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_103@0",
            "content": "Danish Pruthi, Mansi Gupta, Bhuwan Dhingra, Graham Neubig, Zachary Lipton, Learning to deceive with attention-based explanations, 2020, Proceedings of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_103",
            "start": 0,
            "end": 156,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_104@0",
            "content": "UNKNOWN, None, 2021, Explainable deep learning: A field guide for the uninitiated, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_104",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_105@0",
            "content": "A Ronald,  Rensink, The dynamic representation of scenes, 2000, Visual cognition, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_105",
            "start": 0,
            "end": 82,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_106@0",
            "content": "Sameer Marco Tulio Ribeiro, Carlos Singh,  Guestrin, Explaining the predictions of any classifier, 2016, Proceedings of the ACM SIGKDD Conference, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_106",
            "start": 0,
            "end": 147,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_107@0",
            "content": "O Mark,  Riedl, Human-centered artificial intelligence and machine learning, 2019, Human Behavior and Emerging Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_107",
            "start": 0,
            "end": 125,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_108@0",
            "content": "Cynthia Rudin, Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead, 2019, Nature Machine Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_108",
            "start": 0,
            "end": 164,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_109@0",
            "content": "Cansu Sen, Thomas Hartvigsen, Biao Yin, Xiangnan Kong, Elke Rundensteiner, Human attention maps for text classification: Do humans and neural networks focus on the same words?, 2020, Proceedings of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_109",
            "start": 0,
            "end": 203,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_110@0",
            "content": "Sofia Serrano, A Noah,  Smith, Is attention interpretable?, 2019, Proceedings of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_110",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_111@0",
            "content": "Ekta Sood, Simon Tannert, Diego Frassinelli, Andreas Bulling, Ngoc Vu, Interpreting attention models with human visual attention in machine reading comprehension, 2020, Proceedings of CoNLL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_111",
            "start": 0,
            "end": 191,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_112@0",
            "content": "Julia Strout, Ye Zhang, Raymond Mooney, Do human rationales improve machine explanations?, 2019, Proceedings of the ACL Workshop Black-boxNLP: Analyzing and Interpreting Neural Networks for NLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_112",
            "start": 0,
            "end": 195,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_113@0",
            "content": "Kaiser Sun, Ana Marasovi\u0107, Effective attention sheds light on interpretability, 2021, Findings of ACL-IJCNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_113",
            "start": 0,
            "end": 110,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_114@0",
            "content": "Xiaobing Sun, Wei Lu, Understanding attention for text classification, 2020, Proceedings of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_114",
            "start": 0,
            "end": 97,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_115@0",
            "content": "Ian Tenney, Dipanjan Das, Ellie Pavlick, BERT rediscovers the classical NLP pipeline, 2019, Proceedings of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_115",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_116@0",
            "content": "James Thorne, Andreas Vlachos, Generating token-level explanations for natural language inference, 2019, Proceedings of NAACL-HLT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_116",
            "start": 0,
            "end": 131,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_117@0",
            "content": "Martin Tutek, Staying true to your word:(how) can attention become explanation?, 2020, Proceedings of the ACL Workshop on Representation Learning for NLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_117",
            "start": 0,
            "end": 155,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_118@0",
            "content": "UNKNOWN, None, 2019, Attention interpretability across NLP tasks, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_118",
            "start": 0,
            "end": 66,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_119@0",
            "content": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Attention is all you need, 2017, Proceedings of NeurIPS, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_119",
            "start": 0,
            "end": 176,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_120@0",
            "content": "Jesse Vig, Yonatan Belinkov, Analyzing the structure of attention in a transformer language model, 2019, Proceedings of the ACL Workshop Black-boxNLP: Analyzing and Interpreting Neural Networks for NLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_120",
            "start": 0,
            "end": 203,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_121@0",
            "content": "Elena Voita, Pavel Serdyukov, Rico Sennrich, Ivan Titov, Context-aware neural machine translation learns anaphora resolution, 2018, Proceedings of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_121",
            "start": 0,
            "end": 152,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_122@0",
            "content": "Sarah Wiegreffe, Yuval Pinter, Attention is not not explanation, 2019, Proceedings of EMNLP-IJCNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_122",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_123@0",
            "content": "Qizhe Xie, Xuezhe Ma, Zihang Dai, Eduard Hovy, An interpretable knowledge transfer model for knowledge base completion, 2017, Proceedings of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_123",
            "start": 0,
            "end": 146,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_124@0",
            "content": "Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhudinov, Rich Zemel, Yoshua Bengio, Show, attend and tell: Neural image caption generation with visual attention, 2015, Proceedings of ICML, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_124",
            "start": 0,
            "end": 218,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_125@0",
            "content": "Cheng Zhang, Qiuchi Lingyu Hua, Dawei Song, How does attention affect the model?, 2021, Findings of ACL-IJCNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_125",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_126@0",
            "content": "Han Zhang, Ian Goodfellow, Dimitris Metaxas, Augustus Odena, Self-attention generative adversarial networks, 2019, Proceedings of ICML, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_126",
            "start": 0,
            "end": 136,
            "label": {}
        },
        {
            "ix": "419-ARR_v1_127@0",
            "content": "UNKNOWN, None, 2019, Fine-grained sentiment analysis with faithful attention, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "419-ARR_v1_127",
            "start": 0,
            "end": 78,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "419-ARR_v1_0",
            "tgt_ix": "419-ARR_v1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_0",
            "tgt_ix": "419-ARR_v1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_1",
            "tgt_ix": "419-ARR_v1_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_1",
            "tgt_ix": "419-ARR_v1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_0",
            "tgt_ix": "419-ARR_v1_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_2",
            "tgt_ix": "419-ARR_v1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_4",
            "tgt_ix": "419-ARR_v1_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_5",
            "tgt_ix": "419-ARR_v1_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_6",
            "tgt_ix": "419-ARR_v1_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_7",
            "tgt_ix": "419-ARR_v1_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_8",
            "tgt_ix": "419-ARR_v1_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_9",
            "tgt_ix": "419-ARR_v1_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_3",
            "tgt_ix": "419-ARR_v1_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_3",
            "tgt_ix": "419-ARR_v1_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_3",
            "tgt_ix": "419-ARR_v1_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_3",
            "tgt_ix": "419-ARR_v1_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_3",
            "tgt_ix": "419-ARR_v1_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_3",
            "tgt_ix": "419-ARR_v1_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_3",
            "tgt_ix": "419-ARR_v1_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_3",
            "tgt_ix": "419-ARR_v1_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_3",
            "tgt_ix": "419-ARR_v1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_0",
            "tgt_ix": "419-ARR_v1_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_11",
            "tgt_ix": "419-ARR_v1_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_13",
            "tgt_ix": "419-ARR_v1_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_12",
            "tgt_ix": "419-ARR_v1_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_12",
            "tgt_ix": "419-ARR_v1_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_12",
            "tgt_ix": "419-ARR_v1_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_0",
            "tgt_ix": "419-ARR_v1_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_14",
            "tgt_ix": "419-ARR_v1_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_16",
            "tgt_ix": "419-ARR_v1_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_17",
            "tgt_ix": "419-ARR_v1_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_15",
            "tgt_ix": "419-ARR_v1_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_15",
            "tgt_ix": "419-ARR_v1_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_15",
            "tgt_ix": "419-ARR_v1_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_15",
            "tgt_ix": "419-ARR_v1_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_0",
            "tgt_ix": "419-ARR_v1_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_18",
            "tgt_ix": "419-ARR_v1_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_20",
            "tgt_ix": "419-ARR_v1_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_21",
            "tgt_ix": "419-ARR_v1_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_19",
            "tgt_ix": "419-ARR_v1_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_19",
            "tgt_ix": "419-ARR_v1_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_19",
            "tgt_ix": "419-ARR_v1_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_19",
            "tgt_ix": "419-ARR_v1_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_0",
            "tgt_ix": "419-ARR_v1_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_22",
            "tgt_ix": "419-ARR_v1_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_24",
            "tgt_ix": "419-ARR_v1_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_25",
            "tgt_ix": "419-ARR_v1_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_23",
            "tgt_ix": "419-ARR_v1_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_23",
            "tgt_ix": "419-ARR_v1_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_23",
            "tgt_ix": "419-ARR_v1_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_23",
            "tgt_ix": "419-ARR_v1_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_0",
            "tgt_ix": "419-ARR_v1_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_26",
            "tgt_ix": "419-ARR_v1_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_28",
            "tgt_ix": "419-ARR_v1_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_29",
            "tgt_ix": "419-ARR_v1_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_30",
            "tgt_ix": "419-ARR_v1_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_31",
            "tgt_ix": "419-ARR_v1_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_27",
            "tgt_ix": "419-ARR_v1_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_27",
            "tgt_ix": "419-ARR_v1_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_27",
            "tgt_ix": "419-ARR_v1_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_27",
            "tgt_ix": "419-ARR_v1_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_27",
            "tgt_ix": "419-ARR_v1_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_27",
            "tgt_ix": "419-ARR_v1_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_0",
            "tgt_ix": "419-ARR_v1_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_32",
            "tgt_ix": "419-ARR_v1_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_34",
            "tgt_ix": "419-ARR_v1_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_35",
            "tgt_ix": "419-ARR_v1_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_36",
            "tgt_ix": "419-ARR_v1_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_33",
            "tgt_ix": "419-ARR_v1_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_33",
            "tgt_ix": "419-ARR_v1_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_33",
            "tgt_ix": "419-ARR_v1_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_33",
            "tgt_ix": "419-ARR_v1_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_33",
            "tgt_ix": "419-ARR_v1_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_0",
            "tgt_ix": "419-ARR_v1_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_37",
            "tgt_ix": "419-ARR_v1_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_39",
            "tgt_ix": "419-ARR_v1_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_40",
            "tgt_ix": "419-ARR_v1_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_41",
            "tgt_ix": "419-ARR_v1_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_42",
            "tgt_ix": "419-ARR_v1_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_38",
            "tgt_ix": "419-ARR_v1_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_38",
            "tgt_ix": "419-ARR_v1_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_38",
            "tgt_ix": "419-ARR_v1_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_38",
            "tgt_ix": "419-ARR_v1_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_38",
            "tgt_ix": "419-ARR_v1_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_38",
            "tgt_ix": "419-ARR_v1_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_0",
            "tgt_ix": "419-ARR_v1_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_43",
            "tgt_ix": "419-ARR_v1_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_44",
            "tgt_ix": "419-ARR_v1_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_44",
            "tgt_ix": "419-ARR_v1_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_44",
            "tgt_ix": "419-ARR_v1_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_45",
            "tgt_ix": "419-ARR_v1_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_47",
            "tgt_ix": "419-ARR_v1_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_48",
            "tgt_ix": "419-ARR_v1_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_46",
            "tgt_ix": "419-ARR_v1_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_46",
            "tgt_ix": "419-ARR_v1_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_46",
            "tgt_ix": "419-ARR_v1_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_46",
            "tgt_ix": "419-ARR_v1_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_44",
            "tgt_ix": "419-ARR_v1_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_49",
            "tgt_ix": "419-ARR_v1_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_51",
            "tgt_ix": "419-ARR_v1_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_52",
            "tgt_ix": "419-ARR_v1_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_53",
            "tgt_ix": "419-ARR_v1_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_50",
            "tgt_ix": "419-ARR_v1_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_50",
            "tgt_ix": "419-ARR_v1_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_50",
            "tgt_ix": "419-ARR_v1_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_50",
            "tgt_ix": "419-ARR_v1_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_50",
            "tgt_ix": "419-ARR_v1_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_3",
            "tgt_ix": "419-ARR_v1_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_54",
            "tgt_ix": "419-ARR_v1_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_56",
            "tgt_ix": "419-ARR_v1_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_57",
            "tgt_ix": "419-ARR_v1_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_58",
            "tgt_ix": "419-ARR_v1_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_59",
            "tgt_ix": "419-ARR_v1_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_60",
            "tgt_ix": "419-ARR_v1_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_61",
            "tgt_ix": "419-ARR_v1_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_62",
            "tgt_ix": "419-ARR_v1_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_63",
            "tgt_ix": "419-ARR_v1_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_55",
            "tgt_ix": "419-ARR_v1_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_55",
            "tgt_ix": "419-ARR_v1_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_55",
            "tgt_ix": "419-ARR_v1_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_55",
            "tgt_ix": "419-ARR_v1_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_55",
            "tgt_ix": "419-ARR_v1_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_55",
            "tgt_ix": "419-ARR_v1_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_55",
            "tgt_ix": "419-ARR_v1_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_55",
            "tgt_ix": "419-ARR_v1_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_55",
            "tgt_ix": "419-ARR_v1_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_55",
            "tgt_ix": "419-ARR_v1_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_3",
            "tgt_ix": "419-ARR_v1_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_64",
            "tgt_ix": "419-ARR_v1_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_65",
            "tgt_ix": "419-ARR_v1_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_65",
            "tgt_ix": "419-ARR_v1_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "419-ARR_v1_0",
            "tgt_ix": "419-ARR_v1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_1",
            "tgt_ix": "419-ARR_v1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_2",
            "tgt_ix": "419-ARR_v1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_2",
            "tgt_ix": "419-ARR_v1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_2",
            "tgt_ix": "419-ARR_v1_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_2",
            "tgt_ix": "419-ARR_v1_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_2",
            "tgt_ix": "419-ARR_v1_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_2",
            "tgt_ix": "419-ARR_v1_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_2",
            "tgt_ix": "419-ARR_v1_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_3",
            "tgt_ix": "419-ARR_v1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_4",
            "tgt_ix": "419-ARR_v1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_4",
            "tgt_ix": "419-ARR_v1_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_5",
            "tgt_ix": "419-ARR_v1_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_5",
            "tgt_ix": "419-ARR_v1_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_5",
            "tgt_ix": "419-ARR_v1_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_5",
            "tgt_ix": "419-ARR_v1_5@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_5",
            "tgt_ix": "419-ARR_v1_5@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_6",
            "tgt_ix": "419-ARR_v1_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_6",
            "tgt_ix": "419-ARR_v1_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_6",
            "tgt_ix": "419-ARR_v1_6@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_6",
            "tgt_ix": "419-ARR_v1_6@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_7",
            "tgt_ix": "419-ARR_v1_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_7",
            "tgt_ix": "419-ARR_v1_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_7",
            "tgt_ix": "419-ARR_v1_7@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_8",
            "tgt_ix": "419-ARR_v1_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_8",
            "tgt_ix": "419-ARR_v1_8@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_8",
            "tgt_ix": "419-ARR_v1_8@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_8",
            "tgt_ix": "419-ARR_v1_8@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_8",
            "tgt_ix": "419-ARR_v1_8@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_9",
            "tgt_ix": "419-ARR_v1_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_9",
            "tgt_ix": "419-ARR_v1_9@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_9",
            "tgt_ix": "419-ARR_v1_9@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_9",
            "tgt_ix": "419-ARR_v1_9@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_9",
            "tgt_ix": "419-ARR_v1_9@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_10",
            "tgt_ix": "419-ARR_v1_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_11",
            "tgt_ix": "419-ARR_v1_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_11",
            "tgt_ix": "419-ARR_v1_11@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_11",
            "tgt_ix": "419-ARR_v1_11@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_11",
            "tgt_ix": "419-ARR_v1_11@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_12",
            "tgt_ix": "419-ARR_v1_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_13",
            "tgt_ix": "419-ARR_v1_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_13",
            "tgt_ix": "419-ARR_v1_13@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_13",
            "tgt_ix": "419-ARR_v1_13@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_13",
            "tgt_ix": "419-ARR_v1_13@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_13",
            "tgt_ix": "419-ARR_v1_13@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_13",
            "tgt_ix": "419-ARR_v1_13@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_13",
            "tgt_ix": "419-ARR_v1_13@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_13",
            "tgt_ix": "419-ARR_v1_13@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_13",
            "tgt_ix": "419-ARR_v1_13@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_13",
            "tgt_ix": "419-ARR_v1_13@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_14",
            "tgt_ix": "419-ARR_v1_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_14",
            "tgt_ix": "419-ARR_v1_14@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_15",
            "tgt_ix": "419-ARR_v1_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_16",
            "tgt_ix": "419-ARR_v1_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_16",
            "tgt_ix": "419-ARR_v1_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_16",
            "tgt_ix": "419-ARR_v1_16@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_16",
            "tgt_ix": "419-ARR_v1_16@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_16",
            "tgt_ix": "419-ARR_v1_16@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_16",
            "tgt_ix": "419-ARR_v1_16@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_16",
            "tgt_ix": "419-ARR_v1_16@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_17",
            "tgt_ix": "419-ARR_v1_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_17",
            "tgt_ix": "419-ARR_v1_17@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_17",
            "tgt_ix": "419-ARR_v1_17@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_17",
            "tgt_ix": "419-ARR_v1_17@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_17",
            "tgt_ix": "419-ARR_v1_17@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_18",
            "tgt_ix": "419-ARR_v1_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_18",
            "tgt_ix": "419-ARR_v1_18@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_19",
            "tgt_ix": "419-ARR_v1_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_20",
            "tgt_ix": "419-ARR_v1_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_20",
            "tgt_ix": "419-ARR_v1_20@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_20",
            "tgt_ix": "419-ARR_v1_20@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_20",
            "tgt_ix": "419-ARR_v1_20@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_20",
            "tgt_ix": "419-ARR_v1_20@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_20",
            "tgt_ix": "419-ARR_v1_20@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_21",
            "tgt_ix": "419-ARR_v1_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_21",
            "tgt_ix": "419-ARR_v1_21@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_21",
            "tgt_ix": "419-ARR_v1_21@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_21",
            "tgt_ix": "419-ARR_v1_21@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_21",
            "tgt_ix": "419-ARR_v1_21@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_21",
            "tgt_ix": "419-ARR_v1_21@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_22",
            "tgt_ix": "419-ARR_v1_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_22",
            "tgt_ix": "419-ARR_v1_22@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_22",
            "tgt_ix": "419-ARR_v1_22@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_23",
            "tgt_ix": "419-ARR_v1_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_24",
            "tgt_ix": "419-ARR_v1_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_24",
            "tgt_ix": "419-ARR_v1_24@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_24",
            "tgt_ix": "419-ARR_v1_24@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_24",
            "tgt_ix": "419-ARR_v1_24@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_24",
            "tgt_ix": "419-ARR_v1_24@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_24",
            "tgt_ix": "419-ARR_v1_24@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_24",
            "tgt_ix": "419-ARR_v1_24@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_24",
            "tgt_ix": "419-ARR_v1_24@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_24",
            "tgt_ix": "419-ARR_v1_24@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_24",
            "tgt_ix": "419-ARR_v1_24@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_24",
            "tgt_ix": "419-ARR_v1_24@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_24",
            "tgt_ix": "419-ARR_v1_24@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_24",
            "tgt_ix": "419-ARR_v1_24@12",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_25",
            "tgt_ix": "419-ARR_v1_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_25",
            "tgt_ix": "419-ARR_v1_25@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_25",
            "tgt_ix": "419-ARR_v1_25@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_25",
            "tgt_ix": "419-ARR_v1_25@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_26",
            "tgt_ix": "419-ARR_v1_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_26",
            "tgt_ix": "419-ARR_v1_26@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_27",
            "tgt_ix": "419-ARR_v1_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_28",
            "tgt_ix": "419-ARR_v1_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_29",
            "tgt_ix": "419-ARR_v1_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_29",
            "tgt_ix": "419-ARR_v1_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_29",
            "tgt_ix": "419-ARR_v1_29@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_29",
            "tgt_ix": "419-ARR_v1_29@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_29",
            "tgt_ix": "419-ARR_v1_29@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_29",
            "tgt_ix": "419-ARR_v1_29@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_30",
            "tgt_ix": "419-ARR_v1_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_31",
            "tgt_ix": "419-ARR_v1_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_31",
            "tgt_ix": "419-ARR_v1_31@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_31",
            "tgt_ix": "419-ARR_v1_31@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_32",
            "tgt_ix": "419-ARR_v1_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_32",
            "tgt_ix": "419-ARR_v1_32@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_32",
            "tgt_ix": "419-ARR_v1_32@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_32",
            "tgt_ix": "419-ARR_v1_32@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_32",
            "tgt_ix": "419-ARR_v1_32@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_33",
            "tgt_ix": "419-ARR_v1_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_34",
            "tgt_ix": "419-ARR_v1_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_34",
            "tgt_ix": "419-ARR_v1_34@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_34",
            "tgt_ix": "419-ARR_v1_34@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_34",
            "tgt_ix": "419-ARR_v1_34@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_35",
            "tgt_ix": "419-ARR_v1_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_35",
            "tgt_ix": "419-ARR_v1_35@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_35",
            "tgt_ix": "419-ARR_v1_35@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_35",
            "tgt_ix": "419-ARR_v1_35@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_36",
            "tgt_ix": "419-ARR_v1_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_36",
            "tgt_ix": "419-ARR_v1_36@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_36",
            "tgt_ix": "419-ARR_v1_36@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_36",
            "tgt_ix": "419-ARR_v1_36@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_36",
            "tgt_ix": "419-ARR_v1_36@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_36",
            "tgt_ix": "419-ARR_v1_36@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_37",
            "tgt_ix": "419-ARR_v1_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_37",
            "tgt_ix": "419-ARR_v1_37@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_37",
            "tgt_ix": "419-ARR_v1_37@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_37",
            "tgt_ix": "419-ARR_v1_37@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_37",
            "tgt_ix": "419-ARR_v1_37@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_38",
            "tgt_ix": "419-ARR_v1_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_39",
            "tgt_ix": "419-ARR_v1_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_39",
            "tgt_ix": "419-ARR_v1_39@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_39",
            "tgt_ix": "419-ARR_v1_39@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_39",
            "tgt_ix": "419-ARR_v1_39@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_40",
            "tgt_ix": "419-ARR_v1_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_40",
            "tgt_ix": "419-ARR_v1_40@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_40",
            "tgt_ix": "419-ARR_v1_40@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_41",
            "tgt_ix": "419-ARR_v1_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_41",
            "tgt_ix": "419-ARR_v1_41@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_41",
            "tgt_ix": "419-ARR_v1_41@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_41",
            "tgt_ix": "419-ARR_v1_41@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_42",
            "tgt_ix": "419-ARR_v1_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_42",
            "tgt_ix": "419-ARR_v1_42@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_42",
            "tgt_ix": "419-ARR_v1_42@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_42",
            "tgt_ix": "419-ARR_v1_42@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_43",
            "tgt_ix": "419-ARR_v1_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_43",
            "tgt_ix": "419-ARR_v1_43@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_43",
            "tgt_ix": "419-ARR_v1_43@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_43",
            "tgt_ix": "419-ARR_v1_43@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_43",
            "tgt_ix": "419-ARR_v1_43@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_43",
            "tgt_ix": "419-ARR_v1_43@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_44",
            "tgt_ix": "419-ARR_v1_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_45",
            "tgt_ix": "419-ARR_v1_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_45",
            "tgt_ix": "419-ARR_v1_45@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_45",
            "tgt_ix": "419-ARR_v1_45@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_46",
            "tgt_ix": "419-ARR_v1_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_47",
            "tgt_ix": "419-ARR_v1_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_47",
            "tgt_ix": "419-ARR_v1_47@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_47",
            "tgt_ix": "419-ARR_v1_47@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_47",
            "tgt_ix": "419-ARR_v1_47@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_47",
            "tgt_ix": "419-ARR_v1_47@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_47",
            "tgt_ix": "419-ARR_v1_47@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_47",
            "tgt_ix": "419-ARR_v1_47@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_47",
            "tgt_ix": "419-ARR_v1_47@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_47",
            "tgt_ix": "419-ARR_v1_47@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_48",
            "tgt_ix": "419-ARR_v1_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_48",
            "tgt_ix": "419-ARR_v1_48@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_49",
            "tgt_ix": "419-ARR_v1_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_49",
            "tgt_ix": "419-ARR_v1_49@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_49",
            "tgt_ix": "419-ARR_v1_49@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_49",
            "tgt_ix": "419-ARR_v1_49@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_49",
            "tgt_ix": "419-ARR_v1_49@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_49",
            "tgt_ix": "419-ARR_v1_49@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_49",
            "tgt_ix": "419-ARR_v1_49@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_50",
            "tgt_ix": "419-ARR_v1_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_51",
            "tgt_ix": "419-ARR_v1_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_52",
            "tgt_ix": "419-ARR_v1_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_52",
            "tgt_ix": "419-ARR_v1_52@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_52",
            "tgt_ix": "419-ARR_v1_52@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_52",
            "tgt_ix": "419-ARR_v1_52@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_52",
            "tgt_ix": "419-ARR_v1_52@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_53",
            "tgt_ix": "419-ARR_v1_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_53",
            "tgt_ix": "419-ARR_v1_53@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_53",
            "tgt_ix": "419-ARR_v1_53@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_53",
            "tgt_ix": "419-ARR_v1_53@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_53",
            "tgt_ix": "419-ARR_v1_53@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_54",
            "tgt_ix": "419-ARR_v1_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_54",
            "tgt_ix": "419-ARR_v1_54@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_55",
            "tgt_ix": "419-ARR_v1_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_56",
            "tgt_ix": "419-ARR_v1_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_56",
            "tgt_ix": "419-ARR_v1_56@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_56",
            "tgt_ix": "419-ARR_v1_56@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_57",
            "tgt_ix": "419-ARR_v1_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_57",
            "tgt_ix": "419-ARR_v1_57@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_57",
            "tgt_ix": "419-ARR_v1_57@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_57",
            "tgt_ix": "419-ARR_v1_57@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_57",
            "tgt_ix": "419-ARR_v1_57@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_58",
            "tgt_ix": "419-ARR_v1_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_58",
            "tgt_ix": "419-ARR_v1_58@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_58",
            "tgt_ix": "419-ARR_v1_58@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_58",
            "tgt_ix": "419-ARR_v1_58@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_58",
            "tgt_ix": "419-ARR_v1_58@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_59",
            "tgt_ix": "419-ARR_v1_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_59",
            "tgt_ix": "419-ARR_v1_59@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_60",
            "tgt_ix": "419-ARR_v1_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_60",
            "tgt_ix": "419-ARR_v1_60@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_60",
            "tgt_ix": "419-ARR_v1_60@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_60",
            "tgt_ix": "419-ARR_v1_60@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_60",
            "tgt_ix": "419-ARR_v1_60@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_61",
            "tgt_ix": "419-ARR_v1_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_61",
            "tgt_ix": "419-ARR_v1_61@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_62",
            "tgt_ix": "419-ARR_v1_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_62",
            "tgt_ix": "419-ARR_v1_62@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_63",
            "tgt_ix": "419-ARR_v1_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_63",
            "tgt_ix": "419-ARR_v1_63@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_63",
            "tgt_ix": "419-ARR_v1_63@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_63",
            "tgt_ix": "419-ARR_v1_63@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_63",
            "tgt_ix": "419-ARR_v1_63@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_64",
            "tgt_ix": "419-ARR_v1_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_64",
            "tgt_ix": "419-ARR_v1_64@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_64",
            "tgt_ix": "419-ARR_v1_64@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_64",
            "tgt_ix": "419-ARR_v1_64@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_64",
            "tgt_ix": "419-ARR_v1_64@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_64",
            "tgt_ix": "419-ARR_v1_64@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_64",
            "tgt_ix": "419-ARR_v1_64@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_65",
            "tgt_ix": "419-ARR_v1_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_66",
            "tgt_ix": "419-ARR_v1_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_66",
            "tgt_ix": "419-ARR_v1_66@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_66",
            "tgt_ix": "419-ARR_v1_66@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_66",
            "tgt_ix": "419-ARR_v1_66@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_67",
            "tgt_ix": "419-ARR_v1_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_68",
            "tgt_ix": "419-ARR_v1_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_69",
            "tgt_ix": "419-ARR_v1_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_70",
            "tgt_ix": "419-ARR_v1_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_71",
            "tgt_ix": "419-ARR_v1_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_72",
            "tgt_ix": "419-ARR_v1_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_73",
            "tgt_ix": "419-ARR_v1_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_74",
            "tgt_ix": "419-ARR_v1_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_75",
            "tgt_ix": "419-ARR_v1_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_76",
            "tgt_ix": "419-ARR_v1_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_77",
            "tgt_ix": "419-ARR_v1_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_78",
            "tgt_ix": "419-ARR_v1_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_79",
            "tgt_ix": "419-ARR_v1_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_80",
            "tgt_ix": "419-ARR_v1_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_81",
            "tgt_ix": "419-ARR_v1_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_82",
            "tgt_ix": "419-ARR_v1_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_83",
            "tgt_ix": "419-ARR_v1_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_84",
            "tgt_ix": "419-ARR_v1_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_85",
            "tgt_ix": "419-ARR_v1_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_86",
            "tgt_ix": "419-ARR_v1_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_87",
            "tgt_ix": "419-ARR_v1_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_88",
            "tgt_ix": "419-ARR_v1_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_89",
            "tgt_ix": "419-ARR_v1_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_90",
            "tgt_ix": "419-ARR_v1_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_91",
            "tgt_ix": "419-ARR_v1_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_92",
            "tgt_ix": "419-ARR_v1_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_93",
            "tgt_ix": "419-ARR_v1_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_94",
            "tgt_ix": "419-ARR_v1_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_95",
            "tgt_ix": "419-ARR_v1_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_96",
            "tgt_ix": "419-ARR_v1_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_97",
            "tgt_ix": "419-ARR_v1_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_98",
            "tgt_ix": "419-ARR_v1_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_99",
            "tgt_ix": "419-ARR_v1_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_100",
            "tgt_ix": "419-ARR_v1_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_101",
            "tgt_ix": "419-ARR_v1_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_102",
            "tgt_ix": "419-ARR_v1_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_103",
            "tgt_ix": "419-ARR_v1_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_104",
            "tgt_ix": "419-ARR_v1_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_105",
            "tgt_ix": "419-ARR_v1_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_106",
            "tgt_ix": "419-ARR_v1_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_107",
            "tgt_ix": "419-ARR_v1_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_108",
            "tgt_ix": "419-ARR_v1_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_109",
            "tgt_ix": "419-ARR_v1_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_110",
            "tgt_ix": "419-ARR_v1_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_111",
            "tgt_ix": "419-ARR_v1_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_112",
            "tgt_ix": "419-ARR_v1_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_113",
            "tgt_ix": "419-ARR_v1_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_114",
            "tgt_ix": "419-ARR_v1_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_115",
            "tgt_ix": "419-ARR_v1_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_116",
            "tgt_ix": "419-ARR_v1_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_117",
            "tgt_ix": "419-ARR_v1_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_118",
            "tgt_ix": "419-ARR_v1_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_119",
            "tgt_ix": "419-ARR_v1_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_120",
            "tgt_ix": "419-ARR_v1_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_121",
            "tgt_ix": "419-ARR_v1_121@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_122",
            "tgt_ix": "419-ARR_v1_122@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_123",
            "tgt_ix": "419-ARR_v1_123@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_124",
            "tgt_ix": "419-ARR_v1_124@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_125",
            "tgt_ix": "419-ARR_v1_125@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_126",
            "tgt_ix": "419-ARR_v1_126@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "419-ARR_v1_127",
            "tgt_ix": "419-ARR_v1_127@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 1612,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "position_tag_type": "from_draft",
        "doc_id": "419-ARR",
        "version": 1
    }
}