{
    "nodes": [
        {
            "ix": "412-ARR_v1_0",
            "content": "Domain Adaptation in Multilingual and Multi-Domain Monolingual Settings for Complex Word Identification",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_2",
            "content": "Complex word identification (CWI) is a cornerstone process towards proper text simplification. CWI is highly dependent on context, whereas its difficulty is augmented by the scarcity of available datasets which vary greatly in terms of domains and languages. As such, it becomes increasingly more difficult to develop a robust model that generalizes across a wide array of input examples. In this paper we propose a novel training technique for the CWI task based on domain adaptation to improve the target character and context representations. This technique addresses the problem of working with multiple domains, inasmuch as it creates a way of smoothing the differences between the explored datasets. Moreover, we also propose a similar auxiliary task, namely text simplification, that can be used to complement lexical complexity prediction. Our model obtains a boost of up to 2.42% in terms of Pearson Correlation Coefficients in contrast to vanilla training techniques when considering the CompLex from the Lexical Complexity Prediction 2021 dataset. At the same time, we obtain an increase of 3% in Pearson scores, while considering a cross-lingual setup relying on the Complex Word Identification 2018 dataset. In addition, our model yields state-ofthe-art results in terms of Mean Absolute Error.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "412-ARR_v1_4",
            "content": "Evaluating word difficulty represents the first step towards achieving simplified texts (Maddela and Xu, 2018), which in return facilitates access to knowledge to a wider audience. However, complex word identification (CWI) is a highly contextualized task, far from being trivial. The datasets are scarce and, most of the time, the input entries are limited or cover different domains/areas of expertise. Therefore, developing a robust and reliable model that can be used to properly evaluate the complexity of tokens is a challenging task.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_5",
            "content": "Nevertheless, certain training techniques and auxiliary tasks help the model improve its generalization abilities (Schrom et al., 2021), forcing it to focus only on the most relevant, general features. Techniques like domain adaptation can be used for various tasks, with the purpose of selecting relevant features for follow-up processes.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_6",
            "content": "At the same time, the cross-domain scenario can be transposed to a cross-lingual setup, where the input entries are part of multiple available languages. Performance can be improved by also employing the power of domain adaptation, where the domain is the language; as such, the task of identifying complex tokens can be approached even for low resource languages.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_7",
            "content": "We propose several solutions to improve the performance of a model for CWI in a cross-domain or a cross-lingual setting, by adding auxiliary components (i.e., Transformer (Vaswani et al., 2017) decoders, Variational Auto Encoders -VAEs (Kingma and Welling, 2013)), as well as a domain adaptation training technique (Farahani et al., 2020). Moreover, we use the domain adaptation intuition and we apply it in a multi-task adversarial training scenario, where the main task is trained alongside an auxiliary one, and a task discriminator has the purpose of generalizing task-specific features.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_8",
            "content": "We summarize our main contributions as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_9",
            "content": "\u2022 Applying the concept of domain adaptation in a monolingual, cross-domain scenario for complex word identification. \u2022 Introducing the domain adaptation technique in a cross-lingual setup, where the discriminator has the purpose to support the model extract only the most relevant features across all languages. \u2022 Proposing additional components (i.e., Transformer decoders and Variational Auto Encoders) trained alongside the main CWI task to provide more meaningful representations of the inputs and to ensure robustness, while generating new representations or by tuning the existing ones. \u2022 Experimenting with an additional text simplification task alongside domain/language adaptation, with the purpose of extracting cross-task features and improving performance.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_10",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "412-ARR_v1_11",
            "content": "Vanilla Domain Adaptation. Several works employ domain adaptation to improve performance. For example, Du et al. (2020) approach the sentiment analysis task by using a BERT-based (Devlin et al., 2019) (Klimaszewski and Andruszkiewicz, 2019), mixup synthesis training (Tang et al., 2020), and effective regularization (Vernikos et al., 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_12",
            "content": "Cross-Lingual Domain Adaptation. Chen et al. (2018) proposed ADAN, an architecture based on a feed-forward neural network with three main components, namely: a feature extractor, a sentiment classifier, and a language discriminator. The latter has the purpose of supporting the adversarial training setup, thus covering the scenario where the model is unable the detect whether the input language is from the source dataset or the target one. A similar cross-lingual approach is adopted by Zhang et al. (2020), who developed a system to classify entries from the target language, while only labels from the source language are provided. Keung et al. (2019) employed the usage of multilingual BERT (Pires et al., 2019) and argued that a language-adversarial task can improve the performance of zero-resource cross-lingual transfers. Moreover, training under an adversarial technique helps the Transformer model align the representations of the English inputs.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_13",
            "content": "Under a Named Entity Recognition (NER) training scenario, Kim et al. (2017) use features on two levels (i.e., word and characters), together with Recurrent Neural Networks and a language discriminator used for the domain-adversarial setup. Similarly, Huang et al. (2019) use target language discriminators during the process of training models for low-resource name tagging.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_14",
            "content": "Word Complexity Prediction. Gooding and Kochmar (2019) base their implementation for CWI as a sequence labeling task on Long Short-Term Memory (LSTM) (Hochreiter and Schmidhuber, 1997) networks, inasmuch as the context helps towards proper identification of complex tokens. The authors used 300-dimensional pretrained word embeddings as inputs for the LSTMs. Also adopting a sequence labeling approach, Finnimore et al. ( 2019) consider handcrafted features, including punctuation or syllables, that can properly identify complex structures.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_15",
            "content": "The same sequence labeling approach can be applied under a plurality voting technique (Polikar, 2006), or even using an Oracle (Kuncheva et al., 2001). The Oracle functions best when applied to multiple solutions, by jointly using them to obtain a final prediction.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_16",
            "content": "At the same time, Zaharia et al. (2020) explore the power of Transformer-based models (Vaswani et al., 2017) in cross-lingual environments by using different training scenarios, depending on the scarcity of the resources: zero-shot, one-shot, as well as few-shot learning.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_17",
            "content": "Moreover, CWI can be also approached as a probabilistic task. For example, De Hertog and Tack (2018) introduce a series of architectures that combine deep learning features, as well as handcrafted features to solve a regression problem.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_18",
            "content": "Method",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "412-ARR_v1_19",
            "content": "Datasets",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "412-ARR_v1_20",
            "content": "We experimented with two datasets, one monolingual -CompLex LCP 2021 (Shardlow et al., 2020(Shardlow et al., , 2021b) -and one cross-lingual -the CWI Shared Dataset (Yimam et al., 2018). The entries of Com-pLex consist of a sentence and a target token, alongside the complexity of the token, given its context. The complexities are continuous values between 0 and 1, annotated by various individuals on an initial 5-point Likert scale; the annotations were then normalized.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_21",
            "content": "The CompLex dataset contains two types of entries, each with its corresponding subset of entries: a) single, where the target token is represented by a single word, and b) multiple, where the target token is represented by a group of words. While the single-word dataset contains 7,662 training entries, 421 trial entries, and 917 test entries, the multiword dataset has lower counts, with 1,517 training entries, 99 trial entries, and 184 for testing. At the same time, the entries correspond to three different domains (i.e., biblical, biomedical, and political), therefore displaying different characteristics and challenging the models towards generalization.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_22",
            "content": "The Complex Word Identification (CWI) Shared Dataset was introduced in the CWI Shared Task 2018 (Yimam et al., 2018). It is a multilingual dataset, containing entries in English, German, Spanish, and French. Moreover, the English entries are split into three categories, depending on their proficiency levels: professional (News), nonprofessional (WikiNews), and Wikipedia articles. Most entries are for the English language (27,299 training and 3,328 validation), while the fewest training entries are for German (6,151 training and 795 validation). The French language does not contain training or validation entries.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_23",
            "content": "The Domain Adaption Model",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "412-ARR_v1_24",
            "content": "The overarching architecture of our method is introduced in Figure 1. All underlying components are presented in detail in the following subsections. Our model combines character-level BiLSTM features (i.e., F t ) with Transformer-based features for the context sentence (i.e., F c ). The concatenated features (F c +F t ) are then passed through three linear layers, with a dropout separating the first and second. The output is a value representing the complexity of the target word.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_25",
            "content": "Three configurations were experimented. Within Basic Domain Adaptation, the previous features are passed through an additional component, the domain discriminator, composed of a linear layer followed by a softmax activation function. A gradient reversal layer is added between the feature concatenation and the discriminator to reverse the gradients through the backpropagation phase and support extracting general features. The loss function is determined by Equation 1 as:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_26",
            "content": "L = L r \u2212 \u03b2\u03bbL d (1)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_27",
            "content": "where L r is the regression loss, L d is the general domain loss, \u03b2 is a hyperparameter used for controlling the importance of L d , and \u03bb is another hyperparameter that varies as the training process progresses.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_28",
            "content": "The following setups also include the Basic Domain Adaptation training setup.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_29",
            "content": "VAE and Domain Adaptation considers the previous configuration, plus the VAE encoder, that yields the F v features, and the VAE decoder, which aims to reconstruct the input. The concatenation layer now contains the BiLSTM and Transformer features, plus the VAE encoder features (F v ). The loss function is depicted by Equation 2 as:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_30",
            "content": "L = L r \u2212 \u03b2\u03bbL d + \u03b1L v (2)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_31",
            "content": "where, additionally, L v represents the VAE loss described in Equation 6.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_32",
            "content": "Transformer Decoder and Domain Adaptation adds a Transformer Decoder with the purpose of reconstructing the original input, for a more robust context feature extraction. The loss is denoted by Equation 3 as:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_33",
            "content": "L = L r \u2212 \u03b2\u03bbL d + \u03b1L dec (3)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_34",
            "content": "where L dec represents the decoder loss described in Equation 9.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_35",
            "content": "Character-level BiLSTM for Target Word Representation",
            "ntype": "title",
            "meta": {
                "section": "3.2.1"
            }
        },
        {
            "ix": "412-ARR_v1_36",
            "content": "The purpose of this component is to determine the complexity of the target token, given only its constituent characters. A character-level Bidirectional Long Short-Term Memory (BiLSTM) network receives as input an array of characters corresponding to the target word (or group of words), and yields a representation that is afterwards concatenated to the previously mentioned Transformer-based representations. Each character c is mapped to a certain value obtained from the character vocabulary V, containing all the characters present in the input dataset.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_37",
            "content": "The character sequence is represented as",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_38",
            "content": "C i = [c 1 , c 2 , . . . , c n ],",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_39",
            "content": "where n is the maximum length of a target token. C i is then passed through a character embedding layer, thus yielding the output Emb target . Emb target is then fed to the BiLSTM, followed by a dropout layer, thus obtaining the final target word representation, F t .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_40",
            "content": "Transformer-based Context Representation",
            "ntype": "title",
            "meta": {
                "section": "3.2.2"
            }
        },
        {
            "ix": "412-ARR_v1_41",
            "content": "We rely on a Transformer-based model as the main feature extractor for the context of the target word (i.e., the full sentence), considering their superior performance on most NLP tasks. The selected model for the first dataset is RoBERTa (Liu et al., 2019), inasmuch as it yields better results when compared to its counterpart, BERT. RoBERTa is trained with higher learning rates and larger minibatches, as well as it modifies the key hyperparameters of BERT. We employed the usage of XLM-RoBERTa (Conneau et al., 2020), the multilingual counterpart of RoBERTa, now trained on a very large corpus of multilingual texts, for the second cross-lingual task.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_42",
            "content": "The features used for our task are represented by the pooled output of the Transformer model. The feature vector F c of 768 elements captures information about the context of the target word.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_43",
            "content": "Variational AutoEncoders",
            "ntype": "title",
            "meta": {
                "section": "3.2.3"
            }
        },
        {
            "ix": "412-ARR_v1_44",
            "content": "We aim to further improve performance by adding extra features via Variational AutoEncoders (VAEs) (Kingma and Welling, 2013) to the context representation for a target word. More specifically for the CWI task, we use the latent vector z, alongside the Transformer and the Char BiLSTM features. Moreover, we also need to ensure that the Encoder representation is accurate; therefore, we consider the VAE encoding and decoding as an additional task having the purpose of minimizing the reconstruction loss.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_45",
            "content": "The VAE consists of two parts, namely the encoder and the decoder. The encoder g(x) produces the approximation q(z|x) of the posterior distribution p(z|x), thus mapping the input x to the latent space z. The process is presented in Equation 4. We use as features the representation z, denoted as",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_46",
            "content": "F v . p(z|x) \u2248 q(z|x) = N (\u00b5(x), \u03c3(x))(4)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_47",
            "content": "The decoder f(z) maps the latent space to the input space (i.e., p(z) to p(x)), by using Equation 5. Furthermore, E q represents the expectation with relation to the distribution q.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_48",
            "content": "L(f, g) = i {\u2212D KL [q(z|x i )||p(z)] + E q(z|x i ) [lnp(x i |z)]} (6)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_49",
            "content": "Discriminators",
            "ntype": "title",
            "meta": {
                "section": "3.2.4"
            }
        },
        {
            "ix": "412-ARR_v1_50",
            "content": "The features extracted by our architecture can vary greatly as the input entries can originate from different domains or languages. Consequently, we were introduced a generalization technique to extract only cross-domain features that do not present a bias towards a certain domain. We thus employ an adversarial training technique based on domain adaptation, forcing the model to only extract relevant cross-domain features.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_51",
            "content": "A discriminator acts as a classifier, containing three linear layers with corresponding activation functions. The discriminator classifies the input sentence into one of the available domains. Unlike traditional classification approaches, our purpose is not to minimize the loss, but to maximize it. We want our model to become incapable of distinguishing between different categories of input entries, therefore extracting the most relevant, cross-domain features.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_52",
            "content": "Our architecture is encouraged to generalize in terms of extracted features by the gradient reversal layer that reverses the gradients during the backpropagation phase; as such, the parameters are updated towards the direction that maximizes the loss instead of minimizing it.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_53",
            "content": "Three scenarios were considered, each one targeting a different approach towards domain adaptation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_54",
            "content": "Domain Discriminator. The first scenario is applied on the first dataset, CompLex, with entries only in English, but covering multiple domains. The discriminator has the purpose of identifying the domain of the entry, namely biblical, biomedical or political. The intuition is that, by grasping only cross-domain features, the performance of the model increases on all three domains, instead of performing well only on one, while poorer on the others.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_55",
            "content": "Language Discriminator. The intuition is similar to the previous scenario, except that we experimented with the second multilingual dataset. Therefore, our interest was that our model extracts cross-lingual features, such that the performance is equal on all the target languages.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_56",
            "content": "Task Discriminator. In this scenario, we trained a similar, auxiliary task, represented by text simplification. A task discriminator is implemented to detect the origin of the input entry: either the main task or the auxiliary task (i.e., simplified version). The dataset used for text simplification is represented by BenchLS (Paetzold and Specia, 2016) 1 . The employed simplification process consists of masking the word considered to be complex and then using a Transformer for Masked Language Modeling to predict the best candidate. The corresponding flow is described in algorithm 1, while the loss function is presented in Equation 7.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_57",
            "content": "L = L r \u2212 \u03b2\u03bbL task_id + L M L (7)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_58",
            "content": "where L ML is the Sparse Categorical Cross Entropy loss.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_59",
            "content": "Algorithm 1: The Multi-Task Adversarial algorithm (Task 1 -lexical complexity prediction; Task 2 -text simplification).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_60",
            "content": "1 Inputs: Preprocessed dataset, split into batches (x i , y i ), i=1,n (where n is the number of batches, x i are the input features for the target word and the context, and y i is the complexity); 2 Outputs: Updated parameters \u03b8 p ; 3 Initialization: initialize \u03b8 p with random weights; 4 for every batch do All previous discriminators use the same loss, namely Categorical Cross Entropy (Zhang and Sabuncu, 2018).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_61",
            "content": "The overall loss consists of the difference between the task loss and the domain/language loss. Moreover, the importance of the latter can be controlled by multiplication with a \u03bb hyperparameter, that changes over time, and a fixed \u03b2 hyperparameter. The network parameters, \u03b8 p are updated according to Equation 8, where \u03b7 is the learning rate, L d is the domain loss, L r is the task loss and \u03b2 is the weight for the domain loss. A similar equation for language loss (L l ) is in place for the second dataset, where instead of the domain loss L d we used the language identification loss L l , having the same formula.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_62",
            "content": "\u03b8 p = \u03b8 p \u2212 \u03b7( \u2202L r \u2202\u03b8 p \u2212 \u03b2\u03bb \u2202L d \u2202\u03b8 p ) (8)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_63",
            "content": "Transformer Decoder",
            "ntype": "title",
            "meta": {
                "section": "3.2.5"
            }
        },
        {
            "ix": "412-ARR_v1_64",
            "content": "Our model also considers a decoder to reconstruct the original input, starting from the Transformer representation. The intuition behind introducing this decoder is to increase the robustness of the context feature extraction.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_65",
            "content": "The decoder receives as input the outputs of the hidden Transformer layer alongside an embedding of the original input, which are passed through a Gated Recurrent Unit (GRU) (Chung et al., 2014) layer for obtaining the final representation of the initial input. Additionally, two linear layers separated by a dropout are introduced before obtaining the final representation, y = F d . The loss is computed by using the Negative Log Likelihood loss between the outputs of the decoder and the original Transformer input id representation of the entries (see Equations 9 and 10).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_66",
            "content": "L(x, y) = N n=1 l n (9) l n = \u2212w yn x n,yn , w c = weight[c] \u2022 1, {c = index, c = ignore_index} (10)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_67",
            "content": "Experimental Setup",
            "ntype": "title",
            "meta": {
                "section": "3.3"
            }
        },
        {
            "ix": "412-ARR_v1_68",
            "content": "The optimizer used for our models is represented by AdamW (Kingma and Ba, 2014). The learning rate is set to 2e-5, while the loss functions used for the complexity task are the L1 loss (Janocha and Czarnecki, 2017) for the first dataset and the Mean Squared Error (MSE) loss (Kline and Berardi, 2005) for the second one. The auxiliary losses are summed to the main loss (i.e., complexity prediction) and are scaled according to their priority, with a factor of \u03b1, where \u03b1 is set to 0.1 for the VAE loss, and 0.01 for the Transformer decoder and task discriminator losses. The \u03bb parameter used for domain adaptation was updated according to Equation 11.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_69",
            "content": "\u03bb = 2 1 + e \u2212\u03b3e \u2212 1 (11",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_70",
            "content": ")",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_71",
            "content": "where e is the number of epochs the model was trained; \u03b3 was set to 0.1, while \u03b2 was set to 0.2. Moreover, each model was trained for 8 epochs, except for the one including the VAE features, which was trained for 12 epochs.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_72",
            "content": "Results",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "412-ARR_v1_73",
            "content": "LCP 2021 CompLex Dataset",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "412-ARR_v1_74",
            "content": "We consider as baselines two models used for the LCP 2021 competition (Shardlow et al., 2021a), as well as the best-registered score. de Almeida et al. ( 2021) employed the usage of neural network solutions; more specifically, they used chunks of the sentences obtained with Sent2Vec as input features. Zaharia et al. (2021) created models that are based on target and context feature extractors, alongside features resulted from Graph Convolutional Networks, Capsule Networks, or pre-trained word embeddings. Table 1 depicts the results obtained for the English dataset using domain adaptation and various configurations. \"Base\" denotes the initial model (RoBERTa + Char BiLSTM) on which we apply domain adaptation, as well as the auxiliary tasks. The domain adaptation technique offers improved performance when applied on top of an architecture, considering that the model learns cross-domain features. The only exception is represented by a slightly lower Pearson score on the model that uses domain adaptation alongside the Transformer decoding auxiliary task (Base + Decoder + DA), with a value of .7969 on the trial dataset, when compared to the initial 0.7987 (Base). However, the remaining models improve upon the starting architecture, with the largest improvements being observed for domain adaptation and the text simplification auxiliary task (Base + Text simplification + DA), with a Pearson correlation coefficient on the test dataset of .7744, 2.42% better than the base model. The improved performance can be also seen for the Mean Absolute Error score (MAE = .0652).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_75",
            "content": "While the Transformer decoder auxiliary task does not offer the best performance for the single word dataset, the same architecture offers the second-best performance for the multiple word dataset, with a Pearson score of .8252 compared to the best one, .8285.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_76",
            "content": "The domain adaptation and VAE configuration provide improvements upon the base model (.7554 versus .7502 Pearson), but the VAE does not have an important contribution, considering that the Base + domain adaptation model has a slightly higher Pearson score of .7569.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_77",
            "content": "CWI 2018 Dataset",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "412-ARR_v1_78",
            "content": "We also experimented with a multilingual dataset, where the discriminant is considered to be the lan- guage. The baseline consists of three models used from the CWI 2018 competition. The performance is evaluated in terms of MAE; However, we also report the Pearson Correlation Coefficient. First, Kajiwara and Komachi (2018) based their models on regressors, alongside features represented by the number of characters or words and the frequency of the target word in certain corpora. Second, the approach of Bingel and Bjerva (2018)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_79",
            "content": "Discussions",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "412-ARR_v1_80",
            "content": "The domain adaptation technique supports our model to learn general cross-domain (or cross-language) features, while achieving higher performance. Moreover, jointly training on two different tasks (i.e., lexical complexity prediction and text simplification), coupled with domain adaptation to generalize the features from the two tasks, can lead to improved results.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_81",
            "content": "However, there are entries for which our models were unable to properly predict the complexity score, namely: a) entries with a different level of complexity (i.e. biomedical), and b) entries part of a language that was not present in the training dataset (i.e., French).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_82",
            "content": "For the former, scientific terms (e.g., \"sitosterolemia\"), abbreviations (e.g., \"ES\"), or complex elements (e.g., \" H3-2meK9\") impose a series of difficulties for our feature extractors, considering the absence of these tokens from the Transformer vocabulary.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_83",
            "content": "The latter category of problematic entries creates new challenges in the sense that it represents a completely new language on which the architecture is tested. However, as seen in the results section, the cross-lingual domain adaptation technique offers good improvements, helping the model achieve better performance on French, even though the initial architecture was not exposed to any French example.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_84",
            "content": "Conclusion and Future Work",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "412-ARR_v1_85",
            "content": "This work proposes a series of training techniques, including adversarial domain adaptation, as well as multi-task learning, that can be used for improving the overall performance of the models for CWI. Domain adaptation improves results by encouraging the models to extract more general features, that can be further used for the lexical complexity prediction task.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_86",
            "content": "Moreover, by jointly training the model on the CWI taks and an auxiliary similar task (i.e., text simplification), the overall performance is improved. The task discriminator also ensures the extraction of general features, thus making the model more robust on the CWI task.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_87",
            "content": "For future work, we intend to experiment with meta learning (Finn et al., 2017) alongside domain adaptation (Wang et al., 2019), considering the scope of the previously applied training techniques. This would enable us to initialize the model's weights in the best manner, thus ensuring optimal results during the training phase.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "412-ARR_v1_88",
            "content": "Joachim Bingel, Johannes Bjerva, Crosslingual complex word identification with multitask learning, 2018, Proceedings of the thirteenth workshop on innovative use of NLP for building educational applications, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "Joachim Bingel",
                    "Johannes Bjerva"
                ],
                "title": "Crosslingual complex word identification with multitask learning",
                "pub_date": "2018",
                "pub_title": "Proceedings of the thirteenth workshop on innovative use of NLP for building educational applications",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_89",
            "content": "UNKNOWN, None, 2018, Adversarial deep averaging networks for cross-lingual sentiment classification, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Adversarial deep averaging networks for cross-lingual sentiment classification",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_90",
            "content": "UNKNOWN, None, 2014, Empirical evaluation of gated recurrent neural networks on sequence modeling, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": null,
                "title": null,
                "pub_date": "2014",
                "pub_title": "Empirical evaluation of gated recurrent neural networks on sequence modeling",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_91",
            "content": "Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, \u00c9douard Grave, Myle Ott, Luke Zettlemoyer, Veselin Stoyanov, Unsupervised cross-lingual representation learning at scale, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Alexis Conneau",
                    "Kartikay Khandelwal",
                    "Naman Goyal",
                    "Vishrav Chaudhary",
                    "Guillaume Wenzek",
                    "Francisco Guzm\u00e1n",
                    "\u00c9douard Grave",
                    "Myle Ott",
                    "Luke Zettlemoyer",
                    "Veselin Stoyanov"
                ],
                "title": "Unsupervised cross-lingual representation learning at scale",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_92",
            "content": "Erenay Dayanik, Sebastian Pad\u00f3, Masking actor information leads to fairer political claims detection, 2020, Proceedings of the 58th Annual Meeting of the Association for Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Erenay Dayanik",
                    "Sebastian Pad\u00f3"
                ],
                "title": "Masking actor information leads to fairer political claims detection",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Linguistics",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_93",
            "content": "UNKNOWN, None, 2021, C3sl at semeval-2021 task 1: Predicting lexical complexity of words in specific contexts with sentence embeddings, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "C3sl at semeval-2021 task 1: Predicting lexical complexity of words in specific contexts with sentence embeddings",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_94",
            "content": "Dirk De Hertog, Ana\u00efs Tack, Deep learning architecture for complex word identification, 2018, Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications, .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "Dirk De Hertog",
                    "Ana\u00efs Tack"
                ],
                "title": "Deep learning architecture for complex word identification",
                "pub_date": "2018",
                "pub_title": "Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_95",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, Bert: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Jacob Devlin",
                    "Ming-Wei Chang",
                    "Kenton Lee",
                    "Kristina Toutanova"
                ],
                "title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_96",
            "content": "Chunning Du, Haifeng Sun, Jingyu Wang, Qi Qi, Jianxin Liao, Adversarial and domain-aware bert for cross-domain sentiment analysis, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Chunning Du",
                    "Haifeng Sun",
                    "Jingyu Wang",
                    "Qi Qi",
                    "Jianxin Liao"
                ],
                "title": "Adversarial and domain-aware bert for cross-domain sentiment analysis",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_97",
            "content": "UNKNOWN, None, 2020, A brief review of domain adaptation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "A brief review of domain adaptation",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_98",
            "content": "Chelsea Finn, Pieter Abbeel, Sergey Levine, Model-agnostic meta-learning for fast adaptation of deep networks, 2017, Proceedings of the 34th International Conference on Machine Learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Chelsea Finn",
                    "Pieter Abbeel",
                    "Sergey Levine"
                ],
                "title": "Model-agnostic meta-learning for fast adaptation of deep networks",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 34th International Conference on Machine Learning",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_99",
            "content": "Pierre Finnimore, Elisabeth Fritzsch, Daniel King, Alison Sneyd, Aneeq Ur Rehman, Fernando Alva-Manchego, Andreas Vlachos, Strong baselines for complex word identification across multiple languages, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Pierre Finnimore",
                    "Elisabeth Fritzsch",
                    "Daniel King",
                    "Alison Sneyd",
                    "Aneeq Ur Rehman",
                    "Fernando Alva-Manchego",
                    "Andreas Vlachos"
                ],
                "title": "Strong baselines for complex word identification across multiple languages",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_100",
            "content": "Sian Gooding, Ekaterina Kochmar, Camb at cwi shared task 2018: Complex word identification with ensemble-based voting, 2018, Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Sian Gooding",
                    "Ekaterina Kochmar"
                ],
                "title": "Camb at cwi shared task 2018: Complex word identification with ensemble-based voting",
                "pub_date": "2018",
                "pub_title": "Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_101",
            "content": "Sian Gooding, Ekaterina Kochmar, Complex word identification as a sequence labelling task, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    "Sian Gooding",
                    "Ekaterina Kochmar"
                ],
                "title": "Complex word identification as a sequence labelling task",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_102",
            "content": "Sepp Hochreiter, J\u00fcrgen Schmidhuber, Long short-term memory, 1997, Neural computation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Sepp Hochreiter",
                    "J\u00fcrgen Schmidhuber"
                ],
                "title": "Long short-term memory",
                "pub_date": "1997",
                "pub_title": "Neural computation",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_103",
            "content": "Lifu Huang, Ji Heng, Jonathan , Crosslingual multi-level adversarial transfer to enhance low-resource name tagging, 2019-05, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Lifu Huang",
                    "Ji Heng",
                    "Jonathan "
                ],
                "title": "Crosslingual multi-level adversarial transfer to enhance low-resource name tagging",
                "pub_date": "2019-05",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_104",
            "content": "UNKNOWN, None, 2017, On loss functions for deep neural networks in classification, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": "On loss functions for deep neural networks in classification",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_105",
            "content": "Tomoyuki Kajiwara, Mamoru Komachi, Complex word identification based on frequency in a learner corpus, 2018, Proceedings of the thirteenth workshop on innovative use of NLP for building educational applications, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Tomoyuki Kajiwara",
                    "Mamoru Komachi"
                ],
                "title": "Complex word identification based on frequency in a learner corpus",
                "pub_date": "2018",
                "pub_title": "Proceedings of the thirteenth workshop on innovative use of NLP for building educational applications",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_106",
            "content": "Phillip Keung, Vikas Bhardwaj, Adversarial learning with contextual embeddings for zeroresource cross-lingual classification and ner, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Phillip Keung",
                    "Vikas Bhardwaj"
                ],
                "title": "Adversarial learning with contextual embeddings for zeroresource cross-lingual classification and ner",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_107",
            "content": "Joo-Kyung Kim, Young-Bum Kim, Ruhi Sarikaya, Eric Fosler-Lussier, Cross-lingual transfer learning for pos tagging without cross-lingual resources, 2017, Proceedings of the 2017 conference on empirical methods in natural language processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "Joo-Kyung Kim",
                    "Young-Bum Kim",
                    "Ruhi Sarikaya",
                    "Eric Fosler-Lussier"
                ],
                "title": "Cross-lingual transfer learning for pos tagging without cross-lingual resources",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 2017 conference on empirical methods in natural language processing",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_108",
            "content": "UNKNOWN, None, 2014, Adam: A method for stochastic optimization, .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": null,
                "title": null,
                "pub_date": "2014",
                "pub_title": "Adam: A method for stochastic optimization",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_109",
            "content": "UNKNOWN, None, 2013, Autoencoding variational bayes, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": null,
                "title": null,
                "pub_date": "2013",
                "pub_title": "Autoencoding variational bayes",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_110",
            "content": "Mateusz Klimaszewski, Piotr Andruszkiewicz, Wut at semeval-2019 task 9: Domainadversarial neural networks for domain adaptation in suggestion mining, 2019, Proceedings of the 13th International Workshop on Semantic Evaluation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Mateusz Klimaszewski",
                    "Piotr Andruszkiewicz"
                ],
                "title": "Wut at semeval-2019 task 9: Domainadversarial neural networks for domain adaptation in suggestion mining",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 13th International Workshop on Semantic Evaluation",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_111",
            "content": "M Douglas,  Kline, L Victor,  Berardi, Revisiting squared-error and cross-entropy functions for training neural network classifiers, 2005, Neural Computing & Applications, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "M Douglas",
                    " Kline",
                    "L Victor",
                    " Berardi"
                ],
                "title": "Revisiting squared-error and cross-entropy functions for training neural network classifiers",
                "pub_date": "2005",
                "pub_title": "Neural Computing & Applications",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_112",
            "content": "Ludmila I Kuncheva, C James, Robert Pw Bezdek,  Duin, Decision templates for multiple classifier fusion: an experimental comparison, 2001, Pattern recognition, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    " Ludmila I Kuncheva",
                    "C James",
                    "Robert Pw Bezdek",
                    " Duin"
                ],
                "title": "Decision templates for multiple classifier fusion: an experimental comparison",
                "pub_date": "2001",
                "pub_title": "Pattern recognition",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_113",
            "content": "UNKNOWN, None, 2019, Roberta: A robustly optimized bert pretraining approach, .",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Roberta: A robustly optimized bert pretraining approach",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_114",
            "content": "Mounica Maddela, Wei Xu, A wordcomplexity lexicon and a neural readability ranking model for lexical simplification, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": [
                    "Mounica Maddela",
                    "Wei Xu"
                ],
                "title": "A wordcomplexity lexicon and a neural readability ranking model for lexical simplification",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_115",
            "content": "Robert Mchardy, Heike Adel, Roman Klinger, Adversarial training for satire detection: Controlling for confounding variables, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": [
                    "Robert Mchardy",
                    "Heike Adel",
                    "Roman Klinger"
                ],
                "title": "Adversarial training for satire detection: Controlling for confounding variables",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_116",
            "content": "UNKNOWN, None, 2016, BenchLS: A Reliable Dataset for Lexical Simplification, .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": null,
                "title": null,
                "pub_date": "2016",
                "pub_title": "BenchLS: A Reliable Dataset for Lexical Simplification",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_117",
            "content": "Telmo Pires, Eva Schlinger, Dan Garrette, How multilingual is multilingual bert?, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "Telmo Pires",
                    "Eva Schlinger",
                    "Dan Garrette"
                ],
                "title": "How multilingual is multilingual bert?",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_118",
            "content": "UNKNOWN, None, 2006, Ensemble based systems in decision making. IEEE Circuits and systems magazine, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": null,
                "title": null,
                "pub_date": "2006",
                "pub_title": "Ensemble based systems in decision making. IEEE Circuits and systems magazine",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_119",
            "content": "UNKNOWN, None, 2021, Improved multi-source domain adaptation by preservation of factors. Image and Vision Computing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Improved multi-source domain adaptation by preservation of factors. Image and Vision Computing",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_120",
            "content": "Matthew Shardlow, Richard Evans, Gustavo Paetzold, Marcos Zampieri, Semeval-2021 task 1: Lexical complexity prediction, 2021, Proceedings of the 14th International Workshop on Semantic Evaluation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": [
                    "Matthew Shardlow",
                    "Richard Evans",
                    "Gustavo Paetzold",
                    "Marcos Zampieri"
                ],
                "title": "Semeval-2021 task 1: Lexical complexity prediction",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 14th International Workshop on Semantic Evaluation",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_121",
            "content": "UNKNOWN, None, 2021, Predicting lexical complexity in english texts, .",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Predicting lexical complexity in english texts",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_122",
            "content": "Matthew Shardlow, Marcos Zampieri, Michael Cooper, Complex-a new corpus for lexical complexity predicition from likertscale data, 2020, Proceedings of the 1st Workshop on Tools and Resources to Empower People with REAding DIfficulties (READI), .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": [
                    "Matthew Shardlow",
                    "Marcos Zampieri",
                    "Michael Cooper"
                ],
                "title": "Complex-a new corpus for lexical complexity predicition from likertscale data",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 1st Workshop on Tools and Resources to Empower People with REAding DIfficulties (READI)",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_123",
            "content": "Yuhua Tang, Zhipeng Lin, Haotian Wang, Liyang Xu, Adversarial mixup synthesis training for unsupervised domain adaptation, 2020, ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), IEEE.",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": [
                    "Yuhua Tang",
                    "Zhipeng Lin",
                    "Haotian Wang",
                    "Liyang Xu"
                ],
                "title": "Adversarial mixup synthesis training for unsupervised domain adaptation",
                "pub_date": "2020",
                "pub_title": "ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
                "pub": "IEEE"
            }
        },
        {
            "ix": "412-ARR_v1_124",
            "content": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Attention is all you need, 2017, Proceedings of the 31st International Conference on Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "Ashish Vaswani",
                    "Noam Shazeer",
                    "Niki Parmar",
                    "Jakob Uszkoreit",
                    "Llion Jones",
                    "Aidan Gomez",
                    "\u0141ukasz Kaiser",
                    "Illia Polosukhin"
                ],
                "title": "Attention is all you need",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 31st International Conference on Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_125",
            "content": "Giorgos Vernikos, Katerina Margatina, Alexandra Chronopoulou, Ion Androutsopoulos, Domain adversarial fine-tuning as an effective regularizer, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings, .",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": [
                    "Giorgos Vernikos",
                    "Katerina Margatina",
                    "Alexandra Chronopoulou",
                    "Ion Androutsopoulos"
                ],
                "title": "Domain adversarial fine-tuning as an effective regularizer",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_126",
            "content": "Ke Wang, Gong Zhang, Henry Leung, Sar target recognition based on cross-domain and crosstask transfer learning, 2019, IEEE Access, .",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": [
                    "Ke Wang",
                    "Gong Zhang",
                    "Henry Leung"
                ],
                "title": "Sar target recognition based on cross-domain and crosstask transfer learning",
                "pub_date": "2019",
                "pub_title": "IEEE Access",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_127",
            "content": "Chris Seid Muhie Yimam, Shervin Biemann, Gustavo Malmasi, Lucia Paetzold, Sanja Specia,  \u0160tajner, A report on the complex word identification shared task, 2018, Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications, .",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": [
                    "Chris Seid Muhie Yimam",
                    "Shervin Biemann",
                    "Gustavo Malmasi",
                    "Lucia Paetzold",
                    "Sanja Specia",
                    " \u0160tajner"
                ],
                "title": "A report on the complex word identification shared task",
                "pub_date": "2018",
                "pub_title": "Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_128",
            "content": "George-Eduard Zaharia, Dumitru-Clementin Cercel, Mihai Dascalu, Cross-lingual transfer learning for complex word identification, 2020, 2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI), IEEE.",
            "ntype": "ref",
            "meta": {
                "xid": "b40",
                "authors": [
                    "George-Eduard Zaharia",
                    "Dumitru-Clementin Cercel",
                    "Mihai Dascalu"
                ],
                "title": "Cross-lingual transfer learning for complex word identification",
                "pub_date": "2020",
                "pub_title": "2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI)",
                "pub": "IEEE"
            }
        },
        {
            "ix": "412-ARR_v1_129",
            "content": "UNKNOWN, None, 2021, Upb at semeval-2021 task 1: Combining deep learning and hand-crafted features for lexical complexity prediction, .",
            "ntype": "ref",
            "meta": {
                "xid": "b41",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Upb at semeval-2021 task 1: Combining deep learning and hand-crafted features for lexical complexity prediction",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_130",
            "content": "Dejiao Zhang, Ramesh Nallapati, Henghui Zhu, Feng Nan, Kathleen Cicero Dos Santos, Bing Mckeown,  Xiang, Unsupervised domain adaptation for cross-lingual text labeling, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings, .",
            "ntype": "ref",
            "meta": {
                "xid": "b42",
                "authors": [
                    "Dejiao Zhang",
                    "Ramesh Nallapati",
                    "Henghui Zhu",
                    "Feng Nan",
                    "Kathleen Cicero Dos Santos",
                    "Bing Mckeown",
                    " Xiang"
                ],
                "title": "Unsupervised domain adaptation for cross-lingual text labeling",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings",
                "pub": null
            }
        },
        {
            "ix": "412-ARR_v1_131",
            "content": "Zhilu Zhang, R Mert,  Sabuncu, Generalized cross entropy loss for training deep neural networks with noisy labels, 2018, Proceedings of the 32nd International Conference on Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b43",
                "authors": [
                    "Zhilu Zhang",
                    "R Mert",
                    " Sabuncu"
                ],
                "title": "Generalized cross entropy loss for training deep neural networks with noisy labels",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 32nd International Conference on Neural Information Processing Systems",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "412-ARR_v1_0@0",
            "content": "Domain Adaptation in Multilingual and Multi-Domain Monolingual Settings for Complex Word Identification",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_0",
            "start": 0,
            "end": 102,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_2@0",
            "content": "Complex word identification (CWI) is a cornerstone process towards proper text simplification.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_2",
            "start": 0,
            "end": 93,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_2@1",
            "content": "CWI is highly dependent on context, whereas its difficulty is augmented by the scarcity of available datasets which vary greatly in terms of domains and languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_2",
            "start": 95,
            "end": 257,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_2@2",
            "content": "As such, it becomes increasingly more difficult to develop a robust model that generalizes across a wide array of input examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_2",
            "start": 259,
            "end": 387,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_2@3",
            "content": "In this paper we propose a novel training technique for the CWI task based on domain adaptation to improve the target character and context representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_2",
            "start": 389,
            "end": 544,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_2@4",
            "content": "This technique addresses the problem of working with multiple domains, inasmuch as it creates a way of smoothing the differences between the explored datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_2",
            "start": 546,
            "end": 704,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_2@5",
            "content": "Moreover, we also propose a similar auxiliary task, namely text simplification, that can be used to complement lexical complexity prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_2",
            "start": 706,
            "end": 846,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_2@6",
            "content": "Our model obtains a boost of up to 2.42% in terms of Pearson Correlation Coefficients in contrast to vanilla training techniques when considering the CompLex from the Lexical Complexity Prediction 2021 dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_2",
            "start": 848,
            "end": 1057,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_2@7",
            "content": "At the same time, we obtain an increase of 3% in Pearson scores, while considering a cross-lingual setup relying on the Complex Word Identification 2018 dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_2",
            "start": 1059,
            "end": 1219,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_2@8",
            "content": "In addition, our model yields state-ofthe-art results in terms of Mean Absolute Error.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_2",
            "start": 1221,
            "end": 1306,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_4@0",
            "content": "Evaluating word difficulty represents the first step towards achieving simplified texts (Maddela and Xu, 2018), which in return facilitates access to knowledge to a wider audience.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_4",
            "start": 0,
            "end": 179,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_4@1",
            "content": "However, complex word identification (CWI) is a highly contextualized task, far from being trivial.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_4",
            "start": 181,
            "end": 279,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_4@2",
            "content": "The datasets are scarce and, most of the time, the input entries are limited or cover different domains/areas of expertise.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_4",
            "start": 281,
            "end": 403,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_4@3",
            "content": "Therefore, developing a robust and reliable model that can be used to properly evaluate the complexity of tokens is a challenging task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_4",
            "start": 405,
            "end": 539,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_5@0",
            "content": "Nevertheless, certain training techniques and auxiliary tasks help the model improve its generalization abilities (Schrom et al., 2021), forcing it to focus only on the most relevant, general features.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_5",
            "start": 0,
            "end": 200,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_5@1",
            "content": "Techniques like domain adaptation can be used for various tasks, with the purpose of selecting relevant features for follow-up processes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_5",
            "start": 202,
            "end": 338,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_6@0",
            "content": "At the same time, the cross-domain scenario can be transposed to a cross-lingual setup, where the input entries are part of multiple available languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_6",
            "start": 0,
            "end": 152,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_6@1",
            "content": "Performance can be improved by also employing the power of domain adaptation, where the domain is the language; as such, the task of identifying complex tokens can be approached even for low resource languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_6",
            "start": 154,
            "end": 363,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_7@0",
            "content": "We propose several solutions to improve the performance of a model for CWI in a cross-domain or a cross-lingual setting, by adding auxiliary components (i.e., Transformer (Vaswani et al., 2017) decoders, Variational Auto Encoders -VAEs (Kingma and Welling, 2013)), as well as a domain adaptation training technique (Farahani et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_7",
            "start": 0,
            "end": 338,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_7@1",
            "content": "Moreover, we use the domain adaptation intuition and we apply it in a multi-task adversarial training scenario, where the main task is trained alongside an auxiliary one, and a task discriminator has the purpose of generalizing task-specific features.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_7",
            "start": 340,
            "end": 590,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_8@0",
            "content": "We summarize our main contributions as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_8",
            "start": 0,
            "end": 46,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_9@0",
            "content": "\u2022 Applying the concept of domain adaptation in a monolingual, cross-domain scenario for complex word identification. \u2022 Introducing the domain adaptation technique in a cross-lingual setup, where the discriminator has the purpose to support the model extract only the most relevant features across all languages. \u2022 Proposing additional components (i.e., Transformer decoders and Variational Auto Encoders) trained alongside the main CWI task to provide more meaningful representations of the inputs and to ensure robustness, while generating new representations or by tuning the existing ones. \u2022 Experimenting with an additional text simplification task alongside domain/language adaptation, with the purpose of extracting cross-task features and improving performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_9",
            "start": 0,
            "end": 767,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_10@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_10",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_11@0",
            "content": "Vanilla Domain Adaptation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_11",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_11@1",
            "content": "Several works employ domain adaptation to improve performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_11",
            "start": 27,
            "end": 88,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_11@2",
            "content": "For example, Du et al. (2020) approach the sentiment analysis task by using a BERT-based (Devlin et al., 2019) (Klimaszewski and Andruszkiewicz, 2019), mixup synthesis training (Tang et al., 2020), and effective regularization (Vernikos et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_11",
            "start": 90,
            "end": 340,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_12@0",
            "content": "Cross-Lingual Domain Adaptation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_12",
            "start": 0,
            "end": 31,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_12@1",
            "content": "Chen et al. (2018) proposed ADAN, an architecture based on a feed-forward neural network with three main components, namely: a feature extractor, a sentiment classifier, and a language discriminator.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_12",
            "start": 33,
            "end": 231,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_12@2",
            "content": "The latter has the purpose of supporting the adversarial training setup, thus covering the scenario where the model is unable the detect whether the input language is from the source dataset or the target one.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_12",
            "start": 233,
            "end": 441,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_12@3",
            "content": "A similar cross-lingual approach is adopted by Zhang et al. (2020), who developed a system to classify entries from the target language, while only labels from the source language are provided.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_12",
            "start": 443,
            "end": 635,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_12@4",
            "content": "Keung et al. (2019) employed the usage of multilingual BERT (Pires et al., 2019) and argued that a language-adversarial task can improve the performance of zero-resource cross-lingual transfers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_12",
            "start": 637,
            "end": 830,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_12@5",
            "content": "Moreover, training under an adversarial technique helps the Transformer model align the representations of the English inputs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_12",
            "start": 832,
            "end": 957,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_13@0",
            "content": "Under a Named Entity Recognition (NER) training scenario, Kim et al. (2017) use features on two levels (i.e., word and characters), together with Recurrent Neural Networks and a language discriminator used for the domain-adversarial setup.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_13",
            "start": 0,
            "end": 238,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_13@1",
            "content": "Similarly, Huang et al. (2019) use target language discriminators during the process of training models for low-resource name tagging.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_13",
            "start": 240,
            "end": 373,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_14@0",
            "content": "Word Complexity Prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_14",
            "start": 0,
            "end": 26,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_14@1",
            "content": "Gooding and Kochmar (2019) base their implementation for CWI as a sequence labeling task on Long Short-Term Memory (LSTM) (Hochreiter and Schmidhuber, 1997) networks, inasmuch as the context helps towards proper identification of complex tokens.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_14",
            "start": 28,
            "end": 272,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_14@2",
            "content": "The authors used 300-dimensional pretrained word embeddings as inputs for the LSTMs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_14",
            "start": 274,
            "end": 357,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_14@3",
            "content": "Also adopting a sequence labeling approach, Finnimore et al. ( 2019) consider handcrafted features, including punctuation or syllables, that can properly identify complex structures.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_14",
            "start": 359,
            "end": 540,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_15@0",
            "content": "The same sequence labeling approach can be applied under a plurality voting technique (Polikar, 2006), or even using an Oracle (Kuncheva et al., 2001).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_15",
            "start": 0,
            "end": 150,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_15@1",
            "content": "The Oracle functions best when applied to multiple solutions, by jointly using them to obtain a final prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_15",
            "start": 152,
            "end": 264,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_16@0",
            "content": "At the same time, Zaharia et al. (2020) explore the power of Transformer-based models (Vaswani et al., 2017) in cross-lingual environments by using different training scenarios, depending on the scarcity of the resources: zero-shot, one-shot, as well as few-shot learning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_16",
            "start": 0,
            "end": 271,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_17@0",
            "content": "Moreover, CWI can be also approached as a probabilistic task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_17",
            "start": 0,
            "end": 60,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_17@1",
            "content": "For example, De Hertog and Tack (2018) introduce a series of architectures that combine deep learning features, as well as handcrafted features to solve a regression problem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_17",
            "start": 62,
            "end": 235,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_18@0",
            "content": "Method",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_18",
            "start": 0,
            "end": 5,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_19@0",
            "content": "Datasets",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_19",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_20@0",
            "content": "We experimented with two datasets, one monolingual -CompLex LCP 2021 (Shardlow et al., 2020(Shardlow et al., , 2021b) -and one cross-lingual -the CWI Shared Dataset (Yimam et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_20",
            "start": 0,
            "end": 185,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_20@1",
            "content": "The entries of Com-pLex consist of a sentence and a target token, alongside the complexity of the token, given its context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_20",
            "start": 187,
            "end": 309,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_20@2",
            "content": "The complexities are continuous values between 0 and 1, annotated by various individuals on an initial 5-point Likert scale; the annotations were then normalized.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_20",
            "start": 311,
            "end": 472,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_21@0",
            "content": "The CompLex dataset contains two types of entries, each with its corresponding subset of entries: a) single, where the target token is represented by a single word, and b) multiple, where the target token is represented by a group of words.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_21",
            "start": 0,
            "end": 239,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_21@1",
            "content": "While the single-word dataset contains 7,662 training entries, 421 trial entries, and 917 test entries, the multiword dataset has lower counts, with 1,517 training entries, 99 trial entries, and 184 for testing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_21",
            "start": 241,
            "end": 451,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_21@2",
            "content": "At the same time, the entries correspond to three different domains (i.e., biblical, biomedical, and political), therefore displaying different characteristics and challenging the models towards generalization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_21",
            "start": 453,
            "end": 662,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_22@0",
            "content": "The Complex Word Identification (CWI) Shared Dataset was introduced in the CWI Shared Task 2018 (Yimam et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_22",
            "start": 0,
            "end": 116,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_22@1",
            "content": "It is a multilingual dataset, containing entries in English, German, Spanish, and French.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_22",
            "start": 118,
            "end": 206,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_22@2",
            "content": "Moreover, the English entries are split into three categories, depending on their proficiency levels: professional (News), nonprofessional (WikiNews), and Wikipedia articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_22",
            "start": 208,
            "end": 381,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_22@3",
            "content": "Most entries are for the English language (27,299 training and 3,328 validation), while the fewest training entries are for German (6,151 training and 795 validation).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_22",
            "start": 383,
            "end": 549,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_22@4",
            "content": "The French language does not contain training or validation entries.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_22",
            "start": 551,
            "end": 618,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_23@0",
            "content": "The Domain Adaption Model",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_23",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_24@0",
            "content": "The overarching architecture of our method is introduced in Figure 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_24",
            "start": 0,
            "end": 68,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_24@1",
            "content": "All underlying components are presented in detail in the following subsections.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_24",
            "start": 70,
            "end": 148,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_24@2",
            "content": "Our model combines character-level BiLSTM features (i.e., F t ) with Transformer-based features for the context sentence (i.e., F c ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_24",
            "start": 150,
            "end": 283,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_24@3",
            "content": "The concatenated features (F c +F t ) are then passed through three linear layers, with a dropout separating the first and second.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_24",
            "start": 285,
            "end": 414,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_24@4",
            "content": "The output is a value representing the complexity of the target word.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_24",
            "start": 416,
            "end": 484,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_25@0",
            "content": "Three configurations were experimented.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_25",
            "start": 0,
            "end": 38,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_25@1",
            "content": "Within Basic Domain Adaptation, the previous features are passed through an additional component, the domain discriminator, composed of a linear layer followed by a softmax activation function.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_25",
            "start": 40,
            "end": 232,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_25@2",
            "content": "A gradient reversal layer is added between the feature concatenation and the discriminator to reverse the gradients through the backpropagation phase and support extracting general features.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_25",
            "start": 234,
            "end": 423,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_25@3",
            "content": "The loss function is determined by Equation 1 as:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_25",
            "start": 425,
            "end": 473,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_26@0",
            "content": "L = L r \u2212 \u03b2\u03bbL d (1)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_26",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_27@0",
            "content": "where L r is the regression loss, L d is the general domain loss, \u03b2 is a hyperparameter used for controlling the importance of L d , and \u03bb is another hyperparameter that varies as the training process progresses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_27",
            "start": 0,
            "end": 211,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_28@0",
            "content": "The following setups also include the Basic Domain Adaptation training setup.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_28",
            "start": 0,
            "end": 76,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_29@0",
            "content": "VAE and Domain Adaptation considers the previous configuration, plus the VAE encoder, that yields the F v features, and the VAE decoder, which aims to reconstruct the input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_29",
            "start": 0,
            "end": 172,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_29@1",
            "content": "The concatenation layer now contains the BiLSTM and Transformer features, plus the VAE encoder features (F v ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_29",
            "start": 174,
            "end": 284,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_29@2",
            "content": "The loss function is depicted by Equation 2 as:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_29",
            "start": 286,
            "end": 332,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_30@0",
            "content": "L = L r \u2212 \u03b2\u03bbL d + \u03b1L v (2)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_30",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_31@0",
            "content": "where, additionally, L v represents the VAE loss described in Equation 6.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_31",
            "start": 0,
            "end": 72,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_32@0",
            "content": "Transformer Decoder and Domain Adaptation adds a Transformer Decoder with the purpose of reconstructing the original input, for a more robust context feature extraction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_32",
            "start": 0,
            "end": 168,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_32@1",
            "content": "The loss is denoted by Equation 3 as:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_32",
            "start": 170,
            "end": 206,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_33@0",
            "content": "L = L r \u2212 \u03b2\u03bbL d + \u03b1L dec (3)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_33",
            "start": 0,
            "end": 27,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_34@0",
            "content": "where L dec represents the decoder loss described in Equation 9.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_34",
            "start": 0,
            "end": 63,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_35@0",
            "content": "Character-level BiLSTM for Target Word Representation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_35",
            "start": 0,
            "end": 52,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_36@0",
            "content": "The purpose of this component is to determine the complexity of the target token, given only its constituent characters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_36",
            "start": 0,
            "end": 119,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_36@1",
            "content": "A character-level Bidirectional Long Short-Term Memory (BiLSTM) network receives as input an array of characters corresponding to the target word (or group of words), and yields a representation that is afterwards concatenated to the previously mentioned Transformer-based representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_36",
            "start": 121,
            "end": 409,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_36@2",
            "content": "Each character c is mapped to a certain value obtained from the character vocabulary V, containing all the characters present in the input dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_36",
            "start": 411,
            "end": 557,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_37@0",
            "content": "The character sequence is represented as",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_37",
            "start": 0,
            "end": 39,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_38@0",
            "content": "C i = [c 1 , c 2 , . . . , c n ],",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_38",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_39@0",
            "content": "where n is the maximum length of a target token.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_39",
            "start": 0,
            "end": 47,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_39@1",
            "content": "C i is then passed through a character embedding layer, thus yielding the output Emb target .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_39",
            "start": 49,
            "end": 141,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_39@2",
            "content": "Emb target is then fed to the BiLSTM, followed by a dropout layer, thus obtaining the final target word representation, F t .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_39",
            "start": 143,
            "end": 267,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_40@0",
            "content": "Transformer-based Context Representation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_40",
            "start": 0,
            "end": 39,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_41@0",
            "content": "We rely on a Transformer-based model as the main feature extractor for the context of the target word (i.e., the full sentence), considering their superior performance on most NLP tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_41",
            "start": 0,
            "end": 185,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_41@1",
            "content": "The selected model for the first dataset is RoBERTa (Liu et al., 2019), inasmuch as it yields better results when compared to its counterpart, BERT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_41",
            "start": 187,
            "end": 334,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_41@2",
            "content": "RoBERTa is trained with higher learning rates and larger minibatches, as well as it modifies the key hyperparameters of BERT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_41",
            "start": 336,
            "end": 460,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_41@3",
            "content": "We employed the usage of XLM-RoBERTa (Conneau et al., 2020), the multilingual counterpart of RoBERTa, now trained on a very large corpus of multilingual texts, for the second cross-lingual task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_41",
            "start": 462,
            "end": 655,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_42@0",
            "content": "The features used for our task are represented by the pooled output of the Transformer model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_42",
            "start": 0,
            "end": 92,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_42@1",
            "content": "The feature vector F c of 768 elements captures information about the context of the target word.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_42",
            "start": 94,
            "end": 190,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_43@0",
            "content": "Variational AutoEncoders",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_43",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_44@0",
            "content": "We aim to further improve performance by adding extra features via Variational AutoEncoders (VAEs) (Kingma and Welling, 2013) to the context representation for a target word.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_44",
            "start": 0,
            "end": 173,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_44@1",
            "content": "More specifically for the CWI task, we use the latent vector z, alongside the Transformer and the Char BiLSTM features.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_44",
            "start": 175,
            "end": 293,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_44@2",
            "content": "Moreover, we also need to ensure that the Encoder representation is accurate; therefore, we consider the VAE encoding and decoding as an additional task having the purpose of minimizing the reconstruction loss.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_44",
            "start": 295,
            "end": 504,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_45@0",
            "content": "The VAE consists of two parts, namely the encoder and the decoder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_45",
            "start": 0,
            "end": 65,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_45@1",
            "content": "The encoder g(x) produces the approximation q(z|x) of the posterior distribution p(z|x), thus mapping the input x to the latent space z. The process is presented in Equation 4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_45",
            "start": 67,
            "end": 242,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_45@2",
            "content": "We use as features the representation z, denoted as",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_45",
            "start": 244,
            "end": 294,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_46@0",
            "content": "F v . p(z|x) \u2248 q(z|x) = N (\u00b5(x), \u03c3(x))(4)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_46",
            "start": 0,
            "end": 40,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_47@0",
            "content": "The decoder f(z) maps the latent space to the input space (i.e., p(z) to p(x)), by using Equation 5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_47",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_47@1",
            "content": "Furthermore, E q represents the expectation with relation to the distribution q.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_47",
            "start": 101,
            "end": 180,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_48@0",
            "content": "L(f, g) = i {\u2212D KL [q(z|x i )||p(z)] + E q(z|x i ) [lnp(x i |z)]} (6)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_48",
            "start": 0,
            "end": 68,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_49@0",
            "content": "Discriminators",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_49",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_50@0",
            "content": "The features extracted by our architecture can vary greatly as the input entries can originate from different domains or languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_50",
            "start": 0,
            "end": 130,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_50@1",
            "content": "Consequently, we were introduced a generalization technique to extract only cross-domain features that do not present a bias towards a certain domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_50",
            "start": 132,
            "end": 281,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_50@2",
            "content": "We thus employ an adversarial training technique based on domain adaptation, forcing the model to only extract relevant cross-domain features.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_50",
            "start": 283,
            "end": 424,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_51@0",
            "content": "A discriminator acts as a classifier, containing three linear layers with corresponding activation functions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_51",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_51@1",
            "content": "The discriminator classifies the input sentence into one of the available domains.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_51",
            "start": 110,
            "end": 191,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_51@2",
            "content": "Unlike traditional classification approaches, our purpose is not to minimize the loss, but to maximize it.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_51",
            "start": 193,
            "end": 298,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_51@3",
            "content": "We want our model to become incapable of distinguishing between different categories of input entries, therefore extracting the most relevant, cross-domain features.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_51",
            "start": 300,
            "end": 464,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_52@0",
            "content": "Our architecture is encouraged to generalize in terms of extracted features by the gradient reversal layer that reverses the gradients during the backpropagation phase; as such, the parameters are updated towards the direction that maximizes the loss instead of minimizing it.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_52",
            "start": 0,
            "end": 275,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_53@0",
            "content": "Three scenarios were considered, each one targeting a different approach towards domain adaptation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_53",
            "start": 0,
            "end": 98,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_54@0",
            "content": "Domain Discriminator.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_54",
            "start": 0,
            "end": 20,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_54@1",
            "content": "The first scenario is applied on the first dataset, CompLex, with entries only in English, but covering multiple domains.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_54",
            "start": 22,
            "end": 142,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_54@2",
            "content": "The discriminator has the purpose of identifying the domain of the entry, namely biblical, biomedical or political.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_54",
            "start": 144,
            "end": 258,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_54@3",
            "content": "The intuition is that, by grasping only cross-domain features, the performance of the model increases on all three domains, instead of performing well only on one, while poorer on the others.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_54",
            "start": 260,
            "end": 450,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_55@0",
            "content": "Language Discriminator.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_55",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_55@1",
            "content": "The intuition is similar to the previous scenario, except that we experimented with the second multilingual dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_55",
            "start": 24,
            "end": 139,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_55@2",
            "content": "Therefore, our interest was that our model extracts cross-lingual features, such that the performance is equal on all the target languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_55",
            "start": 141,
            "end": 279,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_56@0",
            "content": "Task Discriminator.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_56",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_56@1",
            "content": "In this scenario, we trained a similar, auxiliary task, represented by text simplification.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_56",
            "start": 20,
            "end": 110,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_56@2",
            "content": "A task discriminator is implemented to detect the origin of the input entry: either the main task or the auxiliary task (i.e., simplified version).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_56",
            "start": 112,
            "end": 258,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_56@3",
            "content": "The dataset used for text simplification is represented by BenchLS (Paetzold and Specia, 2016) 1 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_56",
            "start": 260,
            "end": 357,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_56@4",
            "content": "The employed simplification process consists of masking the word considered to be complex and then using a Transformer for Masked Language Modeling to predict the best candidate.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_56",
            "start": 359,
            "end": 536,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_56@5",
            "content": "The corresponding flow is described in algorithm 1, while the loss function is presented in Equation 7.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_56",
            "start": 538,
            "end": 640,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_57@0",
            "content": "L = L r \u2212 \u03b2\u03bbL task_id + L M L (7)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_57",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_58@0",
            "content": "where L ML is the Sparse Categorical Cross Entropy loss.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_58",
            "start": 0,
            "end": 55,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_59@0",
            "content": "Algorithm 1: The Multi-Task Adversarial algorithm (Task 1 -lexical complexity prediction; Task 2 -text simplification).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_59",
            "start": 0,
            "end": 118,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_60@0",
            "content": "1 Inputs: Preprocessed dataset, split into batches (x i , y i ), i=1,n (where n is the number of batches, x i are the input features for the target word and the context, and y i is the complexity); 2 Outputs: Updated parameters \u03b8 p ; 3 Initialization: initialize \u03b8 p with random weights; 4 for every batch do All previous discriminators use the same loss, namely Categorical Cross Entropy (Zhang and Sabuncu, 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_60",
            "start": 0,
            "end": 414,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_61@0",
            "content": "The overall loss consists of the difference between the task loss and the domain/language loss.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_61",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_61@1",
            "content": "Moreover, the importance of the latter can be controlled by multiplication with a \u03bb hyperparameter, that changes over time, and a fixed \u03b2 hyperparameter.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_61",
            "start": 96,
            "end": 248,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_61@2",
            "content": "The network parameters, \u03b8 p are updated according to Equation 8, where \u03b7 is the learning rate, L d is the domain loss, L r is the task loss and \u03b2 is the weight for the domain loss.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_61",
            "start": 250,
            "end": 429,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_61@3",
            "content": "A similar equation for language loss (L l ) is in place for the second dataset, where instead of the domain loss L d we used the language identification loss L l , having the same formula.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_61",
            "start": 431,
            "end": 618,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_62@0",
            "content": "\u03b8 p = \u03b8 p \u2212 \u03b7( \u2202L r \u2202\u03b8 p \u2212 \u03b2\u03bb \u2202L d \u2202\u03b8 p ) (8)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_62",
            "start": 0,
            "end": 44,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_63@0",
            "content": "Transformer Decoder",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_63",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_64@0",
            "content": "Our model also considers a decoder to reconstruct the original input, starting from the Transformer representation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_64",
            "start": 0,
            "end": 114,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_64@1",
            "content": "The intuition behind introducing this decoder is to increase the robustness of the context feature extraction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_64",
            "start": 116,
            "end": 225,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_65@0",
            "content": "The decoder receives as input the outputs of the hidden Transformer layer alongside an embedding of the original input, which are passed through a Gated Recurrent Unit (GRU) (Chung et al., 2014) layer for obtaining the final representation of the initial input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_65",
            "start": 0,
            "end": 260,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_65@1",
            "content": "Additionally, two linear layers separated by a dropout are introduced before obtaining the final representation, y = F d .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_65",
            "start": 262,
            "end": 383,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_65@2",
            "content": "The loss is computed by using the Negative Log Likelihood loss between the outputs of the decoder and the original Transformer input id representation of the entries (see Equations 9 and 10).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_65",
            "start": 385,
            "end": 575,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_66@0",
            "content": "L(x, y) = N n=1 l n (9) l n = \u2212w yn x n,yn , w c = weight[c] \u2022 1, {c = index, c = ignore_index} (10)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_66",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_67@0",
            "content": "Experimental Setup",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_67",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_68@0",
            "content": "The optimizer used for our models is represented by AdamW (Kingma and Ba, 2014).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_68",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_68@1",
            "content": "The learning rate is set to 2e-5, while the loss functions used for the complexity task are the L1 loss (Janocha and Czarnecki, 2017) for the first dataset and the Mean Squared Error (MSE) loss (Kline and Berardi, 2005) for the second one.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_68",
            "start": 81,
            "end": 319,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_68@2",
            "content": "The auxiliary losses are summed to the main loss (i.e., complexity prediction) and are scaled according to their priority, with a factor of \u03b1, where \u03b1 is set to 0.1 for the VAE loss, and 0.01 for the Transformer decoder and task discriminator losses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_68",
            "start": 321,
            "end": 570,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_68@3",
            "content": "The \u03bb parameter used for domain adaptation was updated according to Equation 11.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_68",
            "start": 572,
            "end": 651,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_69@0",
            "content": "\u03bb = 2 1 + e \u2212\u03b3e \u2212 1 (11",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_69",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_70@0",
            "content": ")",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_70",
            "start": 0,
            "end": 0,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_71@0",
            "content": "where e is the number of epochs the model was trained; \u03b3 was set to 0.1, while \u03b2 was set to 0.2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_71",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_71@1",
            "content": "Moreover, each model was trained for 8 epochs, except for the one including the VAE features, which was trained for 12 epochs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_71",
            "start": 97,
            "end": 222,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_72@0",
            "content": "Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_72",
            "start": 0,
            "end": 6,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_73@0",
            "content": "LCP 2021 CompLex Dataset",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_73",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_74@0",
            "content": "We consider as baselines two models used for the LCP 2021 competition (Shardlow et al., 2021a), as well as the best-registered score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_74",
            "start": 0,
            "end": 132,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_74@1",
            "content": "de Almeida et al. ( 2021) employed the usage of neural network solutions; more specifically, they used chunks of the sentences obtained with Sent2Vec as input features.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_74",
            "start": 134,
            "end": 301,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_74@2",
            "content": "Zaharia et al. (2021) created models that are based on target and context feature extractors, alongside features resulted from Graph Convolutional Networks, Capsule Networks, or pre-trained word embeddings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_74",
            "start": 303,
            "end": 508,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_74@3",
            "content": "Table 1 depicts the results obtained for the English dataset using domain adaptation and various configurations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_74",
            "start": 510,
            "end": 621,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_74@4",
            "content": "\"Base\" denotes the initial model (RoBERTa + Char BiLSTM) on which we apply domain adaptation, as well as the auxiliary tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_74",
            "start": 623,
            "end": 747,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_74@5",
            "content": "The domain adaptation technique offers improved performance when applied on top of an architecture, considering that the model learns cross-domain features.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_74",
            "start": 749,
            "end": 904,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_74@6",
            "content": "The only exception is represented by a slightly lower Pearson score on the model that uses domain adaptation alongside the Transformer decoding auxiliary task (Base + Decoder + DA), with a value of .7969 on the trial dataset, when compared to the initial 0.7987 (Base).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_74",
            "start": 906,
            "end": 1174,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_74@7",
            "content": "However, the remaining models improve upon the starting architecture, with the largest improvements being observed for domain adaptation and the text simplification auxiliary task (Base + Text simplification + DA), with a Pearson correlation coefficient on the test dataset of .7744, 2.42% better than the base model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_74",
            "start": 1176,
            "end": 1492,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_74@8",
            "content": "The improved performance can be also seen for the Mean Absolute Error score (MAE = .0652).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_74",
            "start": 1494,
            "end": 1583,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_75@0",
            "content": "While the Transformer decoder auxiliary task does not offer the best performance for the single word dataset, the same architecture offers the second-best performance for the multiple word dataset, with a Pearson score of .8252 compared to the best one, .8285.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_75",
            "start": 0,
            "end": 259,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_76@0",
            "content": "The domain adaptation and VAE configuration provide improvements upon the base model (.7554 versus .7502 Pearson), but the VAE does not have an important contribution, considering that the Base + domain adaptation model has a slightly higher Pearson score of .7569.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_76",
            "start": 0,
            "end": 264,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_77@0",
            "content": "CWI 2018 Dataset",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_77",
            "start": 0,
            "end": 15,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_78@0",
            "content": "We also experimented with a multilingual dataset, where the discriminant is considered to be the lan- guage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_78",
            "start": 0,
            "end": 107,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_78@1",
            "content": "The baseline consists of three models used from the CWI 2018 competition.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_78",
            "start": 109,
            "end": 181,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_78@2",
            "content": "The performance is evaluated in terms of MAE; However, we also report the Pearson Correlation Coefficient.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_78",
            "start": 183,
            "end": 288,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_78@3",
            "content": "First, Kajiwara and Komachi (2018) based their models on regressors, alongside features represented by the number of characters or words and the frequency of the target word in certain corpora.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_78",
            "start": 290,
            "end": 482,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_78@4",
            "content": "Second, the approach of Bingel and Bjerva (2018)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_78",
            "start": 484,
            "end": 531,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_79@0",
            "content": "Discussions",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_79",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_80@0",
            "content": "The domain adaptation technique supports our model to learn general cross-domain (or cross-language) features, while achieving higher performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_80",
            "start": 0,
            "end": 145,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_80@1",
            "content": "Moreover, jointly training on two different tasks (i.e., lexical complexity prediction and text simplification), coupled with domain adaptation to generalize the features from the two tasks, can lead to improved results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_80",
            "start": 147,
            "end": 366,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_81@0",
            "content": "However, there are entries for which our models were unable to properly predict the complexity score, namely: a) entries with a different level of complexity (i.e. biomedical), and b) entries part of a language that was not present in the training dataset (i.e., French).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_81",
            "start": 0,
            "end": 270,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_82@0",
            "content": "For the former, scientific terms (e.g., \"sitosterolemia\"), abbreviations (e.g., \"ES\"), or complex elements (e.g., \" H3-2meK9\") impose a series of difficulties for our feature extractors, considering the absence of these tokens from the Transformer vocabulary.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_82",
            "start": 0,
            "end": 258,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_83@0",
            "content": "The latter category of problematic entries creates new challenges in the sense that it represents a completely new language on which the architecture is tested.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_83",
            "start": 0,
            "end": 159,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_83@1",
            "content": "However, as seen in the results section, the cross-lingual domain adaptation technique offers good improvements, helping the model achieve better performance on French, even though the initial architecture was not exposed to any French example.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_83",
            "start": 161,
            "end": 404,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_84@0",
            "content": "Conclusion and Future Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_84",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_85@0",
            "content": "This work proposes a series of training techniques, including adversarial domain adaptation, as well as multi-task learning, that can be used for improving the overall performance of the models for CWI.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_85",
            "start": 0,
            "end": 201,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_85@1",
            "content": "Domain adaptation improves results by encouraging the models to extract more general features, that can be further used for the lexical complexity prediction task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_85",
            "start": 203,
            "end": 365,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_86@0",
            "content": "Moreover, by jointly training the model on the CWI taks and an auxiliary similar task (i.e., text simplification), the overall performance is improved.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_86",
            "start": 0,
            "end": 150,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_86@1",
            "content": "The task discriminator also ensures the extraction of general features, thus making the model more robust on the CWI task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_86",
            "start": 152,
            "end": 273,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_87@0",
            "content": "For future work, we intend to experiment with meta learning (Finn et al., 2017) alongside domain adaptation (Wang et al., 2019), considering the scope of the previously applied training techniques.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_87",
            "start": 0,
            "end": 196,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_87@1",
            "content": "This would enable us to initialize the model's weights in the best manner, thus ensuring optimal results during the training phase.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_87",
            "start": 198,
            "end": 328,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_88@0",
            "content": "Joachim Bingel, Johannes Bjerva, Crosslingual complex word identification with multitask learning, 2018, Proceedings of the thirteenth workshop on innovative use of NLP for building educational applications, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_88",
            "start": 0,
            "end": 208,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_89@0",
            "content": "UNKNOWN, None, 2018, Adversarial deep averaging networks for cross-lingual sentiment classification, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_89",
            "start": 0,
            "end": 101,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_90@0",
            "content": "UNKNOWN, None, 2014, Empirical evaluation of gated recurrent neural networks on sequence modeling, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_90",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_91@0",
            "content": "Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, \u00c9douard Grave, Myle Ott, Luke Zettlemoyer, Veselin Stoyanov, Unsupervised cross-lingual representation learning at scale, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_91",
            "start": 0,
            "end": 322,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_92@0",
            "content": "Erenay Dayanik, Sebastian Pad\u00f3, Masking actor information leads to fairer political claims detection, 2020, Proceedings of the 58th Annual Meeting of the Association for Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_92",
            "start": 0,
            "end": 183,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_93@0",
            "content": "UNKNOWN, None, 2021, C3sl at semeval-2021 task 1: Predicting lexical complexity of words in specific contexts with sentence embeddings, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_93",
            "start": 0,
            "end": 136,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_94@0",
            "content": "Dirk De Hertog, Ana\u00efs Tack, Deep learning architecture for complex word identification, 2018, Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_94",
            "start": 0,
            "end": 197,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_95@0",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, Bert: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_95",
            "start": 0,
            "end": 294,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_96@0",
            "content": "Chunning Du, Haifeng Sun, Jingyu Wang, Qi Qi, Jianxin Liao, Adversarial and domain-aware bert for cross-domain sentiment analysis, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_96",
            "start": 0,
            "end": 226,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_97@0",
            "content": "UNKNOWN, None, 2020, A brief review of domain adaptation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_97",
            "start": 0,
            "end": 58,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_98@0",
            "content": "Chelsea Finn, Pieter Abbeel, Sergey Levine, Model-agnostic meta-learning for fast adaptation of deep networks, 2017, Proceedings of the 34th International Conference on Machine Learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_98",
            "start": 0,
            "end": 187,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_99@0",
            "content": "Pierre Finnimore, Elisabeth Fritzsch, Daniel King, Alison Sneyd, Aneeq Ur Rehman, Fernando Alva-Manchego, Andreas Vlachos, Strong baselines for complex word identification across multiple languages, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_99",
            "start": 0,
            "end": 349,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_100@0",
            "content": "Sian Gooding, Ekaterina Kochmar, Camb at cwi shared task 2018: Complex word identification with ensemble-based voting, 2018, Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_100",
            "start": 0,
            "end": 228,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_101@0",
            "content": "Sian Gooding, Ekaterina Kochmar, Complex word identification as a sequence labelling task, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_101",
            "start": 0,
            "end": 186,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_102@0",
            "content": "Sepp Hochreiter, J\u00fcrgen Schmidhuber, Long short-term memory, 1997, Neural computation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_102",
            "start": 0,
            "end": 87,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_103@0",
            "content": "Lifu Huang, Ji Heng, Jonathan , Crosslingual multi-level adversarial transfer to enhance low-resource name tagging, 2019-05, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_103",
            "start": 0,
            "end": 269,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_104@0",
            "content": "UNKNOWN, None, 2017, On loss functions for deep neural networks in classification, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_104",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_105@0",
            "content": "Tomoyuki Kajiwara, Mamoru Komachi, Complex word identification based on frequency in a learner corpus, 2018, Proceedings of the thirteenth workshop on innovative use of NLP for building educational applications, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_105",
            "start": 0,
            "end": 212,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_106@0",
            "content": "Phillip Keung, Vikas Bhardwaj, Adversarial learning with contextual embeddings for zeroresource cross-lingual classification and ner, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_106",
            "start": 0,
            "end": 317,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_107@0",
            "content": "Joo-Kyung Kim, Young-Bum Kim, Ruhi Sarikaya, Eric Fosler-Lussier, Cross-lingual transfer learning for pos tagging without cross-lingual resources, 2017, Proceedings of the 2017 conference on empirical methods in natural language processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_107",
            "start": 0,
            "end": 241,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_108@0",
            "content": "UNKNOWN, None, 2014, Adam: A method for stochastic optimization, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_108",
            "start": 0,
            "end": 65,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_109@0",
            "content": "UNKNOWN, None, 2013, Autoencoding variational bayes, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_109",
            "start": 0,
            "end": 53,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_110@0",
            "content": "Mateusz Klimaszewski, Piotr Andruszkiewicz, Wut at semeval-2019 task 9: Domainadversarial neural networks for domain adaptation in suggestion mining, 2019, Proceedings of the 13th International Workshop on Semantic Evaluation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_110",
            "start": 0,
            "end": 227,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_111@0",
            "content": "M Douglas,  Kline, L Victor,  Berardi, Revisiting squared-error and cross-entropy functions for training neural network classifiers, 2005, Neural Computing & Applications, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_111",
            "start": 0,
            "end": 172,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_112@0",
            "content": "Ludmila I Kuncheva, C James, Robert Pw Bezdek,  Duin, Decision templates for multiple classifier fusion: an experimental comparison, 2001, Pattern recognition, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_112",
            "start": 0,
            "end": 160,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_113@0",
            "content": "UNKNOWN, None, 2019, Roberta: A robustly optimized bert pretraining approach, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_113",
            "start": 0,
            "end": 78,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_114@0",
            "content": "Mounica Maddela, Wei Xu, A wordcomplexity lexicon and a neural readability ranking model for lexical simplification, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_114",
            "start": 0,
            "end": 211,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_115@0",
            "content": "Robert Mchardy, Heike Adel, Roman Klinger, Adversarial training for satire detection: Controlling for confounding variables, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_115",
            "start": 0,
            "end": 275,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_116@0",
            "content": "UNKNOWN, None, 2016, BenchLS: A Reliable Dataset for Lexical Simplification, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_116",
            "start": 0,
            "end": 77,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_117@0",
            "content": "Telmo Pires, Eva Schlinger, Dan Garrette, How multilingual is multilingual bert?, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_117",
            "start": 0,
            "end": 177,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_118@0",
            "content": "UNKNOWN, None, 2006, Ensemble based systems in decision making. IEEE Circuits and systems magazine, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_118",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_119@0",
            "content": "UNKNOWN, None, 2021, Improved multi-source domain adaptation by preservation of factors. Image and Vision Computing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_119",
            "start": 0,
            "end": 117,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_120@0",
            "content": "Matthew Shardlow, Richard Evans, Gustavo Paetzold, Marcos Zampieri, Semeval-2021 task 1: Lexical complexity prediction, 2021, Proceedings of the 14th International Workshop on Semantic Evaluation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_120",
            "start": 0,
            "end": 197,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_121@0",
            "content": "UNKNOWN, None, 2021, Predicting lexical complexity in english texts, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_121",
            "start": 0,
            "end": 69,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_122@0",
            "content": "Matthew Shardlow, Marcos Zampieri, Michael Cooper, Complex-a new corpus for lexical complexity predicition from likertscale data, 2020, Proceedings of the 1st Workshop on Tools and Resources to Empower People with REAding DIfficulties (READI), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_122",
            "start": 0,
            "end": 244,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_123@0",
            "content": "Yuhua Tang, Zhipeng Lin, Haotian Wang, Liyang Xu, Adversarial mixup synthesis training for unsupervised domain adaptation, 2020, ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), IEEE.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_123",
            "start": 0,
            "end": 233,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_124@0",
            "content": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Attention is all you need, 2017, Proceedings of the 31st International Conference on Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_124",
            "start": 0,
            "end": 243,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_125@0",
            "content": "Giorgos Vernikos, Katerina Margatina, Alexandra Chronopoulou, Ion Androutsopoulos, Domain adversarial fine-tuning as an effective regularizer, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_125",
            "start": 0,
            "end": 247,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_126@0",
            "content": "Ke Wang, Gong Zhang, Henry Leung, Sar target recognition based on cross-domain and crosstask transfer learning, 2019, IEEE Access, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_126",
            "start": 0,
            "end": 131,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_127@0",
            "content": "Chris Seid Muhie Yimam, Shervin Biemann, Gustavo Malmasi, Lucia Paetzold, Sanja Specia,  \u0160tajner, A report on the complex word identification shared task, 2018, Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_127",
            "start": 0,
            "end": 264,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_128@0",
            "content": "George-Eduard Zaharia, Dumitru-Clementin Cercel, Mihai Dascalu, Cross-lingual transfer learning for complex word identification, 2020, 2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI), IEEE.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_128",
            "start": 0,
            "end": 226,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_129@0",
            "content": "UNKNOWN, None, 2021, Upb at semeval-2021 task 1: Combining deep learning and hand-crafted features for lexical complexity prediction, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_129",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_130@0",
            "content": "Dejiao Zhang, Ramesh Nallapati, Henghui Zhu, Feng Nan, Kathleen Cicero Dos Santos, Bing Mckeown,  Xiang, Unsupervised domain adaptation for cross-lingual text labeling, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_130",
            "start": 0,
            "end": 273,
            "label": {}
        },
        {
            "ix": "412-ARR_v1_131@0",
            "content": "Zhilu Zhang, R Mert,  Sabuncu, Generalized cross entropy loss for training deep neural networks with noisy labels, 2018, Proceedings of the 32nd International Conference on Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "412-ARR_v1_131",
            "start": 0,
            "end": 212,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "412-ARR_v1_0",
            "tgt_ix": "412-ARR_v1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_0",
            "tgt_ix": "412-ARR_v1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_1",
            "tgt_ix": "412-ARR_v1_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_1",
            "tgt_ix": "412-ARR_v1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_0",
            "tgt_ix": "412-ARR_v1_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_2",
            "tgt_ix": "412-ARR_v1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_4",
            "tgt_ix": "412-ARR_v1_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_5",
            "tgt_ix": "412-ARR_v1_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_6",
            "tgt_ix": "412-ARR_v1_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_7",
            "tgt_ix": "412-ARR_v1_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_8",
            "tgt_ix": "412-ARR_v1_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_3",
            "tgt_ix": "412-ARR_v1_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_3",
            "tgt_ix": "412-ARR_v1_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_3",
            "tgt_ix": "412-ARR_v1_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_3",
            "tgt_ix": "412-ARR_v1_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_3",
            "tgt_ix": "412-ARR_v1_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_3",
            "tgt_ix": "412-ARR_v1_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_3",
            "tgt_ix": "412-ARR_v1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_0",
            "tgt_ix": "412-ARR_v1_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_11",
            "tgt_ix": "412-ARR_v1_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_12",
            "tgt_ix": "412-ARR_v1_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_13",
            "tgt_ix": "412-ARR_v1_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_14",
            "tgt_ix": "412-ARR_v1_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_15",
            "tgt_ix": "412-ARR_v1_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_16",
            "tgt_ix": "412-ARR_v1_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_10",
            "tgt_ix": "412-ARR_v1_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_10",
            "tgt_ix": "412-ARR_v1_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_10",
            "tgt_ix": "412-ARR_v1_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_10",
            "tgt_ix": "412-ARR_v1_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_10",
            "tgt_ix": "412-ARR_v1_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_10",
            "tgt_ix": "412-ARR_v1_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_10",
            "tgt_ix": "412-ARR_v1_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_10",
            "tgt_ix": "412-ARR_v1_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_0",
            "tgt_ix": "412-ARR_v1_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_17",
            "tgt_ix": "412-ARR_v1_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_18",
            "tgt_ix": "412-ARR_v1_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_18",
            "tgt_ix": "412-ARR_v1_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_20",
            "tgt_ix": "412-ARR_v1_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_21",
            "tgt_ix": "412-ARR_v1_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_19",
            "tgt_ix": "412-ARR_v1_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_19",
            "tgt_ix": "412-ARR_v1_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_19",
            "tgt_ix": "412-ARR_v1_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_19",
            "tgt_ix": "412-ARR_v1_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_18",
            "tgt_ix": "412-ARR_v1_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_22",
            "tgt_ix": "412-ARR_v1_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_24",
            "tgt_ix": "412-ARR_v1_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_25",
            "tgt_ix": "412-ARR_v1_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_26",
            "tgt_ix": "412-ARR_v1_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_27",
            "tgt_ix": "412-ARR_v1_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_28",
            "tgt_ix": "412-ARR_v1_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_29",
            "tgt_ix": "412-ARR_v1_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_30",
            "tgt_ix": "412-ARR_v1_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_31",
            "tgt_ix": "412-ARR_v1_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_32",
            "tgt_ix": "412-ARR_v1_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_33",
            "tgt_ix": "412-ARR_v1_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_23",
            "tgt_ix": "412-ARR_v1_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_23",
            "tgt_ix": "412-ARR_v1_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_23",
            "tgt_ix": "412-ARR_v1_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_23",
            "tgt_ix": "412-ARR_v1_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_23",
            "tgt_ix": "412-ARR_v1_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_23",
            "tgt_ix": "412-ARR_v1_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_23",
            "tgt_ix": "412-ARR_v1_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_23",
            "tgt_ix": "412-ARR_v1_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_23",
            "tgt_ix": "412-ARR_v1_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_23",
            "tgt_ix": "412-ARR_v1_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_23",
            "tgt_ix": "412-ARR_v1_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_23",
            "tgt_ix": "412-ARR_v1_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_18",
            "tgt_ix": "412-ARR_v1_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_34",
            "tgt_ix": "412-ARR_v1_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_36",
            "tgt_ix": "412-ARR_v1_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_37",
            "tgt_ix": "412-ARR_v1_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_38",
            "tgt_ix": "412-ARR_v1_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_35",
            "tgt_ix": "412-ARR_v1_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_35",
            "tgt_ix": "412-ARR_v1_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_35",
            "tgt_ix": "412-ARR_v1_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_35",
            "tgt_ix": "412-ARR_v1_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_35",
            "tgt_ix": "412-ARR_v1_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_18",
            "tgt_ix": "412-ARR_v1_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_39",
            "tgt_ix": "412-ARR_v1_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_41",
            "tgt_ix": "412-ARR_v1_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_40",
            "tgt_ix": "412-ARR_v1_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_40",
            "tgt_ix": "412-ARR_v1_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_40",
            "tgt_ix": "412-ARR_v1_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_18",
            "tgt_ix": "412-ARR_v1_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_42",
            "tgt_ix": "412-ARR_v1_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_44",
            "tgt_ix": "412-ARR_v1_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_45",
            "tgt_ix": "412-ARR_v1_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_46",
            "tgt_ix": "412-ARR_v1_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_47",
            "tgt_ix": "412-ARR_v1_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_43",
            "tgt_ix": "412-ARR_v1_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_43",
            "tgt_ix": "412-ARR_v1_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_43",
            "tgt_ix": "412-ARR_v1_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_43",
            "tgt_ix": "412-ARR_v1_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_43",
            "tgt_ix": "412-ARR_v1_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_43",
            "tgt_ix": "412-ARR_v1_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_18",
            "tgt_ix": "412-ARR_v1_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_48",
            "tgt_ix": "412-ARR_v1_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_50",
            "tgt_ix": "412-ARR_v1_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_51",
            "tgt_ix": "412-ARR_v1_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_52",
            "tgt_ix": "412-ARR_v1_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_53",
            "tgt_ix": "412-ARR_v1_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_54",
            "tgt_ix": "412-ARR_v1_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_55",
            "tgt_ix": "412-ARR_v1_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_56",
            "tgt_ix": "412-ARR_v1_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_57",
            "tgt_ix": "412-ARR_v1_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_58",
            "tgt_ix": "412-ARR_v1_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_59",
            "tgt_ix": "412-ARR_v1_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_60",
            "tgt_ix": "412-ARR_v1_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_61",
            "tgt_ix": "412-ARR_v1_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_49",
            "tgt_ix": "412-ARR_v1_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_49",
            "tgt_ix": "412-ARR_v1_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_49",
            "tgt_ix": "412-ARR_v1_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_49",
            "tgt_ix": "412-ARR_v1_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_49",
            "tgt_ix": "412-ARR_v1_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_49",
            "tgt_ix": "412-ARR_v1_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_49",
            "tgt_ix": "412-ARR_v1_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_49",
            "tgt_ix": "412-ARR_v1_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_49",
            "tgt_ix": "412-ARR_v1_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_49",
            "tgt_ix": "412-ARR_v1_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_49",
            "tgt_ix": "412-ARR_v1_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_49",
            "tgt_ix": "412-ARR_v1_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_49",
            "tgt_ix": "412-ARR_v1_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_49",
            "tgt_ix": "412-ARR_v1_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_18",
            "tgt_ix": "412-ARR_v1_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_62",
            "tgt_ix": "412-ARR_v1_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_64",
            "tgt_ix": "412-ARR_v1_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_65",
            "tgt_ix": "412-ARR_v1_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_63",
            "tgt_ix": "412-ARR_v1_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_63",
            "tgt_ix": "412-ARR_v1_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_63",
            "tgt_ix": "412-ARR_v1_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_63",
            "tgt_ix": "412-ARR_v1_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_18",
            "tgt_ix": "412-ARR_v1_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_66",
            "tgt_ix": "412-ARR_v1_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_68",
            "tgt_ix": "412-ARR_v1_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_69",
            "tgt_ix": "412-ARR_v1_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_70",
            "tgt_ix": "412-ARR_v1_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_67",
            "tgt_ix": "412-ARR_v1_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_67",
            "tgt_ix": "412-ARR_v1_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_67",
            "tgt_ix": "412-ARR_v1_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_67",
            "tgt_ix": "412-ARR_v1_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_67",
            "tgt_ix": "412-ARR_v1_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_0",
            "tgt_ix": "412-ARR_v1_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_71",
            "tgt_ix": "412-ARR_v1_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_72",
            "tgt_ix": "412-ARR_v1_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_72",
            "tgt_ix": "412-ARR_v1_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_74",
            "tgt_ix": "412-ARR_v1_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_75",
            "tgt_ix": "412-ARR_v1_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_73",
            "tgt_ix": "412-ARR_v1_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_73",
            "tgt_ix": "412-ARR_v1_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_73",
            "tgt_ix": "412-ARR_v1_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_73",
            "tgt_ix": "412-ARR_v1_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_72",
            "tgt_ix": "412-ARR_v1_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_76",
            "tgt_ix": "412-ARR_v1_77",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_77",
            "tgt_ix": "412-ARR_v1_78",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_77",
            "tgt_ix": "412-ARR_v1_78",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_0",
            "tgt_ix": "412-ARR_v1_79",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_78",
            "tgt_ix": "412-ARR_v1_79",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_80",
            "tgt_ix": "412-ARR_v1_81",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_81",
            "tgt_ix": "412-ARR_v1_82",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_82",
            "tgt_ix": "412-ARR_v1_83",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_79",
            "tgt_ix": "412-ARR_v1_80",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_79",
            "tgt_ix": "412-ARR_v1_81",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_79",
            "tgt_ix": "412-ARR_v1_82",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_79",
            "tgt_ix": "412-ARR_v1_83",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_79",
            "tgt_ix": "412-ARR_v1_80",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_0",
            "tgt_ix": "412-ARR_v1_84",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_83",
            "tgt_ix": "412-ARR_v1_84",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_85",
            "tgt_ix": "412-ARR_v1_86",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_86",
            "tgt_ix": "412-ARR_v1_87",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_84",
            "tgt_ix": "412-ARR_v1_85",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_84",
            "tgt_ix": "412-ARR_v1_86",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_84",
            "tgt_ix": "412-ARR_v1_87",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_84",
            "tgt_ix": "412-ARR_v1_85",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "412-ARR_v1_0",
            "tgt_ix": "412-ARR_v1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_1",
            "tgt_ix": "412-ARR_v1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_2",
            "tgt_ix": "412-ARR_v1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_2",
            "tgt_ix": "412-ARR_v1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_2",
            "tgt_ix": "412-ARR_v1_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_2",
            "tgt_ix": "412-ARR_v1_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_2",
            "tgt_ix": "412-ARR_v1_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_2",
            "tgt_ix": "412-ARR_v1_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_2",
            "tgt_ix": "412-ARR_v1_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_2",
            "tgt_ix": "412-ARR_v1_2@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_2",
            "tgt_ix": "412-ARR_v1_2@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_3",
            "tgt_ix": "412-ARR_v1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_4",
            "tgt_ix": "412-ARR_v1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_4",
            "tgt_ix": "412-ARR_v1_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_4",
            "tgt_ix": "412-ARR_v1_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_4",
            "tgt_ix": "412-ARR_v1_4@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_5",
            "tgt_ix": "412-ARR_v1_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_5",
            "tgt_ix": "412-ARR_v1_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_6",
            "tgt_ix": "412-ARR_v1_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_6",
            "tgt_ix": "412-ARR_v1_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_7",
            "tgt_ix": "412-ARR_v1_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_7",
            "tgt_ix": "412-ARR_v1_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_8",
            "tgt_ix": "412-ARR_v1_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_9",
            "tgt_ix": "412-ARR_v1_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_10",
            "tgt_ix": "412-ARR_v1_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_11",
            "tgt_ix": "412-ARR_v1_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_11",
            "tgt_ix": "412-ARR_v1_11@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_11",
            "tgt_ix": "412-ARR_v1_11@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_12",
            "tgt_ix": "412-ARR_v1_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_12",
            "tgt_ix": "412-ARR_v1_12@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_12",
            "tgt_ix": "412-ARR_v1_12@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_12",
            "tgt_ix": "412-ARR_v1_12@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_12",
            "tgt_ix": "412-ARR_v1_12@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_12",
            "tgt_ix": "412-ARR_v1_12@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_13",
            "tgt_ix": "412-ARR_v1_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_13",
            "tgt_ix": "412-ARR_v1_13@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_14",
            "tgt_ix": "412-ARR_v1_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_14",
            "tgt_ix": "412-ARR_v1_14@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_14",
            "tgt_ix": "412-ARR_v1_14@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_14",
            "tgt_ix": "412-ARR_v1_14@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_15",
            "tgt_ix": "412-ARR_v1_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_15",
            "tgt_ix": "412-ARR_v1_15@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_16",
            "tgt_ix": "412-ARR_v1_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_17",
            "tgt_ix": "412-ARR_v1_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_17",
            "tgt_ix": "412-ARR_v1_17@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_18",
            "tgt_ix": "412-ARR_v1_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_19",
            "tgt_ix": "412-ARR_v1_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_20",
            "tgt_ix": "412-ARR_v1_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_20",
            "tgt_ix": "412-ARR_v1_20@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_20",
            "tgt_ix": "412-ARR_v1_20@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_21",
            "tgt_ix": "412-ARR_v1_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_21",
            "tgt_ix": "412-ARR_v1_21@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_21",
            "tgt_ix": "412-ARR_v1_21@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_22",
            "tgt_ix": "412-ARR_v1_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_22",
            "tgt_ix": "412-ARR_v1_22@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_22",
            "tgt_ix": "412-ARR_v1_22@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_22",
            "tgt_ix": "412-ARR_v1_22@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_22",
            "tgt_ix": "412-ARR_v1_22@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_23",
            "tgt_ix": "412-ARR_v1_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_24",
            "tgt_ix": "412-ARR_v1_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_24",
            "tgt_ix": "412-ARR_v1_24@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_24",
            "tgt_ix": "412-ARR_v1_24@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_24",
            "tgt_ix": "412-ARR_v1_24@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_24",
            "tgt_ix": "412-ARR_v1_24@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_25",
            "tgt_ix": "412-ARR_v1_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_25",
            "tgt_ix": "412-ARR_v1_25@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_25",
            "tgt_ix": "412-ARR_v1_25@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_25",
            "tgt_ix": "412-ARR_v1_25@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_26",
            "tgt_ix": "412-ARR_v1_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_27",
            "tgt_ix": "412-ARR_v1_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_28",
            "tgt_ix": "412-ARR_v1_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_29",
            "tgt_ix": "412-ARR_v1_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_29",
            "tgt_ix": "412-ARR_v1_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_29",
            "tgt_ix": "412-ARR_v1_29@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_30",
            "tgt_ix": "412-ARR_v1_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_31",
            "tgt_ix": "412-ARR_v1_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_32",
            "tgt_ix": "412-ARR_v1_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_32",
            "tgt_ix": "412-ARR_v1_32@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_33",
            "tgt_ix": "412-ARR_v1_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_34",
            "tgt_ix": "412-ARR_v1_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_35",
            "tgt_ix": "412-ARR_v1_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_36",
            "tgt_ix": "412-ARR_v1_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_36",
            "tgt_ix": "412-ARR_v1_36@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_36",
            "tgt_ix": "412-ARR_v1_36@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_37",
            "tgt_ix": "412-ARR_v1_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_38",
            "tgt_ix": "412-ARR_v1_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_39",
            "tgt_ix": "412-ARR_v1_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_39",
            "tgt_ix": "412-ARR_v1_39@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_39",
            "tgt_ix": "412-ARR_v1_39@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_40",
            "tgt_ix": "412-ARR_v1_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_41",
            "tgt_ix": "412-ARR_v1_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_41",
            "tgt_ix": "412-ARR_v1_41@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_41",
            "tgt_ix": "412-ARR_v1_41@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_41",
            "tgt_ix": "412-ARR_v1_41@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_42",
            "tgt_ix": "412-ARR_v1_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_42",
            "tgt_ix": "412-ARR_v1_42@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_43",
            "tgt_ix": "412-ARR_v1_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_44",
            "tgt_ix": "412-ARR_v1_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_44",
            "tgt_ix": "412-ARR_v1_44@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_44",
            "tgt_ix": "412-ARR_v1_44@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_45",
            "tgt_ix": "412-ARR_v1_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_45",
            "tgt_ix": "412-ARR_v1_45@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_45",
            "tgt_ix": "412-ARR_v1_45@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_46",
            "tgt_ix": "412-ARR_v1_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_47",
            "tgt_ix": "412-ARR_v1_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_47",
            "tgt_ix": "412-ARR_v1_47@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_48",
            "tgt_ix": "412-ARR_v1_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_49",
            "tgt_ix": "412-ARR_v1_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_50",
            "tgt_ix": "412-ARR_v1_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_50",
            "tgt_ix": "412-ARR_v1_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_50",
            "tgt_ix": "412-ARR_v1_50@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_51",
            "tgt_ix": "412-ARR_v1_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_51",
            "tgt_ix": "412-ARR_v1_51@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_51",
            "tgt_ix": "412-ARR_v1_51@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_51",
            "tgt_ix": "412-ARR_v1_51@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_52",
            "tgt_ix": "412-ARR_v1_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_53",
            "tgt_ix": "412-ARR_v1_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_54",
            "tgt_ix": "412-ARR_v1_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_54",
            "tgt_ix": "412-ARR_v1_54@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_54",
            "tgt_ix": "412-ARR_v1_54@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_54",
            "tgt_ix": "412-ARR_v1_54@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_55",
            "tgt_ix": "412-ARR_v1_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_55",
            "tgt_ix": "412-ARR_v1_55@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_55",
            "tgt_ix": "412-ARR_v1_55@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_56",
            "tgt_ix": "412-ARR_v1_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_56",
            "tgt_ix": "412-ARR_v1_56@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_56",
            "tgt_ix": "412-ARR_v1_56@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_56",
            "tgt_ix": "412-ARR_v1_56@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_56",
            "tgt_ix": "412-ARR_v1_56@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_56",
            "tgt_ix": "412-ARR_v1_56@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_57",
            "tgt_ix": "412-ARR_v1_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_58",
            "tgt_ix": "412-ARR_v1_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_59",
            "tgt_ix": "412-ARR_v1_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_60",
            "tgt_ix": "412-ARR_v1_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_61",
            "tgt_ix": "412-ARR_v1_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_61",
            "tgt_ix": "412-ARR_v1_61@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_61",
            "tgt_ix": "412-ARR_v1_61@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_61",
            "tgt_ix": "412-ARR_v1_61@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_62",
            "tgt_ix": "412-ARR_v1_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_63",
            "tgt_ix": "412-ARR_v1_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_64",
            "tgt_ix": "412-ARR_v1_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_64",
            "tgt_ix": "412-ARR_v1_64@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_65",
            "tgt_ix": "412-ARR_v1_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_65",
            "tgt_ix": "412-ARR_v1_65@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_65",
            "tgt_ix": "412-ARR_v1_65@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_66",
            "tgt_ix": "412-ARR_v1_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_67",
            "tgt_ix": "412-ARR_v1_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_68",
            "tgt_ix": "412-ARR_v1_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_68",
            "tgt_ix": "412-ARR_v1_68@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_68",
            "tgt_ix": "412-ARR_v1_68@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_68",
            "tgt_ix": "412-ARR_v1_68@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_69",
            "tgt_ix": "412-ARR_v1_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_70",
            "tgt_ix": "412-ARR_v1_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_71",
            "tgt_ix": "412-ARR_v1_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_71",
            "tgt_ix": "412-ARR_v1_71@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_72",
            "tgt_ix": "412-ARR_v1_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_73",
            "tgt_ix": "412-ARR_v1_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_74",
            "tgt_ix": "412-ARR_v1_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_74",
            "tgt_ix": "412-ARR_v1_74@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_74",
            "tgt_ix": "412-ARR_v1_74@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_74",
            "tgt_ix": "412-ARR_v1_74@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_74",
            "tgt_ix": "412-ARR_v1_74@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_74",
            "tgt_ix": "412-ARR_v1_74@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_74",
            "tgt_ix": "412-ARR_v1_74@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_74",
            "tgt_ix": "412-ARR_v1_74@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_74",
            "tgt_ix": "412-ARR_v1_74@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_75",
            "tgt_ix": "412-ARR_v1_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_76",
            "tgt_ix": "412-ARR_v1_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_77",
            "tgt_ix": "412-ARR_v1_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_78",
            "tgt_ix": "412-ARR_v1_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_78",
            "tgt_ix": "412-ARR_v1_78@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_78",
            "tgt_ix": "412-ARR_v1_78@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_78",
            "tgt_ix": "412-ARR_v1_78@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_78",
            "tgt_ix": "412-ARR_v1_78@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_79",
            "tgt_ix": "412-ARR_v1_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_80",
            "tgt_ix": "412-ARR_v1_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_80",
            "tgt_ix": "412-ARR_v1_80@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_81",
            "tgt_ix": "412-ARR_v1_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_82",
            "tgt_ix": "412-ARR_v1_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_83",
            "tgt_ix": "412-ARR_v1_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_83",
            "tgt_ix": "412-ARR_v1_83@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_84",
            "tgt_ix": "412-ARR_v1_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_85",
            "tgt_ix": "412-ARR_v1_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_85",
            "tgt_ix": "412-ARR_v1_85@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_86",
            "tgt_ix": "412-ARR_v1_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_86",
            "tgt_ix": "412-ARR_v1_86@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_87",
            "tgt_ix": "412-ARR_v1_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_87",
            "tgt_ix": "412-ARR_v1_87@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_88",
            "tgt_ix": "412-ARR_v1_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_89",
            "tgt_ix": "412-ARR_v1_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_90",
            "tgt_ix": "412-ARR_v1_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_91",
            "tgt_ix": "412-ARR_v1_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_92",
            "tgt_ix": "412-ARR_v1_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_93",
            "tgt_ix": "412-ARR_v1_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_94",
            "tgt_ix": "412-ARR_v1_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_95",
            "tgt_ix": "412-ARR_v1_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_96",
            "tgt_ix": "412-ARR_v1_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_97",
            "tgt_ix": "412-ARR_v1_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_98",
            "tgt_ix": "412-ARR_v1_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_99",
            "tgt_ix": "412-ARR_v1_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_100",
            "tgt_ix": "412-ARR_v1_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_101",
            "tgt_ix": "412-ARR_v1_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_102",
            "tgt_ix": "412-ARR_v1_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_103",
            "tgt_ix": "412-ARR_v1_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_104",
            "tgt_ix": "412-ARR_v1_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_105",
            "tgt_ix": "412-ARR_v1_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_106",
            "tgt_ix": "412-ARR_v1_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_107",
            "tgt_ix": "412-ARR_v1_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_108",
            "tgt_ix": "412-ARR_v1_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_109",
            "tgt_ix": "412-ARR_v1_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_110",
            "tgt_ix": "412-ARR_v1_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_111",
            "tgt_ix": "412-ARR_v1_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_112",
            "tgt_ix": "412-ARR_v1_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_113",
            "tgt_ix": "412-ARR_v1_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_114",
            "tgt_ix": "412-ARR_v1_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_115",
            "tgt_ix": "412-ARR_v1_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_116",
            "tgt_ix": "412-ARR_v1_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_117",
            "tgt_ix": "412-ARR_v1_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_118",
            "tgt_ix": "412-ARR_v1_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_119",
            "tgt_ix": "412-ARR_v1_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_120",
            "tgt_ix": "412-ARR_v1_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_121",
            "tgt_ix": "412-ARR_v1_121@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_122",
            "tgt_ix": "412-ARR_v1_122@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_123",
            "tgt_ix": "412-ARR_v1_123@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_124",
            "tgt_ix": "412-ARR_v1_124@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_125",
            "tgt_ix": "412-ARR_v1_125@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_126",
            "tgt_ix": "412-ARR_v1_126@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_127",
            "tgt_ix": "412-ARR_v1_127@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_128",
            "tgt_ix": "412-ARR_v1_128@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_129",
            "tgt_ix": "412-ARR_v1_129@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_130",
            "tgt_ix": "412-ARR_v1_130@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "412-ARR_v1_131",
            "tgt_ix": "412-ARR_v1_131@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 1225,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "position_tag_type": "from_draft",
        "doc_id": "412-ARR",
        "version": 1
    }
}