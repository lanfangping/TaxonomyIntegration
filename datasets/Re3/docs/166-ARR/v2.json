{
    "nodes": [
        {
            "ix": "166-ARR_v2_0",
            "content": "SDR: Efficient Neural Re-ranking using Succinct Document Representation",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_2",
            "content": "BERT based ranking models have achieved superior performance on various information retrieval tasks. However, the large number of parameters and complex self-attention operations come at a significant latency overhead. To remedy this, recent works propose late-interaction architectures, which allow precomputation of intermediate document representations, thus reducing latency. Nonetheless, having solved the immediate latency issue, these methods now introduce storage costs and network fetching latency, which limit their adoption in real-life production systems.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_3",
            "content": "In this work, we propose the Succinct Document Representation (SDR) scheme that computes highly compressed intermediate document representations, mitigating the storage/network issue. Our approach first reduces the dimension of token representations by encoding them using a novel autoencoder architecture that uses the document's textual content in both the encoding and decoding phases. After this token encoding step, we further reduce the size of the document representations using modern quantization techniques.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_4",
            "content": "Evaluation on MSMARCO's passage rereranking task show that compared to existing approaches using compressed document representations, our method is highly efficient, achieving 4x-11.6x higher compression rates for the same ranking quality. Similarly, on the TREC CAR dataset, we achieve 7.7x higher compression rate for the same ranking quality.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_5",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "166-ARR_v2_6",
            "content": "Information retrieval (IR) systems traditionally comprise of two stages: retrieval and ranking. Given a user query, the role of the retrieval stage is to quickly retrieve a set of candidate documents BERT SPLIT is a distilled late-interaction model with reduced vector width and no compression ( \u00a7 4.2).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_7",
            "content": "For MRR@10 above 0.35, SDR is 4x-11.6x more efficient compared to the baseline.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_8",
            "content": "from a (very large) search index. Retrieval is typically fast but not accurate enough; in order to improve the quality of the end result for the user, the candidate documents are re-ranked using a more accurate but computationally expensive algorithm.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_9",
            "content": "Neural approaches have achieved the state of the art ranking performance in IR applications (Yates et al., 2021). Transformer networks such as BERT (Devlin et al., 2019) consistently show better ranking effectiveness at the cost of a higher computational cost and latency .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_10",
            "content": "To rank k documents, the ranker is called k times with an input of the form (query, document), where the query is the same, but the document is different. Several works (MacAvaney et al., 2020;Gao et al., 2020b;Cao et al., 2020;Nie et al., 2020;Gao et al., 2020b;Khattab and Zaharia, 2020) have proposed to modify BERT-based rankers in a way that allows part of the model to compute query and document representations separately, and then produce the final score using a low-complexity interaction block; we denote these models as late-interaction rankers. Such approaches pre-compute document representations to improve latency significantly. Next, at runtime the model computes the query representation (once), retrieves the precomputed document representations, and is only required to run a low-complexity interaction block k times to produce the final ranking score.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_11",
            "content": "Precomputing document representations has shown to significantly reduce latency and at the same time retain comparable scores to BERT models (Gao et al., 2020b). However, this does not account for additional storage and/or network fetching latency costs. The representations typically consist of the contextual token embeddings in a transformer model, which consume orders of magnitude more storage than storing the entire corpus search index (cf. \u00a7 5.1).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_12",
            "content": "In this work, we propose Succinct Document Representation (SDR), a general scheme for compressing document representations. It enables lateinteraction rankers to be efficient in both latency and storage, while maintaining high ranking quality. SDR is suitable for any ranking scheme that uses contextual embeddings, and achieves extreme compression ratios (2-3 orders of magnitude) with little to no impact on retrieval accuracy. SDR consists of two major components: (1) embedding dimension reduction using an autoencoder with side information and (2) distribution-optimized quantization of the reduced-dimension vectors.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_13",
            "content": "In SDR, the autoencoder consists of two subnetworks: an encoder that reduces the vector's dimensions and a decoder that reconstructs the compressed vector. The encoder's output dimension represents the tradeoff between reconstruction fidelity and storage requirements. To improve the compression-reliability tradeoff, we leverage static token embeddings, which are available since the ranker has access to the document text (as it needs to render it to the user), and are computationally cheap to obtain. We feed these embeddings to both the encoder and decoder as side information, allowing the autoencoder to focus more on storing \"just the context\" of a token, and less on its original meaning that is available in the static embeddings. Ablation tests verify that adding the static vectors significantly improves the compression rates for the same ranking accuracy.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_14",
            "content": "Since data storage is measured in bits rather than floating-point numbers, SDR uses quantization techniques to reduce storage size further. Given that it is hard to evaluate the amount of information in each of the encoder's output dimensions, we perform a randomized Hadamard transform on the vectors, resulting in (1) evenly spread information across all coordinates and (2) transformed vectors that follow a Gaussian-like distribution. We utilize known quantization techniques to represent these vectors using a small number of bits, controlling for the amount of quantization distortion.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_15",
            "content": "Existing late-interaction schemes either ignore the storage overhead, or consider basic compression techniques, such as a simple (1 layer) autoencoder and float16 quantization. However, this is insufficient to reach reasonable storage size (MacAvaney et al., 2020); furthermore, this results in an increased fetching latency. For the MSMARCO dataset, we used a distilled model with a reduced vector width (Hofst\u00e4tter et al., 2020a) as the initial pre-trained weights for the late-interaction model. On top of this, we used a non-linear autoencoder consisting of 2 dense layers followed by float16 quantization, a natural extension of MacAvaney et al. (2020). This baseline achieves compression rates of 30x with no noticeable reduction in retrieval accuracy (measured with the official MRR@10 metric). In comparison with this strong baseline, our SDR scheme achieves an additional compression rate of between 4x to 11.6x with the same ranking quality, reducing document representation size to the same order of magnitude as the retrieved text itself. In Figure 1 we include a high-level presentation of the baseline, a variant of our method with float16 quantization, and our full method. For the TREC CAR dataset, for which we do not have a reduced-width baseline, we used a BERT model as the pre-trained weights for the late-interaction model. The baseline with 2 dense layers and float16 quantization achieves a 30x compression rates with a slight reduction in accuracy. The SDR scheme reaches the same quality while improving compression rate by another 7.7x.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_16",
            "content": "To summarize, here are the contribution of this work 1 :",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_17",
            "content": "\u2022 We propose the Succinct Document Representation (SDR) scheme for compressing the document representations required for fast Transformer-based rankers. The scheme is based on a specialized autoencoder architecture and subsequent quantization. \u2022 For the MSMARCO passage retrieval task, SDR shows compression ratios of 121x with no noticeable decrease in ranking performance. Compared to existing approaches for producing compressed representations, our method attains better compression rates (between 4x and 11.6x) for the same ranking quality. Similar results are demonstrated on the TREC CAR dataset. \u2022 We provide a thorough analysis of the SDR system, showing that the contribution of each of the components to the compression-ranking effectiveness is significant.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_18",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "166-ARR_v2_19",
            "content": "Late-interaction models. The idea of running several transformer layers for the document and the query independently, and then combining them in the last transformer layers, was developed concurrently by multiple teams: PreTTR (MacAvaney et al., 2020), EARL (Gao et al., 2020a), DC-BERT (Nie et al., 2020), DiPair , and the Deformer (Cao et al., 2020). These works show that only a few layers where the query and document interact are sufficient to achieve results close to the performance of a full BERT ranker at a fraction of the runtime cost. For each document, the contextual token vectors are stored in a cache and retrieved during the document ranking phase. This impacts both storage cost as well as latency cost of fetching these vectors during the ranking phase. MORES (Gao et al., 2020b), extends lateinteraction models, where in the last interaction layers only the query attends to the document (and not vice-versa). As document are typically much longer, this results in additional performance improvements with similar storage requirements. Col-BERT (Khattab and Zaharia, 2020) is another variant that runs all transformer layers independently for the query and the document, and the interaction between the final vectors is done through a sumof-max operator. A similar work, the Transformer-Kernel (TK) (Hofst\u00e4tter et al., 2020b), has an interaction block based on a low-complexity kernel operation. Both ColBERT and TK result in models with lower runtime latency at the expense of a drop in ranking quality. However, the storage requirements for both approaches are still significant. Some of the works above acknowledge the issue of storing the precomputed document representations and proposed partial solutions. In Col-BERT (Khattab and Zaharia, 2020), the authors proposed to reduce the dimension of the final token embedding using a linear layer. However, even moderate compression ratios caused a large drop in ranking quality. In the PreTTR model (MacAvaney et al., 2020), it was proposed to address the storage cost by using a standard auto-encoder architecture and the float16 format instead of float32. Again, the ranking quality drops even with moderate compression ratios (they measured up to 12x).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_20",
            "content": "Several other works (Guu et al., 2020;Karpukhin et al., 2020;Xiong et al., 2021;Qu et al., 2020;Lu et al., 2020) proposed representing the queries and documents as vectors (as opposed to a vector per token), and using dot product as the interaction block. While this ranker architecture approach is simple (and can also be used for the retrieval step via an approximate nearest neighbor search such as FAISS (Johnson et al., 2017), ScaNN (Guo et al., 2020) or the Pinecone managed service 2 ), the overall ranking quality is generally lower compared to methods that employ a query-document crossattention interaction. For that reason these methods are used mainly for first-stage retrieval, followed by a reranking step.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_21",
            "content": "Compressed embeddings. Our work reduces storage requirements by reducing the number of bits per floating-point value. Quantization gained attention and success in reducing the size of neural network parameters (Gupta et al., 2015;Essam et al., 2017;Wang et al., 2018;Wu et al., 2018) and distributed learning communication costs (Suresh et al., 2017;Alistarh et al., 2017;Kone\u010dn\u1ef3 and Richt\u00e1rik, 2018;Vargaftik et al., 2021Vargaftik et al., , 2022. Specifically, compressing word embeddings has been studied as an independent goal. May et al. (2019) studied the effect of quantized word embeddings on downstream applications and proposed a metric for quantifying this effect with simple linear models that operate on the word embeddings directly. As our work is concerned with compressing contextual embeddings, these methods do not apply since the set of possible embeddings values is not bounded by the vocabulary size. Nevertheless, as in (May et al., 2019), we also observe that simple quantization schemes are quite effective. Our work uses recent advances in this area to further reduce storage requirements for document representation, which, to the best of our knowledge, were not previously attempted in this context.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_22",
            "content": "Succinct Document Representation (SDR)",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "166-ARR_v2_23",
            "content": "Our work is based on the late-interaction architecture (MacAvaney et al., 2020;Gao et al., 2020b;Cao et al., 2020;Nie et al., 2020), which separates BERT into L independent layers for the documents and the queries, and T \u2212 L interleaving layers, where T is the total number of layers in the original model, e.g., 12 for BERT-Base. Naively storing all documents embeddings consumes a huge amount of storage with a total of m \u2022 h \u2022 4 bytes per document, where m is the average number of tokens per document and h is the model hidden size (384 for the distilled version and 768 for the BERT version). For MSMARCO, with 8.8M documents and m = 76.9, it leads to a high storage cost of over a terabyte, which is not affordable except in large production systems.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_24",
            "content": "Our compression scheme for the document representations consists of two sequential steps, (i) dimensionality reduction and (ii) block-wise quantization, described in \u00a7 3.1 and \u00a7 3.2 respectively.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_25",
            "content": "Dimensionality Reduction using AutoEncoders with Side Information (AESI)",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "166-ARR_v2_26",
            "content": "To compress document representations, we reduce the dimensionality of token representations (i.e., the output of BERT's L-th layer) using an autoencoder. Standard autoencoder architectures typically consist of a neural network split into an encoder and a decoder: the encoder projects the input vector into a lower-dimension vector, which is then reconstructed back using the decoder. Our architecture, AESI, extends the standard autoencoder by using the document's text as side information to both the encoder and decoder. Such an approach is possible since, no matter how the document scores are computed, re-ranking systems have access to the document's text in order to render it back to the user. In the rest of this section, we add the precise details of the AESI architecture.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_27",
            "content": "Side Information. In line with our observation that the ranker has access to the document's raw text, we propose utilizing the token embedding information, which is computed by the embedding layer used in BERT's architecture. The token embeddings encode rich semantic information about the token itself; however, they do not fully capture the context in which they occur; hence, we refer to them as static embeddings. For example, through token embeddings, we cannot disambiguate between the different meanings of the token bank, which can refer to either a geographical location (e.g., \"river bank\") or a financial institution, depending on the context.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_28",
            "content": "Static embeddings are key for upper BERT layers, which learn the contextual representation of tokens via the self-attention mechanism. We use the static embeddings as side information to both the encoder and decoder parts of the autoencoder. This allows the model to focus on encoding the distilled context, and less on the token information since it is already provided to the decoder directly.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_29",
            "content": "AESI Approach. For a token whose representation we wish to compress, our approach proceeds as follows. We take the L-th layer's output contextual representation of the token together with its static embedding and feed both inputs to the autoencoder. The information to be compressed (and reconstructed) is the contextual embedding, and the side-information, which aids in the compression task, is the static embedding. The decoder takes the encoder output, along with the static embedding, and attempts to reconstruct the contextual embedding. Figure 2 shows the AESI architecture.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_30",
            "content": "AESI approach has two parameters that are determined empirically. First, the L-th transformer layer of the contextual representation provided as input, which has a direct impact on latency 3 . Second, the size of the encoder's output directly impacts the compression rate and thus storage costs.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_31",
            "content": "Encoding starts by concatenating the input vector (i.e., the output of layer L, the vector we compress) and the static token embedding (i.e., the output of BERT's embedding layer), and then passes the concatenated vector through an encoder network, which outputs a c-dimensional encoded vector. Decoding starts by concatenating the encoded vector with the static token embedding, then passes the concatenated vector through a decoder layer, which reconstructs the input vector. Specifically, we use a two-layer dense network for both the encoder and the decoder, which can be written using the following formula:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_32",
            "content": "e = E(v, u) := W e 2 \u2022 gelu W e 1 (v; u) (1) v = D(e, u) := W d 2 \u2022 gelu W d 1 (e; u)(2)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_33",
            "content": "where v \u2208 R h is the contextualized token embedding (the output of the L-th layer), u \u2208 R h is the static token embedding (the output of the embedding layer, which is the input to BERT's layer 0 and includes token position embeddings and type embeddings), and u; v means concatenation of these vectors.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_34",
            "content": "W e 1 \u2208 R i\u00d72h , W e 2 \u2208 R c\u00d7i , W d 1 \u2208 R i\u00d7(c+h) , W d 2 \u2208 R h\u00d7i are trainable param- eters.",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_35",
            "content": "h is the dimension of token embeddings (e.g., 384), i is the intermediate autoencoder size, and c is the dimension of the projected (encoded) vector. gelu(\u2022) is an non-linear activation function (Hendrycks and Gimpel, 2016). Additional autoencoder variations are explored in \u00a7 5.3.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_36",
            "content": "Quantization",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "166-ARR_v2_37",
            "content": "Storing the compressed contextual representations in a naive way consumes 32 bits (float32) per coordinate per token, which is still costly. To further reduce storage overhead, we propose to apply a quantization technique, which uses a predetermined B bits per coordinate. However, different coordinates and different tokens have different importance and possibly also different scales, so using the same number of bits and same quantization threshold for all of them increases the quantization error.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_38",
            "content": "To remedy this issue, we follow an approach similar to EDEN quantization (Vargaftik et al., 2022), which uses a randomized Hadamard transform prior to quantization. Loosely speaking, this shuffles the information across all coordinates. Furthermore, each of the coordinates is guaranteed to follow Gaussian-like distribution, for which quantization boundaries can be computed optimally. For the sake of brevity, the full description of the quantization algorithm is deferred to Appendix A.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_39",
            "content": "Efficiently applying the Hadamard transform requires the size of the input to be a power of two. In addition, the input dimension should be large enough (specifically, larger than the output of AESI) so that information can be shuffled effectively. Therefore, we concatenate the AESI vectors of all tokens from a single document, then segment it to a larger block size (we use 128), padding the last block with zeros when necessary. The padding slightly increases space requirements and is considered when evaluating the compression efficiency.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_40",
            "content": "Experimental Settings",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "166-ARR_v2_41",
            "content": "In this section we describe the datasets used to evaluate the competing approaches for ranking documents given a query. Next, we describe the baseline and the different configurations of SDR with emphasis on how we measure the compression ratio.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_42",
            "content": "Tasks and Datasets",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "166-ARR_v2_43",
            "content": "To evaluate the effectiveness of our proposed approach (SDR) and the competing baseline, we consider two information retrieval datasets, each with different characteristics. MSMARCO passage re-ranking In this task (Nguyen et al., 2016), we are given a query and a list of 1,000 passages (retrieved via BM25), and the task is to rerank the passages according to their relevance to the query. The corpus consists of 8.8M passages, downloaded from the web. We consider two query sets:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_44",
            "content": "(1) MSMARCO-DEV, the development set for the MSMARCO passage reranking task, which consists of 6,980 queries. On average, each query has a single relevant passage, and other passages are not annotated. The models are measured using the mean reciprocal rank metric (MRR@10).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_45",
            "content": "(2) TREC 2019 DL Track. Here we consider the test queries from TREC 2019 DL Track passage reranking dataset. Unlike MSMARCO-DEV, there are multiple passages annotated for each query with graded relevance labels (instead of binary labels), allowing us to use the more informative nDCG@10 metric. Due to the excessive annotation overhead, this dataset consists of just 200 queries, so results are noisier compared to MSMARCO-DEV. TREC Complex Answer Retrieval (CAR) is a dataset (Dietz et al., 2017) curated from Wikipedia. It maps from article and section titles to relevant paragraphs. Following , we use the automatic by-article annotations variant, which considers all paragraphs within the same article as relevant. The dataset consists of 30M passages, making storage requirements a more significant challenge compared to the MSMARCO task. The test query set consists of 2,254 queries with an average of 2.74 positive passages per query. We use the MAP@1K official metric.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_46",
            "content": "For both datasets, in addition to the quality metrics, we also measure the Compression Ratio (CR) as the amount of storage required to store the token embeddings when compared to the baseline model. E.g., CR = 10 implies storage size that is one tenth of the baseline vectors.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_47",
            "content": "Baseline -BERT SPLIT",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "166-ARR_v2_48",
            "content": "Our algorithm is based on the late-interaction architecture (MacAvaney et al., 2020;Gao et al., 2020a;Nie et al., 2020;Cao et al., 2020). We created a model based on this architecture, which we name BERT SPLIT , consisting of 10 layers that are computed independently for the query and the document with an additional two late-interaction layers that are executed jointly. For MSMARCO, we initialized the model from reduced width pre-trained weights 4 and fine-tuned it using knowledge distillation from an ensemble of BERT-Large, BERT-Base, and ALBERT-Large (Hofst\u00e4tter et al., 2020b) on the MSMARCO small training dataset, which consists of almost 40M tuples of query, a relevant document, and an irrelevant document. For CAR, the model is initialized from pre-trained BERT-base model and trained on 50M samples curated by .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_49",
            "content": "SDR Configuration and Training",
            "ntype": "title",
            "meta": {
                "section": "4.3"
            }
        },
        {
            "ix": "166-ARR_v2_50",
            "content": "We trained autoencoder variants on a random subset of 500k documents to reduce training time. We incorporate the quantization overhead into the computation of the compression ratios, including metadata and the overhead of padding (cf. Appendix A).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_51",
            "content": "In the following sections, we denote the SDR variants as \"AESI-{c}-{B}b\" where {c} is replaced with the width of the encoded vector and {B} is replaced with the number of bits in the quantization scheme. When discussing AESI with no quantization, we simply write \"AESI-{c}\".",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_52",
            "content": "End to end Latency Measurement",
            "ntype": "title",
            "meta": {
                "section": "4.4"
            }
        },
        {
            "ix": "166-ARR_v2_53",
            "content": "To measure end to end latency, we configured an OpenSearch 5 cluster in AWS. We used default \"production\" configurations, with 3 r6g.large datanode machines; disk space was set to 0.5TB. For ranking, we used a single g4dn.xlarge machine, featuring a single T4 GPU instance. This makes the cost of these two components similar.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_54",
            "content": "Evaluation Results",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "166-ARR_v2_55",
            "content": "In this section, we present the end to end latency results ( \u00a7 5.1), show compression ratios and quality tradeoff of the SDR scheme ( \u00a7 5.2). We then examine how the proposed autoencoder ( \u00a7 5.3) compares with other baselines and present additional measurements ( \u00a7 5.4).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_56",
            "content": "End to End Latency Evaluation",
            "ntype": "title",
            "meta": {
                "section": "5.1"
            }
        },
        {
            "ix": "166-ARR_v2_57",
            "content": "Table 1 (top) shows the latency benefits of SDR on the MSMARCO dataset, assuming document embeddings are stored in the OpenSearch retrieval system and 1k documents are retrieved per query. The Distilbert model (full interaction architecture) has the highest quality and smallest index size (since it is only executed online). However, ranking latency is prohibitively expensive. As a baseline, we use a late interaction model, a two-layer autoencoder with code dimension 24 and float16 quantization, denoted Late+AE-24. For this baseline, the ranking latency is significantly reduced at a cost in terms of quality. However, the document representation is large, causing retrieval and overall latency to increase to 0.7 and 1.22 seconds, respectively. SDR, with a dimension of 16 and 6-bits quantization, reaches the same quality as the baseline while striking a better balance between retrieval and ranking latency, reaching overall latency of 1.1 seconds. The index size is also significantly reduced compared to the baseline compression algorithm.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_58",
            "content": "We also consider variants of the algorithms where the documents are pre-tokenized, and the tokenization output is retrieved instead of computing at runtime (marked as +tok in the table). This further improves the ranking latency at the expense of a slight increase in index size. Note that the baseline does not use the raw text and therefore does not benefit from precomputed tokens.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_59",
            "content": "Table 1 (bottom) shows the latency results on the CAR dataset. Here too, the BERT baseline has the highest ranking quality, at the cost of prohibitive latency. The late interaction variants we consider have the same configuration as in the MS-MARCO case, where the baseline uses 24 features (with float16 quantization) and SDR uses 16 features (with 6 bits EDEN quantization). Unlike in the MSMARCO case, the quality (i.e., MAP@1k score) of these two options is not similar. This makes SDR better than the baseline in latency, index size, as well as quality (by a large margin of over 14%).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_60",
            "content": "In Appendix D we explore additional configurations and show that the baseline with 52 features reaches the same quality as SDR-16-6b. However, we do not measure end-to-end latency for this case due to the excessive storage size and indexing time. Note that using 52 features for the baseline is expected to have a negative impact on retrieval latency, making the benefits of SDR even more pronounced.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_61",
            "content": "Compression Rate and Quality Tradeoff",
            "ntype": "title",
            "meta": {
                "section": "5.2"
            }
        },
        {
            "ix": "166-ARR_v2_62",
            "content": "Table 2 shows the results on the MSMARCO query sets for SDR and its compression ratio against storing contextual token embeddings uncompressed. In terms of compression ratio, it can be seen that AESI allows us to massively reduce storage requirements both with and without quantization.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_63",
            "content": "AESI-16-6b reduces storage requirements by 121x, while at the same time showing no significant ranking performance drop. Using AESI-16-6b, a document's embedding can be stored with only 947 bytes and the entire MSMARCO collection can be stored within 8.6GB. There are several advantages of fitting the entire collection's representation into the main memory of the hosting machine, allowing for fast access, further fine-tuning, etc. If further compression rates are required, AESI-8-5b uses just 5 bytes per token, reaching a compression rate of 277x and 487 bytes per document on average. At this level of compression, the entire MSMARCO corpus fits in 3.8GB. The MRR@10 drop is noticeable (0.0119) but still quite low. Finally, for TREC19-DL, the impact of compressing token embeddings is less evident. Only in the most extreme cases such as AESI-4-4b we see a significant drop in nDCG@10 performance. These results demonstrate that the performance drop is very small, showing the effectiveness of our method.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_64",
            "content": "Autoencoder Evaluation",
            "ntype": "title",
            "meta": {
                "section": "5.3"
            }
        },
        {
            "ix": "166-ARR_v2_65",
            "content": "To better understand the impact of the autoencoder, we present MRR@10 results as a function of autoencoder dimensions (i.e., number of floats stored per token) and with the different autoencoder configurations. In addition to the 2-layer AESI architecture we described in \u00a7 3.1 (AESI-2L), we consider the following variations: AutoEncoder with 2 Layers (AE-2L). Standard 2-layer autoencoder with gelu activation. This is the same as AESI, only without the side information.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_66",
            "content": "AutoEncoder with 1 Layer (AE-1L). Standard autoencoder with a single dense layer in the encoder and decoder.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_67",
            "content": "AESI with 1 Layer (AESI-1L). AESI with a single dense encoder and decoder layer.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_68",
            "content": "). Provides side information to the decoder but not the encoder.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_69",
            "content": "To reduce measurement overhead, we ran the experiment only over the MSMARCO dataset. In addition, we took only the top 25 BERT SPLIT passages for each query, denoted MSMARCO-DEV-25, which has a negligible impact on the results. Figure 3 shows the results for the different autoencoder configurations. Providing the side information to the autoencoder proves to be very effective in reducing storage costs, especially when the encoded vector size is small. A 2-layer encoder/decoder model, as expected, is more effective than a singlelayer model. The gap is especially large when using side information, showing that the interaction between the encoded vector and the static token embeddings is highly nonlinear. Finally, providing the static embeddings only to the decoder is slightly inferior to providing it also to the encoder.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_70",
            "content": "Additional Measurements",
            "ntype": "title",
            "meta": {
                "section": "5.4"
            }
        },
        {
            "ix": "166-ARR_v2_71",
            "content": "Quantization Techniques we compare the quantization technique we use to several other techniques, including Deterministic Rounding (Gersho and Gray, 1992), Stochastic Rounding (Connolly et al., 2021), and Subtractive Dithering (Roberts, 1962;Gray and Stockham, 1993). Due to lack of space, the results appear in Appendix B. We found that a randomized Hadamard transform improves quality (assuming similar bit rate), especially in the low-bits regime. Using a quantization technique fitted to the Gaussian distribution of post randomized Hadamard transform data further improve quality, making the EDEN quantization superior to other quantization techniques in our case.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_72",
            "content": "Our scheme uses a fixed number of bits per coordinate, which is essential for performance. However, variable-rate compression can further reduce storage. We used rate-distortion theory (from the information theory field) to upper bound the benefits of such techniques by 11%, which does not seem to justify the added system complexity (cf. Appendix B).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_73",
            "content": "To better understand the impact of side information, we measure the error rate between an input vector and its reconstructed vector (i.e., after encoding and decoding). As expected, in practically all cases, adding the side information reduces error rate compared to a 2-layer autoencoder (AE-2L) with the same code dimension.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_74",
            "content": "In IR, the document frequency of a token is known to be negatively correlated with the token's importance. We found that the error rate for AE-2L decreases with frequency, while the error rate for AESI increases with frequency. This shows that the AESI scheme can better focus on tokens that are important for ranking. A possible explanation for this phenomena is that the static embeddings for infrequent tokens are more informative (i.e., more helpful as side information) compared to static embeddings for frequent tokens (e.g., 'the'). We also found AESI excels more in compressing nouns, verbs, and adjectives, while AE-2L excels more in compressing punctuation, determiners, and adpositions. Again, this demonstrate that the static embeddings is most helpful in encoding tokens that are crucial for ranking. The details of this evaluation are provided in Appendix C.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_75",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "166-ARR_v2_76",
            "content": "In this paper, we proposed a system called SDR to solve the storage cost and latency overhead of existing late-interaction transformer based models for passage re-ranking. The SDR scheme uses a novel autoencoder architecture that uses static token embeddings as side information to improve encoding quality. In addition, we explored different quantization techniques and showed that the recently proposed EDEN performs well in our use case and presented extensive experimentation. Overall, the SDR scheme reduces pre-computed document representation size by 4x-11.6x compared to a baseline that uses existing approaches.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_77",
            "content": "In future work, we plan to continue investigating means to reduce pre-computed document representation size.We believe that additional analysis of BERT's vector and their interaction with the context would be fundamental in such an advancement.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_78",
            "content": "In this Appendix, we include an overview of the quantization method we adapted to our use case. The algorithm is summarized in Algorithm 1, for full details see Vargaftik et al., 2022, Section 3. We start by introducing the following definitions:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_79",
            "content": "Definition 1 (Horadam, 2012). A normalized Walsh-Hadamard matrix,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_80",
            "content": "H 2 k \u2208 {+1, \u22121} 2 k \u00d72 k , is recursively defined as H 1 = 1; H 2 k = 1 \u221a 2 H 2 k\u22121 H 2 k\u22121 H 2 k\u22121 \u2212H 2 k\u22121 .",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_81",
            "content": "Definition 2 (Ailon and Chazelle, 2006). A randomized Hadamard transform, H, of a vector,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_82",
            "content": "x \u2208 R 2 k , is defined as H(x) := H 2 k Dx,",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_83",
            "content": "where H 2 k is a normazlized Walsh-Hadmard matrix, and D is a diagonal matrix whose diagonal entries are i.i.d. Rademacher random variables (i.e., taken uniformly from {+1, \u22121}). While H is randomized and thus defines a distribution, when D is known, we abuse the notation and define the inverse Hadamard transform as",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_84",
            "content": "H \u22121 (x) := (H 2 k D) \u22121 x = DH 2 k x.",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_85",
            "content": "The quantization operates as follows. Given a vector, denoted x \u2208 R d , we first precondition it using a randomized Hadamard transform, H, and normalize by multiplying by \u221a d / x 2 . There are several desired outcomes of this transform 6 . First, the dynamic range of the values is reduced (measured, for instance, by the ratio of the \u221e and the 2 norms). Loosely speaking, we can think of the transform as spreading the vector's information evenly among its coordinates. Second, regardless of the distribution of the input vector, each coordinate of the transformed vector will have a distribution that is close to the standard Gaussian distribution (as an outcome of the central limit theorem). After the transform, we perform scalar quantization that is optimized for the N (0, 1) distribution, using K-means (also known as Max-Lloyd in the quantization literature (Gersho and Gray, 1992)), with K = 2 B . The vector X of cluster assignments together with the original vector's 2 norm can now be stored as the compressed representation of the original vector.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_86",
            "content": "To retrieve an estimate of the original vector, we perform the same steps in reverse. We replace",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_87",
            "content": "To study the impact of quantization, we fix AESI-16 as our baseline and measure how different quantization strategies and number of bits affect the MRR@10 score. Note that we do not measure quantization over the baseline BERT SPLIT since it can only achieve a compression ratio of up to 32x per coordinate (using 1 bit per coordinate). In addition to EDEN (Appendix A, Algorithm 1), we consider the following quantization strategies: Deterministic Rounding (DR) (Gersho and Gray, 1992). Maps the input coordinates into the [0, 2 B \u2212 1] range using min-max normalization and rounds to the nearest integer. Stochastic Rounding (SR) (Barnes et al., 1951;Connolly et al., 2021). Normalizes as before using min-max normalization, and additionally adds a uniform dither noise in (\u22120.5, 0.5) and then rounds to the nearest integer. This provides an unbiased estimate of each coordinate. Subtractive Dithering (SD) (Roberts, 1962;Gray and Stockham, 1993). Same as SR, only now before denormalization, instead of just using the values in {0, . . . , 2 B \u2212 1}, we first subtract the original dither noise, which we assume can be regenerated using shared randomness. This is an unbiased estimator with reduced variance. Hadamard Variants (H-DR, H-SR, and H-SD). These variants correspond to the previous methods; only they are preceded by a randomized Hadamard transform. EDEN with Bias Correction (EDEN-BC) (Vargaftik et al., 2022, Section 2.3). This variant of EDEN optimizes for lower bias over the mean squared error (MSE) by multiplying the dequantization result in Algorithm 1 by a bias correction scalar: x 2 2 / H(x), \u0177 .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_88",
            "content": "Figure 4 shows the results for the different quantization methods. First, we observe that the Hadamard variants perform better than their non-Hadamard counterparts. Second, we see that EDEN performs better than all other schemes. The differences are more pronounced in the low-bit regime, where the choice of quantization scheme has a drastic impact on quality. We also note that unlike in other use cases, such as distributed mean estimation, bias correction is inappropriate here and should not be performed at the cost of increased mean squared error (MSE). This conclusion follows by observing that EDEN and the deterministic rounding methods (DR, H-DR) are respectively better than EDEN-BC and the stochastic rounding methods (SR, H-SR). We add that the subtractive dithering methods (SD, H-SD), expectedly, work the same or better than their deterministic counterparts since they produce a similar MSE while also being unbiased.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_89",
            "content": "The current quantization scheme requires padding to full 128 blocks. For AESI with a small code size, the padding overhead may reach 10% -20% percent. In addition, we send a normalization value per 128-block, which we currently send as a float32 value, adding 4% -5% additional overhead. Padding can be reduced by treating the last 128-block separately, e.g., applying a method that does not require Hadamard transform. Normalization overhead can be reduced, e.g., by sending normalization factors as float16 instead of full float32. However, such solutions complicate the implementation while providing limited storage benefits, hence, they were not explored in the context of this paper.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_90",
            "content": "Beyond Scalar Quantization. Scalar quantization using a fixed number of bits is a suboptimal technique in general since it does not allocate fewer bits for more frequent cases. Entropy coding (Gersho and Gray, 1992) can do better in this aspect. However, this improvement seems may not justify the added complexity: For the case of 6-bit quantization, the entropy of the quantization indices turned out to be 5.71bit, indicating that the compression gain is limited to about 5% in this case (even before accounting for the overhead incurred from the entropy coding algorithm itself). Additional directions include quantizing multiple values together (vector quantization), as well as designing the quantizer with entropy consideration in mind (entropy-constrained vector quantization).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_91",
            "content": "In order to estimate the potential gains of all these methods combined, we turn to information theory, and rate-distortion theory in particular, which studies the optimal tradeoffs between distortion and compression rate (Cover and Thomas, 2006). For a Gaussian source, which is a reasonable approximation of the vectors that are compressed in our case (following the randomized Hadamard transform), it is known that the optimal (lossy) compression rate is given by 1 2 log 2 ( 1 M SE ), where MSE is the mean squared error of the compressed source. We computed the optimal rate that is achievable for the MSE that our system achieved for 6 bits, and the optimal rate was 5.35bit, indicating a potential gain of 11%. Given these results, and also given that for other bit rates the results were similar, we conclude that further quantization improvements have limited gain, which most likely does not justify the added system complexity.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_92",
            "content": "In the body of the paper, we showed the effectiveness in ranking and utility in compression rates of AESI over AE architectures. However, such evaluations do not capture the encoded information at the token-level. In this intrinsic evaluation we try to discern when and why adding the static embedding as side information contributes to better capturing the token meaning.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_93",
            "content": "We study the effectiveness of different autoencoder configurations in reconstructing back the original token vector, as measured through the MSE between the original vector and the reconstructed vector:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_94",
            "content": "M SE (v, D (E(v, u), u)) ,",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_95",
            "content": "where v is a contextualized vector (BERT SPLIT output at layer 10), u is the static embedding, and the encoder E(v, u) and the decoder D(e, u) are as defined in \u00a7 3.1. High MSE scores indicate the inability of the autoencoder to encode the original vector's information.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_96",
            "content": "Document Frequency: One way to assess the importance of a document w.r.t. a query is through the inverse document frequency of query tokens, typically measured through TF-IDF or BM25 schemes (Robertson and Zaragoza, 2009). In principle, the more infrequent a query token is in a document collection, the higher the ranking of a document containing that token will be. Tokens with (very) high frequencies are typically stop words or punctuation symbols, which have lower importance when determining the query-document relevance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_97",
            "content": "Based on this premise, we study how MSE varies across token frequency. We selected a random sample of 256k documents from MSMARCO, tokenized them, and run them through BERT SPLIT to get 20M contextualized token representations. Then, for each token we measured their document frequency as DF (t) = log 10 (|{d \u2208 D : t \u2208 d}|/|D|) (where D is our document collection), and in Figure 5 we plot the average MSE against the rounded DF scores. From this experiment, we make the following observations. Figure 5: Reconstruction Error vs. DF for the different AE and AESI configurations. AESI shows robust performance in recovering back the token's representation with a MSE score (y-axis), which is constant for documents with varying DF scores. It is interesting to note that for frequent tokens (i.e., tokens that are function words, hence play a marginal role in retrieval), the error rate is higher when compared to the rest of the tokens.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_98",
            "content": "First, on all encoded width configurations, our approach, AESI, consistently achieves lower MSE compared to the AE architecture (for all DF values). Lower MSE correlates to a better ranking quality, as shown in \u00a7 5.3. Furthermore, for tokens with low DF, adding the static side information during the training of AESI for compression provides a huge advantage, which shrinks when the token is present in many documents in the collection.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_99",
            "content": "Second, on the end spectrum of high-frequency tokens, we note a downwards trend for AE and an upwards trend for AESI, especially for DF \u2208 [\u22121, 0]. The MSE decrease for AE is expected since the training data contains more frequent tokens. The increase for AESI can be explained given that in this frequency range, we deal with tokens that are function words (e.g., 'the') whose role is more in tying up content within a sentence and has less standalone meaning. In this case, static embeddings cannot capture context, which reduces the contribution provided by the side information.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_100",
            "content": "In Table 3 we show MAP@1K results on the TREC CAR dataset for a varying number of features. We compare the baseline -an autoencoder with 2 layers and float16 quantization -to SDR scheme, with the same number of features and EDEN 6bits quantization. The SDR scheme is able to provide solid results even for 3 features with a MAP@1K score of 0.268. With the baseline method, similar results are achieved only with 36 features. As a comparison, this is much higher than BM25 using the Answerini system (Yang et al., 2017), which reaches 0.156 MAP@1K score. With 16 features (the configuration we used for Table 1), SDR reaches a score of 0.311, compared to 0.312 for the baseline with 52 features. Finally, with the largest size of features we tested, 64, the baseline reached a MAP@1K score of 0.313, similar to the score achieved by SDR-20 (0.314), demonstrating the effectiveness of the static embeddings as side information.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_101",
            "content": "In Figure 6 we illustrate the architecture of the late interaction model vs. the standard BERT model. In standard BERT, the query and documents are concatenated before the first BERT layer. Therefore, if K documents are ranked, all BERT transformers layers are applied K times. In the late interaction architecture, the bottom L layers (e.g., 10 transformer layers shown in the figure) are executed independently for the query and the documents. The document representation is precomputed and stored in the index. During online execution, the query representation is computed once, and the document representations are retrieved from the index. Only the interaction block (e.g., 2 transformer layers) are executed K times, once for each ranked document.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "166-ARR_v2_102",
            "content": "Nir Ailon, Bernard Chazelle, Approximate nearest neighbors and the fast johnson-lindenstrauss transform, 2006, Proceedings of the Thirty-Eighth Annual ACM Symposium on Theory of Computing, STOC, Association for Computing Machinery.",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "Nir Ailon",
                    "Bernard Chazelle"
                ],
                "title": "Approximate nearest neighbors and the fast johnson-lindenstrauss transform",
                "pub_date": "2006",
                "pub_title": "Proceedings of the Thirty-Eighth Annual ACM Symposium on Theory of Computing, STOC",
                "pub": "Association for Computing Machinery"
            }
        },
        {
            "ix": "166-ARR_v2_103",
            "content": "Dan Alistarh, Demjan Grubic, Jerry Li, Ryota Tomioka, Milan Vojnovic, QSGD: Communication-Efficient Sgd via Gradient Quantization and Encoding, 2017, Advances in Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Dan Alistarh",
                    "Demjan Grubic",
                    "Jerry Li",
                    "Ryota Tomioka",
                    "Milan Vojnovic"
                ],
                "title": "QSGD: Communication-Efficient Sgd via Gradient Quantization and Encoding",
                "pub_date": "2017",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_104",
            "content": "UNKNOWN, None, 1951, An electronic digital computor using cold cathode counting tubes for storage, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": null,
                "title": null,
                "pub_date": "1951",
                "pub_title": "An electronic digital computor using cold cathode counting tubes for storage",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_105",
            "content": "Qingqing Cao, Harsh Trivedi, De-Former: Decomposing pre-trained transformers for faster question answering, 2020, ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Qingqing Cao",
                    "Harsh Trivedi"
                ],
                "title": "De-Former: Decomposing pre-trained transformers for faster question answering",
                "pub_date": "2020",
                "pub_title": "ACL",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_106",
            "content": "Jiecao Chen, Liu Yang, Karthik Raman, Michael Bendersky, Jung-Jung Yeh, Yun Zhou, Marc Najork, Danyang Cai, Ehsan Emadzadeh, DiPair: Fast and accurate distillation for trillion-scale text matching and pair modeling, 2020, Findings of the Association for Computational Linguistics: EMNLP 2020, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Jiecao Chen",
                    "Liu Yang",
                    "Karthik Raman",
                    "Michael Bendersky",
                    "Jung-Jung Yeh",
                    "Yun Zhou",
                    "Marc Najork",
                    "Danyang Cai",
                    "Ehsan Emadzadeh"
                ],
                "title": "DiPair: Fast and accurate distillation for trillion-scale text matching and pair modeling",
                "pub_date": "2020",
                "pub_title": "Findings of the Association for Computational Linguistics: EMNLP 2020",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "166-ARR_v2_107",
            "content": "Michael Connolly, Nicholas Higham, Theo Mary, Stochastic rounding and its probabilistic backward error analysis, 2021, SIAM Journal on Scientific Computing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "Michael Connolly",
                    "Nicholas Higham",
                    "Theo Mary"
                ],
                "title": "Stochastic rounding and its probabilistic backward error analysis",
                "pub_date": "2021",
                "pub_title": "SIAM Journal on Scientific Computing",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_108",
            "content": "M Thomas, Joy Cover,  Thomas, Elements of Information Theory, 2006, Series in Telecommunications and Signal Processing, Wiley-Interscience.",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "M Thomas",
                    "Joy Cover",
                    " Thomas"
                ],
                "title": "Elements of Information Theory",
                "pub_date": "2006",
                "pub_title": "Series in Telecommunications and Signal Processing",
                "pub": "Wiley-Interscience"
            }
        },
        {
            "ix": "166-ARR_v2_109",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long and Short Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Jacob Devlin",
                    "Ming-Wei Chang",
                    "Kenton Lee",
                    "Kristina Toutanova"
                ],
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Long and Short Papers"
            }
        },
        {
            "ix": "166-ARR_v2_110",
            "content": "Laura Dietz, Manisha Verma, Filip Radlinski, Nick Craswell, TREC complex answer retrieval overview, 2017, TREC, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Laura Dietz",
                    "Manisha Verma",
                    "Filip Radlinski",
                    "Nick Craswell"
                ],
                "title": "TREC complex answer retrieval overview",
                "pub_date": "2017",
                "pub_title": "TREC",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_111",
            "content": "Mohaned Essam,  Tong Boon, Eric Tatt Wei Tang, Hsin Ho,  Chen, Dynamic point stochastic rounding algorithm for limited precision arithmetic in deep belief network training, 2017, 8th International IEEE/EMBS Conference on Neural Engineering (NER), .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Mohaned Essam",
                    " Tong Boon",
                    "Eric Tatt Wei Tang",
                    "Hsin Ho",
                    " Chen"
                ],
                "title": "Dynamic point stochastic rounding algorithm for limited precision arithmetic in deep belief network training",
                "pub_date": "2017",
                "pub_title": "8th International IEEE/EMBS Conference on Neural Engineering (NER)",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_112",
            "content": "J Bernard, V Fino,  Ralph Algazi, Unified matrix treatment of the fast walsh-hadamard transform, 1976, IEEE Transactions on Computers, .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "J Bernard",
                    "V Fino",
                    " Ralph Algazi"
                ],
                "title": "Unified matrix treatment of the fast walsh-hadamard transform",
                "pub_date": "1976",
                "pub_title": "IEEE Transactions on Computers",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_113",
            "content": "UNKNOWN, None, 2020, Speedup transformer-based rankers with precomputed representation. arXiv: Information Retrieval, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Speedup transformer-based rankers with precomputed representation. arXiv: Information Retrieval",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_114",
            "content": "Luyu Gao, Zhuyun Dai, Jamie Callan, Modularized transfomer-based ranking framework, 2020, EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Luyu Gao",
                    "Zhuyun Dai",
                    "Jamie Callan"
                ],
                "title": "Modularized transfomer-based ranking framework",
                "pub_date": "2020",
                "pub_title": "EMNLP",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_115",
            "content": "UNKNOWN, None, 1992, Vector quantization and signal compression, Kluwer Academic Publishers.",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": null,
                "title": null,
                "pub_date": "1992",
                "pub_title": "Vector quantization and signal compression",
                "pub": "Kluwer Academic Publishers"
            }
        },
        {
            "ix": "166-ARR_v2_116",
            "content": "R Gray, T Stockham, Dithered quantizers, 1993, IEEE Transactions on Information Theory, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "R Gray",
                    "T Stockham"
                ],
                "title": "Dithered quantizers",
                "pub_date": "1993",
                "pub_title": "IEEE Transactions on Information Theory",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_117",
            "content": "Ruiqi Guo, Philip Sun, Erik Lindgren, Quan Geng, David Simcha, Felix Chern, Sanjiv Kumar, Accelerating large-scale inference with anisotropic vector quantization, 2020, ICML, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Ruiqi Guo",
                    "Philip Sun",
                    "Erik Lindgren",
                    "Quan Geng",
                    "David Simcha",
                    "Felix Chern",
                    "Sanjiv Kumar"
                ],
                "title": "Accelerating large-scale inference with anisotropic vector quantization",
                "pub_date": "2020",
                "pub_title": "ICML",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_118",
            "content": "Suyog Gupta, Ankur Agrawal, Kailash Gopalakrishnan, Pritish Narayanan, Deep learning with limited numerical precision, 2015, Proceedings of Machine Learning Research, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "Suyog Gupta",
                    "Ankur Agrawal",
                    "Kailash Gopalakrishnan",
                    "Pritish Narayanan"
                ],
                "title": "Deep learning with limited numerical precision",
                "pub_date": "2015",
                "pub_title": "Proceedings of Machine Learning Research",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_119",
            "content": "Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Mingwei Chang. 2020. Retrieval augmented language model pre-training, , ICML, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Kelvin Guu",
                    "Kenton Lee",
                    "Zora Tung"
                ],
                "title": "Panupong Pasupat, and Mingwei Chang. 2020. Retrieval augmented language model pre-training",
                "pub_date": null,
                "pub_title": "ICML",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_120",
            "content": "UNKNOWN, None, 2016, Gaussian error linear units (gelus), .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": null,
                "title": null,
                "pub_date": "2016",
                "pub_title": "Gaussian error linear units (gelus)",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_121",
            "content": "UNKNOWN, None, 2020, Improving efficient neural ranking models with cross-architecture knowledge distillation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Improving efficient neural ranking models with cross-architecture knowledge distillation",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_122",
            "content": "UNKNOWN, None, 2020, , .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": null,
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_123",
            "content": ", Interpretable & time-budgetconstrained contextualization for re-ranking, , ECAI, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [],
                "title": "Interpretable & time-budgetconstrained contextualization for re-ranking",
                "pub_date": null,
                "pub_title": "ECAI",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_124",
            "content": "UNKNOWN, None, 2012, Hadamard Matrices and Their Applications, Princeton university press.",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": null,
                "title": null,
                "pub_date": "2012",
                "pub_title": "Hadamard Matrices and Their Applications",
                "pub": "Princeton university press"
            }
        },
        {
            "ix": "166-ARR_v2_125",
            "content": "Jeff Johnson, Matthijs Douze, Herv\u00e9 J\u00e9gou, Billion-scale similarity search with gpus, 2017, IEEE Transactions on Big Data, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Jeff Johnson",
                    "Matthijs Douze",
                    "Herv\u00e9 J\u00e9gou"
                ],
                "title": "Billion-scale similarity search with gpus",
                "pub_date": "2017",
                "pub_title": "IEEE Transactions on Big Data",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_126",
            "content": "Vladimir Karpukhin, Barlas Oguz, Sewon Min, S Patrick, Ledell Lewis, Sergey Wu, Danqi Edunov, Wen Chen, Yih Tau, Dense passage retrieval for open-domain question answering, 2020, EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Vladimir Karpukhin",
                    "Barlas Oguz",
                    "Sewon Min",
                    "S Patrick",
                    "Ledell Lewis",
                    "Sergey Wu",
                    "Danqi Edunov",
                    "Wen Chen",
                    "Yih Tau"
                ],
                "title": "Dense passage retrieval for open-domain question answering",
                "pub_date": "2020",
                "pub_title": "EMNLP",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_127",
            "content": "Omar Khattab, Matei Zaharia, Colbert: Efficient and effective passage search via contextualized late interaction over bert, 2020, SIGIR, .",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Omar Khattab",
                    "Matei Zaharia"
                ],
                "title": "Colbert: Efficient and effective passage search via contextualized late interaction over bert",
                "pub_date": "2020",
                "pub_title": "SIGIR",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_128",
            "content": "Jakub Kone\u010dn\u1ef3, Peter Richt\u00e1rik, Randomized Distributed Mean Estimation: Accuracy vs, 2018, Communication. Frontiers in Applied Mathematics and Statistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": [
                    "Jakub Kone\u010dn\u1ef3",
                    "Peter Richt\u00e1rik"
                ],
                "title": "Randomized Distributed Mean Estimation: Accuracy vs",
                "pub_date": "2018",
                "pub_title": "Communication. Frontiers in Applied Mathematics and Statistics",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_129",
            "content": "UNKNOWN, None, 2020, Twinbert: Distilling knowledge to twin-structured bert models for efficient retrieval, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Twinbert: Distilling knowledge to twin-structured bert models for efficient retrieval",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_130",
            "content": "Sean Macavaney, Maria Franco, Raffaele Nardini, Nicola Perego, Nazli Tonellotto, Ophir Goharian,  Frieder, Efficient document re-ranking for transformers by precomputing term representations, 2020, SIGIR, .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Sean Macavaney",
                    "Maria Franco",
                    "Raffaele Nardini",
                    "Nicola Perego",
                    "Nazli Tonellotto",
                    "Ophir Goharian",
                    " Frieder"
                ],
                "title": "Efficient document re-ranking for transformers by precomputing term representations",
                "pub_date": "2020",
                "pub_title": "SIGIR",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_131",
            "content": "UNKNOWN, None, 2019, On the Downstream Performance of Compressed Word Embeddings, Curran Associates Inc.",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "On the Downstream Performance of Compressed Word Embeddings",
                "pub": "Curran Associates Inc"
            }
        },
        {
            "ix": "166-ARR_v2_132",
            "content": "UNKNOWN, None, 1991, Private vs. Common Random Bits in Communication Complexity. Information processing letters, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": null,
                "title": null,
                "pub_date": "1991",
                "pub_title": "Private vs. Common Random Bits in Communication Complexity. Information processing letters",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_133",
            "content": "Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, Li Deng, Ms marco: A human generated machine reading comprehension dataset, 2016, CoCo@NIPS, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": [
                    "Tri Nguyen",
                    "Mir Rosenberg",
                    "Xia Song",
                    "Jianfeng Gao",
                    "Saurabh Tiwary",
                    "Rangan Majumder",
                    "Li Deng"
                ],
                "title": "Ms marco: A human generated machine reading comprehension dataset",
                "pub_date": "2016",
                "pub_title": "CoCo@NIPS",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_134",
            "content": "Ping Nie, Yuyu Zhang, Xiubo Geng, Arun Ramamurthy, Le Song, Daxin Jiang, Dc-bert: Decoupling question and document for efficient contextual encoding, 2020, SIGIR, .",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": [
                    "Ping Nie",
                    "Yuyu Zhang",
                    "Xiubo Geng",
                    "Arun Ramamurthy",
                    "Le Song",
                    "Daxin Jiang"
                ],
                "title": "Dc-bert: Decoupling question and document for efficient contextual encoding",
                "pub_date": "2020",
                "pub_title": "SIGIR",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_135",
            "content": "UNKNOWN, None, 1901, Passage re-ranking with BERT. CoRR, abs, .",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": null,
                "title": null,
                "pub_date": "1901",
                "pub_title": "Passage re-ranking with BERT. CoRR, abs",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_136",
            "content": "UNKNOWN, None, 2019, Passage re-ranking with BERT. arXiv: Information Retrieval, .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Passage re-ranking with BERT. arXiv: Information Retrieval",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_137",
            "content": "UNKNOWN, None, 2020, Rocketqa: An optimized training approach to dense passage retrieval for open-domain question answering, .",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Rocketqa: An optimized training approach to dense passage retrieval for open-domain question answering",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_138",
            "content": "L Roberts, Picture coding using pseudo-random noise, 1962, IRE Transactions on Information Theory, .",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "L Roberts"
                ],
                "title": "Picture coding using pseudo-random noise",
                "pub_date": "1962",
                "pub_title": "IRE Transactions on Information Theory",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_139",
            "content": "UNKNOWN, None, 2009, The probabilistic relevance framework: BM25 and beyond, Now Publishers Inc.",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": null,
                "title": null,
                "pub_date": "2009",
                "pub_title": "The probabilistic relevance framework: BM25 and beyond",
                "pub": "Now Publishers Inc"
            }
        },
        {
            "ix": "166-ARR_v2_140",
            "content": "Yu Ananda Theertha Suresh, Sanjiv Felix, H Brendan Kumar,  Mcmahan, Distributed Mean Estimation With Limited Communication, 2017, International Conference on Machine Learning, PMLR.",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": [
                    "Yu Ananda Theertha Suresh",
                    "Sanjiv Felix",
                    "H Brendan Kumar",
                    " Mcmahan"
                ],
                "title": "Distributed Mean Estimation With Limited Communication",
                "pub_date": "2017",
                "pub_title": "International Conference on Machine Learning",
                "pub": "PMLR"
            }
        },
        {
            "ix": "166-ARR_v2_141",
            "content": "UNKNOWN, None, , Yaniv Ben-Itzhak, and Michael Mitzenmacher. 2022. Eden: Communication-efficient and robust distributed mean estimation for federated learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Yaniv Ben-Itzhak, and Michael Mitzenmacher. 2022. Eden: Communication-efficient and robust distributed mean estimation for federated learning",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_142",
            "content": "Shay Vargaftik, Ran Ben-Basat, Amit Portnoy, Gal Mendelson, Yaniv Ben-Itzhak, and Michael Mitzenmacher, 2021, Advances in Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b40",
                "authors": [
                    "Shay Vargaftik",
                    "Ran Ben-Basat",
                    "Amit Portnoy",
                    "Gal Mendelson"
                ],
                "title": "Yaniv Ben-Itzhak, and Michael Mitzenmacher",
                "pub_date": "2021",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_143",
            "content": "Naigang Wang, Jungwook Choi, Daniel Brand, Chia-Yu Chen, Kailash Gopalakrishnan, Training deep neural networks with 8-bit floating point numbers, 2018, NIPS, .",
            "ntype": "ref",
            "meta": {
                "xid": "b41",
                "authors": [
                    "Naigang Wang",
                    "Jungwook Choi",
                    "Daniel Brand",
                    "Chia-Yu Chen",
                    "Kailash Gopalakrishnan"
                ],
                "title": "Training deep neural networks with 8-bit floating point numbers",
                "pub_date": "2018",
                "pub_title": "NIPS",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_144",
            "content": "UNKNOWN, None, 2018, Training and inference with integers in deep neural networks, .",
            "ntype": "ref",
            "meta": {
                "xid": "b42",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Training and inference with integers in deep neural networks",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_145",
            "content": "Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul Bennett, Junaid Ahmed, Arnold Overwikj, Approximate nearest neighbor negative contrastive learning for dense text retrieval, 2021, ICLR, .",
            "ntype": "ref",
            "meta": {
                "xid": "b43",
                "authors": [
                    "Lee Xiong",
                    "Chenyan Xiong",
                    "Ye Li",
                    "Kwok-Fung Tang",
                    "Jialin Liu",
                    "Paul Bennett",
                    "Junaid Ahmed",
                    "Arnold Overwikj"
                ],
                "title": "Approximate nearest neighbor negative contrastive learning for dense text retrieval",
                "pub_date": "2021",
                "pub_title": "ICLR",
                "pub": null
            }
        },
        {
            "ix": "166-ARR_v2_146",
            "content": "Peilin Yang, Hui Fang, Jimmy Lin, Anserini: Enabling the use of lucene for information retrieval research, 2017, Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '17, Association for Computing Machinery.",
            "ntype": "ref",
            "meta": {
                "xid": "b44",
                "authors": [
                    "Peilin Yang",
                    "Hui Fang",
                    "Jimmy Lin"
                ],
                "title": "Anserini: Enabling the use of lucene for information retrieval research",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '17",
                "pub": "Association for Computing Machinery"
            }
        },
        {
            "ix": "166-ARR_v2_147",
            "content": "Andrew Yates, Rodrigo Nogueira, Jimmy Lin, Pretrained transformers for text ranking: BERT and beyond, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Tutorials, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b45",
                "authors": [
                    "Andrew Yates",
                    "Rodrigo Nogueira",
                    "Jimmy Lin"
                ],
                "title": "Pretrained transformers for text ranking: BERT and beyond",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Tutorials",
                "pub": "Online. Association for Computational Linguistics"
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "166-ARR_v2_0@0",
            "content": "SDR: Efficient Neural Re-ranking using Succinct Document Representation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_0",
            "start": 0,
            "end": 70,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_2@0",
            "content": "BERT based ranking models have achieved superior performance on various information retrieval tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_2",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_2@1",
            "content": "However, the large number of parameters and complex self-attention operations come at a significant latency overhead.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_2",
            "start": 101,
            "end": 217,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_2@2",
            "content": "To remedy this, recent works propose late-interaction architectures, which allow precomputation of intermediate document representations, thus reducing latency.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_2",
            "start": 219,
            "end": 378,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_2@3",
            "content": "Nonetheless, having solved the immediate latency issue, these methods now introduce storage costs and network fetching latency, which limit their adoption in real-life production systems.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_2",
            "start": 380,
            "end": 566,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_3@0",
            "content": "In this work, we propose the Succinct Document Representation (SDR) scheme that computes highly compressed intermediate document representations, mitigating the storage/network issue.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_3",
            "start": 0,
            "end": 182,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_3@1",
            "content": "Our approach first reduces the dimension of token representations by encoding them using a novel autoencoder architecture that uses the document's textual content in both the encoding and decoding phases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_3",
            "start": 184,
            "end": 387,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_3@2",
            "content": "After this token encoding step, we further reduce the size of the document representations using modern quantization techniques.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_3",
            "start": 389,
            "end": 516,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_4@0",
            "content": "Evaluation on MSMARCO's passage rereranking task show that compared to existing approaches using compressed document representations, our method is highly efficient, achieving 4x-11.6x higher compression rates for the same ranking quality.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_4",
            "start": 0,
            "end": 238,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_4@1",
            "content": "Similarly, on the TREC CAR dataset, we achieve 7.7x higher compression rate for the same ranking quality.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_4",
            "start": 240,
            "end": 344,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_5@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_5",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_6@0",
            "content": "Information retrieval (IR) systems traditionally comprise of two stages: retrieval and ranking.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_6",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_6@1",
            "content": "Given a user query, the role of the retrieval stage is to quickly retrieve a set of candidate documents BERT SPLIT is a distilled late-interaction model with reduced vector width and no compression ( \u00a7 4.2).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_6",
            "start": 96,
            "end": 302,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_7@0",
            "content": "For MRR@10 above 0.35, SDR is 4x-11.6x more efficient compared to the baseline.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_7",
            "start": 0,
            "end": 78,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_8@0",
            "content": "from a (very large) search index.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_8",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_8@1",
            "content": "Retrieval is typically fast but not accurate enough; in order to improve the quality of the end result for the user, the candidate documents are re-ranked using a more accurate but computationally expensive algorithm.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_8",
            "start": 34,
            "end": 250,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_9@0",
            "content": "Neural approaches have achieved the state of the art ranking performance in IR applications (Yates et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_9",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_9@1",
            "content": "Transformer networks such as BERT (Devlin et al., 2019) consistently show better ranking effectiveness at the cost of a higher computational cost and latency .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_9",
            "start": 114,
            "end": 272,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_10@0",
            "content": "To rank k documents, the ranker is called k times with an input of the form (query, document), where the query is the same, but the document is different.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_10",
            "start": 0,
            "end": 153,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_10@1",
            "content": "Several works (MacAvaney et al., 2020;Gao et al., 2020b;Cao et al., 2020;Nie et al., 2020;Gao et al., 2020b;Khattab and Zaharia, 2020) have proposed to modify BERT-based rankers in a way that allows part of the model to compute query and document representations separately, and then produce the final score using a low-complexity interaction block; we denote these models as late-interaction rankers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_10",
            "start": 155,
            "end": 555,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_10@2",
            "content": "Such approaches pre-compute document representations to improve latency significantly.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_10",
            "start": 557,
            "end": 642,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_10@3",
            "content": "Next, at runtime the model computes the query representation (once), retrieves the precomputed document representations, and is only required to run a low-complexity interaction block k times to produce the final ranking score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_10",
            "start": 644,
            "end": 870,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_11@0",
            "content": "Precomputing document representations has shown to significantly reduce latency and at the same time retain comparable scores to BERT models (Gao et al., 2020b).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_11",
            "start": 0,
            "end": 160,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_11@1",
            "content": "However, this does not account for additional storage and/or network fetching latency costs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_11",
            "start": 162,
            "end": 253,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_11@2",
            "content": "The representations typically consist of the contextual token embeddings in a transformer model, which consume orders of magnitude more storage than storing the entire corpus search index (cf. \u00a7 5.1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_11",
            "start": 255,
            "end": 454,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_12@0",
            "content": "In this work, we propose Succinct Document Representation (SDR), a general scheme for compressing document representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_12",
            "start": 0,
            "end": 122,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_12@1",
            "content": "It enables lateinteraction rankers to be efficient in both latency and storage, while maintaining high ranking quality.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_12",
            "start": 124,
            "end": 242,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_12@2",
            "content": "SDR is suitable for any ranking scheme that uses contextual embeddings, and achieves extreme compression ratios (2-3 orders of magnitude) with little to no impact on retrieval accuracy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_12",
            "start": 244,
            "end": 428,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_12@3",
            "content": "SDR consists of two major components: (1) embedding dimension reduction using an autoencoder with side information and (2) distribution-optimized quantization of the reduced-dimension vectors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_12",
            "start": 430,
            "end": 621,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_13@0",
            "content": "In SDR, the autoencoder consists of two subnetworks: an encoder that reduces the vector's dimensions and a decoder that reconstructs the compressed vector.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_13",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_13@1",
            "content": "The encoder's output dimension represents the tradeoff between reconstruction fidelity and storage requirements.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_13",
            "start": 156,
            "end": 267,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_13@2",
            "content": "To improve the compression-reliability tradeoff, we leverage static token embeddings, which are available since the ranker has access to the document text (as it needs to render it to the user), and are computationally cheap to obtain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_13",
            "start": 269,
            "end": 503,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_13@3",
            "content": "We feed these embeddings to both the encoder and decoder as side information, allowing the autoencoder to focus more on storing \"just the context\" of a token, and less on its original meaning that is available in the static embeddings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_13",
            "start": 505,
            "end": 739,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_13@4",
            "content": "Ablation tests verify that adding the static vectors significantly improves the compression rates for the same ranking accuracy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_13",
            "start": 741,
            "end": 868,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_14@0",
            "content": "Since data storage is measured in bits rather than floating-point numbers, SDR uses quantization techniques to reduce storage size further.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_14",
            "start": 0,
            "end": 138,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_14@1",
            "content": "Given that it is hard to evaluate the amount of information in each of the encoder's output dimensions, we perform a randomized Hadamard transform on the vectors, resulting in (1) evenly spread information across all coordinates and (2) transformed vectors that follow a Gaussian-like distribution.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_14",
            "start": 140,
            "end": 437,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_14@2",
            "content": "We utilize known quantization techniques to represent these vectors using a small number of bits, controlling for the amount of quantization distortion.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_14",
            "start": 439,
            "end": 590,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_15@0",
            "content": "Existing late-interaction schemes either ignore the storage overhead, or consider basic compression techniques, such as a simple (1 layer) autoencoder and float16 quantization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_15",
            "start": 0,
            "end": 175,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_15@1",
            "content": "However, this is insufficient to reach reasonable storage size (MacAvaney et al., 2020); furthermore, this results in an increased fetching latency.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_15",
            "start": 177,
            "end": 324,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_15@2",
            "content": "For the MSMARCO dataset, we used a distilled model with a reduced vector width (Hofst\u00e4tter et al., 2020a) as the initial pre-trained weights for the late-interaction model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_15",
            "start": 326,
            "end": 497,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_15@3",
            "content": "On top of this, we used a non-linear autoencoder consisting of 2 dense layers followed by float16 quantization, a natural extension of MacAvaney et al. (2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_15",
            "start": 499,
            "end": 657,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_15@4",
            "content": "This baseline achieves compression rates of 30x with no noticeable reduction in retrieval accuracy (measured with the official MRR@10 metric).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_15",
            "start": 659,
            "end": 800,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_15@5",
            "content": "In comparison with this strong baseline, our SDR scheme achieves an additional compression rate of between 4x to 11.6x with the same ranking quality, reducing document representation size to the same order of magnitude as the retrieved text itself.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_15",
            "start": 802,
            "end": 1049,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_15@6",
            "content": "In Figure 1 we include a high-level presentation of the baseline, a variant of our method with float16 quantization, and our full method.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_15",
            "start": 1051,
            "end": 1187,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_15@7",
            "content": "For the TREC CAR dataset, for which we do not have a reduced-width baseline, we used a BERT model as the pre-trained weights for the late-interaction model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_15",
            "start": 1189,
            "end": 1344,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_15@8",
            "content": "The baseline with 2 dense layers and float16 quantization achieves a 30x compression rates with a slight reduction in accuracy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_15",
            "start": 1346,
            "end": 1472,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_15@9",
            "content": "The SDR scheme reaches the same quality while improving compression rate by another 7.7x.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_15",
            "start": 1474,
            "end": 1562,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_16@0",
            "content": "To summarize, here are the contribution of this work 1 :",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_16",
            "start": 0,
            "end": 55,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_17@0",
            "content": "\u2022 We propose the Succinct Document Representation (SDR) scheme for compressing the document representations required for fast Transformer-based rankers. The scheme is based on a specialized autoencoder architecture and subsequent quantization. \u2022 For the MSMARCO passage retrieval task, SDR shows compression ratios of 121x with no noticeable decrease in ranking performance. Compared to existing approaches for producing compressed representations, our method attains better compression rates (between 4x and 11.6x) for the same ranking quality. Similar results are demonstrated on the TREC CAR dataset. \u2022 We provide a thorough analysis of the SDR system, showing that the contribution of each of the components to the compression-ranking effectiveness is significant.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_17",
            "start": 0,
            "end": 767,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_18@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_18",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_19@0",
            "content": "Late-interaction models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_19",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_19@1",
            "content": "The idea of running several transformer layers for the document and the query independently, and then combining them in the last transformer layers, was developed concurrently by multiple teams: PreTTR (MacAvaney et al., 2020), EARL (Gao et al., 2020a), DC-BERT (Nie et al., 2020), DiPair , and the Deformer (Cao et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_19",
            "start": 25,
            "end": 351,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_19@2",
            "content": "These works show that only a few layers where the query and document interact are sufficient to achieve results close to the performance of a full BERT ranker at a fraction of the runtime cost.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_19",
            "start": 353,
            "end": 545,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_19@3",
            "content": "For each document, the contextual token vectors are stored in a cache and retrieved during the document ranking phase.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_19",
            "start": 547,
            "end": 664,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_19@4",
            "content": "This impacts both storage cost as well as latency cost of fetching these vectors during the ranking phase.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_19",
            "start": 666,
            "end": 771,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_19@5",
            "content": "MORES (Gao et al., 2020b), extends lateinteraction models, where in the last interaction layers only the query attends to the document (and not vice-versa).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_19",
            "start": 773,
            "end": 928,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_19@6",
            "content": "As document are typically much longer, this results in additional performance improvements with similar storage requirements.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_19",
            "start": 930,
            "end": 1054,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_19@7",
            "content": "Col-BERT (Khattab and Zaharia, 2020) is another variant that runs all transformer layers independently for the query and the document, and the interaction between the final vectors is done through a sumof-max operator.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_19",
            "start": 1056,
            "end": 1273,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_19@8",
            "content": "A similar work, the Transformer-Kernel (TK) (Hofst\u00e4tter et al., 2020b), has an interaction block based on a low-complexity kernel operation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_19",
            "start": 1275,
            "end": 1414,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_19@9",
            "content": "Both ColBERT and TK result in models with lower runtime latency at the expense of a drop in ranking quality.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_19",
            "start": 1416,
            "end": 1523,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_19@10",
            "content": "However, the storage requirements for both approaches are still significant.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_19",
            "start": 1525,
            "end": 1600,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_19@11",
            "content": "Some of the works above acknowledge the issue of storing the precomputed document representations and proposed partial solutions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_19",
            "start": 1602,
            "end": 1730,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_19@12",
            "content": "In Col-BERT (Khattab and Zaharia, 2020), the authors proposed to reduce the dimension of the final token embedding using a linear layer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_19",
            "start": 1732,
            "end": 1867,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_19@13",
            "content": "However, even moderate compression ratios caused a large drop in ranking quality.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_19",
            "start": 1869,
            "end": 1949,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_19@14",
            "content": "In the PreTTR model (MacAvaney et al., 2020), it was proposed to address the storage cost by using a standard auto-encoder architecture and the float16 format instead of float32.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_19",
            "start": 1951,
            "end": 2128,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_19@15",
            "content": "Again, the ranking quality drops even with moderate compression ratios (they measured up to 12x).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_19",
            "start": 2130,
            "end": 2226,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_20@0",
            "content": "Several other works (Guu et al., 2020;Karpukhin et al., 2020;Xiong et al., 2021;Qu et al., 2020;Lu et al., 2020) proposed representing the queries and documents as vectors (as opposed to a vector per token), and using dot product as the interaction block.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_20",
            "start": 0,
            "end": 254,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_20@1",
            "content": "While this ranker architecture approach is simple (and can also be used for the retrieval step via an approximate nearest neighbor search such as FAISS (Johnson et al., 2017), ScaNN (Guo et al., 2020) or the Pinecone managed service 2 ), the overall ranking quality is generally lower compared to methods that employ a query-document crossattention interaction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_20",
            "start": 256,
            "end": 616,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_20@2",
            "content": "For that reason these methods are used mainly for first-stage retrieval, followed by a reranking step.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_20",
            "start": 618,
            "end": 719,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_21@0",
            "content": "Compressed embeddings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_21",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_21@1",
            "content": "Our work reduces storage requirements by reducing the number of bits per floating-point value.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_21",
            "start": 23,
            "end": 116,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_21@2",
            "content": "Quantization gained attention and success in reducing the size of neural network parameters (Gupta et al., 2015;Essam et al., 2017;Wang et al., 2018;Wu et al., 2018) and distributed learning communication costs (Suresh et al., 2017;Alistarh et al., 2017;Kone\u010dn\u1ef3 and Richt\u00e1rik, 2018;Vargaftik et al., 2021Vargaftik et al., , 2022.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_21",
            "start": 118,
            "end": 446,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_21@3",
            "content": "Specifically, compressing word embeddings has been studied as an independent goal.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_21",
            "start": 448,
            "end": 529,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_21@4",
            "content": "May et al. (2019) studied the effect of quantized word embeddings on downstream applications and proposed a metric for quantifying this effect with simple linear models that operate on the word embeddings directly.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_21",
            "start": 531,
            "end": 744,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_21@5",
            "content": "As our work is concerned with compressing contextual embeddings, these methods do not apply since the set of possible embeddings values is not bounded by the vocabulary size.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_21",
            "start": 746,
            "end": 919,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_21@6",
            "content": "Nevertheless, as in (May et al., 2019), we also observe that simple quantization schemes are quite effective.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_21",
            "start": 921,
            "end": 1029,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_21@7",
            "content": "Our work uses recent advances in this area to further reduce storage requirements for document representation, which, to the best of our knowledge, were not previously attempted in this context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_21",
            "start": 1031,
            "end": 1224,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_22@0",
            "content": "Succinct Document Representation (SDR)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_22",
            "start": 0,
            "end": 37,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_23@0",
            "content": "Our work is based on the late-interaction architecture (MacAvaney et al., 2020;Gao et al., 2020b;Cao et al., 2020;Nie et al., 2020), which separates BERT into L independent layers for the documents and the queries, and T \u2212 L interleaving layers, where T is the total number of layers in the original model, e.g., 12 for BERT-Base.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_23",
            "start": 0,
            "end": 329,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_23@1",
            "content": "Naively storing all documents embeddings consumes a huge amount of storage with a total of m \u2022 h \u2022 4 bytes per document, where m is the average number of tokens per document and h is the model hidden size (384 for the distilled version and 768 for the BERT version).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_23",
            "start": 331,
            "end": 596,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_23@2",
            "content": "For MSMARCO, with 8.8M documents and m = 76.9, it leads to a high storage cost of over a terabyte, which is not affordable except in large production systems.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_23",
            "start": 598,
            "end": 755,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_24@0",
            "content": "Our compression scheme for the document representations consists of two sequential steps, (i) dimensionality reduction and (ii) block-wise quantization, described in \u00a7 3.1 and \u00a7 3.2 respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_24",
            "start": 0,
            "end": 194,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_25@0",
            "content": "Dimensionality Reduction using AutoEncoders with Side Information (AESI)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_25",
            "start": 0,
            "end": 71,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_26@0",
            "content": "To compress document representations, we reduce the dimensionality of token representations (i.e., the output of BERT's L-th layer) using an autoencoder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_26",
            "start": 0,
            "end": 152,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_26@1",
            "content": "Standard autoencoder architectures typically consist of a neural network split into an encoder and a decoder: the encoder projects the input vector into a lower-dimension vector, which is then reconstructed back using the decoder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_26",
            "start": 154,
            "end": 383,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_26@2",
            "content": "Our architecture, AESI, extends the standard autoencoder by using the document's text as side information to both the encoder and decoder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_26",
            "start": 385,
            "end": 522,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_26@3",
            "content": "Such an approach is possible since, no matter how the document scores are computed, re-ranking systems have access to the document's text in order to render it back to the user.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_26",
            "start": 524,
            "end": 700,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_26@4",
            "content": "In the rest of this section, we add the precise details of the AESI architecture.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_26",
            "start": 702,
            "end": 782,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_27@0",
            "content": "Side Information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_27",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_27@1",
            "content": "In line with our observation that the ranker has access to the document's raw text, we propose utilizing the token embedding information, which is computed by the embedding layer used in BERT's architecture.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_27",
            "start": 18,
            "end": 224,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_27@2",
            "content": "The token embeddings encode rich semantic information about the token itself; however, they do not fully capture the context in which they occur; hence, we refer to them as static embeddings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_27",
            "start": 226,
            "end": 416,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_27@3",
            "content": "For example, through token embeddings, we cannot disambiguate between the different meanings of the token bank, which can refer to either a geographical location (e.g., \"river bank\") or a financial institution, depending on the context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_27",
            "start": 418,
            "end": 653,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_28@0",
            "content": "Static embeddings are key for upper BERT layers, which learn the contextual representation of tokens via the self-attention mechanism.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_28",
            "start": 0,
            "end": 133,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_28@1",
            "content": "We use the static embeddings as side information to both the encoder and decoder parts of the autoencoder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_28",
            "start": 135,
            "end": 240,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_28@2",
            "content": "This allows the model to focus on encoding the distilled context, and less on the token information since it is already provided to the decoder directly.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_28",
            "start": 242,
            "end": 394,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_29@0",
            "content": "AESI Approach.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_29",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_29@1",
            "content": "For a token whose representation we wish to compress, our approach proceeds as follows.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_29",
            "start": 15,
            "end": 101,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_29@2",
            "content": "We take the L-th layer's output contextual representation of the token together with its static embedding and feed both inputs to the autoencoder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_29",
            "start": 103,
            "end": 248,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_29@3",
            "content": "The information to be compressed (and reconstructed) is the contextual embedding, and the side-information, which aids in the compression task, is the static embedding.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_29",
            "start": 250,
            "end": 417,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_29@4",
            "content": "The decoder takes the encoder output, along with the static embedding, and attempts to reconstruct the contextual embedding.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_29",
            "start": 419,
            "end": 542,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_29@5",
            "content": "Figure 2 shows the AESI architecture.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_29",
            "start": 544,
            "end": 580,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_30@0",
            "content": "AESI approach has two parameters that are determined empirically.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_30",
            "start": 0,
            "end": 64,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_30@1",
            "content": "First, the L-th transformer layer of the contextual representation provided as input, which has a direct impact on latency 3 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_30",
            "start": 66,
            "end": 191,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_30@2",
            "content": "Second, the size of the encoder's output directly impacts the compression rate and thus storage costs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_30",
            "start": 193,
            "end": 294,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_31@0",
            "content": "Encoding starts by concatenating the input vector (i.e., the output of layer L, the vector we compress) and the static token embedding (i.e., the output of BERT's embedding layer), and then passes the concatenated vector through an encoder network, which outputs a c-dimensional encoded vector.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_31",
            "start": 0,
            "end": 293,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_31@1",
            "content": "Decoding starts by concatenating the encoded vector with the static token embedding, then passes the concatenated vector through a decoder layer, which reconstructs the input vector.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_31",
            "start": 295,
            "end": 476,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_31@2",
            "content": "Specifically, we use a two-layer dense network for both the encoder and the decoder, which can be written using the following formula:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_31",
            "start": 478,
            "end": 611,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_32@0",
            "content": "e = E(v, u) := W e 2 \u2022 gelu W e 1 (v; u) (1) v = D(e, u) := W d 2 \u2022 gelu W d 1 (e; u)(2)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_32",
            "start": 0,
            "end": 87,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_33@0",
            "content": "where v \u2208 R h is the contextualized token embedding (the output of the L-th layer), u \u2208 R h is the static token embedding (the output of the embedding layer, which is the input to BERT's layer 0 and includes token position embeddings and type embeddings), and u; v means concatenation of these vectors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_33",
            "start": 0,
            "end": 301,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_34@0",
            "content": "W e 1 \u2208 R i\u00d72h , W e 2 \u2208 R c\u00d7i , W d 1 \u2208 R i\u00d7(c+h) , W d 2 \u2208 R h\u00d7i are trainable param- eters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_34",
            "start": 0,
            "end": 93,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_35@0",
            "content": "h is the dimension of token embeddings (e.g., 384), i is the intermediate autoencoder size, and c is the dimension of the projected (encoded) vector.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_35",
            "start": 0,
            "end": 148,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_35@1",
            "content": "gelu(\u2022) is an non-linear activation function (Hendrycks and Gimpel, 2016).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_35",
            "start": 150,
            "end": 223,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_35@2",
            "content": "Additional autoencoder variations are explored in \u00a7 5.3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_35",
            "start": 225,
            "end": 280,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_36@0",
            "content": "Quantization",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_36",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_37@0",
            "content": "Storing the compressed contextual representations in a naive way consumes 32 bits (float32) per coordinate per token, which is still costly.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_37",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_37@1",
            "content": "To further reduce storage overhead, we propose to apply a quantization technique, which uses a predetermined B bits per coordinate.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_37",
            "start": 141,
            "end": 271,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_37@2",
            "content": "However, different coordinates and different tokens have different importance and possibly also different scales, so using the same number of bits and same quantization threshold for all of them increases the quantization error.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_37",
            "start": 273,
            "end": 500,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_38@0",
            "content": "To remedy this issue, we follow an approach similar to EDEN quantization (Vargaftik et al., 2022), which uses a randomized Hadamard transform prior to quantization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_38",
            "start": 0,
            "end": 163,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_38@1",
            "content": "Loosely speaking, this shuffles the information across all coordinates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_38",
            "start": 165,
            "end": 235,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_38@2",
            "content": "Furthermore, each of the coordinates is guaranteed to follow Gaussian-like distribution, for which quantization boundaries can be computed optimally.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_38",
            "start": 237,
            "end": 385,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_38@3",
            "content": "For the sake of brevity, the full description of the quantization algorithm is deferred to Appendix A.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_38",
            "start": 387,
            "end": 488,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_39@0",
            "content": "Efficiently applying the Hadamard transform requires the size of the input to be a power of two.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_39",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_39@1",
            "content": "In addition, the input dimension should be large enough (specifically, larger than the output of AESI) so that information can be shuffled effectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_39",
            "start": 97,
            "end": 247,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_39@2",
            "content": "Therefore, we concatenate the AESI vectors of all tokens from a single document, then segment it to a larger block size (we use 128), padding the last block with zeros when necessary.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_39",
            "start": 249,
            "end": 431,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_39@3",
            "content": "The padding slightly increases space requirements and is considered when evaluating the compression efficiency.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_39",
            "start": 433,
            "end": 543,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_40@0",
            "content": "Experimental Settings",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_40",
            "start": 0,
            "end": 20,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_41@0",
            "content": "In this section we describe the datasets used to evaluate the competing approaches for ranking documents given a query.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_41",
            "start": 0,
            "end": 118,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_41@1",
            "content": "Next, we describe the baseline and the different configurations of SDR with emphasis on how we measure the compression ratio.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_41",
            "start": 120,
            "end": 244,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_42@0",
            "content": "Tasks and Datasets",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_42",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_43@0",
            "content": "To evaluate the effectiveness of our proposed approach (SDR) and the competing baseline, we consider two information retrieval datasets, each with different characteristics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_43",
            "start": 0,
            "end": 172,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_43@1",
            "content": "MSMARCO passage re-ranking In this task (Nguyen et al., 2016), we are given a query and a list of 1,000 passages (retrieved via BM25), and the task is to rerank the passages according to their relevance to the query.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_43",
            "start": 174,
            "end": 389,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_43@2",
            "content": "The corpus consists of 8.8M passages, downloaded from the web.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_43",
            "start": 391,
            "end": 452,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_43@3",
            "content": "We consider two query sets:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_43",
            "start": 454,
            "end": 480,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_44@0",
            "content": "(1) MSMARCO-DEV, the development set for the MSMARCO passage reranking task, which consists of 6,980 queries.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_44",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_44@1",
            "content": "On average, each query has a single relevant passage, and other passages are not annotated.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_44",
            "start": 110,
            "end": 200,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_44@2",
            "content": "The models are measured using the mean reciprocal rank metric (MRR@10).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_44",
            "start": 202,
            "end": 272,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_45@0",
            "content": "(2) TREC 2019 DL Track.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_45",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_45@1",
            "content": "Here we consider the test queries from TREC 2019 DL Track passage reranking dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_45",
            "start": 24,
            "end": 107,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_45@2",
            "content": "Unlike MSMARCO-DEV, there are multiple passages annotated for each query with graded relevance labels (instead of binary labels), allowing us to use the more informative nDCG@10 metric.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_45",
            "start": 109,
            "end": 293,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_45@3",
            "content": "Due to the excessive annotation overhead, this dataset consists of just 200 queries, so results are noisier compared to MSMARCO-DEV.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_45",
            "start": 295,
            "end": 426,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_45@4",
            "content": "TREC Complex Answer Retrieval (CAR) is a dataset (Dietz et al., 2017) curated from Wikipedia.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_45",
            "start": 428,
            "end": 520,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_45@5",
            "content": "It maps from article and section titles to relevant paragraphs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_45",
            "start": 522,
            "end": 584,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_45@6",
            "content": "Following , we use the automatic by-article annotations variant, which considers all paragraphs within the same article as relevant.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_45",
            "start": 586,
            "end": 717,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_45@7",
            "content": "The dataset consists of 30M passages, making storage requirements a more significant challenge compared to the MSMARCO task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_45",
            "start": 719,
            "end": 842,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_45@8",
            "content": "The test query set consists of 2,254 queries with an average of 2.74 positive passages per query.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_45",
            "start": 844,
            "end": 940,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_45@9",
            "content": "We use the MAP@1K official metric.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_45",
            "start": 942,
            "end": 975,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_46@0",
            "content": "For both datasets, in addition to the quality metrics, we also measure the Compression Ratio (CR) as the amount of storage required to store the token embeddings when compared to the baseline model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_46",
            "start": 0,
            "end": 197,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_46@1",
            "content": "E.g., CR = 10 implies storage size that is one tenth of the baseline vectors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_46",
            "start": 199,
            "end": 275,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_47@0",
            "content": "Baseline -BERT SPLIT",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_47",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_48@0",
            "content": "Our algorithm is based on the late-interaction architecture (MacAvaney et al., 2020;Gao et al., 2020a;Nie et al., 2020;Cao et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_48",
            "start": 0,
            "end": 136,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_48@1",
            "content": "We created a model based on this architecture, which we name BERT SPLIT , consisting of 10 layers that are computed independently for the query and the document with an additional two late-interaction layers that are executed jointly.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_48",
            "start": 138,
            "end": 371,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_48@2",
            "content": "For MSMARCO, we initialized the model from reduced width pre-trained weights 4 and fine-tuned it using knowledge distillation from an ensemble of BERT-Large, BERT-Base, and ALBERT-Large (Hofst\u00e4tter et al., 2020b) on the MSMARCO small training dataset, which consists of almost 40M tuples of query, a relevant document, and an irrelevant document.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_48",
            "start": 373,
            "end": 718,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_48@3",
            "content": "For CAR, the model is initialized from pre-trained BERT-base model and trained on 50M samples curated by .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_48",
            "start": 720,
            "end": 825,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_49@0",
            "content": "SDR Configuration and Training",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_49",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_50@0",
            "content": "We trained autoencoder variants on a random subset of 500k documents to reduce training time.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_50",
            "start": 0,
            "end": 92,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_50@1",
            "content": "We incorporate the quantization overhead into the computation of the compression ratios, including metadata and the overhead of padding (cf. Appendix A).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_50",
            "start": 94,
            "end": 246,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_51@0",
            "content": "In the following sections, we denote the SDR variants as \"AESI-{c}-{B}b\" where {c} is replaced with the width of the encoded vector and {B} is replaced with the number of bits in the quantization scheme.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_51",
            "start": 0,
            "end": 202,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_51@1",
            "content": "When discussing AESI with no quantization, we simply write \"AESI-{c}\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_51",
            "start": 204,
            "end": 273,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_52@0",
            "content": "End to end Latency Measurement",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_52",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_53@0",
            "content": "To measure end to end latency, we configured an OpenSearch 5 cluster in AWS.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_53",
            "start": 0,
            "end": 75,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_53@1",
            "content": "We used default \"production\" configurations, with 3 r6g.large datanode machines; disk space was set to 0.5TB.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_53",
            "start": 77,
            "end": 185,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_53@2",
            "content": "For ranking, we used a single g4dn.xlarge machine, featuring a single T4 GPU instance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_53",
            "start": 187,
            "end": 272,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_53@3",
            "content": "This makes the cost of these two components similar.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_53",
            "start": 274,
            "end": 325,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_54@0",
            "content": "Evaluation Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_54",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_55@0",
            "content": "In this section, we present the end to end latency results ( \u00a7 5.1), show compression ratios and quality tradeoff of the SDR scheme ( \u00a7 5.2).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_55",
            "start": 0,
            "end": 140,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_55@1",
            "content": "We then examine how the proposed autoencoder ( \u00a7 5.3) compares with other baselines and present additional measurements ( \u00a7 5.4).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_55",
            "start": 142,
            "end": 270,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_56@0",
            "content": "End to End Latency Evaluation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_56",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_57@0",
            "content": "Table 1 (top) shows the latency benefits of SDR on the MSMARCO dataset, assuming document embeddings are stored in the OpenSearch retrieval system and 1k documents are retrieved per query.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_57",
            "start": 0,
            "end": 187,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_57@1",
            "content": "The Distilbert model (full interaction architecture) has the highest quality and smallest index size (since it is only executed online).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_57",
            "start": 189,
            "end": 324,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_57@2",
            "content": "However, ranking latency is prohibitively expensive.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_57",
            "start": 326,
            "end": 377,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_57@3",
            "content": "As a baseline, we use a late interaction model, a two-layer autoencoder with code dimension 24 and float16 quantization, denoted Late+AE-24.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_57",
            "start": 379,
            "end": 518,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_57@4",
            "content": "For this baseline, the ranking latency is significantly reduced at a cost in terms of quality.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_57",
            "start": 520,
            "end": 613,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_57@5",
            "content": "However, the document representation is large, causing retrieval and overall latency to increase to 0.7 and 1.22 seconds, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_57",
            "start": 615,
            "end": 749,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_57@6",
            "content": "SDR, with a dimension of 16 and 6-bits quantization, reaches the same quality as the baseline while striking a better balance between retrieval and ranking latency, reaching overall latency of 1.1 seconds.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_57",
            "start": 751,
            "end": 955,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_57@7",
            "content": "The index size is also significantly reduced compared to the baseline compression algorithm.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_57",
            "start": 957,
            "end": 1048,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_58@0",
            "content": "We also consider variants of the algorithms where the documents are pre-tokenized, and the tokenization output is retrieved instead of computing at runtime (marked as +tok in the table).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_58",
            "start": 0,
            "end": 185,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_58@1",
            "content": "This further improves the ranking latency at the expense of a slight increase in index size.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_58",
            "start": 187,
            "end": 278,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_58@2",
            "content": "Note that the baseline does not use the raw text and therefore does not benefit from precomputed tokens.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_58",
            "start": 280,
            "end": 383,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_59@0",
            "content": "Table 1 (bottom) shows the latency results on the CAR dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_59",
            "start": 0,
            "end": 61,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_59@1",
            "content": "Here too, the BERT baseline has the highest ranking quality, at the cost of prohibitive latency.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_59",
            "start": 63,
            "end": 158,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_59@2",
            "content": "The late interaction variants we consider have the same configuration as in the MS-MARCO case, where the baseline uses 24 features (with float16 quantization) and SDR uses 16 features (with 6 bits EDEN quantization).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_59",
            "start": 160,
            "end": 375,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_59@3",
            "content": "Unlike in the MSMARCO case, the quality (i.e., MAP@1k score) of these two options is not similar.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_59",
            "start": 377,
            "end": 473,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_59@4",
            "content": "This makes SDR better than the baseline in latency, index size, as well as quality (by a large margin of over 14%).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_59",
            "start": 475,
            "end": 589,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_60@0",
            "content": "In Appendix D we explore additional configurations and show that the baseline with 52 features reaches the same quality as SDR-16-6b.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_60",
            "start": 0,
            "end": 132,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_60@1",
            "content": "However, we do not measure end-to-end latency for this case due to the excessive storage size and indexing time.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_60",
            "start": 134,
            "end": 245,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_60@2",
            "content": "Note that using 52 features for the baseline is expected to have a negative impact on retrieval latency, making the benefits of SDR even more pronounced.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_60",
            "start": 247,
            "end": 399,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_61@0",
            "content": "Compression Rate and Quality Tradeoff",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_61",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_62@0",
            "content": "Table 2 shows the results on the MSMARCO query sets for SDR and its compression ratio against storing contextual token embeddings uncompressed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_62",
            "start": 0,
            "end": 142,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_62@1",
            "content": "In terms of compression ratio, it can be seen that AESI allows us to massively reduce storage requirements both with and without quantization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_62",
            "start": 144,
            "end": 285,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_63@0",
            "content": "AESI-16-6b reduces storage requirements by 121x, while at the same time showing no significant ranking performance drop.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_63",
            "start": 0,
            "end": 119,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_63@1",
            "content": "Using AESI-16-6b, a document's embedding can be stored with only 947 bytes and the entire MSMARCO collection can be stored within 8.6GB.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_63",
            "start": 121,
            "end": 256,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_63@2",
            "content": "There are several advantages of fitting the entire collection's representation into the main memory of the hosting machine, allowing for fast access, further fine-tuning, etc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_63",
            "start": 258,
            "end": 432,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_63@3",
            "content": "If further compression rates are required, AESI-8-5b uses just 5 bytes per token, reaching a compression rate of 277x and 487 bytes per document on average.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_63",
            "start": 434,
            "end": 589,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_63@4",
            "content": "At this level of compression, the entire MSMARCO corpus fits in 3.8GB.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_63",
            "start": 591,
            "end": 660,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_63@5",
            "content": "The MRR@10 drop is noticeable (0.0119) but still quite low.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_63",
            "start": 662,
            "end": 720,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_63@6",
            "content": "Finally, for TREC19-DL, the impact of compressing token embeddings is less evident.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_63",
            "start": 722,
            "end": 804,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_63@7",
            "content": "Only in the most extreme cases such as AESI-4-4b we see a significant drop in nDCG@10 performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_63",
            "start": 806,
            "end": 903,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_63@8",
            "content": "These results demonstrate that the performance drop is very small, showing the effectiveness of our method.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_63",
            "start": 905,
            "end": 1011,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_64@0",
            "content": "Autoencoder Evaluation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_64",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_65@0",
            "content": "To better understand the impact of the autoencoder, we present MRR@10 results as a function of autoencoder dimensions (i.e., number of floats stored per token) and with the different autoencoder configurations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_65",
            "start": 0,
            "end": 209,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_65@1",
            "content": "In addition to the 2-layer AESI architecture we described in \u00a7 3.1 (AESI-2L), we consider the following variations: AutoEncoder with 2 Layers (AE-2L).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_65",
            "start": 211,
            "end": 360,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_65@2",
            "content": "Standard 2-layer autoencoder with gelu activation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_65",
            "start": 362,
            "end": 411,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_65@3",
            "content": "This is the same as AESI, only without the side information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_65",
            "start": 413,
            "end": 472,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_66@0",
            "content": "AutoEncoder with 1 Layer (AE-1L).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_66",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_66@1",
            "content": "Standard autoencoder with a single dense layer in the encoder and decoder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_66",
            "start": 34,
            "end": 107,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_67@0",
            "content": "AESI with 1 Layer (AESI-1L).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_67",
            "start": 0,
            "end": 27,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_67@1",
            "content": "AESI with a single dense encoder and decoder layer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_67",
            "start": 29,
            "end": 79,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_68@0",
            "content": ").",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_68",
            "start": 0,
            "end": 1,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_68@1",
            "content": "Provides side information to the decoder but not the encoder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_68",
            "start": 3,
            "end": 63,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_69@0",
            "content": "To reduce measurement overhead, we ran the experiment only over the MSMARCO dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_69",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_69@1",
            "content": "In addition, we took only the top 25 BERT SPLIT passages for each query, denoted MSMARCO-DEV-25, which has a negligible impact on the results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_69",
            "start": 85,
            "end": 226,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_69@2",
            "content": "Figure 3 shows the results for the different autoencoder configurations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_69",
            "start": 228,
            "end": 299,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_69@3",
            "content": "Providing the side information to the autoencoder proves to be very effective in reducing storage costs, especially when the encoded vector size is small.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_69",
            "start": 301,
            "end": 454,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_69@4",
            "content": "A 2-layer encoder/decoder model, as expected, is more effective than a singlelayer model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_69",
            "start": 456,
            "end": 544,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_69@5",
            "content": "The gap is especially large when using side information, showing that the interaction between the encoded vector and the static token embeddings is highly nonlinear.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_69",
            "start": 546,
            "end": 710,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_69@6",
            "content": "Finally, providing the static embeddings only to the decoder is slightly inferior to providing it also to the encoder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_69",
            "start": 712,
            "end": 829,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_70@0",
            "content": "Additional Measurements",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_70",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_71@0",
            "content": "Quantization Techniques we compare the quantization technique we use to several other techniques, including Deterministic Rounding (Gersho and Gray, 1992), Stochastic Rounding (Connolly et al., 2021), and Subtractive Dithering (Roberts, 1962;Gray and Stockham, 1993).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_71",
            "start": 0,
            "end": 266,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_71@1",
            "content": "Due to lack of space, the results appear in Appendix B. We found that a randomized Hadamard transform improves quality (assuming similar bit rate), especially in the low-bits regime.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_71",
            "start": 268,
            "end": 449,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_71@2",
            "content": "Using a quantization technique fitted to the Gaussian distribution of post randomized Hadamard transform data further improve quality, making the EDEN quantization superior to other quantization techniques in our case.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_71",
            "start": 451,
            "end": 668,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_72@0",
            "content": "Our scheme uses a fixed number of bits per coordinate, which is essential for performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_72",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_72@1",
            "content": "However, variable-rate compression can further reduce storage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_72",
            "start": 91,
            "end": 152,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_72@2",
            "content": "We used rate-distortion theory (from the information theory field) to upper bound the benefits of such techniques by 11%, which does not seem to justify the added system complexity (cf. Appendix B).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_72",
            "start": 154,
            "end": 351,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_73@0",
            "content": "To better understand the impact of side information, we measure the error rate between an input vector and its reconstructed vector (i.e., after encoding and decoding).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_73",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_73@1",
            "content": "As expected, in practically all cases, adding the side information reduces error rate compared to a 2-layer autoencoder (AE-2L) with the same code dimension.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_73",
            "start": 169,
            "end": 325,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_74@0",
            "content": "In IR, the document frequency of a token is known to be negatively correlated with the token's importance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_74",
            "start": 0,
            "end": 105,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_74@1",
            "content": "We found that the error rate for AE-2L decreases with frequency, while the error rate for AESI increases with frequency.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_74",
            "start": 107,
            "end": 226,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_74@2",
            "content": "This shows that the AESI scheme can better focus on tokens that are important for ranking.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_74",
            "start": 228,
            "end": 317,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_74@3",
            "content": "A possible explanation for this phenomena is that the static embeddings for infrequent tokens are more informative (i.e., more helpful as side information) compared to static embeddings for frequent tokens (e.g., 'the').",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_74",
            "start": 319,
            "end": 538,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_74@4",
            "content": "We also found AESI excels more in compressing nouns, verbs, and adjectives, while AE-2L excels more in compressing punctuation, determiners, and adpositions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_74",
            "start": 540,
            "end": 696,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_74@5",
            "content": "Again, this demonstrate that the static embeddings is most helpful in encoding tokens that are crucial for ranking.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_74",
            "start": 698,
            "end": 812,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_74@6",
            "content": "The details of this evaluation are provided in Appendix C.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_74",
            "start": 814,
            "end": 871,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_75@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_75",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_76@0",
            "content": "In this paper, we proposed a system called SDR to solve the storage cost and latency overhead of existing late-interaction transformer based models for passage re-ranking.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_76",
            "start": 0,
            "end": 170,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_76@1",
            "content": "The SDR scheme uses a novel autoencoder architecture that uses static token embeddings as side information to improve encoding quality.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_76",
            "start": 172,
            "end": 306,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_76@2",
            "content": "In addition, we explored different quantization techniques and showed that the recently proposed EDEN performs well in our use case and presented extensive experimentation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_76",
            "start": 308,
            "end": 479,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_76@3",
            "content": "Overall, the SDR scheme reduces pre-computed document representation size by 4x-11.6x compared to a baseline that uses existing approaches.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_76",
            "start": 481,
            "end": 619,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_77@0",
            "content": "In future work, we plan to continue investigating means to reduce pre-computed document representation size.We believe that additional analysis of BERT's vector and their interaction with the context would be fundamental in such an advancement.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_77",
            "start": 0,
            "end": 243,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_78@0",
            "content": "In this Appendix, we include an overview of the quantization method we adapted to our use case.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_78",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_78@1",
            "content": "The algorithm is summarized in Algorithm 1, for full details see Vargaftik et al., 2022, Section 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_78",
            "start": 96,
            "end": 194,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_78@2",
            "content": "We start by introducing the following definitions:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_78",
            "start": 196,
            "end": 245,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_79@0",
            "content": "Definition 1 (Horadam, 2012).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_79",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_79@1",
            "content": "A normalized Walsh-Hadamard matrix,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_79",
            "start": 30,
            "end": 64,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_80@0",
            "content": "H 2 k \u2208 {+1, \u22121} 2 k \u00d72 k , is recursively defined as H 1 = 1; H 2 k = 1 \u221a 2 H 2 k\u22121 H 2 k\u22121 H 2 k\u22121 \u2212H 2 k\u22121 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_80",
            "start": 0,
            "end": 110,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_81@0",
            "content": "Definition 2 (Ailon and Chazelle, 2006).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_81",
            "start": 0,
            "end": 39,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_81@1",
            "content": "A randomized Hadamard transform, H, of a vector,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_81",
            "start": 41,
            "end": 88,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_82@0",
            "content": "x \u2208 R 2 k , is defined as H(x) := H 2 k Dx,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_82",
            "start": 0,
            "end": 42,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_83@0",
            "content": "where H 2 k is a normazlized Walsh-Hadmard matrix, and D is a diagonal matrix whose diagonal entries are i.i.d. Rademacher random variables (i.e., taken uniformly from {+1, \u22121}).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_83",
            "start": 0,
            "end": 177,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_83@1",
            "content": "While H is randomized and thus defines a distribution, when D is known, we abuse the notation and define the inverse Hadamard transform as",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_83",
            "start": 179,
            "end": 316,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_84@0",
            "content": "H \u22121 (x) := (H 2 k D) \u22121 x = DH 2 k x.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_84",
            "start": 0,
            "end": 37,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_85@0",
            "content": "The quantization operates as follows.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_85",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_85@1",
            "content": "Given a vector, denoted x \u2208 R d , we first precondition it using a randomized Hadamard transform, H, and normalize by multiplying by \u221a d / x 2 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_85",
            "start": 38,
            "end": 181,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_85@2",
            "content": "There are several desired outcomes of this transform 6 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_85",
            "start": 183,
            "end": 238,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_85@3",
            "content": "First, the dynamic range of the values is reduced (measured, for instance, by the ratio of the \u221e and the 2 norms).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_85",
            "start": 240,
            "end": 353,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_85@4",
            "content": "Loosely speaking, we can think of the transform as spreading the vector's information evenly among its coordinates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_85",
            "start": 355,
            "end": 469,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_85@5",
            "content": "Second, regardless of the distribution of the input vector, each coordinate of the transformed vector will have a distribution that is close to the standard Gaussian distribution (as an outcome of the central limit theorem).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_85",
            "start": 471,
            "end": 694,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_85@6",
            "content": "After the transform, we perform scalar quantization that is optimized for the N (0, 1) distribution, using K-means (also known as Max-Lloyd in the quantization literature (Gersho and Gray, 1992)), with K = 2 B .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_85",
            "start": 696,
            "end": 906,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_85@7",
            "content": "The vector X of cluster assignments together with the original vector's 2 norm can now be stored as the compressed representation of the original vector.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_85",
            "start": 908,
            "end": 1060,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_86@0",
            "content": "To retrieve an estimate of the original vector, we perform the same steps in reverse.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_86",
            "start": 0,
            "end": 84,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_86@1",
            "content": "We replace",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_86",
            "start": 86,
            "end": 95,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_87@0",
            "content": "To study the impact of quantization, we fix AESI-16 as our baseline and measure how different quantization strategies and number of bits affect the MRR@10 score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_87",
            "start": 0,
            "end": 160,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_87@1",
            "content": "Note that we do not measure quantization over the baseline BERT SPLIT since it can only achieve a compression ratio of up to 32x per coordinate (using 1 bit per coordinate).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_87",
            "start": 162,
            "end": 334,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_87@2",
            "content": "In addition to EDEN (Appendix A, Algorithm 1), we consider the following quantization strategies: Deterministic Rounding (DR) (Gersho and Gray, 1992).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_87",
            "start": 336,
            "end": 485,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_87@3",
            "content": "Maps the input coordinates into the [0, 2 B \u2212 1] range using min-max normalization and rounds to the nearest integer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_87",
            "start": 487,
            "end": 603,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_87@4",
            "content": "Stochastic Rounding (SR) (Barnes et al., 1951;Connolly et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_87",
            "start": 605,
            "end": 673,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_87@5",
            "content": "Normalizes as before using min-max normalization, and additionally adds a uniform dither noise in (\u22120.5, 0.5) and then rounds to the nearest integer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_87",
            "start": 675,
            "end": 823,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_87@6",
            "content": "This provides an unbiased estimate of each coordinate.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_87",
            "start": 825,
            "end": 878,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_87@7",
            "content": "Subtractive Dithering (SD) (Roberts, 1962;Gray and Stockham, 1993).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_87",
            "start": 880,
            "end": 946,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_87@8",
            "content": "Same as SR, only now before denormalization, instead of just using the values in {0, . . . , 2 B \u2212 1}, we first subtract the original dither noise, which we assume can be regenerated using shared randomness.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_87",
            "start": 948,
            "end": 1154,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_87@9",
            "content": "This is an unbiased estimator with reduced variance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_87",
            "start": 1156,
            "end": 1207,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_87@10",
            "content": "Hadamard Variants (H-DR, H-SR, and H-SD).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_87",
            "start": 1209,
            "end": 1249,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_87@11",
            "content": "These variants correspond to the previous methods; only they are preceded by a randomized Hadamard transform.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_87",
            "start": 1251,
            "end": 1359,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_87@12",
            "content": "EDEN with Bias Correction (EDEN-BC) (Vargaftik et al., 2022, Section 2.3).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_87",
            "start": 1361,
            "end": 1434,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_87@13",
            "content": "This variant of EDEN optimizes for lower bias over the mean squared error (MSE) by multiplying the dequantization result in Algorithm 1 by a bias correction scalar: x 2 2 / H(x), \u0177 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_87",
            "start": 1436,
            "end": 1617,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_88@0",
            "content": "Figure 4 shows the results for the different quantization methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_88",
            "start": 0,
            "end": 65,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_88@1",
            "content": "First, we observe that the Hadamard variants perform better than their non-Hadamard counterparts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_88",
            "start": 67,
            "end": 163,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_88@2",
            "content": "Second, we see that EDEN performs better than all other schemes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_88",
            "start": 165,
            "end": 228,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_88@3",
            "content": "The differences are more pronounced in the low-bit regime, where the choice of quantization scheme has a drastic impact on quality.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_88",
            "start": 230,
            "end": 360,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_88@4",
            "content": "We also note that unlike in other use cases, such as distributed mean estimation, bias correction is inappropriate here and should not be performed at the cost of increased mean squared error (MSE).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_88",
            "start": 362,
            "end": 559,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_88@5",
            "content": "This conclusion follows by observing that EDEN and the deterministic rounding methods (DR, H-DR) are respectively better than EDEN-BC and the stochastic rounding methods (SR, H-SR).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_88",
            "start": 561,
            "end": 741,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_88@6",
            "content": "We add that the subtractive dithering methods (SD, H-SD), expectedly, work the same or better than their deterministic counterparts since they produce a similar MSE while also being unbiased.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_88",
            "start": 743,
            "end": 933,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_89@0",
            "content": "The current quantization scheme requires padding to full 128 blocks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_89",
            "start": 0,
            "end": 67,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_89@1",
            "content": "For AESI with a small code size, the padding overhead may reach 10% -20% percent.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_89",
            "start": 69,
            "end": 149,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_89@2",
            "content": "In addition, we send a normalization value per 128-block, which we currently send as a float32 value, adding 4% -5% additional overhead.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_89",
            "start": 151,
            "end": 286,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_89@3",
            "content": "Padding can be reduced by treating the last 128-block separately, e.g., applying a method that does not require Hadamard transform.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_89",
            "start": 288,
            "end": 418,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_89@4",
            "content": "Normalization overhead can be reduced, e.g., by sending normalization factors as float16 instead of full float32.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_89",
            "start": 420,
            "end": 532,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_89@5",
            "content": "However, such solutions complicate the implementation while providing limited storage benefits, hence, they were not explored in the context of this paper.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_89",
            "start": 534,
            "end": 688,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_90@0",
            "content": "Beyond Scalar Quantization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_90",
            "start": 0,
            "end": 26,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_90@1",
            "content": "Scalar quantization using a fixed number of bits is a suboptimal technique in general since it does not allocate fewer bits for more frequent cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_90",
            "start": 28,
            "end": 175,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_90@2",
            "content": "Entropy coding (Gersho and Gray, 1992) can do better in this aspect.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_90",
            "start": 177,
            "end": 244,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_90@3",
            "content": "However, this improvement seems may not justify the added complexity: For the case of 6-bit quantization, the entropy of the quantization indices turned out to be 5.71bit, indicating that the compression gain is limited to about 5% in this case (even before accounting for the overhead incurred from the entropy coding algorithm itself).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_90",
            "start": 246,
            "end": 582,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_90@4",
            "content": "Additional directions include quantizing multiple values together (vector quantization), as well as designing the quantizer with entropy consideration in mind (entropy-constrained vector quantization).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_90",
            "start": 584,
            "end": 784,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_91@0",
            "content": "In order to estimate the potential gains of all these methods combined, we turn to information theory, and rate-distortion theory in particular, which studies the optimal tradeoffs between distortion and compression rate (Cover and Thomas, 2006).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_91",
            "start": 0,
            "end": 245,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_91@1",
            "content": "For a Gaussian source, which is a reasonable approximation of the vectors that are compressed in our case (following the randomized Hadamard transform), it is known that the optimal (lossy) compression rate is given by 1 2 log 2 ( 1 M SE ), where MSE is the mean squared error of the compressed source.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_91",
            "start": 247,
            "end": 548,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_91@2",
            "content": "We computed the optimal rate that is achievable for the MSE that our system achieved for 6 bits, and the optimal rate was 5.35bit, indicating a potential gain of 11%.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_91",
            "start": 550,
            "end": 715,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_91@3",
            "content": "Given these results, and also given that for other bit rates the results were similar, we conclude that further quantization improvements have limited gain, which most likely does not justify the added system complexity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_91",
            "start": 717,
            "end": 936,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_92@0",
            "content": "In the body of the paper, we showed the effectiveness in ranking and utility in compression rates of AESI over AE architectures.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_92",
            "start": 0,
            "end": 127,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_92@1",
            "content": "However, such evaluations do not capture the encoded information at the token-level.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_92",
            "start": 129,
            "end": 212,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_92@2",
            "content": "In this intrinsic evaluation we try to discern when and why adding the static embedding as side information contributes to better capturing the token meaning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_92",
            "start": 214,
            "end": 371,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_93@0",
            "content": "We study the effectiveness of different autoencoder configurations in reconstructing back the original token vector, as measured through the MSE between the original vector and the reconstructed vector:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_93",
            "start": 0,
            "end": 201,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_94@0",
            "content": "M SE (v, D (E(v, u), u)) ,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_94",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_95@0",
            "content": "where v is a contextualized vector (BERT SPLIT output at layer 10), u is the static embedding, and the encoder E(v, u) and the decoder D(e, u) are as defined in \u00a7 3.1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_95",
            "start": 0,
            "end": 166,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_95@1",
            "content": "High MSE scores indicate the inability of the autoencoder to encode the original vector's information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_95",
            "start": 168,
            "end": 269,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_96@0",
            "content": "Document Frequency: One way to assess the importance of a document w.r.t. a query is through the inverse document frequency of query tokens, typically measured through TF-IDF or BM25 schemes (Robertson and Zaragoza, 2009).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_96",
            "start": 0,
            "end": 221,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_96@1",
            "content": "In principle, the more infrequent a query token is in a document collection, the higher the ranking of a document containing that token will be.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_96",
            "start": 223,
            "end": 366,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_96@2",
            "content": "Tokens with (very) high frequencies are typically stop words or punctuation symbols, which have lower importance when determining the query-document relevance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_96",
            "start": 368,
            "end": 526,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_97@0",
            "content": "Based on this premise, we study how MSE varies across token frequency.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_97",
            "start": 0,
            "end": 69,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_97@1",
            "content": "We selected a random sample of 256k documents from MSMARCO, tokenized them, and run them through BERT SPLIT to get 20M contextualized token representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_97",
            "start": 71,
            "end": 226,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_97@2",
            "content": "Then, for each token we measured their document frequency as DF (t) = log 10 (|{d \u2208 D : t \u2208 d}|/|D|) (where D is our document collection), and in Figure 5 we plot the average MSE against the rounded DF scores.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_97",
            "start": 228,
            "end": 436,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_97@3",
            "content": "From this experiment, we make the following observations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_97",
            "start": 438,
            "end": 494,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_97@4",
            "content": "Figure 5: Reconstruction Error vs. DF for the different AE and AESI configurations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_97",
            "start": 496,
            "end": 578,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_97@5",
            "content": "AESI shows robust performance in recovering back the token's representation with a MSE score (y-axis), which is constant for documents with varying DF scores.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_97",
            "start": 580,
            "end": 737,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_97@6",
            "content": "It is interesting to note that for frequent tokens (i.e., tokens that are function words, hence play a marginal role in retrieval), the error rate is higher when compared to the rest of the tokens.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_97",
            "start": 739,
            "end": 935,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_98@0",
            "content": "First, on all encoded width configurations, our approach, AESI, consistently achieves lower MSE compared to the AE architecture (for all DF values).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_98",
            "start": 0,
            "end": 147,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_98@1",
            "content": "Lower MSE correlates to a better ranking quality, as shown in \u00a7 5.3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_98",
            "start": 149,
            "end": 216,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_98@2",
            "content": "Furthermore, for tokens with low DF, adding the static side information during the training of AESI for compression provides a huge advantage, which shrinks when the token is present in many documents in the collection.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_98",
            "start": 218,
            "end": 436,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_99@0",
            "content": "Second, on the end spectrum of high-frequency tokens, we note a downwards trend for AE and an upwards trend for AESI, especially for DF \u2208 [\u22121, 0].",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_99",
            "start": 0,
            "end": 145,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_99@1",
            "content": "The MSE decrease for AE is expected since the training data contains more frequent tokens.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_99",
            "start": 147,
            "end": 236,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_99@2",
            "content": "The increase for AESI can be explained given that in this frequency range, we deal with tokens that are function words (e.g., 'the') whose role is more in tying up content within a sentence and has less standalone meaning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_99",
            "start": 238,
            "end": 459,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_99@3",
            "content": "In this case, static embeddings cannot capture context, which reduces the contribution provided by the side information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_99",
            "start": 461,
            "end": 580,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_100@0",
            "content": "In Table 3 we show MAP@1K results on the TREC CAR dataset for a varying number of features.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_100",
            "start": 0,
            "end": 90,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_100@1",
            "content": "We compare the baseline -an autoencoder with 2 layers and float16 quantization -to SDR scheme, with the same number of features and EDEN 6bits quantization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_100",
            "start": 92,
            "end": 247,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_100@2",
            "content": "The SDR scheme is able to provide solid results even for 3 features with a MAP@1K score of 0.268.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_100",
            "start": 249,
            "end": 345,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_100@3",
            "content": "With the baseline method, similar results are achieved only with 36 features.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_100",
            "start": 347,
            "end": 423,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_100@4",
            "content": "As a comparison, this is much higher than BM25 using the Answerini system (Yang et al., 2017), which reaches 0.156 MAP@1K score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_100",
            "start": 425,
            "end": 552,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_100@5",
            "content": "With 16 features (the configuration we used for Table 1), SDR reaches a score of 0.311, compared to 0.312 for the baseline with 52 features.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_100",
            "start": 554,
            "end": 693,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_100@6",
            "content": "Finally, with the largest size of features we tested, 64, the baseline reached a MAP@1K score of 0.313, similar to the score achieved by SDR-20 (0.314), demonstrating the effectiveness of the static embeddings as side information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_100",
            "start": 695,
            "end": 924,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_101@0",
            "content": "In Figure 6 we illustrate the architecture of the late interaction model vs. the standard BERT model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_101",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_101@1",
            "content": "In standard BERT, the query and documents are concatenated before the first BERT layer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_101",
            "start": 102,
            "end": 188,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_101@2",
            "content": "Therefore, if K documents are ranked, all BERT transformers layers are applied K times.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_101",
            "start": 190,
            "end": 276,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_101@3",
            "content": "In the late interaction architecture, the bottom L layers (e.g., 10 transformer layers shown in the figure) are executed independently for the query and the documents.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_101",
            "start": 278,
            "end": 444,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_101@4",
            "content": "The document representation is precomputed and stored in the index.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_101",
            "start": 446,
            "end": 512,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_101@5",
            "content": "During online execution, the query representation is computed once, and the document representations are retrieved from the index.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_101",
            "start": 514,
            "end": 643,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_101@6",
            "content": "Only the interaction block (e.g., 2 transformer layers) are executed K times, once for each ranked document.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_101",
            "start": 645,
            "end": 752,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_102@0",
            "content": "Nir Ailon, Bernard Chazelle, Approximate nearest neighbors and the fast johnson-lindenstrauss transform, 2006, Proceedings of the Thirty-Eighth Annual ACM Symposium on Theory of Computing, STOC, Association for Computing Machinery.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_102",
            "start": 0,
            "end": 230,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_103@0",
            "content": "Dan Alistarh, Demjan Grubic, Jerry Li, Ryota Tomioka, Milan Vojnovic, QSGD: Communication-Efficient Sgd via Gradient Quantization and Encoding, 2017, Advances in Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_103",
            "start": 0,
            "end": 201,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_104@0",
            "content": "UNKNOWN, None, 1951, An electronic digital computor using cold cathode counting tubes for storage, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_104",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_105@0",
            "content": "Qingqing Cao, Harsh Trivedi, De-Former: Decomposing pre-trained transformers for faster question answering, 2020, ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_105",
            "start": 0,
            "end": 119,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_106@0",
            "content": "Jiecao Chen, Liu Yang, Karthik Raman, Michael Bendersky, Jung-Jung Yeh, Yun Zhou, Marc Najork, Danyang Cai, Ehsan Emadzadeh, DiPair: Fast and accurate distillation for trillion-scale text matching and pair modeling, 2020, Findings of the Association for Computational Linguistics: EMNLP 2020, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_106",
            "start": 0,
            "end": 342,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_107@0",
            "content": "Michael Connolly, Nicholas Higham, Theo Mary, Stochastic rounding and its probabilistic backward error analysis, 2021, SIAM Journal on Scientific Computing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_107",
            "start": 0,
            "end": 157,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_108@0",
            "content": "M Thomas, Joy Cover,  Thomas, Elements of Information Theory, 2006, Series in Telecommunications and Signal Processing, Wiley-Interscience.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_108",
            "start": 0,
            "end": 138,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_109@0",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long and Short Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_109",
            "start": 0,
            "end": 315,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_110@0",
            "content": "Laura Dietz, Manisha Verma, Filip Radlinski, Nick Craswell, TREC complex answer retrieval overview, 2017, TREC, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_110",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_111@0",
            "content": "Mohaned Essam,  Tong Boon, Eric Tatt Wei Tang, Hsin Ho,  Chen, Dynamic point stochastic rounding algorithm for limited precision arithmetic in deep belief network training, 2017, 8th International IEEE/EMBS Conference on Neural Engineering (NER), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_111",
            "start": 0,
            "end": 247,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_112@0",
            "content": "J Bernard, V Fino,  Ralph Algazi, Unified matrix treatment of the fast walsh-hadamard transform, 1976, IEEE Transactions on Computers, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_112",
            "start": 0,
            "end": 135,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_113@0",
            "content": "UNKNOWN, None, 2020, Speedup transformer-based rankers with precomputed representation. arXiv: Information Retrieval, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_113",
            "start": 0,
            "end": 118,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_114@0",
            "content": "Luyu Gao, Zhuyun Dai, Jamie Callan, Modularized transfomer-based ranking framework, 2020, EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_114",
            "start": 0,
            "end": 97,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_115@0",
            "content": "UNKNOWN, None, 1992, Vector quantization and signal compression, Kluwer Academic Publishers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_115",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_116@0",
            "content": "R Gray, T Stockham, Dithered quantizers, 1993, IEEE Transactions on Information Theory, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_116",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_117@0",
            "content": "Ruiqi Guo, Philip Sun, Erik Lindgren, Quan Geng, David Simcha, Felix Chern, Sanjiv Kumar, Accelerating large-scale inference with anisotropic vector quantization, 2020, ICML, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_117",
            "start": 0,
            "end": 175,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_118@0",
            "content": "Suyog Gupta, Ankur Agrawal, Kailash Gopalakrishnan, Pritish Narayanan, Deep learning with limited numerical precision, 2015, Proceedings of Machine Learning Research, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_118",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_119@0",
            "content": "Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Mingwei Chang. 2020. Retrieval augmented language model pre-training, , ICML, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_119",
            "start": 0,
            "end": 135,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_120@0",
            "content": "UNKNOWN, None, 2016, Gaussian error linear units (gelus), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_120",
            "start": 0,
            "end": 58,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_121@0",
            "content": "UNKNOWN, None, 2020, Improving efficient neural ranking models with cross-architecture knowledge distillation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_121",
            "start": 0,
            "end": 111,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_122@0",
            "content": "UNKNOWN, None, 2020, , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_122",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_123@0",
            "content": ", Interpretable & time-budgetconstrained contextualization for re-ranking, , ECAI, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_123",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_124@0",
            "content": "UNKNOWN, None, 2012, Hadamard Matrices and Their Applications, Princeton university press.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_124",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_125@0",
            "content": "Jeff Johnson, Matthijs Douze, Herv\u00e9 J\u00e9gou, Billion-scale similarity search with gpus, 2017, IEEE Transactions on Big Data, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_125",
            "start": 0,
            "end": 123,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_126@0",
            "content": "Vladimir Karpukhin, Barlas Oguz, Sewon Min, S Patrick, Ledell Lewis, Sergey Wu, Danqi Edunov, Wen Chen, Yih Tau, Dense passage retrieval for open-domain question answering, 2020, EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_126",
            "start": 0,
            "end": 186,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_127@0",
            "content": "Omar Khattab, Matei Zaharia, Colbert: Efficient and effective passage search via contextualized late interaction over bert, 2020, SIGIR, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_127",
            "start": 0,
            "end": 137,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_128@0",
            "content": "Jakub Kone\u010dn\u1ef3, Peter Richt\u00e1rik, Randomized Distributed Mean Estimation: Accuracy vs, 2018, Communication. Frontiers in Applied Mathematics and Statistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_128",
            "start": 0,
            "end": 155,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_129@0",
            "content": "UNKNOWN, None, 2020, Twinbert: Distilling knowledge to twin-structured bert models for efficient retrieval, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_129",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_130@0",
            "content": "Sean Macavaney, Maria Franco, Raffaele Nardini, Nicola Perego, Nazli Tonellotto, Ophir Goharian,  Frieder, Efficient document re-ranking for transformers by precomputing term representations, 2020, SIGIR, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_130",
            "start": 0,
            "end": 205,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_131@0",
            "content": "UNKNOWN, None, 2019, On the Downstream Performance of Compressed Word Embeddings, Curran Associates Inc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_131",
            "start": 0,
            "end": 103,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_132@0",
            "content": "UNKNOWN, None, 1991, Private vs. Common Random Bits in Communication Complexity. Information processing letters, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_132",
            "start": 0,
            "end": 113,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_133@0",
            "content": "Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, Li Deng, Ms marco: A human generated machine reading comprehension dataset, 2016, CoCo@NIPS, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_133",
            "start": 0,
            "end": 177,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_134@0",
            "content": "Ping Nie, Yuyu Zhang, Xiubo Geng, Arun Ramamurthy, Le Song, Daxin Jiang, Dc-bert: Decoupling question and document for efficient contextual encoding, 2020, SIGIR, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_134",
            "start": 0,
            "end": 163,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_135@0",
            "content": "UNKNOWN, None, 1901, Passage re-ranking with BERT. CoRR, abs, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_135",
            "start": 0,
            "end": 62,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_136@0",
            "content": "UNKNOWN, None, 2019, Passage re-ranking with BERT. arXiv: Information Retrieval, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_136",
            "start": 0,
            "end": 81,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_137@0",
            "content": "UNKNOWN, None, 2020, Rocketqa: An optimized training approach to dense passage retrieval for open-domain question answering, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_137",
            "start": 0,
            "end": 125,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_138@0",
            "content": "L Roberts, Picture coding using pseudo-random noise, 1962, IRE Transactions on Information Theory, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_138",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_139@0",
            "content": "UNKNOWN, None, 2009, The probabilistic relevance framework: BM25 and beyond, Now Publishers Inc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_139",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_140@0",
            "content": "Yu Ananda Theertha Suresh, Sanjiv Felix, H Brendan Kumar,  Mcmahan, Distributed Mean Estimation With Limited Communication, 2017, International Conference on Machine Learning, PMLR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_140",
            "start": 0,
            "end": 180,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_141@0",
            "content": "UNKNOWN, None, , Yaniv Ben-Itzhak, and Michael Mitzenmacher. 2022. Eden: Communication-efficient and robust distributed mean estimation for federated learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_141",
            "start": 0,
            "end": 160,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_142@0",
            "content": "Shay Vargaftik, Ran Ben-Basat, Amit Portnoy, Gal Mendelson, Yaniv Ben-Itzhak, and Michael Mitzenmacher, 2021, Advances in Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_142",
            "start": 0,
            "end": 161,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_143@0",
            "content": "Naigang Wang, Jungwook Choi, Daniel Brand, Chia-Yu Chen, Kailash Gopalakrishnan, Training deep neural networks with 8-bit floating point numbers, 2018, NIPS, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_143",
            "start": 0,
            "end": 158,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_144@0",
            "content": "UNKNOWN, None, 2018, Training and inference with integers in deep neural networks, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_144",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_145@0",
            "content": "Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul Bennett, Junaid Ahmed, Arnold Overwikj, Approximate nearest neighbor negative contrastive learning for dense text retrieval, 2021, ICLR, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_145",
            "start": 0,
            "end": 203,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_146@0",
            "content": "Peilin Yang, Hui Fang, Jimmy Lin, Anserini: Enabling the use of lucene for information retrieval research, 2017, Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '17, Association for Computing Machinery.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_146",
            "start": 0,
            "end": 272,
            "label": {}
        },
        {
            "ix": "166-ARR_v2_147@0",
            "content": "Andrew Yates, Rodrigo Nogueira, Jimmy Lin, Pretrained transformers for text ranking: BERT and beyond, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Tutorials, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "166-ARR_v2_147",
            "start": 0,
            "end": 312,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "166-ARR_v2_0",
            "tgt_ix": "166-ARR_v2_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_0",
            "tgt_ix": "166-ARR_v2_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_1",
            "tgt_ix": "166-ARR_v2_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_1",
            "tgt_ix": "166-ARR_v2_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_1",
            "tgt_ix": "166-ARR_v2_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_2",
            "tgt_ix": "166-ARR_v2_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_1",
            "tgt_ix": "166-ARR_v2_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_3",
            "tgt_ix": "166-ARR_v2_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_0",
            "tgt_ix": "166-ARR_v2_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_4",
            "tgt_ix": "166-ARR_v2_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_6",
            "tgt_ix": "166-ARR_v2_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_7",
            "tgt_ix": "166-ARR_v2_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_8",
            "tgt_ix": "166-ARR_v2_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_9",
            "tgt_ix": "166-ARR_v2_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_10",
            "tgt_ix": "166-ARR_v2_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_11",
            "tgt_ix": "166-ARR_v2_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_12",
            "tgt_ix": "166-ARR_v2_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_13",
            "tgt_ix": "166-ARR_v2_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_14",
            "tgt_ix": "166-ARR_v2_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_15",
            "tgt_ix": "166-ARR_v2_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_16",
            "tgt_ix": "166-ARR_v2_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_5",
            "tgt_ix": "166-ARR_v2_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_5",
            "tgt_ix": "166-ARR_v2_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_5",
            "tgt_ix": "166-ARR_v2_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_5",
            "tgt_ix": "166-ARR_v2_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_5",
            "tgt_ix": "166-ARR_v2_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_5",
            "tgt_ix": "166-ARR_v2_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_5",
            "tgt_ix": "166-ARR_v2_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_5",
            "tgt_ix": "166-ARR_v2_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_5",
            "tgt_ix": "166-ARR_v2_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_5",
            "tgt_ix": "166-ARR_v2_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_5",
            "tgt_ix": "166-ARR_v2_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_5",
            "tgt_ix": "166-ARR_v2_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_5",
            "tgt_ix": "166-ARR_v2_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_0",
            "tgt_ix": "166-ARR_v2_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_19",
            "tgt_ix": "166-ARR_v2_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_20",
            "tgt_ix": "166-ARR_v2_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_18",
            "tgt_ix": "166-ARR_v2_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_18",
            "tgt_ix": "166-ARR_v2_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_18",
            "tgt_ix": "166-ARR_v2_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_18",
            "tgt_ix": "166-ARR_v2_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_0",
            "tgt_ix": "166-ARR_v2_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_21",
            "tgt_ix": "166-ARR_v2_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_23",
            "tgt_ix": "166-ARR_v2_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_22",
            "tgt_ix": "166-ARR_v2_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_22",
            "tgt_ix": "166-ARR_v2_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_22",
            "tgt_ix": "166-ARR_v2_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_22",
            "tgt_ix": "166-ARR_v2_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_24",
            "tgt_ix": "166-ARR_v2_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_26",
            "tgt_ix": "166-ARR_v2_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_27",
            "tgt_ix": "166-ARR_v2_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_28",
            "tgt_ix": "166-ARR_v2_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_29",
            "tgt_ix": "166-ARR_v2_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_30",
            "tgt_ix": "166-ARR_v2_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_31",
            "tgt_ix": "166-ARR_v2_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_32",
            "tgt_ix": "166-ARR_v2_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_33",
            "tgt_ix": "166-ARR_v2_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_34",
            "tgt_ix": "166-ARR_v2_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_25",
            "tgt_ix": "166-ARR_v2_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_25",
            "tgt_ix": "166-ARR_v2_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_25",
            "tgt_ix": "166-ARR_v2_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_25",
            "tgt_ix": "166-ARR_v2_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_25",
            "tgt_ix": "166-ARR_v2_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_25",
            "tgt_ix": "166-ARR_v2_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_25",
            "tgt_ix": "166-ARR_v2_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_25",
            "tgt_ix": "166-ARR_v2_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_25",
            "tgt_ix": "166-ARR_v2_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_25",
            "tgt_ix": "166-ARR_v2_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_25",
            "tgt_ix": "166-ARR_v2_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_22",
            "tgt_ix": "166-ARR_v2_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_35",
            "tgt_ix": "166-ARR_v2_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_37",
            "tgt_ix": "166-ARR_v2_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_38",
            "tgt_ix": "166-ARR_v2_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_36",
            "tgt_ix": "166-ARR_v2_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_36",
            "tgt_ix": "166-ARR_v2_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_36",
            "tgt_ix": "166-ARR_v2_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_36",
            "tgt_ix": "166-ARR_v2_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_0",
            "tgt_ix": "166-ARR_v2_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_39",
            "tgt_ix": "166-ARR_v2_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_40",
            "tgt_ix": "166-ARR_v2_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_40",
            "tgt_ix": "166-ARR_v2_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_40",
            "tgt_ix": "166-ARR_v2_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_41",
            "tgt_ix": "166-ARR_v2_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_43",
            "tgt_ix": "166-ARR_v2_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_44",
            "tgt_ix": "166-ARR_v2_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_45",
            "tgt_ix": "166-ARR_v2_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_42",
            "tgt_ix": "166-ARR_v2_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_42",
            "tgt_ix": "166-ARR_v2_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_42",
            "tgt_ix": "166-ARR_v2_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_42",
            "tgt_ix": "166-ARR_v2_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_42",
            "tgt_ix": "166-ARR_v2_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_40",
            "tgt_ix": "166-ARR_v2_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_46",
            "tgt_ix": "166-ARR_v2_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_47",
            "tgt_ix": "166-ARR_v2_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_47",
            "tgt_ix": "166-ARR_v2_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_40",
            "tgt_ix": "166-ARR_v2_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_48",
            "tgt_ix": "166-ARR_v2_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_50",
            "tgt_ix": "166-ARR_v2_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_49",
            "tgt_ix": "166-ARR_v2_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_49",
            "tgt_ix": "166-ARR_v2_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_49",
            "tgt_ix": "166-ARR_v2_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_40",
            "tgt_ix": "166-ARR_v2_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_51",
            "tgt_ix": "166-ARR_v2_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_52",
            "tgt_ix": "166-ARR_v2_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_52",
            "tgt_ix": "166-ARR_v2_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_0",
            "tgt_ix": "166-ARR_v2_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_53",
            "tgt_ix": "166-ARR_v2_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_54",
            "tgt_ix": "166-ARR_v2_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_54",
            "tgt_ix": "166-ARR_v2_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_54",
            "tgt_ix": "166-ARR_v2_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_55",
            "tgt_ix": "166-ARR_v2_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_57",
            "tgt_ix": "166-ARR_v2_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_58",
            "tgt_ix": "166-ARR_v2_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_59",
            "tgt_ix": "166-ARR_v2_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_56",
            "tgt_ix": "166-ARR_v2_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_56",
            "tgt_ix": "166-ARR_v2_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_56",
            "tgt_ix": "166-ARR_v2_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_56",
            "tgt_ix": "166-ARR_v2_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_56",
            "tgt_ix": "166-ARR_v2_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_54",
            "tgt_ix": "166-ARR_v2_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_60",
            "tgt_ix": "166-ARR_v2_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_62",
            "tgt_ix": "166-ARR_v2_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_61",
            "tgt_ix": "166-ARR_v2_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_61",
            "tgt_ix": "166-ARR_v2_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_61",
            "tgt_ix": "166-ARR_v2_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_54",
            "tgt_ix": "166-ARR_v2_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_63",
            "tgt_ix": "166-ARR_v2_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_65",
            "tgt_ix": "166-ARR_v2_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_66",
            "tgt_ix": "166-ARR_v2_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_64",
            "tgt_ix": "166-ARR_v2_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_64",
            "tgt_ix": "166-ARR_v2_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_64",
            "tgt_ix": "166-ARR_v2_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_64",
            "tgt_ix": "166-ARR_v2_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_68",
            "tgt_ix": "166-ARR_v2_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_64",
            "tgt_ix": "166-ARR_v2_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_64",
            "tgt_ix": "166-ARR_v2_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_67",
            "tgt_ix": "166-ARR_v2_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_54",
            "tgt_ix": "166-ARR_v2_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_69",
            "tgt_ix": "166-ARR_v2_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_71",
            "tgt_ix": "166-ARR_v2_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_70",
            "tgt_ix": "166-ARR_v2_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_70",
            "tgt_ix": "166-ARR_v2_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_70",
            "tgt_ix": "166-ARR_v2_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_73",
            "tgt_ix": "166-ARR_v2_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_70",
            "tgt_ix": "166-ARR_v2_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_70",
            "tgt_ix": "166-ARR_v2_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_72",
            "tgt_ix": "166-ARR_v2_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_0",
            "tgt_ix": "166-ARR_v2_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_74",
            "tgt_ix": "166-ARR_v2_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_76",
            "tgt_ix": "166-ARR_v2_77",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_78",
            "tgt_ix": "166-ARR_v2_79",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_79",
            "tgt_ix": "166-ARR_v2_80",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_80",
            "tgt_ix": "166-ARR_v2_81",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_81",
            "tgt_ix": "166-ARR_v2_82",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_82",
            "tgt_ix": "166-ARR_v2_83",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_83",
            "tgt_ix": "166-ARR_v2_84",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_84",
            "tgt_ix": "166-ARR_v2_85",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_85",
            "tgt_ix": "166-ARR_v2_86",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_78",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_79",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_80",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_81",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_82",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_83",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_84",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_85",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_86",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_77",
            "tgt_ix": "166-ARR_v2_78",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_87",
            "tgt_ix": "166-ARR_v2_88",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_88",
            "tgt_ix": "166-ARR_v2_89",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_89",
            "tgt_ix": "166-ARR_v2_90",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_90",
            "tgt_ix": "166-ARR_v2_91",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_87",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_88",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_89",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_90",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_91",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_86",
            "tgt_ix": "166-ARR_v2_87",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_92",
            "tgt_ix": "166-ARR_v2_93",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_93",
            "tgt_ix": "166-ARR_v2_94",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_94",
            "tgt_ix": "166-ARR_v2_95",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_95",
            "tgt_ix": "166-ARR_v2_96",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_96",
            "tgt_ix": "166-ARR_v2_97",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_97",
            "tgt_ix": "166-ARR_v2_98",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_98",
            "tgt_ix": "166-ARR_v2_99",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_92",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_93",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_94",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_95",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_96",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_97",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_98",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_99",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_91",
            "tgt_ix": "166-ARR_v2_92",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_100",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_99",
            "tgt_ix": "166-ARR_v2_100",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_101",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_100",
            "tgt_ix": "166-ARR_v2_101",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "166-ARR_v2_0",
            "tgt_ix": "166-ARR_v2_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_1",
            "tgt_ix": "166-ARR_v2_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_2",
            "tgt_ix": "166-ARR_v2_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_2",
            "tgt_ix": "166-ARR_v2_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_2",
            "tgt_ix": "166-ARR_v2_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_2",
            "tgt_ix": "166-ARR_v2_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_3",
            "tgt_ix": "166-ARR_v2_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_3",
            "tgt_ix": "166-ARR_v2_3@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_3",
            "tgt_ix": "166-ARR_v2_3@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_4",
            "tgt_ix": "166-ARR_v2_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_4",
            "tgt_ix": "166-ARR_v2_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_5",
            "tgt_ix": "166-ARR_v2_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_6",
            "tgt_ix": "166-ARR_v2_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_6",
            "tgt_ix": "166-ARR_v2_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_7",
            "tgt_ix": "166-ARR_v2_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_8",
            "tgt_ix": "166-ARR_v2_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_8",
            "tgt_ix": "166-ARR_v2_8@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_9",
            "tgt_ix": "166-ARR_v2_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_9",
            "tgt_ix": "166-ARR_v2_9@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_10",
            "tgt_ix": "166-ARR_v2_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_10",
            "tgt_ix": "166-ARR_v2_10@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_10",
            "tgt_ix": "166-ARR_v2_10@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_10",
            "tgt_ix": "166-ARR_v2_10@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_11",
            "tgt_ix": "166-ARR_v2_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_11",
            "tgt_ix": "166-ARR_v2_11@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_11",
            "tgt_ix": "166-ARR_v2_11@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_12",
            "tgt_ix": "166-ARR_v2_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_12",
            "tgt_ix": "166-ARR_v2_12@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_12",
            "tgt_ix": "166-ARR_v2_12@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_12",
            "tgt_ix": "166-ARR_v2_12@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_13",
            "tgt_ix": "166-ARR_v2_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_13",
            "tgt_ix": "166-ARR_v2_13@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_13",
            "tgt_ix": "166-ARR_v2_13@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_13",
            "tgt_ix": "166-ARR_v2_13@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_13",
            "tgt_ix": "166-ARR_v2_13@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_14",
            "tgt_ix": "166-ARR_v2_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_14",
            "tgt_ix": "166-ARR_v2_14@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_14",
            "tgt_ix": "166-ARR_v2_14@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_15",
            "tgt_ix": "166-ARR_v2_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_15",
            "tgt_ix": "166-ARR_v2_15@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_15",
            "tgt_ix": "166-ARR_v2_15@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_15",
            "tgt_ix": "166-ARR_v2_15@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_15",
            "tgt_ix": "166-ARR_v2_15@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_15",
            "tgt_ix": "166-ARR_v2_15@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_15",
            "tgt_ix": "166-ARR_v2_15@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_15",
            "tgt_ix": "166-ARR_v2_15@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_15",
            "tgt_ix": "166-ARR_v2_15@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_15",
            "tgt_ix": "166-ARR_v2_15@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_16",
            "tgt_ix": "166-ARR_v2_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_17",
            "tgt_ix": "166-ARR_v2_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_18",
            "tgt_ix": "166-ARR_v2_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_19",
            "tgt_ix": "166-ARR_v2_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_19",
            "tgt_ix": "166-ARR_v2_19@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_19",
            "tgt_ix": "166-ARR_v2_19@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_19",
            "tgt_ix": "166-ARR_v2_19@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_19",
            "tgt_ix": "166-ARR_v2_19@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_19",
            "tgt_ix": "166-ARR_v2_19@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_19",
            "tgt_ix": "166-ARR_v2_19@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_19",
            "tgt_ix": "166-ARR_v2_19@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_19",
            "tgt_ix": "166-ARR_v2_19@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_19",
            "tgt_ix": "166-ARR_v2_19@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_19",
            "tgt_ix": "166-ARR_v2_19@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_19",
            "tgt_ix": "166-ARR_v2_19@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_19",
            "tgt_ix": "166-ARR_v2_19@12",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_19",
            "tgt_ix": "166-ARR_v2_19@13",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_19",
            "tgt_ix": "166-ARR_v2_19@14",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_19",
            "tgt_ix": "166-ARR_v2_19@15",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_20",
            "tgt_ix": "166-ARR_v2_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_20",
            "tgt_ix": "166-ARR_v2_20@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_20",
            "tgt_ix": "166-ARR_v2_20@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_21",
            "tgt_ix": "166-ARR_v2_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_21",
            "tgt_ix": "166-ARR_v2_21@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_21",
            "tgt_ix": "166-ARR_v2_21@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_21",
            "tgt_ix": "166-ARR_v2_21@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_21",
            "tgt_ix": "166-ARR_v2_21@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_21",
            "tgt_ix": "166-ARR_v2_21@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_21",
            "tgt_ix": "166-ARR_v2_21@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_21",
            "tgt_ix": "166-ARR_v2_21@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_22",
            "tgt_ix": "166-ARR_v2_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_23",
            "tgt_ix": "166-ARR_v2_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_23",
            "tgt_ix": "166-ARR_v2_23@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_23",
            "tgt_ix": "166-ARR_v2_23@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_24",
            "tgt_ix": "166-ARR_v2_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_25",
            "tgt_ix": "166-ARR_v2_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_26",
            "tgt_ix": "166-ARR_v2_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_26",
            "tgt_ix": "166-ARR_v2_26@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_26",
            "tgt_ix": "166-ARR_v2_26@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_26",
            "tgt_ix": "166-ARR_v2_26@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_26",
            "tgt_ix": "166-ARR_v2_26@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_27",
            "tgt_ix": "166-ARR_v2_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_27",
            "tgt_ix": "166-ARR_v2_27@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_27",
            "tgt_ix": "166-ARR_v2_27@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_27",
            "tgt_ix": "166-ARR_v2_27@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_28",
            "tgt_ix": "166-ARR_v2_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_28",
            "tgt_ix": "166-ARR_v2_28@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_28",
            "tgt_ix": "166-ARR_v2_28@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_29",
            "tgt_ix": "166-ARR_v2_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_29",
            "tgt_ix": "166-ARR_v2_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_29",
            "tgt_ix": "166-ARR_v2_29@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_29",
            "tgt_ix": "166-ARR_v2_29@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_29",
            "tgt_ix": "166-ARR_v2_29@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_29",
            "tgt_ix": "166-ARR_v2_29@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_30",
            "tgt_ix": "166-ARR_v2_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_30",
            "tgt_ix": "166-ARR_v2_30@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_30",
            "tgt_ix": "166-ARR_v2_30@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_31",
            "tgt_ix": "166-ARR_v2_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_31",
            "tgt_ix": "166-ARR_v2_31@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_31",
            "tgt_ix": "166-ARR_v2_31@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_32",
            "tgt_ix": "166-ARR_v2_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_33",
            "tgt_ix": "166-ARR_v2_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_34",
            "tgt_ix": "166-ARR_v2_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_35",
            "tgt_ix": "166-ARR_v2_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_35",
            "tgt_ix": "166-ARR_v2_35@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_35",
            "tgt_ix": "166-ARR_v2_35@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_36",
            "tgt_ix": "166-ARR_v2_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_37",
            "tgt_ix": "166-ARR_v2_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_37",
            "tgt_ix": "166-ARR_v2_37@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_37",
            "tgt_ix": "166-ARR_v2_37@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_38",
            "tgt_ix": "166-ARR_v2_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_38",
            "tgt_ix": "166-ARR_v2_38@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_38",
            "tgt_ix": "166-ARR_v2_38@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_38",
            "tgt_ix": "166-ARR_v2_38@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_39",
            "tgt_ix": "166-ARR_v2_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_39",
            "tgt_ix": "166-ARR_v2_39@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_39",
            "tgt_ix": "166-ARR_v2_39@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_39",
            "tgt_ix": "166-ARR_v2_39@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_40",
            "tgt_ix": "166-ARR_v2_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_41",
            "tgt_ix": "166-ARR_v2_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_41",
            "tgt_ix": "166-ARR_v2_41@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_42",
            "tgt_ix": "166-ARR_v2_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_43",
            "tgt_ix": "166-ARR_v2_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_43",
            "tgt_ix": "166-ARR_v2_43@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_43",
            "tgt_ix": "166-ARR_v2_43@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_43",
            "tgt_ix": "166-ARR_v2_43@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_44",
            "tgt_ix": "166-ARR_v2_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_44",
            "tgt_ix": "166-ARR_v2_44@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_44",
            "tgt_ix": "166-ARR_v2_44@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_45",
            "tgt_ix": "166-ARR_v2_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_45",
            "tgt_ix": "166-ARR_v2_45@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_45",
            "tgt_ix": "166-ARR_v2_45@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_45",
            "tgt_ix": "166-ARR_v2_45@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_45",
            "tgt_ix": "166-ARR_v2_45@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_45",
            "tgt_ix": "166-ARR_v2_45@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_45",
            "tgt_ix": "166-ARR_v2_45@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_45",
            "tgt_ix": "166-ARR_v2_45@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_45",
            "tgt_ix": "166-ARR_v2_45@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_45",
            "tgt_ix": "166-ARR_v2_45@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_46",
            "tgt_ix": "166-ARR_v2_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_46",
            "tgt_ix": "166-ARR_v2_46@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_47",
            "tgt_ix": "166-ARR_v2_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_48",
            "tgt_ix": "166-ARR_v2_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_48",
            "tgt_ix": "166-ARR_v2_48@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_48",
            "tgt_ix": "166-ARR_v2_48@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_48",
            "tgt_ix": "166-ARR_v2_48@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_49",
            "tgt_ix": "166-ARR_v2_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_50",
            "tgt_ix": "166-ARR_v2_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_50",
            "tgt_ix": "166-ARR_v2_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_51",
            "tgt_ix": "166-ARR_v2_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_51",
            "tgt_ix": "166-ARR_v2_51@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_52",
            "tgt_ix": "166-ARR_v2_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_53",
            "tgt_ix": "166-ARR_v2_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_53",
            "tgt_ix": "166-ARR_v2_53@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_53",
            "tgt_ix": "166-ARR_v2_53@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_53",
            "tgt_ix": "166-ARR_v2_53@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_54",
            "tgt_ix": "166-ARR_v2_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_55",
            "tgt_ix": "166-ARR_v2_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_55",
            "tgt_ix": "166-ARR_v2_55@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_56",
            "tgt_ix": "166-ARR_v2_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_57",
            "tgt_ix": "166-ARR_v2_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_57",
            "tgt_ix": "166-ARR_v2_57@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_57",
            "tgt_ix": "166-ARR_v2_57@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_57",
            "tgt_ix": "166-ARR_v2_57@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_57",
            "tgt_ix": "166-ARR_v2_57@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_57",
            "tgt_ix": "166-ARR_v2_57@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_57",
            "tgt_ix": "166-ARR_v2_57@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_57",
            "tgt_ix": "166-ARR_v2_57@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_58",
            "tgt_ix": "166-ARR_v2_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_58",
            "tgt_ix": "166-ARR_v2_58@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_58",
            "tgt_ix": "166-ARR_v2_58@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_59",
            "tgt_ix": "166-ARR_v2_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_59",
            "tgt_ix": "166-ARR_v2_59@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_59",
            "tgt_ix": "166-ARR_v2_59@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_59",
            "tgt_ix": "166-ARR_v2_59@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_59",
            "tgt_ix": "166-ARR_v2_59@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_60",
            "tgt_ix": "166-ARR_v2_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_60",
            "tgt_ix": "166-ARR_v2_60@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_60",
            "tgt_ix": "166-ARR_v2_60@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_61",
            "tgt_ix": "166-ARR_v2_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_62",
            "tgt_ix": "166-ARR_v2_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_62",
            "tgt_ix": "166-ARR_v2_62@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_63",
            "tgt_ix": "166-ARR_v2_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_63",
            "tgt_ix": "166-ARR_v2_63@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_63",
            "tgt_ix": "166-ARR_v2_63@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_63",
            "tgt_ix": "166-ARR_v2_63@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_63",
            "tgt_ix": "166-ARR_v2_63@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_63",
            "tgt_ix": "166-ARR_v2_63@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_63",
            "tgt_ix": "166-ARR_v2_63@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_63",
            "tgt_ix": "166-ARR_v2_63@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_63",
            "tgt_ix": "166-ARR_v2_63@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_64",
            "tgt_ix": "166-ARR_v2_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_65",
            "tgt_ix": "166-ARR_v2_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_65",
            "tgt_ix": "166-ARR_v2_65@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_65",
            "tgt_ix": "166-ARR_v2_65@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_65",
            "tgt_ix": "166-ARR_v2_65@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_66",
            "tgt_ix": "166-ARR_v2_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_66",
            "tgt_ix": "166-ARR_v2_66@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_67",
            "tgt_ix": "166-ARR_v2_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_67",
            "tgt_ix": "166-ARR_v2_67@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_68",
            "tgt_ix": "166-ARR_v2_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_68",
            "tgt_ix": "166-ARR_v2_68@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_69",
            "tgt_ix": "166-ARR_v2_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_69",
            "tgt_ix": "166-ARR_v2_69@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_69",
            "tgt_ix": "166-ARR_v2_69@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_69",
            "tgt_ix": "166-ARR_v2_69@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_69",
            "tgt_ix": "166-ARR_v2_69@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_69",
            "tgt_ix": "166-ARR_v2_69@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_69",
            "tgt_ix": "166-ARR_v2_69@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_70",
            "tgt_ix": "166-ARR_v2_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_71",
            "tgt_ix": "166-ARR_v2_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_71",
            "tgt_ix": "166-ARR_v2_71@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_71",
            "tgt_ix": "166-ARR_v2_71@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_72",
            "tgt_ix": "166-ARR_v2_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_72",
            "tgt_ix": "166-ARR_v2_72@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_72",
            "tgt_ix": "166-ARR_v2_72@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_73",
            "tgt_ix": "166-ARR_v2_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_73",
            "tgt_ix": "166-ARR_v2_73@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_74",
            "tgt_ix": "166-ARR_v2_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_74",
            "tgt_ix": "166-ARR_v2_74@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_74",
            "tgt_ix": "166-ARR_v2_74@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_74",
            "tgt_ix": "166-ARR_v2_74@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_74",
            "tgt_ix": "166-ARR_v2_74@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_74",
            "tgt_ix": "166-ARR_v2_74@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_74",
            "tgt_ix": "166-ARR_v2_74@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_75",
            "tgt_ix": "166-ARR_v2_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_76",
            "tgt_ix": "166-ARR_v2_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_76",
            "tgt_ix": "166-ARR_v2_76@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_76",
            "tgt_ix": "166-ARR_v2_76@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_76",
            "tgt_ix": "166-ARR_v2_76@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_77",
            "tgt_ix": "166-ARR_v2_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_78",
            "tgt_ix": "166-ARR_v2_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_78",
            "tgt_ix": "166-ARR_v2_78@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_78",
            "tgt_ix": "166-ARR_v2_78@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_79",
            "tgt_ix": "166-ARR_v2_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_79",
            "tgt_ix": "166-ARR_v2_79@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_80",
            "tgt_ix": "166-ARR_v2_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_81",
            "tgt_ix": "166-ARR_v2_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_81",
            "tgt_ix": "166-ARR_v2_81@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_82",
            "tgt_ix": "166-ARR_v2_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_83",
            "tgt_ix": "166-ARR_v2_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_83",
            "tgt_ix": "166-ARR_v2_83@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_84",
            "tgt_ix": "166-ARR_v2_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_85",
            "tgt_ix": "166-ARR_v2_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_85",
            "tgt_ix": "166-ARR_v2_85@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_85",
            "tgt_ix": "166-ARR_v2_85@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_85",
            "tgt_ix": "166-ARR_v2_85@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_85",
            "tgt_ix": "166-ARR_v2_85@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_85",
            "tgt_ix": "166-ARR_v2_85@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_85",
            "tgt_ix": "166-ARR_v2_85@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_85",
            "tgt_ix": "166-ARR_v2_85@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_86",
            "tgt_ix": "166-ARR_v2_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_86",
            "tgt_ix": "166-ARR_v2_86@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_87",
            "tgt_ix": "166-ARR_v2_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_87",
            "tgt_ix": "166-ARR_v2_87@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_87",
            "tgt_ix": "166-ARR_v2_87@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_87",
            "tgt_ix": "166-ARR_v2_87@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_87",
            "tgt_ix": "166-ARR_v2_87@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_87",
            "tgt_ix": "166-ARR_v2_87@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_87",
            "tgt_ix": "166-ARR_v2_87@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_87",
            "tgt_ix": "166-ARR_v2_87@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_87",
            "tgt_ix": "166-ARR_v2_87@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_87",
            "tgt_ix": "166-ARR_v2_87@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_87",
            "tgt_ix": "166-ARR_v2_87@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_87",
            "tgt_ix": "166-ARR_v2_87@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_87",
            "tgt_ix": "166-ARR_v2_87@12",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_87",
            "tgt_ix": "166-ARR_v2_87@13",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_88",
            "tgt_ix": "166-ARR_v2_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_88",
            "tgt_ix": "166-ARR_v2_88@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_88",
            "tgt_ix": "166-ARR_v2_88@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_88",
            "tgt_ix": "166-ARR_v2_88@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_88",
            "tgt_ix": "166-ARR_v2_88@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_88",
            "tgt_ix": "166-ARR_v2_88@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_88",
            "tgt_ix": "166-ARR_v2_88@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_89",
            "tgt_ix": "166-ARR_v2_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_89",
            "tgt_ix": "166-ARR_v2_89@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_89",
            "tgt_ix": "166-ARR_v2_89@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_89",
            "tgt_ix": "166-ARR_v2_89@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_89",
            "tgt_ix": "166-ARR_v2_89@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_89",
            "tgt_ix": "166-ARR_v2_89@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_90",
            "tgt_ix": "166-ARR_v2_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_90",
            "tgt_ix": "166-ARR_v2_90@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_90",
            "tgt_ix": "166-ARR_v2_90@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_90",
            "tgt_ix": "166-ARR_v2_90@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_90",
            "tgt_ix": "166-ARR_v2_90@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_91",
            "tgt_ix": "166-ARR_v2_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_91",
            "tgt_ix": "166-ARR_v2_91@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_91",
            "tgt_ix": "166-ARR_v2_91@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_91",
            "tgt_ix": "166-ARR_v2_91@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_92",
            "tgt_ix": "166-ARR_v2_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_92",
            "tgt_ix": "166-ARR_v2_92@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_92",
            "tgt_ix": "166-ARR_v2_92@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_93",
            "tgt_ix": "166-ARR_v2_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_94",
            "tgt_ix": "166-ARR_v2_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_95",
            "tgt_ix": "166-ARR_v2_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_95",
            "tgt_ix": "166-ARR_v2_95@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_96",
            "tgt_ix": "166-ARR_v2_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_96",
            "tgt_ix": "166-ARR_v2_96@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_96",
            "tgt_ix": "166-ARR_v2_96@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_97",
            "tgt_ix": "166-ARR_v2_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_97",
            "tgt_ix": "166-ARR_v2_97@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_97",
            "tgt_ix": "166-ARR_v2_97@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_97",
            "tgt_ix": "166-ARR_v2_97@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_97",
            "tgt_ix": "166-ARR_v2_97@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_97",
            "tgt_ix": "166-ARR_v2_97@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_97",
            "tgt_ix": "166-ARR_v2_97@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_98",
            "tgt_ix": "166-ARR_v2_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_98",
            "tgt_ix": "166-ARR_v2_98@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_98",
            "tgt_ix": "166-ARR_v2_98@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_99",
            "tgt_ix": "166-ARR_v2_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_99",
            "tgt_ix": "166-ARR_v2_99@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_99",
            "tgt_ix": "166-ARR_v2_99@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_99",
            "tgt_ix": "166-ARR_v2_99@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_100",
            "tgt_ix": "166-ARR_v2_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_100",
            "tgt_ix": "166-ARR_v2_100@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_100",
            "tgt_ix": "166-ARR_v2_100@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_100",
            "tgt_ix": "166-ARR_v2_100@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_100",
            "tgt_ix": "166-ARR_v2_100@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_100",
            "tgt_ix": "166-ARR_v2_100@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_100",
            "tgt_ix": "166-ARR_v2_100@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_101",
            "tgt_ix": "166-ARR_v2_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_101",
            "tgt_ix": "166-ARR_v2_101@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_101",
            "tgt_ix": "166-ARR_v2_101@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_101",
            "tgt_ix": "166-ARR_v2_101@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_101",
            "tgt_ix": "166-ARR_v2_101@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_101",
            "tgt_ix": "166-ARR_v2_101@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_101",
            "tgt_ix": "166-ARR_v2_101@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_102",
            "tgt_ix": "166-ARR_v2_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_103",
            "tgt_ix": "166-ARR_v2_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_104",
            "tgt_ix": "166-ARR_v2_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_105",
            "tgt_ix": "166-ARR_v2_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_106",
            "tgt_ix": "166-ARR_v2_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_107",
            "tgt_ix": "166-ARR_v2_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_108",
            "tgt_ix": "166-ARR_v2_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_109",
            "tgt_ix": "166-ARR_v2_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_110",
            "tgt_ix": "166-ARR_v2_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_111",
            "tgt_ix": "166-ARR_v2_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_112",
            "tgt_ix": "166-ARR_v2_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_113",
            "tgt_ix": "166-ARR_v2_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_114",
            "tgt_ix": "166-ARR_v2_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_115",
            "tgt_ix": "166-ARR_v2_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_116",
            "tgt_ix": "166-ARR_v2_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_117",
            "tgt_ix": "166-ARR_v2_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_118",
            "tgt_ix": "166-ARR_v2_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_119",
            "tgt_ix": "166-ARR_v2_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_120",
            "tgt_ix": "166-ARR_v2_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_121",
            "tgt_ix": "166-ARR_v2_121@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_122",
            "tgt_ix": "166-ARR_v2_122@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_123",
            "tgt_ix": "166-ARR_v2_123@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_124",
            "tgt_ix": "166-ARR_v2_124@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_125",
            "tgt_ix": "166-ARR_v2_125@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_126",
            "tgt_ix": "166-ARR_v2_126@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_127",
            "tgt_ix": "166-ARR_v2_127@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_128",
            "tgt_ix": "166-ARR_v2_128@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_129",
            "tgt_ix": "166-ARR_v2_129@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_130",
            "tgt_ix": "166-ARR_v2_130@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_131",
            "tgt_ix": "166-ARR_v2_131@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_132",
            "tgt_ix": "166-ARR_v2_132@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_133",
            "tgt_ix": "166-ARR_v2_133@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_134",
            "tgt_ix": "166-ARR_v2_134@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_135",
            "tgt_ix": "166-ARR_v2_135@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_136",
            "tgt_ix": "166-ARR_v2_136@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_137",
            "tgt_ix": "166-ARR_v2_137@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_138",
            "tgt_ix": "166-ARR_v2_138@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_139",
            "tgt_ix": "166-ARR_v2_139@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_140",
            "tgt_ix": "166-ARR_v2_140@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_141",
            "tgt_ix": "166-ARR_v2_141@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_142",
            "tgt_ix": "166-ARR_v2_142@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_143",
            "tgt_ix": "166-ARR_v2_143@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_144",
            "tgt_ix": "166-ARR_v2_144@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_145",
            "tgt_ix": "166-ARR_v2_145@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_146",
            "tgt_ix": "166-ARR_v2_146@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "166-ARR_v2_147",
            "tgt_ix": "166-ARR_v2_147@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 1130,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "doc_id": "166-ARR",
        "version": 2
    }
}