{
    "nodes": [
        {
            "ix": "6-ARR_v2_0",
            "content": "Inverse is Better! Fast and Accurate Prompt for Few-shot Slot Tagging",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_2",
            "content": "Prompting methods recently achieve impressive success in few-shot learning. These methods modify input samples with prompt sentence pieces, and decode label tokens to map samples to corresponding labels. However, such a paradigm is very inefficient for the task of slot tagging. Since slot tagging samples are multiple consecutive words in a sentence, the prompting methods have to enumerate all n-grams token spans to find all the possible slots, which greatly slows down the prediction. To tackle this, we introduce an inverse paradigm for prompting. Different from the classic prompts mapping tokens to labels, we reversely predict slot values given slot types. Such inverse prompting only requires a oneturn prediction for each slot type and greatly speeds up the prediction. Besides, we propose a novel Iterative Prediction Strategy, from which the model learns to refine predictions by considering the relations between different slot types. We find, somewhat surprisingly, the proposed method not only predicts faster but also significantly improves the effect (improve over 6.1 F1-scores on 10-shot setting) and achieves new state-of-the-art performance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "6-ARR_v2_4",
            "content": "Few-shot learning (FSL) aims at learning a model from only a few examples and is regarded as one of the key steps toward more human-like artificial intelligence (Wang et al., 2020). Recently, promptbased methods achieve impressive results and show promising prospects for few-shot learning of Natural Language Processing (NLP) (Liu et al., 2021a;.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_5",
            "content": "Prompt-based methods reformulate a target task into the language modeling problem, which takes advantages of the powerful pretrained Language Models (LM) (Devlin et al., 2019; For normal prompts, identifying all slots in the query sentence requires enumeration of all spans, while inverse prompt only needs 1-time prediction for each label. Lewis et al., 2020;Brown et al., 2020). For example, when classifying the sentiment of the movie review \"no reason to watch\", prompting methods insert a piece of text \"It was\", i.e. prompts, to the input example, getting \"No reason to watch. It was __\". It is natural to expect a higher probability from the LM to fill the template with \"terrible\" than \"great\", and the original task is then converted to a language modeling task. Such conversion reduces the gap between pretraining and target tasks, which allows less dependency on target task data and helps to achieve better performance in low data scenarios (Gao et al., 2021). However, while achieving great success in sentence level tasks, prompting-based methods show incompatibility for sequence labeling tasks, such as slot tagging. Firstly, the aforementioned prompting paradigm is quite inefficient for slot tagging tasks. Different from the sentence-level tasks that classify samples of whole sentences, slot tagging samples are multiple consecutive words in a sentence. Therefore, as shown in Fig. 1, to find all the possible slots, prompt-based methods have to enumerate all n-gram word spans, and then query LM for each of them, which greatly slows down the prediction (Cui et al., 2021). Further, as a structure prediction problem, slot tagging benefits from taking the dependencies between labels into account (Ma and Hovy, 2016;Hou et al., 2020). For example in Fig. 1, where the arrival entity often appears after a departure entity. Such label dependency is hard to be captured by current prompting methods since they predict labels one-by-one independently.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_6",
            "content": "To tackle the above issues, we introduce an inverse paradigm for prompting. Different from the classic prompts mapping tokens to labels, we reversely predict slot values given slot types. For the example in Fig. 1, we use an inverse prompt to modify the input as \"book a flight from Beijing to New York tomorrow morning. arrival refers to __\", and then LM is able to decode multi-word span \"New York\" at a time. Compared to the classic prompts that require predictions for every n-gram word span (55-times in Fig. 1), we only need to perform decoding for V -times, where V is the number of label types (4-times in Fig. 1), which therefore greatly speeds up the prediction. Surprisingly, experiments show the proposed method not only predicts faster but also significantly improves the performance, indicating that prompting LM reversely is a better fit for the slot tagging task. Besides, to further improve the prediction accuracy, we propose a novel Iterative Prediction Strategy, from which the model learns to refine predictions by considering the relations between different slot types.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_7",
            "content": "To summarize the contribution of this work:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_8",
            "content": "(1) We introduce the idea of inverse prediction to prompting methods for slot tagging tasks, which greatly speeds up the prediction process.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_9",
            "content": "(2) We propose an Iterative Prediction Strategy for learning and prediction with slot tagging prompts, which allows the prompting model to consider dependency between different slot types and refine prediction.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_10",
            "content": "(3) We extensively evaluate the proposed method in various few-shot settings, where the proposed method brings significant improvements not only in speed but also in accuracy.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_11",
            "content": "The code and data are available at https://github.com/AtmaHou/ PromptSlotTagging.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_12",
            "content": "Background",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "6-ARR_v2_13",
            "content": "In this section, we begin with a formal definition of the few-shot slot tagging task ( \u00a72.1), and then introduce the conventional sequence labeling approaches ( \u00a72.2) and recent prompts-based methods ( \u00a72.3) for this task.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_14",
            "content": "Few Shot Slot Tagging",
            "ntype": "title",
            "meta": {
                "section": "2.1"
            }
        },
        {
            "ix": "6-ARR_v2_15",
            "content": "Slot tagging aims at finding key slots within a sentence, such as time or location entities. Given an input sentence x = (x 1 , x 2 , . . . , x n ) as a sequence of words, a slot tagging model extracts all M slot label-values pairs y = {(l i , s i )} M i=1 in the sentence, where l i is the ith label in the label set L and s k j = {x j , ..., x k } is a word span starting from x j and ending with x k .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_16",
            "content": "In few-shot settings, model are often evaluated on multiple low-resource domains {D",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_17",
            "content": "(1)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_18",
            "content": "L , D(2)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_19",
            "content": "L , ...}, which is called target domain (Wang et al., 2020). Each target domain D (j) L only contains a few labeled instances called support set S = {(x (i) , y (i) )} N S i=1 , which usually includes K examples (K-shot) for each of N labels (N-way). On each target domain, given support set examples as references, few-shot slot tagging models are required to make predictions for query set samples. Optionally, some few-shot settings also include a set of data-rich domains {D",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_20",
            "content": "(1)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_21",
            "content": "H , D(2)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_22",
            "content": "H , ...} called source domains, which are used for pretraining of few-shot models.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_23",
            "content": "Conventional Sequence Labeling Approaches",
            "ntype": "title",
            "meta": {
                "section": "2.2"
            }
        },
        {
            "ix": "6-ARR_v2_24",
            "content": "Conventional approaches often formulate slot tagging as a sequence labeling problem, where each word in input is associated with a sequence label. Given sentence x = (x 1 , x 2 , . . . , x n ) as input, these method predicts the best-match sequence labels y = (y 1 , y 2 , ..., y n ). To predict slots with multiple words, sequence labeling approaches adopt a \"BIO\" labeling strategy, which uses \"B\" to mark the begin word of a slot, \"I\" to mark the inner words of a slot and \"O\" to mark non-slot words. For the example in the Fig. sequence labeling model is usually formulated as:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_25",
            "content": "h 1:n = Encoder(x 1:n ), p(y i |x, S) = Softmax(Decoder(h i )), (i \u2208 [1, 2, ..., n]), y * = (y 1 , y 2 , ..., y n ) = arg max y p(y|x, S),",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_26",
            "content": "where S is a K-shot support set, Encoder is usually a pretrained language model such as BERT (Devlin et al., 2019), h 1:n is the hidden state of the encoder with a dimension d h , and Decoder can either be a linear layer, a CRF layer or any other parametric or non-parametric classifier.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_27",
            "content": "Sequence Labeling with Prompts",
            "ntype": "title",
            "meta": {
                "section": "2.3"
            }
        },
        {
            "ix": "6-ARR_v2_28",
            "content": "Prompt-based methods have been proven effective in many NLU tasks, especially in few-shot settings, but things become complicated when it comes to slot tagging tasks. To identify the slot label for a word span s j i = {x i , ..., x j } in sentence x, previous works construct templates, e.g., \"[x] [s j i ] is a [z] entity\", and prompt a pretrained language model with such templates to predict label-related words [z] (Cui et al., 2021). For example in the Fig. 2(b), predicting the time slot can be achieved as \"book a flight from Beijing to New York tomorrow morning. tomorrow morning is a time entity.\" However, to find all possible slots, these methods need to traverse all the n-gram spans s j i , i, j \u2208 [1, n] in a sentence, which is quite expensive in time and computation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_29",
            "content": "Method",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "6-ARR_v2_30",
            "content": "To remedy the high cost of prompt prediction mentioned in the previous section, we introduce a novel inverse paradigm for prompting of slot tagging task, which significantly improves the speed of prediction by transforming the past fill-in-the-blank problem into a generative task. Specifically, we first introduce the construction of our inverse prompts templates ( \u00a73.1), and then describe how to use inverse prompts during training and inference ( \u00a73.2).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_31",
            "content": "Further, we propose an Iterative Prediction Strategy to refine prediction by considering the relation between different slot types ( \u00a73.3). The overview of proposed method is shown in Fig. 3.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_32",
            "content": "Prompt Creation",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "6-ARR_v2_33",
            "content": "In this section, we introduce the creation of the proposed inverse prompts, which includes three main components: the label mapping, the inverse template and the control tokens.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_34",
            "content": "Label Mapping Before prompt construction, we first need to convert each label into a word form that can be easily understood by the pre-trained language model. We employ a label mapping process to achieve this, which use a one-to-one mapping function to convert the label set L = {l 1 , . . . , l |L| } to a natural language word set L = { l1 , . . . , l|L| }. For example, in Fig. 3, we convert the label set L = {from.Loc, to.Loc, Time, Price} to a natural language label set L = { departure, arrival, time, price}.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_35",
            "content": "Inverse Template Prompt template is a piece of sentence with blanks, which is used to modify the original inputs and get prompting inputs for a pretrained language model. To achieve inverse prompting, our template fills in an original sentence and a label as prefixes and subsequently leaves blanks for the LM to generate the corresponding slot values. Specifically, given an input sentence s and a set of mapped labels L, for each mapped label li \u2208 L, the inverse template is defined as: \"x\" li refers to __ For instance, in Fig. 3, we fill the input \"book a flight from beijing to new york tomorrow morning\" and each label in L into the template to get four prompted inputs p: \"book a flight from beijing to new york tomorrow morning\" departure refers to __ \"book a flight from beijing to new york tomorrow morning\" arrival refers to __ \"book a flight from beijing to new york tomorrow morning\" time refers to __ \"book a flight from beijing to new york tomorrow morning\" price refers to __ Control tokens Additionally, we introduce control tokens C to complete the prompts function for the slot tagging task. In order to recognize the case that there's no corresponding entity of the queried slot type, we introduce <NONE> token to pad the output, and in practice, we use \"none\" as <NONE> token to make the model output more natural. In order to tag more than one entity of the same slot type, we introduce \";\" as <SEP> to divide more than one entity of the same slot type. And we also use \".\" as <END> token to indicate the end of a single generation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_36",
            "content": "Training and Inference with Inverse Prompts",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "6-ARR_v2_37",
            "content": "Till now, we have presented the construction of the inverse prompt. This section will show how to perform training and inference with the prompts.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_38",
            "content": "Training At the training time, we pre-construct the prompt with answers such as \"book a flight from beijing to new york tomorrow morning\" departure refers to new york . Then we finetune a pre-trained language model with the answered prompts, and we only calculate loss on the answer tokens (i.e. new york) instead of the loss on the whole sentence.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_39",
            "content": "L = i>|p| CE( \u0177i , y i )",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_40",
            "content": "where |p| is the length of the prompted input, \u0177i denotes the model predictions, and y i is the preconstructed answer.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_41",
            "content": "Inference At the inference time, we feed the prompted inputs into the fine-tuned pre-trained language model and let LM generate the appeared slot values. During generation, we restrict LM to generate only words that appear in the original input sentence or predefined control words. For each prompted input p, the next token t k \u2208 x \u222a C is determined by language model probability:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_42",
            "content": "t k = arg max t k \u2208s\u222aC p LM (t k |p; t 1:k\u22121 )",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_43",
            "content": "Note that restricting the scope of output tokens is crucial to the performance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_44",
            "content": "Iterative Prediction Strategy",
            "ntype": "title",
            "meta": {
                "section": "3.3"
            }
        },
        {
            "ix": "6-ARR_v2_45",
            "content": "In the previous section, different slot types are predicted separately. To consider the relations between different slot types, we introduce the Iterative Prediction Strategy, which also provides the model a second chance to revise those unrecognized entities. We assume that different labels are interactive, so the predicted slots could be used as a hint to help predict the missed slots. For example in Fig. 3, it is often easier to generate the \"arrival\" slot given the results of \"departure\" and \"time\". Motivated by this, as shown in the Fig. 3 We randomly select some occurred labels (e.g., \"arrival\") pretending it was not predicted, and construct a second round prompt: \"book a flight from beijing to new york tomorrow morning\" departure refers to beijing . time refers to tomorrow morning . price refers to none . arrival refers to __. By using these second round prompts for model training, we encourage the language model to find those unrecognized slots in the first round prediction and allow the model to consider relationships between labels.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_46",
            "content": "Inference During the inference time, we construct the second-round prompts and revise the slots that are not recognized in the first round. For example in the Fig. 3, the model predict none value for \"price\" and \"arrival\" slot in the first round. We then construct another iteration of the prompted inputs that query the unrecognized slots, given all the labels and slot values that have been predicted: \"book a flight from beijing to new york tomorrow morning\" departure refers to beijing . time refers to tomorrow morning . arrival refers to __. \"book a flight from beijing to new york tomorrow morning\" departure refers to beijing . time refers to tomorrow morning . price refers to __ .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_47",
            "content": "The model is expected to predict the first-round missed slots during the second iteration, considering relations between labels.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_48",
            "content": "Experiment",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "6-ARR_v2_49",
            "content": "We evaluate the performance of the proposed method on two classic few-shot scenarios: (1) Setting with Only In-domain data, where all training data are only a few labeled support data.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_50",
            "content": "(2) Setting with Meta Source Tasks, where some additional data-rich source domains are available for pretraining.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_51",
            "content": "Evaluation To use same evaluation criteria as conventional sequence labeling methods, we need to label tokens reversely and get output in same format. After generation, we first separate outputs into slot values. For each slot value, we label tokens in the source sentence with three principles: (1) Slot value is complete: only if the whole slot value matches a span in the source sentence, we label it with the corresponding label.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_52",
            "content": "(2) Choose the first overlap predicted slot span: if any token in the source sentence has been labeled, we do not relabel this token even when it matches another slot value.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_53",
            "content": "(3) Use BIO labels: add \"B-\" to the beginning token of the slot span, add \"I-\" to the non-begin token of the slot span, and label non-slot tokens with \"O\". After labeling tokens reversely, we evaluate F1 scores within each few-shot episode. \u2022 Sequence Labeling BERT (Devlin et al., 2019) can be seen as a BERT-based sequence labeling baseline which fine-tunes the BERT model with a token-level linear classifier head.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_54",
            "content": "\u2022 Template-based BART (Cui et al., 2021) is a prompt-based method that query BART-based LM (Lewis et al., 2020) every possible span in sentence if it belong to a certain category and therefore also need to enumerate all label for inference. \u2022 NNShot and StructShot (Yang and Katiyar, 2020) are two metric-based few-shot learning approaches for slot tagging and NER. NNShot is an instance-level nearest neighbor classifier for fewshot prediction, and StructShot promotes NNShot with a Viterbi algorithm during decoding. \u2022 EntLM (Ma et al., 2021b) is a prompt-based method that leverage substitution between words of the same type to achieve one pass prediction.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_55",
            "content": "Results Table 1 shows the results of the proposed method only finetuned on few-shot in-domain data. Among these results, we can observe that:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_56",
            "content": "(1) Our proposed method performs consistently better than all the baseline methods on all three datasets. It outperforms the strongest baseline Template-based BART which uses BART-large by average F1 scores on three datasets of 11.96 in 10shot setting even with a much smaller pre-trained language model (the smallest GPT2).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_57",
            "content": "(2) Our proposed method is even comparable or outperforms those baselines with data-rich domain pre-training.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_58",
            "content": "(3) Our proposed method performs much better than baselines in fewer labeled samples settings, especially in 10 and 20 shot settings, which indicates our method can leverage information from limited labeled data more efficiently. (4) Our method significantly outperformed Sequence Labeling BERT whose performance is quite poor on 10 and 20 shot settings, which indicates that the number of labeled data is too scarce for conventional sequence labeling tasks, and proves that the prompt-based method is effective in few-shot slot tagging tasks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_59",
            "content": "(5) The proposed Iterative Strategy consistently improves the slot tagging performance. The improvements become greater with fewer learning shots and the averaged improvement in 10 and 20 shot setting on three datasets are 2.23 and 1.44. This shows that when there is less data, the iterative revising mechanism is more important.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_60",
            "content": "Setting with Meta Source Tasks",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "6-ARR_v2_61",
            "content": "Datasets We also evaluate the model ability of transferring from data-rich domains to unseen few-shot domains and conduct experiments on SNIPS (Coucke et al., 2018) dataset. Following the data split provided by Hou et al. (2020), we construct 5-shot SNIPS datasets from the original SNIPS datasets. The few-shot SNIPS dataset consists of 7 domains with different label sets: GetWeather (We), Music (Mu), PlayList (Pl), Rate-Book (Bo), SearchScreenEvent (Se), BookRestaurant (Re), and SearchCreativeWork (Cr). Each domain contains 100 few-shot episodes, and each episode consists of a support set and a query.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_62",
            "content": "Implements Following Henderson and Vulic (2021), we conduct our cross-domain experiments with 5-shot few-shot settings to evaluate the ability of our model to transfer from rich-data domains to unseen few-shot domains. For our proposed method, same as in-domain settings, we use the smallest GPT2 as the base model, and no new parameters are introduced. We pretrain the model in source domains and fine-tune it on the target fewshot domain. We set learning rate as 6.25e \u2212 5 and batch size as 16 for pretraining and batch size as 2 for 5-shot finetuning. During finetuning, we use the same AdamW optimizer and linear decaying scheduler. The hyper-parameters are decided according to performance on the dev set. Data and code used are public available.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_63",
            "content": "Baselines We provided competitive strong baselines, including traditional finetune-based methods and advanced few-shot learning methods.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_64",
            "content": "\u2022 Bi-LSTM (Schuster and Paliwal, 1997) uses GLoVe (Pennington et al., 2014) embedding for slot tagging and is trained on the support sets. \u2022 SimBERT is a metric-based method using cosine similarity of BERT-based embedding to label tokens with the most similar token's label. \u2022 Matching Network (MN) (Vinyals et al., 2016) is a few-shot sequence labeling model based on the matching network and uses BERT embedding. \u2022 TransferBERT is a domain transfer-based conventional NER model using BERT, which is first pre-trained on source domains and then fine-tuned on the target domain support set. \u2022 WPZ (Fritzler et al., 2019) is a metric-based few-shot slot tagging method similar to MN, but is based on the prototypical network (Snell et al., 2017). \u2022 TapNet+CDT, L-TapNet+CDT, L-WPZ+CDT (Hou et al., 2020) are metric-based few-shot learning methods designed for slot tagging, which introduces a CRF-based framework to consider the relation between different slots. \u2022 ConVEx (Henderson and Vulic, 2021) is a finetuning-based method that models slot tagging as a cloze task and is first pre-trained on Reddit data then fine-tuned on few-shot slot tagging data. Note that the Reddit data is not used by our method and other baselines during the experiments.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_65",
            "content": "Table 2 shows the results of the crossdomain few-shot setting, from which we can observe that:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_66",
            "content": "(1) Our proposed method outperforms all the baselines except ConVEx which uses extra Reddit data in the cross-domain 5-shot setting. Despite using less training data, our model still achieves comparable results with Covex, proving its superiority.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_67",
            "content": "(2) We outperform TransferBERT by 42.36 F1 scores which strongly proved that the prompt-based method can transfer more knowledge from the source domain and is more data-efficient than conventional methods.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_68",
            "content": "(3) Our method outperforms metric-based few-shot learning baselines, for example, 2.24 F1 scores higher than L-TapNet+CDT, which proves its competitiveness compared to classical few-shot learning methods.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_69",
            "content": "(4) Our Iterative Prediction Strategy improved Our method by about 0.5 F1 scores, demonstrating that the revising ability is likely to be transferable and is effective under cross-domain scenarios.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_70",
            "content": "Analysis",
            "ntype": "title",
            "meta": {
                "section": "4.3"
            }
        },
        {
            "ix": "6-ARR_v2_71",
            "content": "Effects of Iterative Prediction Strategy As shown in Table 1, the proposed Iterative Prediction Learning brings consistent improvement, especially in low-resource settings. It works by revising predictions with a second-round query to recognize those missing slots, which can bring an increase in recall score. To confirm that, we make a detailed analysis with precision score (P), recall score (R) and F1 score (F) in Table 3.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_72",
            "content": "When Iterative Revise Strategy is added, we can get a rise in recall score about 4 points in 10-shot, 2~4 points in 20 shot and more than 1 points in other shot settings in exchange for a slight precision drop, resulting in a rise in overall F1 score by about 2 points in 10 and 20 shots. We further explore the effect of jointly learning of the first-round prediction and the second-round revising, and learn two abilities separately with two models. As shown in and much smaller than the number of spans, so that this growth does not affect the value of our method in practice. Besides, we find no significant correlation between the number of labels and our performance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_73",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "6-ARR_v2_74",
            "content": "Prompt-based learning Prompt-based learning approaches have been a broadly discussed topic since large language models like GPT models (Brown et al., 2020) 2021) proposes a template-based method querying every slot span with each label which is expensive for decoding. Different from them, we introduce an inverse paradigm for prompting slot tagging tasks. Note that inverse prompting (Zou et al., 2021) has a similar name to our work but is entirely different in method and task. They aim to generate prompt templates inversely. Amendable generation (Tian et al., 2021) share a similar idea of using Iterative Prediction Strategy to generate and revise dialog state. By contrast, we focus on a different task for sequence labeling and first introduce an Iterative Prediction Strategy to prompting models. There are also generation-based methods for sequence labeling (Yan et al., 2021), which is not a prompting method, since it re-initializes decoding layers and learns a generative model from scratch.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_75",
            "content": "Few-shot slot tagging Previous few-shot slot tagging methods focus on metric learning based methods, which classify tokens by word-label similarity (Snell et al., 2017;Vinyals et al., 2016). Hou et al. (2020) leverage label name semantics to get better label representation and model label dependency in few-shot settings. Yang and Katiyar (2020) make a prediction based on the nearest neighbor sample instead of the nearest label representation. Besides, some works also explore training a model with additional data from non-slot-tagging task Henderson and Vulic, 2021)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_76",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "6-ARR_v2_77",
            "content": "In this paper, to liberate the prompting methods from the burdensome prediction of slot-tagging tasks, we introduce a novel inverse prediction manner to prompting methods of slot-tagging, which significantly improves both the efficiency and accuracy. To further improve performance, we propose an Iterative Prediction Strategy for learning, which enables the prompting model to consider dependency between labels and refine prediction. Extensive experiments verify the effectiveness of the proposed method in various few-shot settings, indicating inverse prediction is a better fit for prompting of slot tagging task.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_78",
            "content": "All the scientific artifacts used/created are properly cited/licensed, and the usage is consistent with their intended use. This paper does not collect new datasets, nor does the data used contain sensitive information.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v2_79",
            "content": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners, , Advances in Neural Information Processing Systems, Curran Associates, Inc.",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "Tom Brown",
                    "Benjamin Mann",
                    "Nick Ryder",
                    "Melanie Subbiah",
                    "Jared Kaplan",
                    "Prafulla Dhariwal",
                    "Arvind Neelakantan",
                    "Pranav Shyam",
                    "Girish Sastry",
                    "Amanda Askell",
                    "Sandhini Agarwal",
                    "Ariel Herbert-Voss",
                    "Gretchen Krueger",
                    "Tom Henighan",
                    "Rewon Child",
                    "Aditya Ramesh",
                    "Daniel Ziegler",
                    "Jeffrey Wu",
                    "Clemens Winter",
                    "Chris Hesse",
                    "Mark Chen",
                    "Eric Sigler",
                    "Mateusz Litwin"
                ],
                "title": "Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners",
                "pub_date": null,
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": "Curran Associates, Inc"
            }
        },
        {
            "ix": "6-ARR_v2_80",
            "content": "Sam Coope, Tyler Farghly, Daniela Gerz, Ivan Vulic, Matthew Henderson, Span-convert: Few-shot span extraction for dialog with pretrained conversational representations, 2020, Proc. of the ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Sam Coope",
                    "Tyler Farghly",
                    "Daniela Gerz",
                    "Ivan Vulic",
                    "Matthew Henderson"
                ],
                "title": "Span-convert: Few-shot span extraction for dialog with pretrained conversational representations",
                "pub_date": "2020",
                "pub_title": "Proc. of the ACL",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_81",
            "content": "UNKNOWN, None, 2018, Snips voice platform: an embedded spoken language understanding system for private-by-design voice interfaces, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Snips voice platform: an embedded spoken language understanding system for private-by-design voice interfaces",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_82",
            "content": "Leyang Cui, Yu Wu, Jian Liu, Sen Yang, Yue Zhang, Template-based named entity recognition using BART, 2021, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Leyang Cui",
                    "Yu Wu",
                    "Jian Liu",
                    "Sen Yang",
                    "Yue Zhang"
                ],
                "title": "Template-based named entity recognition using BART",
                "pub_date": "2021",
                "pub_title": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_83",
            "content": "UNKNOWN, None, , , .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": null,
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_84",
            "content": "Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long and Short Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "Kristina Toutanova"
                ],
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Long and Short Papers"
            }
        },
        {
            "ix": "6-ARR_v2_85",
            "content": "Alexander Fritzler, Varvara Logacheva, Maksim Kretov, Few-shot classification in named entity recognition task, 2019, Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "Alexander Fritzler",
                    "Varvara Logacheva",
                    "Maksim Kretov"
                ],
                "title": "Few-shot classification in named entity recognition task",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_86",
            "content": "Tianyu Gao, Adam Fisch, Danqi Chen, Making pre-trained language models better few-shot learners, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Tianyu Gao",
                    "Adam Fisch",
                    "Danqi Chen"
                ],
                "title": "Making pre-trained language models better few-shot learners",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "6-ARR_v2_87",
            "content": "UNKNOWN, None, 2021, Ptr: Prompt tuning with rules for text classification, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Ptr: Prompt tuning with rules for text classification",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_88",
            "content": "Matthew Henderson, Ivan Vulic, Convex: Data-efficient and few-shot slot labeling, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Matthew Henderson",
                    "Ivan Vulic"
                ],
                "title": "Convex: Data-efficient and few-shot slot labeling",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_89",
            "content": "Yutai Hou, Wanxiang Che, Yongkui Lai, Zhihan Zhou, Yijia Liu, Han Liu, Ting Liu, Few-shot slot tagging with collapsed dependency transfer and labelenhanced task-adaptive projection network, 2020, Proc. of ACL, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Yutai Hou",
                    "Wanxiang Che",
                    "Yongkui Lai",
                    "Zhihan Zhou",
                    "Yijia Liu",
                    "Han Liu",
                    "Ting Liu"
                ],
                "title": "Few-shot slot tagging with collapsed dependency transfer and labelenhanced task-adaptive projection network",
                "pub_date": "2020",
                "pub_title": "Proc. of ACL",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "6-ARR_v2_90",
            "content": "Yutai Hou, Yongkui Lai, Cheng Chen, Wanxiang Che, Ting Liu, Learning to bridge metric spaces: Few-shot joint learning of intent detection and slot filling, 2021, Findings of the ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Yutai Hou",
                    "Yongkui Lai",
                    "Cheng Chen",
                    "Wanxiang Che",
                    "Ting Liu"
                ],
                "title": "Learning to bridge metric spaces: Few-shot joint learning of intent detection and slot filling",
                "pub_date": "2021",
                "pub_title": "Findings of the ACL",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_91",
            "content": "UNKNOWN, None, 2020, Few-shot named entity recognition: A comprehensive study, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Few-shot named entity recognition: A comprehensive study",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_92",
            "content": "UNKNOWN, None, 2020, How can we know what language models know? Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "How can we know what language models know? Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_93",
            "content": "Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, Luke Zettlemoyer, BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension, 2020, Proc. of the ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Mike Lewis",
                    "Yinhan Liu",
                    "Naman Goyal",
                    "Marjan Ghazvininejad",
                    "Abdelrahman Mohamed",
                    "Omer Levy",
                    "Veselin Stoyanov",
                    "Luke Zettlemoyer"
                ],
                "title": "BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
                "pub_date": "2020",
                "pub_title": "Proc. of the ACL",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_94",
            "content": "UNKNOWN, None, 2021, Prefix-tuning: Optimizing continuous prompts for generation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Prefix-tuning: Optimizing continuous prompts for generation",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_95",
            "content": "UNKNOWN, None, 2021, What makes good in-context examples for gpt-3? arXiv preprint, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "What makes good in-context examples for gpt-3? arXiv preprint",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_96",
            "content": "Jingjing Liu, Panupong Pasupat, Yining Wang, Scott Cyphers, Jim Glass, Query understanding enhanced by hierarchical parsing structures, 2013, IEEE Workshop on Automatic Speech Recognition and Understanding, IEEE.",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Jingjing Liu",
                    "Panupong Pasupat",
                    "Yining Wang",
                    "Scott Cyphers",
                    "Jim Glass"
                ],
                "title": "Query understanding enhanced by hierarchical parsing structures",
                "pub_date": "2013",
                "pub_title": "IEEE Workshop on Automatic Speech Recognition and Understanding",
                "pub": "IEEE"
            }
        },
        {
            "ix": "6-ARR_v2_97",
            "content": "UNKNOWN, None, , , .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": null,
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_98",
            "content": "UNKNOWN, None, 2019, Roberta: A robustly optimized bert pretraining approach, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Roberta: A robustly optimized bert pretraining approach",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_99",
            "content": "UNKNOWN, None, , , .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": null,
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_100",
            "content": ", Frustratingly simple few-shot slot tagging, 2021, Findings of the ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [],
                "title": "Frustratingly simple few-shot slot tagging",
                "pub_date": "2021",
                "pub_title": "Findings of the ACL",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_101",
            "content": "UNKNOWN, None, 2021, Template-free prompt tuning for few-shot NER, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Template-free prompt tuning for few-shot NER",
                "pub": "CoRR"
            }
        },
        {
            "ix": "6-ARR_v2_102",
            "content": "Xuezhe Ma, Eduard Hovy, End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF, 2016, Proceedings of the 54th Annual Meeting of the Association for Computational LinguisticsACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Xuezhe Ma",
                    "Eduard Hovy"
                ],
                "title": "End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 54th Annual Meeting of the Association for Computational LinguisticsACL",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_103",
            "content": "Jeffrey Pennington, Richard Socher, Christopher Manning, Glove: Global vectors for word representation, 2014, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Pro-cessingEMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Jeffrey Pennington",
                    "Richard Socher",
                    "Christopher Manning"
                ],
                "title": "Glove: Global vectors for word representation",
                "pub_date": "2014",
                "pub_title": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Pro-cessingEMNLP",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_104",
            "content": "Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, Language models are unsupervised multitask learners, 2019, OpenAI blog, .",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Alec Radford",
                    "Jeffrey Wu",
                    "Rewon Child",
                    "David Luan",
                    "Dario Amodei",
                    "Ilya Sutskever"
                ],
                "title": "Language models are unsupervised multitask learners",
                "pub_date": "2019",
                "pub_title": "OpenAI blog",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_105",
            "content": "Timo Schick, Hinrich Sch\u00fctze, Exploiting cloze-questions for few-shot text classification and natural language inference, 2021, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": [
                    "Timo Schick",
                    "Hinrich Sch\u00fctze"
                ],
                "title": "Exploiting cloze-questions for few-shot text classification and natural language inference",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_106",
            "content": "Timo Schick, Hinrich Sch\u00fctze, It's not just size that matters: Small language models are also fewshot learners, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": [
                    "Timo Schick",
                    "Hinrich Sch\u00fctze"
                ],
                "title": "It's not just size that matters: Small language models are also fewshot learners",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_107",
            "content": "Mike Schuster, Kuldip Paliwal, Bidirectional recurrent neural networks, 1997, IEEE Trans. Signal Process, .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Mike Schuster",
                    "Kuldip Paliwal"
                ],
                "title": "Bidirectional recurrent neural networks",
                "pub_date": "1997",
                "pub_title": "IEEE Trans. Signal Process",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_108",
            "content": "UNKNOWN, None, 2020, Autoprompt: Eliciting knowledge from language models with automatically generated prompts, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Autoprompt: Eliciting knowledge from language models with automatically generated prompts",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_109",
            "content": "Jake Snell, Kevin Swersky, Richard Zemel, Prototypical networks for few-shot learning, 2017, Advances in Neural Information Processing Systems, Curran Associates, Inc.",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": [
                    "Jake Snell",
                    "Kevin Swersky",
                    "Richard Zemel"
                ],
                "title": "Prototypical networks for few-shot learning",
                "pub_date": "2017",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": "Curran Associates, Inc"
            }
        },
        {
            "ix": "6-ARR_v2_110",
            "content": "UNKNOWN, None, 2021, Amendable generation for dialogue state tracking, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Amendable generation for dialogue state tracking",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_111",
            "content": "Oriol Vinyals, Charles Blundell, Tim Lillicrap, Koray Kavukcuoglu, Daan Wierstra, Matching networks for one shot learning, 2016, Proc. of NIPS, .",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": [
                    "Oriol Vinyals",
                    "Charles Blundell",
                    "Tim Lillicrap",
                    "Koray Kavukcuoglu",
                    "Daan Wierstra"
                ],
                "title": "Matching networks for one shot learning",
                "pub_date": "2016",
                "pub_title": "Proc. of NIPS",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_112",
            "content": "UNKNOWN, None, , , .",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": null,
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_113",
            "content": "Lionel Ni, Generalizing from a few examples: A survey on few-shot learning, 2020, ACM Comput. Surv, .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": [
                    "Lionel Ni"
                ],
                "title": "Generalizing from a few examples: A survey on few-shot learning",
                "pub_date": "2020",
                "pub_title": "ACM Comput. Surv",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_114",
            "content": "Sam Wiseman, Karl Stratos, Label-agnostic sequence labeling by copying nearest neighbors, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational LinguisticsACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": [
                    "Sam Wiseman",
                    "Karl Stratos"
                ],
                "title": "Label-agnostic sequence labeling by copying nearest neighbors",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational LinguisticsACL",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_115",
            "content": "Hang Yan, Tao Gui, Junqi Dai, Qipeng Guo, Zheng Zhang, and Xipeng Qiu. 2021. A unified generative framework for various NER subtasks, , Proc. of the ACL/IJCNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "Hang Yan",
                    "Tao Gui",
                    "Junqi Dai",
                    "Qipeng Guo"
                ],
                "title": "Zheng Zhang, and Xipeng Qiu. 2021. A unified generative framework for various NER subtasks",
                "pub_date": null,
                "pub_title": "Proc. of the ACL/IJCNLP",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_116",
            "content": "Yi Yang, Arzoo Katiyar, Simple and effective few-shot named entity recognition with structured nearest neighbor learning, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": [
                    "Yi Yang",
                    "Arzoo Katiyar"
                ],
                "title": "Simple and effective few-shot named entity recognition with structured nearest neighbor learning",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_117",
            "content": "Dian Yu, Luheng He, Yuan Zhang, Xinya Du, Panupong Pasupat, Qi Li, Few-shot intent classification and slot filling with retrieved examples, 2021, Proc. of the NAACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": [
                    "Dian Yu",
                    "Luheng He",
                    "Yuan Zhang",
                    "Xinya Du",
                    "Panupong Pasupat",
                    "Qi Li"
                ],
                "title": "Few-shot intent classification and slot filling with retrieved examples",
                "pub_date": "2021",
                "pub_title": "Proc. of the NAACL",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_118",
            "content": "UNKNOWN, None, 2021, Calibrate before use: Improving few-shot performance of language models, .",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Calibrate before use: Improving few-shot performance of language models",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_119",
            "content": "UNKNOWN, None, 2008, Example-based named entity recognition. CoRR, abs, .",
            "ntype": "ref",
            "meta": {
                "xid": "b40",
                "authors": null,
                "title": null,
                "pub_date": "2008",
                "pub_title": "Example-based named entity recognition. CoRR, abs",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v2_120",
            "content": "Xu Zou, Qingyang Da Yin, Hongxia Zhong, Zhilin Yang, Jie Yang,  Tang, Controllable generation from pre-trained language models via inverse prompting, 2021-08-14, KDD '21: The 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, ACM.",
            "ntype": "ref",
            "meta": {
                "xid": "b41",
                "authors": [
                    "Xu Zou",
                    "Qingyang Da Yin",
                    "Hongxia Zhong",
                    "Zhilin Yang",
                    "Jie Yang",
                    " Tang"
                ],
                "title": "Controllable generation from pre-trained language models via inverse prompting",
                "pub_date": "2021-08-14",
                "pub_title": "KDD '21: The 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining",
                "pub": "ACM"
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "6-ARR_v2_0@0",
            "content": "Inverse is Better! Fast and Accurate Prompt for Few-shot Slot Tagging",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_0",
            "start": 0,
            "end": 68,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_2@0",
            "content": "Prompting methods recently achieve impressive success in few-shot learning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_2",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_2@1",
            "content": "These methods modify input samples with prompt sentence pieces, and decode label tokens to map samples to corresponding labels.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_2",
            "start": 76,
            "end": 202,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_2@2",
            "content": "However, such a paradigm is very inefficient for the task of slot tagging.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_2",
            "start": 204,
            "end": 277,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_2@3",
            "content": "Since slot tagging samples are multiple consecutive words in a sentence, the prompting methods have to enumerate all n-grams token spans to find all the possible slots, which greatly slows down the prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_2",
            "start": 279,
            "end": 487,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_2@4",
            "content": "To tackle this, we introduce an inverse paradigm for prompting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_2",
            "start": 489,
            "end": 551,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_2@5",
            "content": "Different from the classic prompts mapping tokens to labels, we reversely predict slot values given slot types.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_2",
            "start": 553,
            "end": 663,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_2@6",
            "content": "Such inverse prompting only requires a oneturn prediction for each slot type and greatly speeds up the prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_2",
            "start": 665,
            "end": 778,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_2@7",
            "content": "Besides, we propose a novel Iterative Prediction Strategy, from which the model learns to refine predictions by considering the relations between different slot types.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_2",
            "start": 780,
            "end": 946,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_2@8",
            "content": "We find, somewhat surprisingly, the proposed method not only predicts faster but also significantly improves the effect (improve over 6.1 F1-scores on 10-shot setting) and achieves new state-of-the-art performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_2",
            "start": 948,
            "end": 1161,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_4@0",
            "content": "Few-shot learning (FSL) aims at learning a model from only a few examples and is regarded as one of the key steps toward more human-like artificial intelligence (Wang et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_4",
            "start": 0,
            "end": 180,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_4@1",
            "content": "Recently, promptbased methods achieve impressive results and show promising prospects for few-shot learning of Natural Language Processing (NLP) (Liu et al., 2021a;.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_4",
            "start": 182,
            "end": 346,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_5@0",
            "content": "Prompt-based methods reformulate a target task into the language modeling problem, which takes advantages of the powerful pretrained Language Models (LM) (Devlin et al., 2019; For normal prompts, identifying all slots in the query sentence requires enumeration of all spans, while inverse prompt only needs 1-time prediction for each label. Lewis et al., 2020;Brown et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_5",
            "start": 0,
            "end": 379,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_5@1",
            "content": "For example, when classifying the sentiment of the movie review \"no reason to watch\", prompting methods insert a piece of text \"It was\", i.e. prompts, to the input example, getting \"No reason to watch. It was __\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_5",
            "start": 381,
            "end": 593,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_5@2",
            "content": "It is natural to expect a higher probability from the LM to fill the template with \"terrible\" than \"great\", and the original task is then converted to a language modeling task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_5",
            "start": 595,
            "end": 770,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_5@3",
            "content": "Such conversion reduces the gap between pretraining and target tasks, which allows less dependency on target task data and helps to achieve better performance in low data scenarios (Gao et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_5",
            "start": 772,
            "end": 971,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_5@4",
            "content": "However, while achieving great success in sentence level tasks, prompting-based methods show incompatibility for sequence labeling tasks, such as slot tagging.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_5",
            "start": 973,
            "end": 1131,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_5@5",
            "content": "Firstly, the aforementioned prompting paradigm is quite inefficient for slot tagging tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_5",
            "start": 1133,
            "end": 1223,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_5@6",
            "content": "Different from the sentence-level tasks that classify samples of whole sentences, slot tagging samples are multiple consecutive words in a sentence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_5",
            "start": 1225,
            "end": 1372,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_5@7",
            "content": "Therefore, as shown in Fig. 1, to find all the possible slots, prompt-based methods have to enumerate all n-gram word spans, and then query LM for each of them, which greatly slows down the prediction (Cui et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_5",
            "start": 1374,
            "end": 1593,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_5@8",
            "content": "Further, as a structure prediction problem, slot tagging benefits from taking the dependencies between labels into account (Ma and Hovy, 2016;Hou et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_5",
            "start": 1595,
            "end": 1754,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_5@9",
            "content": "For example in Fig. 1, where the arrival entity often appears after a departure entity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_5",
            "start": 1756,
            "end": 1842,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_5@10",
            "content": "Such label dependency is hard to be captured by current prompting methods since they predict labels one-by-one independently.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_5",
            "start": 1844,
            "end": 1968,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_6@0",
            "content": "To tackle the above issues, we introduce an inverse paradigm for prompting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_6",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_6@1",
            "content": "Different from the classic prompts mapping tokens to labels, we reversely predict slot values given slot types.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_6",
            "start": 76,
            "end": 186,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_6@2",
            "content": "For the example in Fig. 1, we use an inverse prompt to modify the input as \"book a flight from Beijing to New York tomorrow morning. arrival refers to __\", and then LM is able to decode multi-word span \"New York\" at a time.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_6",
            "start": 188,
            "end": 410,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_6@3",
            "content": "Compared to the classic prompts that require predictions for every n-gram word span (55-times in Fig. 1), we only need to perform decoding for V -times, where V is the number of label types (4-times in Fig. 1), which therefore greatly speeds up the prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_6",
            "start": 412,
            "end": 671,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_6@4",
            "content": "Surprisingly, experiments show the proposed method not only predicts faster but also significantly improves the performance, indicating that prompting LM reversely is a better fit for the slot tagging task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_6",
            "start": 673,
            "end": 878,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_6@5",
            "content": "Besides, to further improve the prediction accuracy, we propose a novel Iterative Prediction Strategy, from which the model learns to refine predictions by considering the relations between different slot types.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_6",
            "start": 880,
            "end": 1090,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_7@0",
            "content": "To summarize the contribution of this work:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_7",
            "start": 0,
            "end": 42,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_8@0",
            "content": "(1) We introduce the idea of inverse prediction to prompting methods for slot tagging tasks, which greatly speeds up the prediction process.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_8",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_9@0",
            "content": "(2) We propose an Iterative Prediction Strategy for learning and prediction with slot tagging prompts, which allows the prompting model to consider dependency between different slot types and refine prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_9",
            "start": 0,
            "end": 209,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_10@0",
            "content": "(3) We extensively evaluate the proposed method in various few-shot settings, where the proposed method brings significant improvements not only in speed but also in accuracy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_10",
            "start": 0,
            "end": 174,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_11@0",
            "content": "The code and data are available at https://github.com/AtmaHou/ PromptSlotTagging.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_11",
            "start": 0,
            "end": 80,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_12@0",
            "content": "Background",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_12",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_13@0",
            "content": "In this section, we begin with a formal definition of the few-shot slot tagging task ( \u00a72.1), and then introduce the conventional sequence labeling approaches ( \u00a72.2) and recent prompts-based methods ( \u00a72.3) for this task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_13",
            "start": 0,
            "end": 221,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_14@0",
            "content": "Few Shot Slot Tagging",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_14",
            "start": 0,
            "end": 20,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_15@0",
            "content": "Slot tagging aims at finding key slots within a sentence, such as time or location entities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_15",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_15@1",
            "content": "Given an input sentence x = (x 1 , x 2 , . . . , x n ) as a sequence of words, a slot tagging model extracts all M slot label-values pairs y = {(l i , s i )} M i=1 in the sentence, where l i is the ith label in the label set L and s k j = {x j , ..., x k } is a word span starting from x j and ending with x k .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_15",
            "start": 93,
            "end": 403,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_16@0",
            "content": "In few-shot settings, model are often evaluated on multiple low-resource domains {D",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_16",
            "start": 0,
            "end": 82,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_17@0",
            "content": "(1)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_17",
            "start": 0,
            "end": 2,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_18@0",
            "content": "L , D(2)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_18",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_19@0",
            "content": "L , ...}, which is called target domain (Wang et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_19",
            "start": 0,
            "end": 59,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_19@1",
            "content": "Each target domain D (j) L only contains a few labeled instances called support set S = {(x (i) , y (i) )} N S i=1 , which usually includes K examples (K-shot) for each of N labels (N-way).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_19",
            "start": 61,
            "end": 249,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_19@2",
            "content": "On each target domain, given support set examples as references, few-shot slot tagging models are required to make predictions for query set samples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_19",
            "start": 251,
            "end": 399,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_19@3",
            "content": "Optionally, some few-shot settings also include a set of data-rich domains {D",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_19",
            "start": 401,
            "end": 477,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_20@0",
            "content": "(1)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_20",
            "start": 0,
            "end": 2,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_21@0",
            "content": "H , D(2)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_21",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_22@0",
            "content": "H , ...} called source domains, which are used for pretraining of few-shot models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_22",
            "start": 0,
            "end": 81,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_23@0",
            "content": "Conventional Sequence Labeling Approaches",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_23",
            "start": 0,
            "end": 40,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_24@0",
            "content": "Conventional approaches often formulate slot tagging as a sequence labeling problem, where each word in input is associated with a sequence label.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_24",
            "start": 0,
            "end": 145,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_24@1",
            "content": "Given sentence x = (x 1 , x 2 , . . . , x n ) as input, these method predicts the best-match sequence labels y = (y 1 , y 2 , ..., y n ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_24",
            "start": 147,
            "end": 283,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_24@2",
            "content": "To predict slots with multiple words, sequence labeling approaches adopt a \"BIO\" labeling strategy, which uses \"B\" to mark the begin word of a slot, \"I\" to mark the inner words of a slot and \"O\" to mark non-slot words.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_24",
            "start": 285,
            "end": 502,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_24@3",
            "content": "For the example in the Fig. sequence labeling model is usually formulated as:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_24",
            "start": 504,
            "end": 580,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_25@0",
            "content": "h 1:n = Encoder(x 1:n ), p(y i |x, S) = Softmax(Decoder(h i )), (i \u2208 [1, 2, ..., n]), y * = (y 1 , y 2 , ..., y n ) = arg max y p(y|x, S),",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_25",
            "start": 0,
            "end": 137,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_26@0",
            "content": "where S is a K-shot support set, Encoder is usually a pretrained language model such as BERT (Devlin et al., 2019), h 1:n is the hidden state of the encoder with a dimension d h , and Decoder can either be a linear layer, a CRF layer or any other parametric or non-parametric classifier.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_26",
            "start": 0,
            "end": 286,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_27@0",
            "content": "Sequence Labeling with Prompts",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_27",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_28@0",
            "content": "Prompt-based methods have been proven effective in many NLU tasks, especially in few-shot settings, but things become complicated when it comes to slot tagging tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_28",
            "start": 0,
            "end": 165,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_28@1",
            "content": "To identify the slot label for a word span s j i = {x i , ..., x j } in sentence x, previous works construct templates, e.g., \"[x] [s j i ] is a [z] entity\", and prompt a pretrained language model with such templates to predict label-related words [z] (Cui et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_28",
            "start": 167,
            "end": 437,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_28@2",
            "content": "For example in the Fig. 2(b), predicting the time slot can be achieved as \"book a flight from Beijing to New York tomorrow morning. tomorrow morning is a time entity.\"",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_28",
            "start": 439,
            "end": 605,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_28@3",
            "content": "However, to find all possible slots, these methods need to traverse all the n-gram spans s j i , i, j \u2208 [1, n] in a sentence, which is quite expensive in time and computation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_28",
            "start": 607,
            "end": 781,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_29@0",
            "content": "Method",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_29",
            "start": 0,
            "end": 5,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_30@0",
            "content": "To remedy the high cost of prompt prediction mentioned in the previous section, we introduce a novel inverse paradigm for prompting of slot tagging task, which significantly improves the speed of prediction by transforming the past fill-in-the-blank problem into a generative task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_30",
            "start": 0,
            "end": 280,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_30@1",
            "content": "Specifically, we first introduce the construction of our inverse prompts templates ( \u00a73.1), and then describe how to use inverse prompts during training and inference ( \u00a73.2).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_30",
            "start": 282,
            "end": 456,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_31@0",
            "content": "Further, we propose an Iterative Prediction Strategy to refine prediction by considering the relation between different slot types ( \u00a73.3).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_31",
            "start": 0,
            "end": 138,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_31@1",
            "content": "The overview of proposed method is shown in Fig. 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_31",
            "start": 140,
            "end": 190,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_32@0",
            "content": "Prompt Creation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_32",
            "start": 0,
            "end": 14,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_33@0",
            "content": "In this section, we introduce the creation of the proposed inverse prompts, which includes three main components: the label mapping, the inverse template and the control tokens.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_33",
            "start": 0,
            "end": 176,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_34@0",
            "content": "Label Mapping Before prompt construction, we first need to convert each label into a word form that can be easily understood by the pre-trained language model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_34",
            "start": 0,
            "end": 158,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_34@1",
            "content": "We employ a label mapping process to achieve this, which use a one-to-one mapping function to convert the label set L = {l 1 , . . . , l |L| } to a natural language word set L = { l1 , . . . , l|L| }.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_34",
            "start": 160,
            "end": 359,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_34@2",
            "content": "For example, in Fig. 3, we convert the label set L = {from.Loc, to.Loc, Time, Price} to a natural language label set L = { departure, arrival, time, price}.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_34",
            "start": 361,
            "end": 516,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_35@0",
            "content": "Inverse Template Prompt template is a piece of sentence with blanks, which is used to modify the original inputs and get prompting inputs for a pretrained language model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_35",
            "start": 0,
            "end": 169,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_35@1",
            "content": "To achieve inverse prompting, our template fills in an original sentence and a label as prefixes and subsequently leaves blanks for the LM to generate the corresponding slot values.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_35",
            "start": 171,
            "end": 351,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_35@2",
            "content": "Specifically, given an input sentence s and a set of mapped labels L, for each mapped label li \u2208 L, the inverse template is defined as: \"x\" li refers to __ For instance, in Fig. 3, we fill the input \"book a flight from beijing to new york tomorrow morning\" and each label in L into the template to get four prompted inputs p: \"book a flight from beijing to new york tomorrow morning\" departure refers to __ \"book a flight from beijing to new york tomorrow morning\" arrival refers to __ \"book a flight from beijing to new york tomorrow morning\" time refers to __ \"book a flight from beijing to new york tomorrow morning\" price refers to __ Control tokens Additionally, we introduce control tokens C to complete the prompts function for the slot tagging task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_35",
            "start": 353,
            "end": 1109,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_35@3",
            "content": "In order to recognize the case that there's no corresponding entity of the queried slot type, we introduce <NONE> token to pad the output, and in practice, we use \"none\" as <NONE> token to make the model output more natural.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_35",
            "start": 1111,
            "end": 1334,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_35@4",
            "content": "In order to tag more than one entity of the same slot type, we introduce \";\" as <SEP> to divide more than one entity of the same slot type. And we also use \".\" as <END> token to indicate the end of a single generation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_35",
            "start": 1336,
            "end": 1553,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_36@0",
            "content": "Training and Inference with Inverse Prompts",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_36",
            "start": 0,
            "end": 42,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_37@0",
            "content": "Till now, we have presented the construction of the inverse prompt.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_37",
            "start": 0,
            "end": 66,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_37@1",
            "content": "This section will show how to perform training and inference with the prompts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_37",
            "start": 68,
            "end": 145,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_38@0",
            "content": "Training At the training time, we pre-construct the prompt with answers such as \"book a flight from beijing to new york tomorrow morning\" departure refers to new york .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_38",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_38@1",
            "content": "Then we finetune a pre-trained language model with the answered prompts, and we only calculate loss on the answer tokens (i.e. new york) instead of the loss on the whole sentence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_38",
            "start": 169,
            "end": 347,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_39@0",
            "content": "L = i>|p| CE( \u0177i , y i )",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_39",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_40@0",
            "content": "where |p| is the length of the prompted input, \u0177i denotes the model predictions, and y i is the preconstructed answer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_40",
            "start": 0,
            "end": 117,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_41@0",
            "content": "Inference At the inference time, we feed the prompted inputs into the fine-tuned pre-trained language model and let LM generate the appeared slot values.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_41",
            "start": 0,
            "end": 152,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_41@1",
            "content": "During generation, we restrict LM to generate only words that appear in the original input sentence or predefined control words.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_41",
            "start": 154,
            "end": 281,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_41@2",
            "content": "For each prompted input p, the next token t k \u2208 x \u222a C is determined by language model probability:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_41",
            "start": 283,
            "end": 380,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_42@0",
            "content": "t k = arg max t k \u2208s\u222aC p LM (t k |p; t 1:k\u22121 )",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_42",
            "start": 0,
            "end": 45,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_43@0",
            "content": "Note that restricting the scope of output tokens is crucial to the performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_43",
            "start": 0,
            "end": 78,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_44@0",
            "content": "Iterative Prediction Strategy",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_44",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_45@0",
            "content": "In the previous section, different slot types are predicted separately.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_45",
            "start": 0,
            "end": 70,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_45@1",
            "content": "To consider the relations between different slot types, we introduce the Iterative Prediction Strategy, which also provides the model a second chance to revise those unrecognized entities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_45",
            "start": 72,
            "end": 259,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_45@2",
            "content": "We assume that different labels are interactive, so the predicted slots could be used as a hint to help predict the missed slots.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_45",
            "start": 261,
            "end": 389,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_45@3",
            "content": "For example in Fig. 3, it is often easier to generate the \"arrival\" slot given the results of \"departure\" and \"time\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_45",
            "start": 391,
            "end": 507,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_45@4",
            "content": "Motivated by this, as shown in the Fig. 3 We randomly select some occurred labels (e.g., \"arrival\") pretending it was not predicted, and construct a second round prompt: \"book a flight from beijing to new york tomorrow morning\" departure refers to beijing .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_45",
            "start": 509,
            "end": 765,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_45@5",
            "content": "time refers to tomorrow morning .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_45",
            "start": 767,
            "end": 799,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_45@6",
            "content": "price refers to none .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_45",
            "start": 801,
            "end": 822,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_45@7",
            "content": "arrival refers to __.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_45",
            "start": 824,
            "end": 844,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_45@8",
            "content": "By using these second round prompts for model training, we encourage the language model to find those unrecognized slots in the first round prediction and allow the model to consider relationships between labels.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_45",
            "start": 846,
            "end": 1057,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_46@0",
            "content": "Inference During the inference time, we construct the second-round prompts and revise the slots that are not recognized in the first round.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_46",
            "start": 0,
            "end": 138,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_46@1",
            "content": "For example in the Fig. 3, the model predict none value for \"price\" and \"arrival\" slot in the first round.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_46",
            "start": 140,
            "end": 245,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_46@2",
            "content": "We then construct another iteration of the prompted inputs that query the unrecognized slots, given all the labels and slot values that have been predicted: \"book a flight from beijing to new york tomorrow morning\" departure refers to beijing .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_46",
            "start": 247,
            "end": 490,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_46@3",
            "content": "time refers to tomorrow morning .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_46",
            "start": 492,
            "end": 524,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_46@4",
            "content": "arrival refers to __.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_46",
            "start": 526,
            "end": 546,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_46@5",
            "content": "\"book a flight from beijing to new york tomorrow morning\" departure refers to beijing .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_46",
            "start": 548,
            "end": 634,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_46@6",
            "content": "time refers to tomorrow morning .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_46",
            "start": 636,
            "end": 668,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_46@7",
            "content": "price refers to __ .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_46",
            "start": 670,
            "end": 689,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_47@0",
            "content": "The model is expected to predict the first-round missed slots during the second iteration, considering relations between labels.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_47",
            "start": 0,
            "end": 127,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_48@0",
            "content": "Experiment",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_48",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_49@0",
            "content": "We evaluate the performance of the proposed method on two classic few-shot scenarios: (1) Setting with Only In-domain data, where all training data are only a few labeled support data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_49",
            "start": 0,
            "end": 183,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_50@0",
            "content": "(2) Setting with Meta Source Tasks, where some additional data-rich source domains are available for pretraining.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_50",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_51@0",
            "content": "Evaluation To use same evaluation criteria as conventional sequence labeling methods, we need to label tokens reversely and get output in same format.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_51",
            "start": 0,
            "end": 149,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_51@1",
            "content": "After generation, we first separate outputs into slot values.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_51",
            "start": 151,
            "end": 211,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_51@2",
            "content": "For each slot value, we label tokens in the source sentence with three principles: (1) Slot value is complete: only if the whole slot value matches a span in the source sentence, we label it with the corresponding label.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_51",
            "start": 213,
            "end": 432,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_52@0",
            "content": "(2) Choose the first overlap predicted slot span: if any token in the source sentence has been labeled, we do not relabel this token even when it matches another slot value.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_52",
            "start": 0,
            "end": 172,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_53@0",
            "content": "(3) Use BIO labels: add \"B-\" to the beginning token of the slot span, add \"I-\" to the non-begin token of the slot span, and label non-slot tokens with \"O\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_53",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_53@1",
            "content": "After labeling tokens reversely, we evaluate F1 scores within each few-shot episode.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_53",
            "start": 156,
            "end": 239,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_53@2",
            "content": "\u2022 Sequence Labeling BERT (Devlin et al., 2019) can be seen as a BERT-based sequence labeling baseline which fine-tunes the BERT model with a token-level linear classifier head.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_53",
            "start": 241,
            "end": 416,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_54@0",
            "content": "\u2022 Template-based BART (Cui et al., 2021) is a prompt-based method that query BART-based LM (Lewis et al., 2020) every possible span in sentence if it belong to a certain category and therefore also need to enumerate all label for inference. \u2022 NNShot and StructShot (Yang and Katiyar, 2020) are two metric-based few-shot learning approaches for slot tagging and NER. NNShot is an instance-level nearest neighbor classifier for fewshot prediction, and StructShot promotes NNShot with a Viterbi algorithm during decoding. \u2022 EntLM (Ma et al., 2021b) is a prompt-based method that leverage substitution between words of the same type to achieve one pass prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_54",
            "start": 0,
            "end": 659,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_55@0",
            "content": "Results Table 1 shows the results of the proposed method only finetuned on few-shot in-domain data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_55",
            "start": 0,
            "end": 98,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_55@1",
            "content": "Among these results, we can observe that:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_55",
            "start": 100,
            "end": 140,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_56@0",
            "content": "(1) Our proposed method performs consistently better than all the baseline methods on all three datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_56",
            "start": 0,
            "end": 104,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_56@1",
            "content": "It outperforms the strongest baseline Template-based BART which uses BART-large by average F1 scores on three datasets of 11.96 in 10shot setting even with a much smaller pre-trained language model (the smallest GPT2).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_56",
            "start": 106,
            "end": 323,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_57@0",
            "content": "(2) Our proposed method is even comparable or outperforms those baselines with data-rich domain pre-training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_57",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_58@0",
            "content": "(3) Our proposed method performs much better than baselines in fewer labeled samples settings, especially in 10 and 20 shot settings, which indicates our method can leverage information from limited labeled data more efficiently.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_58",
            "start": 0,
            "end": 228,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_58@1",
            "content": "(4) Our method significantly outperformed Sequence Labeling BERT whose performance is quite poor on 10 and 20 shot settings, which indicates that the number of labeled data is too scarce for conventional sequence labeling tasks, and proves that the prompt-based method is effective in few-shot slot tagging tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_58",
            "start": 230,
            "end": 542,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_59@0",
            "content": "(5) The proposed Iterative Strategy consistently improves the slot tagging performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_59",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_59@1",
            "content": "The improvements become greater with fewer learning shots and the averaged improvement in 10 and 20 shot setting on three datasets are 2.23 and 1.44.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_59",
            "start": 88,
            "end": 236,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_59@2",
            "content": "This shows that when there is less data, the iterative revising mechanism is more important.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_59",
            "start": 238,
            "end": 329,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_60@0",
            "content": "Setting with Meta Source Tasks",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_60",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_61@0",
            "content": "Datasets We also evaluate the model ability of transferring from data-rich domains to unseen few-shot domains and conduct experiments on SNIPS (Coucke et al., 2018) dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_61",
            "start": 0,
            "end": 172,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_61@1",
            "content": "Following the data split provided by Hou et al. (2020), we construct 5-shot SNIPS datasets from the original SNIPS datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_61",
            "start": 174,
            "end": 297,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_61@2",
            "content": "The few-shot SNIPS dataset consists of 7 domains with different label sets: GetWeather (We), Music (Mu), PlayList (Pl), Rate-Book (Bo), SearchScreenEvent (Se), BookRestaurant (Re), and SearchCreativeWork (Cr).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_61",
            "start": 299,
            "end": 507,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_61@3",
            "content": "Each domain contains 100 few-shot episodes, and each episode consists of a support set and a query.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_61",
            "start": 509,
            "end": 607,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_62@0",
            "content": "Implements Following Henderson and Vulic (2021), we conduct our cross-domain experiments with 5-shot few-shot settings to evaluate the ability of our model to transfer from rich-data domains to unseen few-shot domains.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_62",
            "start": 0,
            "end": 217,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_62@1",
            "content": "For our proposed method, same as in-domain settings, we use the smallest GPT2 as the base model, and no new parameters are introduced.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_62",
            "start": 219,
            "end": 352,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_62@2",
            "content": "We pretrain the model in source domains and fine-tune it on the target fewshot domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_62",
            "start": 354,
            "end": 439,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_62@3",
            "content": "We set learning rate as 6.25e \u2212 5 and batch size as 16 for pretraining and batch size as 2 for 5-shot finetuning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_62",
            "start": 441,
            "end": 553,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_62@4",
            "content": "During finetuning, we use the same AdamW optimizer and linear decaying scheduler.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_62",
            "start": 555,
            "end": 635,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_62@5",
            "content": "The hyper-parameters are decided according to performance on the dev set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_62",
            "start": 637,
            "end": 709,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_62@6",
            "content": "Data and code used are public available.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_62",
            "start": 711,
            "end": 750,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_63@0",
            "content": "Baselines We provided competitive strong baselines, including traditional finetune-based methods and advanced few-shot learning methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_63",
            "start": 0,
            "end": 135,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_64@0",
            "content": "\u2022 Bi-LSTM (Schuster and Paliwal, 1997) uses GLoVe (Pennington et al., 2014) embedding for slot tagging and is trained on the support sets. \u2022 SimBERT is a metric-based method using cosine similarity of BERT-based embedding to label tokens with the most similar token's label. \u2022 Matching Network (MN) (Vinyals et al., 2016) is a few-shot sequence labeling model based on the matching network and uses BERT embedding. \u2022 TransferBERT is a domain transfer-based conventional NER model using BERT, which is first pre-trained on source domains and then fine-tuned on the target domain support set. \u2022 WPZ (Fritzler et al., 2019) is a metric-based few-shot slot tagging method similar to MN, but is based on the prototypical network (Snell et al., 2017). \u2022 TapNet+CDT, L-TapNet+CDT, L-WPZ+CDT (Hou et al., 2020) are metric-based few-shot learning methods designed for slot tagging, which introduces a CRF-based framework to consider the relation between different slots. \u2022 ConVEx (Henderson and Vulic, 2021) is a finetuning-based method that models slot tagging as a cloze task and is first pre-trained on Reddit data then fine-tuned on few-shot slot tagging data. Note that the Reddit data is not used by our method and other baselines during the experiments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_64",
            "start": 0,
            "end": 1250,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_65@0",
            "content": "Table 2 shows the results of the crossdomain few-shot setting, from which we can observe that:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_65",
            "start": 0,
            "end": 93,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_66@0",
            "content": "(1) Our proposed method outperforms all the baselines except ConVEx which uses extra Reddit data in the cross-domain 5-shot setting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_66",
            "start": 0,
            "end": 131,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_66@1",
            "content": "Despite using less training data, our model still achieves comparable results with Covex, proving its superiority.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_66",
            "start": 133,
            "end": 246,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_67@0",
            "content": "(2) We outperform TransferBERT by 42.36 F1 scores which strongly proved that the prompt-based method can transfer more knowledge from the source domain and is more data-efficient than conventional methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_67",
            "start": 0,
            "end": 204,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_68@0",
            "content": "(3) Our method outperforms metric-based few-shot learning baselines, for example, 2.24 F1 scores higher than L-TapNet+CDT, which proves its competitiveness compared to classical few-shot learning methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_68",
            "start": 0,
            "end": 203,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_69@0",
            "content": "(4) Our Iterative Prediction Strategy improved Our method by about 0.5 F1 scores, demonstrating that the revising ability is likely to be transferable and is effective under cross-domain scenarios.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_69",
            "start": 0,
            "end": 196,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_70@0",
            "content": "Analysis",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_70",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_71@0",
            "content": "Effects of Iterative Prediction Strategy As shown in Table 1, the proposed Iterative Prediction Learning brings consistent improvement, especially in low-resource settings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_71",
            "start": 0,
            "end": 171,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_71@1",
            "content": "It works by revising predictions with a second-round query to recognize those missing slots, which can bring an increase in recall score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_71",
            "start": 173,
            "end": 309,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_71@2",
            "content": "To confirm that, we make a detailed analysis with precision score (P), recall score (R) and F1 score (F) in Table 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_71",
            "start": 311,
            "end": 426,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_72@0",
            "content": "When Iterative Revise Strategy is added, we can get a rise in recall score about 4 points in 10-shot, 2~4 points in 20 shot and more than 1 points in other shot settings in exchange for a slight precision drop, resulting in a rise in overall F1 score by about 2 points in 10 and 20 shots.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_72",
            "start": 0,
            "end": 287,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_72@1",
            "content": "We further explore the effect of jointly learning of the first-round prediction and the second-round revising, and learn two abilities separately with two models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_72",
            "start": 289,
            "end": 450,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_72@2",
            "content": "As shown in and much smaller than the number of spans, so that this growth does not affect the value of our method in practice.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_72",
            "start": 452,
            "end": 578,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_72@3",
            "content": "Besides, we find no significant correlation between the number of labels and our performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_72",
            "start": 580,
            "end": 672,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_73@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_73",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_74@0",
            "content": "Prompt-based learning Prompt-based learning approaches have been a broadly discussed topic since large language models like GPT models (Brown et al., 2020) 2021) proposes a template-based method querying every slot span with each label which is expensive for decoding.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_74",
            "start": 0,
            "end": 267,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_74@1",
            "content": "Different from them, we introduce an inverse paradigm for prompting slot tagging tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_74",
            "start": 269,
            "end": 355,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_74@2",
            "content": "Note that inverse prompting (Zou et al., 2021) has a similar name to our work but is entirely different in method and task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_74",
            "start": 357,
            "end": 479,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_74@3",
            "content": "They aim to generate prompt templates inversely.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_74",
            "start": 481,
            "end": 528,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_74@4",
            "content": "Amendable generation (Tian et al., 2021) share a similar idea of using Iterative Prediction Strategy to generate and revise dialog state.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_74",
            "start": 530,
            "end": 666,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_74@5",
            "content": "By contrast, we focus on a different task for sequence labeling and first introduce an Iterative Prediction Strategy to prompting models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_74",
            "start": 668,
            "end": 804,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_74@6",
            "content": "There are also generation-based methods for sequence labeling (Yan et al., 2021), which is not a prompting method, since it re-initializes decoding layers and learns a generative model from scratch.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_74",
            "start": 806,
            "end": 1003,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_75@0",
            "content": "Few-shot slot tagging Previous few-shot slot tagging methods focus on metric learning based methods, which classify tokens by word-label similarity (Snell et al., 2017;Vinyals et al., 2016).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_75",
            "start": 0,
            "end": 189,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_75@1",
            "content": "Hou et al. (2020) leverage label name semantics to get better label representation and model label dependency in few-shot settings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_75",
            "start": 191,
            "end": 321,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_75@2",
            "content": "Yang and Katiyar (2020) make a prediction based on the nearest neighbor sample instead of the nearest label representation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_75",
            "start": 323,
            "end": 445,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_75@3",
            "content": "Besides, some works also explore training a model with additional data from non-slot-tagging task Henderson and Vulic, 2021)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_75",
            "start": 447,
            "end": 570,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_76@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_76",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_77@0",
            "content": "In this paper, to liberate the prompting methods from the burdensome prediction of slot-tagging tasks, we introduce a novel inverse prediction manner to prompting methods of slot-tagging, which significantly improves both the efficiency and accuracy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_77",
            "start": 0,
            "end": 249,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_77@1",
            "content": "To further improve performance, we propose an Iterative Prediction Strategy for learning, which enables the prompting model to consider dependency between labels and refine prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_77",
            "start": 251,
            "end": 434,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_77@2",
            "content": "Extensive experiments verify the effectiveness of the proposed method in various few-shot settings, indicating inverse prediction is a better fit for prompting of slot tagging task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_77",
            "start": 436,
            "end": 616,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_78@0",
            "content": "All the scientific artifacts used/created are properly cited/licensed, and the usage is consistent with their intended use.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_78",
            "start": 0,
            "end": 122,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_78@1",
            "content": "This paper does not collect new datasets, nor does the data used contain sensitive information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_78",
            "start": 124,
            "end": 218,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_79@0",
            "content": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners, , Advances in Neural Information Processing Systems, Curran Associates, Inc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_79",
            "start": 0,
            "end": 501,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_80@0",
            "content": "Sam Coope, Tyler Farghly, Daniela Gerz, Ivan Vulic, Matthew Henderson, Span-convert: Few-shot span extraction for dialog with pretrained conversational representations, 2020, Proc. of the ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_80",
            "start": 0,
            "end": 193,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_81@0",
            "content": "UNKNOWN, None, 2018, Snips voice platform: an embedded spoken language understanding system for private-by-design voice interfaces, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_81",
            "start": 0,
            "end": 132,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_82@0",
            "content": "Leyang Cui, Yu Wu, Jian Liu, Sen Yang, Yue Zhang, Template-based named entity recognition using BART, 2021, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_82",
            "start": 0,
            "end": 184,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_83@0",
            "content": "UNKNOWN, None, , , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_83",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_84@0",
            "content": "Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long and Short Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_84",
            "start": 0,
            "end": 273,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_85@0",
            "content": "Alexander Fritzler, Varvara Logacheva, Maksim Kretov, Few-shot classification in named entity recognition task, 2019, Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_85",
            "start": 0,
            "end": 185,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_86@0",
            "content": "Tianyu Gao, Adam Fisch, Danqi Chen, Making pre-trained language models better few-shot learners, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_86",
            "start": 0,
            "end": 278,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_87@0",
            "content": "UNKNOWN, None, 2021, Ptr: Prompt tuning with rules for text classification, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_87",
            "start": 0,
            "end": 76,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_88@0",
            "content": "Matthew Henderson, Ivan Vulic, Convex: Data-efficient and few-shot slot labeling, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_88",
            "start": 0,
            "end": 243,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_89@0",
            "content": "Yutai Hou, Wanxiang Che, Yongkui Lai, Zhihan Zhou, Yijia Liu, Han Liu, Ting Liu, Few-shot slot tagging with collapsed dependency transfer and labelenhanced task-adaptive projection network, 2020, Proc. of ACL, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_89",
            "start": 0,
            "end": 251,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_90@0",
            "content": "Yutai Hou, Yongkui Lai, Cheng Chen, Wanxiang Che, Ting Liu, Learning to bridge metric spaces: Few-shot joint learning of intent detection and slot filling, 2021, Findings of the ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_90",
            "start": 0,
            "end": 183,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_91@0",
            "content": "UNKNOWN, None, 2020, Few-shot named entity recognition: A comprehensive study, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_91",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_92@0",
            "content": "UNKNOWN, None, 2020, How can we know what language models know? Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_92",
            "start": 0,
            "end": 127,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_93@0",
            "content": "Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, Luke Zettlemoyer, BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension, 2020, Proc. of the ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_93",
            "start": 0,
            "end": 266,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_94@0",
            "content": "UNKNOWN, None, 2021, Prefix-tuning: Optimizing continuous prompts for generation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_94",
            "start": 0,
            "end": 82,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_95@0",
            "content": "UNKNOWN, None, 2021, What makes good in-context examples for gpt-3? arXiv preprint, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_95",
            "start": 0,
            "end": 84,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_96@0",
            "content": "Jingjing Liu, Panupong Pasupat, Yining Wang, Scott Cyphers, Jim Glass, Query understanding enhanced by hierarchical parsing structures, 2013, IEEE Workshop on Automatic Speech Recognition and Understanding, IEEE.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_96",
            "start": 0,
            "end": 211,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_97@0",
            "content": "UNKNOWN, None, , , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_97",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_98@0",
            "content": "UNKNOWN, None, 2019, Roberta: A robustly optimized bert pretraining approach, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_98",
            "start": 0,
            "end": 78,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_99@0",
            "content": "UNKNOWN, None, , , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_99",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_100@0",
            "content": ", Frustratingly simple few-shot slot tagging, 2021, Findings of the ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_100",
            "start": 0,
            "end": 73,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_101@0",
            "content": "UNKNOWN, None, 2021, Template-free prompt tuning for few-shot NER, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_101",
            "start": 0,
            "end": 71,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_102@0",
            "content": "Xuezhe Ma, Eduard Hovy, End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF, 2016, Proceedings of the 54th Annual Meeting of the Association for Computational LinguisticsACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_102",
            "start": 0,
            "end": 185,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_103@0",
            "content": "Jeffrey Pennington, Richard Socher, Christopher Manning, Glove: Global vectors for word representation, 2014, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Pro-cessingEMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_103",
            "start": 0,
            "end": 204,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_104@0",
            "content": "Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, Language models are unsupervised multitask learners, 2019, OpenAI blog, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_104",
            "start": 0,
            "end": 153,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_105@0",
            "content": "Timo Schick, Hinrich Sch\u00fctze, Exploiting cloze-questions for few-shot text classification and natural language inference, 2021, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_105",
            "start": 0,
            "end": 250,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_106@0",
            "content": "Timo Schick, Hinrich Sch\u00fctze, It's not just size that matters: Small language models are also fewshot learners, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_106",
            "start": 0,
            "end": 262,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_107@0",
            "content": "Mike Schuster, Kuldip Paliwal, Bidirectional recurrent neural networks, 1997, IEEE Trans. Signal Process, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_107",
            "start": 0,
            "end": 106,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_108@0",
            "content": "UNKNOWN, None, 2020, Autoprompt: Eliciting knowledge from language models with automatically generated prompts, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_108",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_109@0",
            "content": "Jake Snell, Kevin Swersky, Richard Zemel, Prototypical networks for few-shot learning, 2017, Advances in Neural Information Processing Systems, Curran Associates, Inc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_109",
            "start": 0,
            "end": 166,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_110@0",
            "content": "UNKNOWN, None, 2021, Amendable generation for dialogue state tracking, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_110",
            "start": 0,
            "end": 71,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_111@0",
            "content": "Oriol Vinyals, Charles Blundell, Tim Lillicrap, Koray Kavukcuoglu, Daan Wierstra, Matching networks for one shot learning, 2016, Proc. of NIPS, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_111",
            "start": 0,
            "end": 144,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_112@0",
            "content": "UNKNOWN, None, , , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_112",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_113@0",
            "content": "Lionel Ni, Generalizing from a few examples: A survey on few-shot learning, 2020, ACM Comput. Surv, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_113",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_114@0",
            "content": "Sam Wiseman, Karl Stratos, Label-agnostic sequence labeling by copying nearest neighbors, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational LinguisticsACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_114",
            "start": 0,
            "end": 188,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_115@0",
            "content": "Hang Yan, Tao Gui, Junqi Dai, Qipeng Guo, Zheng Zhang, and Xipeng Qiu. 2021. A unified generative framework for various NER subtasks, , Proc. of the ACL/IJCNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_115",
            "start": 0,
            "end": 161,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_116@0",
            "content": "Yi Yang, Arzoo Katiyar, Simple and effective few-shot named entity recognition with structured nearest neighbor learning, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_116",
            "start": 0,
            "end": 224,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_117@0",
            "content": "Dian Yu, Luheng He, Yuan Zhang, Xinya Du, Panupong Pasupat, Qi Li, Few-shot intent classification and slot filling with retrieved examples, 2021, Proc. of the NAACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_117",
            "start": 0,
            "end": 166,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_118@0",
            "content": "UNKNOWN, None, 2021, Calibrate before use: Improving few-shot performance of language models, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_118",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_119@0",
            "content": "UNKNOWN, None, 2008, Example-based named entity recognition. CoRR, abs, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_119",
            "start": 0,
            "end": 72,
            "label": {}
        },
        {
            "ix": "6-ARR_v2_120@0",
            "content": "Xu Zou, Qingyang Da Yin, Hongxia Zhong, Zhilin Yang, Jie Yang,  Tang, Controllable generation from pre-trained language models via inverse prompting, 2021-08-14, KDD '21: The 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, ACM.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v2_120",
            "start": 0,
            "end": 245,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "6-ARR_v2_0",
            "tgt_ix": "6-ARR_v2_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_0",
            "tgt_ix": "6-ARR_v2_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_1",
            "tgt_ix": "6-ARR_v2_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_1",
            "tgt_ix": "6-ARR_v2_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_0",
            "tgt_ix": "6-ARR_v2_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_2",
            "tgt_ix": "6-ARR_v2_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_4",
            "tgt_ix": "6-ARR_v2_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_5",
            "tgt_ix": "6-ARR_v2_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_6",
            "tgt_ix": "6-ARR_v2_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_7",
            "tgt_ix": "6-ARR_v2_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_8",
            "tgt_ix": "6-ARR_v2_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_9",
            "tgt_ix": "6-ARR_v2_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_10",
            "tgt_ix": "6-ARR_v2_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_3",
            "tgt_ix": "6-ARR_v2_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_3",
            "tgt_ix": "6-ARR_v2_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_3",
            "tgt_ix": "6-ARR_v2_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_3",
            "tgt_ix": "6-ARR_v2_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_3",
            "tgt_ix": "6-ARR_v2_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_3",
            "tgt_ix": "6-ARR_v2_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_3",
            "tgt_ix": "6-ARR_v2_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_3",
            "tgt_ix": "6-ARR_v2_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_3",
            "tgt_ix": "6-ARR_v2_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_0",
            "tgt_ix": "6-ARR_v2_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_11",
            "tgt_ix": "6-ARR_v2_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_12",
            "tgt_ix": "6-ARR_v2_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_12",
            "tgt_ix": "6-ARR_v2_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_12",
            "tgt_ix": "6-ARR_v2_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_13",
            "tgt_ix": "6-ARR_v2_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_15",
            "tgt_ix": "6-ARR_v2_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_16",
            "tgt_ix": "6-ARR_v2_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_17",
            "tgt_ix": "6-ARR_v2_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_18",
            "tgt_ix": "6-ARR_v2_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_19",
            "tgt_ix": "6-ARR_v2_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_20",
            "tgt_ix": "6-ARR_v2_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_21",
            "tgt_ix": "6-ARR_v2_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_14",
            "tgt_ix": "6-ARR_v2_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_14",
            "tgt_ix": "6-ARR_v2_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_14",
            "tgt_ix": "6-ARR_v2_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_14",
            "tgt_ix": "6-ARR_v2_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_14",
            "tgt_ix": "6-ARR_v2_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_14",
            "tgt_ix": "6-ARR_v2_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_14",
            "tgt_ix": "6-ARR_v2_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_14",
            "tgt_ix": "6-ARR_v2_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_14",
            "tgt_ix": "6-ARR_v2_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_12",
            "tgt_ix": "6-ARR_v2_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_22",
            "tgt_ix": "6-ARR_v2_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_24",
            "tgt_ix": "6-ARR_v2_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_25",
            "tgt_ix": "6-ARR_v2_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_23",
            "tgt_ix": "6-ARR_v2_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_23",
            "tgt_ix": "6-ARR_v2_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_23",
            "tgt_ix": "6-ARR_v2_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_23",
            "tgt_ix": "6-ARR_v2_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_12",
            "tgt_ix": "6-ARR_v2_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_26",
            "tgt_ix": "6-ARR_v2_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_27",
            "tgt_ix": "6-ARR_v2_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_27",
            "tgt_ix": "6-ARR_v2_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_0",
            "tgt_ix": "6-ARR_v2_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_28",
            "tgt_ix": "6-ARR_v2_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_30",
            "tgt_ix": "6-ARR_v2_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_29",
            "tgt_ix": "6-ARR_v2_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_29",
            "tgt_ix": "6-ARR_v2_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_29",
            "tgt_ix": "6-ARR_v2_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_29",
            "tgt_ix": "6-ARR_v2_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_31",
            "tgt_ix": "6-ARR_v2_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_33",
            "tgt_ix": "6-ARR_v2_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_34",
            "tgt_ix": "6-ARR_v2_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_32",
            "tgt_ix": "6-ARR_v2_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_32",
            "tgt_ix": "6-ARR_v2_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_32",
            "tgt_ix": "6-ARR_v2_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_32",
            "tgt_ix": "6-ARR_v2_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_29",
            "tgt_ix": "6-ARR_v2_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_35",
            "tgt_ix": "6-ARR_v2_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_37",
            "tgt_ix": "6-ARR_v2_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_38",
            "tgt_ix": "6-ARR_v2_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_39",
            "tgt_ix": "6-ARR_v2_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_40",
            "tgt_ix": "6-ARR_v2_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_41",
            "tgt_ix": "6-ARR_v2_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_42",
            "tgt_ix": "6-ARR_v2_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_36",
            "tgt_ix": "6-ARR_v2_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_36",
            "tgt_ix": "6-ARR_v2_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_36",
            "tgt_ix": "6-ARR_v2_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_36",
            "tgt_ix": "6-ARR_v2_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_36",
            "tgt_ix": "6-ARR_v2_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_36",
            "tgt_ix": "6-ARR_v2_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_36",
            "tgt_ix": "6-ARR_v2_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_36",
            "tgt_ix": "6-ARR_v2_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_29",
            "tgt_ix": "6-ARR_v2_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_43",
            "tgt_ix": "6-ARR_v2_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_45",
            "tgt_ix": "6-ARR_v2_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_46",
            "tgt_ix": "6-ARR_v2_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_44",
            "tgt_ix": "6-ARR_v2_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_44",
            "tgt_ix": "6-ARR_v2_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_44",
            "tgt_ix": "6-ARR_v2_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_44",
            "tgt_ix": "6-ARR_v2_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_0",
            "tgt_ix": "6-ARR_v2_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_47",
            "tgt_ix": "6-ARR_v2_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_49",
            "tgt_ix": "6-ARR_v2_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_50",
            "tgt_ix": "6-ARR_v2_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_51",
            "tgt_ix": "6-ARR_v2_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_52",
            "tgt_ix": "6-ARR_v2_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_53",
            "tgt_ix": "6-ARR_v2_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_55",
            "tgt_ix": "6-ARR_v2_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_56",
            "tgt_ix": "6-ARR_v2_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_57",
            "tgt_ix": "6-ARR_v2_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_58",
            "tgt_ix": "6-ARR_v2_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_48",
            "tgt_ix": "6-ARR_v2_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_48",
            "tgt_ix": "6-ARR_v2_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_48",
            "tgt_ix": "6-ARR_v2_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_48",
            "tgt_ix": "6-ARR_v2_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_48",
            "tgt_ix": "6-ARR_v2_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_48",
            "tgt_ix": "6-ARR_v2_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_48",
            "tgt_ix": "6-ARR_v2_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_48",
            "tgt_ix": "6-ARR_v2_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_48",
            "tgt_ix": "6-ARR_v2_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_48",
            "tgt_ix": "6-ARR_v2_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_48",
            "tgt_ix": "6-ARR_v2_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_48",
            "tgt_ix": "6-ARR_v2_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_48",
            "tgt_ix": "6-ARR_v2_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_59",
            "tgt_ix": "6-ARR_v2_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_61",
            "tgt_ix": "6-ARR_v2_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_62",
            "tgt_ix": "6-ARR_v2_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_63",
            "tgt_ix": "6-ARR_v2_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_60",
            "tgt_ix": "6-ARR_v2_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_60",
            "tgt_ix": "6-ARR_v2_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_60",
            "tgt_ix": "6-ARR_v2_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_60",
            "tgt_ix": "6-ARR_v2_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_60",
            "tgt_ix": "6-ARR_v2_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_65",
            "tgt_ix": "6-ARR_v2_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_66",
            "tgt_ix": "6-ARR_v2_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_67",
            "tgt_ix": "6-ARR_v2_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_68",
            "tgt_ix": "6-ARR_v2_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_60",
            "tgt_ix": "6-ARR_v2_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_60",
            "tgt_ix": "6-ARR_v2_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_60",
            "tgt_ix": "6-ARR_v2_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_60",
            "tgt_ix": "6-ARR_v2_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_60",
            "tgt_ix": "6-ARR_v2_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_48",
            "tgt_ix": "6-ARR_v2_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_69",
            "tgt_ix": "6-ARR_v2_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_71",
            "tgt_ix": "6-ARR_v2_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_70",
            "tgt_ix": "6-ARR_v2_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_70",
            "tgt_ix": "6-ARR_v2_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_70",
            "tgt_ix": "6-ARR_v2_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_0",
            "tgt_ix": "6-ARR_v2_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_72",
            "tgt_ix": "6-ARR_v2_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_74",
            "tgt_ix": "6-ARR_v2_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_73",
            "tgt_ix": "6-ARR_v2_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_73",
            "tgt_ix": "6-ARR_v2_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_73",
            "tgt_ix": "6-ARR_v2_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_0",
            "tgt_ix": "6-ARR_v2_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_75",
            "tgt_ix": "6-ARR_v2_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_77",
            "tgt_ix": "6-ARR_v2_78",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_76",
            "tgt_ix": "6-ARR_v2_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_76",
            "tgt_ix": "6-ARR_v2_78",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_76",
            "tgt_ix": "6-ARR_v2_77",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v2_0",
            "tgt_ix": "6-ARR_v2_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_1",
            "tgt_ix": "6-ARR_v2_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_2",
            "tgt_ix": "6-ARR_v2_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_2",
            "tgt_ix": "6-ARR_v2_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_2",
            "tgt_ix": "6-ARR_v2_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_2",
            "tgt_ix": "6-ARR_v2_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_2",
            "tgt_ix": "6-ARR_v2_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_2",
            "tgt_ix": "6-ARR_v2_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_2",
            "tgt_ix": "6-ARR_v2_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_2",
            "tgt_ix": "6-ARR_v2_2@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_2",
            "tgt_ix": "6-ARR_v2_2@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_3",
            "tgt_ix": "6-ARR_v2_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_4",
            "tgt_ix": "6-ARR_v2_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_4",
            "tgt_ix": "6-ARR_v2_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_5",
            "tgt_ix": "6-ARR_v2_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_5",
            "tgt_ix": "6-ARR_v2_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_5",
            "tgt_ix": "6-ARR_v2_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_5",
            "tgt_ix": "6-ARR_v2_5@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_5",
            "tgt_ix": "6-ARR_v2_5@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_5",
            "tgt_ix": "6-ARR_v2_5@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_5",
            "tgt_ix": "6-ARR_v2_5@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_5",
            "tgt_ix": "6-ARR_v2_5@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_5",
            "tgt_ix": "6-ARR_v2_5@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_5",
            "tgt_ix": "6-ARR_v2_5@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_5",
            "tgt_ix": "6-ARR_v2_5@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_6",
            "tgt_ix": "6-ARR_v2_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_6",
            "tgt_ix": "6-ARR_v2_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_6",
            "tgt_ix": "6-ARR_v2_6@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_6",
            "tgt_ix": "6-ARR_v2_6@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_6",
            "tgt_ix": "6-ARR_v2_6@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_6",
            "tgt_ix": "6-ARR_v2_6@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_7",
            "tgt_ix": "6-ARR_v2_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_8",
            "tgt_ix": "6-ARR_v2_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_9",
            "tgt_ix": "6-ARR_v2_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_10",
            "tgt_ix": "6-ARR_v2_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_11",
            "tgt_ix": "6-ARR_v2_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_12",
            "tgt_ix": "6-ARR_v2_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_13",
            "tgt_ix": "6-ARR_v2_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_14",
            "tgt_ix": "6-ARR_v2_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_15",
            "tgt_ix": "6-ARR_v2_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_15",
            "tgt_ix": "6-ARR_v2_15@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_16",
            "tgt_ix": "6-ARR_v2_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_17",
            "tgt_ix": "6-ARR_v2_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_18",
            "tgt_ix": "6-ARR_v2_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_19",
            "tgt_ix": "6-ARR_v2_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_19",
            "tgt_ix": "6-ARR_v2_19@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_19",
            "tgt_ix": "6-ARR_v2_19@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_19",
            "tgt_ix": "6-ARR_v2_19@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_20",
            "tgt_ix": "6-ARR_v2_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_21",
            "tgt_ix": "6-ARR_v2_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_22",
            "tgt_ix": "6-ARR_v2_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_23",
            "tgt_ix": "6-ARR_v2_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_24",
            "tgt_ix": "6-ARR_v2_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_24",
            "tgt_ix": "6-ARR_v2_24@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_24",
            "tgt_ix": "6-ARR_v2_24@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_24",
            "tgt_ix": "6-ARR_v2_24@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_25",
            "tgt_ix": "6-ARR_v2_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_26",
            "tgt_ix": "6-ARR_v2_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_27",
            "tgt_ix": "6-ARR_v2_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_28",
            "tgt_ix": "6-ARR_v2_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_28",
            "tgt_ix": "6-ARR_v2_28@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_28",
            "tgt_ix": "6-ARR_v2_28@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_28",
            "tgt_ix": "6-ARR_v2_28@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_29",
            "tgt_ix": "6-ARR_v2_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_30",
            "tgt_ix": "6-ARR_v2_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_30",
            "tgt_ix": "6-ARR_v2_30@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_31",
            "tgt_ix": "6-ARR_v2_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_31",
            "tgt_ix": "6-ARR_v2_31@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_32",
            "tgt_ix": "6-ARR_v2_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_33",
            "tgt_ix": "6-ARR_v2_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_34",
            "tgt_ix": "6-ARR_v2_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_34",
            "tgt_ix": "6-ARR_v2_34@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_34",
            "tgt_ix": "6-ARR_v2_34@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_35",
            "tgt_ix": "6-ARR_v2_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_35",
            "tgt_ix": "6-ARR_v2_35@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_35",
            "tgt_ix": "6-ARR_v2_35@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_35",
            "tgt_ix": "6-ARR_v2_35@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_35",
            "tgt_ix": "6-ARR_v2_35@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_36",
            "tgt_ix": "6-ARR_v2_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_37",
            "tgt_ix": "6-ARR_v2_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_37",
            "tgt_ix": "6-ARR_v2_37@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_38",
            "tgt_ix": "6-ARR_v2_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_38",
            "tgt_ix": "6-ARR_v2_38@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_39",
            "tgt_ix": "6-ARR_v2_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_40",
            "tgt_ix": "6-ARR_v2_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_41",
            "tgt_ix": "6-ARR_v2_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_41",
            "tgt_ix": "6-ARR_v2_41@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_41",
            "tgt_ix": "6-ARR_v2_41@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_42",
            "tgt_ix": "6-ARR_v2_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_43",
            "tgt_ix": "6-ARR_v2_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_44",
            "tgt_ix": "6-ARR_v2_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_45",
            "tgt_ix": "6-ARR_v2_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_45",
            "tgt_ix": "6-ARR_v2_45@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_45",
            "tgt_ix": "6-ARR_v2_45@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_45",
            "tgt_ix": "6-ARR_v2_45@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_45",
            "tgt_ix": "6-ARR_v2_45@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_45",
            "tgt_ix": "6-ARR_v2_45@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_45",
            "tgt_ix": "6-ARR_v2_45@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_45",
            "tgt_ix": "6-ARR_v2_45@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_45",
            "tgt_ix": "6-ARR_v2_45@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_46",
            "tgt_ix": "6-ARR_v2_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_46",
            "tgt_ix": "6-ARR_v2_46@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_46",
            "tgt_ix": "6-ARR_v2_46@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_46",
            "tgt_ix": "6-ARR_v2_46@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_46",
            "tgt_ix": "6-ARR_v2_46@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_46",
            "tgt_ix": "6-ARR_v2_46@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_46",
            "tgt_ix": "6-ARR_v2_46@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_46",
            "tgt_ix": "6-ARR_v2_46@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_47",
            "tgt_ix": "6-ARR_v2_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_48",
            "tgt_ix": "6-ARR_v2_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_49",
            "tgt_ix": "6-ARR_v2_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_50",
            "tgt_ix": "6-ARR_v2_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_51",
            "tgt_ix": "6-ARR_v2_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_51",
            "tgt_ix": "6-ARR_v2_51@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_51",
            "tgt_ix": "6-ARR_v2_51@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_52",
            "tgt_ix": "6-ARR_v2_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_53",
            "tgt_ix": "6-ARR_v2_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_53",
            "tgt_ix": "6-ARR_v2_53@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_53",
            "tgt_ix": "6-ARR_v2_53@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_54",
            "tgt_ix": "6-ARR_v2_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_55",
            "tgt_ix": "6-ARR_v2_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_55",
            "tgt_ix": "6-ARR_v2_55@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_56",
            "tgt_ix": "6-ARR_v2_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_56",
            "tgt_ix": "6-ARR_v2_56@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_57",
            "tgt_ix": "6-ARR_v2_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_58",
            "tgt_ix": "6-ARR_v2_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_58",
            "tgt_ix": "6-ARR_v2_58@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_59",
            "tgt_ix": "6-ARR_v2_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_59",
            "tgt_ix": "6-ARR_v2_59@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_59",
            "tgt_ix": "6-ARR_v2_59@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_60",
            "tgt_ix": "6-ARR_v2_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_61",
            "tgt_ix": "6-ARR_v2_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_61",
            "tgt_ix": "6-ARR_v2_61@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_61",
            "tgt_ix": "6-ARR_v2_61@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_61",
            "tgt_ix": "6-ARR_v2_61@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_62",
            "tgt_ix": "6-ARR_v2_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_62",
            "tgt_ix": "6-ARR_v2_62@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_62",
            "tgt_ix": "6-ARR_v2_62@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_62",
            "tgt_ix": "6-ARR_v2_62@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_62",
            "tgt_ix": "6-ARR_v2_62@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_62",
            "tgt_ix": "6-ARR_v2_62@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_62",
            "tgt_ix": "6-ARR_v2_62@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_63",
            "tgt_ix": "6-ARR_v2_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_64",
            "tgt_ix": "6-ARR_v2_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_65",
            "tgt_ix": "6-ARR_v2_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_66",
            "tgt_ix": "6-ARR_v2_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_66",
            "tgt_ix": "6-ARR_v2_66@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_67",
            "tgt_ix": "6-ARR_v2_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_68",
            "tgt_ix": "6-ARR_v2_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_69",
            "tgt_ix": "6-ARR_v2_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_70",
            "tgt_ix": "6-ARR_v2_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_71",
            "tgt_ix": "6-ARR_v2_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_71",
            "tgt_ix": "6-ARR_v2_71@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_71",
            "tgt_ix": "6-ARR_v2_71@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_72",
            "tgt_ix": "6-ARR_v2_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_72",
            "tgt_ix": "6-ARR_v2_72@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_72",
            "tgt_ix": "6-ARR_v2_72@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_72",
            "tgt_ix": "6-ARR_v2_72@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_73",
            "tgt_ix": "6-ARR_v2_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_74",
            "tgt_ix": "6-ARR_v2_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_74",
            "tgt_ix": "6-ARR_v2_74@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_74",
            "tgt_ix": "6-ARR_v2_74@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_74",
            "tgt_ix": "6-ARR_v2_74@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_74",
            "tgt_ix": "6-ARR_v2_74@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_74",
            "tgt_ix": "6-ARR_v2_74@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_74",
            "tgt_ix": "6-ARR_v2_74@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_75",
            "tgt_ix": "6-ARR_v2_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_75",
            "tgt_ix": "6-ARR_v2_75@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_75",
            "tgt_ix": "6-ARR_v2_75@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_75",
            "tgt_ix": "6-ARR_v2_75@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_76",
            "tgt_ix": "6-ARR_v2_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_77",
            "tgt_ix": "6-ARR_v2_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_77",
            "tgt_ix": "6-ARR_v2_77@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_77",
            "tgt_ix": "6-ARR_v2_77@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_78",
            "tgt_ix": "6-ARR_v2_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_78",
            "tgt_ix": "6-ARR_v2_78@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_79",
            "tgt_ix": "6-ARR_v2_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_80",
            "tgt_ix": "6-ARR_v2_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_81",
            "tgt_ix": "6-ARR_v2_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_82",
            "tgt_ix": "6-ARR_v2_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_83",
            "tgt_ix": "6-ARR_v2_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_84",
            "tgt_ix": "6-ARR_v2_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_85",
            "tgt_ix": "6-ARR_v2_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_86",
            "tgt_ix": "6-ARR_v2_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_87",
            "tgt_ix": "6-ARR_v2_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_88",
            "tgt_ix": "6-ARR_v2_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_89",
            "tgt_ix": "6-ARR_v2_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_90",
            "tgt_ix": "6-ARR_v2_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_91",
            "tgt_ix": "6-ARR_v2_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_92",
            "tgt_ix": "6-ARR_v2_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_93",
            "tgt_ix": "6-ARR_v2_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_94",
            "tgt_ix": "6-ARR_v2_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_95",
            "tgt_ix": "6-ARR_v2_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_96",
            "tgt_ix": "6-ARR_v2_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_97",
            "tgt_ix": "6-ARR_v2_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_98",
            "tgt_ix": "6-ARR_v2_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_99",
            "tgt_ix": "6-ARR_v2_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_100",
            "tgt_ix": "6-ARR_v2_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_101",
            "tgt_ix": "6-ARR_v2_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_102",
            "tgt_ix": "6-ARR_v2_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_103",
            "tgt_ix": "6-ARR_v2_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_104",
            "tgt_ix": "6-ARR_v2_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_105",
            "tgt_ix": "6-ARR_v2_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_106",
            "tgt_ix": "6-ARR_v2_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_107",
            "tgt_ix": "6-ARR_v2_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_108",
            "tgt_ix": "6-ARR_v2_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_109",
            "tgt_ix": "6-ARR_v2_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_110",
            "tgt_ix": "6-ARR_v2_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_111",
            "tgt_ix": "6-ARR_v2_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_112",
            "tgt_ix": "6-ARR_v2_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_113",
            "tgt_ix": "6-ARR_v2_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_114",
            "tgt_ix": "6-ARR_v2_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_115",
            "tgt_ix": "6-ARR_v2_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_116",
            "tgt_ix": "6-ARR_v2_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_117",
            "tgt_ix": "6-ARR_v2_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_118",
            "tgt_ix": "6-ARR_v2_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_119",
            "tgt_ix": "6-ARR_v2_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v2_120",
            "tgt_ix": "6-ARR_v2_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 734,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "doc_id": "6-ARR",
        "version": 2
    }
}