{
    "nodes": [
        {
            "ix": "6-ARR_v1_0",
            "content": "Inverse is Better! Fast and Accurate Prompt for Slot Tagging",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_2",
            "content": "Prompting methods recently achieve impressive success in few-shot learning. These methods embed input samples with prompt sentence pieces and decode label-related tokens to map samples to the label. However, such a paradigm is very inefficient for the task of slot tagging. Because the slot tagging samples are multiple consecutive words in a sentence, the prompting methods have to enumerate all n-grams token span to find all the possible slots, which greatly slows down the prediction. To tackle this, we introduce an inverse paradigm for prompting. Different from the classic prompts map tokens to labels, we reversely predict slot values given slot types. Such inverse prompting only requires a one-turn prediction for each slot type and greatly speeds up the prediction. Besides, we propose a novel Iterative Prediction Strategy, from which the model learns to refine predictions by considering the relations between different slot types. We find, somewhat surprisingly, the proposed method not only predicts faster, but also significantly improves the effect (improve over 6.1 F1-scores on 10-shot setting) and achieves new state-of-the-art performance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "6-ARR_v1_4",
            "content": "Few-shot learning (FSL) aims at learning a model from only a few examples and is regarded as one of the key steps toward more human-like artificial intelligence (Wang et al., 2020). Recently, promptbased methods achieve impressive results and show promising prospects for few-shot learning of Natural Language Processing (NLP) (Liu et al., 2021a;.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_5",
            "content": "Prompt-based methods reformulate a target task into the language modeling problem, which takes advantages of the powerful Pretrained Language Models (LM) (Devlin et al., 2019;Liu et al., 2019;Lewis et al., 2020;Brown et al., 2020). For example, when classifying the sentiment of the movie review \"no reason to watch\", prompting methods insert a piece of text \"It was\", i.e. prompts, to the input examples, getting \"No reason to watch. It was __\". It is natural to expect a higher probability from the LM to fill the template with \"terrible\" than \"great\", and the original task is then converted to a language modeling task. Such conversion reduces the gap between pretraining and target tasks, which allows depending less on target task data and helps to achieve better performance in low data scenarios (Gao et al., 2021).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_6",
            "content": "However, while achieving great success in sentence-level tasks, prompting-based methods show incompatibility for sequence labeling task, such as slot tagging. Firstly, the aforementioned prompting paradigm is quite inefficient for slot tagging task. Different from the sentence-level tasks that classify samples of whole sentences, slot tagging samples are multiple consecutive words in a sentence. Therefore, as shown in Figure 1, to find all the possible slots, prompt-based methods have to enumerate all n-gram word spans, and then query LM for each of them, which greatly slows down the prediction (Cui et al., 2021). Further, as a structure prediction problem, slot tagging benefits from taking the dependencies between labels into account (Ma and Hovy, 2016;Hou et al., 2020) For example in Figure 1, where to.Loc entity often appear after from.Loc entity. Such label dependency is hard to be captured by current prompting methods, since they predict labels one-by-one independently.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_7",
            "content": "To tackle the above issues, we introduce an inverse paradigm for prompting. Different from the classic prompts map tokens to labels, we reversely predict slot values given slot types. For the example in Figure 1, we embed the input with an inverse prompt as \"book a flight from Beijing to New York tomorrow morning. arrival refers to __\", and then LM is able to decode multi-word span \"New York\" at a time. Compared to the classic prompts that require predictions for every n-gram word span (55-times in Figure 1), we only need to perform decoding for V -times, where V is the number of label types (4-times in Figure 1), and therefore greatly speed up the prediction. Surprisingly, experiments show the proposed method not only predicts faster, but also significantly improve the performance, indicating that prompting LM reversely is a better fit for the slot tagging task. Besides, to further improve the prediction accuracy, we propose a novel Iterative Prediction Strategy, from which the model learns to refine predictions by considering the relations between different slot types.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_8",
            "content": "To summarize the contribution of this work:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_9",
            "content": "(1) We introduce the idea of inverse prediction to prompting-methods for slot tagging task, which greatly speeds up the prediction process.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_10",
            "content": "(2) We propose an Iterative Prediction Strategy for learning and prediction for slot tagging prompt, which allows the prompting model to consider dependency between different slot types and refine prediction.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_11",
            "content": "(3) We extensively evaluate the proposed method in various few-shot settings, where the proposed method brings significant improvements not only for the speed, but also for the accuracy.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_12",
            "content": "All code and data will be publicly available.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_13",
            "content": "Background",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "6-ARR_v1_14",
            "content": "In this part, we first present a formal definition of the few shot slot tagging task in Section 2.1, followed by an introduction of the conventional sequence labeling approaches in Section 2.2 and Sequence Labeling with Prompts in Section 2.3.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_15",
            "content": "Few Shot Slot Tagging",
            "ntype": "title",
            "meta": {
                "section": "2.1"
            }
        },
        {
            "ix": "6-ARR_v1_16",
            "content": "We define sentence x = (x 1 , x 2 , ...x n ) as a sequence of words and y = (y 1 , y 2 , ..., y n ) as the label sequence matching the sentence x, a domain",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_17",
            "content": "D = {(x (i) , y (i) )} N D",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_18",
            "content": "i=1 is a set of (x, y), and the label set",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_19",
            "content": "L D = {l i } N L D",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_20",
            "content": "i=1 is unique to each domain. In few shot scenarios, there are a set of lowresource domains {D L only contains a few labeled instances called support set S = {(x (i) , y (i) )} N S i=1 , which usually includes K examples (K-shot) for each of N labels (N-way). On each target domain, given support set examples as references, few shot slot tagging models are required to make predictions for query set samples. Optionally, some few-shot settings also include a set of optional rich-data domains {D",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_21",
            "content": "(1)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_22",
            "content": "H , D(2)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_23",
            "content": "H , ...} called source domains, which are used for pretraining of few-shot models.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_24",
            "content": "Conventional Sequence Labeling Approaches",
            "ntype": "title",
            "meta": {
                "section": "2.2"
            }
        },
        {
            "ix": "6-ARR_v1_25",
            "content": "Conventional approaches regard slot tagging as a sequence labeling problem where each word in a sentence is assigned with a BIO-based label. For the example in the Figure 2, B-time is tagged to the first word in a time slot, I-time is tagged to a non-begin word within a time slot, and O label refers to non-slot tokens. Few-shot slot tagging is then defined as: given a K-shot support set S and an input query sequence x = (x 1 , x 2 , ..., x n ), find x's best label sequence y * . As shown in Figure 2(a), this method can be formulated as:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_26",
            "content": "h 1:n = Encoder(x 1:n ), p(y c |x, S) = Softmax(Decoder(h c )), (c \u2208 [1, 2, ..., n]), y * = (y 1 , y 2 , ..., y n ) = arg max y p(y|x, S),",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_27",
            "content": "where Encoder is usually a pretrained language model such as BERT (Devlin et al., 2019), h 1:n is the hidden state of the encoder with a dimension d h , Decoder can be a linear layer, a CRF layer or any other parametric or non-parametric classifier.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_28",
            "content": "Sequence Labeling with Prompts",
            "ntype": "title",
            "meta": {
                "section": "2.3"
            }
        },
        {
            "ix": "6-ARR_v1_29",
            "content": "Prompt-based methods have been proven effective in many NLU tasks especially in few-shot settings, but things become complicated when it comes to slot tagging tasks. In Cui et al. ( 2021), a slot s i j = {x i , ..., x j } is a span starts from x i and ends with x j , and they construct a template",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_30",
            "content": "\"[x i ] [s j i ] is a [z] entity.\" to predict [z] (e.",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_31",
            "content": "g., person) corresponding to an entity label (e.g., PERSON) after finetuned on this kind of template support set. In their method, to construct templates, we need to traverse all the n-gram spans s i j , i, j \u2208 [1, n] in a sentence with each label in the label set which is quite expensive in time and compute resources.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_32",
            "content": "Method",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "6-ARR_v1_33",
            "content": "In this section, we propose a new paradigm for few-shot slot tagging using an inverse prompt to convert slot tagging into a generation task. We first introduce how to create our reverse prompts in Section 3.1, then show the inference details in Section 3.2 and the Iterative Prediction Strategy in Section 3.3, respectively.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_34",
            "content": "Prompt Creation",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "6-ARR_v1_35",
            "content": "We create the inverse prompt P and turn slot tagging into a generation task by filling a template combined with input text and slot labels. Our prompt P consists of two parts, i,e., the label mapping and the inverse prompt template.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_36",
            "content": "The label mapping is a one-to-one mapping function to convert the label set L = {l 1 , ..., l |L| } (e.g., l k = to.Loc) to a natural word set L = { l1 , ..., l|L| } (e.g. lk = departure). And the inverse prompt templates are constructed by querying each label in the label set for a given original sentence. Specifically, given an input original sentence s and a set of labels L = { li }, for each label li \u2208 L, our prompted inputs are defined as: \"s\" li refers to __, and the model requires to generate slot values naturally. By guiding the language model to continue generating slot values naturally, we leverage knowledge from pretrained language models to our slot tagging tasks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_37",
            "content": "Reverse Inference with Prompts",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "6-ARR_v1_38",
            "content": "In this section, we will introduce how the generative slot tagging is conducted in the inference procedure with proposed inverse prompts.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_39",
            "content": "The inference procedure can be concluded as the following steps: (1) We use the label mapping to map all labels {l 1 , ..., l |L| } in the label set to { l1 , ..., l|L| }. (2) For each mapped label lj , we sample one input sentence s i , then fill them in the prepared template to get prompted input x ij . (3) We use the fine-tuned pre-trained language model to conduct a controlled generation procedure in which generation word-list is constraint in the original sentence along with structure control tokens t \u2208 \u015di = s i \u222a {<NONE>, <SEP>, <END>}. Specially, for the control tokens, we use \"none\" as <NONE> token if there's no corresponding slot value in s; we use \";\" as <SEP> token to divide more than one corresponding slot values and we use \".\" as <END> token to indicate the end of the generation. For each prompted input x ij , the next token t k is determined by:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_40",
            "content": "t k = arg max t k \u2208 \u015di log(p(t k |x ij ; t 1:k\u22121 ))",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_41",
            "content": "As shown in Figure 3, given a sentence 'book a flight from beijing to new york tomorrow morning' and a label set L = {from.Loc, to.Loc, Time, Price}. (1) We map the label to a natural language label set L = { departure, arrival, time, price}. (2) For each l \u2208 L, we fill them into the template to get prompted inputs. (3) We feed the prompted inputs into our model to generate corresponding slot values following the textgeneration procedure until reaching the max length or having a full stop generated.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_42",
            "content": "Iterative Prediction Strategy",
            "ntype": "title",
            "meta": {
                "section": "3.3"
            }
        },
        {
            "ix": "6-ARR_v1_43",
            "content": "The Iterative Prediction Strategy completes the whole prediction process by revising the slot values that were \"none\" in the first iteration. We assume that different labels are interactive, so the predicted slot values could be used as a hint to help predict those \"none\" ones. For example, the model tends to successfully generate the slot value of \"arrival\" given the results of \"departure\" and \"time\" in the first iteration (Figure 3). Motivated by this, we construct another template for the Iterative Prediction Strategy, which concatenates those predicted prompts and places them before the unpredicted prompted inputs. Below we introduce the strategy for the inference and training stages in detail.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_44",
            "content": "At the inference time, as shown in Figure 3, we take the predicted slot labels in the first round into inputs for models to process. We denote the original input as s, and the i-th recognized labels in the first iteration as l r i \u2208 L R , the j-th unpredicted labels (whose slot values are \"none\") as l u j \u2208 L U (L U = L \\ L R ). So for unrecognized slot label l u j the prompted inputs are constructed as:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_45",
            "content": "\"s\" l r 1 refers to <slot_value 1 > . ... . l r n refers to <slot_value n > . l u j refers to__. The model revises the unrecognized slots given the above prompted inputs during the second iteration.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_46",
            "content": "During the training time, we simulate the cases where the slots are not recognized so as to enable the model to revise the none slot values. We do this by manually constructing none slot value examples. Specifically, for each original sentence s, we randomly select some occurred labels l s (e.g., \"arrival\" in Fig. 3) and combine them with the nonoccurred labels (e.g., \"price\" in Fig. 3) to construct the unrecognized set L U . The rest of the occurred labels (e.g., \"departure\" and \"time\" in Fig. 3) form the recognized set L R .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_47",
            "content": "Given the i-th recognized slot label l r i \u2208 L R and the j-th unrecognized slot label l u j \u2208 L U , the prompted inputs are constructed as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_48",
            "content": "\"s\" l r 1 refers to <slot_value 1 > . ... . l r n refers to <slot_value n > . l u j refers to__ The model outputs \"none\" if l u j is from the nonoccurred labels. It outputs the corresponding slot values if l u j is the selected label l s (If multiple slot values are generated, we separate them with \";\" ).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_49",
            "content": "Experiment",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "6-ARR_v1_50",
            "content": "We evaluate the performance of the proposed method on two types of few-shot learning benchmarks: (1) Setting with Only In-domain data, where all training data are only a few labeled support data. (2) Setting with Meta Source Tasks, where some additional data-rich source domains are available for pretraining.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_51",
            "content": "Evaluation To directly compare with conventional sequence labeling methods, we need to label tokens reversely. After generation, we first separate outputs into slot values. For each slot value, we label tokens in the source sentence with three principles: (1) Slot value is complete: only if the whole slot value matches a span in the source sentence, we label it with the corresponding label. (2) Choose the first overlap predicted slot span: if any token in the source sentence has been labeled, we do not relabel this token even when it matches another slot value. (3) Use BIO labels: add 'B-' to the beginning token of the slot span, add 'I-' to the non-begin token of the slot span and label non-slot tokens with 'O'. After labeling tokens reversely, we evaluate F1 scores within each few-shot episode. 1 1 For each episode, we calculate the F1 score on query samples with conlleval script: https: //www.clips.uantwerpen.be/conll2000/ chunking/conlleval.txt",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_52",
            "content": "Setting with Only In-domain data",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "6-ARR_v1_53",
            "content": "Datasets To evaluate our proposed method in only few-shot in-domain data without source domain knowledge transfer, we conduct experiments on three few-shot datasets: MIT-Restaurant Review (Liu et al., 2013), MIT-Movie Review (Liu et al., 2013) and MIT-Movie-Hard. 2 Each dataset has 10 episodes, and each episode consists of a different k-shot support set and the same query set.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_54",
            "content": "Implements We conduct experiments with K \u2208 {10, 20, 50, 100, 200, 500} shot few-shot settings to fully evaluate the performance of our method in all three datasets. Our proposed method employs GPT2-small (Radford et al., 2019) pre-trained model as the base model for fine-tuning, and no new parameters are introduced. Besides, we set the learning rate=6.25e \u2212 5 and batch size=2 for few-shot training. For all our experiments, we finetune the model only on few-shot support set for 2~4 epochs with the AdamW optimizer and linear decaying scheduler.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_55",
            "content": "Baselines In our experiments, we provide competitive conventional sequence labeling method, forward template-based method and some methods pretrained on data-rich source domains.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_56",
            "content": "\u2022 Sequence Labeling BERT (Devlin et al., 2019) can be seen as a BERT-based sequence labeling baseline which fine-tunes the BERT model with a token-level linear classifier head. \u2022 Template-based BART (Cui et al., 2021) uses BART to encode the source sentence and decodes the template constructed by querying each possible span in a sentence with each class separately. \u2022 NNShot and StructShot (Yang and Katiyar, 2020) are two metric-based few-shot learning approaches for slot tagging and NER. NNShot is an instance-level nearest neighbor classifier for fewshot prediction, and StructShot promotes NNShot with a Viterbi algorithm during decoding. \u2022 EntLM (Ma et al., 2021b) is a prompt-based method using one pass language model replacing label words with pre-selected slot values.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_57",
            "content": "Results Table 1 shows the results of the proposed method only finetuned on few-shot in-domain data and baselines under few-shot setting. Among these methods, we can observe that:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_58",
            "content": "(1) Our proposed method performs consistently better than all the baseline methods on all three datasets. It outperforms the strongest baseline Template-based BART which uses BART-large by average F1 scores on three datasets of 11.96 in 10shot setting even with a 40% smaller pretrained language model GPT2-small.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_59",
            "content": "(2) Our proposed method is even comparable or outperforms those baselines with data-rich domain pretrained.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_60",
            "content": "(3) Our proposed method performs much better than baselines in fewer labeled samples settings, especially in 10 and 20 shot settings, which indicates our method can leverage information from limited labeled data more efficiently.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_61",
            "content": "(4) Our method significantly outperformed Sequence Labeling BERT whose performance is quite poor on 10 and 20 shot settings, which indicates that the number of labeled data under the few-shot setting is scarce for conventional sequence labeling task, and proves that the prompt-based method is effective in few-shot slot tagging tasks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_62",
            "content": "(5) The proposed Iterative Prediction Strategy improves our method by average F1 score on three datasets of 2.23 and 1.44 in 10 and 20 shot setting respectively and even sees improvements in 200 and 500 shot settings, which proves the effectiveness of the Iterative Prediction Strategy in very few labeled data settings and it may still work in middle size labeled data scenarios.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_63",
            "content": "Setting with Meta Source Task",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "6-ARR_v1_64",
            "content": "Datasets To evaluate the transferability from data-rich domains to unseen few-shot domains of our proposed model, we conduct experiments on SNIPS (Coucke et al., 2018) dataset. Following the data split provided by Hou et al. (2020), we construct 5-shot SNIPS datasets from the original SNIPS datasets. The few-shot SNIPS dataset consists of 7 domains with different label sets: GetWeather (We), Music (Mu), PlayList (Pl), Rate-Book (Bo), SearchScreenEvent (Se), BookRestaurant (Re) and SearchCreativeWork (Cr). Each domain contains 100 episodes, and each episode consists of a support set with a batch of labeled samples and query samples to evaluate.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_65",
            "content": "Implements Following Henderson and Vulic (2021), we conduct our cross-domain experiments with 5-shot few-shot settings to evaluate the ability of our model to transfer from rich-data domains to unseen few-shot domains. For our proposed method, same as in-domain settings, we use GPT2small pre-trained model as the base model for pretraining in source domain and fine-tuning in target few-shot domain, and no new parameters are introduced. We set learning rate=6.25e \u2212 5 and batch size=16 for pretraining and batch size=2 for 5-shot finetuning. During finetuning, we use the same AdamW optimizer and linear decaying scheduler.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_66",
            "content": "The hyper-parameters are decided according to performance on the dev set.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_67",
            "content": "Baselines We provided competitive strong baselines, including traditional methods, finetune-based methods and advanced few-shot learning methods.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_68",
            "content": "\u2022 Bi-LSTM (Schuster and Paliwal, 1997) uses GLoVe (Pennington et al., 2014) embedding for slot tagging. Train on the support sets and test on the query examples. \u2022 SimBERT is a metric-based method using original BERT to label tokens with the most similar token's label in cosine similarity. \u2022 Matching Network (MN) (Vinyals et al., 2016) A few-shot sequence labeling model employing the matching network with BERT embedding for token-level classification. \u2022 TransferBERT is a domain transfer conventional NER model using BERT, pretrained on source domains and fine-tuned on target domain support set and performs on the test set \u2022 WPZ (Fritzler et al., 2019) is a metric-based fewshot slot tagging method using the prototypical network (Snell et al., 2017). It pre-trains a prototypical network on source domains, and utilizes the network to do word-level classification on target domains without training. \u2022 TapNet+CDT, L-TapNet+CDT, L-WPZ+CDT (Hou et al., 2020) cloze task first pre-trained on Reddit data to learn general span extraction ability, then fine-tuned on few-shot slot tagging data. Note that the Reddit data is not used by our method and other baselines during the experiment.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_69",
            "content": "Table 2 shows the results of the crossdomain few-shot setting. Among these methods in the table, we can observe that:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_70",
            "content": "(1) Our proposed method outperforms all the baselines except ConVEx which uses extra Reddit data in cross-domain 5-shot setting.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_71",
            "content": "(2) We outperform TransferBERT by 42.36 F1 scores which strongly proved that prompt-based method can transfer more knowledge from source domain and more data-efficient than conventional methods. Noting that we can directly compare with TransferBERT for both our methods first pretrained on source domains and then finetuned on each few-shot domain respectively without any fewshot learning tricks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_72",
            "content": "(3) Our method outperforms some metric-based few-shot learning baselines, for example, 2.24 F1 scores higher than L-TapNet+CDT, which demonstrate the effectiveness of prompt method in the slot tagging task.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_73",
            "content": "(4) Our Iterative Prediction Strategy improved Our method by about 0.5 F1 scores, demonstrating its effectiveness under cross-domain scenarios.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_74",
            "content": "Analysis",
            "ntype": "title",
            "meta": {
                "section": "4.3"
            }
        },
        {
            "ix": "6-ARR_v1_75",
            "content": "Effects of Iterative Prediction Learning As shown in Table 1, the proposed Iterative Prediction Learning brings consistent improvement ,especially in low-resource settings. It works by revising predictions with a second-round query to recognize those missing slots, which can bring an increase in recall score. To confirm that, we make our analysis",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_76",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "6-ARR_v1_77",
            "content": "Prompt-based learning Prompt-based learning approaches have been a broadly discussed topic since large language models like GPT models (Brown et al., 2020) Han et al., 2021) have been proposed. Unlike sentence-level tasks, prompting method is very complicated for slot tagging and NER tasks. Cui et al. (2021) proposes a template-based method querying every slot span with each label which is expensive for decoding. Different from them, we introduce an inverse paradigm for prompting slot tagging task. Note that inverse prompting (Zou et al., 2021) has a similar name to our work but is entirely different in method and task. They aim to generate prompt templates inversely. Amendable generation (Tian et al., 2021) share a similar idea of using Iterative Prediction Strategy to generate and revise dialog state. By contrast, we focus on a different task sequence labeling and first to introduce an Iterative Prediction Strategy to prompting models. There are also generation-based methods for sequence labeling (Yan et al., 2021), which is not a prompting method, since it re-initializes decoding layers and learns a generative model from scratch.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_78",
            "content": "Few-shot slot tagging Previous few-shot slot tagging methods focus on metric learning based methods, which classify tokens with word-label similarity (Snell et al., 2017;Vinyals et al., 2016). Hou et al. (2020) leverage label name semantics to get better label representation and model label dependency in few-shot setting. Yang and Katiyar (2020) uses make a prediction based on the nearest neighbor sample instead of the nearest label representation. Besides, some works also explore training a model with additional data from non-slottagging task Henderson and Vulic, 2021). Different from directly learning the few-shot slot tagging model, some researches explore to reformulate the slot tagging into other NLP tasks, Ma et al. (2021a) reforms slot tagging into a reading comprehension task, treats slot tagging as a retrieval task, Coope et al. (2020) uses span extracting task to extract slot and predict corresponding label and Cui et al. (2021) leverages prompts for few-shot NER. Different from those methods above, we are the first to reformulate slot tagging task into a prompt-based generation task.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_79",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "6-ARR_v1_80",
            "content": "In this paper, to liberate the prompting methods from burdensome prediction of slot-tagging tasks, we introduce a novel inverse prediction manner to prompting methods of slot-tagging, which significantly improves both the efficiency and accuracy.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_81",
            "content": "To further improve performance, we propose an Iterative Prediction Strategy for learning, which enable the prompting model to consider dependency between labels and refine prediction. Extensive experiments verify the effectiveness of the proposed method in various few-shot settings, indicating inverse prediction is a better fit for prompting of slot tagging task.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "6-ARR_v1_82",
            "content": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners, , Advances in Neural Information Processing Systems, Curran Associates, Inc.",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "Tom Brown",
                    "Benjamin Mann",
                    "Nick Ryder",
                    "Melanie Subbiah",
                    "Jared Kaplan",
                    "Prafulla Dhariwal",
                    "Arvind Neelakantan",
                    "Pranav Shyam",
                    "Girish Sastry",
                    "Amanda Askell",
                    "Sandhini Agarwal",
                    "Ariel Herbert-Voss",
                    "Gretchen Krueger",
                    "Tom Henighan",
                    "Rewon Child",
                    "Aditya Ramesh",
                    "Daniel Ziegler",
                    "Jeffrey Wu",
                    "Clemens Winter",
                    "Chris Hesse",
                    "Mark Chen",
                    "Eric Sigler",
                    "Mateusz Litwin"
                ],
                "title": "Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners",
                "pub_date": null,
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": "Curran Associates, Inc"
            }
        },
        {
            "ix": "6-ARR_v1_83",
            "content": "Sam Coope, Tyler Farghly, Daniela Gerz, Ivan Vulic, Matthew Henderson, Span-convert: Fewshot span extraction for dialog with pretrained conversational representations, 2020, Proc. of the ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Sam Coope",
                    "Tyler Farghly",
                    "Daniela Gerz",
                    "Ivan Vulic",
                    "Matthew Henderson"
                ],
                "title": "Span-convert: Fewshot span extraction for dialog with pretrained conversational representations",
                "pub_date": "2020",
                "pub_title": "Proc. of the ACL",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_84",
            "content": "UNKNOWN, None, 2018, Snips voice platform: an embedded spoken language understanding system for privateby-design voice interfaces, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Snips voice platform: an embedded spoken language understanding system for privateby-design voice interfaces",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_85",
            "content": "Leyang Cui, Yu Wu, Jian Liu, Sen Yang, Yue Zhang, Template-based named entity recognition using BART, 2021, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Leyang Cui",
                    "Yu Wu",
                    "Jian Liu",
                    "Sen Yang",
                    "Yue Zhang"
                ],
                "title": "Template-based named entity recognition using BART",
                "pub_date": "2021",
                "pub_title": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "6-ARR_v1_86",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Jacob Devlin",
                    "Ming-Wei Chang",
                    "Kenton Lee",
                    "Kristina Toutanova"
                ],
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "6-ARR_v1_87",
            "content": "Alexander Fritzler, Varvara Logacheva, Maksim Kretov, Few-shot classification in named entity recognition task, 2019, Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "Alexander Fritzler",
                    "Varvara Logacheva",
                    "Maksim Kretov"
                ],
                "title": "Few-shot classification in named entity recognition task",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_88",
            "content": "Tianyu Gao, Adam Fisch, Danqi Chen, Making pre-trained language models better few-shot learners, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "Tianyu Gao",
                    "Adam Fisch",
                    "Danqi Chen"
                ],
                "title": "Making pre-trained language models better few-shot learners",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "6-ARR_v1_89",
            "content": "UNKNOWN, None, 2021, Ptr: Prompt tuning with rules for text classification, .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Ptr: Prompt tuning with rules for text classification",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_90",
            "content": "Matthew Henderson, Ivan Vulic, Convex: Data-efficient and few-shot slot labeling, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Matthew Henderson",
                    "Ivan Vulic"
                ],
                "title": "Convex: Data-efficient and few-shot slot labeling",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_91",
            "content": "Yutai Hou, Wanxiang Che, Yongkui Lai, Zhihan Zhou, Yijia Liu, Han Liu, Ting Liu, Few-shot slot tagging with collapsed dependency transfer and labelenhanced task-adaptive projection network, 2020, Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Yutai Hou",
                    "Wanxiang Che",
                    "Yongkui Lai",
                    "Zhihan Zhou",
                    "Yijia Liu",
                    "Han Liu",
                    "Ting Liu"
                ],
                "title": "Few-shot slot tagging with collapsed dependency transfer and labelenhanced task-adaptive projection network",
                "pub_date": "2020",
                "pub_title": "Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_92",
            "content": "UNKNOWN, None, 2020, Few-shot named entity recognition: A comprehensive study, .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Few-shot named entity recognition: A comprehensive study",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_93",
            "content": "Zhengbao Jiang, F Frank,  Xu, How can we know what language models know?, 2020-06, Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Zhengbao Jiang",
                    "F Frank",
                    " Xu"
                ],
                "title": "How can we know what language models know?",
                "pub_date": "2020-06",
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_94",
            "content": "Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, Luke Zettlemoyer, BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Mike Lewis",
                    "Yinhan Liu",
                    "Naman Goyal",
                    "Marjan Ghazvininejad",
                    "Abdelrahman Mohamed",
                    "Omer Levy",
                    "Veselin Stoyanov",
                    "Luke Zettlemoyer"
                ],
                "title": "BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_95",
            "content": "UNKNOWN, None, 2021, Prefix-tuning: Optimizing continuous prompts for generation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Prefix-tuning: Optimizing continuous prompts for generation",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_96",
            "content": "UNKNOWN, None, 2021, What makes good in-context examples for gpt-3? arXiv preprint, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "What makes good in-context examples for gpt-3? arXiv preprint",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_97",
            "content": "Jingjing Liu, Panupong Pasupat, Yining Wang, Scott Cyphers, Jim Glass, Query understanding enhanced by hierarchical parsing structures, 2013, IEEE Workshop on Automatic Speech Recognition and Understanding, IEEE.",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Jingjing Liu",
                    "Panupong Pasupat",
                    "Yining Wang",
                    "Scott Cyphers",
                    "Jim Glass"
                ],
                "title": "Query understanding enhanced by hierarchical parsing structures",
                "pub_date": "2013",
                "pub_title": "IEEE Workshop on Automatic Speech Recognition and Understanding",
                "pub": "IEEE"
            }
        },
        {
            "ix": "6-ARR_v1_98",
            "content": "UNKNOWN, None, , , .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": null,
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_99",
            "content": "UNKNOWN, None, 2019, Roberta: A robustly optimized bert pretraining approach, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Roberta: A robustly optimized bert pretraining approach",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_100",
            "content": "Jianqiang Ma, Zeyu Yan, Chang Li, Yang Zhang, Frustratingly simple few-shot slot tagging, 2021, Findings of the ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Jianqiang Ma",
                    "Zeyu Yan",
                    "Chang Li",
                    "Yang Zhang"
                ],
                "title": "Frustratingly simple few-shot slot tagging",
                "pub_date": "2021",
                "pub_title": "Findings of the ACL",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_101",
            "content": "UNKNOWN, None, 2021, Template-free prompt tuning for few-shot NER, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Template-free prompt tuning for few-shot NER",
                "pub": "CoRR"
            }
        },
        {
            "ix": "6-ARR_v1_102",
            "content": "Xuezhe Ma, Eduard Hovy, End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF, 2016, Proceedings of the 54th Annual Meeting of the Association for Computational LinguisticsACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Xuezhe Ma",
                    "Eduard Hovy"
                ],
                "title": "End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 54th Annual Meeting of the Association for Computational LinguisticsACL",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_103",
            "content": "Jeffrey Pennington, Richard Socher, Christopher Manning, Glove: Global vectors for word representation, 2014, Proceedings of the 2014 Conference on Empirical Methods in Natural Language ProcessingEMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "Jeffrey Pennington",
                    "Richard Socher",
                    "Christopher Manning"
                ],
                "title": "Glove: Global vectors for word representation",
                "pub_date": "2014",
                "pub_title": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language ProcessingEMNLP",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_104",
            "content": "UNKNOWN, None, 2019, Language models are unsupervised multitask learners, .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Language models are unsupervised multitask learners",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_105",
            "content": "Timo Schick, Hinrich Sch\u00fctze, Exploiting cloze-questions for few-shot text classification and natural language inference, 2021, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Timo Schick",
                    "Hinrich Sch\u00fctze"
                ],
                "title": "Exploiting cloze-questions for few-shot text classification and natural language inference",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_106",
            "content": "Timo Schick, Hinrich Sch\u00fctze, It's not just size that matters: Small language models are also fewshot learners, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Timo Schick",
                    "Hinrich Sch\u00fctze"
                ],
                "title": "It's not just size that matters: Small language models are also fewshot learners",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "6-ARR_v1_107",
            "content": "Mike Schuster, Kuldip Paliwal, Bidirectional recurrent neural networks, 1997, IEEE Trans. Signal Process, .",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Mike Schuster",
                    "Kuldip Paliwal"
                ],
                "title": "Bidirectional recurrent neural networks",
                "pub_date": "1997",
                "pub_title": "IEEE Trans. Signal Process",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_108",
            "content": "UNKNOWN, None, 2020, Autoprompt: Eliciting knowledge from language models with automatically generated prompts, .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Autoprompt: Eliciting knowledge from language models with automatically generated prompts",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_109",
            "content": "Jake Snell, Kevin Swersky, Richard Zemel, Prototypical networks for few-shot learning, 2017, Advances in Neural Information Processing Systems, Curran Associates, Inc.",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": [
                    "Jake Snell",
                    "Kevin Swersky",
                    "Richard Zemel"
                ],
                "title": "Prototypical networks for few-shot learning",
                "pub_date": "2017",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": "Curran Associates, Inc"
            }
        },
        {
            "ix": "6-ARR_v1_110",
            "content": "UNKNOWN, None, 2021, Amendable generation for dialogue state tracking, .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Amendable generation for dialogue state tracking",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_111",
            "content": "Oriol Vinyals, Charles Blundell, Tim Lillicrap, Koray Kavukcuoglu, Daan Wierstra, Matching networks for one shot learning, 2016, Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing System-sNIPS, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "Oriol Vinyals",
                    "Charles Blundell",
                    "Tim Lillicrap",
                    "Koray Kavukcuoglu",
                    "Daan Wierstra"
                ],
                "title": "Matching networks for one shot learning",
                "pub_date": "2016",
                "pub_title": "Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing System-sNIPS",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_112",
            "content": "Yaqing Wang, Quanming Yao, James Kwok, Lionel Ni, Generalizing from a few examples: A survey on few-shot learning, 2020, ACM Comput. Surv, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": [
                    "Yaqing Wang",
                    "Quanming Yao",
                    "James Kwok",
                    "Lionel Ni"
                ],
                "title": "Generalizing from a few examples: A survey on few-shot learning",
                "pub_date": "2020",
                "pub_title": "ACM Comput. Surv",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_113",
            "content": "Sam Wiseman, Karl Stratos, Label-agnostic sequence labeling by copying nearest neighbors, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational LinguisticsACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": [
                    "Sam Wiseman",
                    "Karl Stratos"
                ],
                "title": "Label-agnostic sequence labeling by copying nearest neighbors",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational LinguisticsACL",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_114",
            "content": "Hang Yan, Tao Gui, Junqi Dai, Qipeng Guo, Zheng Zhang, and Xipeng Qiu. 2021. A unified generative framework for various NER subtasks, , Proc. of the ACL/IJCNLP, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": [
                    "Hang Yan",
                    "Tao Gui",
                    "Junqi Dai",
                    "Qipeng Guo"
                ],
                "title": "Zheng Zhang, and Xipeng Qiu. 2021. A unified generative framework for various NER subtasks",
                "pub_date": null,
                "pub_title": "Proc. of the ACL/IJCNLP",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "6-ARR_v1_115",
            "content": "Yi Yang, Arzoo Katiyar, Simple and effective few-shot named entity recognition with structured nearest neighbor learning, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": [
                    "Yi Yang",
                    "Arzoo Katiyar"
                ],
                "title": "Simple and effective few-shot named entity recognition with structured nearest neighbor learning",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "6-ARR_v1_116",
            "content": "Dian Yu, Luheng He, Yuan Zhang, Xinya Du, Panupong Pasupat, Qi Li, Few-shot intent classification and slot filling with retrieved examples, 2021, Proc. of the NAACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": [
                    "Dian Yu",
                    "Luheng He",
                    "Yuan Zhang",
                    "Xinya Du",
                    "Panupong Pasupat",
                    "Qi Li"
                ],
                "title": "Few-shot intent classification and slot filling with retrieved examples",
                "pub_date": "2021",
                "pub_title": "Proc. of the NAACL",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_117",
            "content": "UNKNOWN, None, 2021, Calibrate before use: Improving few-shot performance of language models, .",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Calibrate before use: Improving few-shot performance of language models",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_118",
            "content": "UNKNOWN, None, 2008, Example-based named entity recognition. CoRR, abs, .",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": null,
                "title": null,
                "pub_date": "2008",
                "pub_title": "Example-based named entity recognition. CoRR, abs",
                "pub": null
            }
        },
        {
            "ix": "6-ARR_v1_119",
            "content": "Xu Zou, Qingyang Da Yin, Hongxia Zhong, Zhilin Yang, Jie Yang,  Tang, Controllable generation from pre-trained language models via inverse prompting, 2021-08-14, KDD '21: The 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Virtual Event, ACM.",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": [
                    "Xu Zou",
                    "Qingyang Da Yin",
                    "Hongxia Zhong",
                    "Zhilin Yang",
                    "Jie Yang",
                    " Tang"
                ],
                "title": "Controllable generation from pre-trained language models via inverse prompting",
                "pub_date": "2021-08-14",
                "pub_title": "KDD '21: The 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Virtual Event",
                "pub": "ACM"
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "6-ARR_v1_0@0",
            "content": "Inverse is Better! Fast and Accurate Prompt for Slot Tagging",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_0",
            "start": 0,
            "end": 59,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_2@0",
            "content": "Prompting methods recently achieve impressive success in few-shot learning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_2",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_2@1",
            "content": "These methods embed input samples with prompt sentence pieces and decode label-related tokens to map samples to the label.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_2",
            "start": 76,
            "end": 197,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_2@2",
            "content": "However, such a paradigm is very inefficient for the task of slot tagging.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_2",
            "start": 199,
            "end": 272,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_2@3",
            "content": "Because the slot tagging samples are multiple consecutive words in a sentence, the prompting methods have to enumerate all n-grams token span to find all the possible slots, which greatly slows down the prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_2",
            "start": 274,
            "end": 487,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_2@4",
            "content": "To tackle this, we introduce an inverse paradigm for prompting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_2",
            "start": 489,
            "end": 551,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_2@5",
            "content": "Different from the classic prompts map tokens to labels, we reversely predict slot values given slot types.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_2",
            "start": 553,
            "end": 659,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_2@6",
            "content": "Such inverse prompting only requires a one-turn prediction for each slot type and greatly speeds up the prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_2",
            "start": 661,
            "end": 775,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_2@7",
            "content": "Besides, we propose a novel Iterative Prediction Strategy, from which the model learns to refine predictions by considering the relations between different slot types.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_2",
            "start": 777,
            "end": 943,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_2@8",
            "content": "We find, somewhat surprisingly, the proposed method not only predicts faster, but also significantly improves the effect (improve over 6.1 F1-scores on 10-shot setting) and achieves new state-of-the-art performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_2",
            "start": 945,
            "end": 1159,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_4@0",
            "content": "Few-shot learning (FSL) aims at learning a model from only a few examples and is regarded as one of the key steps toward more human-like artificial intelligence (Wang et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_4",
            "start": 0,
            "end": 180,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_4@1",
            "content": "Recently, promptbased methods achieve impressive results and show promising prospects for few-shot learning of Natural Language Processing (NLP) (Liu et al., 2021a;.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_4",
            "start": 182,
            "end": 346,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_5@0",
            "content": "Prompt-based methods reformulate a target task into the language modeling problem, which takes advantages of the powerful Pretrained Language Models (LM) (Devlin et al., 2019;Liu et al., 2019;Lewis et al., 2020;Brown et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_5",
            "start": 0,
            "end": 230,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_5@1",
            "content": "For example, when classifying the sentiment of the movie review \"no reason to watch\", prompting methods insert a piece of text \"It was\", i.e. prompts, to the input examples, getting \"No reason to watch. It was __\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_5",
            "start": 232,
            "end": 445,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_5@2",
            "content": "It is natural to expect a higher probability from the LM to fill the template with \"terrible\" than \"great\", and the original task is then converted to a language modeling task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_5",
            "start": 447,
            "end": 622,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_5@3",
            "content": "Such conversion reduces the gap between pretraining and target tasks, which allows depending less on target task data and helps to achieve better performance in low data scenarios (Gao et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_5",
            "start": 624,
            "end": 822,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_6@0",
            "content": "However, while achieving great success in sentence-level tasks, prompting-based methods show incompatibility for sequence labeling task, such as slot tagging.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_6",
            "start": 0,
            "end": 157,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_6@1",
            "content": "Firstly, the aforementioned prompting paradigm is quite inefficient for slot tagging task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_6",
            "start": 159,
            "end": 248,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_6@2",
            "content": "Different from the sentence-level tasks that classify samples of whole sentences, slot tagging samples are multiple consecutive words in a sentence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_6",
            "start": 250,
            "end": 397,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_6@3",
            "content": "Therefore, as shown in Figure 1, to find all the possible slots, prompt-based methods have to enumerate all n-gram word spans, and then query LM for each of them, which greatly slows down the prediction (Cui et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_6",
            "start": 399,
            "end": 620,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_6@4",
            "content": "Further, as a structure prediction problem, slot tagging benefits from taking the dependencies between labels into account (Ma and Hovy, 2016;Hou et al., 2020) For example in Figure 1, where to.Loc entity often appear after from.Loc entity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_6",
            "start": 622,
            "end": 861,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_6@5",
            "content": "Such label dependency is hard to be captured by current prompting methods, since they predict labels one-by-one independently.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_6",
            "start": 863,
            "end": 988,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_7@0",
            "content": "To tackle the above issues, we introduce an inverse paradigm for prompting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_7",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_7@1",
            "content": "Different from the classic prompts map tokens to labels, we reversely predict slot values given slot types.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_7",
            "start": 76,
            "end": 182,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_7@2",
            "content": "For the example in Figure 1, we embed the input with an inverse prompt as \"book a flight from Beijing to New York tomorrow morning. arrival refers to __\", and then LM is able to decode multi-word span \"New York\" at a time.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_7",
            "start": 184,
            "end": 405,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_7@3",
            "content": "Compared to the classic prompts that require predictions for every n-gram word span (55-times in Figure 1), we only need to perform decoding for V -times, where V is the number of label types (4-times in Figure 1), and therefore greatly speed up the prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_7",
            "start": 407,
            "end": 667,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_7@4",
            "content": "Surprisingly, experiments show the proposed method not only predicts faster, but also significantly improve the performance, indicating that prompting LM reversely is a better fit for the slot tagging task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_7",
            "start": 669,
            "end": 874,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_7@5",
            "content": "Besides, to further improve the prediction accuracy, we propose a novel Iterative Prediction Strategy, from which the model learns to refine predictions by considering the relations between different slot types.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_7",
            "start": 876,
            "end": 1086,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_8@0",
            "content": "To summarize the contribution of this work:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_8",
            "start": 0,
            "end": 42,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_9@0",
            "content": "(1) We introduce the idea of inverse prediction to prompting-methods for slot tagging task, which greatly speeds up the prediction process.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_9",
            "start": 0,
            "end": 138,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_10@0",
            "content": "(2) We propose an Iterative Prediction Strategy for learning and prediction for slot tagging prompt, which allows the prompting model to consider dependency between different slot types and refine prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_10",
            "start": 0,
            "end": 207,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_11@0",
            "content": "(3) We extensively evaluate the proposed method in various few-shot settings, where the proposed method brings significant improvements not only for the speed, but also for the accuracy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_11",
            "start": 0,
            "end": 185,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_12@0",
            "content": "All code and data will be publicly available.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_12",
            "start": 0,
            "end": 44,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_13@0",
            "content": "Background",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_13",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_14@0",
            "content": "In this part, we first present a formal definition of the few shot slot tagging task in Section 2.1, followed by an introduction of the conventional sequence labeling approaches in Section 2.2 and Sequence Labeling with Prompts in Section 2.3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_14",
            "start": 0,
            "end": 242,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_15@0",
            "content": "Few Shot Slot Tagging",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_15",
            "start": 0,
            "end": 20,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_16@0",
            "content": "We define sentence x = (x 1 , x 2 , ...x n ) as a sequence of words and y = (y 1 , y 2 , ..., y n ) as the label sequence matching the sentence x, a domain",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_16",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_17@0",
            "content": "D = {(x (i) , y (i) )} N D",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_17",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_18@0",
            "content": "i=1 is a set of (x, y), and the label set",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_18",
            "start": 0,
            "end": 40,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_19@0",
            "content": "L D = {l i } N L D",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_19",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_20@0",
            "content": "i=1 is unique to each domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_20",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_20@1",
            "content": "In few shot scenarios, there are a set of lowresource domains {D L only contains a few labeled instances called support set S = {(x (i) , y (i) )} N S i=1 , which usually includes K examples (K-shot) for each of N labels (N-way).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_20",
            "start": 30,
            "end": 258,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_20@2",
            "content": "On each target domain, given support set examples as references, few shot slot tagging models are required to make predictions for query set samples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_20",
            "start": 260,
            "end": 408,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_20@3",
            "content": "Optionally, some few-shot settings also include a set of optional rich-data domains {D",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_20",
            "start": 410,
            "end": 495,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_21@0",
            "content": "(1)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_21",
            "start": 0,
            "end": 2,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_22@0",
            "content": "H , D(2)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_22",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_23@0",
            "content": "H , ...} called source domains, which are used for pretraining of few-shot models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_23",
            "start": 0,
            "end": 81,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_24@0",
            "content": "Conventional Sequence Labeling Approaches",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_24",
            "start": 0,
            "end": 40,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_25@0",
            "content": "Conventional approaches regard slot tagging as a sequence labeling problem where each word in a sentence is assigned with a BIO-based label.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_25",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_25@1",
            "content": "For the example in the Figure 2, B-time is tagged to the first word in a time slot, I-time is tagged to a non-begin word within a time slot, and O label refers to non-slot tokens.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_25",
            "start": 141,
            "end": 319,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_25@2",
            "content": "Few-shot slot tagging is then defined as: given a K-shot support set S and an input query sequence x = (x 1 , x 2 , ..., x n ), find x's best label sequence y * .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_25",
            "start": 321,
            "end": 482,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_25@3",
            "content": "As shown in Figure 2(a), this method can be formulated as:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_25",
            "start": 484,
            "end": 541,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_26@0",
            "content": "h 1:n = Encoder(x 1:n ), p(y c |x, S) = Softmax(Decoder(h c )), (c \u2208 [1, 2, ..., n]), y * = (y 1 , y 2 , ..., y n ) = arg max y p(y|x, S),",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_26",
            "start": 0,
            "end": 137,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_27@0",
            "content": "where Encoder is usually a pretrained language model such as BERT (Devlin et al., 2019), h 1:n is the hidden state of the encoder with a dimension d h , Decoder can be a linear layer, a CRF layer or any other parametric or non-parametric classifier.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_27",
            "start": 0,
            "end": 248,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_28@0",
            "content": "Sequence Labeling with Prompts",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_28",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_29@0",
            "content": "Prompt-based methods have been proven effective in many NLU tasks especially in few-shot settings, but things become complicated when it comes to slot tagging tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_29",
            "start": 0,
            "end": 164,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_29@1",
            "content": "In Cui et al. ( 2021), a slot s i j = {x i , ..., x j } is a span starts from x i and ends with x j , and they construct a template",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_29",
            "start": 166,
            "end": 296,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_30@0",
            "content": "\"[x i ] [s j i ] is a [z] entity.\" to predict [z] (e.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_30",
            "start": 0,
            "end": 52,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_31@0",
            "content": "g., person) corresponding to an entity label (e.g., PERSON) after finetuned on this kind of template support set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_31",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_31@1",
            "content": "In their method, to construct templates, we need to traverse all the n-gram spans s i j , i, j \u2208 [1, n] in a sentence with each label in the label set which is quite expensive in time and compute resources.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_31",
            "start": 114,
            "end": 319,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_32@0",
            "content": "Method",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_32",
            "start": 0,
            "end": 5,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_33@0",
            "content": "In this section, we propose a new paradigm for few-shot slot tagging using an inverse prompt to convert slot tagging into a generation task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_33",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_33@1",
            "content": "We first introduce how to create our reverse prompts in Section 3.1, then show the inference details in Section 3.2 and the Iterative Prediction Strategy in Section 3.3, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_33",
            "start": 141,
            "end": 323,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_34@0",
            "content": "Prompt Creation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_34",
            "start": 0,
            "end": 14,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_35@0",
            "content": "We create the inverse prompt P and turn slot tagging into a generation task by filling a template combined with input text and slot labels.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_35",
            "start": 0,
            "end": 138,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_35@1",
            "content": "Our prompt P consists of two parts, i,e., the label mapping and the inverse prompt template.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_35",
            "start": 140,
            "end": 231,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_36@0",
            "content": "The label mapping is a one-to-one mapping function to convert the label set L = {l 1 , ..., l |L| } (e.g., l k = to.Loc) to a natural word set L = { l1 , ..., l|L| } (e.g. lk = departure). And the inverse prompt templates are constructed by querying each label in the label set for a given original sentence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_36",
            "start": 0,
            "end": 307,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_36@1",
            "content": "Specifically, given an input original sentence s and a set of labels L = { li }, for each label li \u2208 L, our prompted inputs are defined as: \"s\" li refers to __, and the model requires to generate slot values naturally.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_36",
            "start": 309,
            "end": 526,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_36@2",
            "content": "By guiding the language model to continue generating slot values naturally, we leverage knowledge from pretrained language models to our slot tagging tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_36",
            "start": 528,
            "end": 683,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_37@0",
            "content": "Reverse Inference with Prompts",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_37",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_38@0",
            "content": "In this section, we will introduce how the generative slot tagging is conducted in the inference procedure with proposed inverse prompts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_38",
            "start": 0,
            "end": 136,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_39@0",
            "content": "The inference procedure can be concluded as the following steps: (1) We use the label mapping to map all labels {l 1 , ..., l |L| } in the label set to { l1 , ..., l|L| }.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_39",
            "start": 0,
            "end": 170,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_39@1",
            "content": "(2) For each mapped label lj , we sample one input sentence s i , then fill them in the prepared template to get prompted input x ij .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_39",
            "start": 172,
            "end": 305,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_39@2",
            "content": "(3) We use the fine-tuned pre-trained language model to conduct a controlled generation procedure in which generation word-list is constraint in the original sentence along with structure control tokens t \u2208 \u015di = s i \u222a {<NONE>, <SEP>, <END>}.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_39",
            "start": 307,
            "end": 547,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_39@3",
            "content": "Specially, for the control tokens, we use \"none\" as <NONE> token if there's no corresponding slot value in s; we use \";\" as <SEP> token to divide more than one corresponding slot values and we use \".\" as <END> token to indicate the end of the generation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_39",
            "start": 549,
            "end": 802,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_39@4",
            "content": "For each prompted input x ij , the next token t k is determined by:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_39",
            "start": 804,
            "end": 870,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_40@0",
            "content": "t k = arg max t k \u2208 \u015di log(p(t k |x ij ; t 1:k\u22121 ))",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_40",
            "start": 0,
            "end": 50,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_41@0",
            "content": "As shown in Figure 3, given a sentence 'book a flight from beijing to new york tomorrow morning' and a label set L = {from.Loc, to.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_41",
            "start": 0,
            "end": 130,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_41@1",
            "content": "Loc, Time, Price}. (1) We map the label to a natural language label set L = { departure, arrival, time, price}. (2) For each l \u2208 L, we fill them into the template to get prompted inputs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_41",
            "start": 131,
            "end": 316,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_41@2",
            "content": "(3) We feed the prompted inputs into our model to generate corresponding slot values following the textgeneration procedure until reaching the max length or having a full stop generated.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_41",
            "start": 318,
            "end": 503,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_42@0",
            "content": "Iterative Prediction Strategy",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_42",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_43@0",
            "content": "The Iterative Prediction Strategy completes the whole prediction process by revising the slot values that were \"none\" in the first iteration.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_43",
            "start": 0,
            "end": 140,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_43@1",
            "content": "We assume that different labels are interactive, so the predicted slot values could be used as a hint to help predict those \"none\" ones.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_43",
            "start": 142,
            "end": 277,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_43@2",
            "content": "For example, the model tends to successfully generate the slot value of \"arrival\" given the results of \"departure\" and \"time\" in the first iteration (Figure 3).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_43",
            "start": 279,
            "end": 438,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_43@3",
            "content": "Motivated by this, we construct another template for the Iterative Prediction Strategy, which concatenates those predicted prompts and places them before the unpredicted prompted inputs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_43",
            "start": 440,
            "end": 625,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_43@4",
            "content": "Below we introduce the strategy for the inference and training stages in detail.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_43",
            "start": 627,
            "end": 706,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_44@0",
            "content": "At the inference time, as shown in Figure 3, we take the predicted slot labels in the first round into inputs for models to process.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_44",
            "start": 0,
            "end": 131,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_44@1",
            "content": "We denote the original input as s, and the i-th recognized labels in the first iteration as l r i \u2208 L R , the j-th unpredicted labels (whose slot values are \"none\") as l u j \u2208 L U (L U = L \\ L R ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_44",
            "start": 133,
            "end": 329,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_44@2",
            "content": "So for unrecognized slot label l u j the prompted inputs are constructed as:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_44",
            "start": 331,
            "end": 406,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_45@0",
            "content": "\"s\" l r 1 refers to <slot_value 1 > . ... .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_45",
            "start": 0,
            "end": 42,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_45@1",
            "content": "l r n refers to <slot_value n > .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_45",
            "start": 44,
            "end": 76,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_45@2",
            "content": "l u j refers to__. The model revises the unrecognized slots given the above prompted inputs during the second iteration.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_45",
            "start": 78,
            "end": 197,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_46@0",
            "content": "During the training time, we simulate the cases where the slots are not recognized so as to enable the model to revise the none slot values.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_46",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_46@1",
            "content": "We do this by manually constructing none slot value examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_46",
            "start": 141,
            "end": 201,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_46@2",
            "content": "Specifically, for each original sentence s, we randomly select some occurred labels l s (e.g., \"arrival\" in Fig. 3) and combine them with the nonoccurred labels (e.g., \"price\" in Fig. 3) to construct the unrecognized set L U .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_46",
            "start": 203,
            "end": 428,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_46@3",
            "content": "The rest of the occurred labels (e.g., \"departure\" and \"time\" in Fig. 3) form the recognized set L R .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_46",
            "start": 430,
            "end": 531,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_47@0",
            "content": "Given the i-th recognized slot label l r i \u2208 L R and the j-th unrecognized slot label l u j \u2208 L U , the prompted inputs are constructed as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_47",
            "start": 0,
            "end": 146,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_48@0",
            "content": "\"s\" l r 1 refers to <slot_value 1 > . ... .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_48",
            "start": 0,
            "end": 42,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_48@1",
            "content": "l r n refers to <slot_value n > .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_48",
            "start": 44,
            "end": 76,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_48@2",
            "content": "l u j refers to__ The model outputs \"none\" if l u j is from the nonoccurred labels.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_48",
            "start": 78,
            "end": 160,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_48@3",
            "content": "It outputs the corresponding slot values if l u j is the selected label l s (If multiple slot values are generated, we separate them with \";\" ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_48",
            "start": 162,
            "end": 305,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_49@0",
            "content": "Experiment",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_49",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_50@0",
            "content": "We evaluate the performance of the proposed method on two types of few-shot learning benchmarks: (1) Setting with Only In-domain data, where all training data are only a few labeled support data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_50",
            "start": 0,
            "end": 194,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_50@1",
            "content": "(2) Setting with Meta Source Tasks, where some additional data-rich source domains are available for pretraining.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_50",
            "start": 196,
            "end": 308,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_51@0",
            "content": "Evaluation To directly compare with conventional sequence labeling methods, we need to label tokens reversely.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_51",
            "start": 0,
            "end": 109,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_51@1",
            "content": "After generation, we first separate outputs into slot values.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_51",
            "start": 111,
            "end": 171,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_51@2",
            "content": "For each slot value, we label tokens in the source sentence with three principles: (1) Slot value is complete: only if the whole slot value matches a span in the source sentence, we label it with the corresponding label.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_51",
            "start": 173,
            "end": 392,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_51@3",
            "content": "(2) Choose the first overlap predicted slot span: if any token in the source sentence has been labeled, we do not relabel this token even when it matches another slot value.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_51",
            "start": 394,
            "end": 566,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_51@4",
            "content": "(3) Use BIO labels: add 'B-' to the beginning token of the slot span, add 'I-' to the non-begin token of the slot span and label non-slot tokens with 'O'.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_51",
            "start": 568,
            "end": 721,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_51@5",
            "content": "After labeling tokens reversely, we evaluate F1 scores within each few-shot episode.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_51",
            "start": 723,
            "end": 806,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_51@6",
            "content": "1 1 For each episode, we calculate the F1 score on query samples with conlleval script: https: //www.clips.uantwerpen.be/conll2000/ chunking/conlleval.txt",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_51",
            "start": 808,
            "end": 961,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_52@0",
            "content": "Setting with Only In-domain data",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_52",
            "start": 0,
            "end": 31,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_53@0",
            "content": "Datasets To evaluate our proposed method in only few-shot in-domain data without source domain knowledge transfer, we conduct experiments on three few-shot datasets: MIT-Restaurant Review (Liu et al., 2013), MIT-Movie Review (Liu et al., 2013) and MIT-Movie-Hard.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_53",
            "start": 0,
            "end": 262,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_53@1",
            "content": "2 Each dataset has 10 episodes, and each episode consists of a different k-shot support set and the same query set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_53",
            "start": 264,
            "end": 378,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_54@0",
            "content": "Implements We conduct experiments with K \u2208 {10, 20, 50, 100, 200, 500} shot few-shot settings to fully evaluate the performance of our method in all three datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_54",
            "start": 0,
            "end": 163,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_54@1",
            "content": "Our proposed method employs GPT2-small (Radford et al., 2019) pre-trained model as the base model for fine-tuning, and no new parameters are introduced.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_54",
            "start": 165,
            "end": 316,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_54@2",
            "content": "Besides, we set the learning rate=6.25e \u2212 5 and batch size=2 for few-shot training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_54",
            "start": 318,
            "end": 400,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_54@3",
            "content": "For all our experiments, we finetune the model only on few-shot support set for 2~4 epochs with the AdamW optimizer and linear decaying scheduler.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_54",
            "start": 402,
            "end": 547,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_55@0",
            "content": "Baselines In our experiments, we provide competitive conventional sequence labeling method, forward template-based method and some methods pretrained on data-rich source domains.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_55",
            "start": 0,
            "end": 177,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_56@0",
            "content": "\u2022 Sequence Labeling BERT (Devlin et al., 2019) can be seen as a BERT-based sequence labeling baseline which fine-tunes the BERT model with a token-level linear classifier head. \u2022 Template-based BART (Cui et al., 2021) uses BART to encode the source sentence and decodes the template constructed by querying each possible span in a sentence with each class separately. \u2022 NNShot and StructShot (Yang and Katiyar, 2020) are two metric-based few-shot learning approaches for slot tagging and NER. NNShot is an instance-level nearest neighbor classifier for fewshot prediction, and StructShot promotes NNShot with a Viterbi algorithm during decoding. \u2022 EntLM (Ma et al., 2021b) is a prompt-based method using one pass language model replacing label words with pre-selected slot values.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_56",
            "start": 0,
            "end": 779,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_57@0",
            "content": "Results Table 1 shows the results of the proposed method only finetuned on few-shot in-domain data and baselines under few-shot setting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_57",
            "start": 0,
            "end": 135,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_57@1",
            "content": "Among these methods, we can observe that:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_57",
            "start": 137,
            "end": 177,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_58@0",
            "content": "(1) Our proposed method performs consistently better than all the baseline methods on all three datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_58",
            "start": 0,
            "end": 104,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_58@1",
            "content": "It outperforms the strongest baseline Template-based BART which uses BART-large by average F1 scores on three datasets of 11.96 in 10shot setting even with a 40% smaller pretrained language model GPT2-small.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_58",
            "start": 106,
            "end": 312,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_59@0",
            "content": "(2) Our proposed method is even comparable or outperforms those baselines with data-rich domain pretrained.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_59",
            "start": 0,
            "end": 106,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_60@0",
            "content": "(3) Our proposed method performs much better than baselines in fewer labeled samples settings, especially in 10 and 20 shot settings, which indicates our method can leverage information from limited labeled data more efficiently.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_60",
            "start": 0,
            "end": 228,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_61@0",
            "content": "(4) Our method significantly outperformed Sequence Labeling BERT whose performance is quite poor on 10 and 20 shot settings, which indicates that the number of labeled data under the few-shot setting is scarce for conventional sequence labeling task, and proves that the prompt-based method is effective in few-shot slot tagging tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_61",
            "start": 0,
            "end": 334,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_62@0",
            "content": "(5) The proposed Iterative Prediction Strategy improves our method by average F1 score on three datasets of 2.23 and 1.44 in 10 and 20 shot setting respectively and even sees improvements in 200 and 500 shot settings, which proves the effectiveness of the Iterative Prediction Strategy in very few labeled data settings and it may still work in middle size labeled data scenarios.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_62",
            "start": 0,
            "end": 379,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_63@0",
            "content": "Setting with Meta Source Task",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_63",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_64@0",
            "content": "Datasets To evaluate the transferability from data-rich domains to unseen few-shot domains of our proposed model, we conduct experiments on SNIPS (Coucke et al., 2018) dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_64",
            "start": 0,
            "end": 175,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_64@1",
            "content": "Following the data split provided by Hou et al. (2020), we construct 5-shot SNIPS datasets from the original SNIPS datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_64",
            "start": 177,
            "end": 300,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_64@2",
            "content": "The few-shot SNIPS dataset consists of 7 domains with different label sets: GetWeather (We), Music (Mu), PlayList (Pl), Rate-Book (Bo), SearchScreenEvent (Se), BookRestaurant (Re) and SearchCreativeWork (Cr).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_64",
            "start": 302,
            "end": 509,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_64@3",
            "content": "Each domain contains 100 episodes, and each episode consists of a support set with a batch of labeled samples and query samples to evaluate.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_64",
            "start": 511,
            "end": 650,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_65@0",
            "content": "Implements Following Henderson and Vulic (2021), we conduct our cross-domain experiments with 5-shot few-shot settings to evaluate the ability of our model to transfer from rich-data domains to unseen few-shot domains.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_65",
            "start": 0,
            "end": 217,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_65@1",
            "content": "For our proposed method, same as in-domain settings, we use GPT2small pre-trained model as the base model for pretraining in source domain and fine-tuning in target few-shot domain, and no new parameters are introduced.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_65",
            "start": 219,
            "end": 437,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_65@2",
            "content": "We set learning rate=6.25e \u2212 5 and batch size=16 for pretraining and batch size=2 for 5-shot finetuning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_65",
            "start": 439,
            "end": 542,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_65@3",
            "content": "During finetuning, we use the same AdamW optimizer and linear decaying scheduler.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_65",
            "start": 544,
            "end": 624,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_66@0",
            "content": "The hyper-parameters are decided according to performance on the dev set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_66",
            "start": 0,
            "end": 72,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_67@0",
            "content": "Baselines We provided competitive strong baselines, including traditional methods, finetune-based methods and advanced few-shot learning methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_67",
            "start": 0,
            "end": 144,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_68@0",
            "content": "\u2022 Bi-LSTM (Schuster and Paliwal, 1997) uses GLoVe (Pennington et al., 2014) embedding for slot tagging. Train on the support sets and test on the query examples. \u2022 SimBERT is a metric-based method using original BERT to label tokens with the most similar token's label in cosine similarity. \u2022 Matching Network (MN) (Vinyals et al., 2016) A few-shot sequence labeling model employing the matching network with BERT embedding for token-level classification. \u2022 TransferBERT is a domain transfer conventional NER model using BERT, pretrained on source domains and fine-tuned on target domain support set and performs on the test set \u2022 WPZ (Fritzler et al., 2019) is a metric-based fewshot slot tagging method using the prototypical network (Snell et al., 2017). It pre-trains a prototypical network on source domains, and utilizes the network to do word-level classification on target domains without training. \u2022 TapNet+CDT, L-TapNet+CDT, L-WPZ+CDT (Hou et al., 2020) cloze task first pre-trained on Reddit data to learn general span extraction ability, then fine-tuned on few-shot slot tagging data. Note that the Reddit data is not used by our method and other baselines during the experiment.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_68",
            "start": 0,
            "end": 1190,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_69@0",
            "content": "Table 2 shows the results of the crossdomain few-shot setting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_69",
            "start": 0,
            "end": 61,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_69@1",
            "content": "Among these methods in the table, we can observe that:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_69",
            "start": 63,
            "end": 116,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_70@0",
            "content": "(1) Our proposed method outperforms all the baselines except ConVEx which uses extra Reddit data in cross-domain 5-shot setting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_70",
            "start": 0,
            "end": 127,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_71@0",
            "content": "(2) We outperform TransferBERT by 42.36 F1 scores which strongly proved that prompt-based method can transfer more knowledge from source domain and more data-efficient than conventional methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_71",
            "start": 0,
            "end": 193,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_71@1",
            "content": "Noting that we can directly compare with TransferBERT for both our methods first pretrained on source domains and then finetuned on each few-shot domain respectively without any fewshot learning tricks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_71",
            "start": 195,
            "end": 396,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_72@0",
            "content": "(3) Our method outperforms some metric-based few-shot learning baselines, for example, 2.24 F1 scores higher than L-TapNet+CDT, which demonstrate the effectiveness of prompt method in the slot tagging task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_72",
            "start": 0,
            "end": 205,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_73@0",
            "content": "(4) Our Iterative Prediction Strategy improved Our method by about 0.5 F1 scores, demonstrating its effectiveness under cross-domain scenarios.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_73",
            "start": 0,
            "end": 142,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_74@0",
            "content": "Analysis",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_74",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_75@0",
            "content": "Effects of Iterative Prediction Learning As shown in Table 1, the proposed Iterative Prediction Learning brings consistent improvement ,especially in low-resource settings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_75",
            "start": 0,
            "end": 171,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_75@1",
            "content": "It works by revising predictions with a second-round query to recognize those missing slots, which can bring an increase in recall score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_75",
            "start": 173,
            "end": 309,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_75@2",
            "content": "To confirm that, we make our analysis",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_75",
            "start": 311,
            "end": 347,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_76@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_76",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_77@0",
            "content": "Prompt-based learning Prompt-based learning approaches have been a broadly discussed topic since large language models like GPT models (Brown et al., 2020) Han et al., 2021) have been proposed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_77",
            "start": 0,
            "end": 192,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_77@1",
            "content": "Unlike sentence-level tasks, prompting method is very complicated for slot tagging and NER tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_77",
            "start": 194,
            "end": 290,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_77@2",
            "content": "Cui et al. (2021) proposes a template-based method querying every slot span with each label which is expensive for decoding.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_77",
            "start": 292,
            "end": 415,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_77@3",
            "content": "Different from them, we introduce an inverse paradigm for prompting slot tagging task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_77",
            "start": 417,
            "end": 502,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_77@4",
            "content": "Note that inverse prompting (Zou et al., 2021) has a similar name to our work but is entirely different in method and task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_77",
            "start": 504,
            "end": 626,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_77@5",
            "content": "They aim to generate prompt templates inversely.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_77",
            "start": 628,
            "end": 675,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_77@6",
            "content": "Amendable generation (Tian et al., 2021) share a similar idea of using Iterative Prediction Strategy to generate and revise dialog state.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_77",
            "start": 677,
            "end": 813,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_77@7",
            "content": "By contrast, we focus on a different task sequence labeling and first to introduce an Iterative Prediction Strategy to prompting models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_77",
            "start": 815,
            "end": 950,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_77@8",
            "content": "There are also generation-based methods for sequence labeling (Yan et al., 2021), which is not a prompting method, since it re-initializes decoding layers and learns a generative model from scratch.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_77",
            "start": 952,
            "end": 1149,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_78@0",
            "content": "Few-shot slot tagging Previous few-shot slot tagging methods focus on metric learning based methods, which classify tokens with word-label similarity (Snell et al., 2017;Vinyals et al., 2016).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_78",
            "start": 0,
            "end": 191,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_78@1",
            "content": "Hou et al. (2020) leverage label name semantics to get better label representation and model label dependency in few-shot setting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_78",
            "start": 193,
            "end": 322,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_78@2",
            "content": "Yang and Katiyar (2020) uses make a prediction based on the nearest neighbor sample instead of the nearest label representation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_78",
            "start": 324,
            "end": 451,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_78@3",
            "content": "Besides, some works also explore training a model with additional data from non-slottagging task Henderson and Vulic, 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_78",
            "start": 453,
            "end": 576,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_78@4",
            "content": "Different from directly learning the few-shot slot tagging model, some researches explore to reformulate the slot tagging into other NLP tasks, Ma et al. (2021a) reforms slot tagging into a reading comprehension task, treats slot tagging as a retrieval task, Coope et al. (2020) uses span extracting task to extract slot and predict corresponding label and Cui et al. (2021) leverages prompts for few-shot NER.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_78",
            "start": 578,
            "end": 987,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_78@5",
            "content": "Different from those methods above, we are the first to reformulate slot tagging task into a prompt-based generation task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_78",
            "start": 989,
            "end": 1110,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_79@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_79",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_80@0",
            "content": "In this paper, to liberate the prompting methods from burdensome prediction of slot-tagging tasks, we introduce a novel inverse prediction manner to prompting methods of slot-tagging, which significantly improves both the efficiency and accuracy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_80",
            "start": 0,
            "end": 245,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_81@0",
            "content": "To further improve performance, we propose an Iterative Prediction Strategy for learning, which enable the prompting model to consider dependency between labels and refine prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_81",
            "start": 0,
            "end": 182,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_81@1",
            "content": "Extensive experiments verify the effectiveness of the proposed method in various few-shot settings, indicating inverse prediction is a better fit for prompting of slot tagging task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_81",
            "start": 184,
            "end": 364,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_82@0",
            "content": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners, , Advances in Neural Information Processing Systems, Curran Associates, Inc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_82",
            "start": 0,
            "end": 501,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_83@0",
            "content": "Sam Coope, Tyler Farghly, Daniela Gerz, Ivan Vulic, Matthew Henderson, Span-convert: Fewshot span extraction for dialog with pretrained conversational representations, 2020, Proc. of the ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_83",
            "start": 0,
            "end": 192,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_84@0",
            "content": "UNKNOWN, None, 2018, Snips voice platform: an embedded spoken language understanding system for privateby-design voice interfaces, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_84",
            "start": 0,
            "end": 131,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_85@0",
            "content": "Leyang Cui, Yu Wu, Jian Liu, Sen Yang, Yue Zhang, Template-based named entity recognition using BART, 2021, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_85",
            "start": 0,
            "end": 233,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_86@0",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_86",
            "start": 0,
            "end": 335,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_87@0",
            "content": "Alexander Fritzler, Varvara Logacheva, Maksim Kretov, Few-shot classification in named entity recognition task, 2019, Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_87",
            "start": 0,
            "end": 185,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_88@0",
            "content": "Tianyu Gao, Adam Fisch, Danqi Chen, Making pre-trained language models better few-shot learners, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_88",
            "start": 0,
            "end": 278,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_89@0",
            "content": "UNKNOWN, None, 2021, Ptr: Prompt tuning with rules for text classification, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_89",
            "start": 0,
            "end": 76,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_90@0",
            "content": "Matthew Henderson, Ivan Vulic, Convex: Data-efficient and few-shot slot labeling, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_90",
            "start": 0,
            "end": 243,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_91@0",
            "content": "Yutai Hou, Wanxiang Che, Yongkui Lai, Zhihan Zhou, Yijia Liu, Han Liu, Ting Liu, Few-shot slot tagging with collapsed dependency transfer and labelenhanced task-adaptive projection network, 2020, Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_91",
            "start": 0,
            "end": 239,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_92@0",
            "content": "UNKNOWN, None, 2020, Few-shot named entity recognition: A comprehensive study, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_92",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_93@0",
            "content": "Zhengbao Jiang, F Frank,  Xu, How can we know what language models know?, 2020-06, Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_93",
            "start": 0,
            "end": 146,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_94@0",
            "content": "Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, Luke Zettlemoyer, BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_94",
            "start": 0,
            "end": 337,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_95@0",
            "content": "UNKNOWN, None, 2021, Prefix-tuning: Optimizing continuous prompts for generation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_95",
            "start": 0,
            "end": 82,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_96@0",
            "content": "UNKNOWN, None, 2021, What makes good in-context examples for gpt-3? arXiv preprint, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_96",
            "start": 0,
            "end": 84,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_97@0",
            "content": "Jingjing Liu, Panupong Pasupat, Yining Wang, Scott Cyphers, Jim Glass, Query understanding enhanced by hierarchical parsing structures, 2013, IEEE Workshop on Automatic Speech Recognition and Understanding, IEEE.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_97",
            "start": 0,
            "end": 211,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_98@0",
            "content": "UNKNOWN, None, , , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_98",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_99@0",
            "content": "UNKNOWN, None, 2019, Roberta: A robustly optimized bert pretraining approach, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_99",
            "start": 0,
            "end": 78,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_100@0",
            "content": "Jianqiang Ma, Zeyu Yan, Chang Li, Yang Zhang, Frustratingly simple few-shot slot tagging, 2021, Findings of the ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_100",
            "start": 0,
            "end": 117,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_101@0",
            "content": "UNKNOWN, None, 2021, Template-free prompt tuning for few-shot NER, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_101",
            "start": 0,
            "end": 71,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_102@0",
            "content": "Xuezhe Ma, Eduard Hovy, End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF, 2016, Proceedings of the 54th Annual Meeting of the Association for Computational LinguisticsACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_102",
            "start": 0,
            "end": 185,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_103@0",
            "content": "Jeffrey Pennington, Richard Socher, Christopher Manning, Glove: Global vectors for word representation, 2014, Proceedings of the 2014 Conference on Empirical Methods in Natural Language ProcessingEMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_103",
            "start": 0,
            "end": 203,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_104@0",
            "content": "UNKNOWN, None, 2019, Language models are unsupervised multitask learners, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_104",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_105@0",
            "content": "Timo Schick, Hinrich Sch\u00fctze, Exploiting cloze-questions for few-shot text classification and natural language inference, 2021, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_105",
            "start": 0,
            "end": 250,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_106@0",
            "content": "Timo Schick, Hinrich Sch\u00fctze, It's not just size that matters: Small language models are also fewshot learners, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_106",
            "start": 0,
            "end": 311,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_107@0",
            "content": "Mike Schuster, Kuldip Paliwal, Bidirectional recurrent neural networks, 1997, IEEE Trans. Signal Process, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_107",
            "start": 0,
            "end": 106,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_108@0",
            "content": "UNKNOWN, None, 2020, Autoprompt: Eliciting knowledge from language models with automatically generated prompts, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_108",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_109@0",
            "content": "Jake Snell, Kevin Swersky, Richard Zemel, Prototypical networks for few-shot learning, 2017, Advances in Neural Information Processing Systems, Curran Associates, Inc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_109",
            "start": 0,
            "end": 166,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_110@0",
            "content": "UNKNOWN, None, 2021, Amendable generation for dialogue state tracking, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_110",
            "start": 0,
            "end": 71,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_111@0",
            "content": "Oriol Vinyals, Charles Blundell, Tim Lillicrap, Koray Kavukcuoglu, Daan Wierstra, Matching networks for one shot learning, 2016, Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing System-sNIPS, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_111",
            "start": 0,
            "end": 248,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_112@0",
            "content": "Yaqing Wang, Quanming Yao, James Kwok, Lionel Ni, Generalizing from a few examples: A survey on few-shot learning, 2020, ACM Comput. Surv, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_112",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_113@0",
            "content": "Sam Wiseman, Karl Stratos, Label-agnostic sequence labeling by copying nearest neighbors, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational LinguisticsACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_113",
            "start": 0,
            "end": 188,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_114@0",
            "content": "Hang Yan, Tao Gui, Junqi Dai, Qipeng Guo, Zheng Zhang, and Xipeng Qiu. 2021. A unified generative framework for various NER subtasks, , Proc. of the ACL/IJCNLP, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_114",
            "start": 0,
            "end": 202,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_115@0",
            "content": "Yi Yang, Arzoo Katiyar, Simple and effective few-shot named entity recognition with structured nearest neighbor learning, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_115",
            "start": 0,
            "end": 273,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_116@0",
            "content": "Dian Yu, Luheng He, Yuan Zhang, Xinya Du, Panupong Pasupat, Qi Li, Few-shot intent classification and slot filling with retrieved examples, 2021, Proc. of the NAACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_116",
            "start": 0,
            "end": 166,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_117@0",
            "content": "UNKNOWN, None, 2021, Calibrate before use: Improving few-shot performance of language models, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_117",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_118@0",
            "content": "UNKNOWN, None, 2008, Example-based named entity recognition. CoRR, abs, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_118",
            "start": 0,
            "end": 72,
            "label": {}
        },
        {
            "ix": "6-ARR_v1_119@0",
            "content": "Xu Zou, Qingyang Da Yin, Hongxia Zhong, Zhilin Yang, Jie Yang,  Tang, Controllable generation from pre-trained language models via inverse prompting, 2021-08-14, KDD '21: The 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Virtual Event, ACM.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "6-ARR_v1_119",
            "start": 0,
            "end": 260,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "6-ARR_v1_0",
            "tgt_ix": "6-ARR_v1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_0",
            "tgt_ix": "6-ARR_v1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_1",
            "tgt_ix": "6-ARR_v1_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_1",
            "tgt_ix": "6-ARR_v1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_0",
            "tgt_ix": "6-ARR_v1_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_2",
            "tgt_ix": "6-ARR_v1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_4",
            "tgt_ix": "6-ARR_v1_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_5",
            "tgt_ix": "6-ARR_v1_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_6",
            "tgt_ix": "6-ARR_v1_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_7",
            "tgt_ix": "6-ARR_v1_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_8",
            "tgt_ix": "6-ARR_v1_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_9",
            "tgt_ix": "6-ARR_v1_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_10",
            "tgt_ix": "6-ARR_v1_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_11",
            "tgt_ix": "6-ARR_v1_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_3",
            "tgt_ix": "6-ARR_v1_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_3",
            "tgt_ix": "6-ARR_v1_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_3",
            "tgt_ix": "6-ARR_v1_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_3",
            "tgt_ix": "6-ARR_v1_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_3",
            "tgt_ix": "6-ARR_v1_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_3",
            "tgt_ix": "6-ARR_v1_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_3",
            "tgt_ix": "6-ARR_v1_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_3",
            "tgt_ix": "6-ARR_v1_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_3",
            "tgt_ix": "6-ARR_v1_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_3",
            "tgt_ix": "6-ARR_v1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_0",
            "tgt_ix": "6-ARR_v1_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_12",
            "tgt_ix": "6-ARR_v1_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_13",
            "tgt_ix": "6-ARR_v1_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_13",
            "tgt_ix": "6-ARR_v1_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_13",
            "tgt_ix": "6-ARR_v1_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_14",
            "tgt_ix": "6-ARR_v1_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_16",
            "tgt_ix": "6-ARR_v1_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_17",
            "tgt_ix": "6-ARR_v1_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_18",
            "tgt_ix": "6-ARR_v1_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_19",
            "tgt_ix": "6-ARR_v1_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_20",
            "tgt_ix": "6-ARR_v1_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_21",
            "tgt_ix": "6-ARR_v1_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_22",
            "tgt_ix": "6-ARR_v1_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_15",
            "tgt_ix": "6-ARR_v1_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_15",
            "tgt_ix": "6-ARR_v1_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_15",
            "tgt_ix": "6-ARR_v1_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_15",
            "tgt_ix": "6-ARR_v1_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_15",
            "tgt_ix": "6-ARR_v1_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_15",
            "tgt_ix": "6-ARR_v1_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_15",
            "tgt_ix": "6-ARR_v1_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_15",
            "tgt_ix": "6-ARR_v1_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_15",
            "tgt_ix": "6-ARR_v1_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_13",
            "tgt_ix": "6-ARR_v1_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_23",
            "tgt_ix": "6-ARR_v1_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_25",
            "tgt_ix": "6-ARR_v1_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_26",
            "tgt_ix": "6-ARR_v1_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_24",
            "tgt_ix": "6-ARR_v1_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_24",
            "tgt_ix": "6-ARR_v1_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_24",
            "tgt_ix": "6-ARR_v1_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_24",
            "tgt_ix": "6-ARR_v1_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_13",
            "tgt_ix": "6-ARR_v1_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_27",
            "tgt_ix": "6-ARR_v1_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_29",
            "tgt_ix": "6-ARR_v1_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_30",
            "tgt_ix": "6-ARR_v1_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_28",
            "tgt_ix": "6-ARR_v1_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_28",
            "tgt_ix": "6-ARR_v1_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_28",
            "tgt_ix": "6-ARR_v1_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_28",
            "tgt_ix": "6-ARR_v1_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_0",
            "tgt_ix": "6-ARR_v1_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_31",
            "tgt_ix": "6-ARR_v1_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_32",
            "tgt_ix": "6-ARR_v1_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_32",
            "tgt_ix": "6-ARR_v1_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_32",
            "tgt_ix": "6-ARR_v1_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_33",
            "tgt_ix": "6-ARR_v1_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_35",
            "tgt_ix": "6-ARR_v1_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_34",
            "tgt_ix": "6-ARR_v1_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_34",
            "tgt_ix": "6-ARR_v1_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_34",
            "tgt_ix": "6-ARR_v1_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_32",
            "tgt_ix": "6-ARR_v1_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_36",
            "tgt_ix": "6-ARR_v1_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_38",
            "tgt_ix": "6-ARR_v1_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_39",
            "tgt_ix": "6-ARR_v1_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_40",
            "tgt_ix": "6-ARR_v1_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_37",
            "tgt_ix": "6-ARR_v1_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_37",
            "tgt_ix": "6-ARR_v1_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_37",
            "tgt_ix": "6-ARR_v1_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_37",
            "tgt_ix": "6-ARR_v1_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_37",
            "tgt_ix": "6-ARR_v1_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_32",
            "tgt_ix": "6-ARR_v1_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_41",
            "tgt_ix": "6-ARR_v1_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_43",
            "tgt_ix": "6-ARR_v1_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_44",
            "tgt_ix": "6-ARR_v1_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_45",
            "tgt_ix": "6-ARR_v1_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_46",
            "tgt_ix": "6-ARR_v1_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_47",
            "tgt_ix": "6-ARR_v1_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_42",
            "tgt_ix": "6-ARR_v1_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_42",
            "tgt_ix": "6-ARR_v1_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_42",
            "tgt_ix": "6-ARR_v1_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_42",
            "tgt_ix": "6-ARR_v1_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_42",
            "tgt_ix": "6-ARR_v1_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_42",
            "tgt_ix": "6-ARR_v1_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_42",
            "tgt_ix": "6-ARR_v1_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_0",
            "tgt_ix": "6-ARR_v1_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_48",
            "tgt_ix": "6-ARR_v1_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_50",
            "tgt_ix": "6-ARR_v1_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_49",
            "tgt_ix": "6-ARR_v1_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_49",
            "tgt_ix": "6-ARR_v1_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_49",
            "tgt_ix": "6-ARR_v1_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_49",
            "tgt_ix": "6-ARR_v1_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_51",
            "tgt_ix": "6-ARR_v1_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_53",
            "tgt_ix": "6-ARR_v1_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_54",
            "tgt_ix": "6-ARR_v1_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_55",
            "tgt_ix": "6-ARR_v1_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_57",
            "tgt_ix": "6-ARR_v1_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_58",
            "tgt_ix": "6-ARR_v1_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_59",
            "tgt_ix": "6-ARR_v1_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_60",
            "tgt_ix": "6-ARR_v1_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_61",
            "tgt_ix": "6-ARR_v1_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_52",
            "tgt_ix": "6-ARR_v1_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_52",
            "tgt_ix": "6-ARR_v1_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_52",
            "tgt_ix": "6-ARR_v1_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_52",
            "tgt_ix": "6-ARR_v1_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_52",
            "tgt_ix": "6-ARR_v1_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_52",
            "tgt_ix": "6-ARR_v1_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_52",
            "tgt_ix": "6-ARR_v1_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_52",
            "tgt_ix": "6-ARR_v1_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_52",
            "tgt_ix": "6-ARR_v1_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_52",
            "tgt_ix": "6-ARR_v1_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_52",
            "tgt_ix": "6-ARR_v1_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_49",
            "tgt_ix": "6-ARR_v1_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_62",
            "tgt_ix": "6-ARR_v1_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_64",
            "tgt_ix": "6-ARR_v1_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_65",
            "tgt_ix": "6-ARR_v1_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_66",
            "tgt_ix": "6-ARR_v1_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_67",
            "tgt_ix": "6-ARR_v1_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_63",
            "tgt_ix": "6-ARR_v1_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_63",
            "tgt_ix": "6-ARR_v1_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_63",
            "tgt_ix": "6-ARR_v1_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_63",
            "tgt_ix": "6-ARR_v1_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_63",
            "tgt_ix": "6-ARR_v1_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_63",
            "tgt_ix": "6-ARR_v1_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_69",
            "tgt_ix": "6-ARR_v1_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_70",
            "tgt_ix": "6-ARR_v1_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_71",
            "tgt_ix": "6-ARR_v1_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_72",
            "tgt_ix": "6-ARR_v1_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_63",
            "tgt_ix": "6-ARR_v1_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_63",
            "tgt_ix": "6-ARR_v1_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_63",
            "tgt_ix": "6-ARR_v1_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_63",
            "tgt_ix": "6-ARR_v1_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_63",
            "tgt_ix": "6-ARR_v1_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_49",
            "tgt_ix": "6-ARR_v1_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_73",
            "tgt_ix": "6-ARR_v1_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_74",
            "tgt_ix": "6-ARR_v1_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_74",
            "tgt_ix": "6-ARR_v1_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_0",
            "tgt_ix": "6-ARR_v1_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_75",
            "tgt_ix": "6-ARR_v1_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_77",
            "tgt_ix": "6-ARR_v1_78",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_76",
            "tgt_ix": "6-ARR_v1_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_76",
            "tgt_ix": "6-ARR_v1_78",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_76",
            "tgt_ix": "6-ARR_v1_77",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_0",
            "tgt_ix": "6-ARR_v1_79",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_78",
            "tgt_ix": "6-ARR_v1_79",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_80",
            "tgt_ix": "6-ARR_v1_81",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_79",
            "tgt_ix": "6-ARR_v1_80",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_79",
            "tgt_ix": "6-ARR_v1_81",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_79",
            "tgt_ix": "6-ARR_v1_80",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "6-ARR_v1_0",
            "tgt_ix": "6-ARR_v1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_1",
            "tgt_ix": "6-ARR_v1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_2",
            "tgt_ix": "6-ARR_v1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_2",
            "tgt_ix": "6-ARR_v1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_2",
            "tgt_ix": "6-ARR_v1_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_2",
            "tgt_ix": "6-ARR_v1_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_2",
            "tgt_ix": "6-ARR_v1_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_2",
            "tgt_ix": "6-ARR_v1_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_2",
            "tgt_ix": "6-ARR_v1_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_2",
            "tgt_ix": "6-ARR_v1_2@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_2",
            "tgt_ix": "6-ARR_v1_2@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_3",
            "tgt_ix": "6-ARR_v1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_4",
            "tgt_ix": "6-ARR_v1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_4",
            "tgt_ix": "6-ARR_v1_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_5",
            "tgt_ix": "6-ARR_v1_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_5",
            "tgt_ix": "6-ARR_v1_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_5",
            "tgt_ix": "6-ARR_v1_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_5",
            "tgt_ix": "6-ARR_v1_5@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_6",
            "tgt_ix": "6-ARR_v1_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_6",
            "tgt_ix": "6-ARR_v1_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_6",
            "tgt_ix": "6-ARR_v1_6@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_6",
            "tgt_ix": "6-ARR_v1_6@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_6",
            "tgt_ix": "6-ARR_v1_6@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_6",
            "tgt_ix": "6-ARR_v1_6@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_7",
            "tgt_ix": "6-ARR_v1_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_7",
            "tgt_ix": "6-ARR_v1_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_7",
            "tgt_ix": "6-ARR_v1_7@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_7",
            "tgt_ix": "6-ARR_v1_7@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_7",
            "tgt_ix": "6-ARR_v1_7@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_7",
            "tgt_ix": "6-ARR_v1_7@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_8",
            "tgt_ix": "6-ARR_v1_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_9",
            "tgt_ix": "6-ARR_v1_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_10",
            "tgt_ix": "6-ARR_v1_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_11",
            "tgt_ix": "6-ARR_v1_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_12",
            "tgt_ix": "6-ARR_v1_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_13",
            "tgt_ix": "6-ARR_v1_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_14",
            "tgt_ix": "6-ARR_v1_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_15",
            "tgt_ix": "6-ARR_v1_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_16",
            "tgt_ix": "6-ARR_v1_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_17",
            "tgt_ix": "6-ARR_v1_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_18",
            "tgt_ix": "6-ARR_v1_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_19",
            "tgt_ix": "6-ARR_v1_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_20",
            "tgt_ix": "6-ARR_v1_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_20",
            "tgt_ix": "6-ARR_v1_20@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_20",
            "tgt_ix": "6-ARR_v1_20@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_20",
            "tgt_ix": "6-ARR_v1_20@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_21",
            "tgt_ix": "6-ARR_v1_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_22",
            "tgt_ix": "6-ARR_v1_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_23",
            "tgt_ix": "6-ARR_v1_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_24",
            "tgt_ix": "6-ARR_v1_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_25",
            "tgt_ix": "6-ARR_v1_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_25",
            "tgt_ix": "6-ARR_v1_25@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_25",
            "tgt_ix": "6-ARR_v1_25@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_25",
            "tgt_ix": "6-ARR_v1_25@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_26",
            "tgt_ix": "6-ARR_v1_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_27",
            "tgt_ix": "6-ARR_v1_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_28",
            "tgt_ix": "6-ARR_v1_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_29",
            "tgt_ix": "6-ARR_v1_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_29",
            "tgt_ix": "6-ARR_v1_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_30",
            "tgt_ix": "6-ARR_v1_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_31",
            "tgt_ix": "6-ARR_v1_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_31",
            "tgt_ix": "6-ARR_v1_31@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_32",
            "tgt_ix": "6-ARR_v1_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_33",
            "tgt_ix": "6-ARR_v1_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_33",
            "tgt_ix": "6-ARR_v1_33@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_34",
            "tgt_ix": "6-ARR_v1_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_35",
            "tgt_ix": "6-ARR_v1_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_35",
            "tgt_ix": "6-ARR_v1_35@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_36",
            "tgt_ix": "6-ARR_v1_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_36",
            "tgt_ix": "6-ARR_v1_36@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_36",
            "tgt_ix": "6-ARR_v1_36@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_37",
            "tgt_ix": "6-ARR_v1_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_38",
            "tgt_ix": "6-ARR_v1_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_39",
            "tgt_ix": "6-ARR_v1_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_39",
            "tgt_ix": "6-ARR_v1_39@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_39",
            "tgt_ix": "6-ARR_v1_39@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_39",
            "tgt_ix": "6-ARR_v1_39@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_39",
            "tgt_ix": "6-ARR_v1_39@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_40",
            "tgt_ix": "6-ARR_v1_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_41",
            "tgt_ix": "6-ARR_v1_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_41",
            "tgt_ix": "6-ARR_v1_41@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_41",
            "tgt_ix": "6-ARR_v1_41@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_42",
            "tgt_ix": "6-ARR_v1_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_43",
            "tgt_ix": "6-ARR_v1_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_43",
            "tgt_ix": "6-ARR_v1_43@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_43",
            "tgt_ix": "6-ARR_v1_43@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_43",
            "tgt_ix": "6-ARR_v1_43@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_43",
            "tgt_ix": "6-ARR_v1_43@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_44",
            "tgt_ix": "6-ARR_v1_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_44",
            "tgt_ix": "6-ARR_v1_44@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_44",
            "tgt_ix": "6-ARR_v1_44@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_45",
            "tgt_ix": "6-ARR_v1_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_45",
            "tgt_ix": "6-ARR_v1_45@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_45",
            "tgt_ix": "6-ARR_v1_45@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_46",
            "tgt_ix": "6-ARR_v1_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_46",
            "tgt_ix": "6-ARR_v1_46@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_46",
            "tgt_ix": "6-ARR_v1_46@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_46",
            "tgt_ix": "6-ARR_v1_46@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_47",
            "tgt_ix": "6-ARR_v1_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_48",
            "tgt_ix": "6-ARR_v1_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_48",
            "tgt_ix": "6-ARR_v1_48@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_48",
            "tgt_ix": "6-ARR_v1_48@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_48",
            "tgt_ix": "6-ARR_v1_48@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_49",
            "tgt_ix": "6-ARR_v1_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_50",
            "tgt_ix": "6-ARR_v1_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_50",
            "tgt_ix": "6-ARR_v1_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_51",
            "tgt_ix": "6-ARR_v1_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_51",
            "tgt_ix": "6-ARR_v1_51@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_51",
            "tgt_ix": "6-ARR_v1_51@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_51",
            "tgt_ix": "6-ARR_v1_51@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_51",
            "tgt_ix": "6-ARR_v1_51@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_51",
            "tgt_ix": "6-ARR_v1_51@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_51",
            "tgt_ix": "6-ARR_v1_51@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_52",
            "tgt_ix": "6-ARR_v1_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_53",
            "tgt_ix": "6-ARR_v1_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_53",
            "tgt_ix": "6-ARR_v1_53@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_54",
            "tgt_ix": "6-ARR_v1_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_54",
            "tgt_ix": "6-ARR_v1_54@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_54",
            "tgt_ix": "6-ARR_v1_54@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_54",
            "tgt_ix": "6-ARR_v1_54@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_55",
            "tgt_ix": "6-ARR_v1_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_56",
            "tgt_ix": "6-ARR_v1_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_57",
            "tgt_ix": "6-ARR_v1_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_57",
            "tgt_ix": "6-ARR_v1_57@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_58",
            "tgt_ix": "6-ARR_v1_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_58",
            "tgt_ix": "6-ARR_v1_58@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_59",
            "tgt_ix": "6-ARR_v1_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_60",
            "tgt_ix": "6-ARR_v1_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_61",
            "tgt_ix": "6-ARR_v1_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_62",
            "tgt_ix": "6-ARR_v1_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_63",
            "tgt_ix": "6-ARR_v1_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_64",
            "tgt_ix": "6-ARR_v1_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_64",
            "tgt_ix": "6-ARR_v1_64@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_64",
            "tgt_ix": "6-ARR_v1_64@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_64",
            "tgt_ix": "6-ARR_v1_64@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_65",
            "tgt_ix": "6-ARR_v1_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_65",
            "tgt_ix": "6-ARR_v1_65@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_65",
            "tgt_ix": "6-ARR_v1_65@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_65",
            "tgt_ix": "6-ARR_v1_65@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_66",
            "tgt_ix": "6-ARR_v1_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_67",
            "tgt_ix": "6-ARR_v1_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_68",
            "tgt_ix": "6-ARR_v1_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_69",
            "tgt_ix": "6-ARR_v1_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_69",
            "tgt_ix": "6-ARR_v1_69@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_70",
            "tgt_ix": "6-ARR_v1_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_71",
            "tgt_ix": "6-ARR_v1_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_71",
            "tgt_ix": "6-ARR_v1_71@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_72",
            "tgt_ix": "6-ARR_v1_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_73",
            "tgt_ix": "6-ARR_v1_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_74",
            "tgt_ix": "6-ARR_v1_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_75",
            "tgt_ix": "6-ARR_v1_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_75",
            "tgt_ix": "6-ARR_v1_75@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_75",
            "tgt_ix": "6-ARR_v1_75@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_76",
            "tgt_ix": "6-ARR_v1_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_77",
            "tgt_ix": "6-ARR_v1_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_77",
            "tgt_ix": "6-ARR_v1_77@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_77",
            "tgt_ix": "6-ARR_v1_77@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_77",
            "tgt_ix": "6-ARR_v1_77@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_77",
            "tgt_ix": "6-ARR_v1_77@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_77",
            "tgt_ix": "6-ARR_v1_77@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_77",
            "tgt_ix": "6-ARR_v1_77@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_77",
            "tgt_ix": "6-ARR_v1_77@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_77",
            "tgt_ix": "6-ARR_v1_77@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_78",
            "tgt_ix": "6-ARR_v1_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_78",
            "tgt_ix": "6-ARR_v1_78@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_78",
            "tgt_ix": "6-ARR_v1_78@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_78",
            "tgt_ix": "6-ARR_v1_78@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_78",
            "tgt_ix": "6-ARR_v1_78@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_78",
            "tgt_ix": "6-ARR_v1_78@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_79",
            "tgt_ix": "6-ARR_v1_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_80",
            "tgt_ix": "6-ARR_v1_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_81",
            "tgt_ix": "6-ARR_v1_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_81",
            "tgt_ix": "6-ARR_v1_81@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_82",
            "tgt_ix": "6-ARR_v1_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_83",
            "tgt_ix": "6-ARR_v1_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_84",
            "tgt_ix": "6-ARR_v1_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_85",
            "tgt_ix": "6-ARR_v1_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_86",
            "tgt_ix": "6-ARR_v1_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_87",
            "tgt_ix": "6-ARR_v1_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_88",
            "tgt_ix": "6-ARR_v1_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_89",
            "tgt_ix": "6-ARR_v1_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_90",
            "tgt_ix": "6-ARR_v1_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_91",
            "tgt_ix": "6-ARR_v1_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_92",
            "tgt_ix": "6-ARR_v1_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_93",
            "tgt_ix": "6-ARR_v1_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_94",
            "tgt_ix": "6-ARR_v1_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_95",
            "tgt_ix": "6-ARR_v1_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_96",
            "tgt_ix": "6-ARR_v1_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_97",
            "tgt_ix": "6-ARR_v1_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_98",
            "tgt_ix": "6-ARR_v1_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_99",
            "tgt_ix": "6-ARR_v1_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_100",
            "tgt_ix": "6-ARR_v1_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_101",
            "tgt_ix": "6-ARR_v1_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_102",
            "tgt_ix": "6-ARR_v1_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_103",
            "tgt_ix": "6-ARR_v1_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_104",
            "tgt_ix": "6-ARR_v1_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_105",
            "tgt_ix": "6-ARR_v1_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_106",
            "tgt_ix": "6-ARR_v1_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_107",
            "tgt_ix": "6-ARR_v1_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_108",
            "tgt_ix": "6-ARR_v1_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_109",
            "tgt_ix": "6-ARR_v1_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_110",
            "tgt_ix": "6-ARR_v1_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_111",
            "tgt_ix": "6-ARR_v1_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_112",
            "tgt_ix": "6-ARR_v1_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_113",
            "tgt_ix": "6-ARR_v1_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_114",
            "tgt_ix": "6-ARR_v1_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_115",
            "tgt_ix": "6-ARR_v1_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_116",
            "tgt_ix": "6-ARR_v1_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_117",
            "tgt_ix": "6-ARR_v1_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_118",
            "tgt_ix": "6-ARR_v1_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "6-ARR_v1_119",
            "tgt_ix": "6-ARR_v1_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 1127,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "position_tag_type": "from_draft",
        "doc_id": "6-ARR",
        "version": 1
    }
}