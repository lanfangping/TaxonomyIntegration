{
    "nodes": [
        {
            "ix": "23-ARR_v2_0",
            "content": "Bridging the Generalization Gap in Text-to-SQL Parsing with Schema Expansion",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_2",
            "content": "Text-to-SQL parsers map natural language questions to programs that are executable over tables to generate answers, and are typically evaluated on large-scale datasets like SPIDER (Yu et al., 2018). We argue that existing benchmarks fail to capture a certain out-of-domain generalization problem that is of significant practical importance: matching domain specific phrases to composite operations over columns.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_3",
            "content": "To study this problem, we propose a synthetic dataset and a re-purposed train/test split of the SQUALL dataset (Shi et al., 2020) as new benchmarks to quantify domain generalization over column operations. Our results indicate that existing state-of-the-art parsers struggle in these benchmarks. We propose to address this problem by incorporating prior domain knowledge by preprocessing table schemas, and design a method that consists of two components: schema expansion and schema pruning. This method can be easily applied to multiple existing base parsers, and we show that it significantly outperforms baseline parsers on this domain generalization problem, boosting the underlying parsers' overall performance by up to 13.8% relative accuracy gain (5.1% absolute) on the new SQUALL data split.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_4",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "23-ARR_v2_5",
            "content": "Text-to-SQL parsing is the task of translating natural language questions over provided tables to SQL queries which can be executed to produce answers. In recent years, with the availability of large-scale datasets (e.g., Zhong et al., 2017;Yu et al., 2018), neural semantic parsers have witnessed significant success on this task. However, recent work (Suhr et al., 2020;Lee et al., 2021) has suggested that these state-of-the-art parsers are far from successful in terms of out-of-domain generalization in real scenarios, where users may ask questions related to potentially very large tables with the goal of improving their productivity (e.g., while they are viewing or editing a large Excel spreadsheet).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_6",
            "content": "Figure 1: Illustration of two aspects of out-of-domain generalization that are challenging for text-to-SQL parsers. While existing methods partially address the \"column matching\" issue, they still suffer when it comes to \"column operations\". Note that there are more tables on the right to illustrate the fact that there are a variety of settings the parser may run into at test time.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_7",
            "content": "In such scenarios, it is common to encounter tables specific to new domains that were not encountered while training a parser. Perhaps the most challenging aspect of domain generalization is that models need to understand domain-specific phrases that they have not seen before, and translate them into logical form segments that involve references to table elements (e.g., column names or aggregation operations over columns). We argue that two kinds of abstract operations, shown in Figure 1, are particularly challenging for new domains:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_8",
            "content": "1. Column Matching: The task of mapping natural language phrases to the most relevant columns (e.g., mapping \"Income\" to the \"Wages\" column). This can be challenging because some mappings may be implicit or may require domain knowledge. 2. Column Operations: The task of mapping natural language phrases to composite expressions over table columns. For example, in Figure 1, we need to map income to just \"Wages\" for one table, and to \"Salary\" + \"Stock\" for another table. Similarly, consider the complex \"Term\" column in Figure 2, in which two subfields 1 and 2 represent the term start (e.g., 1926) and term end (e.g., 1927), respectively. Some questions may ask about the term duration while others may ask about the term start.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_9",
            "content": "Figure 2: Illustration of the training pipeline for the proposed method and the inference process for an example. The proposed method is described in detail in \u00a74. Note that the proposed components interact with the parser by modifying the table that is fed to it as input, as well as the target program during training in the case of schema expansion.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_10",
            "content": "Each of these questions requires mapping the corresponding phrase to an expression that refers to this column (e.g., \"Term\". 2 -\"Term\". 1 for the former and \"Term\". 1 for the latter).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_11",
            "content": "While recent approaches rely on pre-trained language models (e.g., Yin et al., 2020;Deng et al., 2021) for addressing the column matching challenge, column operations remain relatively unexplored due to the lack of evaluation benchmarks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_12",
            "content": "To this end, we first propose two new benchmarks: a synthetic dataset and a train/test repartitioning of the SQUALL dataset (Shi et al., 2020); both capable of quantifying out-of-domain generalization on column operations. We then show that existing neural parsers underperform on both benchmarks because they require an impractically large amount of in-domain training datawhich is not available in our setting-to effectively \"memorize\" mappings from natural language phrases to program fragments. Finally, we propose a new method for making any existing text-to-SQL parsers aware of prior information that may be available about the domains of interest. Specifically, we propose two new components: schema expansion and schema pruning.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_13",
            "content": "Schema expansion uses heuristics to expand columns into sets of derived columns based solely on their types (all schemas are assumed to be typed which tends to be true for both relational databases and Excel spreadsheets in practice; Excel uses a built-in type inference mechanism). Relying on generic types makes this method applicable to new domains, as long as they make use of similar underlying types. This process allows us to transform complex program fragments (e.g., \"Term\". 2 -\"Term\". 1) into simpler ones (e.g., \"Term Duration\") that are better aligned with the natural language questions, thus making the underlying parser's job easier. While schema expansion may result in a large number of unnecessary expanded columns, schema pruning then examines both the input question and the available columns (original and expanded) and prunes the set of columns that the final parser is exposed to.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_14",
            "content": "Our experiments show that schema expansion and schema pruning can boost the underlying parsers' performance by up to 13.8% relative accuracy (5.1% absolute) on the new SQUALL data split. Furthermore, they also boost performance over the original SQUALL data splits by up to 4.2% relative (1.9% absolute). One of our main goals in this paper is to put attention on the difficult problem of domain generalization by providing a new evaluation benchmark, as well as an initial direction for solving this problem. Our evaluation benchmarks along with code for reproducing our experiments are available at https://aka.ms/ text-to-sql-schema-expansion-generalization.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_15",
            "content": "Background",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "23-ARR_v2_16",
            "content": "Task. Semantic parsing has been widely studied in the context of multiple other tasks like instruction following (Chen and Mooney, 2011;Artzi and Zettlemoyer, 2013), code generation (Oda et al., 2015;Iyer et al., 2018), knowledge graph question answering (Berant et al., 2013;Yih et al., 2015), etc. We focus on using tables as the context in which semantic parsing is performed, where the goal is to translate pairs of natural language questions and tables to executable SQL queries, also known as text-to-SQL parsing (Androutsopoulos et al., 1995;Minock et al., 2008). Note that, while we focus on questions in the English language, there exists prior work on multilingual semantic parsing as well (Jie and Lu, 2014;Sherborne et al., 2020) and the contributions of our work also apply there. Formally, our goal is to map a pair (q, T ), where q is a natural language question and T is a table, to an executable program \u03c0 that, when executed against table T , will produce the answer \u03b1 to question q. We focus on the fully-supervised setting where the target executable program \u03c0 * is provided as supervision for training our parser.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_17",
            "content": "Out-of-Domain Generalization. Generalization in machine learning is often defined as the ability to do well on a test set after learning from a training set, where all examples in both sets are drawn independently from the same distribution (i.i.d. generalization). However, as Gu et al. (2021) argue, in real-world applications such as semantic parsing, the test data may involve new compositional structures (compositional generalization), or new domains (domain generalization) that are not encountered during training. Existing work in compositional generalization for semantic parsing has focused on using synthetic datasets (e.g., Keysers et al., 2020;Lake and Baroni, 2018), or repartitioning existing text-to-SQL datasets into new train and test splits (e.g., Finegan-Dollak et al., 2018). Both approaches have generally shown that compositional generalization remains an important challenge (e.g., Shaw et al., 2021). We focus on the arguably even more challenging domain generalization problem, also known as domain adaptation, where entire domains may never be encountered during training or may only be encountered a small number of times (Motiian et al., 2017). Even though this problem has been studied extensively in the context of classification (Daum\u00e9 III and Marcu, 2006), machine translation (Daum\u00e9 III and Jagarlamudi, 2011), and question answering (Talmor and Berant, 2019), it remains underexplored for semantic parsing. To be applicable in real scenarios, semantic parsers must be able to generalize to new domains since collecting domain-specific labeled data is often prohibitively expensive. Recent approaches have focused on data synthesis (Yin et al., 2021), meta-learning (Wang et al., 2021), relation-aware schema encoding (Wang et al., 2020), and encoder pretraining (Yin et al., 2020;Herzig et al., 2020;Yu et al., 2020;Deng et al., 2021). In this paper, we hone in on one aspect of domain generalization that we shall broadly refer to as column operations and which was introduced in \u00a71 and illustrated in Figure 1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_18",
            "content": "Evaluation Benchmarks. Text-to-SQL parsing became popular after the introduction of large-scale datasets and evaluation benchmarks. Zhong et al. (2017) first introduced WIKISQL, which contains Wikipedia tables paired with questions and annotated with SQL queries, albeit the queries are generated from a limited set of templates. SPIDER was introduced by Yu et al. (2018) the following year. It contains more complex questions and SQL queries and focuses on generalizing to previously unseen database schemas, but the dataset has the artifact from its annotation design that the references columns are often mentioned verbatim in the natural language questions. Deng et al. (2021) attempt to address this limitation by repartitioning SPIDER to produce a more realistic benchmark, and Lee et al. (2021) propose a challenging test set from Kaggle for evaluating parsers trained on SPIDER dataset. However, as Suhr et al. (2020) point out, SPIDER also uses a simplified setting which excludes examples that involve multiple columns (e.g., adding two columns together), as well as ones that require background knowledge. These benchmarks are thus limited in their usefulness for evaluating parsers in real-world settings where they may encounter complex questions that require mapping specific phrases to expressions over table columns, rather than to a single column. Furthermore, while both WIKISQL and SPIDER assume \"simple\" tables with only String-or Number-valued columns, in practice we may encounter tables where the columns themselves may have structured types (e.g., TimeSpan). For example, consider the table shown on the top left of Figure 2. In this case, the \"Term\" column is of type TimeSpan and consists of two Numbers that represent the beginning and the end of the timespan. In this case, users may ask questions that require constructing expressions to access nested elements from the \"Term\" column (e.g., \"How long was Pier's term?\"). Recently, Shi et al. (2020) introduced SQUALL, a dataset that annotates WIKITABLEQUES-TIONS (Pasupat and Liang, 2015) with SQL queries and refined column types like Date, Score, (T1, T2), and List[T]. However, SQUALL distributes tables evenly between the train and test splits, thus not allowing us to evaluate the kind of out-of-domain generalization we are interested in. Therefore as we will show in the following section, we aim to address this limitation by repartitioning SQUALL into new train and test splits. Neural Text-to-SQL Parsers. Neural encoder-decoder models have recently gained popularity for text-to-SQL parsing (e.g., Xu et al., 2017). We focus on two models that represent the current state-of-the-art for SQUALL and SPIDER, respectively: SEQ2SEQ of Shi et al. (2020) 1 and SMBOP of Rubin and Berant (2021). Both models concatenate the question with a textual representation of the table schema, separated by a special [SEP] token, and feed the combined sequence to a pre-trained instance of the BERT (Devlin et al., 2019) language model. The activations of the last layer represent the encoded representations of the question and the table schema. SEQ2SEQ then uses a autoregressive decoder, which represents programs as token sequences and at each decoding step it: (1) predicts the next token type (i.e., whether the next token is a SQL keyword, a column name, or a literal value), and (2) predicts the token conditioned on its type. SMBOP, on the other hand, uses bottom-up decoding, which represents programs as abstract syntax trees and constructs these trees in a bottom-up fashion (i.e., it starts by predicting the leaf nodes and then recursively composes generated sub-trees into new trees and ranks them, in a way that resembles beam search), until it reaches the tree root. We refer the reader to the aforementioned papers for details.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_19",
            "content": "Proposed Evaluation Benchmarks",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "23-ARR_v2_20",
            "content": "Our goal is to design an evaluation benchmark that has the following out-of-domain generalization properties: (i) the training data involves a different set of domains from the test data, (ii) the questions and tables that appear in the train and test data are non-overlapping, not only in terms of the domains they belong to, but also in terms of the program fragments that they contain, and (iii) to simulate the more challenging setting that is often encountered in real applications, the test data is biased to contain more examples that involve both nested column access operations, like getting the start of a \"Term\" in Figure 2, as well as composite column expressions, like getting the duration of a \"Term\". To this end, we propose a new synthetic dataset and a repartitioning of the SQUALL dataset into new train/test splits.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_21",
            "content": "Synthetic Dataset",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "23-ARR_v2_22",
            "content": "We consider three fictional domains inspired by common uses of tables: finance, sports, and science. We explain our synthetic dataset generation process through a running example as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_23",
            "content": "1. For each domain, we declare a set of formulas that relate different quantities (e.g., \"Income\" = \"Salary\" + \"Stock\"). The primitives used in these formulas define the set of available columns. 2. For each column we declare a set of noun phrases that can be used to refer to it (e.g., \"wages\" for \"Income\" and \"base salary\" for \"salary\"). We also define a SQL query template that shall be used for all programs: SELECT <column> FROM t WHERE \"Year\" = <year>, and a question template What was <column> in <year>? Note that the \"Year\" column is special and is included in all examples of this synthetic dataset. 3. We sample a formula and a variable from that formula (e.g., \"Income\" from formula \"Income\" = \"Salary\" + \"Stock\" ). We then generate a question asking for this variable, randomly replacing the variable with a noun phrase in the corresponding set, and randomly generate a year value (e.g., use \"wages\" to replace \"income\" and generate a question \"What was [wages] in [2011]?\"). 4. To generate the target program \u03c0 * , we randomly drop a variable from the sampled formula in step 3.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_24",
            "content": "If the asked value corresponds to this variable, we transform its reference in the SQL query so that it is expressed as a function of the columns that are kept (e.g., \"Salary\" + \"Stock\"), otherwise we use the column name (e.g., \"Income\"). 5. To generate a table schema we first add a \"Year\" column and two of the columns that were not sampled from the formula (e.g., \"Salary\" and \"Stock\"). We then sample k other columns and add them to schema (k = 15 in our experiments) as distractor columns. Note that we do not generate full tables for this synthetic dataset since we do not evaluate on table cell selections.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_25",
            "content": "We construct benchmark datasets by first generating 1,000 examples per domain and then iterating over the domains and keeping the data generated for the current domain as our test data, while using the data of the remaining two domains for training. This results in three datasets, each with 2,000 train examples and 1,000 test examples. More details on the declarations for our domains can be found in Appendix A.1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_26",
            "content": "SQUALL Repartitioning",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "23-ARR_v2_27",
            "content": "Aside from the synthetic dataset we also propose to repartition SQUALL into new train and test data splits, with a focus on the aforementioned out-of-domain generalization properties. The original splits for SQUALL were produced by uniformly sampling 20% of the tables to produce the test set and using the remaining 80% as the train set. This process was repeated 5 times and the evaluation metric results were averaged over the results obtained for each repetition. adding all examples that use tables included in this cluster. This step will result in disproportionally more column operations being used in our test set than in our train set, which means that the model will need to learn to generalize well in this setting to do well in this dataset.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_28",
            "content": "In the following sections we pay special attention to four data subcategories that are representative of the out-of-domain generalization setting for SQUALL:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_29",
            "content": "-Score Expressions: Represents SQL queries that include expressions over columns of type Score (e.g., a query selecting the score difference for a basketball game). -Score Accessors: Represents SQL queries that include field accessors for columns of type Score (e.g., a column with the results of a basketball game, like \"89-72\", and a query that requires accessing the first element of this score; i.e., \"89\"). -Date Expressions: Similar to Score expressions except using the Date and TimeSpan type (e.g., a query asking for the duration of a presidency term). -Date Accessors: Similar to Score Accessors, except using the Date and TimeSpan type (e.g., a query asking for the start of a term).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_30",
            "content": "We shall refer to these categories when reporting experimental results in \u00a75. We provide statistics for the resulting dataset in Table 1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_31",
            "content": "Proposed Method",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "23-ARR_v2_32",
            "content": "In this section we propose a simple approach for tackling this specific out-of-domain generalization problem that ought to serve as evidence that it is a real problem and that it is solvable, as well as a reference point for evaluating future approaches. Our approach consists of two new components that can be used in combination with any existing text-to-SQL parser: schema expansion and schema pruning. These components interact with the parser by preprocessing the table that is fed to it as input. This is illustrated in Figure 2.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_33",
            "content": "As discussed in \u00a71, there are two kinds of challenges related to out-of-domain generalization in text-to-SQL parsing, column matching and column operations, with the latter being more challenging. The goal of schema expansion is to reduce column operation challenges to column matching by adding synthetic columns to the table schema. These synthetic columns correspond to expressions or accessors over existing columns (e.g., a column that represents the sum of two columns). Rather than learning (or memorizing) the ways in which different types of columns can be composed together, we propose to inject prior knowledge as to what kind of symbolic operations are possible based solely on the column types in a schema. This reduces column operations to column matching by effectively bringing the target programs closer to their surface form in the natural language question. For example, \"Income\" can now map to a synthetic column that corresponds to the sum of \"Salary\" and \"Stock\" instead of having the parser produce the sum expression directly. Since our expansion is based on column types, we argue that it is reasonable to assume that all schemas are typed and our expansion could be applied to any new domain. It is also worth noting that even though our templates may not cover all cases, 2 when applying our method to new domains, developers can declare a few templates of their interest and apply schema expansion on these templates to create parser-friendly schemas. This would be more cost-effective compared to collecting large in-domain training data for training the parser.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_34",
            "content": "Naturally, having a component that expands the table schema means that we may end up with large schemas that the parser has to deal with, which will often involve a lot of irrelevant columns (partially because the schema expansion component does not peek at the question). This can result in increased latency which is not desirable in real-world systems. To this end, we introduce a schema pruning component that looks at both the expanded table schema and the question and decides which columns to prune before invoking the parser. It can be argued that this pruning is as hard as parsing itself, but there is evidence from other areas that it can indeed be helpful (e.g., vocabulary selection; Chen et al., 2019;Xu et al., 2021). As we shall show schema pruning can actually provide an additional boost in accuracy, depending on architecture of the underlying parser.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_35",
            "content": "Schema Expansion",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "23-ARR_v2_36",
            "content": "A domain developer first declares a set of templates that specify the ways in which different column types can interact (e.g., it specifies that given a typed TimeSpan column that contains two subfields, 1 and 2, the expression TimeSpan. 2 -TimeSpan. 1 can be constructed that represents a duration), and the names for each such interaction (e.g., \"Duration\"). 3 The schema expansion component receives as input this set of templates along with the table schema and returns an expanded schema that includes additional columns generated by using all applicable templates. For our SQUALL experiments, we declared the templates shown in Table 2. Although these templates are somewhat tailored to this dataset, our main goal is to show that there is considerable room for improvement in this challenging generalization scenario, and that even a simple approach with minimal manual effort can result in significant gains.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_37",
            "content": "Schema Pruning",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "23-ARR_v2_38",
            "content": "We propose a simple schema pruning approach that is inspired by vocabulary selection methods in machine translation. Let us denote the input question by q and the input column names after expansion by c 1 , . . . , c M . We concatenate the question and the column names as",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_39",
            "content": "[CLS] q [SEP] c1 [SEP] ... [SEP] cM [SEP]",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_40",
            "content": "and feed the resulting sequence to a BERT encoder (Devlin et al., 2019). We then define the embedding of each column, c i , as the final-layer representation of the last token of that column's name. Finally, we define the probability that a column should be kept as",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_41",
            "content": "p i = Softmax (MLP(c i ))",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_42",
            "content": ". We train this model based on whether each column is used in the corresponding SQL program. At inference time, we need to choose a threshold on the predicted probabilities for deciding whether to prune a column or not. We assume a transductive setting and choose this threshold such that the ratio of pruned columns over the test set equals to the ratio of pruned columns over the train set plus a constant hyperparameter to account for fact that accuracy will likely be lower for the test set than the train set. Note that assuming a transductive setting is fine because in a realworld system we could be tuning this threshold based on the last t requests made to the model. While this is not equivalent, assuming a large enough t, we should be able to adapt this threshold using the same approach.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_43",
            "content": "Negative Column Sampling. As is evident from Figure 2, we also introduce a negative column sampling component. This is because we train our pruning model on the same data that we use to train the underlying parser (aside from the modified table schemas) and thus the pruning model can become good at pruning all irrelevant columns over this dataset. This will result in the underlying parser being unable to handle situations where irrelevant columns are mistakenly left unpruned by the pruning model. To this end, during training we introduce some irrelevant columns to improve the robustness of the underlying parser. We found that making sure to always include at least 3 columns in the resulting schemas was sufficient and equivalent to randomly sampling 1 or 2 additional columns for each training example, and so that is what we did in our experiments.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_44",
            "content": "Experiments",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "23-ARR_v2_45",
            "content": "We performed experiments on the two proposed benchmarks (as well as the existing version of the SQUALL benchmark), using the two current state-of-the-art parser architectures presented in \u00a72 in combination with our proposed schema expansion and pruning components.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_46",
            "content": "Experimental Setup",
            "ntype": "title",
            "meta": {
                "section": "5.1"
            }
        },
        {
            "ix": "23-ARR_v2_47",
            "content": "As described in \u00a73, our synthetic benchmark consists of three domains, finance, sports and science. We repeat our experiments once for each domain. For each repetition we test on one of the domains, while training on the other two. For SQUALL, we present results on our repartitioned split from \u00a73.2. For both datasets, we also include results for three i.i.d. splits. In each experiment, we compare four different configurations for the parsers:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_48",
            "content": "1. Base: The underlying parser which can be either SEQ2SEQ or SMBOP. 2. Base + P: Base while also using schema pruning. 3. Base + E: Base while also using schema expansion. 4. Base + P + E: Base while also using both schema expansion and schema pruning.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_49",
            "content": "We repeat each experiment three times using different random seeds and report mean exact match accuracy (i.e., fraction of examples where the predicted SQL queries exactly match the gold queries), and standard error for this mean. Note that for SQUALL, researchers often also report execution accuracy, which measures the fraction of examples for which executing the predicted SQL queries results in the correct answer to the input question. However, we found that for 7% of the examples that are representative of out-of-domain generalization, executing the gold SQL queries does not yield the correct answer (e.g., in cases where the correct answer is a sub-string of a cell value). Therefore we chose to only report exact match accuracy in our experiments. Table 3: Mean accuracy and standard error for 3 experiment runs, computed over multiple different splits for each dataset. The best results in each row are shown in bold red font. Note that, when compared with the Base model, all gains statistically significant. + P stands for using the schema pruning model and + E for the schema expansion model.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_50",
            "content": "Results",
            "ntype": "title",
            "meta": {
                "section": "5.2"
            }
        },
        {
            "ix": "23-ARR_v2_51",
            "content": "Synthetic Benchmark Results. Our results for this benchmark are presented in the top part of Table 3. A first observation is that performance on the i.i.d. split for the baseline parsers is significantly better than on the domain-based splits. Interestingly, our expansion and pruning components still provide a significant boost over baseline performance in this setting (up to 43.7% absolute accuracy / 83.2% relative). However, the baseline parsers are practically unusable in the domain-based splits. In this case, our approach provides a very significant accuracy gain, rendering them useful (up to 55.0% absolute / 327.4% relative).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_52",
            "content": "SQUALL Benchmark Results. Our results for this benchmark are presented in the bottom part of Table 3. Similar to the synthetic benchmark, we observe that both parsers perform reasonably well on the i.i.d. split, but significantly underperform in our repartitioned benchmark. This is consistent with earlier observations by Suhr et al. (2020) and Lee et al. (2021). Furthermore, we observe that our expansion component helps boost the accuracy of both parsers significantly (up to 5.1% absolute / 13.8% relative) and the pruning component provides some small further improvements on top of that. However, we notice that the pruning component is not as helpful for SMBOP as it is for SEQ2SEQ, which we provide detailed analysis in \u00a75.4. Drilling down a bit further, we observe that most gains are due to the data categories we defined in \u00a73.2. Perhaps most importantly, we get a 47.0% absolute accuracy gain (1,468.8% relative) for SMBOP on the \"Date Expressions\" category alone. This can be largely attributed to our schema expansion component, where by incorporating prior domain knowledge we are effectively reducing the original column operations problem to a column matching problem, which is significantly easier. As a result, we get significant improvements on both \"Expression\" data categories. We do not observe the same for \"Accessor\" categories, which we address in the following section.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_53",
            "content": "When is Schema Expansion Helpful?",
            "ntype": "title",
            "meta": {
                "section": "5.3"
            }
        },
        {
            "ix": "23-ARR_v2_54",
            "content": "From Table 3, schema expansion does not seem to help much for \"Accessor\" expressions (i.e., Base + P performs as well as or slightly better than Base + E + P on those categories). In order to further understand the contribution of schema expansion, we conducted an ablation study where we compare the proposed Base + P + E with three more approaches: (1) E Expressions: the schema expansion component only uses \"Expression\" templates, (2) E Accessors: the schema expansion component only uses \"Accessor\" templates, (3) P Oracle: the schema pruning model is replaced with an oracle model that always only keeps the columns that are used in the gold SQL queries (so the parser only has to figure out how to use them, rather than also figuring out which ones to use). Note that (3) will be discussed in the following section. We present the results for this ablation study in Table 4. We observe that expanding \"Expressions\" but not \"Accessors\" boosts performance on the \"Expressions\" categories, and similarly for \"Accessors\". More importantly though we see that using either one alone performs worse than using both types of expansion, indicating that they both provide value and that they work well together.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_55",
            "content": "When is Schema Pruning Helpful?",
            "ntype": "title",
            "meta": {
                "section": "5.4"
            }
        },
        {
            "ix": "23-ARR_v2_56",
            "content": "It is evident from Table 3 that schema pruning is useful both on its own (i.e., Base + P), but also on top of schema expansion (i.e., Base + E + P). For SMBOP, we observe that Base + P is more or less on par with Base. Though this may seem inconsistent with the SEQ2SEQ results at first, it is not actually surprising because SMBOP keeps the most relevant columns in the beam during bottom-up decoding, and thus it is implicitly already using a schema pruning component. Furthermore, we observe that schema pruning is especially useful on top of schema expansion for the column operation data categories (\"Expressions\" and \"Accessors\"). This is because in the corresponding examples we end up with a significantly larger number of expanded columns that labeled as negatives when training the pruning model. Figure 4: Example that showcases some of the challenges that are not addressed by our approach, but which are accounted for in the evaluation benchmarks that we propose. In this case, the \"Score\" and \"Result\" columns have domain-specific semantics that are hard for the model to learn, and the question also depends on the title of the table, which current models do not take into account.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_57",
            "content": "Schema pruning then filters most of these irrelevant columns before training the underlying parser, resulting in a more robust training procedure. Finally, in Table 4 we observe that P Oracle performs really well, indicating that investing in a good schema pruning model would be meaningful for improving generalization performance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_58",
            "content": "Schema Pruning Decision Threshold. As discussed in \u00a74, the proposed schema pruning component requires setting a decision threshold hyperparameter. We already described the way we do this in \u00a74, but it is also worth analyzing the impact of this decision on the overall parser accuracy. This is because, intuitively we expect that too aggressive pruning will likely cause cascading errors, while too conservative pruning would not be very effective and end up being equivalent to not using any pruning at all. To this end, we conducted a study for how the parser accuracy varies as a function of the schema pruning model hyperparameter which was discussed in \u00a74. We performed this experiment using the SEQ2SEQ model which is more affected by the pruning component, over our repartitioned SQUALL benchmark.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_59",
            "content": "The results are shown in Figure 3. It is evident that aggressive pruning has a more significant negative impact on accuracy then conservative pruning.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_60",
            "content": "Limitations",
            "ntype": "title",
            "meta": {
                "section": "5.5"
            }
        },
        {
            "ix": "23-ARR_v2_61",
            "content": "The proposed method is of course not without any limitations and in this section we would like to put attention on some of them. While schema expansion does help significantly when tackling out-of-domain generalization on column operations, there are a lot of cases that it cannot directly handle as currently designed. For example, consider the question-table pair shown in Figure 4. In this case the original table contains a \"Score\" column and a \"Result\" column. The interpretation of these columns is very domain-specific and in this case, \"Score\" refers to the score in a game right before the player of that row scored a goal, while \"Result\" refers to the final score of the game. Our schema expansion component cannot help with resolving distinctions of this kind. Arguably, one might say this is a challenge inherently related to column matching, but putting details aside, our approach coupled with the proposed benchmarks does help show that column operations pose a significant challenge for existing text-to-SQL parsers, and this paper provides a reference point that future work can build upon. Also, note that while constructing expansion templates requires some effort and may initially seem like a limitation of our approach, we have shown that this effort can be small relative to the amount of training data that would need to be annotated otherwise.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_62",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "23-ARR_v2_63",
            "content": "In this paper, we introduced and focused on column operations, an important challenge related to out-ofdomain generalization for text-to-SQL parsing. We proposed two new evaluation benchmarks-one based on a new synthetic dataset and one based on a repartitioning of the SQUALL dataset-and showed that current stateof-the-art parsers significantly underperform when it comes to this form of generalization. We then proposed a simple way to incorporate prior domain knowledge to the parser via a new component called schema expansion that allows us to reduce the column operations challenge to column matching; an arguably easier challenge. We also introduced a schema pruning component allowing us to scale schema expansion, and showed that when paired together, these two components can boost the performance of existing text-to-SQL parsers by a significant amount (up to 13.8% relative accuracy gain / 5.1% absolute in our experiments). Through column expansion, we created a new table schema that is more friendly to downstream parsers. Our work uses heuristics based schema expansion and works well when limited to columns that have specified types (e.g., scores or timespans), but our synthetic experiments suggest much larger potential on this problem. We hope this work could motivate future research on creating a parserfriendly table ontology. Future work could explore learning approaches that use models to automatically expand any table schema, for example, by showing appropriate prompts to ask pre-trained language models to tackle it (Brown et al., 2020;Petroni et al., 2019).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "23-ARR_v2_64",
            "content": "UNKNOWN, None, 1995, Natural language interfaces to databases-an introduction, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": null,
                "title": null,
                "pub_date": "1995",
                "pub_title": "Natural language interfaces to databases-an introduction",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_65",
            "content": "Yoav Artzi, Luke Zettlemoyer, Weakly supervised learning of semantic parsers for mapping instructions to actions, 2013, Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Yoav Artzi",
                    "Luke Zettlemoyer"
                ],
                "title": "Weakly supervised learning of semantic parsers for mapping instructions to actions",
                "pub_date": "2013",
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_66",
            "content": "Jonathan Berant, Andrew Chou, Roy Frostig, Percy Liang, Semantic parsing on freebase from question-answer pairs, 2013, Proceedings of Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "Jonathan Berant",
                    "Andrew Chou",
                    "Roy Frostig",
                    "Percy Liang"
                ],
                "title": "Semantic parsing on freebase from question-answer pairs",
                "pub_date": "2013",
                "pub_title": "Proceedings of Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_67",
            "content": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Language models are few-shot learners, 2020, Proceedings of Advances in Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Tom Brown",
                    "Benjamin Mann",
                    "Nick Ryder",
                    "Melanie Subbiah",
                    "Jared Kaplan",
                    "Prafulla Dhariwal",
                    "Arvind Neelakantan",
                    "Pranav Shyam",
                    "Girish Sastry",
                    "Amanda Askell",
                    "Sandhini Agarwal",
                    "Ariel Herbert-Voss",
                    "Gretchen Krueger",
                    "Tom Henighan",
                    "Rewon Child",
                    "Aditya Ramesh",
                    "Daniel Ziegler",
                    "Jeffrey Wu",
                    "Clemens Winter",
                    "Chris Hesse",
                    "Mark Chen",
                    "Eric Sigler",
                    "Mateusz Litwin"
                ],
                "title": "Language models are few-shot learners",
                "pub_date": "2020",
                "pub_title": "Proceedings of Advances in Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_68",
            "content": "David Chen, Raymond Mooney, Learning to interpret natural language navigation instructions from observations, 2011, Proceedings of the Association for the Advancement of Artificial Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "David Chen",
                    "Raymond Mooney"
                ],
                "title": "Learning to interpret natural language navigation instructions from observations",
                "pub_date": "2011",
                "pub_title": "Proceedings of the Association for the Advancement of Artificial Intelligence",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_69",
            "content": "Wenhu Chen, Yu Su, Yilin Shen, Zhiyu Chen, Xifeng Yan, William Wang, How large a vocabulary does text classification need? a variational approach to vocabulary selection, 2019, Conference of the North American Chapter, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "Wenhu Chen",
                    "Yu Su",
                    "Yilin Shen",
                    "Zhiyu Chen",
                    "Xifeng Yan",
                    "William Wang"
                ],
                "title": "How large a vocabulary does text classification need? a variational approach to vocabulary selection",
                "pub_date": "2019",
                "pub_title": "Conference of the North American Chapter",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "23-ARR_v2_70",
            "content": "Hal Daum\u00e9, Iii , Jagadeesh Jagarlamudi, Domain adaptation for machine translation by mining unseen words, 2011, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "Hal Daum\u00e9",
                    "Iii ",
                    "Jagadeesh Jagarlamudi"
                ],
                "title": "Domain adaptation for machine translation by mining unseen words",
                "pub_date": "2011",
                "pub_title": "Proceedings of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_71",
            "content": "Hal Daum\u00e9, Iii , Daniel Marcu, Domain adaptation for statistical classifiers, 2006, Journal of artificial Intelligence research, .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Hal Daum\u00e9",
                    "Iii ",
                    "Daniel Marcu"
                ],
                "title": "Domain adaptation for statistical classifiers",
                "pub_date": "2006",
                "pub_title": "Journal of artificial Intelligence research",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_72",
            "content": "Xiang Deng, Ahmed Awadallah, Christopher Meek, Oleksandr Polozov, Huan Sun, Matthew Richardson, Structure-grounded pretraining for text-to-sql, 2021, Conference of the North American Chapter, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Xiang Deng",
                    "Ahmed Awadallah",
                    "Christopher Meek",
                    "Oleksandr Polozov",
                    "Huan Sun",
                    "Matthew Richardson"
                ],
                "title": "Structure-grounded pretraining for text-to-sql",
                "pub_date": "2021",
                "pub_title": "Conference of the North American Chapter",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "23-ARR_v2_73",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Conference of the North American Chapter of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Jacob Devlin",
                    "Ming-Wei Chang",
                    "Kenton Lee",
                    "Kristina Toutanova"
                ],
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "pub_date": "2019",
                "pub_title": "Conference of the North American Chapter of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_74",
            "content": "Catherine Finegan-Dollak, Jonathan Kummerfeld, Li Zhang, Karthik Ramanathan, Sesh Sadasivam, Rui Zhang, Dragomir Radev, Improving textto-SQL evaluation methodology, 2018, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Catherine Finegan-Dollak",
                    "Jonathan Kummerfeld",
                    "Li Zhang",
                    "Karthik Ramanathan",
                    "Sesh Sadasivam",
                    "Rui Zhang",
                    "Dragomir Radev"
                ],
                "title": "Improving textto-SQL evaluation methodology",
                "pub_date": "2018",
                "pub_title": "Proceedings of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_75",
            "content": "Yu Gu, Sue Kase, Michelle Vanni, Brian Sadler, Percy Liang, Xifeng Yan, Yu Su, Beyond iid: three levels of generalization for question answering on knowledge bases, 2021, Proceedings of the World Wide Web Conference, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Yu Gu",
                    "Sue Kase",
                    "Michelle Vanni",
                    "Brian Sadler",
                    "Percy Liang",
                    "Xifeng Yan",
                    "Yu Su"
                ],
                "title": "Beyond iid: three levels of generalization for question answering on knowledge bases",
                "pub_date": "2021",
                "pub_title": "Proceedings of the World Wide Web Conference",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_76",
            "content": "Jonathan Herzig, Krzysztof Nowak, Thomas Mueller, Francesco Piccinno, Julian Eisenschlos, Tapas: Weakly supervised table parsing via pre-training, 2020, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Jonathan Herzig",
                    "Krzysztof Nowak",
                    "Thomas Mueller",
                    "Francesco Piccinno",
                    "Julian Eisenschlos"
                ],
                "title": "Tapas: Weakly supervised table parsing via pre-training",
                "pub_date": "2020",
                "pub_title": "Proceedings of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_77",
            "content": "Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, Luke Zettlemoyer, Mapping language to code in programmatic context, 2018, Proceedings of Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    "Srinivasan Iyer",
                    "Ioannis Konstas",
                    "Alvin Cheung",
                    "Luke Zettlemoyer"
                ],
                "title": "Mapping language to code in programmatic context",
                "pub_date": "2018",
                "pub_title": "Proceedings of Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_78",
            "content": "Zhanming Jie, Wei Lu, Multilingual semantic parsing: Parsing multiple languages into semantic representations, 2014, Proceedings of International Conference on Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Zhanming Jie",
                    "Wei Lu"
                ],
                "title": "Multilingual semantic parsing: Parsing multiple languages into semantic representations",
                "pub_date": "2014",
                "pub_title": "Proceedings of International Conference on Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_79",
            "content": "Daniel Keysers, Nathanael Sch\u00e4rli, Nathan Scales, Hylke Buisman, Daniel Furrer, Sergii Kashubin, Nikola Momchev, Danila Sinopalnikov, Lukasz Stafiniak, Tibor Tihon, Measuring compositional generalization: A comprehensive method on realistic data, 2020, Proceedings of the International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Daniel Keysers",
                    "Nathanael Sch\u00e4rli",
                    "Nathan Scales",
                    "Hylke Buisman",
                    "Daniel Furrer",
                    "Sergii Kashubin",
                    "Nikola Momchev",
                    "Danila Sinopalnikov",
                    "Lukasz Stafiniak",
                    "Tibor Tihon"
                ],
                "title": "Measuring compositional generalization: A comprehensive method on realistic data",
                "pub_date": "2020",
                "pub_title": "Proceedings of the International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_80",
            "content": "Brenden Lake, Marco Baroni, Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks, 2018, Proceedings of the International Conference of Machine Learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "Brenden Lake",
                    "Marco Baroni"
                ],
                "title": "Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks",
                "pub_date": "2018",
                "pub_title": "Proceedings of the International Conference of Machine Learning",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_81",
            "content": "Chia-Hsuan Lee, Oleksandr Polozov, Matthew Richardson, KaggleDBQA: Realistic evaluation of text-to-SQL parsers, 2021, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Chia-Hsuan Lee",
                    "Oleksandr Polozov",
                    "Matthew Richardson"
                ],
                "title": "KaggleDBQA: Realistic evaluation of text-to-SQL parsers",
                "pub_date": "2021",
                "pub_title": "Proceedings of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_82",
            "content": "Michael Minock, Peter Olofsson, Alexander N\u00e4slund, Towards building robust natural language interfaces to databases, 2008, International Conference on Application of Natural Language to Information Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Michael Minock",
                    "Peter Olofsson",
                    "Alexander N\u00e4slund"
                ],
                "title": "Towards building robust natural language interfaces to databases",
                "pub_date": "2008",
                "pub_title": "International Conference on Application of Natural Language to Information Systems",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_83",
            "content": "Saeid Motiian, Quinn Jones, Seyed Iranmanesh, Gianfranco Doretto, Few-shot adversarial domain adaptation, 2017, Proceedings of Advances in Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "Saeid Motiian",
                    "Quinn Jones",
                    "Seyed Iranmanesh",
                    "Gianfranco Doretto"
                ],
                "title": "Few-shot adversarial domain adaptation",
                "pub_date": "2017",
                "pub_title": "Proceedings of Advances in Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_84",
            "content": "Yusuke Oda, Hiroyuki Fudaba, Graham Neubig, Hideaki Hata, Sakriani Sakti, Tomoki Toda, Satoshi Nakamura, Learning to generate pseudo-code from source code using statistical machine translation, 2015, International Conference on Automated Software Engineering, .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Yusuke Oda",
                    "Hiroyuki Fudaba",
                    "Graham Neubig",
                    "Hideaki Hata",
                    "Sakriani Sakti",
                    "Tomoki Toda",
                    "Satoshi Nakamura"
                ],
                "title": "Learning to generate pseudo-code from source code using statistical machine translation",
                "pub_date": "2015",
                "pub_title": "International Conference on Automated Software Engineering",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_85",
            "content": "Panupong Pasupat, Percy Liang, Compositional semantic parsing on semi-structured tables, 2015, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "Panupong Pasupat",
                    "Percy Liang"
                ],
                "title": "Compositional semantic parsing on semi-structured tables",
                "pub_date": "2015",
                "pub_title": "Proceedings of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_86",
            "content": "Fabio Petroni, Tim Rockt\u00e4schel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander Miller, Language models as knowledge bases?, 2019, Proceedings of Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Fabio Petroni",
                    "Tim Rockt\u00e4schel",
                    "Sebastian Riedel",
                    "Patrick Lewis",
                    "Anton Bakhtin",
                    "Yuxiang Wu",
                    "Alexander Miller"
                ],
                "title": "Language models as knowledge bases?",
                "pub_date": "2019",
                "pub_title": "Proceedings of Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_87",
            "content": "Ohad Rubin, Jonathan Berant, SmBoP: Semiautoregressive bottom-up semantic parsing, 2021, Conference of the North American Chapter of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Ohad Rubin",
                    "Jonathan Berant"
                ],
                "title": "SmBoP: Semiautoregressive bottom-up semantic parsing",
                "pub_date": "2021",
                "pub_title": "Conference of the North American Chapter of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_88",
            "content": "Peter Shaw, Ming-Wei Chang, Panupong Pasupat, Kristina Toutanova, Compositional generalization and natural language variation: Can a semantic parsing approach handle both?, 2021, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Peter Shaw",
                    "Ming-Wei Chang",
                    "Panupong Pasupat",
                    "Kristina Toutanova"
                ],
                "title": "Compositional generalization and natural language variation: Can a semantic parsing approach handle both?",
                "pub_date": "2021",
                "pub_title": "Proceedings of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_89",
            "content": "Tom Sherborne, Yumo Xu, Mirella Lapata, Bootstrapping a crosslingual semantic parser, 2020, Findings of the Association for Computational Linguistics: EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Tom Sherborne",
                    "Yumo Xu",
                    "Mirella Lapata"
                ],
                "title": "Bootstrapping a crosslingual semantic parser",
                "pub_date": "2020",
                "pub_title": "Findings of the Association for Computational Linguistics: EMNLP",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_90",
            "content": "Tianze Shi, Chen Zhao, Jordan Boyd-Graber, Hal Daum\u00e9, Iii , Lillian Lee, On the potential of lexico-logical alignments for semantic parsing to SQL queries, 2020, Findings of the Association for Computational Linguistics: EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": [
                    "Tianze Shi",
                    "Chen Zhao",
                    "Jordan Boyd-Graber",
                    "Hal Daum\u00e9",
                    "Iii ",
                    "Lillian Lee"
                ],
                "title": "On the potential of lexico-logical alignments for semantic parsing to SQL queries",
                "pub_date": "2020",
                "pub_title": "Findings of the Association for Computational Linguistics: EMNLP",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_91",
            "content": "Alane Suhr, Ming-Wei Chang, Peter Shaw, Kenton Lee, Exploring unexplored generalization challenges for cross-database semantic parsing, 2020, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": [
                    "Alane Suhr",
                    "Ming-Wei Chang",
                    "Peter Shaw",
                    "Kenton Lee"
                ],
                "title": "Exploring unexplored generalization challenges for cross-database semantic parsing",
                "pub_date": "2020",
                "pub_title": "Proceedings of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_92",
            "content": "Alon Talmor, Jonathan Berant, Multiqa: An empirical investigation of generalization and transfer in reading comprehension, 2019, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Alon Talmor",
                    "Jonathan Berant"
                ],
                "title": "Multiqa: An empirical investigation of generalization and transfer in reading comprehension",
                "pub_date": "2019",
                "pub_title": "Proceedings of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_93",
            "content": "Bailin Wang, Mirella Lapata, Ivan Titov, Meta-learning for domain generalization in semantic parsing, 2021, Conference of the North American Chapter of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "Bailin Wang",
                    "Mirella Lapata",
                    "Ivan Titov"
                ],
                "title": "Meta-learning for domain generalization in semantic parsing",
                "pub_date": "2021",
                "pub_title": "Conference of the North American Chapter of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_94",
            "content": "Bailin Wang, Richard Shin, Xiaodong Liu, Oleksandr Polozov, Matthew Richardson, Rat-sql: Relation-aware schema encoding and linking for textto-sql parsers, 2020, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": [
                    "Bailin Wang",
                    "Richard Shin",
                    "Xiaodong Liu",
                    "Oleksandr Polozov",
                    "Matthew Richardson"
                ],
                "title": "Rat-sql: Relation-aware schema encoding and linking for textto-sql parsers",
                "pub_date": "2020",
                "pub_title": "Proceedings of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_95",
            "content": "Jingjing Xu, Hao Zhou, Chun Gan, Zaixiang Zheng, Lei Li, Vocabulary learning via optimal transport for neural machine translation, 2021, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": [
                    "Jingjing Xu",
                    "Hao Zhou",
                    "Chun Gan",
                    "Zaixiang Zheng",
                    "Lei Li"
                ],
                "title": "Vocabulary learning via optimal transport for neural machine translation",
                "pub_date": "2021",
                "pub_title": "Proceedings of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_96",
            "content": "UNKNOWN, None, 2017, Sqlnet: Generating structured queries from natural language without reinforcement learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": "Sqlnet: Generating structured queries from natural language without reinforcement learning",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_97",
            "content": "Ming-Wei Wen-Tau Yih, Xiaodong Chang, Jianfeng He,  Gao, Semantic parsing via staged query graph generation: Question answering with knowledge base, 2015, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": [
                    "Ming-Wei Wen-Tau Yih",
                    "Xiaodong Chang",
                    "Jianfeng He",
                    " Gao"
                ],
                "title": "Semantic parsing via staged query graph generation: Question answering with knowledge base",
                "pub_date": "2015",
                "pub_title": "Proceedings of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_98",
            "content": "Pengcheng Yin, Graham Neubig, Sebastian Wen Tau Yih,  Riedel, TaBERT: Pretraining for joint understanding of textual and tabular data, 2020, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": [
                    "Pengcheng Yin",
                    "Graham Neubig",
                    "Sebastian Wen Tau Yih",
                    " Riedel"
                ],
                "title": "TaBERT: Pretraining for joint understanding of textual and tabular data",
                "pub_date": "2020",
                "pub_title": "Proceedings of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_99",
            "content": "UNKNOWN, None, 2021, On the ingredients of an effective zero-shot semantic parser, .",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "On the ingredients of an effective zero-shot semantic parser",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_100",
            "content": "Tao Yu, Chien-Sheng Wu, Xi Lin, Yi Chern Tan, Xinyi Yang, Dragomir Radev, Caiming Xiong, Grappa: Grammar-augmented pre-training for table semantic parsing, 2020, Proceedings of the International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "Tao Yu",
                    "Chien-Sheng Wu",
                    "Xi Lin",
                    "Yi Chern Tan",
                    "Xinyi Yang",
                    "Dragomir Radev",
                    "Caiming Xiong"
                ],
                "title": "Grappa: Grammar-augmented pre-training for table semantic parsing",
                "pub_date": "2020",
                "pub_title": "Proceedings of the International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_101",
            "content": "Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingning Yao, Shanelle Roman, Zilin Zhang, Dragomir Radev, Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-SQL task, 2018, Proceedings of Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": [
                    "Tao Yu",
                    "Rui Zhang",
                    "Kai Yang",
                    "Michihiro Yasunaga",
                    "Dongxu Wang",
                    "Zifan Li",
                    "James Ma",
                    "Irene Li",
                    "Qingning Yao",
                    "Shanelle Roman",
                    "Zilin Zhang",
                    "Dragomir Radev"
                ],
                "title": "Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-SQL task",
                "pub_date": "2018",
                "pub_title": "Proceedings of Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "23-ARR_v2_102",
            "content": "UNKNOWN, None, 2017, Seq2SQL: Generating structured queries from natural language using reinforcement learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": "Seq2SQL: Generating structured queries from natural language using reinforcement learning",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "23-ARR_v2_0@0",
            "content": "Bridging the Generalization Gap in Text-to-SQL Parsing with Schema Expansion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_0",
            "start": 0,
            "end": 75,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_2@0",
            "content": "Text-to-SQL parsers map natural language questions to programs that are executable over tables to generate answers, and are typically evaluated on large-scale datasets like SPIDER (Yu et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_2",
            "start": 0,
            "end": 197,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_2@1",
            "content": "We argue that existing benchmarks fail to capture a certain out-of-domain generalization problem that is of significant practical importance: matching domain specific phrases to composite operations over columns.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_2",
            "start": 199,
            "end": 410,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_3@0",
            "content": "To study this problem, we propose a synthetic dataset and a re-purposed train/test split of the SQUALL dataset (Shi et al., 2020) as new benchmarks to quantify domain generalization over column operations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_3",
            "start": 0,
            "end": 204,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_3@1",
            "content": "Our results indicate that existing state-of-the-art parsers struggle in these benchmarks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_3",
            "start": 206,
            "end": 294,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_3@2",
            "content": "We propose to address this problem by incorporating prior domain knowledge by preprocessing table schemas, and design a method that consists of two components: schema expansion and schema pruning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_3",
            "start": 296,
            "end": 491,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_3@3",
            "content": "This method can be easily applied to multiple existing base parsers, and we show that it significantly outperforms baseline parsers on this domain generalization problem, boosting the underlying parsers' overall performance by up to 13.8% relative accuracy gain (5.1% absolute) on the new SQUALL data split.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_3",
            "start": 493,
            "end": 799,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_4@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_4",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_5@0",
            "content": "Text-to-SQL parsing is the task of translating natural language questions over provided tables to SQL queries which can be executed to produce answers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_5",
            "start": 0,
            "end": 150,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_5@1",
            "content": "In recent years, with the availability of large-scale datasets (e.g., Zhong et al., 2017;Yu et al., 2018), neural semantic parsers have witnessed significant success on this task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_5",
            "start": 152,
            "end": 330,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_5@2",
            "content": "However, recent work (Suhr et al., 2020;Lee et al., 2021) has suggested that these state-of-the-art parsers are far from successful in terms of out-of-domain generalization in real scenarios, where users may ask questions related to potentially very large tables with the goal of improving their productivity (e.g., while they are viewing or editing a large Excel spreadsheet).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_5",
            "start": 332,
            "end": 708,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_6@0",
            "content": "Figure 1: Illustration of two aspects of out-of-domain generalization that are challenging for text-to-SQL parsers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_6",
            "start": 0,
            "end": 114,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_6@1",
            "content": "While existing methods partially address the \"column matching\" issue, they still suffer when it comes to \"column operations\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_6",
            "start": 116,
            "end": 240,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_6@2",
            "content": "Note that there are more tables on the right to illustrate the fact that there are a variety of settings the parser may run into at test time.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_6",
            "start": 242,
            "end": 383,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_7@0",
            "content": "In such scenarios, it is common to encounter tables specific to new domains that were not encountered while training a parser.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_7",
            "start": 0,
            "end": 125,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_7@1",
            "content": "Perhaps the most challenging aspect of domain generalization is that models need to understand domain-specific phrases that they have not seen before, and translate them into logical form segments that involve references to table elements (e.g., column names or aggregation operations over columns).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_7",
            "start": 127,
            "end": 425,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_7@2",
            "content": "We argue that two kinds of abstract operations, shown in Figure 1, are particularly challenging for new domains:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_7",
            "start": 427,
            "end": 538,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_8@0",
            "content": "1. Column Matching: The task of mapping natural language phrases to the most relevant columns (e.g., mapping \"Income\" to the \"Wages\" column).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_8",
            "start": 0,
            "end": 140,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_8@1",
            "content": "This can be challenging because some mappings may be implicit or may require domain knowledge.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_8",
            "start": 142,
            "end": 235,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_8@2",
            "content": "2. Column Operations: The task of mapping natural language phrases to composite expressions over table columns.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_8",
            "start": 237,
            "end": 347,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_8@3",
            "content": "For example, in Figure 1, we need to map income to just \"Wages\" for one table, and to \"Salary\" + \"Stock\" for another table.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_8",
            "start": 349,
            "end": 471,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_8@4",
            "content": "Similarly, consider the complex \"Term\" column in Figure 2, in which two subfields 1 and 2 represent the term start (e.g., 1926) and term end (e.g., 1927), respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_8",
            "start": 473,
            "end": 640,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_8@5",
            "content": "Some questions may ask about the term duration while others may ask about the term start.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_8",
            "start": 642,
            "end": 730,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_9@0",
            "content": "Figure 2: Illustration of the training pipeline for the proposed method and the inference process for an example.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_9",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_9@1",
            "content": "The proposed method is described in detail in \u00a74.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_9",
            "start": 114,
            "end": 162,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_9@2",
            "content": "Note that the proposed components interact with the parser by modifying the table that is fed to it as input, as well as the target program during training in the case of schema expansion.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_9",
            "start": 164,
            "end": 351,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_10@0",
            "content": "Each of these questions requires mapping the corresponding phrase to an expression that refers to this column (e.g., \"Term\". 2 -\"Term\". 1 for the former and \"Term\". 1 for the latter).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_10",
            "start": 0,
            "end": 182,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_11@0",
            "content": "While recent approaches rely on pre-trained language models (e.g., Yin et al., 2020;Deng et al., 2021) for addressing the column matching challenge, column operations remain relatively unexplored due to the lack of evaluation benchmarks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_11",
            "start": 0,
            "end": 236,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_12@0",
            "content": "To this end, we first propose two new benchmarks: a synthetic dataset and a train/test repartitioning of the SQUALL dataset (Shi et al., 2020); both capable of quantifying out-of-domain generalization on column operations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_12",
            "start": 0,
            "end": 221,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_12@1",
            "content": "We then show that existing neural parsers underperform on both benchmarks because they require an impractically large amount of in-domain training datawhich is not available in our setting-to effectively \"memorize\" mappings from natural language phrases to program fragments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_12",
            "start": 223,
            "end": 497,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_12@2",
            "content": "Finally, we propose a new method for making any existing text-to-SQL parsers aware of prior information that may be available about the domains of interest.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_12",
            "start": 499,
            "end": 654,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_12@3",
            "content": "Specifically, we propose two new components: schema expansion and schema pruning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_12",
            "start": 656,
            "end": 736,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_13@0",
            "content": "Schema expansion uses heuristics to expand columns into sets of derived columns based solely on their types (all schemas are assumed to be typed which tends to be true for both relational databases and Excel spreadsheets in practice; Excel uses a built-in type inference mechanism).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_13",
            "start": 0,
            "end": 281,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_13@1",
            "content": "Relying on generic types makes this method applicable to new domains, as long as they make use of similar underlying types.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_13",
            "start": 283,
            "end": 405,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_13@2",
            "content": "This process allows us to transform complex program fragments (e.g., \"Term\". 2 -\"Term\". 1) into simpler ones (e.g., \"Term Duration\") that are better aligned with the natural language questions, thus making the underlying parser's job easier.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_13",
            "start": 407,
            "end": 647,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_13@3",
            "content": "While schema expansion may result in a large number of unnecessary expanded columns, schema pruning then examines both the input question and the available columns (original and expanded) and prunes the set of columns that the final parser is exposed to.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_13",
            "start": 649,
            "end": 902,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_14@0",
            "content": "Our experiments show that schema expansion and schema pruning can boost the underlying parsers' performance by up to 13.8% relative accuracy (5.1% absolute) on the new SQUALL data split.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_14",
            "start": 0,
            "end": 185,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_14@1",
            "content": "Furthermore, they also boost performance over the original SQUALL data splits by up to 4.2% relative (1.9% absolute).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_14",
            "start": 187,
            "end": 303,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_14@2",
            "content": "One of our main goals in this paper is to put attention on the difficult problem of domain generalization by providing a new evaluation benchmark, as well as an initial direction for solving this problem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_14",
            "start": 305,
            "end": 508,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_14@3",
            "content": "Our evaluation benchmarks along with code for reproducing our experiments are available at https://aka.ms/ text-to-sql-schema-expansion-generalization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_14",
            "start": 510,
            "end": 660,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_15@0",
            "content": "Background",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_15",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_16@0",
            "content": "Task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_16",
            "start": 0,
            "end": 4,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_16@1",
            "content": "Semantic parsing has been widely studied in the context of multiple other tasks like instruction following (Chen and Mooney, 2011;Artzi and Zettlemoyer, 2013), code generation (Oda et al., 2015;Iyer et al., 2018), knowledge graph question answering (Berant et al., 2013;Yih et al., 2015), etc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_16",
            "start": 6,
            "end": 298,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_16@2",
            "content": "We focus on using tables as the context in which semantic parsing is performed, where the goal is to translate pairs of natural language questions and tables to executable SQL queries, also known as text-to-SQL parsing (Androutsopoulos et al., 1995;Minock et al., 2008).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_16",
            "start": 300,
            "end": 569,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_16@3",
            "content": "Note that, while we focus on questions in the English language, there exists prior work on multilingual semantic parsing as well (Jie and Lu, 2014;Sherborne et al., 2020) and the contributions of our work also apply there.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_16",
            "start": 571,
            "end": 792,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_16@4",
            "content": "Formally, our goal is to map a pair (q, T ), where q is a natural language question and T is a table, to an executable program \u03c0 that, when executed against table T , will produce the answer \u03b1 to question q. We focus on the fully-supervised setting where the target executable program \u03c0 * is provided as supervision for training our parser.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_16",
            "start": 794,
            "end": 1133,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_17@0",
            "content": "Out-of-Domain Generalization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_17",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_17@1",
            "content": "Generalization in machine learning is often defined as the ability to do well on a test set after learning from a training set, where all examples in both sets are drawn independently from the same distribution (i.i.d. generalization).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_17",
            "start": 30,
            "end": 264,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_17@2",
            "content": "However, as Gu et al. (2021) argue, in real-world applications such as semantic parsing, the test data may involve new compositional structures (compositional generalization), or new domains (domain generalization) that are not encountered during training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_17",
            "start": 266,
            "end": 521,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_17@3",
            "content": "Existing work in compositional generalization for semantic parsing has focused on using synthetic datasets (e.g., Keysers et al., 2020;Lake and Baroni, 2018), or repartitioning existing text-to-SQL datasets into new train and test splits (e.g., Finegan-Dollak et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_17",
            "start": 523,
            "end": 796,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_17@4",
            "content": "Both approaches have generally shown that compositional generalization remains an important challenge (e.g., Shaw et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_17",
            "start": 798,
            "end": 925,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_17@5",
            "content": "We focus on the arguably even more challenging domain generalization problem, also known as domain adaptation, where entire domains may never be encountered during training or may only be encountered a small number of times (Motiian et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_17",
            "start": 927,
            "end": 1173,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_17@6",
            "content": "Even though this problem has been studied extensively in the context of classification (Daum\u00e9 III and Marcu, 2006), machine translation (Daum\u00e9 III and Jagarlamudi, 2011), and question answering (Talmor and Berant, 2019), it remains underexplored for semantic parsing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_17",
            "start": 1175,
            "end": 1441,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_17@7",
            "content": "To be applicable in real scenarios, semantic parsers must be able to generalize to new domains since collecting domain-specific labeled data is often prohibitively expensive.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_17",
            "start": 1443,
            "end": 1616,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_17@8",
            "content": "Recent approaches have focused on data synthesis (Yin et al., 2021), meta-learning (Wang et al., 2021), relation-aware schema encoding (Wang et al., 2020), and encoder pretraining (Yin et al., 2020;Herzig et al., 2020;Yu et al., 2020;Deng et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_17",
            "start": 1618,
            "end": 1870,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_17@9",
            "content": "In this paper, we hone in on one aspect of domain generalization that we shall broadly refer to as column operations and which was introduced in \u00a71 and illustrated in Figure 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_17",
            "start": 1872,
            "end": 2047,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_18@0",
            "content": "Evaluation Benchmarks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_18",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_18@1",
            "content": "Text-to-SQL parsing became popular after the introduction of large-scale datasets and evaluation benchmarks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_18",
            "start": 23,
            "end": 130,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_18@2",
            "content": "Zhong et al. (2017) first introduced WIKISQL, which contains Wikipedia tables paired with questions and annotated with SQL queries, albeit the queries are generated from a limited set of templates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_18",
            "start": 132,
            "end": 328,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_18@3",
            "content": "SPIDER was introduced by Yu et al. (2018) the following year.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_18",
            "start": 330,
            "end": 390,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_18@4",
            "content": "It contains more complex questions and SQL queries and focuses on generalizing to previously unseen database schemas, but the dataset has the artifact from its annotation design that the references columns are often mentioned verbatim in the natural language questions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_18",
            "start": 392,
            "end": 660,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_18@5",
            "content": "Deng et al. (2021) attempt to address this limitation by repartitioning SPIDER to produce a more realistic benchmark, and Lee et al. (2021) propose a challenging test set from Kaggle for evaluating parsers trained on SPIDER dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_18",
            "start": 662,
            "end": 893,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_18@6",
            "content": "However, as Suhr et al. (2020) point out, SPIDER also uses a simplified setting which excludes examples that involve multiple columns (e.g., adding two columns together), as well as ones that require background knowledge.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_18",
            "start": 895,
            "end": 1115,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_18@7",
            "content": "These benchmarks are thus limited in their usefulness for evaluating parsers in real-world settings where they may encounter complex questions that require mapping specific phrases to expressions over table columns, rather than to a single column.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_18",
            "start": 1117,
            "end": 1363,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_18@8",
            "content": "Furthermore, while both WIKISQL and SPIDER assume \"simple\" tables with only String-or Number-valued columns, in practice we may encounter tables where the columns themselves may have structured types (e.g., TimeSpan).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_18",
            "start": 1365,
            "end": 1581,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_18@9",
            "content": "For example, consider the table shown on the top left of Figure 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_18",
            "start": 1583,
            "end": 1648,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_18@10",
            "content": "In this case, the \"Term\" column is of type TimeSpan and consists of two Numbers that represent the beginning and the end of the timespan.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_18",
            "start": 1650,
            "end": 1786,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_18@11",
            "content": "In this case, users may ask questions that require constructing expressions to access nested elements from the \"Term\" column (e.g., \"How long was Pier's term?\").",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_18",
            "start": 1788,
            "end": 1948,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_18@12",
            "content": "Recently, Shi et al. (2020) introduced SQUALL, a dataset that annotates WIKITABLEQUES-TIONS (Pasupat and Liang, 2015) with SQL queries and refined column types like Date, Score, (T1, T2), and List[T].",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_18",
            "start": 1950,
            "end": 2149,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_18@13",
            "content": "However, SQUALL distributes tables evenly between the train and test splits, thus not allowing us to evaluate the kind of out-of-domain generalization we are interested in.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_18",
            "start": 2151,
            "end": 2322,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_18@14",
            "content": "Therefore as we will show in the following section, we aim to address this limitation by repartitioning SQUALL into new train and test splits.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_18",
            "start": 2324,
            "end": 2465,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_18@15",
            "content": "Neural Text-to-SQL Parsers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_18",
            "start": 2467,
            "end": 2493,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_18@16",
            "content": "Neural encoder-decoder models have recently gained popularity for text-to-SQL parsing (e.g., Xu et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_18",
            "start": 2495,
            "end": 2604,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_18@17",
            "content": "We focus on two models that represent the current state-of-the-art for SQUALL and SPIDER, respectively: SEQ2SEQ of Shi et al. (2020) 1 and SMBOP of Rubin and Berant (2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_18",
            "start": 2606,
            "end": 2777,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_18@18",
            "content": "Both models concatenate the question with a textual representation of the table schema, separated by a special [SEP] token, and feed the combined sequence to a pre-trained instance of the BERT (Devlin et al., 2019) language model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_18",
            "start": 2779,
            "end": 3008,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_18@19",
            "content": "The activations of the last layer represent the encoded representations of the question and the table schema.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_18",
            "start": 3010,
            "end": 3118,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_18@20",
            "content": "SEQ2SEQ then uses a autoregressive decoder, which represents programs as token sequences and at each decoding step it: (1) predicts the next token type (i.e., whether the next token is a SQL keyword, a column name, or a literal value), and (2) predicts the token conditioned on its type.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_18",
            "start": 3120,
            "end": 3406,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_18@21",
            "content": "SMBOP, on the other hand, uses bottom-up decoding, which represents programs as abstract syntax trees and constructs these trees in a bottom-up fashion (i.e., it starts by predicting the leaf nodes and then recursively composes generated sub-trees into new trees and ranks them, in a way that resembles beam search), until it reaches the tree root.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_18",
            "start": 3408,
            "end": 3755,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_18@22",
            "content": "We refer the reader to the aforementioned papers for details.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_18",
            "start": 3757,
            "end": 3817,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_19@0",
            "content": "Proposed Evaluation Benchmarks",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_19",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_20@0",
            "content": "Our goal is to design an evaluation benchmark that has the following out-of-domain generalization properties: (i) the training data involves a different set of domains from the test data, (ii) the questions and tables that appear in the train and test data are non-overlapping, not only in terms of the domains they belong to, but also in terms of the program fragments that they contain, and (iii) to simulate the more challenging setting that is often encountered in real applications, the test data is biased to contain more examples that involve both nested column access operations, like getting the start of a \"Term\" in Figure 2, as well as composite column expressions, like getting the duration of a \"Term\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_20",
            "start": 0,
            "end": 714,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_20@1",
            "content": "To this end, we propose a new synthetic dataset and a repartitioning of the SQUALL dataset into new train/test splits.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_20",
            "start": 716,
            "end": 833,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_21@0",
            "content": "Synthetic Dataset",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_21",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_22@0",
            "content": "We consider three fictional domains inspired by common uses of tables: finance, sports, and science.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_22",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_22@1",
            "content": "We explain our synthetic dataset generation process through a running example as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_22",
            "start": 101,
            "end": 189,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_23@0",
            "content": "1. For each domain, we declare a set of formulas that relate different quantities (e.g., \"Income\" = \"Salary\" + \"Stock\").",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_23",
            "start": 0,
            "end": 119,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_23@1",
            "content": "The primitives used in these formulas define the set of available columns.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_23",
            "start": 121,
            "end": 194,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_23@2",
            "content": "2. For each column we declare a set of noun phrases that can be used to refer to it (e.g., \"wages\" for \"Income\" and \"base salary\" for \"salary\").",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_23",
            "start": 196,
            "end": 339,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_23@3",
            "content": "We also define a SQL query template that shall be used for all programs: SELECT <column> FROM t WHERE \"Year\" = <year>, and a question template What was <column> in <year>?",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_23",
            "start": 341,
            "end": 511,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_23@4",
            "content": "Note that the \"Year\" column is special and is included in all examples of this synthetic dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_23",
            "start": 513,
            "end": 609,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_23@5",
            "content": "3. We sample a formula and a variable from that formula (e.g., \"Income\" from formula \"Income\" = \"Salary\" + \"Stock\" ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_23",
            "start": 611,
            "end": 727,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_23@6",
            "content": "We then generate a question asking for this variable, randomly replacing the variable with a noun phrase in the corresponding set, and randomly generate a year value (e.g., use \"wages\" to replace \"income\" and generate a question \"What was [wages] in [2011]?\").",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_23",
            "start": 729,
            "end": 988,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_23@7",
            "content": "4. To generate the target program \u03c0 * , we randomly drop a variable from the sampled formula in step 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_23",
            "start": 990,
            "end": 1092,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_24@0",
            "content": "If the asked value corresponds to this variable, we transform its reference in the SQL query so that it is expressed as a function of the columns that are kept (e.g., \"Salary\" + \"Stock\"), otherwise we use the column name (e.g., \"Income\").",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_24",
            "start": 0,
            "end": 237,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_24@1",
            "content": "5. To generate a table schema we first add a \"Year\" column and two of the columns that were not sampled from the formula (e.g., \"Salary\" and \"Stock\").",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_24",
            "start": 239,
            "end": 388,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_24@2",
            "content": "We then sample k other columns and add them to schema (k = 15 in our experiments) as distractor columns.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_24",
            "start": 390,
            "end": 493,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_24@3",
            "content": "Note that we do not generate full tables for this synthetic dataset since we do not evaluate on table cell selections.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_24",
            "start": 495,
            "end": 612,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_25@0",
            "content": "We construct benchmark datasets by first generating 1,000 examples per domain and then iterating over the domains and keeping the data generated for the current domain as our test data, while using the data of the remaining two domains for training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_25",
            "start": 0,
            "end": 248,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_25@1",
            "content": "This results in three datasets, each with 2,000 train examples and 1,000 test examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_25",
            "start": 250,
            "end": 336,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_25@2",
            "content": "More details on the declarations for our domains can be found in Appendix A.1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_25",
            "start": 338,
            "end": 415,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_26@0",
            "content": "SQUALL Repartitioning",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_26",
            "start": 0,
            "end": 20,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_27@0",
            "content": "Aside from the synthetic dataset we also propose to repartition SQUALL into new train and test data splits, with a focus on the aforementioned out-of-domain generalization properties.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_27",
            "start": 0,
            "end": 182,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_27@1",
            "content": "The original splits for SQUALL were produced by uniformly sampling 20% of the tables to produce the test set and using the remaining 80% as the train set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_27",
            "start": 184,
            "end": 337,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_27@2",
            "content": "This process was repeated 5 times and the evaluation metric results were averaged over the results obtained for each repetition.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_27",
            "start": 339,
            "end": 466,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_27@3",
            "content": "adding all examples that use tables included in this cluster.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_27",
            "start": 468,
            "end": 528,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_27@4",
            "content": "This step will result in disproportionally more column operations being used in our test set than in our train set, which means that the model will need to learn to generalize well in this setting to do well in this dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_27",
            "start": 530,
            "end": 753,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_28@0",
            "content": "In the following sections we pay special attention to four data subcategories that are representative of the out-of-domain generalization setting for SQUALL:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_28",
            "start": 0,
            "end": 156,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_29@0",
            "content": "-Score Expressions: Represents SQL queries that include expressions over columns of type Score (e.g., a query selecting the score difference for a basketball game).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_29",
            "start": 0,
            "end": 163,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_29@1",
            "content": "-Score Accessors: Represents SQL queries that include field accessors for columns of type Score (e.g., a column with the results of a basketball game, like \"89-72\", and a query that requires accessing the first element of this score; i.e., \"89\").",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_29",
            "start": 165,
            "end": 410,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_29@2",
            "content": "-Date Expressions: Similar to Score expressions except using the Date and TimeSpan type (e.g., a query asking for the duration of a presidency term).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_29",
            "start": 412,
            "end": 560,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_29@3",
            "content": "-Date Accessors: Similar to Score Accessors, except using the Date and TimeSpan type (e.g., a query asking for the start of a term).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_29",
            "start": 562,
            "end": 693,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_30@0",
            "content": "We shall refer to these categories when reporting experimental results in \u00a75.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_30",
            "start": 0,
            "end": 76,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_30@1",
            "content": "We provide statistics for the resulting dataset in Table 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_30",
            "start": 78,
            "end": 136,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_31@0",
            "content": "Proposed Method",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_31",
            "start": 0,
            "end": 14,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_32@0",
            "content": "In this section we propose a simple approach for tackling this specific out-of-domain generalization problem that ought to serve as evidence that it is a real problem and that it is solvable, as well as a reference point for evaluating future approaches.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_32",
            "start": 0,
            "end": 253,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_32@1",
            "content": "Our approach consists of two new components that can be used in combination with any existing text-to-SQL parser: schema expansion and schema pruning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_32",
            "start": 255,
            "end": 404,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_32@2",
            "content": "These components interact with the parser by preprocessing the table that is fed to it as input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_32",
            "start": 406,
            "end": 501,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_32@3",
            "content": "This is illustrated in Figure 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_32",
            "start": 503,
            "end": 534,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_33@0",
            "content": "As discussed in \u00a71, there are two kinds of challenges related to out-of-domain generalization in text-to-SQL parsing, column matching and column operations, with the latter being more challenging.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_33",
            "start": 0,
            "end": 195,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_33@1",
            "content": "The goal of schema expansion is to reduce column operation challenges to column matching by adding synthetic columns to the table schema.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_33",
            "start": 197,
            "end": 333,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_33@2",
            "content": "These synthetic columns correspond to expressions or accessors over existing columns (e.g., a column that represents the sum of two columns).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_33",
            "start": 335,
            "end": 475,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_33@3",
            "content": "Rather than learning (or memorizing) the ways in which different types of columns can be composed together, we propose to inject prior knowledge as to what kind of symbolic operations are possible based solely on the column types in a schema.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_33",
            "start": 477,
            "end": 718,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_33@4",
            "content": "This reduces column operations to column matching by effectively bringing the target programs closer to their surface form in the natural language question.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_33",
            "start": 720,
            "end": 875,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_33@5",
            "content": "For example, \"Income\" can now map to a synthetic column that corresponds to the sum of \"Salary\" and \"Stock\" instead of having the parser produce the sum expression directly.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_33",
            "start": 877,
            "end": 1049,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_33@6",
            "content": "Since our expansion is based on column types, we argue that it is reasonable to assume that all schemas are typed and our expansion could be applied to any new domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_33",
            "start": 1051,
            "end": 1217,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_33@7",
            "content": "It is also worth noting that even though our templates may not cover all cases, 2 when applying our method to new domains, developers can declare a few templates of their interest and apply schema expansion on these templates to create parser-friendly schemas.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_33",
            "start": 1219,
            "end": 1478,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_33@8",
            "content": "This would be more cost-effective compared to collecting large in-domain training data for training the parser.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_33",
            "start": 1480,
            "end": 1590,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_34@0",
            "content": "Naturally, having a component that expands the table schema means that we may end up with large schemas that the parser has to deal with, which will often involve a lot of irrelevant columns (partially because the schema expansion component does not peek at the question).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_34",
            "start": 0,
            "end": 271,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_34@1",
            "content": "This can result in increased latency which is not desirable in real-world systems.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_34",
            "start": 273,
            "end": 354,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_34@2",
            "content": "To this end, we introduce a schema pruning component that looks at both the expanded table schema and the question and decides which columns to prune before invoking the parser.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_34",
            "start": 356,
            "end": 532,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_34@3",
            "content": "It can be argued that this pruning is as hard as parsing itself, but there is evidence from other areas that it can indeed be helpful (e.g., vocabulary selection; Chen et al., 2019;Xu et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_34",
            "start": 534,
            "end": 731,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_34@4",
            "content": "As we shall show schema pruning can actually provide an additional boost in accuracy, depending on architecture of the underlying parser.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_34",
            "start": 733,
            "end": 869,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_35@0",
            "content": "Schema Expansion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_35",
            "start": 0,
            "end": 15,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_36@0",
            "content": "A domain developer first declares a set of templates that specify the ways in which different column types can interact (e.g., it specifies that given a typed TimeSpan column that contains two subfields, 1 and 2, the expression TimeSpan. 2 -TimeSpan. 1 can be constructed that represents a duration), and the names for each such interaction (e.g., \"Duration\").",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_36",
            "start": 0,
            "end": 359,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_36@1",
            "content": "3 The schema expansion component receives as input this set of templates along with the table schema and returns an expanded schema that includes additional columns generated by using all applicable templates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_36",
            "start": 361,
            "end": 569,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_36@2",
            "content": "For our SQUALL experiments, we declared the templates shown in Table 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_36",
            "start": 571,
            "end": 641,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_36@3",
            "content": "Although these templates are somewhat tailored to this dataset, our main goal is to show that there is considerable room for improvement in this challenging generalization scenario, and that even a simple approach with minimal manual effort can result in significant gains.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_36",
            "start": 643,
            "end": 915,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_37@0",
            "content": "Schema Pruning",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_37",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_38@0",
            "content": "We propose a simple schema pruning approach that is inspired by vocabulary selection methods in machine translation. Let us denote the input question by q and the input column names after expansion by c 1 , . . . , c M .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_38",
            "start": 0,
            "end": 219,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_38@1",
            "content": "We concatenate the question and the column names as",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_38",
            "start": 221,
            "end": 271,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_39@0",
            "content": "[CLS] q [SEP] c1 [SEP] ... [SEP] cM [SEP]",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_39",
            "start": 0,
            "end": 40,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_40@0",
            "content": "and feed the resulting sequence to a BERT encoder (Devlin et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_40",
            "start": 0,
            "end": 71,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_40@1",
            "content": "We then define the embedding of each column, c i , as the final-layer representation of the last token of that column's name.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_40",
            "start": 73,
            "end": 197,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_40@2",
            "content": "Finally, we define the probability that a column should be kept as",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_40",
            "start": 199,
            "end": 264,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_41@0",
            "content": "p i = Softmax (MLP(c i ))",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_41",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_42@0",
            "content": ".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_42",
            "start": 0,
            "end": 0,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_42@1",
            "content": "We train this model based on whether each column is used in the corresponding SQL program.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_42",
            "start": 2,
            "end": 91,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_42@2",
            "content": "At inference time, we need to choose a threshold on the predicted probabilities for deciding whether to prune a column or not.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_42",
            "start": 93,
            "end": 218,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_42@3",
            "content": "We assume a transductive setting and choose this threshold such that the ratio of pruned columns over the test set equals to the ratio of pruned columns over the train set plus a constant hyperparameter to account for fact that accuracy will likely be lower for the test set than the train set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_42",
            "start": 220,
            "end": 513,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_42@4",
            "content": "Note that assuming a transductive setting is fine because in a realworld system we could be tuning this threshold based on the last t requests made to the model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_42",
            "start": 515,
            "end": 675,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_42@5",
            "content": "While this is not equivalent, assuming a large enough t, we should be able to adapt this threshold using the same approach.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_42",
            "start": 677,
            "end": 799,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_43@0",
            "content": "Negative Column Sampling.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_43",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_43@1",
            "content": "As is evident from Figure 2, we also introduce a negative column sampling component.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_43",
            "start": 26,
            "end": 109,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_43@2",
            "content": "This is because we train our pruning model on the same data that we use to train the underlying parser (aside from the modified table schemas) and thus the pruning model can become good at pruning all irrelevant columns over this dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_43",
            "start": 111,
            "end": 348,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_43@3",
            "content": "This will result in the underlying parser being unable to handle situations where irrelevant columns are mistakenly left unpruned by the pruning model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_43",
            "start": 350,
            "end": 500,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_43@4",
            "content": "To this end, during training we introduce some irrelevant columns to improve the robustness of the underlying parser.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_43",
            "start": 502,
            "end": 618,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_43@5",
            "content": "We found that making sure to always include at least 3 columns in the resulting schemas was sufficient and equivalent to randomly sampling 1 or 2 additional columns for each training example, and so that is what we did in our experiments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_43",
            "start": 620,
            "end": 857,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_44@0",
            "content": "Experiments",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_44",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_45@0",
            "content": "We performed experiments on the two proposed benchmarks (as well as the existing version of the SQUALL benchmark), using the two current state-of-the-art parser architectures presented in \u00a72 in combination with our proposed schema expansion and pruning components.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_45",
            "start": 0,
            "end": 263,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_46@0",
            "content": "Experimental Setup",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_46",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_47@0",
            "content": "As described in \u00a73, our synthetic benchmark consists of three domains, finance, sports and science.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_47",
            "start": 0,
            "end": 98,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_47@1",
            "content": "We repeat our experiments once for each domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_47",
            "start": 100,
            "end": 146,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_47@2",
            "content": "For each repetition we test on one of the domains, while training on the other two.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_47",
            "start": 148,
            "end": 230,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_47@3",
            "content": "For SQUALL, we present results on our repartitioned split from \u00a73.2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_47",
            "start": 232,
            "end": 299,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_47@4",
            "content": "For both datasets, we also include results for three i.i.d. splits.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_47",
            "start": 301,
            "end": 367,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_47@5",
            "content": "In each experiment, we compare four different configurations for the parsers:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_47",
            "start": 369,
            "end": 445,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_48@0",
            "content": "1. Base: The underlying parser which can be either SEQ2SEQ or SMBOP.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_48",
            "start": 0,
            "end": 67,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_48@1",
            "content": "2. Base + P: Base while also using schema pruning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_48",
            "start": 69,
            "end": 118,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_48@2",
            "content": "3. Base + E: Base while also using schema expansion.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_48",
            "start": 120,
            "end": 171,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_48@3",
            "content": "4. Base + P + E: Base while also using both schema expansion and schema pruning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_48",
            "start": 173,
            "end": 252,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_49@0",
            "content": "We repeat each experiment three times using different random seeds and report mean exact match accuracy (i.e., fraction of examples where the predicted SQL queries exactly match the gold queries), and standard error for this mean.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_49",
            "start": 0,
            "end": 229,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_49@1",
            "content": "Note that for SQUALL, researchers often also report execution accuracy, which measures the fraction of examples for which executing the predicted SQL queries results in the correct answer to the input question.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_49",
            "start": 231,
            "end": 440,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_49@2",
            "content": "However, we found that for 7% of the examples that are representative of out-of-domain generalization, executing the gold SQL queries does not yield the correct answer (e.g., in cases where the correct answer is a sub-string of a cell value).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_49",
            "start": 442,
            "end": 683,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_49@3",
            "content": "Therefore we chose to only report exact match accuracy in our experiments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_49",
            "start": 685,
            "end": 758,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_49@4",
            "content": "Table 3: Mean accuracy and standard error for 3 experiment runs, computed over multiple different splits for each dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_49",
            "start": 760,
            "end": 881,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_49@5",
            "content": "The best results in each row are shown in bold red font.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_49",
            "start": 883,
            "end": 938,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_49@6",
            "content": "Note that, when compared with the Base model, all gains statistically significant.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_49",
            "start": 940,
            "end": 1021,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_49@7",
            "content": "+ P stands for using the schema pruning model and + E for the schema expansion model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_49",
            "start": 1023,
            "end": 1107,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_50@0",
            "content": "Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_50",
            "start": 0,
            "end": 6,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_51@0",
            "content": "Synthetic Benchmark Results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_51",
            "start": 0,
            "end": 27,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_51@1",
            "content": "Our results for this benchmark are presented in the top part of Table 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_51",
            "start": 29,
            "end": 100,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_51@2",
            "content": "A first observation is that performance on the i.i.d. split for the baseline parsers is significantly better than on the domain-based splits.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_51",
            "start": 102,
            "end": 242,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_51@3",
            "content": "Interestingly, our expansion and pruning components still provide a significant boost over baseline performance in this setting (up to 43.7% absolute accuracy / 83.2% relative).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_51",
            "start": 244,
            "end": 420,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_51@4",
            "content": "However, the baseline parsers are practically unusable in the domain-based splits.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_51",
            "start": 422,
            "end": 503,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_51@5",
            "content": "In this case, our approach provides a very significant accuracy gain, rendering them useful (up to 55.0% absolute / 327.4% relative).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_51",
            "start": 505,
            "end": 637,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_52@0",
            "content": "SQUALL Benchmark Results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_52",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_52@1",
            "content": "Our results for this benchmark are presented in the bottom part of Table 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_52",
            "start": 26,
            "end": 100,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_52@2",
            "content": "Similar to the synthetic benchmark, we observe that both parsers perform reasonably well on the i.i.d. split, but significantly underperform in our repartitioned benchmark.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_52",
            "start": 102,
            "end": 273,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_52@3",
            "content": "This is consistent with earlier observations by Suhr et al. (2020) and Lee et al. (2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_52",
            "start": 275,
            "end": 363,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_52@4",
            "content": "Furthermore, we observe that our expansion component helps boost the accuracy of both parsers significantly (up to 5.1% absolute / 13.8% relative) and the pruning component provides some small further improvements on top of that.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_52",
            "start": 365,
            "end": 593,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_52@5",
            "content": "However, we notice that the pruning component is not as helpful for SMBOP as it is for SEQ2SEQ, which we provide detailed analysis in \u00a75.4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_52",
            "start": 595,
            "end": 733,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_52@6",
            "content": "Drilling down a bit further, we observe that most gains are due to the data categories we defined in \u00a73.2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_52",
            "start": 735,
            "end": 840,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_52@7",
            "content": "Perhaps most importantly, we get a 47.0% absolute accuracy gain (1,468.8% relative) for SMBOP on the \"Date Expressions\" category alone.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_52",
            "start": 842,
            "end": 976,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_52@8",
            "content": "This can be largely attributed to our schema expansion component, where by incorporating prior domain knowledge we are effectively reducing the original column operations problem to a column matching problem, which is significantly easier.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_52",
            "start": 978,
            "end": 1216,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_52@9",
            "content": "As a result, we get significant improvements on both \"Expression\" data categories.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_52",
            "start": 1218,
            "end": 1299,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_52@10",
            "content": "We do not observe the same for \"Accessor\" categories, which we address in the following section.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_52",
            "start": 1301,
            "end": 1396,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_53@0",
            "content": "When is Schema Expansion Helpful?",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_53",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_54@0",
            "content": "From Table 3, schema expansion does not seem to help much for \"Accessor\" expressions (i.e., Base + P performs as well as or slightly better than Base + E + P on those categories).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_54",
            "start": 0,
            "end": 178,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_54@1",
            "content": "In order to further understand the contribution of schema expansion, we conducted an ablation study where we compare the proposed Base + P + E with three more approaches: (1) E Expressions: the schema expansion component only uses \"Expression\" templates, (2) E Accessors: the schema expansion component only uses \"Accessor\" templates, (3) P Oracle: the schema pruning model is replaced with an oracle model that always only keeps the columns that are used in the gold SQL queries (so the parser only has to figure out how to use them, rather than also figuring out which ones to use).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_54",
            "start": 180,
            "end": 763,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_54@2",
            "content": "Note that (3) will be discussed in the following section.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_54",
            "start": 765,
            "end": 821,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_54@3",
            "content": "We present the results for this ablation study in Table 4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_54",
            "start": 823,
            "end": 880,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_54@4",
            "content": "We observe that expanding \"Expressions\" but not \"Accessors\" boosts performance on the \"Expressions\" categories, and similarly for \"Accessors\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_54",
            "start": 882,
            "end": 1023,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_54@5",
            "content": "More importantly though we see that using either one alone performs worse than using both types of expansion, indicating that they both provide value and that they work well together.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_54",
            "start": 1025,
            "end": 1207,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_55@0",
            "content": "When is Schema Pruning Helpful?",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_55",
            "start": 0,
            "end": 30,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_56@0",
            "content": "It is evident from Table 3 that schema pruning is useful both on its own (i.e., Base + P), but also on top of schema expansion (i.e., Base + E + P).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_56",
            "start": 0,
            "end": 147,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_56@1",
            "content": "For SMBOP, we observe that Base + P is more or less on par with Base.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_56",
            "start": 149,
            "end": 217,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_56@2",
            "content": "Though this may seem inconsistent with the SEQ2SEQ results at first, it is not actually surprising because SMBOP keeps the most relevant columns in the beam during bottom-up decoding, and thus it is implicitly already using a schema pruning component.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_56",
            "start": 219,
            "end": 469,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_56@3",
            "content": "Furthermore, we observe that schema pruning is especially useful on top of schema expansion for the column operation data categories (\"Expressions\" and \"Accessors\").",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_56",
            "start": 471,
            "end": 635,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_56@4",
            "content": "This is because in the corresponding examples we end up with a significantly larger number of expanded columns that labeled as negatives when training the pruning model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_56",
            "start": 637,
            "end": 805,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_56@5",
            "content": "Figure 4: Example that showcases some of the challenges that are not addressed by our approach, but which are accounted for in the evaluation benchmarks that we propose.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_56",
            "start": 807,
            "end": 975,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_56@6",
            "content": "In this case, the \"Score\" and \"Result\" columns have domain-specific semantics that are hard for the model to learn, and the question also depends on the title of the table, which current models do not take into account.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_56",
            "start": 977,
            "end": 1195,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_57@0",
            "content": "Schema pruning then filters most of these irrelevant columns before training the underlying parser, resulting in a more robust training procedure.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_57",
            "start": 0,
            "end": 145,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_57@1",
            "content": "Finally, in Table 4 we observe that P Oracle performs really well, indicating that investing in a good schema pruning model would be meaningful for improving generalization performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_57",
            "start": 147,
            "end": 331,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_58@0",
            "content": "Schema Pruning Decision Threshold.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_58",
            "start": 0,
            "end": 33,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_58@1",
            "content": "As discussed in \u00a74, the proposed schema pruning component requires setting a decision threshold hyperparameter.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_58",
            "start": 35,
            "end": 145,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_58@2",
            "content": "We already described the way we do this in \u00a74, but it is also worth analyzing the impact of this decision on the overall parser accuracy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_58",
            "start": 147,
            "end": 283,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_58@3",
            "content": "This is because, intuitively we expect that too aggressive pruning will likely cause cascading errors, while too conservative pruning would not be very effective and end up being equivalent to not using any pruning at all.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_58",
            "start": 285,
            "end": 506,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_58@4",
            "content": "To this end, we conducted a study for how the parser accuracy varies as a function of the schema pruning model hyperparameter which was discussed in \u00a74.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_58",
            "start": 508,
            "end": 659,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_58@5",
            "content": "We performed this experiment using the SEQ2SEQ model which is more affected by the pruning component, over our repartitioned SQUALL benchmark.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_58",
            "start": 661,
            "end": 802,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_59@0",
            "content": "The results are shown in Figure 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_59",
            "start": 0,
            "end": 33,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_59@1",
            "content": "It is evident that aggressive pruning has a more significant negative impact on accuracy then conservative pruning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_59",
            "start": 35,
            "end": 149,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_60@0",
            "content": "Limitations",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_60",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_61@0",
            "content": "The proposed method is of course not without any limitations and in this section we would like to put attention on some of them.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_61",
            "start": 0,
            "end": 127,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_61@1",
            "content": "While schema expansion does help significantly when tackling out-of-domain generalization on column operations, there are a lot of cases that it cannot directly handle as currently designed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_61",
            "start": 129,
            "end": 318,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_61@2",
            "content": "For example, consider the question-table pair shown in Figure 4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_61",
            "start": 320,
            "end": 383,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_61@3",
            "content": "In this case the original table contains a \"Score\" column and a \"Result\" column.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_61",
            "start": 385,
            "end": 464,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_61@4",
            "content": "The interpretation of these columns is very domain-specific and in this case, \"Score\" refers to the score in a game right before the player of that row scored a goal, while \"Result\" refers to the final score of the game.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_61",
            "start": 466,
            "end": 685,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_61@5",
            "content": "Our schema expansion component cannot help with resolving distinctions of this kind.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_61",
            "start": 687,
            "end": 770,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_61@6",
            "content": "Arguably, one might say this is a challenge inherently related to column matching, but putting details aside, our approach coupled with the proposed benchmarks does help show that column operations pose a significant challenge for existing text-to-SQL parsers, and this paper provides a reference point that future work can build upon.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_61",
            "start": 772,
            "end": 1106,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_61@7",
            "content": "Also, note that while constructing expansion templates requires some effort and may initially seem like a limitation of our approach, we have shown that this effort can be small relative to the amount of training data that would need to be annotated otherwise.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_61",
            "start": 1108,
            "end": 1367,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_62@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_62",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_63@0",
            "content": "In this paper, we introduced and focused on column operations, an important challenge related to out-ofdomain generalization for text-to-SQL parsing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_63",
            "start": 0,
            "end": 148,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_63@1",
            "content": "We proposed two new evaluation benchmarks-one based on a new synthetic dataset and one based on a repartitioning of the SQUALL dataset-and showed that current stateof-the-art parsers significantly underperform when it comes to this form of generalization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_63",
            "start": 150,
            "end": 404,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_63@2",
            "content": "We then proposed a simple way to incorporate prior domain knowledge to the parser via a new component called schema expansion that allows us to reduce the column operations challenge to column matching; an arguably easier challenge.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_63",
            "start": 406,
            "end": 637,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_63@3",
            "content": "We also introduced a schema pruning component allowing us to scale schema expansion, and showed that when paired together, these two components can boost the performance of existing text-to-SQL parsers by a significant amount (up to 13.8% relative accuracy gain / 5.1% absolute in our experiments).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_63",
            "start": 639,
            "end": 936,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_63@4",
            "content": "Through column expansion, we created a new table schema that is more friendly to downstream parsers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_63",
            "start": 938,
            "end": 1037,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_63@5",
            "content": "Our work uses heuristics based schema expansion and works well when limited to columns that have specified types (e.g., scores or timespans), but our synthetic experiments suggest much larger potential on this problem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_63",
            "start": 1039,
            "end": 1256,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_63@6",
            "content": "We hope this work could motivate future research on creating a parserfriendly table ontology.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_63",
            "start": 1258,
            "end": 1350,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_63@7",
            "content": "Future work could explore learning approaches that use models to automatically expand any table schema, for example, by showing appropriate prompts to ask pre-trained language models to tackle it (Brown et al., 2020;Petroni et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_63",
            "start": 1352,
            "end": 1589,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_64@0",
            "content": "UNKNOWN, None, 1995, Natural language interfaces to databases-an introduction, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_64",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_65@0",
            "content": "Yoav Artzi, Luke Zettlemoyer, Weakly supervised learning of semantic parsers for mapping instructions to actions, 2013, Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_65",
            "start": 0,
            "end": 183,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_66@0",
            "content": "Jonathan Berant, Andrew Chou, Roy Frostig, Percy Liang, Semantic parsing on freebase from question-answer pairs, 2013, Proceedings of Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_66",
            "start": 0,
            "end": 184,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_67@0",
            "content": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Language models are few-shot learners, 2020, Proceedings of Advances in Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_67",
            "start": 0,
            "end": 458,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_68@0",
            "content": "David Chen, Raymond Mooney, Learning to interpret natural language navigation instructions from observations, 2011, Proceedings of the Association for the Advancement of Artificial Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_68",
            "start": 0,
            "end": 195,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_69@0",
            "content": "Wenhu Chen, Yu Su, Yilin Shen, Zhiyu Chen, Xifeng Yan, William Wang, How large a vocabulary does text classification need? a variational approach to vocabulary selection, 2019, Conference of the North American Chapter, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_69",
            "start": 0,
            "end": 260,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_70@0",
            "content": "Hal Daum\u00e9, Iii , Jagadeesh Jagarlamudi, Domain adaptation for machine translation by mining unseen words, 2011, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_70",
            "start": 0,
            "end": 174,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_71@0",
            "content": "Hal Daum\u00e9, Iii , Daniel Marcu, Domain adaptation for statistical classifiers, 2006, Journal of artificial Intelligence research, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_71",
            "start": 0,
            "end": 129,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_72@0",
            "content": "Xiang Deng, Ahmed Awadallah, Christopher Meek, Oleksandr Polozov, Huan Sun, Matthew Richardson, Structure-grounded pretraining for text-to-sql, 2021, Conference of the North American Chapter, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_72",
            "start": 0,
            "end": 233,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_73@0",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Conference of the North American Chapter of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_73",
            "start": 0,
            "end": 241,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_74@0",
            "content": "Catherine Finegan-Dollak, Jonathan Kummerfeld, Li Zhang, Karthik Ramanathan, Sesh Sadasivam, Rui Zhang, Dragomir Radev, Improving textto-SQL evaluation methodology, 2018, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_74",
            "start": 0,
            "end": 233,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_75@0",
            "content": "Yu Gu, Sue Kase, Michelle Vanni, Brian Sadler, Percy Liang, Xifeng Yan, Yu Su, Beyond iid: three levels of generalization for question answering on knowledge bases, 2021, Proceedings of the World Wide Web Conference, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_75",
            "start": 0,
            "end": 217,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_76@0",
            "content": "Jonathan Herzig, Krzysztof Nowak, Thomas Mueller, Francesco Piccinno, Julian Eisenschlos, Tapas: Weakly supervised table parsing via pre-training, 2020, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_76",
            "start": 0,
            "end": 215,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_77@0",
            "content": "Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, Luke Zettlemoyer, Mapping language to code in programmatic context, 2018, Proceedings of Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_77",
            "start": 0,
            "end": 187,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_78@0",
            "content": "Zhanming Jie, Wei Lu, Multilingual semantic parsing: Parsing multiple languages into semantic representations, 2014, Proceedings of International Conference on Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_78",
            "start": 0,
            "end": 187,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_79@0",
            "content": "Daniel Keysers, Nathanael Sch\u00e4rli, Nathan Scales, Hylke Buisman, Daniel Furrer, Sergii Kashubin, Nikola Momchev, Danila Sinopalnikov, Lukasz Stafiniak, Tibor Tihon, Measuring compositional generalization: A comprehensive method on realistic data, 2020, Proceedings of the International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_79",
            "start": 0,
            "end": 326,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_80@0",
            "content": "Brenden Lake, Marco Baroni, Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks, 2018, Proceedings of the International Conference of Machine Learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_80",
            "start": 0,
            "end": 209,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_81@0",
            "content": "Chia-Hsuan Lee, Oleksandr Polozov, Matthew Richardson, KaggleDBQA: Realistic evaluation of text-to-SQL parsers, 2021, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_81",
            "start": 0,
            "end": 180,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_82@0",
            "content": "Michael Minock, Peter Olofsson, Alexander N\u00e4slund, Towards building robust natural language interfaces to databases, 2008, International Conference on Application of Natural Language to Information Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_82",
            "start": 0,
            "end": 207,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_83@0",
            "content": "Saeid Motiian, Quinn Jones, Seyed Iranmanesh, Gianfranco Doretto, Few-shot adversarial domain adaptation, 2017, Proceedings of Advances in Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_83",
            "start": 0,
            "end": 178,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_84@0",
            "content": "Yusuke Oda, Hiroyuki Fudaba, Graham Neubig, Hideaki Hata, Sakriani Sakti, Tomoki Toda, Satoshi Nakamura, Learning to generate pseudo-code from source code using statistical machine translation, 2015, International Conference on Automated Software Engineering, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_84",
            "start": 0,
            "end": 260,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_85@0",
            "content": "Panupong Pasupat, Percy Liang, Compositional semantic parsing on semi-structured tables, 2015, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_85",
            "start": 0,
            "end": 157,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_86@0",
            "content": "Fabio Petroni, Tim Rockt\u00e4schel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander Miller, Language models as knowledge bases?, 2019, Proceedings of Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_86",
            "start": 0,
            "end": 218,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_87@0",
            "content": "Ohad Rubin, Jonathan Berant, SmBoP: Semiautoregressive bottom-up semantic parsing, 2021, Conference of the North American Chapter of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_87",
            "start": 0,
            "end": 180,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_88@0",
            "content": "Peter Shaw, Ming-Wei Chang, Panupong Pasupat, Kristina Toutanova, Compositional generalization and natural language variation: Can a semantic parsing approach handle both?, 2021, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_88",
            "start": 0,
            "end": 241,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_89@0",
            "content": "Tom Sherborne, Yumo Xu, Mirella Lapata, Bootstrapping a crosslingual semantic parser, 2020, Findings of the Association for Computational Linguistics: EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_89",
            "start": 0,
            "end": 158,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_90@0",
            "content": "Tianze Shi, Chen Zhao, Jordan Boyd-Graber, Hal Daum\u00e9, Iii , Lillian Lee, On the potential of lexico-logical alignments for semantic parsing to SQL queries, 2020, Findings of the Association for Computational Linguistics: EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_90",
            "start": 0,
            "end": 228,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_91@0",
            "content": "Alane Suhr, Ming-Wei Chang, Peter Shaw, Kenton Lee, Exploring unexplored generalization challenges for cross-database semantic parsing, 2020, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_91",
            "start": 0,
            "end": 204,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_92@0",
            "content": "Alon Talmor, Jonathan Berant, Multiqa: An empirical investigation of generalization and transfer in reading comprehension, 2019, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_92",
            "start": 0,
            "end": 191,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_93@0",
            "content": "Bailin Wang, Mirella Lapata, Ivan Titov, Meta-learning for domain generalization in semantic parsing, 2021, Conference of the North American Chapter of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_93",
            "start": 0,
            "end": 199,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_94@0",
            "content": "Bailin Wang, Richard Shin, Xiaodong Liu, Oleksandr Polozov, Matthew Richardson, Rat-sql: Relation-aware schema encoding and linking for textto-sql parsers, 2020, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_94",
            "start": 0,
            "end": 224,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_95@0",
            "content": "Jingjing Xu, Hao Zhou, Chun Gan, Zaixiang Zheng, Lei Li, Vocabulary learning via optimal transport for neural machine translation, 2021, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_95",
            "start": 0,
            "end": 199,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_96@0",
            "content": "UNKNOWN, None, 2017, Sqlnet: Generating structured queries from natural language without reinforcement learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_96",
            "start": 0,
            "end": 113,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_97@0",
            "content": "Ming-Wei Wen-Tau Yih, Xiaodong Chang, Jianfeng He,  Gao, Semantic parsing via staged query graph generation: Question answering with knowledge base, 2015, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_97",
            "start": 0,
            "end": 217,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_98@0",
            "content": "Pengcheng Yin, Graham Neubig, Sebastian Wen Tau Yih,  Riedel, TaBERT: Pretraining for joint understanding of textual and tabular data, 2020, Proceedings of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_98",
            "start": 0,
            "end": 203,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_99@0",
            "content": "UNKNOWN, None, 2021, On the ingredients of an effective zero-shot semantic parser, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_99",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_100@0",
            "content": "Tao Yu, Chien-Sheng Wu, Xi Lin, Yi Chern Tan, Xinyi Yang, Dragomir Radev, Caiming Xiong, Grappa: Grammar-augmented pre-training for table semantic parsing, 2020, Proceedings of the International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_100",
            "start": 0,
            "end": 235,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_101@0",
            "content": "Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingning Yao, Shanelle Roman, Zilin Zhang, Dragomir Radev, Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-SQL task, 2018, Proceedings of Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_101",
            "start": 0,
            "end": 334,
            "label": {}
        },
        {
            "ix": "23-ARR_v2_102@0",
            "content": "UNKNOWN, None, 2017, Seq2SQL: Generating structured queries from natural language using reinforcement learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "23-ARR_v2_102",
            "start": 0,
            "end": 112,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "23-ARR_v2_0",
            "tgt_ix": "23-ARR_v2_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_0",
            "tgt_ix": "23-ARR_v2_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_1",
            "tgt_ix": "23-ARR_v2_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_1",
            "tgt_ix": "23-ARR_v2_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_1",
            "tgt_ix": "23-ARR_v2_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_2",
            "tgt_ix": "23-ARR_v2_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_0",
            "tgt_ix": "23-ARR_v2_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_3",
            "tgt_ix": "23-ARR_v2_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_5",
            "tgt_ix": "23-ARR_v2_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_6",
            "tgt_ix": "23-ARR_v2_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_7",
            "tgt_ix": "23-ARR_v2_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_8",
            "tgt_ix": "23-ARR_v2_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_9",
            "tgt_ix": "23-ARR_v2_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_10",
            "tgt_ix": "23-ARR_v2_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_11",
            "tgt_ix": "23-ARR_v2_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_12",
            "tgt_ix": "23-ARR_v2_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_13",
            "tgt_ix": "23-ARR_v2_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_4",
            "tgt_ix": "23-ARR_v2_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_4",
            "tgt_ix": "23-ARR_v2_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_4",
            "tgt_ix": "23-ARR_v2_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_4",
            "tgt_ix": "23-ARR_v2_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_4",
            "tgt_ix": "23-ARR_v2_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_4",
            "tgt_ix": "23-ARR_v2_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_4",
            "tgt_ix": "23-ARR_v2_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_4",
            "tgt_ix": "23-ARR_v2_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_4",
            "tgt_ix": "23-ARR_v2_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_4",
            "tgt_ix": "23-ARR_v2_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_4",
            "tgt_ix": "23-ARR_v2_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_0",
            "tgt_ix": "23-ARR_v2_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_14",
            "tgt_ix": "23-ARR_v2_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_16",
            "tgt_ix": "23-ARR_v2_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_17",
            "tgt_ix": "23-ARR_v2_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_15",
            "tgt_ix": "23-ARR_v2_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_15",
            "tgt_ix": "23-ARR_v2_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_15",
            "tgt_ix": "23-ARR_v2_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_15",
            "tgt_ix": "23-ARR_v2_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_0",
            "tgt_ix": "23-ARR_v2_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_18",
            "tgt_ix": "23-ARR_v2_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_19",
            "tgt_ix": "23-ARR_v2_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_19",
            "tgt_ix": "23-ARR_v2_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_19",
            "tgt_ix": "23-ARR_v2_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_20",
            "tgt_ix": "23-ARR_v2_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_22",
            "tgt_ix": "23-ARR_v2_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_23",
            "tgt_ix": "23-ARR_v2_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_24",
            "tgt_ix": "23-ARR_v2_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_21",
            "tgt_ix": "23-ARR_v2_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_21",
            "tgt_ix": "23-ARR_v2_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_21",
            "tgt_ix": "23-ARR_v2_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_21",
            "tgt_ix": "23-ARR_v2_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_21",
            "tgt_ix": "23-ARR_v2_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_19",
            "tgt_ix": "23-ARR_v2_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_25",
            "tgt_ix": "23-ARR_v2_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_27",
            "tgt_ix": "23-ARR_v2_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_28",
            "tgt_ix": "23-ARR_v2_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_29",
            "tgt_ix": "23-ARR_v2_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_26",
            "tgt_ix": "23-ARR_v2_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_26",
            "tgt_ix": "23-ARR_v2_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_26",
            "tgt_ix": "23-ARR_v2_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_26",
            "tgt_ix": "23-ARR_v2_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_26",
            "tgt_ix": "23-ARR_v2_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_0",
            "tgt_ix": "23-ARR_v2_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_30",
            "tgt_ix": "23-ARR_v2_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_32",
            "tgt_ix": "23-ARR_v2_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_33",
            "tgt_ix": "23-ARR_v2_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_31",
            "tgt_ix": "23-ARR_v2_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_31",
            "tgt_ix": "23-ARR_v2_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_31",
            "tgt_ix": "23-ARR_v2_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_31",
            "tgt_ix": "23-ARR_v2_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_31",
            "tgt_ix": "23-ARR_v2_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_34",
            "tgt_ix": "23-ARR_v2_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_35",
            "tgt_ix": "23-ARR_v2_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_35",
            "tgt_ix": "23-ARR_v2_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_31",
            "tgt_ix": "23-ARR_v2_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_36",
            "tgt_ix": "23-ARR_v2_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_38",
            "tgt_ix": "23-ARR_v2_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_39",
            "tgt_ix": "23-ARR_v2_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_40",
            "tgt_ix": "23-ARR_v2_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_41",
            "tgt_ix": "23-ARR_v2_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_42",
            "tgt_ix": "23-ARR_v2_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_37",
            "tgt_ix": "23-ARR_v2_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_37",
            "tgt_ix": "23-ARR_v2_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_37",
            "tgt_ix": "23-ARR_v2_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_37",
            "tgt_ix": "23-ARR_v2_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_37",
            "tgt_ix": "23-ARR_v2_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_37",
            "tgt_ix": "23-ARR_v2_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_37",
            "tgt_ix": "23-ARR_v2_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_0",
            "tgt_ix": "23-ARR_v2_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_43",
            "tgt_ix": "23-ARR_v2_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_44",
            "tgt_ix": "23-ARR_v2_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_44",
            "tgt_ix": "23-ARR_v2_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_44",
            "tgt_ix": "23-ARR_v2_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_45",
            "tgt_ix": "23-ARR_v2_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_47",
            "tgt_ix": "23-ARR_v2_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_48",
            "tgt_ix": "23-ARR_v2_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_46",
            "tgt_ix": "23-ARR_v2_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_46",
            "tgt_ix": "23-ARR_v2_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_46",
            "tgt_ix": "23-ARR_v2_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_46",
            "tgt_ix": "23-ARR_v2_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_44",
            "tgt_ix": "23-ARR_v2_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_49",
            "tgt_ix": "23-ARR_v2_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_51",
            "tgt_ix": "23-ARR_v2_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_50",
            "tgt_ix": "23-ARR_v2_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_50",
            "tgt_ix": "23-ARR_v2_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_50",
            "tgt_ix": "23-ARR_v2_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_44",
            "tgt_ix": "23-ARR_v2_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_52",
            "tgt_ix": "23-ARR_v2_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_53",
            "tgt_ix": "23-ARR_v2_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_53",
            "tgt_ix": "23-ARR_v2_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_44",
            "tgt_ix": "23-ARR_v2_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_54",
            "tgt_ix": "23-ARR_v2_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_56",
            "tgt_ix": "23-ARR_v2_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_57",
            "tgt_ix": "23-ARR_v2_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_58",
            "tgt_ix": "23-ARR_v2_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_55",
            "tgt_ix": "23-ARR_v2_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_55",
            "tgt_ix": "23-ARR_v2_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_55",
            "tgt_ix": "23-ARR_v2_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_55",
            "tgt_ix": "23-ARR_v2_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_55",
            "tgt_ix": "23-ARR_v2_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_44",
            "tgt_ix": "23-ARR_v2_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_59",
            "tgt_ix": "23-ARR_v2_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_60",
            "tgt_ix": "23-ARR_v2_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_60",
            "tgt_ix": "23-ARR_v2_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_0",
            "tgt_ix": "23-ARR_v2_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_61",
            "tgt_ix": "23-ARR_v2_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_62",
            "tgt_ix": "23-ARR_v2_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_62",
            "tgt_ix": "23-ARR_v2_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "23-ARR_v2_0",
            "tgt_ix": "23-ARR_v2_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_1",
            "tgt_ix": "23-ARR_v2_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_2",
            "tgt_ix": "23-ARR_v2_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_2",
            "tgt_ix": "23-ARR_v2_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_3",
            "tgt_ix": "23-ARR_v2_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_3",
            "tgt_ix": "23-ARR_v2_3@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_3",
            "tgt_ix": "23-ARR_v2_3@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_3",
            "tgt_ix": "23-ARR_v2_3@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_4",
            "tgt_ix": "23-ARR_v2_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_5",
            "tgt_ix": "23-ARR_v2_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_5",
            "tgt_ix": "23-ARR_v2_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_5",
            "tgt_ix": "23-ARR_v2_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_6",
            "tgt_ix": "23-ARR_v2_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_6",
            "tgt_ix": "23-ARR_v2_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_6",
            "tgt_ix": "23-ARR_v2_6@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_7",
            "tgt_ix": "23-ARR_v2_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_7",
            "tgt_ix": "23-ARR_v2_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_7",
            "tgt_ix": "23-ARR_v2_7@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_8",
            "tgt_ix": "23-ARR_v2_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_8",
            "tgt_ix": "23-ARR_v2_8@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_8",
            "tgt_ix": "23-ARR_v2_8@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_8",
            "tgt_ix": "23-ARR_v2_8@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_8",
            "tgt_ix": "23-ARR_v2_8@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_8",
            "tgt_ix": "23-ARR_v2_8@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_9",
            "tgt_ix": "23-ARR_v2_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_9",
            "tgt_ix": "23-ARR_v2_9@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_9",
            "tgt_ix": "23-ARR_v2_9@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_10",
            "tgt_ix": "23-ARR_v2_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_11",
            "tgt_ix": "23-ARR_v2_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_12",
            "tgt_ix": "23-ARR_v2_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_12",
            "tgt_ix": "23-ARR_v2_12@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_12",
            "tgt_ix": "23-ARR_v2_12@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_12",
            "tgt_ix": "23-ARR_v2_12@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_13",
            "tgt_ix": "23-ARR_v2_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_13",
            "tgt_ix": "23-ARR_v2_13@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_13",
            "tgt_ix": "23-ARR_v2_13@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_13",
            "tgt_ix": "23-ARR_v2_13@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_14",
            "tgt_ix": "23-ARR_v2_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_14",
            "tgt_ix": "23-ARR_v2_14@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_14",
            "tgt_ix": "23-ARR_v2_14@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_14",
            "tgt_ix": "23-ARR_v2_14@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_15",
            "tgt_ix": "23-ARR_v2_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_16",
            "tgt_ix": "23-ARR_v2_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_16",
            "tgt_ix": "23-ARR_v2_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_16",
            "tgt_ix": "23-ARR_v2_16@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_16",
            "tgt_ix": "23-ARR_v2_16@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_16",
            "tgt_ix": "23-ARR_v2_16@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_17",
            "tgt_ix": "23-ARR_v2_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_17",
            "tgt_ix": "23-ARR_v2_17@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_17",
            "tgt_ix": "23-ARR_v2_17@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_17",
            "tgt_ix": "23-ARR_v2_17@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_17",
            "tgt_ix": "23-ARR_v2_17@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_17",
            "tgt_ix": "23-ARR_v2_17@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_17",
            "tgt_ix": "23-ARR_v2_17@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_17",
            "tgt_ix": "23-ARR_v2_17@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_17",
            "tgt_ix": "23-ARR_v2_17@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_17",
            "tgt_ix": "23-ARR_v2_17@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_18",
            "tgt_ix": "23-ARR_v2_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_18",
            "tgt_ix": "23-ARR_v2_18@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_18",
            "tgt_ix": "23-ARR_v2_18@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_18",
            "tgt_ix": "23-ARR_v2_18@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_18",
            "tgt_ix": "23-ARR_v2_18@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_18",
            "tgt_ix": "23-ARR_v2_18@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_18",
            "tgt_ix": "23-ARR_v2_18@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_18",
            "tgt_ix": "23-ARR_v2_18@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_18",
            "tgt_ix": "23-ARR_v2_18@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_18",
            "tgt_ix": "23-ARR_v2_18@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_18",
            "tgt_ix": "23-ARR_v2_18@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_18",
            "tgt_ix": "23-ARR_v2_18@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_18",
            "tgt_ix": "23-ARR_v2_18@12",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_18",
            "tgt_ix": "23-ARR_v2_18@13",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_18",
            "tgt_ix": "23-ARR_v2_18@14",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_18",
            "tgt_ix": "23-ARR_v2_18@15",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_18",
            "tgt_ix": "23-ARR_v2_18@16",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_18",
            "tgt_ix": "23-ARR_v2_18@17",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_18",
            "tgt_ix": "23-ARR_v2_18@18",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_18",
            "tgt_ix": "23-ARR_v2_18@19",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_18",
            "tgt_ix": "23-ARR_v2_18@20",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_18",
            "tgt_ix": "23-ARR_v2_18@21",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_18",
            "tgt_ix": "23-ARR_v2_18@22",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_19",
            "tgt_ix": "23-ARR_v2_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_20",
            "tgt_ix": "23-ARR_v2_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_20",
            "tgt_ix": "23-ARR_v2_20@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_21",
            "tgt_ix": "23-ARR_v2_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_22",
            "tgt_ix": "23-ARR_v2_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_22",
            "tgt_ix": "23-ARR_v2_22@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_23",
            "tgt_ix": "23-ARR_v2_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_23",
            "tgt_ix": "23-ARR_v2_23@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_23",
            "tgt_ix": "23-ARR_v2_23@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_23",
            "tgt_ix": "23-ARR_v2_23@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_23",
            "tgt_ix": "23-ARR_v2_23@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_23",
            "tgt_ix": "23-ARR_v2_23@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_23",
            "tgt_ix": "23-ARR_v2_23@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_23",
            "tgt_ix": "23-ARR_v2_23@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_24",
            "tgt_ix": "23-ARR_v2_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_24",
            "tgt_ix": "23-ARR_v2_24@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_24",
            "tgt_ix": "23-ARR_v2_24@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_24",
            "tgt_ix": "23-ARR_v2_24@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_25",
            "tgt_ix": "23-ARR_v2_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_25",
            "tgt_ix": "23-ARR_v2_25@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_25",
            "tgt_ix": "23-ARR_v2_25@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_26",
            "tgt_ix": "23-ARR_v2_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_27",
            "tgt_ix": "23-ARR_v2_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_27",
            "tgt_ix": "23-ARR_v2_27@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_27",
            "tgt_ix": "23-ARR_v2_27@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_27",
            "tgt_ix": "23-ARR_v2_27@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_27",
            "tgt_ix": "23-ARR_v2_27@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_28",
            "tgt_ix": "23-ARR_v2_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_29",
            "tgt_ix": "23-ARR_v2_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_29",
            "tgt_ix": "23-ARR_v2_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_29",
            "tgt_ix": "23-ARR_v2_29@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_29",
            "tgt_ix": "23-ARR_v2_29@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_30",
            "tgt_ix": "23-ARR_v2_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_30",
            "tgt_ix": "23-ARR_v2_30@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_31",
            "tgt_ix": "23-ARR_v2_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_32",
            "tgt_ix": "23-ARR_v2_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_32",
            "tgt_ix": "23-ARR_v2_32@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_32",
            "tgt_ix": "23-ARR_v2_32@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_32",
            "tgt_ix": "23-ARR_v2_32@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_33",
            "tgt_ix": "23-ARR_v2_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_33",
            "tgt_ix": "23-ARR_v2_33@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_33",
            "tgt_ix": "23-ARR_v2_33@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_33",
            "tgt_ix": "23-ARR_v2_33@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_33",
            "tgt_ix": "23-ARR_v2_33@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_33",
            "tgt_ix": "23-ARR_v2_33@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_33",
            "tgt_ix": "23-ARR_v2_33@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_33",
            "tgt_ix": "23-ARR_v2_33@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_33",
            "tgt_ix": "23-ARR_v2_33@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_34",
            "tgt_ix": "23-ARR_v2_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_34",
            "tgt_ix": "23-ARR_v2_34@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_34",
            "tgt_ix": "23-ARR_v2_34@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_34",
            "tgt_ix": "23-ARR_v2_34@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_34",
            "tgt_ix": "23-ARR_v2_34@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_35",
            "tgt_ix": "23-ARR_v2_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_36",
            "tgt_ix": "23-ARR_v2_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_36",
            "tgt_ix": "23-ARR_v2_36@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_36",
            "tgt_ix": "23-ARR_v2_36@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_36",
            "tgt_ix": "23-ARR_v2_36@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_37",
            "tgt_ix": "23-ARR_v2_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_38",
            "tgt_ix": "23-ARR_v2_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_38",
            "tgt_ix": "23-ARR_v2_38@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_39",
            "tgt_ix": "23-ARR_v2_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_40",
            "tgt_ix": "23-ARR_v2_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_40",
            "tgt_ix": "23-ARR_v2_40@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_40",
            "tgt_ix": "23-ARR_v2_40@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_41",
            "tgt_ix": "23-ARR_v2_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_42",
            "tgt_ix": "23-ARR_v2_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_42",
            "tgt_ix": "23-ARR_v2_42@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_42",
            "tgt_ix": "23-ARR_v2_42@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_42",
            "tgt_ix": "23-ARR_v2_42@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_42",
            "tgt_ix": "23-ARR_v2_42@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_42",
            "tgt_ix": "23-ARR_v2_42@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_43",
            "tgt_ix": "23-ARR_v2_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_43",
            "tgt_ix": "23-ARR_v2_43@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_43",
            "tgt_ix": "23-ARR_v2_43@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_43",
            "tgt_ix": "23-ARR_v2_43@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_43",
            "tgt_ix": "23-ARR_v2_43@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_43",
            "tgt_ix": "23-ARR_v2_43@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_44",
            "tgt_ix": "23-ARR_v2_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_45",
            "tgt_ix": "23-ARR_v2_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_46",
            "tgt_ix": "23-ARR_v2_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_47",
            "tgt_ix": "23-ARR_v2_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_47",
            "tgt_ix": "23-ARR_v2_47@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_47",
            "tgt_ix": "23-ARR_v2_47@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_47",
            "tgt_ix": "23-ARR_v2_47@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_47",
            "tgt_ix": "23-ARR_v2_47@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_47",
            "tgt_ix": "23-ARR_v2_47@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_48",
            "tgt_ix": "23-ARR_v2_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_48",
            "tgt_ix": "23-ARR_v2_48@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_48",
            "tgt_ix": "23-ARR_v2_48@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_48",
            "tgt_ix": "23-ARR_v2_48@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_49",
            "tgt_ix": "23-ARR_v2_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_49",
            "tgt_ix": "23-ARR_v2_49@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_49",
            "tgt_ix": "23-ARR_v2_49@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_49",
            "tgt_ix": "23-ARR_v2_49@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_49",
            "tgt_ix": "23-ARR_v2_49@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_49",
            "tgt_ix": "23-ARR_v2_49@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_49",
            "tgt_ix": "23-ARR_v2_49@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_49",
            "tgt_ix": "23-ARR_v2_49@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_50",
            "tgt_ix": "23-ARR_v2_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_51",
            "tgt_ix": "23-ARR_v2_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_51",
            "tgt_ix": "23-ARR_v2_51@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_51",
            "tgt_ix": "23-ARR_v2_51@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_51",
            "tgt_ix": "23-ARR_v2_51@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_51",
            "tgt_ix": "23-ARR_v2_51@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_51",
            "tgt_ix": "23-ARR_v2_51@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_52",
            "tgt_ix": "23-ARR_v2_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_52",
            "tgt_ix": "23-ARR_v2_52@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_52",
            "tgt_ix": "23-ARR_v2_52@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_52",
            "tgt_ix": "23-ARR_v2_52@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_52",
            "tgt_ix": "23-ARR_v2_52@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_52",
            "tgt_ix": "23-ARR_v2_52@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_52",
            "tgt_ix": "23-ARR_v2_52@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_52",
            "tgt_ix": "23-ARR_v2_52@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_52",
            "tgt_ix": "23-ARR_v2_52@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_52",
            "tgt_ix": "23-ARR_v2_52@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_52",
            "tgt_ix": "23-ARR_v2_52@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_53",
            "tgt_ix": "23-ARR_v2_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_54",
            "tgt_ix": "23-ARR_v2_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_54",
            "tgt_ix": "23-ARR_v2_54@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_54",
            "tgt_ix": "23-ARR_v2_54@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_54",
            "tgt_ix": "23-ARR_v2_54@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_54",
            "tgt_ix": "23-ARR_v2_54@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_54",
            "tgt_ix": "23-ARR_v2_54@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_55",
            "tgt_ix": "23-ARR_v2_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_56",
            "tgt_ix": "23-ARR_v2_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_56",
            "tgt_ix": "23-ARR_v2_56@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_56",
            "tgt_ix": "23-ARR_v2_56@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_56",
            "tgt_ix": "23-ARR_v2_56@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_56",
            "tgt_ix": "23-ARR_v2_56@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_56",
            "tgt_ix": "23-ARR_v2_56@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_56",
            "tgt_ix": "23-ARR_v2_56@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_57",
            "tgt_ix": "23-ARR_v2_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_57",
            "tgt_ix": "23-ARR_v2_57@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_58",
            "tgt_ix": "23-ARR_v2_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_58",
            "tgt_ix": "23-ARR_v2_58@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_58",
            "tgt_ix": "23-ARR_v2_58@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_58",
            "tgt_ix": "23-ARR_v2_58@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_58",
            "tgt_ix": "23-ARR_v2_58@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_58",
            "tgt_ix": "23-ARR_v2_58@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_59",
            "tgt_ix": "23-ARR_v2_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_59",
            "tgt_ix": "23-ARR_v2_59@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_60",
            "tgt_ix": "23-ARR_v2_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_61",
            "tgt_ix": "23-ARR_v2_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_61",
            "tgt_ix": "23-ARR_v2_61@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_61",
            "tgt_ix": "23-ARR_v2_61@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_61",
            "tgt_ix": "23-ARR_v2_61@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_61",
            "tgt_ix": "23-ARR_v2_61@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_61",
            "tgt_ix": "23-ARR_v2_61@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_61",
            "tgt_ix": "23-ARR_v2_61@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_61",
            "tgt_ix": "23-ARR_v2_61@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_62",
            "tgt_ix": "23-ARR_v2_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_63",
            "tgt_ix": "23-ARR_v2_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_63",
            "tgt_ix": "23-ARR_v2_63@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_63",
            "tgt_ix": "23-ARR_v2_63@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_63",
            "tgt_ix": "23-ARR_v2_63@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_63",
            "tgt_ix": "23-ARR_v2_63@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_63",
            "tgt_ix": "23-ARR_v2_63@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_63",
            "tgt_ix": "23-ARR_v2_63@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_63",
            "tgt_ix": "23-ARR_v2_63@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_64",
            "tgt_ix": "23-ARR_v2_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_65",
            "tgt_ix": "23-ARR_v2_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_66",
            "tgt_ix": "23-ARR_v2_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_67",
            "tgt_ix": "23-ARR_v2_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_68",
            "tgt_ix": "23-ARR_v2_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_69",
            "tgt_ix": "23-ARR_v2_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_70",
            "tgt_ix": "23-ARR_v2_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_71",
            "tgt_ix": "23-ARR_v2_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_72",
            "tgt_ix": "23-ARR_v2_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_73",
            "tgt_ix": "23-ARR_v2_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_74",
            "tgt_ix": "23-ARR_v2_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_75",
            "tgt_ix": "23-ARR_v2_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_76",
            "tgt_ix": "23-ARR_v2_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_77",
            "tgt_ix": "23-ARR_v2_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_78",
            "tgt_ix": "23-ARR_v2_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_79",
            "tgt_ix": "23-ARR_v2_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_80",
            "tgt_ix": "23-ARR_v2_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_81",
            "tgt_ix": "23-ARR_v2_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_82",
            "tgt_ix": "23-ARR_v2_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_83",
            "tgt_ix": "23-ARR_v2_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_84",
            "tgt_ix": "23-ARR_v2_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_85",
            "tgt_ix": "23-ARR_v2_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_86",
            "tgt_ix": "23-ARR_v2_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_87",
            "tgt_ix": "23-ARR_v2_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_88",
            "tgt_ix": "23-ARR_v2_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_89",
            "tgt_ix": "23-ARR_v2_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_90",
            "tgt_ix": "23-ARR_v2_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_91",
            "tgt_ix": "23-ARR_v2_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_92",
            "tgt_ix": "23-ARR_v2_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_93",
            "tgt_ix": "23-ARR_v2_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_94",
            "tgt_ix": "23-ARR_v2_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_95",
            "tgt_ix": "23-ARR_v2_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_96",
            "tgt_ix": "23-ARR_v2_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_97",
            "tgt_ix": "23-ARR_v2_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_98",
            "tgt_ix": "23-ARR_v2_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_99",
            "tgt_ix": "23-ARR_v2_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_100",
            "tgt_ix": "23-ARR_v2_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_101",
            "tgt_ix": "23-ARR_v2_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "23-ARR_v2_102",
            "tgt_ix": "23-ARR_v2_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 810,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "doc_id": "23-ARR",
        "version": 2
    }
}